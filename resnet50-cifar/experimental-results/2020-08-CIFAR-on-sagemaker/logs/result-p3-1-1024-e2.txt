wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 6:50
   221184/170498071 [..............................] - ETA: 1:03
  1687552/170498071 [..............................] - ETA: 13s 
  4956160/170498071 [..............................] - ETA: 6s 
  9248768/170498071 [>.............................] - ETA: 4s
 13090816/170498071 [=>............................] - ETA: 3s
 16932864/170498071 [=>............................] - ETA: 3s
 20258816/170498071 [==>...........................] - ETA: 2s
 24059904/170498071 [===>..........................] - ETA: 2s
 27926528/170498071 [===>..........................] - ETA: 2s
 31252480/170498071 [====>.........................] - ETA: 2s
 35086336/170498071 [=====>........................] - ETA: 2s
 38920192/170498071 [=====>........................] - ETA: 2s
 42180608/170498071 [======>.......................] - ETA: 2s
 45948928/170498071 [=======>......................] - ETA: 2s
 49799168/170498071 [=======>......................] - ETA: 1s
 53108736/170498071 [========>.....................] - ETA: 1s
 56909824/170498071 [=========>....................] - ETA: 1s
 60768256/170498071 [=========>....................] - ETA: 1s
 64053248/170498071 [==========>...................] - ETA: 1s
 67788800/170498071 [==========>...................] - ETA: 1s
 71532544/170498071 [===========>..................] - ETA: 1s
 74997760/170498071 [============>.................] - ETA: 1s
 78618624/170498071 [============>.................] - ETA: 1s
 82444288/170498071 [=============>................] - ETA: 1s
 85975040/170498071 [==============>...............] - ETA: 1s
 89628672/170498071 [==============>...............] - ETA: 1s
 93446144/170498071 [===============>..............] - ETA: 1s
 96903168/170498071 [================>.............] - ETA: 1s
100540416/170498071 [================>.............] - ETA: 1s
104333312/170498071 [=================>............] - ETA: 0s
107847680/170498071 [=================>............] - ETA: 0s
111419392/170498071 [==================>...........] - ETA: 0s
115212288/170498071 [===================>..........] - ETA: 0s
118775808/170498071 [===================>..........] - ETA: 0s
122331136/170498071 [====================>.........] - ETA: 0s
126107648/170498071 [=====================>........] - ETA: 0s
129720320/170498071 [=====================>........] - ETA: 0s
133251072/170498071 [======================>.......] - ETA: 0s
136994816/170498071 [=======================>......] - ETA: 0s
140632064/170498071 [=======================>......] - ETA: 0s
144162816/170498071 [========================>.....] - ETA: 0s
147922944/170498071 [=========================>....] - ETA: 0s
151592960/170498071 [=========================>....] - ETA: 0s
155090944/170498071 [==========================>...] - ETA: 0s
158801920/170498071 [==========================>...] - ETA: 0s
162521088/170498071 [===========================>..] - ETA: 0s
165994496/170498071 [============================>.] - ETA: 0s
169713664/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 2s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 4530176/94765736 [>.............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 1s
12926976/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
24346624/94765736 [======>.......................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
33792000/94765736 [=========>....................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
40706048/94765736 [===========>..................] - ETA: 0s
45957120/94765736 [=============>................] - ETA: 0s
48668672/94765736 [==============>...............] - ETA: 0s
56582144/94765736 [================>.............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
61800448/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
69713920/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
78651392/94765736 [=======================>......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
90423296/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 15.532572507858276
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1609195288.709663s

Real time: 1609195288.7096934
Epoch 1/5

on_train_batch_begin: 1609195289.681145s

on_train_batch_end: 1609195307.444051s

 1024/50000 [..............................] - ETA: 14:56 - loss: 17.8137 - accuracy: 2.0218e-04
on_train_batch_begin: 1609195307.444886s

1 step training time: 17.763741s

on_train_batch_end: 1609195307.564520s

 2048/50000 [>.............................] - ETA: 7:21 - loss: 15.2368 - accuracy: 1.0109e-04 
on_train_batch_begin: 1609195307.565048s

2 step training time: 0.120162s

on_train_batch_end: 1609195307.686514s

 3072/50000 [>.............................] - ETA: 4:49 - loss: 13.2549 - accuracy: 2.9500e-04
on_train_batch_begin: 1609195307.686986s

3 step training time: 0.121938s

on_train_batch_end: 1609195307.804890s

 4096/50000 [=>............................] - ETA: 3:34 - loss: 12.0814 - accuracy: 0.0015    
on_train_batch_begin: 1609195307.805361s

4 step training time: 0.118375s

on_train_batch_end: 1609195307.923827s

 5120/50000 [==>...........................] - ETA: 2:48 - loss: 11.3261 - accuracy: 0.0042
on_train_batch_begin: 1609195307.924319s

5 step training time: 0.118959s

on_train_batch_end: 1609195308.044094s

 6144/50000 [==>...........................] - ETA: 2:18 - loss: 10.7962 - accuracy: 0.0097
on_train_batch_begin: 1609195308.044556s

6 step training time: 0.120237s

on_train_batch_end: 1609195308.162650s

 7168/50000 [===>..........................] - ETA: 1:56 - loss: 10.4279 - accuracy: 0.0139
on_train_batch_begin: 1609195308.163129s

7 step training time: 0.118573s

on_train_batch_end: 1609195308.283056s

 8192/50000 [===>..........................] - ETA: 1:39 - loss: 10.1280 - accuracy: 0.0183
on_train_batch_begin: 1609195308.283541s

8 step training time: 0.120412s

on_train_batch_end: 1609195308.402081s

 9216/50000 [====>.........................] - ETA: 1:27 - loss: 9.9028 - accuracy: 0.0223 
on_train_batch_begin: 1609195308.402554s

9 step training time: 0.119013s

on_train_batch_end: 1609195308.520353s

10240/50000 [=====>........................] - ETA: 1:16 - loss: 9.6903 - accuracy: 0.0265
on_train_batch_begin: 1609195308.520823s

10 step training time: 0.118268s

on_train_batch_end: 1609195308.639006s

11264/50000 [=====>........................] - ETA: 1:08 - loss: 9.5179 - accuracy: 0.0303
on_train_batch_begin: 1609195308.639482s

11 step training time: 0.118659s

on_train_batch_end: 1609195308.757775s

12288/50000 [======>.......................] - ETA: 1:01 - loss: 9.3749 - accuracy: 0.0355
on_train_batch_begin: 1609195308.758243s

12 step training time: 0.118762s

on_train_batch_end: 1609195308.876934s

13312/50000 [======>.......................] - ETA: 55s - loss: 9.2498 - accuracy: 0.0382 
on_train_batch_begin: 1609195308.877406s

13 step training time: 0.119163s

on_train_batch_end: 1609195308.996025s

14336/50000 [=======>......................] - ETA: 50s - loss: 9.1387 - accuracy: 0.0410
on_train_batch_begin: 1609195308.996491s

14 step training time: 0.119085s

on_train_batch_end: 1609195309.117923s

15360/50000 [========>.....................] - ETA: 46s - loss: 9.0423 - accuracy: 0.0438
on_train_batch_begin: 1609195309.118399s

15 step training time: 0.121908s

on_train_batch_end: 1609195309.236060s

16384/50000 [========>.....................] - ETA: 42s - loss: 8.9646 - accuracy: 0.0469
on_train_batch_begin: 1609195309.236535s

16 step training time: 0.118136s

on_train_batch_end: 1609195309.354129s

17408/50000 [=========>....................] - ETA: 38s - loss: 8.8923 - accuracy: 0.0489
on_train_batch_begin: 1609195309.354600s

17 step training time: 0.118065s

on_train_batch_end: 1609195309.471446s

18432/50000 [==========>...................] - ETA: 35s - loss: 8.8173 - accuracy: 0.0511
on_train_batch_begin: 1609195309.471902s

18 step training time: 0.117302s

on_train_batch_end: 1609195309.589508s

19456/50000 [==========>...................] - ETA: 32s - loss: 8.7523 - accuracy: 0.0527
on_train_batch_begin: 1609195309.589972s

19 step training time: 0.118069s

on_train_batch_end: 1609195309.708037s

20480/50000 [===========>..................] - ETA: 30s - loss: 8.7027 - accuracy: 0.0549
on_train_batch_begin: 1609195309.708503s

20 step training time: 0.118531s

on_train_batch_end: 1609195309.827014s

21504/50000 [===========>..................] - ETA: 27s - loss: 8.6496 - accuracy: 0.0569
on_train_batch_begin: 1609195309.827478s

21 step training time: 0.118976s

on_train_batch_end: 1609195309.945287s

22528/50000 [============>.................] - ETA: 25s - loss: 8.6015 - accuracy: 0.0584
on_train_batch_begin: 1609195309.945748s

22 step training time: 0.118270s

on_train_batch_end: 1609195310.063684s

23552/50000 [=============>................] - ETA: 23s - loss: 8.5606 - accuracy: 0.0594
on_train_batch_begin: 1609195310.064143s

23 step training time: 0.118395s

on_train_batch_end: 1609195310.182115s

24576/50000 [=============>................] - ETA: 22s - loss: 8.5153 - accuracy: 0.0608
on_train_batch_begin: 1609195310.182573s

24 step training time: 0.118430s

on_train_batch_end: 1609195310.300220s

25600/50000 [==============>...............] - ETA: 20s - loss: 8.4805 - accuracy: 0.0625
on_train_batch_begin: 1609195310.300678s

25 step training time: 0.118105s

on_train_batch_end: 1609195310.419144s

26624/50000 [==============>...............] - ETA: 19s - loss: 8.4414 - accuracy: 0.0636
on_train_batch_begin: 1609195310.419600s

26 step training time: 0.118922s

on_train_batch_end: 1609195310.537777s

27648/50000 [===============>..............] - ETA: 17s - loss: 8.4028 - accuracy: 0.0646
on_train_batch_begin: 1609195310.538242s

27 step training time: 0.118642s

on_train_batch_end: 1609195310.655679s

28672/50000 [================>.............] - ETA: 16s - loss: 8.3690 - accuracy: 0.0657
on_train_batch_begin: 1609195310.656142s

28 step training time: 0.117900s

on_train_batch_end: 1609195310.774351s

29696/50000 [================>.............] - ETA: 15s - loss: 8.3385 - accuracy: 0.0668
on_train_batch_begin: 1609195310.774823s

29 step training time: 0.118682s

on_train_batch_end: 1609195310.893388s

30720/50000 [=================>............] - ETA: 13s - loss: 8.3167 - accuracy: 0.0680
on_train_batch_begin: 1609195310.893873s

30 step training time: 0.119050s

on_train_batch_end: 1609195311.011090s

31744/50000 [==================>...........] - ETA: 12s - loss: 8.2870 - accuracy: 0.0689
on_train_batch_begin: 1609195311.011568s

31 step training time: 0.117695s

on_train_batch_end: 1609195311.129587s

32768/50000 [==================>...........] - ETA: 11s - loss: 8.2586 - accuracy: 0.0696
on_train_batch_begin: 1609195311.130047s

32 step training time: 0.118479s

on_train_batch_end: 1609195311.248542s

33792/50000 [===================>..........] - ETA: 10s - loss: 8.2313 - accuracy: 0.0700
on_train_batch_begin: 1609195311.249043s

33 step training time: 0.118996s

on_train_batch_end: 1609195311.366696s

34816/50000 [===================>..........] - ETA: 9s - loss: 8.2045 - accuracy: 0.0704 
on_train_batch_begin: 1609195311.367156s

34 step training time: 0.118113s

on_train_batch_end: 1609195311.485216s

35840/50000 [====================>.........] - ETA: 8s - loss: 8.1849 - accuracy: 0.0711
on_train_batch_begin: 1609195311.485681s

35 step training time: 0.118525s

on_train_batch_end: 1609195311.603577s

36864/50000 [=====================>........] - ETA: 8s - loss: 8.1603 - accuracy: 0.0717
on_train_batch_begin: 1609195311.604035s

36 step training time: 0.118354s

on_train_batch_end: 1609195311.721671s

37888/50000 [=====================>........] - ETA: 7s - loss: 8.1358 - accuracy: 0.0721
on_train_batch_begin: 1609195311.722159s

37 step training time: 0.118124s

on_train_batch_end: 1609195311.839895s

38912/50000 [======================>.......] - ETA: 6s - loss: 8.1142 - accuracy: 0.0729
on_train_batch_begin: 1609195311.840374s

38 step training time: 0.118215s

on_train_batch_end: 1609195311.957863s

39936/50000 [======================>.......] - ETA: 5s - loss: 8.0931 - accuracy: 0.0733
on_train_batch_begin: 1609195311.958366s

39 step training time: 0.117991s

on_train_batch_end: 1609195312.077312s

40960/50000 [=======================>......] - ETA: 5s - loss: 8.0706 - accuracy: 0.0736
on_train_batch_begin: 1609195312.077883s

40 step training time: 0.119517s

on_train_batch_end: 1609195312.195709s

41984/50000 [========================>.....] - ETA: 4s - loss: 8.0465 - accuracy: 0.0742
on_train_batch_begin: 1609195312.196182s

41 step training time: 0.118300s

on_train_batch_end: 1609195312.314172s

43008/50000 [========================>.....] - ETA: 3s - loss: 8.0254 - accuracy: 0.0747
on_train_batch_begin: 1609195312.314645s

42 step training time: 0.118463s

on_train_batch_end: 1609195312.433044s

44032/50000 [=========================>....] - ETA: 3s - loss: 8.0048 - accuracy: 0.0753
on_train_batch_begin: 1609195312.433511s

43 step training time: 0.118866s

on_train_batch_end: 1609195312.551217s

45056/50000 [==========================>...] - ETA: 2s - loss: 7.9883 - accuracy: 0.0758
on_train_batch_begin: 1609195312.551679s

44 step training time: 0.118168s

on_train_batch_end: 1609195312.669289s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.9721 - accuracy: 0.0759
on_train_batch_begin: 1609195312.669757s

45 step training time: 0.118078s

on_train_batch_end: 1609195312.787136s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.9500 - accuracy: 0.0762
on_train_batch_begin: 1609195312.787629s

46 step training time: 0.117872s

on_train_batch_end: 1609195312.906077s

48128/50000 [===========================>..] - ETA: 0s - loss: 7.9336 - accuracy: 0.0762
on_train_batch_begin: 1609195312.906544s

47 step training time: 0.118915s

on_train_batch_end: 1609195313.023754s

49152/50000 [============================>.] - ETA: 0s - loss: 7.9152 - accuracy: 0.0764
on_train_batch_begin: 1609195313.024217s

48 step training time: 0.117673s

on_train_batch_end: 1609195314.872229s

on_test_batch_begin: 1609195315.114603s

49 step training time: 2.090386s

on_epoch_end: 1609195318.626043s

Validation time: 3.511401s

Real time: 1609195318.626043s

Epoch time: 29.91637635231018s

50000/50000 [==============================] - 30s 598us/sample - loss: 7.8994 - accuracy: 0.0768 - val_loss: 10.4542 - val_accuracy: 0.1001

on_epoch_begin: 1609195318.626341s

Real time: 1609195318.626351
Epoch 2/5

on_train_batch_begin: 1609195318.630696s

on_train_batch_end: 1609195318.748739s

 1024/50000 [..............................] - ETA: 5s - loss: 7.0903 - accuracy: 0.0900
on_train_batch_begin: 1609195318.749243s

1 step training time: 0.118547s

on_train_batch_end: 1609195318.867287s

 2048/50000 [>.............................] - ETA: 5s - loss: 7.0038 - accuracy: 0.0985
on_train_batch_begin: 1609195318.867787s

2 step training time: 0.118544s

on_train_batch_end: 1609195318.990158s

 3072/50000 [>.............................] - ETA: 5s - loss: 7.0251 - accuracy: 0.0998
on_train_batch_begin: 1609195318.990615s

3 step training time: 0.122828s

on_train_batch_end: 1609195319.109189s

 4096/50000 [=>............................] - ETA: 5s - loss: 7.0157 - accuracy: 0.0983
on_train_batch_begin: 1609195319.109651s

4 step training time: 0.119035s

on_train_batch_end: 1609195319.227136s

 5120/50000 [==>...........................] - ETA: 5s - loss: 7.0208 - accuracy: 0.0965
on_train_batch_begin: 1609195319.227595s

5 step training time: 0.117944s

on_train_batch_end: 1609195319.345818s

 6144/50000 [==>...........................] - ETA: 5s - loss: 7.0173 - accuracy: 0.0980
on_train_batch_begin: 1609195319.346282s

6 step training time: 0.118687s

on_train_batch_end: 1609195319.464178s

 7168/50000 [===>..........................] - ETA: 5s - loss: 6.9959 - accuracy: 0.0983
on_train_batch_begin: 1609195319.464656s

7 step training time: 0.118374s

on_train_batch_end: 1609195319.582654s

 8192/50000 [===>..........................] - ETA: 4s - loss: 6.9867 - accuracy: 0.0974
on_train_batch_begin: 1609195319.583137s

8 step training time: 0.118481s

on_train_batch_end: 1609195319.700602s

 9216/50000 [====>.........................] - ETA: 4s - loss: 6.9885 - accuracy: 0.0968
on_train_batch_begin: 1609195319.701102s

9 step training time: 0.117965s

on_train_batch_end: 1609195319.820900s

10240/50000 [=====>........................] - ETA: 4s - loss: 6.9791 - accuracy: 0.0969
on_train_batch_begin: 1609195319.821363s

10 step training time: 0.120261s

on_train_batch_end: 1609195319.939091s

11264/50000 [=====>........................] - ETA: 4s - loss: 6.9738 - accuracy: 0.0973
on_train_batch_begin: 1609195319.939555s

11 step training time: 0.118192s

on_train_batch_end: 1609195320.057423s

12288/50000 [======>.......................] - ETA: 4s - loss: 6.9689 - accuracy: 0.0981
on_train_batch_begin: 1609195320.057883s

12 step training time: 0.118328s

on_train_batch_end: 1609195320.175177s

13312/50000 [======>.......................] - ETA: 4s - loss: 6.9663 - accuracy: 0.0980
on_train_batch_begin: 1609195320.175646s

13 step training time: 0.117763s

on_train_batch_end: 1609195320.294163s

14336/50000 [=======>......................] - ETA: 4s - loss: 6.9599 - accuracy: 0.0978
on_train_batch_begin: 1609195320.294633s

14 step training time: 0.118987s

on_train_batch_end: 1609195320.412518s

15360/50000 [========>.....................] - ETA: 4s - loss: 6.9633 - accuracy: 0.0978
on_train_batch_begin: 1609195320.413044s

15 step training time: 0.118411s

on_train_batch_end: 1609195320.531587s

16384/50000 [========>.....................] - ETA: 3s - loss: 6.9531 - accuracy: 0.0984
on_train_batch_begin: 1609195320.532059s

16 step training time: 0.119015s

on_train_batch_end: 1609195320.649846s

17408/50000 [=========>....................] - ETA: 3s - loss: 6.9450 - accuracy: 0.0978
on_train_batch_begin: 1609195320.650334s

17 step training time: 0.118276s

on_train_batch_end: 1609195320.768960s

18432/50000 [==========>...................] - ETA: 3s - loss: 6.9458 - accuracy: 0.0969
on_train_batch_begin: 1609195320.769430s

18 step training time: 0.119096s

on_train_batch_end: 1609195320.887744s

19456/50000 [==========>...................] - ETA: 3s - loss: 6.9360 - accuracy: 0.0968
on_train_batch_begin: 1609195320.888250s

19 step training time: 0.118820s

on_train_batch_end: 1609195321.006392s

20480/50000 [===========>..................] - ETA: 3s - loss: 6.9329 - accuracy: 0.0970
on_train_batch_begin: 1609195321.006869s

20 step training time: 0.118619s

on_train_batch_end: 1609195321.124897s

21504/50000 [===========>..................] - ETA: 3s - loss: 6.9335 - accuracy: 0.0967
on_train_batch_begin: 1609195321.125404s

21 step training time: 0.118535s

on_train_batch_end: 1609195321.243411s

22528/50000 [============>.................] - ETA: 3s - loss: 6.9217 - accuracy: 0.0973
on_train_batch_begin: 1609195321.243879s

22 step training time: 0.118475s

on_train_batch_end: 1609195321.364237s

23552/50000 [=============>................] - ETA: 3s - loss: 6.9149 - accuracy: 0.0972
on_train_batch_begin: 1609195321.365044s

23 step training time: 0.121164s

on_train_batch_end: 1609195321.486734s

24576/50000 [=============>................] - ETA: 2s - loss: 6.9076 - accuracy: 0.0974
on_train_batch_begin: 1609195321.487271s

24 step training time: 0.122227s

on_train_batch_end: 1609195321.605133s

25600/50000 [==============>...............] - ETA: 2s - loss: 6.8977 - accuracy: 0.0972
on_train_batch_begin: 1609195321.605660s

25 step training time: 0.118390s

on_train_batch_end: 1609195321.723660s

26624/50000 [==============>...............] - ETA: 2s - loss: 6.8944 - accuracy: 0.0972
on_train_batch_begin: 1609195321.724164s

26 step training time: 0.118503s

on_train_batch_end: 1609195321.841445s

27648/50000 [===============>..............] - ETA: 2s - loss: 6.8843 - accuracy: 0.0969
on_train_batch_begin: 1609195321.841907s

27 step training time: 0.117743s

on_train_batch_end: 1609195321.959060s

28672/50000 [================>.............] - ETA: 2s - loss: 6.8795 - accuracy: 0.0964
on_train_batch_begin: 1609195321.959522s

28 step training time: 0.117616s

on_train_batch_end: 1609195322.077201s

29696/50000 [================>.............] - ETA: 2s - loss: 6.8738 - accuracy: 0.0963
on_train_batch_begin: 1609195322.077677s

29 step training time: 0.118154s

on_train_batch_end: 1609195322.196819s

30720/50000 [=================>............] - ETA: 2s - loss: 6.8686 - accuracy: 0.0965
on_train_batch_begin: 1609195322.197323s

30 step training time: 0.119647s

on_train_batch_end: 1609195322.315032s

31744/50000 [==================>...........] - ETA: 2s - loss: 6.8608 - accuracy: 0.0967
on_train_batch_begin: 1609195322.315507s

31 step training time: 0.118184s

on_train_batch_end: 1609195322.433966s

32768/50000 [==================>...........] - ETA: 2s - loss: 6.8575 - accuracy: 0.0965
on_train_batch_begin: 1609195322.434537s

32 step training time: 0.119030s

on_train_batch_end: 1609195322.553211s

33792/50000 [===================>..........] - ETA: 1s - loss: 6.8535 - accuracy: 0.0961
on_train_batch_begin: 1609195322.553683s

33 step training time: 0.119146s

on_train_batch_end: 1609195322.671800s

34816/50000 [===================>..........] - ETA: 1s - loss: 6.8485 - accuracy: 0.0960
on_train_batch_begin: 1609195322.672261s

34 step training time: 0.118579s

on_train_batch_end: 1609195322.789813s

35840/50000 [====================>.........] - ETA: 1s - loss: 6.8458 - accuracy: 0.0964
on_train_batch_begin: 1609195322.790293s

35 step training time: 0.118031s

on_train_batch_end: 1609195322.907462s

36864/50000 [=====================>........] - ETA: 1s - loss: 6.8421 - accuracy: 0.0964
on_train_batch_begin: 1609195322.907921s

36 step training time: 0.117628s

on_train_batch_end: 1609195323.026000s

37888/50000 [=====================>........] - ETA: 1s - loss: 6.8350 - accuracy: 0.0962
on_train_batch_begin: 1609195323.026463s

37 step training time: 0.118542s

on_train_batch_end: 1609195323.145621s

38912/50000 [======================>.......] - ETA: 1s - loss: 6.8311 - accuracy: 0.0958
on_train_batch_begin: 1609195323.146116s

38 step training time: 0.119654s

on_train_batch_end: 1609195323.263165s

39936/50000 [======================>.......] - ETA: 1s - loss: 6.8281 - accuracy: 0.0958
on_train_batch_begin: 1609195323.263628s

39 step training time: 0.117512s

on_train_batch_end: 1609195323.384173s

40960/50000 [=======================>......] - ETA: 1s - loss: 6.8190 - accuracy: 0.0959
on_train_batch_begin: 1609195323.384651s

40 step training time: 0.121023s

on_train_batch_end: 1609195323.502469s

41984/50000 [========================>.....] - ETA: 0s - loss: 6.8120 - accuracy: 0.0958
on_train_batch_begin: 1609195323.502996s

41 step training time: 0.118345s

on_train_batch_end: 1609195323.621227s

43008/50000 [========================>.....] - ETA: 0s - loss: 6.8072 - accuracy: 0.0957
on_train_batch_begin: 1609195323.621710s

42 step training time: 0.118714s

on_train_batch_end: 1609195323.739046s

44032/50000 [=========================>....] - ETA: 0s - loss: 6.8009 - accuracy: 0.0955
on_train_batch_begin: 1609195323.739527s

43 step training time: 0.117817s

on_train_batch_end: 1609195323.856435s

45056/50000 [==========================>...] - ETA: 0s - loss: 6.7931 - accuracy: 0.0954
on_train_batch_begin: 1609195323.856947s

44 step training time: 0.117419s

on_train_batch_end: 1609195323.974384s

46080/50000 [==========================>...] - ETA: 0s - loss: 6.7894 - accuracy: 0.0951
on_train_batch_begin: 1609195323.974851s

45 step training time: 0.117904s

on_train_batch_end: 1609195324.092665s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.7845 - accuracy: 0.0951
on_train_batch_begin: 1609195324.093165s

46 step training time: 0.118315s

on_train_batch_end: 1609195324.211984s

48128/50000 [===========================>..] - ETA: 0s - loss: 6.7775 - accuracy: 0.0946
on_train_batch_begin: 1609195324.212542s

47 step training time: 0.119377s

on_train_batch_end: 1609195324.329962s

49152/50000 [============================>.] - ETA: 0s - loss: 6.7769 - accuracy: 0.0942
on_train_batch_begin: 1609195324.330428s

48 step training time: 0.117886s

on_train_batch_end: 1609195324.434222s

on_test_batch_begin: 1609195324.451440s

49 step training time: 0.121012s

on_epoch_end: 1609195324.888646s

Validation time: 0.437185s

Real time: 1609195324.888646s

Epoch time: 6.262321710586548s

50000/50000 [==============================] - 6s 125us/sample - loss: 6.7752 - accuracy: 0.0939 - val_loss: 192.2657 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609195324.888964s

Real time: 1609195324.8889773
Epoch 3/5

on_train_batch_begin: 1609195324.893355s

on_train_batch_end: 1609195325.010831s

 1024/50000 [..............................] - ETA: 5s - loss: 6.6046 - accuracy: 0.0821
on_train_batch_begin: 1609195325.011326s

1 step training time: 0.117971s

on_train_batch_end: 1609195325.128786s

 2048/50000 [>.............................] - ETA: 5s - loss: 6.4789 - accuracy: 0.0885
on_train_batch_begin: 1609195325.129293s

2 step training time: 0.117967s

on_train_batch_end: 1609195325.246685s

 3072/50000 [>.............................] - ETA: 5s - loss: 6.5216 - accuracy: 0.0904
on_train_batch_begin: 1609195325.247144s

3 step training time: 0.117851s

on_train_batch_end: 1609195325.364510s

 4096/50000 [=>............................] - ETA: 5s - loss: 6.5611 - accuracy: 0.0895
on_train_batch_begin: 1609195325.365009s

4 step training time: 0.117865s

on_train_batch_end: 1609195325.484776s

 5120/50000 [==>...........................] - ETA: 5s - loss: 6.5652 - accuracy: 0.0904
on_train_batch_begin: 1609195325.485270s

5 step training time: 0.120261s

on_train_batch_end: 1609195325.603116s

 6144/50000 [==>...........................] - ETA: 5s - loss: 6.5619 - accuracy: 0.0926
on_train_batch_begin: 1609195325.603571s

6 step training time: 0.118301s

on_train_batch_end: 1609195325.721382s

 7168/50000 [===>..........................] - ETA: 4s - loss: 6.5710 - accuracy: 0.0939
on_train_batch_begin: 1609195325.721845s

7 step training time: 0.118274s

on_train_batch_end: 1609195325.839614s

 8192/50000 [===>..........................] - ETA: 4s - loss: 6.5514 - accuracy: 0.0939
on_train_batch_begin: 1609195325.840073s

8 step training time: 0.118227s

on_train_batch_end: 1609195325.958452s

 9216/50000 [====>.........................] - ETA: 4s - loss: 6.5577 - accuracy: 0.0933
on_train_batch_begin: 1609195325.958904s

9 step training time: 0.118831s

on_train_batch_end: 1609195326.076969s

10240/50000 [=====>........................] - ETA: 4s - loss: 6.5551 - accuracy: 0.0940
on_train_batch_begin: 1609195326.077435s

10 step training time: 0.118532s

on_train_batch_end: 1609195326.195815s

11264/50000 [=====>........................] - ETA: 4s - loss: 6.5508 - accuracy: 0.0932
on_train_batch_begin: 1609195326.196326s

11 step training time: 0.118890s

on_train_batch_end: 1609195326.317674s

12288/50000 [======>.......................] - ETA: 4s - loss: 6.5414 - accuracy: 0.0937
on_train_batch_begin: 1609195326.318135s

12 step training time: 0.121809s

on_train_batch_end: 1609195326.435884s

13312/50000 [======>.......................] - ETA: 4s - loss: 6.5500 - accuracy: 0.0930
on_train_batch_begin: 1609195326.436362s

13 step training time: 0.118227s

on_train_batch_end: 1609195326.554130s

14336/50000 [=======>......................] - ETA: 4s - loss: 6.5551 - accuracy: 0.0937
on_train_batch_begin: 1609195326.554600s

14 step training time: 0.118239s

on_train_batch_end: 1609195326.672265s

15360/50000 [========>.....................] - ETA: 4s - loss: 6.5482 - accuracy: 0.0929
on_train_batch_begin: 1609195326.672721s

15 step training time: 0.118120s

on_train_batch_end: 1609195326.790587s

16384/50000 [========>.....................] - ETA: 3s - loss: 6.5356 - accuracy: 0.0923
on_train_batch_begin: 1609195326.791045s

16 step training time: 0.118324s

on_train_batch_end: 1609195326.908477s

17408/50000 [=========>....................] - ETA: 3s - loss: 6.5394 - accuracy: 0.0919
on_train_batch_begin: 1609195326.908980s

17 step training time: 0.117935s

on_train_batch_end: 1609195327.027282s

18432/50000 [==========>...................] - ETA: 3s - loss: 6.5406 - accuracy: 0.0925
on_train_batch_begin: 1609195327.027744s

18 step training time: 0.118764s

on_train_batch_end: 1609195327.147632s

19456/50000 [==========>...................] - ETA: 3s - loss: 6.5431 - accuracy: 0.0923
on_train_batch_begin: 1609195327.148094s

19 step training time: 0.120350s

on_train_batch_end: 1609195327.266987s

20480/50000 [===========>..................] - ETA: 3s - loss: 6.5414 - accuracy: 0.0923
on_train_batch_begin: 1609195327.267452s

20 step training time: 0.119358s

on_train_batch_end: 1609195327.386013s

21504/50000 [===========>..................] - ETA: 3s - loss: 6.5544 - accuracy: 0.0916
on_train_batch_begin: 1609195327.386483s

21 step training time: 0.119031s

on_train_batch_end: 1609195327.504298s

22528/50000 [============>.................] - ETA: 3s - loss: 6.5536 - accuracy: 0.0914
on_train_batch_begin: 1609195327.504763s

22 step training time: 0.118279s

on_train_batch_end: 1609195327.622583s

23552/50000 [=============>................] - ETA: 3s - loss: 6.5495 - accuracy: 0.0912
on_train_batch_begin: 1609195327.623045s

23 step training time: 0.118283s

on_train_batch_end: 1609195327.743067s

24576/50000 [=============>................] - ETA: 2s - loss: 6.5528 - accuracy: 0.0906
on_train_batch_begin: 1609195327.743525s

24 step training time: 0.120480s

on_train_batch_end: 1609195327.861326s

25600/50000 [==============>...............] - ETA: 2s - loss: 6.5552 - accuracy: 0.0903
on_train_batch_begin: 1609195327.861791s

25 step training time: 0.118266s

on_train_batch_end: 1609195327.979444s

26624/50000 [==============>...............] - ETA: 2s - loss: 6.5557 - accuracy: 0.0893
on_train_batch_begin: 1609195327.979903s

26 step training time: 0.118113s

on_train_batch_end: 1609195328.098121s

27648/50000 [===============>..............] - ETA: 2s - loss: 6.5497 - accuracy: 0.0900
on_train_batch_begin: 1609195328.098583s

27 step training time: 0.118680s

on_train_batch_end: 1609195328.216690s

28672/50000 [================>.............] - ETA: 2s - loss: 6.5396 - accuracy: 0.0903
on_train_batch_begin: 1609195328.217188s

28 step training time: 0.118605s

on_train_batch_end: 1609195328.334848s

29696/50000 [================>.............] - ETA: 2s - loss: 6.5402 - accuracy: 0.0902
on_train_batch_begin: 1609195328.335336s

29 step training time: 0.118148s

on_train_batch_end: 1609195328.453846s

30720/50000 [=================>............] - ETA: 2s - loss: 6.5368 - accuracy: 0.0900
on_train_batch_begin: 1609195328.454501s

30 step training time: 0.119165s

on_train_batch_end: 1609195328.572271s

31744/50000 [==================>...........] - ETA: 2s - loss: 6.5335 - accuracy: 0.0901
on_train_batch_begin: 1609195328.572728s

31 step training time: 0.118227s

on_train_batch_end: 1609195328.690483s

32768/50000 [==================>...........] - ETA: 1s - loss: 6.5312 - accuracy: 0.0899
on_train_batch_begin: 1609195328.690946s

32 step training time: 0.118218s

on_train_batch_end: 1609195328.808105s

33792/50000 [===================>..........] - ETA: 1s - loss: 6.5259 - accuracy: 0.0900
on_train_batch_begin: 1609195328.808587s

33 step training time: 0.117641s

on_train_batch_end: 1609195328.926569s

34816/50000 [===================>..........] - ETA: 1s - loss: 6.5168 - accuracy: 0.0900
on_train_batch_begin: 1609195328.927038s

34 step training time: 0.118451s

on_train_batch_end: 1609195329.044460s

35840/50000 [====================>.........] - ETA: 1s - loss: 6.5118 - accuracy: 0.0892
on_train_batch_begin: 1609195329.044945s

35 step training time: 0.117907s

on_train_batch_end: 1609195329.162055s

36864/50000 [=====================>........] - ETA: 1s - loss: 6.5097 - accuracy: 0.0885
on_train_batch_begin: 1609195329.162527s

36 step training time: 0.117583s

on_train_batch_end: 1609195329.280087s

37888/50000 [=====================>........] - ETA: 1s - loss: 6.5029 - accuracy: 0.0878
on_train_batch_begin: 1609195329.280544s

37 step training time: 0.118016s

on_train_batch_end: 1609195329.397452s

38912/50000 [======================>.......] - ETA: 1s - loss: 6.5034 - accuracy: 0.0873
on_train_batch_begin: 1609195329.397942s

38 step training time: 0.117398s

on_train_batch_end: 1609195329.514946s

39936/50000 [======================>.......] - ETA: 1s - loss: 6.4998 - accuracy: 0.0873
on_train_batch_begin: 1609195329.515409s

39 step training time: 0.117467s

on_train_batch_end: 1609195329.633212s

40960/50000 [=======================>......] - ETA: 1s - loss: 6.4985 - accuracy: 0.0869
on_train_batch_begin: 1609195329.633672s

40 step training time: 0.118264s

on_train_batch_end: 1609195329.751547s

41984/50000 [========================>.....] - ETA: 0s - loss: 6.4957 - accuracy: 0.0868
on_train_batch_begin: 1609195329.752019s

41 step training time: 0.118347s

on_train_batch_end: 1609195329.870683s

43008/50000 [========================>.....] - ETA: 0s - loss: 6.4918 - accuracy: 0.0865
on_train_batch_begin: 1609195329.871160s

42 step training time: 0.119141s

on_train_batch_end: 1609195329.993309s

44032/50000 [=========================>....] - ETA: 0s - loss: 6.4898 - accuracy: 0.0862
on_train_batch_begin: 1609195329.993773s

43 step training time: 0.122613s

on_train_batch_end: 1609195330.111360s

45056/50000 [==========================>...] - ETA: 0s - loss: 6.4898 - accuracy: 0.0856
on_train_batch_begin: 1609195330.111817s

44 step training time: 0.118044s

on_train_batch_end: 1609195330.231079s

46080/50000 [==========================>...] - ETA: 0s - loss: 6.4861 - accuracy: 0.0857
on_train_batch_begin: 1609195330.231541s

45 step training time: 0.119724s

on_train_batch_end: 1609195330.350153s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.4806 - accuracy: 0.0856
on_train_batch_begin: 1609195330.350623s

46 step training time: 0.119082s

on_train_batch_end: 1609195330.469371s

48128/50000 [===========================>..] - ETA: 0s - loss: 6.4790 - accuracy: 0.0857
on_train_batch_begin: 1609195330.469841s

47 step training time: 0.119218s

on_train_batch_end: 1609195330.587277s

49152/50000 [============================>.] - ETA: 0s - loss: 6.4755 - accuracy: 0.0856
on_train_batch_begin: 1609195330.587735s

48 step training time: 0.117894s

on_train_batch_end: 1609195330.692774s

on_test_batch_begin: 1609195330.708937s

49 step training time: 0.121202s

on_epoch_end: 1609195331.165731s

Validation time: 0.456769s

Real time: 1609195331.165731s

Epoch time: 6.2767722606658936s

50000/50000 [==============================] - 6s 126us/sample - loss: 6.4723 - accuracy: 0.0855 - val_loss: 1756.2928 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609195331.166028s

Real time: 1609195331.166039
Epoch 4/5

on_train_batch_begin: 1609195331.170450s

on_train_batch_end: 1609195331.289035s

 1024/50000 [..............................] - ETA: 5s - loss: 6.1311 - accuracy: 0.0854
on_train_batch_begin: 1609195331.289542s

1 step training time: 0.119092s

on_train_batch_end: 1609195331.409031s

 2048/50000 [>.............................] - ETA: 5s - loss: 6.1813 - accuracy: 0.0792
on_train_batch_begin: 1609195331.409499s

2 step training time: 0.119957s

on_train_batch_end: 1609195331.527062s

 3072/50000 [>.............................] - ETA: 5s - loss: 6.2344 - accuracy: 0.0823
on_train_batch_begin: 1609195331.527513s

3 step training time: 0.118013s

on_train_batch_end: 1609195331.644311s

 4096/50000 [=>............................] - ETA: 5s - loss: 6.2471 - accuracy: 0.0757
on_train_batch_begin: 1609195331.644780s

4 step training time: 0.117267s

on_train_batch_end: 1609195331.765141s

 5120/50000 [==>...........................] - ETA: 5s - loss: 6.2168 - accuracy: 0.0759
on_train_batch_begin: 1609195331.765604s

5 step training time: 0.120824s

on_train_batch_end: 1609195331.883138s

 6144/50000 [==>...........................] - ETA: 5s - loss: 6.2355 - accuracy: 0.0745
on_train_batch_begin: 1609195331.883594s

6 step training time: 0.117990s

on_train_batch_end: 1609195332.001554s

 7168/50000 [===>..........................] - ETA: 4s - loss: 6.2502 - accuracy: 0.0745
on_train_batch_begin: 1609195332.002058s

7 step training time: 0.118464s

on_train_batch_end: 1609195332.121396s

 8192/50000 [===>..........................] - ETA: 4s - loss: 6.2548 - accuracy: 0.0738
on_train_batch_begin: 1609195332.121862s

8 step training time: 0.119804s

on_train_batch_end: 1609195332.239957s

 9216/50000 [====>.........................] - ETA: 4s - loss: 6.2390 - accuracy: 0.0729
on_train_batch_begin: 1609195332.240456s

9 step training time: 0.118593s

on_train_batch_end: 1609195332.358837s

10240/50000 [=====>........................] - ETA: 4s - loss: 6.2097 - accuracy: 0.0711
on_train_batch_begin: 1609195332.359298s

10 step training time: 0.118842s

on_train_batch_end: 1609195332.477566s

11264/50000 [=====>........................] - ETA: 4s - loss: 6.2070 - accuracy: 0.0687
on_train_batch_begin: 1609195332.478023s

11 step training time: 0.118725s

on_train_batch_end: 1609195332.596506s

12288/50000 [======>.......................] - ETA: 4s - loss: 6.1924 - accuracy: 0.0672
on_train_batch_begin: 1609195332.596998s

12 step training time: 0.118975s

on_train_batch_end: 1609195332.714654s

13312/50000 [======>.......................] - ETA: 4s - loss: 6.1636 - accuracy: 0.0659
on_train_batch_begin: 1609195332.715118s

13 step training time: 0.118120s

on_train_batch_end: 1609195332.831182s

14336/50000 [=======>......................] - ETA: 4s - loss: 6.1507 - accuracy: 0.0642
on_train_batch_begin: 1609195332.831643s

14 step training time: 0.116525s

on_train_batch_end: 1609195332.949474s

15360/50000 [========>.....................] - ETA: 4s - loss: 6.1312 - accuracy: 0.0631
on_train_batch_begin: 1609195332.949941s

15 step training time: 0.118298s

on_train_batch_end: 1609195333.070019s

16384/50000 [========>.....................] - ETA: 3s - loss: 6.1064 - accuracy: 0.0623
on_train_batch_begin: 1609195333.070486s

16 step training time: 0.120545s

on_train_batch_end: 1609195333.188257s

17408/50000 [=========>....................] - ETA: 3s - loss: 6.0797 - accuracy: 0.0613
on_train_batch_begin: 1609195333.188731s

17 step training time: 0.118245s

on_train_batch_end: 1609195333.307624s

18432/50000 [==========>...................] - ETA: 3s - loss: 6.0560 - accuracy: 0.0605
on_train_batch_begin: 1609195333.308092s

18 step training time: 0.119362s

on_train_batch_end: 1609195333.426451s

19456/50000 [==========>...................] - ETA: 3s - loss: 6.0347 - accuracy: 0.0598
on_train_batch_begin: 1609195333.426954s

19 step training time: 0.118862s

on_train_batch_end: 1609195333.545243s

20480/50000 [===========>..................] - ETA: 3s - loss: 6.0007 - accuracy: 0.0595
on_train_batch_begin: 1609195333.545713s

20 step training time: 0.118759s

on_train_batch_end: 1609195333.664163s

21504/50000 [===========>..................] - ETA: 3s - loss: 5.9698 - accuracy: 0.0593
on_train_batch_begin: 1609195333.664632s

21 step training time: 0.118918s

on_train_batch_end: 1609195333.784312s

22528/50000 [============>.................] - ETA: 3s - loss: 5.9394 - accuracy: 0.0591
on_train_batch_begin: 1609195333.784784s

22 step training time: 0.120152s

on_train_batch_end: 1609195333.902992s

23552/50000 [=============>................] - ETA: 3s - loss: 5.9056 - accuracy: 0.0593
on_train_batch_begin: 1609195333.903462s

23 step training time: 0.118678s

on_train_batch_end: 1609195334.021823s

24576/50000 [=============>................] - ETA: 2s - loss: 5.8653 - accuracy: 0.0594
on_train_batch_begin: 1609195334.022290s

24 step training time: 0.118828s

on_train_batch_end: 1609195334.139865s

25600/50000 [==============>...............] - ETA: 2s - loss: 5.8229 - accuracy: 0.0596
on_train_batch_begin: 1609195334.140328s

25 step training time: 0.118038s

on_train_batch_end: 1609195334.258631s

26624/50000 [==============>...............] - ETA: 2s - loss: 5.7828 - accuracy: 0.0597
on_train_batch_begin: 1609195334.259101s

26 step training time: 0.118773s

on_train_batch_end: 1609195334.377820s

27648/50000 [===============>..............] - ETA: 2s - loss: 5.7430 - accuracy: 0.0600
on_train_batch_begin: 1609195334.378326s

27 step training time: 0.119225s

on_train_batch_end: 1609195334.495750s

28672/50000 [================>.............] - ETA: 2s - loss: 5.7014 - accuracy: 0.0602
on_train_batch_begin: 1609195334.496218s

28 step training time: 0.117892s

on_train_batch_end: 1609195334.614408s

29696/50000 [================>.............] - ETA: 2s - loss: 5.6617 - accuracy: 0.0606
on_train_batch_begin: 1609195334.614873s

29 step training time: 0.118655s

on_train_batch_end: 1609195334.732214s

30720/50000 [=================>............] - ETA: 2s - loss: 5.6211 - accuracy: 0.0609
on_train_batch_begin: 1609195334.732671s

30 step training time: 0.117798s

on_train_batch_end: 1609195334.850137s

31744/50000 [==================>...........] - ETA: 2s - loss: 5.5794 - accuracy: 0.0612
on_train_batch_begin: 1609195334.850600s

31 step training time: 0.117929s

on_train_batch_end: 1609195334.968734s

32768/50000 [==================>...........] - ETA: 1s - loss: 5.5392 - accuracy: 0.0617
on_train_batch_begin: 1609195334.969239s

32 step training time: 0.118639s

on_train_batch_end: 1609195335.087147s

33792/50000 [===================>..........] - ETA: 1s - loss: 5.4947 - accuracy: 0.0622
on_train_batch_begin: 1609195335.087644s

33 step training time: 0.118405s

on_train_batch_end: 1609195335.205863s

34816/50000 [===================>..........] - ETA: 1s - loss: 5.4458 - accuracy: 0.0627
on_train_batch_begin: 1609195335.206341s

34 step training time: 0.118696s

on_train_batch_end: 1609195335.324536s

35840/50000 [====================>.........] - ETA: 1s - loss: 5.4016 - accuracy: 0.0633
on_train_batch_begin: 1609195335.325059s

35 step training time: 0.118718s

on_train_batch_end: 1609195335.443381s

36864/50000 [=====================>........] - ETA: 1s - loss: 5.3608 - accuracy: 0.0638
on_train_batch_begin: 1609195335.443853s

36 step training time: 0.118793s

on_train_batch_end: 1609195335.562139s

37888/50000 [=====================>........] - ETA: 1s - loss: 5.3194 - accuracy: 0.0643
on_train_batch_begin: 1609195335.562605s

37 step training time: 0.118753s

on_train_batch_end: 1609195335.680649s

38912/50000 [======================>.......] - ETA: 1s - loss: 5.2761 - accuracy: 0.0648
on_train_batch_begin: 1609195335.681153s

38 step training time: 0.118548s

on_train_batch_end: 1609195335.799168s

39936/50000 [======================>.......] - ETA: 1s - loss: 5.2215 - accuracy: 0.0655
on_train_batch_begin: 1609195335.799638s

39 step training time: 0.118485s

on_train_batch_end: 1609195335.916693s

40960/50000 [=======================>......] - ETA: 1s - loss: 5.1829 - accuracy: 0.0661
on_train_batch_begin: 1609195335.917204s

40 step training time: 0.117566s

on_train_batch_end: 1609195336.035362s

41984/50000 [========================>.....] - ETA: 0s - loss: 5.1386 - accuracy: 0.0668
on_train_batch_begin: 1609195336.035882s

41 step training time: 0.118677s

on_train_batch_end: 1609195336.154990s

43008/50000 [========================>.....] - ETA: 0s - loss: 5.0906 - accuracy: 0.0674
on_train_batch_begin: 1609195336.155450s

42 step training time: 0.119568s

on_train_batch_end: 1609195336.273281s

44032/50000 [=========================>....] - ETA: 0s - loss: 5.0451 - accuracy: 0.0681
on_train_batch_begin: 1609195336.273738s

43 step training time: 0.118288s

on_train_batch_end: 1609195336.389961s

45056/50000 [==========================>...] - ETA: 0s - loss: 5.0023 - accuracy: 0.0687
on_train_batch_begin: 1609195336.390421s

44 step training time: 0.116683s

on_train_batch_end: 1609195336.508898s

46080/50000 [==========================>...] - ETA: 0s - loss: 4.9661 - accuracy: 0.0693
on_train_batch_begin: 1609195336.509369s

45 step training time: 0.118948s

on_train_batch_end: 1609195336.627784s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.9299 - accuracy: 0.0699
on_train_batch_begin: 1609195336.628247s

46 step training time: 0.118878s

on_train_batch_end: 1609195336.745674s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.8919 - accuracy: 0.0705
on_train_batch_begin: 1609195336.746147s

47 step training time: 0.117900s

on_train_batch_end: 1609195336.865842s

49152/50000 [============================>.] - ETA: 0s - loss: 4.8558 - accuracy: 0.0711
on_train_batch_begin: 1609195336.866331s

48 step training time: 0.120184s

on_train_batch_end: 1609195336.971147s

on_test_batch_begin: 1609195336.986565s

49 step training time: 0.120233s

on_epoch_end: 1609195337.432404s

Validation time: 0.445815s

Real time: 1609195337.432404s

Epoch time: 6.266391038894653s

50000/50000 [==============================] - 6s 125us/sample - loss: 4.8271 - accuracy: 0.0714 - val_loss: 7.5569 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609195337.432695s

Real time: 1609195337.4327047
Epoch 5/5

on_train_batch_begin: 1609195337.437185s

on_train_batch_end: 1609195337.555613s

 1024/50000 [..............................] - ETA: 5s - loss: 2.9178 - accuracy: 0.1003
on_train_batch_begin: 1609195337.556189s

1 step training time: 0.119005s

on_train_batch_end: 1609195337.678932s

 2048/50000 [>.............................] - ETA: 5s - loss: 2.8901 - accuracy: 0.1001
on_train_batch_begin: 1609195337.679418s

2 step training time: 0.123229s

on_train_batch_end: 1609195337.798304s

 3072/50000 [>.............................] - ETA: 5s - loss: 2.9115 - accuracy: 0.0998
on_train_batch_begin: 1609195337.798762s

3 step training time: 0.119344s

on_train_batch_end: 1609195337.915773s

 4096/50000 [=>............................] - ETA: 5s - loss: 2.9100 - accuracy: 0.0998
on_train_batch_begin: 1609195337.916242s

4 step training time: 0.117480s

on_train_batch_end: 1609195338.034199s

 5120/50000 [==>...........................] - ETA: 5s - loss: 2.8737 - accuracy: 0.0999
on_train_batch_begin: 1609195338.034658s

5 step training time: 0.118416s

on_train_batch_end: 1609195338.154402s

 6144/50000 [==>...........................] - ETA: 5s - loss: 2.8791 - accuracy: 0.0998
on_train_batch_begin: 1609195338.154857s

6 step training time: 0.120199s

on_train_batch_end: 1609195338.276087s

 7168/50000 [===>..........................] - ETA: 5s - loss: 2.8618 - accuracy: 0.0998
on_train_batch_begin: 1609195338.276553s

7 step training time: 0.121696s

on_train_batch_end: 1609195338.396226s

 8192/50000 [===>..........................] - ETA: 4s - loss: 2.8528 - accuracy: 0.0998
on_train_batch_begin: 1609195338.396694s

8 step training time: 0.120141s

on_train_batch_end: 1609195338.515855s

 9216/50000 [====>.........................] - ETA: 4s - loss: 2.8221 - accuracy: 0.0998
on_train_batch_begin: 1609195338.516332s

9 step training time: 0.119638s

on_train_batch_end: 1609195338.636727s

10240/50000 [=====>........................] - ETA: 4s - loss: 2.7727 - accuracy: 0.0999
on_train_batch_begin: 1609195338.637282s

10 step training time: 0.120950s

on_train_batch_end: 1609195338.756601s

11264/50000 [=====>........................] - ETA: 4s - loss: 2.7420 - accuracy: 0.0998
on_train_batch_begin: 1609195338.757156s

11 step training time: 0.119874s

on_train_batch_end: 1609195338.876794s

12288/50000 [======>.......................] - ETA: 4s - loss: 2.7024 - accuracy: 0.0999
on_train_batch_begin: 1609195338.877290s

12 step training time: 0.120135s

on_train_batch_end: 1609195338.994696s

13312/50000 [======>.......................] - ETA: 4s - loss: 2.6682 - accuracy: 0.0999
on_train_batch_begin: 1609195338.995166s

13 step training time: 0.117876s

on_train_batch_end: 1609195339.114177s

14336/50000 [=======>......................] - ETA: 4s - loss: 2.6322 - accuracy: 0.0999
on_train_batch_begin: 1609195339.114673s

14 step training time: 0.119507s

on_train_batch_end: 1609195339.242074s

15360/50000 [========>.....................] - ETA: 4s - loss: 2.6012 - accuracy: 0.0999
on_train_batch_begin: 1609195339.242548s

15 step training time: 0.127875s

on_train_batch_end: 1609195339.361046s

16384/50000 [========>.....................] - ETA: 3s - loss: 2.5696 - accuracy: 0.0999
on_train_batch_begin: 1609195339.361520s

16 step training time: 0.118972s

on_train_batch_end: 1609195339.480536s

17408/50000 [=========>....................] - ETA: 3s - loss: 2.5560 - accuracy: 0.0999
on_train_batch_begin: 1609195339.481045s

17 step training time: 0.119525s

on_train_batch_end: 1609195339.600779s

18432/50000 [==========>...................] - ETA: 3s - loss: 2.5371 - accuracy: 0.0999
on_train_batch_begin: 1609195339.601301s

18 step training time: 0.120256s

on_train_batch_end: 1609195339.723763s

19456/50000 [==========>...................] - ETA: 3s - loss: 2.5161 - accuracy: 0.0999
on_train_batch_begin: 1609195339.724244s

19 step training time: 0.122943s

on_train_batch_end: 1609195339.843063s

20480/50000 [===========>..................] - ETA: 3s - loss: 2.4945 - accuracy: 0.0999
on_train_batch_begin: 1609195339.843559s

20 step training time: 0.119315s

on_train_batch_end: 1609195339.962295s

21504/50000 [===========>..................] - ETA: 3s - loss: 2.4679 - accuracy: 0.1000
on_train_batch_begin: 1609195339.962756s

21 step training time: 0.119197s

on_train_batch_end: 1609195340.081613s

22528/50000 [============>.................] - ETA: 3s - loss: 2.4502 - accuracy: 0.0999
on_train_batch_begin: 1609195340.082073s

22 step training time: 0.119317s

on_train_batch_end: 1609195340.200627s

23552/50000 [=============>................] - ETA: 3s - loss: 2.4354 - accuracy: 0.1000
on_train_batch_begin: 1609195340.201121s

23 step training time: 0.119048s

on_train_batch_end: 1609195340.317571s

24576/50000 [=============>................] - ETA: 2s - loss: 2.4082 - accuracy: 0.1000
on_train_batch_begin: 1609195340.318028s

24 step training time: 0.116907s

on_train_batch_end: 1609195340.436438s

25600/50000 [==============>...............] - ETA: 2s - loss: 2.3841 - accuracy: 0.1000
on_train_batch_begin: 1609195340.436939s

25 step training time: 0.118911s

on_train_batch_end: 1609195340.554893s

26624/50000 [==============>...............] - ETA: 2s - loss: 2.3668 - accuracy: 0.1000
on_train_batch_begin: 1609195340.555358s

26 step training time: 0.118419s

on_train_batch_end: 1609195340.673574s

27648/50000 [===============>..............] - ETA: 2s - loss: 2.3514 - accuracy: 0.1000
on_train_batch_begin: 1609195340.674036s

27 step training time: 0.118678s

on_train_batch_end: 1609195340.791323s

28672/50000 [================>.............] - ETA: 2s - loss: 2.3361 - accuracy: 0.1000
on_train_batch_begin: 1609195340.791788s

28 step training time: 0.117752s

on_train_batch_end: 1609195340.909157s

29696/50000 [================>.............] - ETA: 2s - loss: 2.3211 - accuracy: 0.1000
on_train_batch_begin: 1609195340.909615s

29 step training time: 0.117827s

on_train_batch_end: 1609195341.026617s

30720/50000 [=================>............] - ETA: 2s - loss: 2.3112 - accuracy: 0.1000
on_train_batch_begin: 1609195341.027074s

30 step training time: 0.117459s

on_train_batch_end: 1609195341.145707s

31744/50000 [==================>...........] - ETA: 2s - loss: 2.3034 - accuracy: 0.1000
on_train_batch_begin: 1609195341.146173s

31 step training time: 0.119099s

on_train_batch_end: 1609195341.264581s

32768/50000 [==================>...........] - ETA: 2s - loss: 2.2921 - accuracy: 0.1000
on_train_batch_begin: 1609195341.265077s

32 step training time: 0.118903s

on_train_batch_end: 1609195341.385842s

33792/50000 [===================>..........] - ETA: 1s - loss: 2.2793 - accuracy: 0.1000
on_train_batch_begin: 1609195341.386339s

33 step training time: 0.121263s

on_train_batch_end: 1609195341.506659s

34816/50000 [===================>..........] - ETA: 1s - loss: 2.2663 - accuracy: 0.1000
on_train_batch_begin: 1609195341.507130s

34 step training time: 0.120791s

on_train_batch_end: 1609195341.623669s

35840/50000 [====================>.........] - ETA: 1s - loss: 2.2554 - accuracy: 0.1000
on_train_batch_begin: 1609195341.624149s

35 step training time: 0.117019s

on_train_batch_end: 1609195341.743316s

36864/50000 [=====================>........] - ETA: 1s - loss: 2.2438 - accuracy: 0.1000
on_train_batch_begin: 1609195341.743784s

36 step training time: 0.119636s

on_train_batch_end: 1609195341.861339s

37888/50000 [=====================>........] - ETA: 1s - loss: 2.2336 - accuracy: 0.1000
on_train_batch_begin: 1609195341.861804s

37 step training time: 0.118019s

on_train_batch_end: 1609195341.979415s

38912/50000 [======================>.......] - ETA: 1s - loss: 2.2166 - accuracy: 0.1000
on_train_batch_begin: 1609195341.979892s

38 step training time: 0.118088s

on_train_batch_end: 1609195342.097245s

39936/50000 [======================>.......] - ETA: 1s - loss: 2.1990 - accuracy: 0.1000
on_train_batch_begin: 1609195342.097705s

39 step training time: 0.117814s

on_train_batch_end: 1609195342.219223s

40960/50000 [=======================>......] - ETA: 1s - loss: 2.1819 - accuracy: 0.1000
on_train_batch_begin: 1609195342.219683s

40 step training time: 0.121978s

on_train_batch_end: 1609195342.337703s

41984/50000 [========================>.....] - ETA: 0s - loss: 2.1663 - accuracy: 0.1000
on_train_batch_begin: 1609195342.338171s

41 step training time: 0.118488s

on_train_batch_end: 1609195342.455706s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.1551 - accuracy: 0.1000
on_train_batch_begin: 1609195342.456186s

42 step training time: 0.118015s

on_train_batch_end: 1609195342.573919s

44032/50000 [=========================>....] - ETA: 0s - loss: 2.1425 - accuracy: 0.1000
on_train_batch_begin: 1609195342.574382s

43 step training time: 0.118196s

on_train_batch_end: 1609195342.691887s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.1326 - accuracy: 0.1000
on_train_batch_begin: 1609195342.692347s

44 step training time: 0.117965s

on_train_batch_end: 1609195342.810758s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.1207 - accuracy: 0.1000
on_train_batch_begin: 1609195342.811225s

45 step training time: 0.118878s

on_train_batch_end: 1609195342.928662s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.1109 - accuracy: 0.1000
on_train_batch_begin: 1609195342.929164s

46 step training time: 0.117939s

on_train_batch_end: 1609195343.046936s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.0947 - accuracy: 0.1000
on_train_batch_begin: 1609195343.047405s

47 step training time: 0.118240s

on_train_batch_end: 1609195343.164247s

49152/50000 [============================>.] - ETA: 0s - loss: 2.0802 - accuracy: 0.1001
on_train_batch_begin: 1609195343.164710s

48 step training time: 0.117305s

on_train_batch_end: 1609195343.268084s

on_test_batch_begin: 1609195343.284253s

49 step training time: 0.119543s

on_epoch_end: 1609195343.730722s

Validation time: 0.446448s

Real time: 1609195343.730722s

Epoch time: 6.298044443130493s

50000/50000 [==============================] - 6s 126us/sample - loss: 2.0708 - accuracy: 0.1001 - val_loss: 7.4958 - val_accuracy: 0.0000e+00
Tempo do fit: 59.47277545928955