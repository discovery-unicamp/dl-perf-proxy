wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:01
   155648/170498071 [..............................] - ETA: 1:20
   565248/170498071 [..............................] - ETA: 37s 
  2072576/170498071 [..............................] - ETA: 14s
  4939776/170498071 [..............................] - ETA: 7s 
  7790592/170498071 [>.............................] - ETA: 5s
 10706944/170498071 [>.............................] - ETA: 4s
 13639680/170498071 [=>............................] - ETA: 4s
 16523264/170498071 [=>............................] - ETA: 3s
 19718144/170498071 [==>...........................] - ETA: 3s
 22880256/170498071 [===>..........................] - ETA: 3s
 26075136/170498071 [===>..........................] - ETA: 3s
 29253632/170498071 [====>.........................] - ETA: 3s
 32448512/170498071 [====>.........................] - ETA: 2s
 35627008/170498071 [=====>........................] - ETA: 2s
 38821888/170498071 [=====>........................] - ETA: 2s
 42016768/170498071 [======>.......................] - ETA: 2s
 45195264/170498071 [======>.......................] - ETA: 2s
 48390144/170498071 [=======>......................] - ETA: 2s
 51585024/170498071 [========>.....................] - ETA: 2s
 54763520/170498071 [========>.....................] - ETA: 2s
 57974784/170498071 [=========>....................] - ETA: 2s
 61136896/170498071 [=========>....................] - ETA: 2s
 64331776/170498071 [==========>...................] - ETA: 1s
 67543040/170498071 [==========>...................] - ETA: 1s
 70770688/170498071 [===========>..................] - ETA: 1s
 73965568/170498071 [============>.................] - ETA: 1s
 77144064/170498071 [============>.................] - ETA: 1s
 80355328/170498071 [=============>................] - ETA: 1s
 83550208/170498071 [=============>................] - ETA: 1s
 86712320/170498071 [==============>...............] - ETA: 1s
 89923584/170498071 [==============>...............] - ETA: 1s
 93134848/170498071 [===============>..............] - ETA: 1s
 96329728/170498071 [===============>..............] - ETA: 1s
 99540992/170498071 [================>.............] - ETA: 1s
102727680/170498071 [=================>............] - ETA: 1s
105848832/170498071 [=================>............] - ETA: 1s
109043712/170498071 [==================>...........] - ETA: 1s
112222208/170498071 [==================>...........] - ETA: 1s
115417088/170498071 [===================>..........] - ETA: 0s
118595584/170498071 [===================>..........] - ETA: 0s
121790464/170498071 [====================>.........] - ETA: 0s
125001728/170498071 [====================>.........] - ETA: 0s
128180224/170498071 [=====================>........] - ETA: 0s
131358720/170498071 [======================>.......] - ETA: 0s
134537216/170498071 [======================>.......] - ETA: 0s
137732096/170498071 [=======================>......] - ETA: 0s
140935168/170498071 [=======================>......] - ETA: 0s
144121856/170498071 [========================>.....] - ETA: 0s
147308544/170498071 [========================>.....] - ETA: 0s
150495232/170498071 [=========================>....] - ETA: 0s
153673728/170498071 [==========================>...] - ETA: 0s
156868608/170498071 [==========================>...] - ETA: 0s
160096256/170498071 [===========================>..] - ETA: 0s
163241984/170498071 [===========================>..] - ETA: 0s
166436864/170498071 [============================>.] - ETA: 0s
169615360/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 1114112/94765736 [..............................] - ETA: 5s
 4317184/94765736 [>.............................] - ETA: 2s
 9601024/94765736 [==>...........................] - ETA: 1s
16867328/94765736 [====>.........................] - ETA: 1s
21954560/94765736 [=====>........................] - ETA: 0s
28516352/94765736 [========>.....................] - ETA: 0s
30531584/94765736 [========>.....................] - ETA: 0s
30597120/94765736 [========>.....................] - ETA: 1s
33882112/94765736 [=========>....................] - ETA: 0s
39657472/94765736 [===========>..................] - ETA: 0s
46563328/94765736 [=============>................] - ETA: 0s
49307648/94765736 [==============>...............] - ETA: 0s
51994624/94765736 [===============>..............] - ETA: 0s
55410688/94765736 [================>.............] - ETA: 0s
61161472/94765736 [==================>...........] - ETA: 0s
64593920/94765736 [===================>..........] - ETA: 0s
77537280/94765736 [=======================>......] - ETA: 0s
81715200/94765736 [========================>.....] - ETA: 0s
86007808/94765736 [==========================>...] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.984977960586548
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615855072.190315s

Real time: 1615855072.1903353
Epoch 1/5

on_train_batch_begin: 1615855072.958053s

on_train_batch_end: 1615855093.114731s

 2048/50000 [>.............................] - ETA: 8:09 - loss: 18.0045 - accuracy: 2.6870e-04
on_train_batch_begin: 1615855093.115349s

1 step training time: 20.157296s

on_train_batch_end: 1615855093.779966s

 4096/50000 [=>............................] - ETA: 4:01 - loss: 14.1527 - accuracy: 4.3356e-04
on_train_batch_begin: 1615855093.780301s

2 step training time: 0.664952s

on_train_batch_end: 1615855094.436222s

 6144/50000 [==>...........................] - ETA: 2:38 - loss: 12.2374 - accuracy: 4.5331e-04
on_train_batch_begin: 1615855094.436550s

3 step training time: 0.656249s

on_train_batch_end: 1615855095.090919s

 8192/50000 [===>..........................] - ETA: 1:56 - loss: 11.2142 - accuracy: 0.0014    
on_train_batch_begin: 1615855095.091243s

4 step training time: 0.654693s

on_train_batch_end: 1615855095.748055s

10240/50000 [=====>........................] - ETA: 1:31 - loss: 10.5708 - accuracy: 0.0037
on_train_batch_begin: 1615855095.748379s

5 step training time: 0.657137s

on_train_batch_end: 1615855096.412633s

12288/50000 [======>.......................] - ETA: 1:14 - loss: 10.1548 - accuracy: 0.0059
on_train_batch_begin: 1615855096.412959s

6 step training time: 0.664579s

on_train_batch_end: 1615855097.071327s

14336/50000 [=======>......................] - ETA: 1:01 - loss: 9.8086 - accuracy: 0.0106 
on_train_batch_begin: 1615855097.071653s

7 step training time: 0.658694s

on_train_batch_end: 1615855097.737032s

16384/50000 [========>.....................] - ETA: 52s - loss: 9.5285 - accuracy: 0.0145 
on_train_batch_begin: 1615855097.737357s

8 step training time: 0.665704s

on_train_batch_end: 1615855098.396618s

18432/50000 [==========>...................] - ETA: 44s - loss: 9.3030 - accuracy: 0.0178
on_train_batch_begin: 1615855098.396951s

9 step training time: 0.659594s

on_train_batch_end: 1615855099.063805s

20480/50000 [===========>..................] - ETA: 38s - loss: 9.1283 - accuracy: 0.0208
on_train_batch_begin: 1615855099.064132s

10 step training time: 0.667181s

on_train_batch_end: 1615855099.728799s

22528/50000 [============>.................] - ETA: 33s - loss: 8.9732 - accuracy: 0.0221
on_train_batch_begin: 1615855099.729118s

11 step training time: 0.664987s

on_train_batch_end: 1615855100.396384s

24576/50000 [=============>................] - ETA: 29s - loss: 8.8346 - accuracy: 0.0239
on_train_batch_begin: 1615855100.396705s

12 step training time: 0.667587s

on_train_batch_end: 1615855101.062084s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.7175 - accuracy: 0.0257
on_train_batch_begin: 1615855101.062418s

13 step training time: 0.665712s

on_train_batch_end: 1615855101.723812s

28672/50000 [================>.............] - ETA: 21s - loss: 8.6115 - accuracy: 0.0278
on_train_batch_begin: 1615855101.724117s

14 step training time: 0.661699s

on_train_batch_end: 1615855102.385730s

30720/50000 [=================>............] - ETA: 18s - loss: 8.5165 - accuracy: 0.0297
on_train_batch_begin: 1615855102.386045s

15 step training time: 0.661928s

on_train_batch_end: 1615855103.053046s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.4283 - accuracy: 0.0322
on_train_batch_begin: 1615855103.053356s

16 step training time: 0.667311s

on_train_batch_end: 1615855103.719759s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.3476 - accuracy: 0.0344
on_train_batch_begin: 1615855103.720065s

17 step training time: 0.666709s

on_train_batch_end: 1615855104.386764s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.2690 - accuracy: 0.0368
on_train_batch_begin: 1615855104.387071s

18 step training time: 0.667006s

on_train_batch_end: 1615855105.048320s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.2002 - accuracy: 0.0386 
on_train_batch_begin: 1615855105.048633s

19 step training time: 0.661563s

on_train_batch_end: 1615855105.716848s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.1311 - accuracy: 0.0402
on_train_batch_begin: 1615855105.717151s

20 step training time: 0.668518s

on_train_batch_end: 1615855106.384717s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.0667 - accuracy: 0.0419
on_train_batch_begin: 1615855106.385034s

21 step training time: 0.667883s

on_train_batch_end: 1615855107.052692s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.0063 - accuracy: 0.0436
on_train_batch_begin: 1615855107.052996s

22 step training time: 0.667962s

on_train_batch_end: 1615855107.724060s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.9440 - accuracy: 0.0452
on_train_batch_begin: 1615855107.724364s

23 step training time: 0.671368s

on_train_batch_end: 1615855108.389994s

49152/50000 [============================>.] - ETA: 0s - loss: 7.8865 - accuracy: 0.0465
on_train_batch_begin: 1615855108.390341s

24 step training time: 0.665977s

on_train_batch_end: 1615855114.411056s

on_test_batch_begin: 1615855114.601366s

25 step training time: 6.211025s

on_epoch_end: 1615855119.842246s

Validation time: 5.240865s

Real time: 1615855119.842246s

Epoch time: 47.65192890167236s

50000/50000 [==============================] - 48s 953us/sample - loss: 7.8633 - accuracy: 0.0467 - val_loss: 1900.8522 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615855119.842465s

Real time: 1615855119.842471
Epoch 2/5

on_train_batch_begin: 1615855119.845905s

on_train_batch_end: 1615855120.526891s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.3842 - accuracy: 0.0823
on_train_batch_begin: 1615855120.527204s

1 step training time: 0.681299s

on_train_batch_end: 1615855121.201535s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.4192 - accuracy: 0.0820
on_train_batch_begin: 1615855121.201838s

2 step training time: 0.674634s

on_train_batch_end: 1615855121.877551s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.4296 - accuracy: 0.0817
on_train_batch_begin: 1615855121.877852s

3 step training time: 0.676015s

on_train_batch_end: 1615855122.545693s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.4196 - accuracy: 0.0822
on_train_batch_begin: 1615855122.545997s

4 step training time: 0.668144s

on_train_batch_end: 1615855123.225309s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.3881 - accuracy: 0.0829
on_train_batch_begin: 1615855123.225618s

5 step training time: 0.679621s

on_train_batch_end: 1615855123.899052s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.3722 - accuracy: 0.0830
on_train_batch_begin: 1615855123.899360s

6 step training time: 0.673742s

on_train_batch_end: 1615855124.572711s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.3455 - accuracy: 0.0838
on_train_batch_begin: 1615855124.573024s

7 step training time: 0.673663s

on_train_batch_end: 1615855125.249376s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.3237 - accuracy: 0.0833
on_train_batch_begin: 1615855125.249682s

8 step training time: 0.676659s

on_train_batch_end: 1615855125.932325s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.2992 - accuracy: 0.0838
on_train_batch_begin: 1615855125.932633s

9 step training time: 0.682950s

on_train_batch_end: 1615855126.603290s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.2786 - accuracy: 0.0839 
on_train_batch_begin: 1615855126.603603s

10 step training time: 0.670970s

on_train_batch_end: 1615855127.286564s

22528/50000 [============>.................] - ETA: 9s - loss: 6.2545 - accuracy: 0.0839
on_train_batch_begin: 1615855127.286865s

11 step training time: 0.683262s

on_train_batch_end: 1615855127.962105s

24576/50000 [=============>................] - ETA: 8s - loss: 6.2282 - accuracy: 0.0841
on_train_batch_begin: 1615855127.962437s

12 step training time: 0.675572s

on_train_batch_end: 1615855128.641961s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.2018 - accuracy: 0.0838
on_train_batch_begin: 1615855128.642304s

13 step training time: 0.679867s

on_train_batch_end: 1615855129.323078s

28672/50000 [================>.............] - ETA: 7s - loss: 6.1790 - accuracy: 0.0835
on_train_batch_begin: 1615855129.323386s

14 step training time: 0.681083s

on_train_batch_end: 1615855130.003897s

30720/50000 [=================>............] - ETA: 6s - loss: 6.1470 - accuracy: 0.0835
on_train_batch_begin: 1615855130.004199s

15 step training time: 0.680812s

on_train_batch_end: 1615855130.681008s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.1246 - accuracy: 0.0832
on_train_batch_begin: 1615855130.681311s

16 step training time: 0.677113s

on_train_batch_end: 1615855131.361498s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.0972 - accuracy: 0.0832
on_train_batch_begin: 1615855131.361809s

17 step training time: 0.680498s

on_train_batch_end: 1615855132.043095s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.0743 - accuracy: 0.0830
on_train_batch_begin: 1615855132.043404s

18 step training time: 0.681595s

on_train_batch_end: 1615855132.729887s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.0465 - accuracy: 0.0827
on_train_batch_begin: 1615855132.730209s

19 step training time: 0.686805s

on_train_batch_end: 1615855133.412032s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.0196 - accuracy: 0.0821
on_train_batch_begin: 1615855133.412340s

20 step training time: 0.682131s

on_train_batch_end: 1615855134.096318s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.9900 - accuracy: 0.0814
on_train_batch_begin: 1615855134.096622s

21 step training time: 0.684282s

on_train_batch_end: 1615855134.785111s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.9576 - accuracy: 0.0808
on_train_batch_begin: 1615855134.785418s

22 step training time: 0.688796s

on_train_batch_end: 1615855135.468486s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.9229 - accuracy: 0.0801
on_train_batch_begin: 1615855135.468786s

23 step training time: 0.683367s

on_train_batch_end: 1615855136.152720s

49152/50000 [============================>.] - ETA: 0s - loss: 5.8984 - accuracy: 0.0793
on_train_batch_begin: 1615855136.153032s

24 step training time: 0.684246s

on_train_batch_end: 1615855136.429985s

on_test_batch_begin: 1615855136.468708s

25 step training time: 0.315677s

on_epoch_end: 1615855137.326777s

Validation time: 0.858053s

Real time: 1615855137.326777s

Epoch time: 17.484322547912598s

50000/50000 [==============================] - 17s 350us/sample - loss: 5.8837 - accuracy: 0.0792 - val_loss: 8.1837 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615855137.326977s

Real time: 1615855137.3269827
Epoch 3/5

on_train_batch_begin: 1615855137.330405s

on_train_batch_end: 1615855138.009431s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.1193 - accuracy: 0.0636
on_train_batch_begin: 1615855138.009759s

1 step training time: 0.679354s

on_train_batch_end: 1615855138.699564s

 4096/50000 [=>............................] - ETA: 15s - loss: 5.0599 - accuracy: 0.0643
on_train_batch_begin: 1615855138.699890s

2 step training time: 0.690132s

on_train_batch_end: 1615855139.379219s

 6144/50000 [==>...........................] - ETA: 14s - loss: 4.9940 - accuracy: 0.0654
on_train_batch_begin: 1615855139.379542s

3 step training time: 0.679651s

on_train_batch_end: 1615855140.067404s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.9708 - accuracy: 0.0650
on_train_batch_begin: 1615855140.067722s

4 step training time: 0.688180s

on_train_batch_end: 1615855140.721879s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.9443 - accuracy: 0.0649
on_train_batch_begin: 1615855140.722214s

5 step training time: 0.654492s

on_train_batch_end: 1615855141.420647s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.9008 - accuracy: 0.0658
on_train_batch_begin: 1615855141.420970s

6 step training time: 0.698756s

on_train_batch_end: 1615855142.108776s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.8777 - accuracy: 0.0659
on_train_batch_begin: 1615855142.109104s

7 step training time: 0.688134s

on_train_batch_end: 1615855142.799331s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.8643 - accuracy: 0.0662
on_train_batch_begin: 1615855142.799659s

8 step training time: 0.690555s

on_train_batch_end: 1615855143.492440s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.8434 - accuracy: 0.0665
on_train_batch_begin: 1615855143.492765s

9 step training time: 0.693106s

on_train_batch_end: 1615855144.179414s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.8163 - accuracy: 0.0669 
on_train_batch_begin: 1615855144.179739s

10 step training time: 0.686974s

on_train_batch_end: 1615855144.872736s

22528/50000 [============>.................] - ETA: 9s - loss: 4.7829 - accuracy: 0.0672
on_train_batch_begin: 1615855144.873056s

11 step training time: 0.693316s

on_train_batch_end: 1615855145.562466s

24576/50000 [=============>................] - ETA: 8s - loss: 4.7505 - accuracy: 0.0674
on_train_batch_begin: 1615855145.562793s

12 step training time: 0.689737s

on_train_batch_end: 1615855146.255142s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.7082 - accuracy: 0.0680
on_train_batch_begin: 1615855146.255472s

13 step training time: 0.692679s

on_train_batch_end: 1615855146.948001s

28672/50000 [================>.............] - ETA: 7s - loss: 4.6628 - accuracy: 0.0685
on_train_batch_begin: 1615855146.948323s

14 step training time: 0.692852s

on_train_batch_end: 1615855147.641285s

30720/50000 [=================>............] - ETA: 6s - loss: 4.6274 - accuracy: 0.0690
on_train_batch_begin: 1615855147.641611s

15 step training time: 0.693288s

on_train_batch_end: 1615855148.340581s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.5876 - accuracy: 0.0697
on_train_batch_begin: 1615855148.340913s

16 step training time: 0.699301s

on_train_batch_end: 1615855149.035927s

34816/50000 [===================>..........] - ETA: 5s - loss: 4.5516 - accuracy: 0.0702
on_train_batch_begin: 1615855149.036249s

17 step training time: 0.695336s

on_train_batch_end: 1615855149.728278s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.5127 - accuracy: 0.0709
on_train_batch_begin: 1615855149.728612s

18 step training time: 0.692363s

on_train_batch_end: 1615855150.425576s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.4723 - accuracy: 0.0715
on_train_batch_begin: 1615855150.425899s

19 step training time: 0.697286s

on_train_batch_end: 1615855151.119325s

40960/50000 [=======================>......] - ETA: 3s - loss: 4.4381 - accuracy: 0.0721
on_train_batch_begin: 1615855151.119650s

20 step training time: 0.693752s

on_train_batch_end: 1615855151.812328s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.3967 - accuracy: 0.0726
on_train_batch_begin: 1615855151.812649s

21 step training time: 0.692998s

on_train_batch_end: 1615855152.505268s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.3589 - accuracy: 0.0733
on_train_batch_begin: 1615855152.505585s

22 step training time: 0.692936s

on_train_batch_end: 1615855153.204588s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.3106 - accuracy: 0.0740
on_train_batch_begin: 1615855153.204913s

23 step training time: 0.699327s

on_train_batch_end: 1615855153.896160s

49152/50000 [============================>.] - ETA: 0s - loss: 4.2611 - accuracy: 0.0747
on_train_batch_begin: 1615855153.896482s

24 step training time: 0.691569s

on_train_batch_end: 1615855154.194863s

on_test_batch_begin: 1615855154.233486s

25 step training time: 0.337004s

on_epoch_end: 1615855155.095404s

Validation time: 0.861901s

Real time: 1615855155.095404s

Epoch time: 17.768438577651978s

50000/50000 [==============================] - 18s 355us/sample - loss: 4.2382 - accuracy: 0.0749 - val_loss: 8.8612 - val_accuracy: 0.0998

on_epoch_begin: 1615855155.095611s

Real time: 1615855155.095616
Epoch 4/5

on_train_batch_begin: 1615855155.099076s

on_train_batch_end: 1615855155.792301s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.8436 - accuracy: 0.0937
on_train_batch_begin: 1615855155.792622s

1 step training time: 0.693547s

on_train_batch_end: 1615855156.491402s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.7797 - accuracy: 0.0966
on_train_batch_begin: 1615855156.491718s

2 step training time: 0.699095s

on_train_batch_end: 1615855157.193735s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.7944 - accuracy: 0.0969
on_train_batch_begin: 1615855157.194056s

3 step training time: 0.702339s

on_train_batch_end: 1615855157.891050s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.7815 - accuracy: 0.0975
on_train_batch_begin: 1615855157.891366s

4 step training time: 0.697309s

on_train_batch_end: 1615855158.596372s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.7567 - accuracy: 0.0980
on_train_batch_begin: 1615855158.596694s

5 step training time: 0.705328s

on_train_batch_end: 1615855159.292940s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.7362 - accuracy: 0.0982
on_train_batch_begin: 1615855159.293262s

6 step training time: 0.696568s

on_train_batch_end: 1615855159.995127s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.7355 - accuracy: 0.0984
on_train_batch_begin: 1615855159.995448s

7 step training time: 0.702186s

on_train_batch_end: 1615855160.688254s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.7286 - accuracy: 0.0985
on_train_batch_begin: 1615855160.688572s

8 step training time: 0.693124s

on_train_batch_end: 1615855161.392794s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.7122 - accuracy: 0.0985
on_train_batch_begin: 1615855161.393114s

9 step training time: 0.704541s

on_train_batch_end: 1615855162.097252s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.6852 - accuracy: 0.0987
on_train_batch_begin: 1615855162.097581s

10 step training time: 0.704468s

on_train_batch_end: 1615855162.799897s

22528/50000 [============>.................] - ETA: 9s - loss: 2.6582 - accuracy: 0.0988 
on_train_batch_begin: 1615855162.800220s

11 step training time: 0.702639s

on_train_batch_end: 1615855163.500472s

24576/50000 [=============>................] - ETA: 8s - loss: 2.6360 - accuracy: 0.0988
on_train_batch_begin: 1615855163.500790s

12 step training time: 0.700569s

on_train_batch_end: 1615855164.205448s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.6234 - accuracy: 0.0990
on_train_batch_begin: 1615855164.205770s

13 step training time: 0.704981s

on_train_batch_end: 1615855164.911207s

28672/50000 [================>.............] - ETA: 7s - loss: 2.6126 - accuracy: 0.0990
on_train_batch_begin: 1615855164.911536s

14 step training time: 0.705765s

on_train_batch_end: 1615855165.614589s

30720/50000 [=================>............] - ETA: 6s - loss: 2.5893 - accuracy: 0.0990
on_train_batch_begin: 1615855165.614916s

15 step training time: 0.703380s

on_train_batch_end: 1615855166.320274s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.5719 - accuracy: 0.0991
on_train_batch_begin: 1615855166.320604s

16 step training time: 0.705688s

on_train_batch_end: 1615855167.025495s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.5471 - accuracy: 0.0991
on_train_batch_begin: 1615855167.025818s

17 step training time: 0.705214s

on_train_batch_end: 1615855167.732957s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.5295 - accuracy: 0.0991
on_train_batch_begin: 1615855167.733280s

18 step training time: 0.707462s

on_train_batch_end: 1615855168.442908s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.5087 - accuracy: 0.0992
on_train_batch_begin: 1615855168.443233s

19 step training time: 0.709953s

on_train_batch_end: 1615855169.148205s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.4865 - accuracy: 0.0992
on_train_batch_begin: 1615855169.148530s

20 step training time: 0.705297s

on_train_batch_end: 1615855169.854212s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.4629 - accuracy: 0.0992
on_train_batch_begin: 1615855169.854545s

21 step training time: 0.706015s

on_train_batch_end: 1615855170.559948s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.4472 - accuracy: 0.0993
on_train_batch_begin: 1615855170.560271s

22 step training time: 0.705726s

on_train_batch_end: 1615855171.268709s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.4296 - accuracy: 0.0993
on_train_batch_begin: 1615855171.269036s

23 step training time: 0.708764s

on_train_batch_end: 1615855171.972317s

49152/50000 [============================>.] - ETA: 0s - loss: 2.4180 - accuracy: 0.0993
on_train_batch_begin: 1615855171.972640s

24 step training time: 0.703605s

on_train_batch_end: 1615855172.275784s

on_test_batch_begin: 1615855172.313961s

25 step training time: 0.341321s

on_epoch_end: 1615855173.188632s

Validation time: 0.874654s

Real time: 1615855173.188632s

Epoch time: 18.093032121658325s

50000/50000 [==============================] - 18s 362us/sample - loss: 2.4112 - accuracy: 0.0993 - val_loss: 8.0661 - val_accuracy: 0.0998

on_epoch_begin: 1615855173.188825s

Real time: 1615855173.1888301
Epoch 5/5

on_train_batch_begin: 1615855173.192209s

on_train_batch_end: 1615855173.892588s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.7758 - accuracy: 0.1000
on_train_batch_begin: 1615855173.892894s

1 step training time: 0.700685s

on_train_batch_end: 1615855174.604744s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.7736 - accuracy: 0.1001
on_train_batch_begin: 1615855174.605068s

2 step training time: 0.712175s

on_train_batch_end: 1615855175.311619s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.7792 - accuracy: 0.1001
on_train_batch_begin: 1615855175.311927s

3 step training time: 0.706859s

on_train_batch_end: 1615855176.019907s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.7676 - accuracy: 0.1001
on_train_batch_begin: 1615855176.020212s

4 step training time: 0.708285s

on_train_batch_end: 1615855176.725531s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.7586 - accuracy: 0.1001
on_train_batch_begin: 1615855176.725832s

5 step training time: 0.705620s

on_train_batch_end: 1615855177.436054s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.7477 - accuracy: 0.1000
on_train_batch_begin: 1615855177.436361s

6 step training time: 0.710529s

on_train_batch_end: 1615855178.151355s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.7285 - accuracy: 0.1000
on_train_batch_begin: 1615855178.151653s

7 step training time: 0.715292s

on_train_batch_end: 1615855178.861727s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.7191 - accuracy: 0.1000
on_train_batch_begin: 1615855178.862026s

8 step training time: 0.710374s

on_train_batch_end: 1615855179.573841s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.6964 - accuracy: 0.1000
on_train_batch_begin: 1615855179.574140s

9 step training time: 0.712114s

on_train_batch_end: 1615855180.291767s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.6776 - accuracy: 0.1000
on_train_batch_begin: 1615855180.292075s

10 step training time: 0.717935s

on_train_batch_end: 1615855181.004078s

22528/50000 [============>.................] - ETA: 9s - loss: 1.6811 - accuracy: 0.1000 
on_train_batch_begin: 1615855181.004397s

11 step training time: 0.712322s

on_train_batch_end: 1615855181.721126s

24576/50000 [=============>................] - ETA: 8s - loss: 1.6710 - accuracy: 0.1000
on_train_batch_begin: 1615855181.721431s

12 step training time: 0.717035s

on_train_batch_end: 1615855182.433676s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.6607 - accuracy: 0.1000
on_train_batch_begin: 1615855182.433989s

13 step training time: 0.712558s

on_train_batch_end: 1615855183.151778s

28672/50000 [================>.............] - ETA: 7s - loss: 1.6492 - accuracy: 0.1000
on_train_batch_begin: 1615855183.152079s

14 step training time: 0.718090s

on_train_batch_end: 1615855183.866938s

30720/50000 [=================>............] - ETA: 6s - loss: 1.6359 - accuracy: 0.1000
on_train_batch_begin: 1615855183.867237s

15 step training time: 0.715158s

on_train_batch_end: 1615855184.586274s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.6345 - accuracy: 0.1000
on_train_batch_begin: 1615855184.586584s

16 step training time: 0.719346s

on_train_batch_end: 1615855185.296401s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.6299 - accuracy: 0.1001
on_train_batch_begin: 1615855185.296703s

17 step training time: 0.710120s

on_train_batch_end: 1615855186.015706s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.6267 - accuracy: 0.1001
on_train_batch_begin: 1615855186.016006s

18 step training time: 0.719302s

on_train_batch_end: 1615855186.735291s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.6164 - accuracy: 0.1000
on_train_batch_begin: 1615855186.735595s

19 step training time: 0.719589s

on_train_batch_end: 1615855187.452270s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.6099 - accuracy: 0.1000
on_train_batch_begin: 1615855187.452576s

20 step training time: 0.716981s

on_train_batch_end: 1615855188.176092s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.5990 - accuracy: 0.1001
on_train_batch_begin: 1615855188.176406s

21 step training time: 0.723830s

on_train_batch_end: 1615855188.893726s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.5924 - accuracy: 0.1001
on_train_batch_begin: 1615855188.894027s

22 step training time: 0.717621s

on_train_batch_end: 1615855189.615715s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.5872 - accuracy: 0.1001
on_train_batch_begin: 1615855189.616042s

23 step training time: 0.722014s

on_train_batch_end: 1615855190.332535s

49152/50000 [============================>.] - ETA: 0s - loss: 1.5845 - accuracy: 0.1001
on_train_batch_begin: 1615855190.332857s

24 step training time: 0.716815s

on_train_batch_end: 1615855190.639806s

on_test_batch_begin: 1615855190.678240s

25 step training time: 0.345383s

on_epoch_end: 1615855191.573309s

Validation time: 0.895053s

Real time: 1615855191.573309s

Epoch time: 18.38449454307556s

50000/50000 [==============================] - 18s 368us/sample - loss: 1.5833 - accuracy: 0.1001 - val_loss: 7.5175 - val_accuracy: 0.0998
Tempo do fit: 122.900874376297