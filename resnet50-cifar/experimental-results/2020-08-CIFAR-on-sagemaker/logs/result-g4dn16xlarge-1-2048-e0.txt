wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:45
   188416/170498071 [..............................] - ETA: 1:05
   843776/170498071 [..............................] - ETA: 28s 
  3432448/170498071 [..............................] - ETA: 9s 
  6676480/170498071 [>.............................] - ETA: 5s
  9953280/170498071 [>.............................] - ETA: 4s
 13197312/170498071 [=>............................] - ETA: 4s
 16457728/170498071 [=>............................] - ETA: 3s
 19718144/170498071 [==>...........................] - ETA: 3s
 22978560/170498071 [===>..........................] - ETA: 3s
 26238976/170498071 [===>..........................] - ETA: 2s
 29499392/170498071 [====>.........................] - ETA: 2s
 32759808/170498071 [====>.........................] - ETA: 2s
 36003840/170498071 [=====>........................] - ETA: 2s
 39198720/170498071 [=====>........................] - ETA: 2s
 42377216/170498071 [======>.......................] - ETA: 2s
 45637632/170498071 [=======>......................] - ETA: 2s
 48881664/170498071 [=======>......................] - ETA: 2s
 52142080/170498071 [========>.....................] - ETA: 2s
 55402496/170498071 [========>.....................] - ETA: 2s
 58662912/170498071 [=========>....................] - ETA: 1s
 61923328/170498071 [=========>....................] - ETA: 1s
 65200128/170498071 [==========>...................] - ETA: 1s
 68476928/170498071 [===========>..................] - ETA: 1s
 71753728/170498071 [===========>..................] - ETA: 1s
 75014144/170498071 [============>.................] - ETA: 1s
 78241792/170498071 [============>.................] - ETA: 1s
 81469440/170498071 [=============>................] - ETA: 1s
 84615168/170498071 [=============>................] - ETA: 1s
 86908928/170498071 [==============>...............] - ETA: 1s
 90955776/170498071 [===============>..............] - ETA: 1s
 94183424/170498071 [===============>..............] - ETA: 1s
 97411072/170498071 [================>.............] - ETA: 1s
100687872/170498071 [================>.............] - ETA: 1s
103931904/170498071 [=================>............] - ETA: 1s
107126784/170498071 [=================>............] - ETA: 1s
110444544/170498071 [==================>...........] - ETA: 1s
113704960/170498071 [===================>..........] - ETA: 0s
116891648/170498071 [===================>..........] - ETA: 0s
120127488/170498071 [====================>.........] - ETA: 0s
123346944/170498071 [====================>.........] - ETA: 0s
126590976/170498071 [=====================>........] - ETA: 0s
129851392/170498071 [=====================>........] - ETA: 0s
133111808/170498071 [======================>.......] - ETA: 0s
136290304/170498071 [======================>.......] - ETA: 0s
139468800/170498071 [=======================>......] - ETA: 0s
142729216/170498071 [========================>.....] - ETA: 0s
145973248/170498071 [========================>.....] - ETA: 0s
149233664/170498071 [=========================>....] - ETA: 0s
152502272/170498071 [=========================>....] - ETA: 0s
155705344/170498071 [==========================>...] - ETA: 0s
158932992/170498071 [==========================>...] - ETA: 0s
161996800/170498071 [===========================>..] - ETA: 0s
165240832/170498071 [============================>.] - ETA: 0s
168255488/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 5799936/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
18833408/94765736 [====>.........................] - ETA: 0s
21618688/94765736 [=====>........................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
35897344/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
42803200/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
54509568/94765736 [================>.............] - ETA: 0s
62078976/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
73424896/94765736 [======================>.......] - ETA: 0s
76619776/94765736 [=======================>......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
92987392/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 15.4019615650177
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598505865.334596s

Real time: 1598505865.334614
Epoch 1/5

on_train_batch_begin: 1598505866.091669s

on_train_batch_end: 1598505887.037501s

 2048/50000 [>.............................] - ETA: 8:28 - loss: 17.9641 - accuracy: 9.6083e-05
on_train_batch_begin: 1598505887.038132s

1 step training time: 20.946463s

on_train_batch_end: 1598505887.727112s

 4096/50000 [=>............................] - ETA: 4:10 - loss: 14.7775 - accuracy: 2.9492e-04
on_train_batch_begin: 1598505887.727478s

2 step training time: 0.689346s

on_train_batch_end: 1598505888.411578s

 6144/50000 [==>...........................] - ETA: 2:44 - loss: 12.7481 - accuracy: 4.5649e-04
on_train_batch_begin: 1598505888.411919s

3 step training time: 0.684441s

on_train_batch_end: 1598505889.099943s

 8192/50000 [===>..........................] - ETA: 2:01 - loss: 11.5984 - accuracy: 0.0018    
on_train_batch_begin: 1598505889.100294s

4 step training time: 0.688375s

on_train_batch_end: 1598505889.780020s

10240/50000 [=====>........................] - ETA: 1:34 - loss: 10.8808 - accuracy: 0.0046
on_train_batch_begin: 1598505889.780317s

5 step training time: 0.680023s

on_train_batch_end: 1598505890.460752s

12288/50000 [======>.......................] - ETA: 1:17 - loss: 10.3937 - accuracy: 0.0091
on_train_batch_begin: 1598505890.461041s

6 step training time: 0.680724s

on_train_batch_end: 1598505891.146007s

14336/50000 [=======>......................] - ETA: 1:04 - loss: 10.0370 - accuracy: 0.0134
on_train_batch_begin: 1598505891.146277s

7 step training time: 0.685236s

on_train_batch_end: 1598505891.823172s

16384/50000 [========>.....................] - ETA: 54s - loss: 9.7753 - accuracy: 0.0179  
on_train_batch_begin: 1598505891.823466s

8 step training time: 0.677189s

on_train_batch_end: 1598505892.509511s

18432/50000 [==========>...................] - ETA: 46s - loss: 9.5529 - accuracy: 0.0212
on_train_batch_begin: 1598505892.509809s

9 step training time: 0.686342s

on_train_batch_end: 1598505893.190441s

20480/50000 [===========>..................] - ETA: 40s - loss: 9.3747 - accuracy: 0.0238
on_train_batch_begin: 1598505893.190718s

10 step training time: 0.680909s

on_train_batch_end: 1598505893.877843s

22528/50000 [============>.................] - ETA: 34s - loss: 9.2168 - accuracy: 0.0264
on_train_batch_begin: 1598505893.878118s

11 step training time: 0.687400s

on_train_batch_end: 1598505894.561202s

24576/50000 [=============>................] - ETA: 30s - loss: 9.0704 - accuracy: 0.0291
on_train_batch_begin: 1598505894.561478s

12 step training time: 0.683360s

on_train_batch_end: 1598505895.251053s

26624/50000 [==============>...............] - ETA: 26s - loss: 8.9485 - accuracy: 0.0308
on_train_batch_begin: 1598505895.251332s

13 step training time: 0.689854s

on_train_batch_end: 1598505895.937097s

28672/50000 [================>.............] - ETA: 22s - loss: 8.8301 - accuracy: 0.0322
on_train_batch_begin: 1598505895.937378s

14 step training time: 0.686046s

on_train_batch_end: 1598505896.625518s

30720/50000 [=================>............] - ETA: 19s - loss: 8.7284 - accuracy: 0.0338
on_train_batch_begin: 1598505896.625808s

15 step training time: 0.688430s

on_train_batch_end: 1598505897.309707s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.6325 - accuracy: 0.0353
on_train_batch_begin: 1598505897.309992s

16 step training time: 0.684184s

on_train_batch_end: 1598505897.997432s

34816/50000 [===================>..........] - ETA: 14s - loss: 8.5490 - accuracy: 0.0366
on_train_batch_begin: 1598505897.997727s

17 step training time: 0.687735s

on_train_batch_end: 1598505898.684390s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.4660 - accuracy: 0.0379
on_train_batch_begin: 1598505898.684671s

18 step training time: 0.686945s

on_train_batch_end: 1598505899.376502s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.3962 - accuracy: 0.0388 
on_train_batch_begin: 1598505899.376782s

19 step training time: 0.692111s

on_train_batch_end: 1598505900.067451s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.3265 - accuracy: 0.0403
on_train_batch_begin: 1598505900.067732s

20 step training time: 0.690949s

on_train_batch_end: 1598505900.764843s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.2652 - accuracy: 0.0419
on_train_batch_begin: 1598505900.765123s

21 step training time: 0.697392s

on_train_batch_end: 1598505901.459248s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.2098 - accuracy: 0.0433
on_train_batch_begin: 1598505901.459526s

22 step training time: 0.694402s

on_train_batch_end: 1598505902.150502s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.1536 - accuracy: 0.0447
on_train_batch_begin: 1598505902.150787s

23 step training time: 0.691262s

on_train_batch_end: 1598505902.837156s

49152/50000 [============================>.] - ETA: 0s - loss: 8.1054 - accuracy: 0.0459
on_train_batch_begin: 1598505902.837432s

24 step training time: 0.686644s

on_train_batch_end: 1598505909.118819s

on_test_batch_begin: 1598505909.302537s

25 step training time: 6.465106s

on_epoch_end: 1598505914.860977s

Validation time: 5.558426s

Real time: 1598505914.860977s

Epoch time: 49.52638506889343s

50000/50000 [==============================] - 50s 991us/sample - loss: 8.0867 - accuracy: 0.0461 - val_loss: 851560.2322 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598505914.861202s

Real time: 1598505914.8612077
Epoch 2/5

on_train_batch_begin: 1598505914.864789s

on_train_batch_end: 1598505915.570707s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.7862 - accuracy: 0.0851
on_train_batch_begin: 1598505915.570981s

1 step training time: 0.706192s

on_train_batch_end: 1598505916.274920s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.7830 - accuracy: 0.0848
on_train_batch_begin: 1598505916.275239s

2 step training time: 0.704258s

on_train_batch_end: 1598505916.978482s

 6144/50000 [==>...........................] - ETA: 15s - loss: 6.7563 - accuracy: 0.0860
on_train_batch_begin: 1598505916.978805s

3 step training time: 0.703566s

on_train_batch_end: 1598505917.680699s

 8192/50000 [===>..........................] - ETA: 14s - loss: 6.7478 - accuracy: 0.0861
on_train_batch_begin: 1598505917.681008s

4 step training time: 0.702203s

on_train_batch_end: 1598505918.384091s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.7399 - accuracy: 0.0856
on_train_batch_begin: 1598505918.384351s

5 step training time: 0.703343s

on_train_batch_end: 1598505919.087484s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.7413 - accuracy: 0.0859
on_train_batch_begin: 1598505919.087830s

6 step training time: 0.703479s

on_train_batch_end: 1598505919.795315s

14336/50000 [=======>......................] - ETA: 12s - loss: 6.7179 - accuracy: 0.0857
on_train_batch_begin: 1598505919.795638s

7 step training time: 0.707808s

on_train_batch_end: 1598505920.500692s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.6897 - accuracy: 0.0865
on_train_batch_begin: 1598505920.501030s

8 step training time: 0.705392s

on_train_batch_end: 1598505921.208631s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.6753 - accuracy: 0.0862
on_train_batch_begin: 1598505921.208966s

9 step training time: 0.707936s

on_train_batch_end: 1598505921.918695s

20480/50000 [===========>..................] - ETA: 10s - loss: 6.6363 - accuracy: 0.0868
on_train_batch_begin: 1598505921.919027s

10 step training time: 0.710061s

on_train_batch_end: 1598505922.626505s

22528/50000 [============>.................] - ETA: 9s - loss: 6.6145 - accuracy: 0.0866 
on_train_batch_begin: 1598505922.626843s

11 step training time: 0.707816s

on_train_batch_end: 1598505923.338051s

24576/50000 [=============>................] - ETA: 8s - loss: 6.5794 - accuracy: 0.0868
on_train_batch_begin: 1598505923.338407s

12 step training time: 0.711564s

on_train_batch_end: 1598505924.050539s

26624/50000 [==============>...............] - ETA: 8s - loss: 6.5608 - accuracy: 0.0868
on_train_batch_begin: 1598505924.050877s

13 step training time: 0.712471s

on_train_batch_end: 1598505924.760266s

28672/50000 [================>.............] - ETA: 7s - loss: 6.5333 - accuracy: 0.0865
on_train_batch_begin: 1598505924.760608s

14 step training time: 0.709731s

on_train_batch_end: 1598505925.467993s

30720/50000 [=================>............] - ETA: 6s - loss: 6.5008 - accuracy: 0.0866
on_train_batch_begin: 1598505925.468343s

15 step training time: 0.707735s

on_train_batch_end: 1598505926.189411s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.4750 - accuracy: 0.0866
on_train_batch_begin: 1598505926.189780s

16 step training time: 0.721437s

on_train_batch_end: 1598505926.902712s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.4532 - accuracy: 0.0868
on_train_batch_begin: 1598505926.903064s

17 step training time: 0.713283s

on_train_batch_end: 1598505927.616965s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.4316 - accuracy: 0.0869
on_train_batch_begin: 1598505927.617311s

18 step training time: 0.714247s

on_train_batch_end: 1598505928.333863s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.4065 - accuracy: 0.0867
on_train_batch_begin: 1598505928.334209s

19 step training time: 0.716898s

on_train_batch_end: 1598505929.052486s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.3802 - accuracy: 0.0867
on_train_batch_begin: 1598505929.052860s

20 step training time: 0.718651s

on_train_batch_end: 1598505929.765569s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.3615 - accuracy: 0.0867
on_train_batch_begin: 1598505929.765911s

21 step training time: 0.713051s

on_train_batch_end: 1598505930.454606s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.3354 - accuracy: 0.0866
on_train_batch_begin: 1598505930.454953s

22 step training time: 0.689042s

on_train_batch_end: 1598505931.170604s

47104/50000 [===========================>..] - ETA: 1s - loss: 6.3161 - accuracy: 0.0865
on_train_batch_begin: 1598505931.170945s

23 step training time: 0.715992s

on_train_batch_end: 1598505931.875925s

49152/50000 [============================>.] - ETA: 0s - loss: 6.2909 - accuracy: 0.0863
on_train_batch_begin: 1598505931.876258s

24 step training time: 0.705314s

on_train_batch_end: 1598505932.177562s

on_test_batch_begin: 1598505932.294564s

25 step training time: 0.418305s

on_epoch_end: 1598505933.297870s

Validation time: 1.003287s

Real time: 1598505933.297870s

Epoch time: 18.43668270111084s

50000/50000 [==============================] - 18s 369us/sample - loss: 6.2837 - accuracy: 0.0863 - val_loss: 7.2562 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598505933.298087s

Real time: 1598505933.298093
Epoch 3/5

on_train_batch_begin: 1598505933.301482s

on_train_batch_end: 1598505934.009744s

 2048/50000 [>.............................] - ETA: 16s - loss: 5.6496 - accuracy: 0.0835
on_train_batch_begin: 1598505934.010057s

1 step training time: 0.708575s

on_train_batch_end: 1598505934.733602s

 4096/50000 [=>............................] - ETA: 16s - loss: 5.6104 - accuracy: 0.0841
on_train_batch_begin: 1598505934.733942s

2 step training time: 0.723885s

on_train_batch_end: 1598505935.452063s

 6144/50000 [==>...........................] - ETA: 15s - loss: 5.5975 - accuracy: 0.0816
on_train_batch_begin: 1598505935.452392s

3 step training time: 0.718450s

on_train_batch_end: 1598505936.173778s

 8192/50000 [===>..........................] - ETA: 14s - loss: 5.5546 - accuracy: 0.0803
on_train_batch_begin: 1598505936.174118s

4 step training time: 0.721726s

on_train_batch_end: 1598505936.894572s

10240/50000 [=====>........................] - ETA: 13s - loss: 5.5264 - accuracy: 0.0796
on_train_batch_begin: 1598505936.894904s

5 step training time: 0.720786s

on_train_batch_end: 1598505937.615531s

12288/50000 [======>.......................] - ETA: 13s - loss: 5.5520 - accuracy: 0.0782
on_train_batch_begin: 1598505937.615864s

6 step training time: 0.720960s

on_train_batch_end: 1598505938.335939s

14336/50000 [=======>......................] - ETA: 12s - loss: 5.5401 - accuracy: 0.0770
on_train_batch_begin: 1598505938.336272s

7 step training time: 0.720408s

on_train_batch_end: 1598505939.055845s

16384/50000 [========>.....................] - ETA: 11s - loss: 5.5156 - accuracy: 0.0764
on_train_batch_begin: 1598505939.056183s

8 step training time: 0.719911s

on_train_batch_end: 1598505939.776073s

18432/50000 [==========>...................] - ETA: 11s - loss: 5.5014 - accuracy: 0.0763
on_train_batch_begin: 1598505939.776407s

9 step training time: 0.720223s

on_train_batch_end: 1598505940.498544s

20480/50000 [===========>..................] - ETA: 10s - loss: 5.4927 - accuracy: 0.0763
on_train_batch_begin: 1598505940.498890s

10 step training time: 0.722484s

on_train_batch_end: 1598505941.220919s

22528/50000 [============>.................] - ETA: 9s - loss: 5.4788 - accuracy: 0.0766 
on_train_batch_begin: 1598505941.221277s

11 step training time: 0.722386s

on_train_batch_end: 1598505941.946506s

24576/50000 [=============>................] - ETA: 8s - loss: 5.4723 - accuracy: 0.0774
on_train_batch_begin: 1598505941.946843s

12 step training time: 0.725566s

on_train_batch_end: 1598505942.670985s

26624/50000 [==============>...............] - ETA: 8s - loss: 5.4653 - accuracy: 0.0776
on_train_batch_begin: 1598505942.671329s

13 step training time: 0.724487s

on_train_batch_end: 1598505943.400537s

28672/50000 [================>.............] - ETA: 7s - loss: 5.4525 - accuracy: 0.0778
on_train_batch_begin: 1598505943.400884s

14 step training time: 0.729555s

on_train_batch_end: 1598505944.122298s

30720/50000 [=================>............] - ETA: 6s - loss: 5.4368 - accuracy: 0.0777
on_train_batch_begin: 1598505944.122669s

15 step training time: 0.721785s

on_train_batch_end: 1598505944.849056s

32768/50000 [==================>...........] - ETA: 6s - loss: 5.4273 - accuracy: 0.0781
on_train_batch_begin: 1598505944.849405s

16 step training time: 0.726737s

on_train_batch_end: 1598505945.573124s

34816/50000 [===================>..........] - ETA: 5s - loss: 5.4244 - accuracy: 0.0784
on_train_batch_begin: 1598505945.573477s

17 step training time: 0.724072s

on_train_batch_end: 1598505946.302006s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.4139 - accuracy: 0.0789
on_train_batch_begin: 1598505946.302365s

18 step training time: 0.728888s

on_train_batch_end: 1598505947.034340s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.4016 - accuracy: 0.0792
on_train_batch_begin: 1598505947.034713s

19 step training time: 0.732348s

on_train_batch_end: 1598505947.766662s

40960/50000 [=======================>......] - ETA: 3s - loss: 5.3876 - accuracy: 0.0794
on_train_batch_begin: 1598505947.767030s

20 step training time: 0.732317s

on_train_batch_end: 1598505948.499580s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.3751 - accuracy: 0.0792
on_train_batch_begin: 1598505948.499950s

21 step training time: 0.732920s

on_train_batch_end: 1598505949.228599s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.3594 - accuracy: 0.0788
on_train_batch_begin: 1598505949.228963s

22 step training time: 0.729013s

on_train_batch_end: 1598505949.960886s

47104/50000 [===========================>..] - ETA: 1s - loss: 5.3504 - accuracy: 0.0784
on_train_batch_begin: 1598505949.961229s

23 step training time: 0.732266s

on_train_batch_end: 1598505950.690291s

49152/50000 [============================>.] - ETA: 0s - loss: 5.3365 - accuracy: 0.0780
on_train_batch_begin: 1598505950.690658s

24 step training time: 0.729429s

on_train_batch_end: 1598505950.993006s

on_test_batch_begin: 1598505951.114182s

25 step training time: 0.423524s

on_epoch_end: 1598505952.110792s

Validation time: 0.996590s

Real time: 1598505952.110792s

Epoch time: 18.8127224445343s

50000/50000 [==============================] - 19s 376us/sample - loss: 5.3282 - accuracy: 0.0780 - val_loss: 7.1975 - val_accuracy: 0.0998

on_epoch_begin: 1598505952.111011s

Real time: 1598505952.1110163
Epoch 4/5

on_train_batch_begin: 1598505952.114511s

on_train_batch_end: 1598505952.836465s

 2048/50000 [>.............................] - ETA: 16s - loss: 4.9162 - accuracy: 0.0645
on_train_batch_begin: 1598505952.836796s

1 step training time: 0.722285s

on_train_batch_end: 1598505953.572468s

 4096/50000 [=>............................] - ETA: 16s - loss: 4.9074 - accuracy: 0.0647
on_train_batch_begin: 1598505953.572832s

2 step training time: 0.736036s

on_train_batch_end: 1598505954.301120s

 6144/50000 [==>...........................] - ETA: 15s - loss: 4.9092 - accuracy: 0.0653
on_train_batch_begin: 1598505954.301451s

3 step training time: 0.728618s

on_train_batch_end: 1598505955.027956s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.9134 - accuracy: 0.0631
on_train_batch_begin: 1598505955.028295s

4 step training time: 0.726844s

on_train_batch_end: 1598505955.766613s

10240/50000 [=====>........................] - ETA: 14s - loss: 4.9008 - accuracy: 0.0618
on_train_batch_begin: 1598505955.766949s

5 step training time: 0.738654s

on_train_batch_end: 1598505956.501700s

12288/50000 [======>.......................] - ETA: 13s - loss: 4.8945 - accuracy: 0.0611
on_train_batch_begin: 1598505956.502043s

6 step training time: 0.735094s

on_train_batch_end: 1598505957.233607s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.8618 - accuracy: 0.0609
on_train_batch_begin: 1598505957.233963s

7 step training time: 0.731920s

on_train_batch_end: 1598505957.967848s

16384/50000 [========>.....................] - ETA: 12s - loss: 4.8668 - accuracy: 0.0598
on_train_batch_begin: 1598505957.968194s

8 step training time: 0.734231s

on_train_batch_end: 1598505958.701360s

18432/50000 [==========>...................] - ETA: 11s - loss: 4.8454 - accuracy: 0.0591
on_train_batch_begin: 1598505958.701718s

9 step training time: 0.733525s

on_train_batch_end: 1598505959.437825s

20480/50000 [===========>..................] - ETA: 10s - loss: 4.8263 - accuracy: 0.0590
on_train_batch_begin: 1598505959.438165s

10 step training time: 0.736447s

on_train_batch_end: 1598505960.174194s

22528/50000 [============>.................] - ETA: 9s - loss: 4.8164 - accuracy: 0.0591 
on_train_batch_begin: 1598505960.174540s

11 step training time: 0.736374s

on_train_batch_end: 1598505960.909444s

24576/50000 [=============>................] - ETA: 9s - loss: 4.7972 - accuracy: 0.0593
on_train_batch_begin: 1598505960.909808s

12 step training time: 0.735269s

on_train_batch_end: 1598505961.644304s

26624/50000 [==============>...............] - ETA: 8s - loss: 4.7803 - accuracy: 0.0598
on_train_batch_begin: 1598505961.644650s

13 step training time: 0.734841s

on_train_batch_end: 1598505962.377146s

28672/50000 [================>.............] - ETA: 7s - loss: 4.7646 - accuracy: 0.0603
on_train_batch_begin: 1598505962.377492s

14 step training time: 0.732842s

on_train_batch_end: 1598505963.114257s

30720/50000 [=================>............] - ETA: 6s - loss: 4.7436 - accuracy: 0.0606
on_train_batch_begin: 1598505963.114606s

15 step training time: 0.737114s

on_train_batch_end: 1598505963.854063s

32768/50000 [==================>...........] - ETA: 6s - loss: 4.7263 - accuracy: 0.0606
on_train_batch_begin: 1598505963.854407s

16 step training time: 0.739801s

on_train_batch_end: 1598505964.591175s

34816/50000 [===================>..........] - ETA: 5s - loss: 4.7123 - accuracy: 0.0606
on_train_batch_begin: 1598505964.591519s

17 step training time: 0.737112s

on_train_batch_end: 1598505965.330925s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.7056 - accuracy: 0.0605
on_train_batch_begin: 1598505965.331270s

18 step training time: 0.739751s

on_train_batch_end: 1598505966.071575s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.6902 - accuracy: 0.0605
on_train_batch_begin: 1598505966.071923s

19 step training time: 0.740653s

on_train_batch_end: 1598505966.814005s

40960/50000 [=======================>......] - ETA: 3s - loss: 4.6738 - accuracy: 0.0607
on_train_batch_begin: 1598505966.814347s

20 step training time: 0.742424s

on_train_batch_end: 1598505967.562697s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.6624 - accuracy: 0.0609
on_train_batch_begin: 1598505967.563045s

21 step training time: 0.748698s

on_train_batch_end: 1598505968.307054s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.6473 - accuracy: 0.0610
on_train_batch_begin: 1598505968.307399s

22 step training time: 0.744354s

on_train_batch_end: 1598505969.053704s

47104/50000 [===========================>..] - ETA: 1s - loss: 4.6350 - accuracy: 0.0611
on_train_batch_begin: 1598505969.054043s

23 step training time: 0.746644s

on_train_batch_end: 1598505969.794200s

49152/50000 [============================>.] - ETA: 0s - loss: 4.6238 - accuracy: 0.0613
on_train_batch_begin: 1598505969.794535s

24 step training time: 0.740492s

on_train_batch_end: 1598505970.105742s

on_test_batch_begin: 1598505970.228019s

25 step training time: 0.433484s

on_epoch_end: 1598505971.253837s

Validation time: 1.025800s

Real time: 1598505971.253837s

Epoch time: 19.142842531204224s

50000/50000 [==============================] - 19s 383us/sample - loss: 4.6163 - accuracy: 0.0613 - val_loss: 7.3908 - val_accuracy: 0.0998

on_epoch_begin: 1598505971.254047s

Real time: 1598505971.2540524
Epoch 5/5

on_train_batch_begin: 1598505971.257483s

on_train_batch_end: 1598505971.993339s

 2048/50000 [>.............................] - ETA: 17s - loss: 4.1658 - accuracy: 0.0698
on_train_batch_begin: 1598505971.993634s

1 step training time: 0.736151s

on_train_batch_end: 1598505972.742803s

 4096/50000 [=>............................] - ETA: 16s - loss: 4.1804 - accuracy: 0.0691
on_train_batch_begin: 1598505972.743119s

2 step training time: 0.749485s

on_train_batch_end: 1598505973.488707s

 6144/50000 [==>...........................] - ETA: 15s - loss: 4.1838 - accuracy: 0.0685
on_train_batch_begin: 1598505973.489031s

3 step training time: 0.745912s

on_train_batch_end: 1598505974.233602s

 8192/50000 [===>..........................] - ETA: 15s - loss: 4.1786 - accuracy: 0.0682
on_train_batch_begin: 1598505974.233938s

4 step training time: 0.744907s

on_train_batch_end: 1598505974.983823s

10240/50000 [=====>........................] - ETA: 14s - loss: 4.1700 - accuracy: 0.0679
on_train_batch_begin: 1598505974.984155s

5 step training time: 0.750217s

on_train_batch_end: 1598505975.728521s

12288/50000 [======>.......................] - ETA: 13s - loss: 4.1506 - accuracy: 0.0678
on_train_batch_begin: 1598505975.728867s

6 step training time: 0.744712s

on_train_batch_end: 1598505976.478263s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.1400 - accuracy: 0.0682
on_train_batch_begin: 1598505976.478601s

7 step training time: 0.749734s

on_train_batch_end: 1598505977.220301s

16384/50000 [========>.....................] - ETA: 12s - loss: 4.1054 - accuracy: 0.0687
on_train_batch_begin: 1598505977.220645s

8 step training time: 0.742044s

on_train_batch_end: 1598505977.965736s

18432/50000 [==========>...................] - ETA: 11s - loss: 4.0833 - accuracy: 0.0689
on_train_batch_begin: 1598505977.966073s

9 step training time: 0.745429s

on_train_batch_end: 1598505978.704306s

20480/50000 [===========>..................] - ETA: 10s - loss: 4.0403 - accuracy: 0.0693
on_train_batch_begin: 1598505978.704641s

10 step training time: 0.738568s

on_train_batch_end: 1598505979.449419s

22528/50000 [============>.................] - ETA: 9s - loss: 4.0246 - accuracy: 0.0695 
on_train_batch_begin: 1598505979.449777s

11 step training time: 0.745136s

on_train_batch_end: 1598505980.191368s

24576/50000 [=============>................] - ETA: 9s - loss: 4.0030 - accuracy: 0.0699
on_train_batch_begin: 1598505980.191719s

12 step training time: 0.741942s

on_train_batch_end: 1598505980.931236s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.9804 - accuracy: 0.0702
on_train_batch_begin: 1598505980.931576s

13 step training time: 0.739857s

on_train_batch_end: 1598505981.677627s

28672/50000 [================>.............] - ETA: 7s - loss: 3.9607 - accuracy: 0.0706
on_train_batch_begin: 1598505981.677964s

14 step training time: 0.746388s

on_train_batch_end: 1598505982.421564s

30720/50000 [=================>............] - ETA: 7s - loss: 3.9433 - accuracy: 0.0708
on_train_batch_begin: 1598505982.421909s

15 step training time: 0.743945s

on_train_batch_end: 1598505983.166246s

32768/50000 [==================>...........] - ETA: 6s - loss: 3.9282 - accuracy: 0.0711
on_train_batch_begin: 1598505983.166594s

16 step training time: 0.744685s

on_train_batch_end: 1598505983.911319s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.9165 - accuracy: 0.0712
on_train_batch_begin: 1598505983.911663s

17 step training time: 0.745068s

on_train_batch_end: 1598505984.654058s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.8999 - accuracy: 0.0714
on_train_batch_begin: 1598505984.654398s

18 step training time: 0.742736s

on_train_batch_end: 1598505985.394675s

38912/50000 [======================>.......] - ETA: 4s - loss: 3.8766 - accuracy: 0.0717
on_train_batch_begin: 1598505985.395033s

19 step training time: 0.740635s

on_train_batch_end: 1598505986.139959s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.8525 - accuracy: 0.0720
on_train_batch_begin: 1598505986.140306s

20 step training time: 0.745272s

on_train_batch_end: 1598505986.876326s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.8282 - accuracy: 0.0722
on_train_batch_begin: 1598505986.876673s

21 step training time: 0.736367s

on_train_batch_end: 1598505987.624089s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.8043 - accuracy: 0.0725
on_train_batch_begin: 1598505987.624433s

22 step training time: 0.747760s

on_train_batch_end: 1598505988.371443s

47104/50000 [===========================>..] - ETA: 1s - loss: 3.7825 - accuracy: 0.0730
on_train_batch_begin: 1598505988.371769s

23 step training time: 0.747336s

on_train_batch_end: 1598505989.114067s

49152/50000 [============================>.] - ETA: 0s - loss: 3.7597 - accuracy: 0.0734
on_train_batch_begin: 1598505989.114403s

24 step training time: 0.742633s

on_train_batch_end: 1598505989.431777s

on_test_batch_begin: 1598505989.557252s

25 step training time: 0.442850s

on_epoch_end: 1598505990.572158s

Validation time: 1.014888s

Real time: 1598505990.572158s

Epoch time: 19.31812572479248s

50000/50000 [==============================] - 19s 386us/sample - loss: 3.7443 - accuracy: 0.0735 - val_loss: 7.6276 - val_accuracy: 0.0000e+00
Tempo do fit: 128.81862044334412