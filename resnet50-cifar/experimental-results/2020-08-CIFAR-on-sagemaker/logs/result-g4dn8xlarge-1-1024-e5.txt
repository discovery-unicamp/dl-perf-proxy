wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:42
   221184/170498071 [..............................] - ETA: 1:11
  1212416/170498071 [..............................] - ETA: 19s 
  4022272/170498071 [..............................] - ETA: 7s 
  7364608/170498071 [>.............................] - ETA: 5s
 10756096/170498071 [>.............................] - ETA: 4s
 14114816/170498071 [=>............................] - ETA: 3s
 16916480/170498071 [=>............................] - ETA: 3s
 20619264/170498071 [==>...........................] - ETA: 3s
 23764992/170498071 [===>..........................] - ETA: 3s
 26959872/170498071 [===>..........................] - ETA: 2s
 30285824/170498071 [====>.........................] - ETA: 2s
 33652736/170498071 [====>.........................] - ETA: 2s
 37019648/170498071 [=====>........................] - ETA: 2s
 40402944/170498071 [======>.......................] - ETA: 2s
 43769856/170498071 [======>.......................] - ETA: 2s
 47144960/170498071 [=======>......................] - ETA: 2s
 50388992/170498071 [=======>......................] - ETA: 2s
 53567488/170498071 [========>.....................] - ETA: 2s
 56860672/170498071 [=========>....................] - ETA: 2s
 60252160/170498071 [=========>....................] - ETA: 1s
 63627264/170498071 [==========>...................] - ETA: 1s
 66994176/170498071 [==========>...................] - ETA: 1s
 70344704/170498071 [===========>..................] - ETA: 1s
 73719808/170498071 [===========>..................] - ETA: 1s
 76996608/170498071 [============>.................] - ETA: 1s
 80191488/170498071 [=============>................] - ETA: 1s
 83378176/170498071 [=============>................] - ETA: 1s
 86761472/170498071 [==============>...............] - ETA: 1s
 90071040/170498071 [==============>...............] - ETA: 1s
 93437952/170498071 [===============>..............] - ETA: 1s
 96804864/170498071 [================>.............] - ETA: 1s
100163584/170498071 [================>.............] - ETA: 1s
103522304/170498071 [=================>............] - ETA: 1s
106848256/170498071 [=================>............] - ETA: 1s
109993984/170498071 [==================>...........] - ETA: 0s
113238016/170498071 [==================>...........] - ETA: 0s
116621312/170498071 [===================>..........] - ETA: 0s
119922688/170498071 [====================>.........] - ETA: 0s
123297792/170498071 [====================>.........] - ETA: 0s
126590976/170498071 [=====================>........] - ETA: 0s
129966080/170498071 [=====================>........] - ETA: 0s
133341184/170498071 [======================>.......] - ETA: 0s
136683520/170498071 [=======================>......] - ETA: 0s
139927552/170498071 [=======================>......] - ETA: 0s
143302656/170498071 [========================>.....] - ETA: 0s
146464768/170498071 [========================>.....] - ETA: 0s
149774336/170498071 [=========================>....] - ETA: 0s
153083904/170498071 [=========================>....] - ETA: 0s
156459008/170498071 [==========================>...] - ETA: 0s
159801344/170498071 [===========================>..] - ETA: 0s
163143680/170498071 [===========================>..] - ETA: 0s
166338560/170498071 [============================>.] - ETA: 0s
169549824/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 2105344/94765736 [..............................] - ETA: 2s
 7454720/94765736 [=>............................] - ETA: 1s
12910592/94765736 [===>..........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
23429120/94765736 [======>.......................] - ETA: 0s
30687232/94765736 [========>.....................] - ETA: 0s
35782656/94765736 [==========>...................] - ETA: 0s
44023808/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
52355072/94765736 [===============>..............] - ETA: 0s
57319424/94765736 [=================>............] - ETA: 0s
62357504/94765736 [==================>...........] - ETA: 0s
67837952/94765736 [====================>.........] - ETA: 0s
72204288/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
80273408/94765736 [========================>.....] - ETA: 0s
84975616/94765736 [=========================>....] - ETA: 0s
90980352/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.617985486984253
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615758882.331862s

Real time: 1615758882.3318825
Epoch 1/5

on_train_batch_begin: 1615758883.100052s

on_train_batch_end: 1615758900.306659s

 1024/50000 [..............................] - ETA: 14:19 - loss: 17.5693 - accuracy: 1.9073e-04
on_train_batch_begin: 1615758900.307264s

1 step training time: 17.207212s

on_train_batch_end: 1615758900.635114s

 2048/50000 [>.............................] - ETA: 7:08 - loss: 13.6781 - accuracy: 3.6001e-04 
on_train_batch_begin: 1615758900.635427s

2 step training time: 0.328163s

on_train_batch_end: 1615758900.960250s

 3072/50000 [>.............................] - ETA: 4:44 - loss: 12.0058 - accuracy: 0.0012    
on_train_batch_begin: 1615758900.960548s

3 step training time: 0.325122s

on_train_batch_end: 1615758901.286138s

 4096/50000 [=>............................] - ETA: 3:32 - loss: 11.0699 - accuracy: 0.0029
on_train_batch_begin: 1615758901.286436s

4 step training time: 0.325887s

on_train_batch_end: 1615758901.611137s

 5120/50000 [==>...........................] - ETA: 2:48 - loss: 10.5102 - accuracy: 0.0061
on_train_batch_begin: 1615758901.611447s

5 step training time: 0.325011s

on_train_batch_end: 1615758901.936579s

 6144/50000 [==>...........................] - ETA: 2:19 - loss: 10.0911 - accuracy: 0.0102
on_train_batch_begin: 1615758901.936874s

6 step training time: 0.325428s

on_train_batch_end: 1615758902.261654s

 7168/50000 [===>..........................] - ETA: 1:59 - loss: 9.7771 - accuracy: 0.0144 
on_train_batch_begin: 1615758902.261961s

7 step training time: 0.325086s

on_train_batch_end: 1615758902.585547s

 8192/50000 [===>..........................] - ETA: 1:43 - loss: 9.5309 - accuracy: 0.0178
on_train_batch_begin: 1615758902.585846s

8 step training time: 0.323885s

on_train_batch_end: 1615758902.911135s

 9216/50000 [====>.........................] - ETA: 1:31 - loss: 9.3270 - accuracy: 0.0208
on_train_batch_begin: 1615758902.911440s

9 step training time: 0.325594s

on_train_batch_end: 1615758903.235980s

10240/50000 [=====>........................] - ETA: 1:21 - loss: 9.1442 - accuracy: 0.0240
on_train_batch_begin: 1615758903.236280s

10 step training time: 0.324840s

on_train_batch_end: 1615758903.564418s

11264/50000 [=====>........................] - ETA: 1:13 - loss: 9.0024 - accuracy: 0.0271
on_train_batch_begin: 1615758903.564713s

11 step training time: 0.328433s

on_train_batch_end: 1615758903.890305s

12288/50000 [======>.......................] - ETA: 1:06 - loss: 8.8773 - accuracy: 0.0305
on_train_batch_begin: 1615758903.890619s

12 step training time: 0.325906s

on_train_batch_end: 1615758904.212331s

13312/50000 [======>.......................] - ETA: 1:00 - loss: 8.7797 - accuracy: 0.0327
on_train_batch_begin: 1615758904.212632s

13 step training time: 0.322013s

on_train_batch_end: 1615758904.538983s

14336/50000 [=======>......................] - ETA: 55s - loss: 8.6936 - accuracy: 0.0352 
on_train_batch_begin: 1615758904.539281s

14 step training time: 0.326649s

on_train_batch_end: 1615758904.863476s

15360/50000 [========>.....................] - ETA: 50s - loss: 8.6125 - accuracy: 0.0375
on_train_batch_begin: 1615758904.863774s

15 step training time: 0.324493s

on_train_batch_end: 1615758905.189670s

16384/50000 [========>.....................] - ETA: 46s - loss: 8.5409 - accuracy: 0.0392
on_train_batch_begin: 1615758905.189968s

16 step training time: 0.326194s

on_train_batch_end: 1615758905.515847s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.4751 - accuracy: 0.0412
on_train_batch_begin: 1615758905.516140s

17 step training time: 0.326172s

on_train_batch_end: 1615758905.840224s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.4045 - accuracy: 0.0443
on_train_batch_begin: 1615758905.840521s

18 step training time: 0.324380s

on_train_batch_end: 1615758906.167924s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.3472 - accuracy: 0.0462
on_train_batch_begin: 1615758906.168218s

19 step training time: 0.327698s

on_train_batch_end: 1615758906.495266s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.2908 - accuracy: 0.0480
on_train_batch_begin: 1615758906.495559s

20 step training time: 0.327341s

on_train_batch_end: 1615758906.823603s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.2301 - accuracy: 0.0497
on_train_batch_begin: 1615758906.823893s

21 step training time: 0.328334s

on_train_batch_end: 1615758907.151879s

22528/50000 [============>.................] - ETA: 30s - loss: 8.1746 - accuracy: 0.0515
on_train_batch_begin: 1615758907.152168s

22 step training time: 0.328275s

on_train_batch_end: 1615758907.478909s

23552/50000 [=============>................] - ETA: 28s - loss: 8.1299 - accuracy: 0.0527
on_train_batch_begin: 1615758907.479201s

23 step training time: 0.327034s

on_train_batch_end: 1615758907.807265s

24576/50000 [=============>................] - ETA: 26s - loss: 8.0799 - accuracy: 0.0541
on_train_batch_begin: 1615758907.807551s

24 step training time: 0.328350s

on_train_batch_end: 1615758908.133479s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.0359 - accuracy: 0.0553
on_train_batch_begin: 1615758908.133765s

25 step training time: 0.326214s

on_train_batch_end: 1615758908.458319s

26624/50000 [==============>...............] - ETA: 22s - loss: 7.9909 - accuracy: 0.0566
on_train_batch_begin: 1615758908.458612s

26 step training time: 0.324847s

on_train_batch_end: 1615758908.784758s

27648/50000 [===============>..............] - ETA: 21s - loss: 7.9508 - accuracy: 0.0573
on_train_batch_begin: 1615758908.785047s

27 step training time: 0.326435s

on_train_batch_end: 1615758909.110540s

28672/50000 [================>.............] - ETA: 19s - loss: 7.9122 - accuracy: 0.0578
on_train_batch_begin: 1615758909.110825s

28 step training time: 0.325778s

on_train_batch_end: 1615758909.437856s

29696/50000 [================>.............] - ETA: 18s - loss: 7.8681 - accuracy: 0.0591
on_train_batch_begin: 1615758909.438147s

29 step training time: 0.327322s

on_train_batch_end: 1615758909.764488s

30720/50000 [=================>............] - ETA: 17s - loss: 7.8305 - accuracy: 0.0599
on_train_batch_begin: 1615758909.764773s

30 step training time: 0.326625s

on_train_batch_end: 1615758910.089932s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.7891 - accuracy: 0.0606
on_train_batch_begin: 1615758910.090224s

31 step training time: 0.325451s

on_train_batch_end: 1615758910.418959s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.7521 - accuracy: 0.0614
on_train_batch_begin: 1615758910.419244s

32 step training time: 0.329020s

on_train_batch_end: 1615758910.748509s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.7195 - accuracy: 0.0622
on_train_batch_begin: 1615758910.748797s

33 step training time: 0.329554s

on_train_batch_end: 1615758911.086734s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.6893 - accuracy: 0.0628
on_train_batch_begin: 1615758911.087049s

34 step training time: 0.338251s

on_train_batch_end: 1615758911.416921s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.6552 - accuracy: 0.0635
on_train_batch_begin: 1615758911.417211s

35 step training time: 0.330162s

on_train_batch_end: 1615758911.748503s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.6245 - accuracy: 0.0639
on_train_batch_begin: 1615758911.748794s

36 step training time: 0.331583s

on_train_batch_end: 1615758912.083018s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.5931 - accuracy: 0.0646 
on_train_batch_begin: 1615758912.083315s

37 step training time: 0.334521s

on_train_batch_end: 1615758912.413261s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.5621 - accuracy: 0.0652
on_train_batch_begin: 1615758912.413558s

38 step training time: 0.330243s

on_train_batch_end: 1615758912.743548s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.5346 - accuracy: 0.0654
on_train_batch_begin: 1615758912.743846s

39 step training time: 0.330288s

on_train_batch_end: 1615758913.072769s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.5049 - accuracy: 0.0659
on_train_batch_begin: 1615758913.073076s

40 step training time: 0.329230s

on_train_batch_end: 1615758913.401297s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.4752 - accuracy: 0.0663
on_train_batch_begin: 1615758913.401592s

41 step training time: 0.328516s

on_train_batch_end: 1615758913.731655s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.4470 - accuracy: 0.0667
on_train_batch_begin: 1615758913.731951s

42 step training time: 0.330359s

on_train_batch_end: 1615758914.064032s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.4190 - accuracy: 0.0672
on_train_batch_begin: 1615758914.064325s

43 step training time: 0.332374s

on_train_batch_end: 1615758914.394259s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.3898 - accuracy: 0.0675
on_train_batch_begin: 1615758914.394554s

44 step training time: 0.330230s

on_train_batch_end: 1615758914.722382s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.3603 - accuracy: 0.0678
on_train_batch_begin: 1615758914.722675s

45 step training time: 0.328120s

on_train_batch_end: 1615758915.054932s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.3326 - accuracy: 0.0681
on_train_batch_begin: 1615758915.055224s

46 step training time: 0.332549s

on_train_batch_end: 1615758915.385314s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.3067 - accuracy: 0.0683
on_train_batch_begin: 1615758915.385607s

47 step training time: 0.330383s

on_train_batch_end: 1615758915.714347s

49152/50000 [============================>.] - ETA: 0s - loss: 7.2804 - accuracy: 0.0685
on_train_batch_begin: 1615758915.714652s

48 step training time: 0.329045s

on_train_batch_end: 1615758921.573009s

on_test_batch_begin: 1615758921.763064s

49 step training time: 6.048412s

on_epoch_end: 1615758926.480912s

Validation time: 4.717833s

Real time: 1615758926.480912s

Epoch time: 44.149046897888184s

50000/50000 [==============================] - 44s 883us/sample - loss: 7.2597 - accuracy: 0.0686 - val_loss: 20.6823 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615758926.481114s

Real time: 1615758926.4811192
Epoch 2/5

on_train_batch_begin: 1615758926.484492s

on_train_batch_end: 1615758926.816256s

 1024/50000 [..............................] - ETA: 16s - loss: 5.9655 - accuracy: 0.0745
on_train_batch_begin: 1615758926.816575s

1 step training time: 0.332082s

on_train_batch_end: 1615758927.145896s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.9080 - accuracy: 0.0781
on_train_batch_begin: 1615758927.146192s

2 step training time: 0.329617s

on_train_batch_end: 1615758927.479072s

 3072/50000 [>.............................] - ETA: 15s - loss: 5.8474 - accuracy: 0.0817
on_train_batch_begin: 1615758927.479357s

3 step training time: 0.333166s

on_train_batch_end: 1615758927.810598s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.8031 - accuracy: 0.0789
on_train_batch_begin: 1615758927.810904s

4 step training time: 0.331547s

on_train_batch_end: 1615758928.141499s

 5120/50000 [==>...........................] - ETA: 14s - loss: 5.8108 - accuracy: 0.0766
on_train_batch_begin: 1615758928.141788s

5 step training time: 0.330884s

on_train_batch_end: 1615758928.474925s

 6144/50000 [==>...........................] - ETA: 14s - loss: 5.7801 - accuracy: 0.0749
on_train_batch_begin: 1615758928.475217s

6 step training time: 0.333429s

on_train_batch_end: 1615758928.806751s

 7168/50000 [===>..........................] - ETA: 13s - loss: 5.7613 - accuracy: 0.0753
on_train_batch_begin: 1615758928.807063s

7 step training time: 0.331846s

on_train_batch_end: 1615758929.140369s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.7488 - accuracy: 0.0737
on_train_batch_begin: 1615758929.140664s

8 step training time: 0.333601s

on_train_batch_end: 1615758929.472355s

 9216/50000 [====>.........................] - ETA: 13s - loss: 5.7440 - accuracy: 0.0730
on_train_batch_begin: 1615758929.472643s

9 step training time: 0.331979s

on_train_batch_end: 1615758929.801921s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.7148 - accuracy: 0.0724
on_train_batch_begin: 1615758929.802239s

10 step training time: 0.329597s

on_train_batch_end: 1615758930.136073s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.6875 - accuracy: 0.0726
on_train_batch_begin: 1615758930.136361s

11 step training time: 0.334121s

on_train_batch_end: 1615758930.467000s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.6653 - accuracy: 0.0726
on_train_batch_begin: 1615758930.467293s

12 step training time: 0.330932s

on_train_batch_end: 1615758930.798481s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.6433 - accuracy: 0.0733
on_train_batch_begin: 1615758930.798770s

13 step training time: 0.331478s

on_train_batch_end: 1615758931.130097s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.6187 - accuracy: 0.0730
on_train_batch_begin: 1615758931.130386s

14 step training time: 0.331616s

on_train_batch_end: 1615758931.464007s

15360/50000 [========>.....................] - ETA: 11s - loss: 5.5904 - accuracy: 0.0727
on_train_batch_begin: 1615758931.464297s

15 step training time: 0.333911s

on_train_batch_end: 1615758931.793762s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.5682 - accuracy: 0.0723
on_train_batch_begin: 1615758931.794050s

16 step training time: 0.329753s

on_train_batch_end: 1615758932.125630s

17408/50000 [=========>....................] - ETA: 10s - loss: 5.5583 - accuracy: 0.0722
on_train_batch_begin: 1615758932.125920s

17 step training time: 0.331870s

on_train_batch_end: 1615758932.458383s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.5356 - accuracy: 0.0716
on_train_batch_begin: 1615758932.458671s

18 step training time: 0.332752s

on_train_batch_end: 1615758932.788274s

19456/50000 [==========>...................] - ETA: 9s - loss: 5.5201 - accuracy: 0.0707 
on_train_batch_begin: 1615758932.788567s

19 step training time: 0.329896s

on_train_batch_end: 1615758933.123347s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.4921 - accuracy: 0.0702
on_train_batch_begin: 1615758933.123641s

20 step training time: 0.335073s

on_train_batch_end: 1615758933.460784s

21504/50000 [===========>..................] - ETA: 9s - loss: 5.4684 - accuracy: 0.0708
on_train_batch_begin: 1615758933.461081s

21 step training time: 0.337440s

on_train_batch_end: 1615758933.795008s

22528/50000 [============>.................] - ETA: 8s - loss: 5.4439 - accuracy: 0.0707
on_train_batch_begin: 1615758933.795310s

22 step training time: 0.334229s

on_train_batch_end: 1615758934.125941s

23552/50000 [=============>................] - ETA: 8s - loss: 5.4241 - accuracy: 0.0706
on_train_batch_begin: 1615758934.126241s

23 step training time: 0.330931s

on_train_batch_end: 1615758934.460731s

24576/50000 [=============>................] - ETA: 8s - loss: 5.4032 - accuracy: 0.0704
on_train_batch_begin: 1615758934.461033s

24 step training time: 0.334792s

on_train_batch_end: 1615758934.794554s

25600/50000 [==============>...............] - ETA: 7s - loss: 5.3771 - accuracy: 0.0705
on_train_batch_begin: 1615758934.794873s

25 step training time: 0.333840s

on_train_batch_end: 1615758935.126997s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.3524 - accuracy: 0.0705
on_train_batch_begin: 1615758935.127295s

26 step training time: 0.332421s

on_train_batch_end: 1615758935.460376s

27648/50000 [===============>..............] - ETA: 7s - loss: 5.3301 - accuracy: 0.0704
on_train_batch_begin: 1615758935.460670s

27 step training time: 0.333375s

on_train_batch_end: 1615758935.791658s

28672/50000 [================>.............] - ETA: 6s - loss: 5.3076 - accuracy: 0.0705
on_train_batch_begin: 1615758935.791952s

28 step training time: 0.331282s

on_train_batch_end: 1615758936.125077s

29696/50000 [================>.............] - ETA: 6s - loss: 5.2809 - accuracy: 0.0705
on_train_batch_begin: 1615758936.125371s

29 step training time: 0.333419s

on_train_batch_end: 1615758936.457077s

30720/50000 [=================>............] - ETA: 6s - loss: 5.2505 - accuracy: 0.0708
on_train_batch_begin: 1615758936.457373s

30 step training time: 0.332002s

on_train_batch_end: 1615758936.789447s

31744/50000 [==================>...........] - ETA: 5s - loss: 5.2204 - accuracy: 0.0711
on_train_batch_begin: 1615758936.789741s

31 step training time: 0.332368s

on_train_batch_end: 1615758937.124087s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.1932 - accuracy: 0.0712
on_train_batch_begin: 1615758937.124381s

32 step training time: 0.334640s

on_train_batch_end: 1615758937.459299s

33792/50000 [===================>..........] - ETA: 5s - loss: 5.1688 - accuracy: 0.0714
on_train_batch_begin: 1615758937.459589s

33 step training time: 0.335208s

on_train_batch_end: 1615758937.793450s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.1388 - accuracy: 0.0718
on_train_batch_begin: 1615758937.793752s

34 step training time: 0.334162s

on_train_batch_end: 1615758938.128163s

35840/50000 [====================>.........] - ETA: 4s - loss: 5.1041 - accuracy: 0.0723
on_train_batch_begin: 1615758938.128452s

35 step training time: 0.334700s

on_train_batch_end: 1615758938.462514s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.0743 - accuracy: 0.0728
on_train_batch_begin: 1615758938.462814s

36 step training time: 0.334362s

on_train_batch_end: 1615758938.792530s

37888/50000 [=====================>........] - ETA: 3s - loss: 5.0389 - accuracy: 0.0733
on_train_batch_begin: 1615758938.792835s

37 step training time: 0.330021s

on_train_batch_end: 1615758939.126555s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.9988 - accuracy: 0.0737
on_train_batch_begin: 1615758939.126864s

38 step training time: 0.334029s

on_train_batch_end: 1615758939.458931s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.9652 - accuracy: 0.0741
on_train_batch_begin: 1615758939.459222s

39 step training time: 0.332358s

on_train_batch_end: 1615758939.791570s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.9268 - accuracy: 0.0746
on_train_batch_begin: 1615758939.791859s

40 step training time: 0.332637s

on_train_batch_end: 1615758940.125739s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.8859 - accuracy: 0.0750
on_train_batch_begin: 1615758940.126034s

41 step training time: 0.334175s

on_train_batch_end: 1615758940.457215s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.8462 - accuracy: 0.0756
on_train_batch_begin: 1615758940.457504s

42 step training time: 0.331470s

on_train_batch_end: 1615758940.790652s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.8057 - accuracy: 0.0761
on_train_batch_begin: 1615758940.790966s

43 step training time: 0.333462s

on_train_batch_end: 1615758941.123728s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.7646 - accuracy: 0.0766
on_train_batch_begin: 1615758941.124022s

44 step training time: 0.333056s

on_train_batch_end: 1615758941.457774s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.7223 - accuracy: 0.0771
on_train_batch_begin: 1615758941.458063s

45 step training time: 0.334041s

on_train_batch_end: 1615758941.790292s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.6793 - accuracy: 0.0776
on_train_batch_begin: 1615758941.790587s

46 step training time: 0.332524s

on_train_batch_end: 1615758942.126656s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.6358 - accuracy: 0.0781
on_train_batch_begin: 1615758942.126973s

47 step training time: 0.336386s

on_train_batch_end: 1615758942.460873s

49152/50000 [============================>.] - ETA: 0s - loss: 4.5992 - accuracy: 0.0785
on_train_batch_begin: 1615758942.461165s

48 step training time: 0.334192s

on_train_batch_end: 1615758942.739578s

on_test_batch_begin: 1615758942.751200s

49 step training time: 0.290035s

on_epoch_end: 1615758943.556605s

Validation time: 0.805389s

Real time: 1615758943.556605s

Epoch time: 17.075502395629883s

50000/50000 [==============================] - 17s 342us/sample - loss: 4.5650 - accuracy: 0.0788 - val_loss: 7.2836 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615758943.556798s

Real time: 1615758943.5568044
Epoch 3/5

on_train_batch_begin: 1615758943.560132s

on_train_batch_end: 1615758943.894868s

 1024/50000 [..............................] - ETA: 16s - loss: 2.4344 - accuracy: 0.0994
on_train_batch_begin: 1615758943.895168s

1 step training time: 0.335036s

on_train_batch_end: 1615758944.228789s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.4992 - accuracy: 0.1000
on_train_batch_begin: 1615758944.229087s

2 step training time: 0.333919s

on_train_batch_end: 1615758944.565404s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.5030 - accuracy: 0.0997
on_train_batch_begin: 1615758944.565699s

3 step training time: 0.336612s

on_train_batch_end: 1615758944.898650s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.4670 - accuracy: 0.0998
on_train_batch_begin: 1615758944.898991s

4 step training time: 0.333292s

on_train_batch_end: 1615758945.234283s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.4544 - accuracy: 0.0997
on_train_batch_begin: 1615758945.234577s

5 step training time: 0.335586s

on_train_batch_end: 1615758945.566288s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.4595 - accuracy: 0.0997
on_train_batch_begin: 1615758945.566578s

6 step training time: 0.332001s

on_train_batch_end: 1615758945.902114s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.4061 - accuracy: 0.0998
on_train_batch_begin: 1615758945.902409s

7 step training time: 0.335831s

on_train_batch_end: 1615758946.235958s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.3805 - accuracy: 0.0998
on_train_batch_begin: 1615758946.236247s

8 step training time: 0.333837s

on_train_batch_end: 1615758946.572701s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.3708 - accuracy: 0.0999
on_train_batch_begin: 1615758946.572985s

9 step training time: 0.336739s

on_train_batch_end: 1615758946.904962s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.3459 - accuracy: 0.1000
on_train_batch_begin: 1615758946.905256s

10 step training time: 0.332270s

on_train_batch_end: 1615758947.240250s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.3176 - accuracy: 0.1000
on_train_batch_begin: 1615758947.240541s

11 step training time: 0.335285s

on_train_batch_end: 1615758947.574290s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.2929 - accuracy: 0.1000
on_train_batch_begin: 1615758947.574583s

12 step training time: 0.334043s

on_train_batch_end: 1615758947.910426s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.2729 - accuracy: 0.1001
on_train_batch_begin: 1615758947.910722s

13 step training time: 0.336138s

on_train_batch_end: 1615758948.243083s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.2585 - accuracy: 0.1001
on_train_batch_begin: 1615758948.243368s

14 step training time: 0.332646s

on_train_batch_end: 1615758948.577705s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.2494 - accuracy: 0.1001
on_train_batch_begin: 1615758948.578001s

15 step training time: 0.334634s

on_train_batch_end: 1615758948.911422s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.2237 - accuracy: 0.1001
on_train_batch_begin: 1615758948.911714s

16 step training time: 0.333712s

on_train_batch_end: 1615758949.246793s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.2108 - accuracy: 0.1001
on_train_batch_begin: 1615758949.247105s

17 step training time: 0.335391s

on_train_batch_end: 1615758949.581078s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.1989 - accuracy: 0.1001
on_train_batch_begin: 1615758949.581365s

18 step training time: 0.334260s

on_train_batch_end: 1615758949.917775s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.1883 - accuracy: 0.1001 
on_train_batch_begin: 1615758949.918062s

19 step training time: 0.336697s

on_train_batch_end: 1615758950.250711s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.1788 - accuracy: 0.1001
on_train_batch_begin: 1615758950.251024s

20 step training time: 0.332963s

on_train_batch_end: 1615758950.586190s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.1778 - accuracy: 0.1001
on_train_batch_begin: 1615758950.586483s

21 step training time: 0.335459s

on_train_batch_end: 1615758950.919310s

22528/50000 [============>.................] - ETA: 8s - loss: 2.1696 - accuracy: 0.1001
on_train_batch_begin: 1615758950.919598s

22 step training time: 0.333115s

on_train_batch_end: 1615758951.255335s

23552/50000 [=============>................] - ETA: 8s - loss: 2.1697 - accuracy: 0.1001
on_train_batch_begin: 1615758951.255633s

23 step training time: 0.336036s

on_train_batch_end: 1615758951.588344s

24576/50000 [=============>................] - ETA: 8s - loss: 2.1626 - accuracy: 0.1002
on_train_batch_begin: 1615758951.588631s

24 step training time: 0.332998s

on_train_batch_end: 1615758951.925444s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.1571 - accuracy: 0.1002
on_train_batch_begin: 1615758951.925735s

25 step training time: 0.337104s

on_train_batch_end: 1615758952.261200s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.1488 - accuracy: 0.1002
on_train_batch_begin: 1615758952.261495s

26 step training time: 0.335760s

on_train_batch_end: 1615758952.598522s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.1404 - accuracy: 0.1002
on_train_batch_begin: 1615758952.598819s

27 step training time: 0.337324s

on_train_batch_end: 1615758952.935373s

28672/50000 [================>.............] - ETA: 6s - loss: 2.1240 - accuracy: 0.1002
on_train_batch_begin: 1615758952.935668s

28 step training time: 0.336849s

on_train_batch_end: 1615758953.270688s

29696/50000 [================>.............] - ETA: 6s - loss: 2.1198 - accuracy: 0.1002
on_train_batch_begin: 1615758953.271020s

29 step training time: 0.335352s

on_train_batch_end: 1615758953.608251s

30720/50000 [=================>............] - ETA: 6s - loss: 2.1122 - accuracy: 0.1002
on_train_batch_begin: 1615758953.608543s

30 step training time: 0.337523s

on_train_batch_end: 1615758953.941406s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.1079 - accuracy: 0.1002
on_train_batch_begin: 1615758953.941700s

31 step training time: 0.333157s

on_train_batch_end: 1615758954.278959s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.1046 - accuracy: 0.1002
on_train_batch_begin: 1615758954.279251s

32 step training time: 0.337551s

on_train_batch_end: 1615758954.612804s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.1040 - accuracy: 0.1002
on_train_batch_begin: 1615758954.613094s

33 step training time: 0.333843s

on_train_batch_end: 1615758954.949742s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.0957 - accuracy: 0.1002
on_train_batch_begin: 1615758954.950034s

34 step training time: 0.336940s

on_train_batch_end: 1615758955.276013s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.0889 - accuracy: 0.1002
on_train_batch_begin: 1615758955.276309s

35 step training time: 0.326274s

on_train_batch_end: 1615758955.609639s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.0840 - accuracy: 0.1002
on_train_batch_begin: 1615758955.609932s

36 step training time: 0.333623s

on_train_batch_end: 1615758955.946659s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.0742 - accuracy: 0.1002
on_train_batch_begin: 1615758955.946977s

37 step training time: 0.337045s

on_train_batch_end: 1615758956.278776s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.0738 - accuracy: 0.1002
on_train_batch_begin: 1615758956.279091s

38 step training time: 0.332114s

on_train_batch_end: 1615758956.616902s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.0686 - accuracy: 0.1002
on_train_batch_begin: 1615758956.617200s

39 step training time: 0.338109s

on_train_batch_end: 1615758956.949300s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.0613 - accuracy: 0.1002
on_train_batch_begin: 1615758956.949586s

40 step training time: 0.332387s

on_train_batch_end: 1615758957.286543s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.0579 - accuracy: 0.1002
on_train_batch_begin: 1615758957.286834s

41 step training time: 0.337247s

on_train_batch_end: 1615758957.621267s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.0511 - accuracy: 0.1002
on_train_batch_begin: 1615758957.621557s

42 step training time: 0.334724s

on_train_batch_end: 1615758957.958107s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.0470 - accuracy: 0.1002
on_train_batch_begin: 1615758957.958395s

43 step training time: 0.336838s

on_train_batch_end: 1615758958.294242s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.0457 - accuracy: 0.1002
on_train_batch_begin: 1615758958.294534s

44 step training time: 0.336138s

on_train_batch_end: 1615758958.629990s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.0381 - accuracy: 0.1002
on_train_batch_begin: 1615758958.630284s

45 step training time: 0.335751s

on_train_batch_end: 1615758958.967068s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.0323 - accuracy: 0.1002
on_train_batch_begin: 1615758958.967361s

46 step training time: 0.337077s

on_train_batch_end: 1615758959.302206s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.0294 - accuracy: 0.1002
on_train_batch_begin: 1615758959.302496s

47 step training time: 0.335135s

on_train_batch_end: 1615758959.639188s

49152/50000 [============================>.] - ETA: 0s - loss: 2.0215 - accuracy: 0.1002
on_train_batch_begin: 1615758959.639477s

48 step training time: 0.336981s

on_train_batch_end: 1615758959.915960s

on_test_batch_begin: 1615758959.927313s

49 step training time: 0.287836s

on_epoch_end: 1615758960.745707s

Validation time: 0.818383s

Real time: 1615758960.745707s

Epoch time: 17.188920497894287s

50000/50000 [==============================] - 17s 344us/sample - loss: 2.0160 - accuracy: 0.1002 - val_loss: 7.2802 - val_accuracy: 0.0999

on_epoch_begin: 1615758960.745898s

Real time: 1615758960.7459028
Epoch 4/5

on_train_batch_begin: 1615758960.749236s

on_train_batch_end: 1615758961.085651s

 1024/50000 [..............................] - ETA: 16s - loss: 1.6951 - accuracy: 0.1006
on_train_batch_begin: 1615758961.085976s

1 step training time: 0.336740s

on_train_batch_end: 1615758961.424740s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.5709 - accuracy: 0.1002
on_train_batch_begin: 1615758961.425040s

2 step training time: 0.339064s

on_train_batch_end: 1615758961.759797s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.5354 - accuracy: 0.1002
on_train_batch_begin: 1615758961.760090s

3 step training time: 0.335049s

on_train_batch_end: 1615758962.096554s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.5711 - accuracy: 0.1002
on_train_batch_begin: 1615758962.096849s

4 step training time: 0.336759s

on_train_batch_end: 1615758962.430546s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.5583 - accuracy: 0.1002
on_train_batch_begin: 1615758962.430840s

5 step training time: 0.333991s

on_train_batch_end: 1615758962.770516s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.5304 - accuracy: 0.1002
on_train_batch_begin: 1615758962.770811s

6 step training time: 0.339970s

on_train_batch_end: 1615758963.107256s

 7168/50000 [===>..........................] - ETA: 14s - loss: 1.5343 - accuracy: 0.1002
on_train_batch_begin: 1615758963.107567s

7 step training time: 0.336756s

on_train_batch_end: 1615758963.442972s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.5278 - accuracy: 0.1002
on_train_batch_begin: 1615758963.443263s

8 step training time: 0.335696s

on_train_batch_end: 1615758963.781875s

 9216/50000 [====>.........................] - ETA: 13s - loss: 1.5282 - accuracy: 0.1002
on_train_batch_begin: 1615758963.782171s

9 step training time: 0.338908s

on_train_batch_end: 1615758964.117977s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.5128 - accuracy: 0.1002
on_train_batch_begin: 1615758964.118369s

10 step training time: 0.336198s

on_train_batch_end: 1615758964.455657s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.5041 - accuracy: 0.1002
on_train_batch_begin: 1615758964.455951s

11 step training time: 0.337583s

on_train_batch_end: 1615758964.793314s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.4919 - accuracy: 0.1002
on_train_batch_begin: 1615758964.793613s

12 step training time: 0.337662s

on_train_batch_end: 1615758965.132191s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.4923 - accuracy: 0.1002
on_train_batch_begin: 1615758965.132510s

13 step training time: 0.338897s

on_train_batch_end: 1615758965.472283s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.4862 - accuracy: 0.1002
on_train_batch_begin: 1615758965.472587s

14 step training time: 0.340077s

on_train_batch_end: 1615758965.811566s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.4749 - accuracy: 0.1002
on_train_batch_begin: 1615758965.811964s

15 step training time: 0.339377s

on_train_batch_end: 1615758966.149080s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.4640 - accuracy: 0.1002
on_train_batch_begin: 1615758966.149376s

16 step training time: 0.337413s

on_train_batch_end: 1615758966.487961s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.4529 - accuracy: 0.1002
on_train_batch_begin: 1615758966.488245s

17 step training time: 0.338869s

on_train_batch_end: 1615758966.822919s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.4473 - accuracy: 0.1002
on_train_batch_begin: 1615758966.823205s

18 step training time: 0.334960s

on_train_batch_end: 1615758967.161719s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.4332 - accuracy: 0.1002
on_train_batch_begin: 1615758967.162008s

19 step training time: 0.338803s

on_train_batch_end: 1615758967.495930s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.4262 - accuracy: 0.1002 
on_train_batch_begin: 1615758967.496218s

20 step training time: 0.334211s

on_train_batch_end: 1615758967.834951s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.4224 - accuracy: 0.1002
on_train_batch_begin: 1615758967.835238s

21 step training time: 0.339020s

on_train_batch_end: 1615758968.173391s

22528/50000 [============>.................] - ETA: 9s - loss: 1.4165 - accuracy: 0.1002
on_train_batch_begin: 1615758968.173693s

22 step training time: 0.338454s

on_train_batch_end: 1615758968.510588s

23552/50000 [=============>................] - ETA: 8s - loss: 1.4151 - accuracy: 0.1002
on_train_batch_begin: 1615758968.510904s

23 step training time: 0.337211s

on_train_batch_end: 1615758968.849301s

24576/50000 [=============>................] - ETA: 8s - loss: 1.4122 - accuracy: 0.1002
on_train_batch_begin: 1615758968.849598s

24 step training time: 0.338694s

on_train_batch_end: 1615758969.186932s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.4080 - accuracy: 0.1002
on_train_batch_begin: 1615758969.187227s

25 step training time: 0.337629s

on_train_batch_end: 1615758969.523739s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.4002 - accuracy: 0.1002
on_train_batch_begin: 1615758969.524033s

26 step training time: 0.336807s

on_train_batch_end: 1615758969.863365s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.3945 - accuracy: 0.1002
on_train_batch_begin: 1615758969.863664s

27 step training time: 0.339631s

on_train_batch_end: 1615758970.199415s

28672/50000 [================>.............] - ETA: 7s - loss: 1.3932 - accuracy: 0.1002
on_train_batch_begin: 1615758970.199702s

28 step training time: 0.336038s

on_train_batch_end: 1615758970.537716s

29696/50000 [================>.............] - ETA: 6s - loss: 1.3920 - accuracy: 0.1002
on_train_batch_begin: 1615758970.538014s

29 step training time: 0.338312s

on_train_batch_end: 1615758970.878058s

30720/50000 [=================>............] - ETA: 6s - loss: 1.3878 - accuracy: 0.1002
on_train_batch_begin: 1615758970.878351s

30 step training time: 0.340338s

on_train_batch_end: 1615758971.215667s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.3820 - accuracy: 0.1002
on_train_batch_begin: 1615758971.215960s

31 step training time: 0.337609s

on_train_batch_end: 1615758971.555013s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.3761 - accuracy: 0.1002
on_train_batch_begin: 1615758971.555315s

32 step training time: 0.339355s

on_train_batch_end: 1615758971.895344s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.3721 - accuracy: 0.1002
on_train_batch_begin: 1615758971.895632s

33 step training time: 0.340317s

on_train_batch_end: 1615758972.234208s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.3671 - accuracy: 0.1002
on_train_batch_begin: 1615758972.234499s

34 step training time: 0.338866s

on_train_batch_end: 1615758972.571818s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.3626 - accuracy: 0.1002
on_train_batch_begin: 1615758972.572105s

35 step training time: 0.337606s

on_train_batch_end: 1615758972.912316s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.3564 - accuracy: 0.1002
on_train_batch_begin: 1615758972.912617s

36 step training time: 0.340512s

on_train_batch_end: 1615758973.251064s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.3529 - accuracy: 0.1002
on_train_batch_begin: 1615758973.251348s

37 step training time: 0.338731s

on_train_batch_end: 1615758973.587890s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.3460 - accuracy: 0.1002
on_train_batch_begin: 1615758973.588177s

38 step training time: 0.336829s

on_train_batch_end: 1615758973.929149s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.3427 - accuracy: 0.1002
on_train_batch_begin: 1615758973.929438s

39 step training time: 0.341261s

on_train_batch_end: 1615758974.268334s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.3390 - accuracy: 0.1002
on_train_batch_begin: 1615758974.268622s

40 step training time: 0.339185s

on_train_batch_end: 1615758974.604315s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.3332 - accuracy: 0.1002
on_train_batch_begin: 1615758974.604616s

41 step training time: 0.335994s

on_train_batch_end: 1615758974.945606s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.3280 - accuracy: 0.1002
on_train_batch_begin: 1615758974.945896s

42 step training time: 0.341280s

on_train_batch_end: 1615758975.283853s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.3228 - accuracy: 0.1002
on_train_batch_begin: 1615758975.284143s

43 step training time: 0.338247s

on_train_batch_end: 1615758975.622610s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.3213 - accuracy: 0.1002
on_train_batch_begin: 1615758975.622917s

44 step training time: 0.338774s

on_train_batch_end: 1615758975.963865s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.3188 - accuracy: 0.1002
on_train_batch_begin: 1615758975.964154s

45 step training time: 0.341237s

on_train_batch_end: 1615758976.302454s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.3169 - accuracy: 0.1003
on_train_batch_begin: 1615758976.302762s

46 step training time: 0.338609s

on_train_batch_end: 1615758976.641568s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.3125 - accuracy: 0.1003
on_train_batch_begin: 1615758976.641863s

47 step training time: 0.339101s

on_train_batch_end: 1615758976.980177s

49152/50000 [============================>.] - ETA: 0s - loss: 1.3081 - accuracy: 0.1003
on_train_batch_begin: 1615758976.980473s

48 step training time: 0.338610s

on_train_batch_end: 1615758977.263413s

on_test_batch_begin: 1615758977.273681s

49 step training time: 0.293208s

on_epoch_end: 1615758978.090044s

Validation time: 0.816348s

Real time: 1615758978.090044s

Epoch time: 17.344156742095947s

50000/50000 [==============================] - 17s 347us/sample - loss: 1.3038 - accuracy: 0.1003 - val_loss: 7.0732 - val_accuracy: 0.0999

on_epoch_begin: 1615758978.090236s

Real time: 1615758978.090241
Epoch 5/5

on_train_batch_begin: 1615758978.093634s

on_train_batch_end: 1615758978.431847s

 1024/50000 [..............................] - ETA: 16s - loss: 0.9087 - accuracy: 0.1003
on_train_batch_begin: 1615758978.432141s

1 step training time: 0.338507s

on_train_batch_end: 1615758978.771599s

 2048/50000 [>.............................] - ETA: 15s - loss: 0.9389 - accuracy: 0.1002
on_train_batch_begin: 1615758978.771888s

2 step training time: 0.339746s

on_train_batch_end: 1615758979.113702s

 3072/50000 [>.............................] - ETA: 15s - loss: 0.9318 - accuracy: 0.1002
on_train_batch_begin: 1615758979.113994s

3 step training time: 0.342106s

on_train_batch_end: 1615758979.453873s

 4096/50000 [=>............................] - ETA: 15s - loss: 0.9693 - accuracy: 0.1002
on_train_batch_begin: 1615758979.454163s

4 step training time: 0.340169s

on_train_batch_end: 1615758979.793663s

 5120/50000 [==>...........................] - ETA: 14s - loss: 0.9559 - accuracy: 0.1002
on_train_batch_begin: 1615758979.793955s

5 step training time: 0.339792s

on_train_batch_end: 1615758980.131663s

 6144/50000 [==>...........................] - ETA: 14s - loss: 0.9315 - accuracy: 0.1002
on_train_batch_begin: 1615758980.131952s

6 step training time: 0.337996s

on_train_batch_end: 1615758980.473648s

 7168/50000 [===>..........................] - ETA: 14s - loss: 0.9249 - accuracy: 0.1002
on_train_batch_begin: 1615758980.473935s

7 step training time: 0.341984s

on_train_batch_end: 1615758980.812356s

 8192/50000 [===>..........................] - ETA: 13s - loss: 0.9340 - accuracy: 0.1002
on_train_batch_begin: 1615758980.812658s

8 step training time: 0.338723s

on_train_batch_end: 1615758981.150464s

 9216/50000 [====>.........................] - ETA: 13s - loss: 0.9254 - accuracy: 0.1002
on_train_batch_begin: 1615758981.150756s

9 step training time: 0.338098s

on_train_batch_end: 1615758981.489166s

10240/50000 [=====>........................] - ETA: 13s - loss: 0.9310 - accuracy: 0.1002
on_train_batch_begin: 1615758981.489456s

10 step training time: 0.338700s

on_train_batch_end: 1615758981.831072s

11264/50000 [=====>........................] - ETA: 12s - loss: 0.9365 - accuracy: 0.1002
on_train_batch_begin: 1615758981.831369s

11 step training time: 0.341914s

on_train_batch_end: 1615758982.170399s

12288/50000 [======>.......................] - ETA: 12s - loss: 0.9272 - accuracy: 0.1002
on_train_batch_begin: 1615758982.170689s

12 step training time: 0.339320s

on_train_batch_end: 1615758982.508050s

13312/50000 [======>.......................] - ETA: 12s - loss: 0.9197 - accuracy: 0.1002
on_train_batch_begin: 1615758982.508337s

13 step training time: 0.337647s

on_train_batch_end: 1615758982.848359s

14336/50000 [=======>......................] - ETA: 11s - loss: 0.9157 - accuracy: 0.1002
on_train_batch_begin: 1615758982.848646s

14 step training time: 0.340309s

on_train_batch_end: 1615758983.189223s

15360/50000 [========>.....................] - ETA: 11s - loss: 0.9157 - accuracy: 0.1002
on_train_batch_begin: 1615758983.189510s

15 step training time: 0.340865s

on_train_batch_end: 1615758983.528113s

16384/50000 [========>.....................] - ETA: 11s - loss: 0.9136 - accuracy: 0.1002
on_train_batch_begin: 1615758983.528395s

16 step training time: 0.338884s

on_train_batch_end: 1615758983.866042s

17408/50000 [=========>....................] - ETA: 10s - loss: 0.9165 - accuracy: 0.1002
on_train_batch_begin: 1615758983.866329s

17 step training time: 0.337935s

on_train_batch_end: 1615758984.205433s

18432/50000 [==========>...................] - ETA: 10s - loss: 0.9117 - accuracy: 0.1002
on_train_batch_begin: 1615758984.205721s

18 step training time: 0.339392s

on_train_batch_end: 1615758984.546599s

19456/50000 [==========>...................] - ETA: 10s - loss: 0.9111 - accuracy: 0.1002
on_train_batch_begin: 1615758984.546901s

19 step training time: 0.341180s

on_train_batch_end: 1615758984.885988s

20480/50000 [===========>..................] - ETA: 9s - loss: 0.9090 - accuracy: 0.1002 
on_train_batch_begin: 1615758984.886282s

20 step training time: 0.339381s

on_train_batch_end: 1615758985.224454s

21504/50000 [===========>..................] - ETA: 9s - loss: 0.9103 - accuracy: 0.1002
on_train_batch_begin: 1615758985.224744s

21 step training time: 0.338462s

on_train_batch_end: 1615758985.565762s

22528/50000 [============>.................] - ETA: 9s - loss: 0.9089 - accuracy: 0.1002
on_train_batch_begin: 1615758985.566049s

22 step training time: 0.341305s

on_train_batch_end: 1615758985.906890s

23552/50000 [=============>................] - ETA: 8s - loss: 0.9120 - accuracy: 0.1002
on_train_batch_begin: 1615758985.907184s

23 step training time: 0.341135s

on_train_batch_end: 1615758986.246389s

24576/50000 [=============>................] - ETA: 8s - loss: 0.9101 - accuracy: 0.1002
on_train_batch_begin: 1615758986.246689s

24 step training time: 0.339505s

on_train_batch_end: 1615758986.584625s

25600/50000 [==============>...............] - ETA: 8s - loss: 0.9082 - accuracy: 0.1002
on_train_batch_begin: 1615758986.584918s

25 step training time: 0.338229s

on_train_batch_end: 1615758986.942125s

26624/50000 [==============>...............] - ETA: 7s - loss: 0.9061 - accuracy: 0.1002
on_train_batch_begin: 1615758986.942418s

26 step training time: 0.357500s

on_train_batch_end: 1615758987.284868s

27648/50000 [===============>..............] - ETA: 7s - loss: 0.9045 - accuracy: 0.1002
on_train_batch_begin: 1615758987.285167s

27 step training time: 0.342749s

on_train_batch_end: 1615758987.622018s

28672/50000 [================>.............] - ETA: 7s - loss: 0.9068 - accuracy: 0.1003
on_train_batch_begin: 1615758987.622312s

28 step training time: 0.337144s

on_train_batch_end: 1615758987.964156s

29696/50000 [================>.............] - ETA: 6s - loss: 0.9067 - accuracy: 0.1003
on_train_batch_begin: 1615758987.964453s

29 step training time: 0.342142s

on_train_batch_end: 1615758988.304296s

30720/50000 [=================>............] - ETA: 6s - loss: 0.9039 - accuracy: 0.1003
on_train_batch_begin: 1615758988.304588s

30 step training time: 0.340134s

on_train_batch_end: 1615758988.646619s

31744/50000 [==================>...........] - ETA: 6s - loss: 0.9026 - accuracy: 0.1003
on_train_batch_begin: 1615758988.646926s

31 step training time: 0.342339s

on_train_batch_end: 1615758988.988666s

32768/50000 [==================>...........] - ETA: 5s - loss: 0.9002 - accuracy: 0.1003
on_train_batch_begin: 1615758988.988959s

32 step training time: 0.342033s

on_train_batch_end: 1615758989.327037s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.8983 - accuracy: 0.1003
on_train_batch_begin: 1615758989.327328s

33 step training time: 0.338369s

on_train_batch_end: 1615758989.666930s

34816/50000 [===================>..........] - ETA: 5s - loss: 0.8996 - accuracy: 0.1003
on_train_batch_begin: 1615758989.667225s

34 step training time: 0.339897s

on_train_batch_end: 1615758990.008112s

35840/50000 [====================>.........] - ETA: 4s - loss: 0.8938 - accuracy: 0.1003
on_train_batch_begin: 1615758990.008402s

35 step training time: 0.341177s

on_train_batch_end: 1615758990.348816s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.8913 - accuracy: 0.1003
on_train_batch_begin: 1615758990.349107s

36 step training time: 0.340705s

on_train_batch_end: 1615758990.688319s

37888/50000 [=====================>........] - ETA: 4s - loss: 0.8904 - accuracy: 0.1003
on_train_batch_begin: 1615758990.688607s

37 step training time: 0.339500s

on_train_batch_end: 1615758991.025533s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.8920 - accuracy: 0.1003
on_train_batch_begin: 1615758991.025825s

38 step training time: 0.337217s

on_train_batch_end: 1615758991.368012s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.8915 - accuracy: 0.1003
on_train_batch_begin: 1615758991.368300s

39 step training time: 0.342476s

on_train_batch_end: 1615758991.707884s

40960/50000 [=======================>......] - ETA: 3s - loss: 0.8908 - accuracy: 0.1003
on_train_batch_begin: 1615758991.708174s

40 step training time: 0.339874s

on_train_batch_end: 1615758992.048176s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.8905 - accuracy: 0.1003
on_train_batch_begin: 1615758992.048460s

41 step training time: 0.340286s

on_train_batch_end: 1615758992.388378s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.8898 - accuracy: 0.1003
on_train_batch_begin: 1615758992.388664s

42 step training time: 0.340204s

on_train_batch_end: 1615758992.730048s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.8867 - accuracy: 0.1003
on_train_batch_begin: 1615758992.730336s

43 step training time: 0.341672s

on_train_batch_end: 1615758993.071028s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.8861 - accuracy: 0.1003
on_train_batch_begin: 1615758993.071328s

44 step training time: 0.340991s

on_train_batch_end: 1615758993.413255s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.8847 - accuracy: 0.1003
on_train_batch_begin: 1615758993.413550s

45 step training time: 0.342223s

on_train_batch_end: 1615758993.751740s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.8825 - accuracy: 0.1003
on_train_batch_begin: 1615758993.752029s

46 step training time: 0.338479s

on_train_batch_end: 1615758994.093866s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.8789 - accuracy: 0.1003
on_train_batch_begin: 1615758994.094167s

47 step training time: 0.342138s

on_train_batch_end: 1615758994.433336s

49152/50000 [============================>.] - ETA: 0s - loss: 0.8786 - accuracy: 0.1003
on_train_batch_begin: 1615758994.433626s

48 step training time: 0.339459s

on_train_batch_end: 1615758994.717793s

on_test_batch_begin: 1615758994.729324s

49 step training time: 0.295698s

on_epoch_end: 1615758995.559004s

Validation time: 0.829667s

Real time: 1615758995.559004s

Epoch time: 17.468780755996704s

50000/50000 [==============================] - 17s 349us/sample - loss: 0.8778 - accuracy: 0.1003 - val_loss: 7.0975 - val_accuracy: 0.0999
Tempo do fit: 116.66626167297363