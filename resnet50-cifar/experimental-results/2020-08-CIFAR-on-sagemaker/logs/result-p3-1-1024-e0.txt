wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:43
   204800/170498071 [..............................] - ETA: 1:17
  1187840/170498071 [..............................] - ETA: 20s 
  3481600/170498071 [..............................] - ETA: 9s 
  6864896/170498071 [>.............................] - ETA: 5s
 10215424/170498071 [>.............................] - ETA: 4s
 13582336/170498071 [=>............................] - ETA: 3s
 16908288/170498071 [=>............................] - ETA: 3s
 20029440/170498071 [==>...........................] - ETA: 3s
 23158784/170498071 [===>..........................] - ETA: 3s
 26370048/170498071 [===>..........................] - ETA: 2s
 29646848/170498071 [====>.........................] - ETA: 2s
 32989184/170498071 [====>.........................] - ETA: 2s
 36347904/170498071 [=====>........................] - ETA: 2s
 39698432/170498071 [=====>........................] - ETA: 2s
 43065344/170498071 [======>.......................] - ETA: 2s
 46399488/170498071 [=======>......................] - ETA: 2s
 49766400/170498071 [=======>......................] - ETA: 2s
 52961280/170498071 [========>.....................] - ETA: 2s
 56156160/170498071 [========>.....................] - ETA: 2s
 59383808/170498071 [=========>....................] - ETA: 1s
 62742528/170498071 [==========>...................] - ETA: 1s
 66052096/170498071 [==========>...................] - ETA: 1s
 69410816/170498071 [===========>..................] - ETA: 1s
 72720384/170498071 [===========>..................] - ETA: 1s
 76070912/170498071 [============>.................] - ETA: 1s
 79437824/170498071 [============>.................] - ETA: 1s
 82780160/170498071 [=============>................] - ETA: 1s
 85958656/170498071 [==============>...............] - ETA: 1s
 89186304/170498071 [==============>...............] - ETA: 1s
 92471296/170498071 [===============>..............] - ETA: 1s
 95830016/170498071 [===============>..............] - ETA: 1s
 99147776/170498071 [================>.............] - ETA: 1s
102481920/170498071 [=================>............] - ETA: 1s
105807872/170498071 [=================>............] - ETA: 1s
109117440/170498071 [==================>...........] - ETA: 1s
112484352/170498071 [==================>...........] - ETA: 0s
115695616/170498071 [===================>..........] - ETA: 0s
118874112/170498071 [===================>..........] - ETA: 0s
122134528/170498071 [====================>.........] - ETA: 0s
125493248/170498071 [=====================>........] - ETA: 0s
128835584/170498071 [=====================>........] - ETA: 0s
132177920/170498071 [======================>.......] - ETA: 0s
135487488/170498071 [======================>.......] - ETA: 0s
138878976/170498071 [=======================>......] - ETA: 0s
142163968/170498071 [========================>.....] - ETA: 0s
145547264/170498071 [========================>.....] - ETA: 0s
148692992/170498071 [=========================>....] - ETA: 0s
151937024/170498071 [=========================>....] - ETA: 0s
155246592/170498071 [==========================>...] - ETA: 0s
158621696/170498071 [==========================>...] - ETA: 0s
161980416/170498071 [===========================>..] - ETA: 0s
165339136/170498071 [============================>.] - ETA: 0s
168697856/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 6s
 5496832/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
16302080/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 1s
26198016/94765736 [=======>......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 1s
35356672/94765736 [==========>...................] - ETA: 0s
41639936/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
53870592/94765736 [================>.............] - ETA: 0s
59514880/94765736 [=================>............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
72400896/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
76619776/94765736 [=======================>......] - ETA: 0s
83255296/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
90128384/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.975983619689941
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1597963468.999836s

Real time: 1597963468.9998565
Epoch 1/5

on_train_batch_begin: 1597963469.819102s

on_train_batch_end: 1597963484.830764s

 1024/50000 [..............................] - ETA: 12:37 - loss: 17.9072 - accuracy: 3.8528e-04
on_train_batch_begin: 1597963484.831452s

1 step training time: 15.012350s

on_train_batch_end: 1597963484.947364s

 2048/50000 [>.............................] - ETA: 6:13 - loss: 15.1664 - accuracy: 3.2759e-04 
on_train_batch_begin: 1597963484.947762s

2 step training time: 0.116310s

on_train_batch_end: 1597963485.062912s

 3072/50000 [>.............................] - ETA: 4:05 - loss: 13.0752 - accuracy: 5.6140e-04
on_train_batch_begin: 1597963485.063291s

3 step training time: 0.115529s

on_train_batch_end: 1597963485.178150s

 4096/50000 [=>............................] - ETA: 3:01 - loss: 11.8778 - accuracy: 0.0011    
on_train_batch_begin: 1597963485.178513s

4 step training time: 0.115222s

on_train_batch_end: 1597963485.295402s

 5120/50000 [==>...........................] - ETA: 2:22 - loss: 11.1004 - accuracy: 0.0026
on_train_batch_begin: 1597963485.295784s

5 step training time: 0.117271s

on_train_batch_end: 1597963485.410540s

 6144/50000 [==>...........................] - ETA: 1:57 - loss: 10.5980 - accuracy: 0.0055
on_train_batch_begin: 1597963485.410902s

6 step training time: 0.115118s

on_train_batch_end: 1597963485.526323s

 7168/50000 [===>..........................] - ETA: 1:38 - loss: 10.2120 - accuracy: 0.0087
on_train_batch_begin: 1597963485.526713s

7 step training time: 0.115811s

on_train_batch_end: 1597963485.641398s

 8192/50000 [===>..........................] - ETA: 1:24 - loss: 9.9347 - accuracy: 0.0136 
on_train_batch_begin: 1597963485.641766s

8 step training time: 0.115053s

on_train_batch_end: 1597963485.757047s

 9216/50000 [====>.........................] - ETA: 1:14 - loss: 9.6980 - accuracy: 0.0186
on_train_batch_begin: 1597963485.757417s

9 step training time: 0.115651s

on_train_batch_end: 1597963485.872385s

10240/50000 [=====>........................] - ETA: 1:05 - loss: 9.4979 - accuracy: 0.0218
on_train_batch_begin: 1597963485.872820s

10 step training time: 0.115403s

on_train_batch_end: 1597963485.987295s

11264/50000 [=====>........................] - ETA: 58s - loss: 9.3153 - accuracy: 0.0247 
on_train_batch_begin: 1597963485.987676s

11 step training time: 0.114856s

on_train_batch_end: 1597963486.102526s

12288/50000 [======>.......................] - ETA: 52s - loss: 9.1637 - accuracy: 0.0278
on_train_batch_begin: 1597963486.102907s

12 step training time: 0.115231s

on_train_batch_end: 1597963486.217625s

13312/50000 [======>.......................] - ETA: 47s - loss: 9.0273 - accuracy: 0.0312
on_train_batch_begin: 1597963486.217990s

13 step training time: 0.115083s

on_train_batch_end: 1597963486.332738s

14336/50000 [=======>......................] - ETA: 43s - loss: 8.9027 - accuracy: 0.0340
on_train_batch_begin: 1597963486.333127s

14 step training time: 0.115137s

on_train_batch_end: 1597963486.447870s

15360/50000 [========>.....................] - ETA: 39s - loss: 8.8012 - accuracy: 0.0375
on_train_batch_begin: 1597963486.448242s

15 step training time: 0.115115s

on_train_batch_end: 1597963486.562749s

16384/50000 [========>.....................] - ETA: 36s - loss: 8.7096 - accuracy: 0.0402
on_train_batch_begin: 1597963486.563109s

16 step training time: 0.114866s

on_train_batch_end: 1597963486.677608s

17408/50000 [=========>....................] - ETA: 33s - loss: 8.6154 - accuracy: 0.0432
on_train_batch_begin: 1597963486.677979s

17 step training time: 0.114871s

on_train_batch_end: 1597963486.792679s

18432/50000 [==========>...................] - ETA: 30s - loss: 8.5366 - accuracy: 0.0451
on_train_batch_begin: 1597963486.793077s

18 step training time: 0.115098s

on_train_batch_end: 1597963486.907957s

19456/50000 [==========>...................] - ETA: 28s - loss: 8.4680 - accuracy: 0.0470
on_train_batch_begin: 1597963486.908334s

19 step training time: 0.115256s

on_train_batch_end: 1597963487.022929s

20480/50000 [===========>..................] - ETA: 25s - loss: 8.4070 - accuracy: 0.0481
on_train_batch_begin: 1597963487.023292s

20 step training time: 0.114959s

on_train_batch_end: 1597963487.138547s

21504/50000 [===========>..................] - ETA: 24s - loss: 8.3487 - accuracy: 0.0492
on_train_batch_begin: 1597963487.139102s

21 step training time: 0.115810s

on_train_batch_end: 1597963487.254492s

22528/50000 [============>.................] - ETA: 22s - loss: 8.2892 - accuracy: 0.0506
on_train_batch_begin: 1597963487.254855s

22 step training time: 0.115753s

on_train_batch_end: 1597963487.369203s

23552/50000 [=============>................] - ETA: 20s - loss: 8.2335 - accuracy: 0.0520
on_train_batch_begin: 1597963487.369579s

23 step training time: 0.114724s

on_train_batch_end: 1597963487.484474s

24576/50000 [=============>................] - ETA: 19s - loss: 8.1751 - accuracy: 0.0535
on_train_batch_begin: 1597963487.484841s

24 step training time: 0.115262s

on_train_batch_end: 1597963487.599240s

25600/50000 [==============>...............] - ETA: 17s - loss: 8.1208 - accuracy: 0.0549
on_train_batch_begin: 1597963487.599593s

25 step training time: 0.114752s

on_train_batch_end: 1597963487.714399s

26624/50000 [==============>...............] - ETA: 16s - loss: 8.0719 - accuracy: 0.0562
on_train_batch_begin: 1597963487.714765s

26 step training time: 0.115171s

on_train_batch_end: 1597963487.829739s

27648/50000 [===============>..............] - ETA: 15s - loss: 8.0295 - accuracy: 0.0575
on_train_batch_begin: 1597963487.830099s

27 step training time: 0.115334s

on_train_batch_end: 1597963487.945485s

28672/50000 [================>.............] - ETA: 14s - loss: 7.9847 - accuracy: 0.0586
on_train_batch_begin: 1597963487.945968s

28 step training time: 0.115869s

on_train_batch_end: 1597963488.063369s

29696/50000 [================>.............] - ETA: 13s - loss: 7.9373 - accuracy: 0.0600
on_train_batch_begin: 1597963488.063745s

29 step training time: 0.117777s

on_train_batch_end: 1597963488.180053s

30720/50000 [=================>............] - ETA: 12s - loss: 7.8958 - accuracy: 0.0609
on_train_batch_begin: 1597963488.180414s

30 step training time: 0.116669s

on_train_batch_end: 1597963488.295067s

31744/50000 [==================>...........] - ETA: 11s - loss: 7.8506 - accuracy: 0.0622
on_train_batch_begin: 1597963488.295438s

31 step training time: 0.115024s

on_train_batch_end: 1597963488.410915s

32768/50000 [==================>...........] - ETA: 10s - loss: 7.8066 - accuracy: 0.0630
on_train_batch_begin: 1597963488.411284s

32 step training time: 0.115846s

on_train_batch_end: 1597963488.525981s

33792/50000 [===================>..........] - ETA: 9s - loss: 7.7622 - accuracy: 0.0638 
on_train_batch_begin: 1597963488.526351s

33 step training time: 0.115067s

on_train_batch_end: 1597963488.641445s

34816/50000 [===================>..........] - ETA: 8s - loss: 7.7163 - accuracy: 0.0647
on_train_batch_begin: 1597963488.641818s

34 step training time: 0.115468s

on_train_batch_end: 1597963488.757602s

35840/50000 [====================>.........] - ETA: 7s - loss: 7.6742 - accuracy: 0.0655
on_train_batch_begin: 1597963488.757973s

35 step training time: 0.116155s

on_train_batch_end: 1597963488.874130s

36864/50000 [=====================>........] - ETA: 7s - loss: 7.6349 - accuracy: 0.0662
on_train_batch_begin: 1597963488.874494s

36 step training time: 0.116521s

on_train_batch_end: 1597963488.989599s

37888/50000 [=====================>........] - ETA: 6s - loss: 7.5938 - accuracy: 0.0667
on_train_batch_begin: 1597963488.989962s

37 step training time: 0.115468s

on_train_batch_end: 1597963489.104505s

38912/50000 [======================>.......] - ETA: 5s - loss: 7.5561 - accuracy: 0.0672
on_train_batch_begin: 1597963489.104882s

38 step training time: 0.114919s

on_train_batch_end: 1597963489.219465s

39936/50000 [======================>.......] - ETA: 5s - loss: 7.5196 - accuracy: 0.0673
on_train_batch_begin: 1597963489.219857s

39 step training time: 0.114976s

on_train_batch_end: 1597963489.334553s

40960/50000 [=======================>......] - ETA: 4s - loss: 7.4803 - accuracy: 0.0677
on_train_batch_begin: 1597963489.334923s

40 step training time: 0.115066s

on_train_batch_end: 1597963489.449126s

41984/50000 [========================>.....] - ETA: 3s - loss: 7.4448 - accuracy: 0.0678
on_train_batch_begin: 1597963489.449494s

41 step training time: 0.114571s

on_train_batch_end: 1597963489.564273s

43008/50000 [========================>.....] - ETA: 3s - loss: 7.4086 - accuracy: 0.0680
on_train_batch_begin: 1597963489.564663s

42 step training time: 0.115169s

on_train_batch_end: 1597963489.679452s

44032/50000 [=========================>....] - ETA: 2s - loss: 7.3716 - accuracy: 0.0681
on_train_batch_begin: 1597963489.679816s

43 step training time: 0.115153s

on_train_batch_end: 1597963489.794526s

45056/50000 [==========================>...] - ETA: 2s - loss: 7.3382 - accuracy: 0.0682
on_train_batch_begin: 1597963489.794896s

44 step training time: 0.115080s

on_train_batch_end: 1597963489.909643s

46080/50000 [==========================>...] - ETA: 1s - loss: 7.3054 - accuracy: 0.0683
on_train_batch_begin: 1597963489.910047s

45 step training time: 0.115151s

on_train_batch_end: 1597963490.024942s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.2713 - accuracy: 0.0686
on_train_batch_begin: 1597963490.025336s

46 step training time: 0.115289s

on_train_batch_end: 1597963490.140756s

48128/50000 [===========================>..] - ETA: 0s - loss: 7.2356 - accuracy: 0.0691
on_train_batch_begin: 1597963490.141148s

47 step training time: 0.115812s

on_train_batch_end: 1597963490.254930s

49152/50000 [============================>.] - ETA: 0s - loss: 7.2032 - accuracy: 0.0694
on_train_batch_begin: 1597963490.255289s

48 step training time: 0.114141s

on_train_batch_end: 1597963492.104433s

on_test_batch_begin: 1597963492.311817s

49 step training time: 2.056528s

on_epoch_end: 1597963495.609849s

Validation time: 3.298013s

Real time: 1597963495.609849s

Epoch time: 26.610013246536255s

50000/50000 [==============================] - 27s 532us/sample - loss: 7.1752 - accuracy: 0.0695 - val_loss: 314.6109 - val_accuracy: 0.0000e+00

on_epoch_begin: 1597963495.610110s

Real time: 1597963495.6101193
Epoch 2/5

on_train_batch_begin: 1597963495.614342s

on_train_batch_end: 1597963495.729080s

 1024/50000 [..............................] - ETA: 5s - loss: 5.5381 - accuracy: 0.0830
on_train_batch_begin: 1597963495.729453s

1 step training time: 0.115111s

on_train_batch_end: 1597963495.844985s

 2048/50000 [>.............................] - ETA: 5s - loss: 5.5900 - accuracy: 0.0796
on_train_batch_begin: 1597963495.845351s

2 step training time: 0.115898s

on_train_batch_end: 1597963495.959765s

 3072/50000 [>.............................] - ETA: 5s - loss: 5.5327 - accuracy: 0.0833
on_train_batch_begin: 1597963495.960126s

3 step training time: 0.114775s

on_train_batch_end: 1597963496.074922s

 4096/50000 [=>............................] - ETA: 5s - loss: 5.5059 - accuracy: 0.0810
on_train_batch_begin: 1597963496.075321s

4 step training time: 0.115196s

on_train_batch_end: 1597963496.189283s

 5120/50000 [==>...........................] - ETA: 5s - loss: 5.5121 - accuracy: 0.0809
on_train_batch_begin: 1597963496.189648s

5 step training time: 0.114327s

on_train_batch_end: 1597963496.304812s

 6144/50000 [==>...........................] - ETA: 4s - loss: 5.4770 - accuracy: 0.0794
on_train_batch_begin: 1597963496.305197s

6 step training time: 0.115549s

on_train_batch_end: 1597963496.419935s

 7168/50000 [===>..........................] - ETA: 4s - loss: 5.4502 - accuracy: 0.0776
on_train_batch_begin: 1597963496.420302s

7 step training time: 0.115105s

on_train_batch_end: 1597963496.535197s

 8192/50000 [===>..........................] - ETA: 4s - loss: 5.4313 - accuracy: 0.0756
on_train_batch_begin: 1597963496.535565s

8 step training time: 0.115263s

on_train_batch_end: 1597963496.650124s

 9216/50000 [====>.........................] - ETA: 4s - loss: 5.4170 - accuracy: 0.0738
on_train_batch_begin: 1597963496.650539s

9 step training time: 0.114974s

on_train_batch_end: 1597963496.765913s

10240/50000 [=====>........................] - ETA: 4s - loss: 5.4053 - accuracy: 0.0730
on_train_batch_begin: 1597963496.766287s

10 step training time: 0.115748s

on_train_batch_end: 1597963496.881151s

11264/50000 [=====>........................] - ETA: 4s - loss: 5.3929 - accuracy: 0.0727
on_train_batch_begin: 1597963496.881524s

11 step training time: 0.115237s

on_train_batch_end: 1597963496.996314s

12288/50000 [======>.......................] - ETA: 4s - loss: 5.3923 - accuracy: 0.0722
on_train_batch_begin: 1597963496.996691s

12 step training time: 0.115167s

on_train_batch_end: 1597963497.110965s

13312/50000 [======>.......................] - ETA: 4s - loss: 5.3816 - accuracy: 0.0721
on_train_batch_begin: 1597963497.111334s

13 step training time: 0.114643s

on_train_batch_end: 1597963497.226108s

14336/50000 [=======>......................] - ETA: 4s - loss: 5.3689 - accuracy: 0.0722
on_train_batch_begin: 1597963497.226489s

14 step training time: 0.115155s

on_train_batch_end: 1597963497.341371s

15360/50000 [========>.....................] - ETA: 3s - loss: 5.3563 - accuracy: 0.0722
on_train_batch_begin: 1597963497.341747s

15 step training time: 0.115258s

on_train_batch_end: 1597963497.456194s

16384/50000 [========>.....................] - ETA: 3s - loss: 5.3450 - accuracy: 0.0728
on_train_batch_begin: 1597963497.456565s

16 step training time: 0.114818s

on_train_batch_end: 1597963497.571030s

17408/50000 [=========>....................] - ETA: 3s - loss: 5.3323 - accuracy: 0.0726
on_train_batch_begin: 1597963497.571396s

17 step training time: 0.114831s

on_train_batch_end: 1597963497.685375s

18432/50000 [==========>...................] - ETA: 3s - loss: 5.3179 - accuracy: 0.0725
on_train_batch_begin: 1597963497.685742s

18 step training time: 0.114346s

on_train_batch_end: 1597963497.801818s

19456/50000 [==========>...................] - ETA: 3s - loss: 5.3074 - accuracy: 0.0717
on_train_batch_begin: 1597963497.802180s

19 step training time: 0.116438s

on_train_batch_end: 1597963497.916529s

20480/50000 [===========>..................] - ETA: 3s - loss: 5.2907 - accuracy: 0.0716
on_train_batch_begin: 1597963497.916904s

20 step training time: 0.114725s

on_train_batch_end: 1597963498.031485s

21504/50000 [===========>..................] - ETA: 3s - loss: 5.2836 - accuracy: 0.0707
on_train_batch_begin: 1597963498.031857s

21 step training time: 0.114953s

on_train_batch_end: 1597963498.146964s

22528/50000 [============>.................] - ETA: 3s - loss: 5.2753 - accuracy: 0.0699
on_train_batch_begin: 1597963498.147335s

22 step training time: 0.115478s

on_train_batch_end: 1597963498.262533s

23552/50000 [=============>................] - ETA: 2s - loss: 5.2657 - accuracy: 0.0694
on_train_batch_begin: 1597963498.262914s

23 step training time: 0.115579s

on_train_batch_end: 1597963498.377398s

24576/50000 [=============>................] - ETA: 2s - loss: 5.2526 - accuracy: 0.0688
on_train_batch_begin: 1597963498.377774s

24 step training time: 0.114859s

on_train_batch_end: 1597963498.494129s

25600/50000 [==============>...............] - ETA: 2s - loss: 5.2360 - accuracy: 0.0682
on_train_batch_begin: 1597963498.494503s

25 step training time: 0.116729s

on_train_batch_end: 1597963498.609850s

26624/50000 [==============>...............] - ETA: 2s - loss: 5.2203 - accuracy: 0.0677
on_train_batch_begin: 1597963498.610222s

26 step training time: 0.115719s

on_train_batch_end: 1597963498.725019s

27648/50000 [===============>..............] - ETA: 2s - loss: 5.2109 - accuracy: 0.0676
on_train_batch_begin: 1597963498.725518s

27 step training time: 0.115296s

on_train_batch_end: 1597963498.840826s

28672/50000 [================>.............] - ETA: 2s - loss: 5.1954 - accuracy: 0.0676
on_train_batch_begin: 1597963498.841218s

28 step training time: 0.115701s

on_train_batch_end: 1597963498.955480s

29696/50000 [================>.............] - ETA: 2s - loss: 5.1874 - accuracy: 0.0671
on_train_batch_begin: 1597963498.955847s

29 step training time: 0.114629s

on_train_batch_end: 1597963499.069334s

30720/50000 [=================>............] - ETA: 2s - loss: 5.1724 - accuracy: 0.0668
on_train_batch_begin: 1597963499.069704s

30 step training time: 0.113857s

on_train_batch_end: 1597963499.184150s

31744/50000 [==================>...........] - ETA: 2s - loss: 5.1647 - accuracy: 0.0666
on_train_batch_begin: 1597963499.184511s

31 step training time: 0.114808s

on_train_batch_end: 1597963499.298405s

32768/50000 [==================>...........] - ETA: 1s - loss: 5.1550 - accuracy: 0.0663
on_train_batch_begin: 1597963499.298775s

32 step training time: 0.114264s

on_train_batch_end: 1597963499.413405s

33792/50000 [===================>..........] - ETA: 1s - loss: 5.1482 - accuracy: 0.0660
on_train_batch_begin: 1597963499.413789s

33 step training time: 0.115014s

on_train_batch_end: 1597963499.528661s

34816/50000 [===================>..........] - ETA: 1s - loss: 5.1381 - accuracy: 0.0665
on_train_batch_begin: 1597963499.529056s

34 step training time: 0.115267s

on_train_batch_end: 1597963499.644349s

35840/50000 [====================>.........] - ETA: 1s - loss: 5.1292 - accuracy: 0.0668
on_train_batch_begin: 1597963499.644721s

35 step training time: 0.115665s

on_train_batch_end: 1597963499.759128s

36864/50000 [=====================>........] - ETA: 1s - loss: 5.1227 - accuracy: 0.0677
on_train_batch_begin: 1597963499.759504s

36 step training time: 0.114783s

on_train_batch_end: 1597963499.874518s

37888/50000 [=====================>........] - ETA: 1s - loss: 5.1174 - accuracy: 0.0682
on_train_batch_begin: 1597963499.874917s

37 step training time: 0.115413s

on_train_batch_end: 1597963499.989643s

38912/50000 [======================>.......] - ETA: 1s - loss: 5.1088 - accuracy: 0.0688
on_train_batch_begin: 1597963499.990013s

38 step training time: 0.115096s

on_train_batch_end: 1597963500.104360s

39936/50000 [======================>.......] - ETA: 1s - loss: 5.1044 - accuracy: 0.0691
on_train_batch_begin: 1597963500.104738s

39 step training time: 0.114725s

on_train_batch_end: 1597963500.219146s

40960/50000 [=======================>......] - ETA: 1s - loss: 5.0978 - accuracy: 0.0692
on_train_batch_begin: 1597963500.219526s

40 step training time: 0.114789s

on_train_batch_end: 1597963500.334142s

41984/50000 [========================>.....] - ETA: 0s - loss: 5.0892 - accuracy: 0.0693
on_train_batch_begin: 1597963500.334520s

41 step training time: 0.114993s

on_train_batch_end: 1597963500.449236s

43008/50000 [========================>.....] - ETA: 0s - loss: 5.0831 - accuracy: 0.0692
on_train_batch_begin: 1597963500.449616s

42 step training time: 0.115097s

on_train_batch_end: 1597963500.564779s

44032/50000 [=========================>....] - ETA: 0s - loss: 5.0773 - accuracy: 0.0692
on_train_batch_begin: 1597963500.565197s

43 step training time: 0.115581s

on_train_batch_end: 1597963500.681008s

45056/50000 [==========================>...] - ETA: 0s - loss: 5.0692 - accuracy: 0.0690
on_train_batch_begin: 1597963500.681380s

44 step training time: 0.116183s

on_train_batch_end: 1597963500.795651s

46080/50000 [==========================>...] - ETA: 0s - loss: 5.0624 - accuracy: 0.0688
on_train_batch_begin: 1597963500.796021s

45 step training time: 0.114641s

on_train_batch_end: 1597963500.910841s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.0526 - accuracy: 0.0686
on_train_batch_begin: 1597963500.911216s

46 step training time: 0.115195s

on_train_batch_end: 1597963501.025217s

48128/50000 [===========================>..] - ETA: 0s - loss: 5.0398 - accuracy: 0.0684
on_train_batch_begin: 1597963501.025584s

47 step training time: 0.114368s

on_train_batch_end: 1597963501.139710s

49152/50000 [============================>.] - ETA: 0s - loss: 5.0276 - accuracy: 0.0683
on_train_batch_begin: 1597963501.140074s

48 step training time: 0.114490s

on_train_batch_end: 1597963501.240283s

on_test_batch_begin: 1597963501.252678s

49 step training time: 0.112605s

on_epoch_end: 1597963501.652276s

Validation time: 0.399584s

Real time: 1597963501.652276s

Epoch time: 6.042177200317383s

50000/50000 [==============================] - 6s 121us/sample - loss: 5.0178 - accuracy: 0.0681 - val_loss: 268.0826 - val_accuracy: 0.0000e+00

on_epoch_begin: 1597963501.652523s

Real time: 1597963501.6525323
Epoch 3/5

on_train_batch_begin: 1597963501.656708s

on_train_batch_end: 1597963501.771165s

 1024/50000 [..............................] - ETA: 5s - loss: 4.3885 - accuracy: 0.0578
on_train_batch_begin: 1597963501.771529s

1 step training time: 0.114821s

on_train_batch_end: 1597963501.885709s

 2048/50000 [>.............................] - ETA: 5s - loss: 4.3363 - accuracy: 0.0595
on_train_batch_begin: 1597963501.886083s

2 step training time: 0.114554s

on_train_batch_end: 1597963502.001160s

 3072/50000 [>.............................] - ETA: 5s - loss: 4.3406 - accuracy: 0.0602
on_train_batch_begin: 1597963502.001530s

3 step training time: 0.115447s

on_train_batch_end: 1597963502.116419s

 4096/50000 [=>............................] - ETA: 5s - loss: 4.3316 - accuracy: 0.0603
on_train_batch_begin: 1597963502.116786s

4 step training time: 0.115256s

on_train_batch_end: 1597963502.232054s

 5120/50000 [==>...........................] - ETA: 5s - loss: 4.3438 - accuracy: 0.0604
on_train_batch_begin: 1597963502.232424s

5 step training time: 0.115638s

on_train_batch_end: 1597963502.347409s

 6144/50000 [==>...........................] - ETA: 4s - loss: 4.3339 - accuracy: 0.0605
on_train_batch_begin: 1597963502.347778s

6 step training time: 0.115354s

on_train_batch_end: 1597963502.462948s

 7168/50000 [===>..........................] - ETA: 4s - loss: 4.3264 - accuracy: 0.0608
on_train_batch_begin: 1597963502.463313s

7 step training time: 0.115535s

on_train_batch_end: 1597963502.578255s

 8192/50000 [===>..........................] - ETA: 4s - loss: 4.3168 - accuracy: 0.0633
on_train_batch_begin: 1597963502.578624s

8 step training time: 0.115311s

on_train_batch_end: 1597963502.693491s

 9216/50000 [====>.........................] - ETA: 4s - loss: 4.2798 - accuracy: 0.0651
on_train_batch_begin: 1597963502.693853s

9 step training time: 0.115229s

on_train_batch_end: 1597963502.807946s

10240/50000 [=====>........................] - ETA: 4s - loss: 4.2425 - accuracy: 0.0675
on_train_batch_begin: 1597963502.808321s

10 step training time: 0.114469s

on_train_batch_end: 1597963502.922817s

11264/50000 [=====>........................] - ETA: 4s - loss: 4.2177 - accuracy: 0.0692
on_train_batch_begin: 1597963502.923192s

11 step training time: 0.114871s

on_train_batch_end: 1597963503.038636s

12288/50000 [======>.......................] - ETA: 4s - loss: 4.1845 - accuracy: 0.0710
on_train_batch_begin: 1597963503.039038s

12 step training time: 0.115846s

on_train_batch_end: 1597963503.154209s

13312/50000 [======>.......................] - ETA: 4s - loss: 4.1531 - accuracy: 0.0724
on_train_batch_begin: 1597963503.154588s

13 step training time: 0.115550s

on_train_batch_end: 1597963503.269186s

14336/50000 [=======>......................] - ETA: 4s - loss: 4.1089 - accuracy: 0.0739
on_train_batch_begin: 1597963503.269568s

14 step training time: 0.114980s

on_train_batch_end: 1597963503.383529s

15360/50000 [========>.....................] - ETA: 3s - loss: 4.0846 - accuracy: 0.0752
on_train_batch_begin: 1597963503.383908s

15 step training time: 0.114341s

on_train_batch_end: 1597963503.498524s

16384/50000 [========>.....................] - ETA: 3s - loss: 4.0465 - accuracy: 0.0766
on_train_batch_begin: 1597963503.498900s

16 step training time: 0.114992s

on_train_batch_end: 1597963503.613651s

17408/50000 [=========>....................] - ETA: 3s - loss: 4.0190 - accuracy: 0.0777
on_train_batch_begin: 1597963503.614025s

17 step training time: 0.115125s

on_train_batch_end: 1597963503.728558s

18432/50000 [==========>...................] - ETA: 3s - loss: 3.9820 - accuracy: 0.0785
on_train_batch_begin: 1597963503.728938s

18 step training time: 0.114913s

on_train_batch_end: 1597963503.843370s

19456/50000 [==========>...................] - ETA: 3s - loss: 3.9428 - accuracy: 0.0796
on_train_batch_begin: 1597963503.843769s

19 step training time: 0.114831s

on_train_batch_end: 1597963503.958313s

20480/50000 [===========>..................] - ETA: 3s - loss: 3.9161 - accuracy: 0.0804
on_train_batch_begin: 1597963503.958678s

20 step training time: 0.114909s

on_train_batch_end: 1597963504.073704s

21504/50000 [===========>..................] - ETA: 3s - loss: 3.8975 - accuracy: 0.0811
on_train_batch_begin: 1597963504.074069s

21 step training time: 0.115391s

on_train_batch_end: 1597963504.188895s

22528/50000 [============>.................] - ETA: 3s - loss: 3.8705 - accuracy: 0.0819
on_train_batch_begin: 1597963504.189284s

22 step training time: 0.115215s

on_train_batch_end: 1597963504.304141s

23552/50000 [=============>................] - ETA: 2s - loss: 3.8455 - accuracy: 0.0826
on_train_batch_begin: 1597963504.304505s

23 step training time: 0.115221s

on_train_batch_end: 1597963504.418949s

24576/50000 [=============>................] - ETA: 2s - loss: 3.8237 - accuracy: 0.0832
on_train_batch_begin: 1597963504.419308s

24 step training time: 0.114804s

on_train_batch_end: 1597963504.533388s

25600/50000 [==============>...............] - ETA: 2s - loss: 3.7954 - accuracy: 0.0839
on_train_batch_begin: 1597963504.533757s

25 step training time: 0.114449s

on_train_batch_end: 1597963504.648365s

26624/50000 [==============>...............] - ETA: 2s - loss: 3.7628 - accuracy: 0.0844
on_train_batch_begin: 1597963504.648731s

26 step training time: 0.114974s

on_train_batch_end: 1597963504.765246s

27648/50000 [===============>..............] - ETA: 2s - loss: 3.7335 - accuracy: 0.0850
on_train_batch_begin: 1597963504.765616s

27 step training time: 0.116885s

on_train_batch_end: 1597963504.880074s

28672/50000 [================>.............] - ETA: 2s - loss: 3.7025 - accuracy: 0.0855
on_train_batch_begin: 1597963504.880440s

28 step training time: 0.114825s

on_train_batch_end: 1597963504.993946s

29696/50000 [================>.............] - ETA: 2s - loss: 3.6768 - accuracy: 0.0860
on_train_batch_begin: 1597963504.994306s

29 step training time: 0.113865s

on_train_batch_end: 1597963505.109537s

30720/50000 [=================>............] - ETA: 2s - loss: 3.6536 - accuracy: 0.0865
on_train_batch_begin: 1597963505.109910s

30 step training time: 0.115604s

on_train_batch_end: 1597963505.223721s

31744/50000 [==================>...........] - ETA: 2s - loss: 3.6343 - accuracy: 0.0869
on_train_batch_begin: 1597963505.224087s

31 step training time: 0.114177s

on_train_batch_end: 1597963505.339012s

32768/50000 [==================>...........] - ETA: 1s - loss: 3.6102 - accuracy: 0.0873
on_train_batch_begin: 1597963505.339384s

32 step training time: 0.115298s

on_train_batch_end: 1597963505.453896s

33792/50000 [===================>..........] - ETA: 1s - loss: 3.5906 - accuracy: 0.0877
on_train_batch_begin: 1597963505.454261s

33 step training time: 0.114877s

on_train_batch_end: 1597963505.568910s

34816/50000 [===================>..........] - ETA: 1s - loss: 3.5682 - accuracy: 0.0880
on_train_batch_begin: 1597963505.569325s

34 step training time: 0.115063s

on_train_batch_end: 1597963505.687527s

35840/50000 [====================>.........] - ETA: 1s - loss: 3.5432 - accuracy: 0.0883
on_train_batch_begin: 1597963505.687889s

35 step training time: 0.118564s

on_train_batch_end: 1597963505.803016s

36864/50000 [=====================>........] - ETA: 1s - loss: 3.5191 - accuracy: 0.0886
on_train_batch_begin: 1597963505.803387s

36 step training time: 0.115498s

on_train_batch_end: 1597963505.917662s

37888/50000 [=====================>........] - ETA: 1s - loss: 3.4978 - accuracy: 0.0889
on_train_batch_begin: 1597963505.918021s

37 step training time: 0.114634s

on_train_batch_end: 1597963506.032503s

38912/50000 [======================>.......] - ETA: 1s - loss: 3.4761 - accuracy: 0.0892
on_train_batch_begin: 1597963506.032866s

38 step training time: 0.114845s

on_train_batch_end: 1597963506.147434s

39936/50000 [======================>.......] - ETA: 1s - loss: 3.4523 - accuracy: 0.0895
on_train_batch_begin: 1597963506.147795s

39 step training time: 0.114929s

on_train_batch_end: 1597963506.262820s

40960/50000 [=======================>......] - ETA: 1s - loss: 3.4326 - accuracy: 0.0897
on_train_batch_begin: 1597963506.263191s

40 step training time: 0.115396s

on_train_batch_end: 1597963506.377137s

41984/50000 [========================>.....] - ETA: 0s - loss: 3.4092 - accuracy: 0.0900
on_train_batch_begin: 1597963506.377510s

41 step training time: 0.114319s

on_train_batch_end: 1597963506.491701s

43008/50000 [========================>.....] - ETA: 0s - loss: 3.3851 - accuracy: 0.0902
on_train_batch_begin: 1597963506.492090s

42 step training time: 0.114580s

on_train_batch_end: 1597963506.606937s

44032/50000 [=========================>....] - ETA: 0s - loss: 3.3617 - accuracy: 0.0904
on_train_batch_begin: 1597963506.607323s

43 step training time: 0.115233s

on_train_batch_end: 1597963506.721522s

45056/50000 [==========================>...] - ETA: 0s - loss: 3.3429 - accuracy: 0.0906
on_train_batch_begin: 1597963506.721889s

44 step training time: 0.114567s

on_train_batch_end: 1597963506.836790s

46080/50000 [==========================>...] - ETA: 0s - loss: 3.3245 - accuracy: 0.0908
on_train_batch_begin: 1597963506.837183s

45 step training time: 0.115293s

on_train_batch_end: 1597963506.952346s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.3058 - accuracy: 0.0910
on_train_batch_begin: 1597963506.952712s

46 step training time: 0.115530s

on_train_batch_end: 1597963507.067432s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.2864 - accuracy: 0.0912
on_train_batch_begin: 1597963507.067793s

47 step training time: 0.115080s

on_train_batch_end: 1597963507.184228s

49152/50000 [============================>.] - ETA: 0s - loss: 3.2660 - accuracy: 0.0914
on_train_batch_begin: 1597963507.184593s

48 step training time: 0.116801s

on_train_batch_end: 1597963507.285074s

on_test_batch_begin: 1597963507.300438s

49 step training time: 0.115844s

on_epoch_end: 1597963507.705585s

Validation time: 0.405133s

Real time: 1597963507.705585s

Epoch time: 6.053072929382324s

50000/50000 [==============================] - 6s 121us/sample - loss: 3.2514 - accuracy: 0.0915 - val_loss: 7.1919 - val_accuracy: 0.0999

on_epoch_begin: 1597963507.705823s

Real time: 1597963507.7058325
Epoch 4/5

on_train_batch_begin: 1597963507.709989s

on_train_batch_end: 1597963507.824448s

 1024/50000 [..............................] - ETA: 5s - loss: 2.0333 - accuracy: 0.1011
on_train_batch_begin: 1597963507.824810s

1 step training time: 0.114821s

on_train_batch_end: 1597963507.939562s

 2048/50000 [>.............................] - ETA: 5s - loss: 2.0723 - accuracy: 0.1002
on_train_batch_begin: 1597963507.939936s

2 step training time: 0.115127s

on_train_batch_end: 1597963508.054553s

 3072/50000 [>.............................] - ETA: 5s - loss: 2.1202 - accuracy: 0.0998
on_train_batch_begin: 1597963508.054921s

3 step training time: 0.114984s

on_train_batch_end: 1597963508.169383s

 4096/50000 [=>............................] - ETA: 5s - loss: 2.1188 - accuracy: 0.1000
on_train_batch_begin: 1597963508.169750s

4 step training time: 0.114829s

on_train_batch_end: 1597963508.283979s

 5120/50000 [==>...........................] - ETA: 5s - loss: 2.1225 - accuracy: 0.1000
on_train_batch_begin: 1597963508.284350s

5 step training time: 0.114600s

on_train_batch_end: 1597963508.398935s

 6144/50000 [==>...........................] - ETA: 4s - loss: 2.1393 - accuracy: 0.1000
on_train_batch_begin: 1597963508.399301s

6 step training time: 0.114951s

on_train_batch_end: 1597963508.514224s

 7168/50000 [===>..........................] - ETA: 4s - loss: 2.1164 - accuracy: 0.1001
on_train_batch_begin: 1597963508.514591s

7 step training time: 0.115290s

on_train_batch_end: 1597963508.629537s

 8192/50000 [===>..........................] - ETA: 4s - loss: 2.1006 - accuracy: 0.1001
on_train_batch_begin: 1597963508.629895s

8 step training time: 0.115304s

on_train_batch_end: 1597963508.744861s

 9216/50000 [====>.........................] - ETA: 4s - loss: 2.0663 - accuracy: 0.1001
on_train_batch_begin: 1597963508.745247s

9 step training time: 0.115352s

on_train_batch_end: 1597963508.860509s

10240/50000 [=====>........................] - ETA: 4s - loss: 2.0460 - accuracy: 0.1002
on_train_batch_begin: 1597963508.860877s

10 step training time: 0.115630s

on_train_batch_end: 1597963508.975426s

11264/50000 [=====>........................] - ETA: 4s - loss: 2.0540 - accuracy: 0.1001
on_train_batch_begin: 1597963508.975799s

11 step training time: 0.114922s

on_train_batch_end: 1597963509.090167s

12288/50000 [======>.......................] - ETA: 4s - loss: 2.0556 - accuracy: 0.1001
on_train_batch_begin: 1597963509.090547s

12 step training time: 0.114748s

on_train_batch_end: 1597963509.205287s

13312/50000 [======>.......................] - ETA: 4s - loss: 2.0431 - accuracy: 0.1001
on_train_batch_begin: 1597963509.205671s

13 step training time: 0.115124s

on_train_batch_end: 1597963509.320686s

14336/50000 [=======>......................] - ETA: 4s - loss: 2.0355 - accuracy: 0.1001
on_train_batch_begin: 1597963509.321089s

14 step training time: 0.115418s

on_train_batch_end: 1597963509.436005s

15360/50000 [========>.....................] - ETA: 3s - loss: 2.0285 - accuracy: 0.1001
on_train_batch_begin: 1597963509.436378s

15 step training time: 0.115289s

on_train_batch_end: 1597963509.550816s

16384/50000 [========>.....................] - ETA: 3s - loss: 2.0246 - accuracy: 0.1001
on_train_batch_begin: 1597963509.551188s

16 step training time: 0.114810s

on_train_batch_end: 1597963509.665906s

17408/50000 [=========>....................] - ETA: 3s - loss: 2.0285 - accuracy: 0.1000
on_train_batch_begin: 1597963509.666274s

17 step training time: 0.115086s

on_train_batch_end: 1597963509.780641s

18432/50000 [==========>...................] - ETA: 3s - loss: 2.0193 - accuracy: 0.1000
on_train_batch_begin: 1597963509.781029s

18 step training time: 0.114755s

on_train_batch_end: 1597963509.895801s

19456/50000 [==========>...................] - ETA: 3s - loss: 2.0086 - accuracy: 0.1000
on_train_batch_begin: 1597963509.896164s

19 step training time: 0.115135s

on_train_batch_end: 1597963510.010385s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.9907 - accuracy: 0.1001
on_train_batch_begin: 1597963510.010751s

20 step training time: 0.114587s

on_train_batch_end: 1597963510.126095s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.9798 - accuracy: 0.1001
on_train_batch_begin: 1597963510.126459s

21 step training time: 0.115707s

on_train_batch_end: 1597963510.241429s

22528/50000 [============>.................] - ETA: 3s - loss: 1.9754 - accuracy: 0.1001
on_train_batch_begin: 1597963510.241794s

22 step training time: 0.115335s

on_train_batch_end: 1597963510.356074s

23552/50000 [=============>................] - ETA: 2s - loss: 1.9643 - accuracy: 0.1001
on_train_batch_begin: 1597963510.356452s

23 step training time: 0.114657s

on_train_batch_end: 1597963510.470571s

24576/50000 [=============>................] - ETA: 2s - loss: 1.9581 - accuracy: 0.1001
on_train_batch_begin: 1597963510.470942s

24 step training time: 0.114491s

on_train_batch_end: 1597963510.586226s

25600/50000 [==============>...............] - ETA: 2s - loss: 1.9570 - accuracy: 0.1001
on_train_batch_begin: 1597963510.586601s

25 step training time: 0.115659s

on_train_batch_end: 1597963510.701891s

26624/50000 [==============>...............] - ETA: 2s - loss: 1.9432 - accuracy: 0.1000
on_train_batch_begin: 1597963510.702264s

26 step training time: 0.115662s

on_train_batch_end: 1597963510.816837s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.9350 - accuracy: 0.1001
on_train_batch_begin: 1597963510.817242s

27 step training time: 0.114978s

on_train_batch_end: 1597963510.931415s

28672/50000 [================>.............] - ETA: 2s - loss: 1.9231 - accuracy: 0.1001
on_train_batch_begin: 1597963510.931791s

28 step training time: 0.114548s

on_train_batch_end: 1597963511.046185s

29696/50000 [================>.............] - ETA: 2s - loss: 1.9136 - accuracy: 0.1001
on_train_batch_begin: 1597963511.046554s

29 step training time: 0.114763s

on_train_batch_end: 1597963511.161129s

30720/50000 [=================>............] - ETA: 2s - loss: 1.9032 - accuracy: 0.1001
on_train_batch_begin: 1597963511.161500s

30 step training time: 0.114946s

on_train_batch_end: 1597963511.276684s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.8946 - accuracy: 0.1002
on_train_batch_begin: 1597963511.277091s

31 step training time: 0.115591s

on_train_batch_end: 1597963511.391521s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.8901 - accuracy: 0.1001
on_train_batch_begin: 1597963511.391892s

32 step training time: 0.114801s

on_train_batch_end: 1597963511.506382s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.8813 - accuracy: 0.1001
on_train_batch_begin: 1597963511.506760s

33 step training time: 0.114868s

on_train_batch_end: 1597963511.621546s

34816/50000 [===================>..........] - ETA: 1s - loss: 1.8758 - accuracy: 0.1002
on_train_batch_begin: 1597963511.621932s

34 step training time: 0.115172s

on_train_batch_end: 1597963511.736266s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.8668 - accuracy: 0.1001
on_train_batch_begin: 1597963511.736625s

35 step training time: 0.114693s

on_train_batch_end: 1597963511.851007s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.8639 - accuracy: 0.1001
on_train_batch_begin: 1597963511.851367s

36 step training time: 0.114743s

on_train_batch_end: 1597963511.966545s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.8577 - accuracy: 0.1001
on_train_batch_begin: 1597963511.966913s

37 step training time: 0.115545s

on_train_batch_end: 1597963512.082177s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.8524 - accuracy: 0.1001
on_train_batch_begin: 1597963512.082553s

38 step training time: 0.115640s

on_train_batch_end: 1597963512.196874s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.8477 - accuracy: 0.1001
on_train_batch_begin: 1597963512.197273s

39 step training time: 0.114721s

on_train_batch_end: 1597963512.311979s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.8391 - accuracy: 0.1001
on_train_batch_begin: 1597963512.312353s

40 step training time: 0.115080s

on_train_batch_end: 1597963512.427572s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.8300 - accuracy: 0.1001
on_train_batch_begin: 1597963512.427946s

41 step training time: 0.115592s

on_train_batch_end: 1597963512.542288s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.8265 - accuracy: 0.1001
on_train_batch_begin: 1597963512.542662s

42 step training time: 0.114716s

on_train_batch_end: 1597963512.657316s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.8217 - accuracy: 0.1001
on_train_batch_begin: 1597963512.657705s

43 step training time: 0.115043s

on_train_batch_end: 1597963512.772397s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.8150 - accuracy: 0.1001
on_train_batch_begin: 1597963512.772757s

44 step training time: 0.115052s

on_train_batch_end: 1597963512.887960s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.8103 - accuracy: 0.1001
on_train_batch_begin: 1597963512.888340s

45 step training time: 0.115583s

on_train_batch_end: 1597963513.002679s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8039 - accuracy: 0.1001
on_train_batch_begin: 1597963513.003052s

46 step training time: 0.114712s

on_train_batch_end: 1597963513.116838s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7990 - accuracy: 0.1001
on_train_batch_begin: 1597963513.117240s

47 step training time: 0.114188s

on_train_batch_end: 1597963513.231240s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7929 - accuracy: 0.1002
on_train_batch_begin: 1597963513.231608s

48 step training time: 0.114368s

on_train_batch_end: 1597963513.332082s

on_test_batch_begin: 1597963513.348530s

49 step training time: 0.116921s

on_epoch_end: 1597963513.753328s

Validation time: 0.404784s

Real time: 1597963513.753328s

Epoch time: 6.047520637512207s

50000/50000 [==============================] - 6s 121us/sample - loss: 1.7926 - accuracy: 0.1002 - val_loss: 7.6184 - val_accuracy: 0.0999

on_epoch_begin: 1597963513.753581s

Real time: 1597963513.7535937
Epoch 5/5

on_train_batch_begin: 1597963513.757715s

on_train_batch_end: 1597963513.873250s

 1024/50000 [..............................] - ETA: 5s - loss: 1.2365 - accuracy: 0.1000
on_train_batch_begin: 1597963513.873634s

1 step training time: 0.115919s

on_train_batch_end: 1597963513.989740s

 2048/50000 [>.............................] - ETA: 5s - loss: 1.3652 - accuracy: 0.1001
on_train_batch_begin: 1597963513.990107s

2 step training time: 0.116473s

on_train_batch_end: 1597963514.103961s

 3072/50000 [>.............................] - ETA: 5s - loss: 1.3826 - accuracy: 0.1002
on_train_batch_begin: 1597963514.104328s

3 step training time: 0.114221s

on_train_batch_end: 1597963514.219234s

 4096/50000 [=>............................] - ETA: 5s - loss: 1.4013 - accuracy: 0.1002
on_train_batch_begin: 1597963514.219596s

4 step training time: 0.115268s

on_train_batch_end: 1597963514.334280s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.4357 - accuracy: 0.1001
on_train_batch_begin: 1597963514.334645s

5 step training time: 0.115049s

on_train_batch_end: 1597963514.449548s

 6144/50000 [==>...........................] - ETA: 4s - loss: 1.4095 - accuracy: 0.1003
on_train_batch_begin: 1597963514.449909s

6 step training time: 0.115264s

on_train_batch_end: 1597963514.564536s

 7168/50000 [===>..........................] - ETA: 4s - loss: 1.3717 - accuracy: 0.1004
on_train_batch_begin: 1597963514.564902s

7 step training time: 0.114993s

on_train_batch_end: 1597963514.679573s

 8192/50000 [===>..........................] - ETA: 4s - loss: 1.3844 - accuracy: 0.1003
on_train_batch_begin: 1597963514.679937s

8 step training time: 0.115036s

on_train_batch_end: 1597963514.794631s

 9216/50000 [====>.........................] - ETA: 4s - loss: 1.3984 - accuracy: 0.1003
on_train_batch_begin: 1597963514.795005s

9 step training time: 0.115068s

on_train_batch_end: 1597963514.910025s

10240/50000 [=====>........................] - ETA: 4s - loss: 1.3989 - accuracy: 0.1003
on_train_batch_begin: 1597963514.910393s

10 step training time: 0.115388s

on_train_batch_end: 1597963515.024793s

11264/50000 [=====>........................] - ETA: 4s - loss: 1.4044 - accuracy: 0.1003
on_train_batch_begin: 1597963515.025181s

11 step training time: 0.114788s

on_train_batch_end: 1597963515.140551s

12288/50000 [======>.......................] - ETA: 4s - loss: 1.4074 - accuracy: 0.1003
on_train_batch_begin: 1597963515.140918s

12 step training time: 0.115736s

on_train_batch_end: 1597963515.255792s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.4076 - accuracy: 0.1003
on_train_batch_begin: 1597963515.256168s

13 step training time: 0.115251s

on_train_batch_end: 1597963515.371257s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.4212 - accuracy: 0.1003
on_train_batch_begin: 1597963515.371653s

14 step training time: 0.115484s

on_train_batch_end: 1597963515.485844s

15360/50000 [========>.....................] - ETA: 3s - loss: 1.4290 - accuracy: 0.1003
on_train_batch_begin: 1597963515.486233s

15 step training time: 0.114580s

on_train_batch_end: 1597963515.601263s

16384/50000 [========>.....................] - ETA: 3s - loss: 1.4305 - accuracy: 0.1004
on_train_batch_begin: 1597963515.601647s

16 step training time: 0.115415s

on_train_batch_end: 1597963515.718916s

17408/50000 [=========>....................] - ETA: 3s - loss: 1.4297 - accuracy: 0.1003
on_train_batch_begin: 1597963515.719286s

17 step training time: 0.117639s

on_train_batch_end: 1597963515.834082s

18432/50000 [==========>...................] - ETA: 3s - loss: 1.4272 - accuracy: 0.1004
on_train_batch_begin: 1597963515.834449s

18 step training time: 0.115162s

on_train_batch_end: 1597963515.951395s

19456/50000 [==========>...................] - ETA: 3s - loss: 1.4334 - accuracy: 0.1004
on_train_batch_begin: 1597963515.951760s

19 step training time: 0.117312s

on_train_batch_end: 1597963516.066918s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.4351 - accuracy: 0.1004
on_train_batch_begin: 1597963516.067299s

20 step training time: 0.115539s

on_train_batch_end: 1597963516.181988s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.4368 - accuracy: 0.1004
on_train_batch_begin: 1597963516.182358s

21 step training time: 0.115059s

on_train_batch_end: 1597963516.297252s

22528/50000 [============>.................] - ETA: 3s - loss: 1.4353 - accuracy: 0.1004
on_train_batch_begin: 1597963516.297618s

22 step training time: 0.115260s

on_train_batch_end: 1597963516.412447s

23552/50000 [=============>................] - ETA: 2s - loss: 1.4271 - accuracy: 0.1004
on_train_batch_begin: 1597963516.412842s

23 step training time: 0.115223s

on_train_batch_end: 1597963516.526855s

24576/50000 [=============>................] - ETA: 2s - loss: 1.4254 - accuracy: 0.1004
on_train_batch_begin: 1597963516.527219s

24 step training time: 0.114377s

on_train_batch_end: 1597963516.642202s

25600/50000 [==============>...............] - ETA: 2s - loss: 1.4213 - accuracy: 0.1004
on_train_batch_begin: 1597963516.642573s

25 step training time: 0.115353s

on_train_batch_end: 1597963516.757357s

26624/50000 [==============>...............] - ETA: 2s - loss: 1.4195 - accuracy: 0.1004
on_train_batch_begin: 1597963516.757726s

26 step training time: 0.115153s

on_train_batch_end: 1597963516.871462s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.4225 - accuracy: 0.1004
on_train_batch_begin: 1597963516.871826s

27 step training time: 0.114100s

on_train_batch_end: 1597963516.986412s

28672/50000 [================>.............] - ETA: 2s - loss: 1.4202 - accuracy: 0.1004
on_train_batch_begin: 1597963516.986782s

28 step training time: 0.114956s

on_train_batch_end: 1597963517.102063s

29696/50000 [================>.............] - ETA: 2s - loss: 1.4182 - accuracy: 0.1004
on_train_batch_begin: 1597963517.102426s

29 step training time: 0.115644s

on_train_batch_end: 1597963517.216593s

30720/50000 [=================>............] - ETA: 2s - loss: 1.4247 - accuracy: 0.1004
on_train_batch_begin: 1597963517.216990s

30 step training time: 0.114563s

on_train_batch_end: 1597963517.331363s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.4224 - accuracy: 0.1004
on_train_batch_begin: 1597963517.331734s

31 step training time: 0.114744s

on_train_batch_end: 1597963517.446701s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.4229 - accuracy: 0.1004
on_train_batch_begin: 1597963517.447082s

32 step training time: 0.115348s

on_train_batch_end: 1597963517.564517s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.4209 - accuracy: 0.1004
on_train_batch_begin: 1597963517.564881s

33 step training time: 0.117798s

on_train_batch_end: 1597963517.679948s

34816/50000 [===================>..........] - ETA: 1s - loss: 1.4213 - accuracy: 0.1004
on_train_batch_begin: 1597963517.680320s

34 step training time: 0.115439s

on_train_batch_end: 1597963517.795461s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.4181 - accuracy: 0.1004
on_train_batch_begin: 1597963517.795829s

35 step training time: 0.115510s

on_train_batch_end: 1597963517.911968s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.4247 - accuracy: 0.1003
on_train_batch_begin: 1597963517.912354s

36 step training time: 0.116525s

on_train_batch_end: 1597963518.027444s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.4229 - accuracy: 0.1003
on_train_batch_begin: 1597963518.027809s

37 step training time: 0.115455s

on_train_batch_end: 1597963518.143142s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.4189 - accuracy: 0.1003
on_train_batch_begin: 1597963518.143513s

38 step training time: 0.115704s

on_train_batch_end: 1597963518.258554s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.4167 - accuracy: 0.1003
on_train_batch_begin: 1597963518.258918s

39 step training time: 0.115405s

on_train_batch_end: 1597963518.374014s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.4109 - accuracy: 0.1003
on_train_batch_begin: 1597963518.374378s

40 step training time: 0.115460s

on_train_batch_end: 1597963518.489995s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.4094 - accuracy: 0.1003
on_train_batch_begin: 1597963518.490360s

41 step training time: 0.115982s

on_train_batch_end: 1597963518.605815s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.4072 - accuracy: 0.1003
on_train_batch_begin: 1597963518.606180s

42 step training time: 0.115820s

on_train_batch_end: 1597963518.721198s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.4092 - accuracy: 0.1003
on_train_batch_begin: 1597963518.721574s

43 step training time: 0.115394s

on_train_batch_end: 1597963518.835910s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.4055 - accuracy: 0.1003
on_train_batch_begin: 1597963518.836278s

44 step training time: 0.114705s

on_train_batch_end: 1597963518.951853s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.4017 - accuracy: 0.1003
on_train_batch_begin: 1597963518.952224s

45 step training time: 0.115946s

on_train_batch_end: 1597963519.068220s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.3994 - accuracy: 0.1003
on_train_batch_begin: 1597963519.068587s

46 step training time: 0.116363s

on_train_batch_end: 1597963519.183793s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.3933 - accuracy: 0.1003
on_train_batch_begin: 1597963519.184185s

47 step training time: 0.115598s

on_train_batch_end: 1597963519.300364s

49152/50000 [============================>.] - ETA: 0s - loss: 1.3921 - accuracy: 0.1003
on_train_batch_begin: 1597963519.300728s

48 step training time: 0.116543s

on_train_batch_end: 1597963519.401413s

on_test_batch_begin: 1597963519.415344s

49 step training time: 0.114615s

on_epoch_end: 1597963519.828860s

Validation time: 0.413503s

Real time: 1597963519.828860s

Epoch time: 6.075284242630005s

50000/50000 [==============================] - 6s 122us/sample - loss: 1.3944 - accuracy: 0.1003 - val_loss: 7.0507 - val_accuracy: 0.0999
Tempo do fit: 54.49269509315491