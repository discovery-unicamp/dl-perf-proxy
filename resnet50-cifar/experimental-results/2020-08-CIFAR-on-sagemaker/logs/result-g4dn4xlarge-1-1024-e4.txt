wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:46
   221184/170498071 [..............................] - ETA: 1:11
  1204224/170498071 [..............................] - ETA: 20s 
  3760128/170498071 [..............................] - ETA: 8s 
  7118848/170498071 [>.............................] - ETA: 5s
 10461184/170498071 [>.............................] - ETA: 4s
 13770752/170498071 [=>............................] - ETA: 3s
 17080320/170498071 [==>...........................] - ETA: 3s
 20406272/170498071 [==>...........................] - ETA: 3s
 23617536/170498071 [===>..........................] - ETA: 3s
 26845184/170498071 [===>..........................] - ETA: 2s
 30138368/170498071 [====>.........................] - ETA: 2s
 33447936/170498071 [====>.........................] - ETA: 2s
 36741120/170498071 [=====>........................] - ETA: 2s
 40050688/170498071 [======>.......................] - ETA: 2s
 43376640/170498071 [======>.......................] - ETA: 2s
 46718976/170498071 [=======>......................] - ETA: 2s
 50028544/170498071 [=======>......................] - ETA: 2s
 53256192/170498071 [========>.....................] - ETA: 2s
 56532992/170498071 [========>.....................] - ETA: 2s
 59777024/170498071 [=========>....................] - ETA: 1s
 63102976/170498071 [==========>...................] - ETA: 1s
 66412544/170498071 [==========>...................] - ETA: 1s
 69771264/170498071 [===========>..................] - ETA: 1s
 72982528/170498071 [===========>..................] - ETA: 1s
 76308480/170498071 [============>.................] - ETA: 1s
 79618048/170498071 [=============>................] - ETA: 1s
 82919424/170498071 [=============>................] - ETA: 1s
 86106112/170498071 [==============>...............] - ETA: 1s
 89415680/170498071 [==============>...............] - ETA: 1s
 92626944/170498071 [===============>..............] - ETA: 1s
 95821824/170498071 [===============>..............] - ETA: 1s
 99147776/170498071 [================>.............] - ETA: 1s
102342656/170498071 [=================>............] - ETA: 1s
105684992/170498071 [=================>............] - ETA: 1s
109027328/170498071 [==================>...........] - ETA: 1s
112353280/170498071 [==================>...........] - ETA: 0s
115613696/170498071 [===================>..........] - ETA: 0s
118857728/170498071 [===================>..........] - ETA: 0s
122216448/170498071 [====================>.........] - ETA: 0s
125386752/170498071 [=====================>........] - ETA: 0s
128688128/170498071 [=====================>........] - ETA: 0s
131997696/170498071 [======================>.......] - ETA: 0s
135290880/170498071 [======================>.......] - ETA: 0s
138633216/170498071 [=======================>......] - ETA: 0s
141975552/170498071 [=======================>......] - ETA: 0s
145268736/170498071 [========================>.....] - ETA: 0s
148529152/170498071 [=========================>....] - ETA: 0s
151789568/170498071 [=========================>....] - ETA: 0s
155033600/170498071 [==========================>...] - ETA: 0s
158359552/170498071 [==========================>...] - ETA: 0s
161636352/170498071 [===========================>..] - ETA: 0s
164978688/170498071 [============================>.] - ETA: 0s
168304640/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 5922816/94765736 [>.............................] - ETA: 0s
 9945088/94765736 [==>...........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
27820032/94765736 [=======>......................] - ETA: 0s
29474816/94765736 [========>.....................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
44908544/94765736 [=============>................] - ETA: 0s
47259648/94765736 [=============>................] - ETA: 0s
55500800/94765736 [================>.............] - ETA: 0s
57589760/94765736 [=================>............] - ETA: 0s
66117632/94765736 [===================>..........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
83714048/94765736 [=========================>....] - ETA: 0s
90693632/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.38642406463623
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615686516.635695s

Real time: 1615686516.635713
Epoch 1/5

on_train_batch_begin: 1615686517.413397s

on_train_batch_end: 1615686535.129319s

 1024/50000 [..............................] - ETA: 14:44 - loss: 17.9754 - accuracy: 2.9850e-04
on_train_batch_begin: 1615686535.129914s

1 step training time: 17.716516s

on_train_batch_end: 1615686535.449124s

 2048/50000 [>.............................] - ETA: 7:20 - loss: 14.6797 - accuracy: 4.2295e-04 
on_train_batch_begin: 1615686535.449473s

2 step training time: 0.319559s

on_train_batch_end: 1615686535.768677s

 3072/50000 [>.............................] - ETA: 4:52 - loss: 12.6742 - accuracy: 5.2261e-04
on_train_batch_begin: 1615686535.769022s

3 step training time: 0.319550s

on_train_batch_end: 1615686536.086699s

 4096/50000 [=>............................] - ETA: 3:37 - loss: 11.5960 - accuracy: 0.0014    
on_train_batch_begin: 1615686536.087018s

4 step training time: 0.317995s

on_train_batch_end: 1615686536.401562s

 5120/50000 [==>...........................] - ETA: 2:53 - loss: 10.9408 - accuracy: 0.0036
on_train_batch_begin: 1615686536.401881s

5 step training time: 0.314863s

on_train_batch_end: 1615686536.722893s

 6144/50000 [==>...........................] - ETA: 2:23 - loss: 10.5193 - accuracy: 0.0073
on_train_batch_begin: 1615686536.723217s

6 step training time: 0.321337s

on_train_batch_end: 1615686537.040561s

 7168/50000 [===>..........................] - ETA: 2:01 - loss: 10.1685 - accuracy: 0.0122
on_train_batch_begin: 1615686537.040876s

7 step training time: 0.317659s

on_train_batch_end: 1615686537.356230s

 8192/50000 [===>..........................] - ETA: 1:45 - loss: 9.8794 - accuracy: 0.0167 
on_train_batch_begin: 1615686537.356566s

8 step training time: 0.315690s

on_train_batch_end: 1615686537.677820s

 9216/50000 [====>.........................] - ETA: 1:33 - loss: 9.6438 - accuracy: 0.0217
on_train_batch_begin: 1615686537.678139s

9 step training time: 0.321573s

on_train_batch_end: 1615686537.995310s

10240/50000 [=====>........................] - ETA: 1:22 - loss: 9.4540 - accuracy: 0.0265
on_train_batch_begin: 1615686537.995656s

10 step training time: 0.317518s

on_train_batch_end: 1615686538.311250s

11264/50000 [=====>........................] - ETA: 1:14 - loss: 9.3028 - accuracy: 0.0303
on_train_batch_begin: 1615686538.311590s

11 step training time: 0.315934s

on_train_batch_end: 1615686538.632769s

12288/50000 [======>.......................] - ETA: 1:07 - loss: 9.1623 - accuracy: 0.0328
on_train_batch_begin: 1615686538.633088s

12 step training time: 0.321498s

on_train_batch_end: 1615686538.952008s

13312/50000 [======>.......................] - ETA: 1:01 - loss: 9.0491 - accuracy: 0.0356
on_train_batch_begin: 1615686538.952326s

13 step training time: 0.319238s

on_train_batch_end: 1615686539.267130s

14336/50000 [=======>......................] - ETA: 56s - loss: 8.9426 - accuracy: 0.0374 
on_train_batch_begin: 1615686539.267477s

14 step training time: 0.315151s

on_train_batch_end: 1615686539.587462s

15360/50000 [========>.....................] - ETA: 51s - loss: 8.8582 - accuracy: 0.0396
on_train_batch_begin: 1615686539.587788s

15 step training time: 0.320311s

on_train_batch_end: 1615686539.905055s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.7810 - accuracy: 0.0412
on_train_batch_begin: 1615686539.905373s

16 step training time: 0.317586s

on_train_batch_end: 1615686540.220371s

17408/50000 [=========>....................] - ETA: 44s - loss: 8.7126 - accuracy: 0.0422
on_train_batch_begin: 1615686540.220688s

17 step training time: 0.315314s

on_train_batch_end: 1615686540.544846s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.6451 - accuracy: 0.0440
on_train_batch_begin: 1615686540.545168s

18 step training time: 0.324480s

on_train_batch_end: 1615686540.865828s

19456/50000 [==========>...................] - ETA: 38s - loss: 8.5905 - accuracy: 0.0452
on_train_batch_begin: 1615686540.866145s

19 step training time: 0.320977s

on_train_batch_end: 1615686541.179132s

20480/50000 [===========>..................] - ETA: 35s - loss: 8.5368 - accuracy: 0.0465
on_train_batch_begin: 1615686541.179476s

20 step training time: 0.313331s

on_train_batch_end: 1615686541.498211s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.4806 - accuracy: 0.0476
on_train_batch_begin: 1615686541.498543s

21 step training time: 0.319066s

on_train_batch_end: 1615686541.818501s

22528/50000 [============>.................] - ETA: 30s - loss: 8.4322 - accuracy: 0.0495
on_train_batch_begin: 1615686541.818819s

22 step training time: 0.320276s

on_train_batch_end: 1615686542.132913s

23552/50000 [=============>................] - ETA: 28s - loss: 8.3783 - accuracy: 0.0518
on_train_batch_begin: 1615686542.133229s

23 step training time: 0.314410s

on_train_batch_end: 1615686542.452138s

24576/50000 [=============>................] - ETA: 26s - loss: 8.3308 - accuracy: 0.0535
on_train_batch_begin: 1615686542.452463s

24 step training time: 0.319234s

on_train_batch_end: 1615686542.769209s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.2928 - accuracy: 0.0549
on_train_batch_begin: 1615686542.769523s

25 step training time: 0.317060s

on_train_batch_end: 1615686543.086985s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.2565 - accuracy: 0.0561
on_train_batch_begin: 1615686543.087303s

26 step training time: 0.317780s

on_train_batch_end: 1615686543.409228s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.2208 - accuracy: 0.0574
on_train_batch_begin: 1615686543.409540s

27 step training time: 0.322237s

on_train_batch_end: 1615686543.731866s

28672/50000 [================>.............] - ETA: 20s - loss: 8.1848 - accuracy: 0.0581
on_train_batch_begin: 1615686543.732186s

28 step training time: 0.322646s

on_train_batch_end: 1615686544.048087s

29696/50000 [================>.............] - ETA: 18s - loss: 8.1511 - accuracy: 0.0588
on_train_batch_begin: 1615686544.048405s

29 step training time: 0.316219s

on_train_batch_end: 1615686544.365801s

30720/50000 [=================>............] - ETA: 17s - loss: 8.1166 - accuracy: 0.0595
on_train_batch_begin: 1615686544.366107s

30 step training time: 0.317702s

on_train_batch_end: 1615686544.687286s

31744/50000 [==================>...........] - ETA: 16s - loss: 8.0846 - accuracy: 0.0600
on_train_batch_begin: 1615686544.687611s

31 step training time: 0.321504s

on_train_batch_end: 1615686545.008523s

32768/50000 [==================>...........] - ETA: 14s - loss: 8.0569 - accuracy: 0.0608
on_train_batch_begin: 1615686545.008828s

32 step training time: 0.321217s

on_train_batch_end: 1615686545.324376s

33792/50000 [===================>..........] - ETA: 13s - loss: 8.0301 - accuracy: 0.0616
on_train_batch_begin: 1615686545.324692s

33 step training time: 0.315864s

on_train_batch_end: 1615686545.646931s

34816/50000 [===================>..........] - ETA: 12s - loss: 8.0058 - accuracy: 0.0621
on_train_batch_begin: 1615686545.647231s

34 step training time: 0.322539s

on_train_batch_end: 1615686545.968043s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.9813 - accuracy: 0.0627
on_train_batch_begin: 1615686545.968353s

35 step training time: 0.321122s

on_train_batch_end: 1615686546.289022s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.9559 - accuracy: 0.0631
on_train_batch_begin: 1615686546.289324s

36 step training time: 0.320971s

on_train_batch_end: 1615686546.603117s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.9282 - accuracy: 0.0639 
on_train_batch_begin: 1615686546.603428s

37 step training time: 0.314104s

on_train_batch_end: 1615686546.923101s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.9039 - accuracy: 0.0648
on_train_batch_begin: 1615686546.923439s

38 step training time: 0.320011s

on_train_batch_end: 1615686547.246093s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.8789 - accuracy: 0.0655
on_train_batch_begin: 1615686547.246389s

39 step training time: 0.322949s

on_train_batch_end: 1615686547.566427s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.8543 - accuracy: 0.0660
on_train_batch_begin: 1615686547.566728s

40 step training time: 0.320339s

on_train_batch_end: 1615686547.881063s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.8308 - accuracy: 0.0660
on_train_batch_begin: 1615686547.881371s

41 step training time: 0.314643s

on_train_batch_end: 1615686548.202443s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.8060 - accuracy: 0.0668
on_train_batch_begin: 1615686548.202745s

42 step training time: 0.321374s

on_train_batch_end: 1615686548.524640s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.7849 - accuracy: 0.0673
on_train_batch_begin: 1615686548.524947s

43 step training time: 0.322201s

on_train_batch_end: 1615686548.843808s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.7692 - accuracy: 0.0675
on_train_batch_begin: 1615686548.844122s

44 step training time: 0.319175s

on_train_batch_end: 1615686549.160225s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.7474 - accuracy: 0.0680
on_train_batch_begin: 1615686549.160533s

45 step training time: 0.316411s

on_train_batch_end: 1615686549.481476s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.7280 - accuracy: 0.0681
on_train_batch_begin: 1615686549.481776s

46 step training time: 0.321244s

on_train_batch_end: 1615686549.805081s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.7092 - accuracy: 0.0680
on_train_batch_begin: 1615686549.805384s

47 step training time: 0.323607s

on_train_batch_end: 1615686550.125452s

49152/50000 [============================>.] - ETA: 0s - loss: 7.6913 - accuracy: 0.0679
on_train_batch_begin: 1615686550.125748s

48 step training time: 0.320364s

on_train_batch_end: 1615686555.750928s

on_test_batch_begin: 1615686555.938567s

49 step training time: 5.812819s

on_epoch_end: 1615686560.485598s

Validation time: 4.547016s

Real time: 1615686560.485598s

Epoch time: 43.849902868270874s

50000/50000 [==============================] - 44s 877us/sample - loss: 7.6754 - accuracy: 0.0680 - val_loss: 7.1221 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615686560.485800s

Real time: 1615686560.4858053
Epoch 2/5

on_train_batch_begin: 1615686560.489207s

on_train_batch_end: 1615686560.813278s

 1024/50000 [..............................] - ETA: 15s - loss: 6.7034 - accuracy: 0.0832
on_train_batch_begin: 1615686560.813576s

1 step training time: 0.324369s

on_train_batch_end: 1615686561.132685s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.7018 - accuracy: 0.0790
on_train_batch_begin: 1615686561.132981s

2 step training time: 0.319405s

on_train_batch_end: 1615686561.445921s

 3072/50000 [>.............................] - ETA: 14s - loss: 6.7348 - accuracy: 0.0807
on_train_batch_begin: 1615686561.446222s

3 step training time: 0.313241s

on_train_batch_end: 1615686561.767625s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.7339 - accuracy: 0.0785
on_train_batch_begin: 1615686561.767918s

4 step training time: 0.321696s

on_train_batch_end: 1615686562.089904s

 5120/50000 [==>...........................] - ETA: 14s - loss: 6.7364 - accuracy: 0.0793
on_train_batch_begin: 1615686562.090204s

5 step training time: 0.322286s

on_train_batch_end: 1615686562.409620s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.7673 - accuracy: 0.0787
on_train_batch_begin: 1615686562.409911s

6 step training time: 0.319707s

on_train_batch_end: 1615686562.728209s

 7168/50000 [===>..........................] - ETA: 13s - loss: 6.7585 - accuracy: 0.0775
on_train_batch_begin: 1615686562.728509s

7 step training time: 0.318599s

on_train_batch_end: 1615686563.047212s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.7460 - accuracy: 0.0799
on_train_batch_begin: 1615686563.047537s

8 step training time: 0.319028s

on_train_batch_end: 1615686563.369805s

 9216/50000 [====>.........................] - ETA: 12s - loss: 6.7333 - accuracy: 0.0801
on_train_batch_begin: 1615686563.370099s

9 step training time: 0.322562s

on_train_batch_end: 1615686563.689306s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.7242 - accuracy: 0.0807
on_train_batch_begin: 1615686563.689604s

10 step training time: 0.319505s

on_train_batch_end: 1615686564.003723s

11264/50000 [=====>........................] - ETA: 12s - loss: 6.7150 - accuracy: 0.0804
on_train_batch_begin: 1615686564.004027s

11 step training time: 0.314423s

on_train_batch_end: 1615686564.323077s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.7114 - accuracy: 0.0807
on_train_batch_begin: 1615686564.323351s

12 step training time: 0.319324s

on_train_batch_end: 1615686564.641568s

13312/50000 [======>.......................] - ETA: 11s - loss: 6.7098 - accuracy: 0.0800
on_train_batch_begin: 1615686564.641842s

13 step training time: 0.318491s

on_train_batch_end: 1615686564.958139s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.7162 - accuracy: 0.0809
on_train_batch_begin: 1615686564.958448s

14 step training time: 0.316605s

on_train_batch_end: 1615686565.276747s

15360/50000 [========>.....................] - ETA: 10s - loss: 6.7142 - accuracy: 0.0810
on_train_batch_begin: 1615686565.277043s

15 step training time: 0.318595s

on_train_batch_end: 1615686565.600986s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.7014 - accuracy: 0.0817
on_train_batch_begin: 1615686565.601273s

16 step training time: 0.324230s

on_train_batch_end: 1615686565.918105s

17408/50000 [=========>....................] - ETA: 10s - loss: 6.6998 - accuracy: 0.0818
on_train_batch_begin: 1615686565.918398s

17 step training time: 0.317125s

on_train_batch_end: 1615686566.221369s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.6969 - accuracy: 0.0821 
on_train_batch_begin: 1615686566.221667s

18 step training time: 0.303269s

on_train_batch_end: 1615686566.540385s

19456/50000 [==========>...................] - ETA: 9s - loss: 6.6918 - accuracy: 0.0822
on_train_batch_begin: 1615686566.540681s

19 step training time: 0.319014s

on_train_batch_end: 1615686566.861904s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.6944 - accuracy: 0.0828
on_train_batch_begin: 1615686566.862205s

20 step training time: 0.321524s

on_train_batch_end: 1615686567.180223s

21504/50000 [===========>..................] - ETA: 8s - loss: 6.6890 - accuracy: 0.0835
on_train_batch_begin: 1615686567.180529s

21 step training time: 0.318324s

on_train_batch_end: 1615686567.496701s

22528/50000 [============>.................] - ETA: 8s - loss: 6.6929 - accuracy: 0.0837
on_train_batch_begin: 1615686567.497014s

22 step training time: 0.316485s

on_train_batch_end: 1615686567.817055s

23552/50000 [=============>................] - ETA: 8s - loss: 6.6926 - accuracy: 0.0847
on_train_batch_begin: 1615686567.817382s

23 step training time: 0.320368s

on_train_batch_end: 1615686568.139336s

24576/50000 [=============>................] - ETA: 7s - loss: 6.6831 - accuracy: 0.0858
on_train_batch_begin: 1615686568.139685s

24 step training time: 0.322303s

on_train_batch_end: 1615686568.439809s

25600/50000 [==============>...............] - ETA: 7s - loss: 6.6867 - accuracy: 0.0858
on_train_batch_begin: 1615686568.440126s

25 step training time: 0.300442s

on_train_batch_end: 1615686568.757488s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.6798 - accuracy: 0.0861
on_train_batch_begin: 1615686568.757806s

26 step training time: 0.317680s

on_train_batch_end: 1615686569.078202s

27648/50000 [===============>..............] - ETA: 6s - loss: 6.6762 - accuracy: 0.0859
on_train_batch_begin: 1615686569.078520s

27 step training time: 0.320714s

on_train_batch_end: 1615686569.399763s

28672/50000 [================>.............] - ETA: 6s - loss: 6.6822 - accuracy: 0.0855
on_train_batch_begin: 1615686569.400085s

28 step training time: 0.321565s

on_train_batch_end: 1615686569.717465s

29696/50000 [================>.............] - ETA: 6s - loss: 6.6810 - accuracy: 0.0853
on_train_batch_begin: 1615686569.717793s

29 step training time: 0.317708s

on_train_batch_end: 1615686570.036265s

30720/50000 [=================>............] - ETA: 5s - loss: 6.6767 - accuracy: 0.0849
on_train_batch_begin: 1615686570.036581s

30 step training time: 0.318788s

on_train_batch_end: 1615686570.357711s

31744/50000 [==================>...........] - ETA: 5s - loss: 6.6756 - accuracy: 0.0841
on_train_batch_begin: 1615686570.358036s

31 step training time: 0.321455s

on_train_batch_end: 1615686570.678733s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.6711 - accuracy: 0.0832
on_train_batch_begin: 1615686570.679063s

32 step training time: 0.321027s

on_train_batch_end: 1615686570.999176s

33792/50000 [===================>..........] - ETA: 5s - loss: 6.6706 - accuracy: 0.0828
on_train_batch_begin: 1615686570.999513s

33 step training time: 0.320450s

on_train_batch_end: 1615686571.315837s

34816/50000 [===================>..........] - ETA: 4s - loss: 6.6658 - accuracy: 0.0827
on_train_batch_begin: 1615686571.316162s

34 step training time: 0.316650s

on_train_batch_end: 1615686571.635988s

35840/50000 [====================>.........] - ETA: 4s - loss: 6.6599 - accuracy: 0.0826
on_train_batch_begin: 1615686571.636302s

35 step training time: 0.320139s

on_train_batch_end: 1615686571.956868s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.6585 - accuracy: 0.0822
on_train_batch_begin: 1615686571.957189s

36 step training time: 0.320888s

on_train_batch_end: 1615686572.278833s

37888/50000 [=====================>........] - ETA: 3s - loss: 6.6547 - accuracy: 0.0825
on_train_batch_begin: 1615686572.279177s

37 step training time: 0.321988s

on_train_batch_end: 1615686572.596502s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.6514 - accuracy: 0.0825
on_train_batch_begin: 1615686572.596823s

38 step training time: 0.317647s

on_train_batch_end: 1615686572.915044s

39936/50000 [======================>.......] - ETA: 3s - loss: 6.6484 - accuracy: 0.0821
on_train_batch_begin: 1615686572.915415s

39 step training time: 0.318592s

on_train_batch_end: 1615686573.238274s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.6441 - accuracy: 0.0820
on_train_batch_begin: 1615686573.238588s

40 step training time: 0.323173s

on_train_batch_end: 1615686573.559588s

41984/50000 [========================>.....] - ETA: 2s - loss: 6.6371 - accuracy: 0.0818
on_train_batch_begin: 1615686573.559897s

41 step training time: 0.321309s

on_train_batch_end: 1615686573.883094s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.6333 - accuracy: 0.0816
on_train_batch_begin: 1615686573.883417s

42 step training time: 0.323520s

on_train_batch_end: 1615686574.200813s

44032/50000 [=========================>....] - ETA: 1s - loss: 6.6307 - accuracy: 0.0813
on_train_batch_begin: 1615686574.201105s

43 step training time: 0.317688s

on_train_batch_end: 1615686574.518663s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.6275 - accuracy: 0.0810
on_train_batch_begin: 1615686574.518956s

44 step training time: 0.317851s

on_train_batch_end: 1615686574.839433s

46080/50000 [==========================>...] - ETA: 1s - loss: 6.6254 - accuracy: 0.0808
on_train_batch_begin: 1615686574.839750s

45 step training time: 0.320795s

on_train_batch_end: 1615686575.160498s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.6238 - accuracy: 0.0806
on_train_batch_begin: 1615686575.160780s

46 step training time: 0.321030s

on_train_batch_end: 1615686575.478789s

48128/50000 [===========================>..] - ETA: 0s - loss: 6.6190 - accuracy: 0.0805
on_train_batch_begin: 1615686575.479055s

47 step training time: 0.318274s

on_train_batch_end: 1615686575.795879s

49152/50000 [============================>.] - ETA: 0s - loss: 6.6163 - accuracy: 0.0805
on_train_batch_begin: 1615686575.796140s

48 step training time: 0.317086s

on_train_batch_end: 1615686576.064587s

on_test_batch_begin: 1615686576.074820s

49 step training time: 0.278679s

on_epoch_end: 1615686576.841849s

Validation time: 0.767018s

Real time: 1615686576.841849s

Epoch time: 16.356061220169067s

50000/50000 [==============================] - 16s 327us/sample - loss: 6.6097 - accuracy: 0.0804 - val_loss: 7.3131 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615686576.842051s

Real time: 1615686576.842057
Epoch 3/5

on_train_batch_begin: 1615686576.845468s

on_train_batch_end: 1615686577.166889s

 1024/50000 [..............................] - ETA: 15s - loss: 6.4503 - accuracy: 0.0734
on_train_batch_begin: 1615686577.167195s

1 step training time: 0.321727s

on_train_batch_end: 1615686577.482798s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.4565 - accuracy: 0.0668
on_train_batch_begin: 1615686577.483090s

2 step training time: 0.315896s

on_train_batch_end: 1615686577.803331s

 3072/50000 [>.............................] - ETA: 14s - loss: 6.4296 - accuracy: 0.0663
on_train_batch_begin: 1615686577.803658s

3 step training time: 0.320568s

on_train_batch_end: 1615686578.126446s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.4006 - accuracy: 0.0657
on_train_batch_begin: 1615686578.126745s

4 step training time: 0.323087s

on_train_batch_end: 1615686578.446841s

 5120/50000 [==>...........................] - ETA: 14s - loss: 6.3885 - accuracy: 0.0624
on_train_batch_begin: 1615686578.447150s

5 step training time: 0.320405s

on_train_batch_end: 1615686578.768725s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.3784 - accuracy: 0.0618
on_train_batch_begin: 1615686578.769057s

6 step training time: 0.321907s

on_train_batch_end: 1615686579.088159s

 7168/50000 [===>..........................] - ETA: 13s - loss: 6.3535 - accuracy: 0.0606
on_train_batch_begin: 1615686579.088458s

7 step training time: 0.319402s

on_train_batch_end: 1615686579.406336s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.3463 - accuracy: 0.0603
on_train_batch_begin: 1615686579.406633s

8 step training time: 0.318175s

on_train_batch_end: 1615686579.726610s

 9216/50000 [====>.........................] - ETA: 12s - loss: 6.3329 - accuracy: 0.0603
on_train_batch_begin: 1615686579.726901s

9 step training time: 0.320268s

on_train_batch_end: 1615686580.048734s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.3147 - accuracy: 0.0587
on_train_batch_begin: 1615686580.049021s

10 step training time: 0.322120s

on_train_batch_end: 1615686580.369507s

11264/50000 [=====>........................] - ETA: 12s - loss: 6.2947 - accuracy: 0.0578
on_train_batch_begin: 1615686580.369791s

11 step training time: 0.320770s

on_train_batch_end: 1615686580.688178s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.2768 - accuracy: 0.0569
on_train_batch_begin: 1615686580.688477s

12 step training time: 0.318686s

on_train_batch_end: 1615686581.008126s

13312/50000 [======>.......................] - ETA: 11s - loss: 6.2741 - accuracy: 0.0560
on_train_batch_begin: 1615686581.008425s

13 step training time: 0.319948s

on_train_batch_end: 1615686581.329219s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.2531 - accuracy: 0.0558
on_train_batch_begin: 1615686581.329525s

14 step training time: 0.321100s

on_train_batch_end: 1615686581.652034s

15360/50000 [========>.....................] - ETA: 10s - loss: 6.2425 - accuracy: 0.0553
on_train_batch_begin: 1615686581.652333s

15 step training time: 0.322808s

on_train_batch_end: 1615686581.971561s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.2290 - accuracy: 0.0550
on_train_batch_begin: 1615686581.971848s

16 step training time: 0.319515s

on_train_batch_end: 1615686582.289360s

17408/50000 [=========>....................] - ETA: 10s - loss: 6.2112 - accuracy: 0.0551
on_train_batch_begin: 1615686582.289625s

17 step training time: 0.317777s

on_train_batch_end: 1615686582.607366s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.1968 - accuracy: 0.0549 
on_train_batch_begin: 1615686582.607671s

18 step training time: 0.318046s

on_train_batch_end: 1615686582.930874s

19456/50000 [==========>...................] - ETA: 9s - loss: 6.1723 - accuracy: 0.0548
on_train_batch_begin: 1615686582.931185s

19 step training time: 0.323514s

on_train_batch_end: 1615686583.253572s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.1398 - accuracy: 0.0553
on_train_batch_begin: 1615686583.253868s

20 step training time: 0.322683s

on_train_batch_end: 1615686583.573889s

21504/50000 [===========>..................] - ETA: 8s - loss: 6.1080 - accuracy: 0.0556
on_train_batch_begin: 1615686583.574174s

21 step training time: 0.320306s

on_train_batch_end: 1615686583.892934s

22528/50000 [============>.................] - ETA: 8s - loss: 6.0669 - accuracy: 0.0563
on_train_batch_begin: 1615686583.893228s

22 step training time: 0.319053s

on_train_batch_end: 1615686584.213998s

23552/50000 [=============>................] - ETA: 8s - loss: 6.0309 - accuracy: 0.0569
on_train_batch_begin: 1615686584.214291s

23 step training time: 0.321063s

on_train_batch_end: 1615686584.533174s

24576/50000 [=============>................] - ETA: 7s - loss: 5.9936 - accuracy: 0.0574
on_train_batch_begin: 1615686584.533451s

24 step training time: 0.319160s

on_train_batch_end: 1615686584.857484s

25600/50000 [==============>...............] - ETA: 7s - loss: 5.9546 - accuracy: 0.0580
on_train_batch_begin: 1615686584.857746s

25 step training time: 0.324296s

on_train_batch_end: 1615686585.179935s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.9064 - accuracy: 0.0589
on_train_batch_begin: 1615686585.180208s

26 step training time: 0.322462s

on_train_batch_end: 1615686585.504837s

27648/50000 [===============>..............] - ETA: 7s - loss: 5.8666 - accuracy: 0.0595
on_train_batch_begin: 1615686585.505101s

27 step training time: 0.324893s

on_train_batch_end: 1615686585.828914s

28672/50000 [================>.............] - ETA: 6s - loss: 5.8286 - accuracy: 0.0601
on_train_batch_begin: 1615686585.829229s

28 step training time: 0.324128s

on_train_batch_end: 1615686586.152854s

29696/50000 [================>.............] - ETA: 6s - loss: 5.7929 - accuracy: 0.0607
on_train_batch_begin: 1615686586.153155s

29 step training time: 0.323926s

on_train_batch_end: 1615686586.473749s

30720/50000 [=================>............] - ETA: 6s - loss: 5.7564 - accuracy: 0.0613
on_train_batch_begin: 1615686586.474043s

30 step training time: 0.320888s

on_train_batch_end: 1615686586.792733s

31744/50000 [==================>...........] - ETA: 5s - loss: 5.7178 - accuracy: 0.0619
on_train_batch_begin: 1615686586.793030s

31 step training time: 0.318986s

on_train_batch_end: 1615686587.112242s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.6825 - accuracy: 0.0625
on_train_batch_begin: 1615686587.112544s

32 step training time: 0.319514s

on_train_batch_end: 1615686587.434699s

33792/50000 [===================>..........] - ETA: 5s - loss: 5.6449 - accuracy: 0.0631
on_train_batch_begin: 1615686587.434996s

33 step training time: 0.322453s

on_train_batch_end: 1615686587.757020s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.5994 - accuracy: 0.0637
on_train_batch_begin: 1615686587.757317s

34 step training time: 0.322321s

on_train_batch_end: 1615686588.079333s

35840/50000 [====================>.........] - ETA: 4s - loss: 5.5626 - accuracy: 0.0643
on_train_batch_begin: 1615686588.079659s

35 step training time: 0.322342s

on_train_batch_end: 1615686588.404770s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.5284 - accuracy: 0.0648
on_train_batch_begin: 1615686588.405071s

36 step training time: 0.325412s

on_train_batch_end: 1615686588.728711s

37888/50000 [=====================>........] - ETA: 3s - loss: 5.4905 - accuracy: 0.0654
on_train_batch_begin: 1615686588.729034s

37 step training time: 0.323963s

on_train_batch_end: 1615686589.052824s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.4538 - accuracy: 0.0661
on_train_batch_begin: 1615686589.053131s

38 step training time: 0.324097s

on_train_batch_end: 1615686589.376439s

39936/50000 [======================>.......] - ETA: 3s - loss: 5.4193 - accuracy: 0.0666
on_train_batch_begin: 1615686589.376739s

39 step training time: 0.323607s

on_train_batch_end: 1615686589.697507s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.3861 - accuracy: 0.0672
on_train_batch_begin: 1615686589.697809s

40 step training time: 0.321071s

on_train_batch_end: 1615686590.017007s

41984/50000 [========================>.....] - ETA: 2s - loss: 5.3550 - accuracy: 0.0676
on_train_batch_begin: 1615686590.017305s

41 step training time: 0.319495s

on_train_batch_end: 1615686590.335881s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.3249 - accuracy: 0.0680
on_train_batch_begin: 1615686590.336180s

42 step training time: 0.318876s

on_train_batch_end: 1615686590.657167s

44032/50000 [=========================>....] - ETA: 1s - loss: 5.2900 - accuracy: 0.0686
on_train_batch_begin: 1615686590.657467s

43 step training time: 0.321286s

on_train_batch_end: 1615686590.979556s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.2560 - accuracy: 0.0691
on_train_batch_begin: 1615686590.979865s

44 step training time: 0.322398s

on_train_batch_end: 1615686591.301879s

46080/50000 [==========================>...] - ETA: 1s - loss: 5.2245 - accuracy: 0.0696
on_train_batch_begin: 1615686591.302182s

45 step training time: 0.322317s

on_train_batch_end: 1615686591.623324s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.1922 - accuracy: 0.0701
on_train_batch_begin: 1615686591.623649s

46 step training time: 0.321467s

on_train_batch_end: 1615686591.943754s

48128/50000 [===========================>..] - ETA: 0s - loss: 5.1587 - accuracy: 0.0706
on_train_batch_begin: 1615686591.944053s

47 step training time: 0.320404s

on_train_batch_end: 1615686592.263170s

49152/50000 [============================>.] - ETA: 0s - loss: 5.1320 - accuracy: 0.0711
on_train_batch_begin: 1615686592.263499s

48 step training time: 0.319446s

on_train_batch_end: 1615686592.533638s

on_test_batch_begin: 1615686592.546657s

49 step training time: 0.283157s

on_epoch_end: 1615686593.320822s

Validation time: 0.774148s

Real time: 1615686593.320822s

Epoch time: 16.478783130645752s

50000/50000 [==============================] - 16s 330us/sample - loss: 5.1074 - accuracy: 0.0714 - val_loss: 8.6257 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615686593.321036s

Real time: 1615686593.3210416
Epoch 4/5

on_train_batch_begin: 1615686593.324518s

on_train_batch_end: 1615686593.645751s

 1024/50000 [..............................] - ETA: 15s - loss: 3.6114 - accuracy: 0.0958
on_train_batch_begin: 1615686593.646075s

1 step training time: 0.321556s

on_train_batch_end: 1615686593.967825s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.4945 - accuracy: 0.0972
on_train_batch_begin: 1615686593.968140s

2 step training time: 0.322066s

on_train_batch_end: 1615686594.291203s

 3072/50000 [>.............................] - ETA: 14s - loss: 3.5422 - accuracy: 0.0965
on_train_batch_begin: 1615686594.291546s

3 step training time: 0.323406s

on_train_batch_end: 1615686594.611753s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.4594 - accuracy: 0.0971
on_train_batch_begin: 1615686594.612069s

4 step training time: 0.320522s

on_train_batch_end: 1615686594.935607s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.4252 - accuracy: 0.0972
on_train_batch_begin: 1615686594.935928s

5 step training time: 0.323859s

on_train_batch_end: 1615686595.260987s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.3789 - accuracy: 0.0970
on_train_batch_begin: 1615686595.261304s

6 step training time: 0.325376s

on_train_batch_end: 1615686595.585615s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.3158 - accuracy: 0.0969
on_train_batch_begin: 1615686595.585934s

7 step training time: 0.324630s

on_train_batch_end: 1615686595.908427s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.2357 - accuracy: 0.0970
on_train_batch_begin: 1615686595.908741s

8 step training time: 0.322807s

on_train_batch_end: 1615686596.233971s

 9216/50000 [====>.........................] - ETA: 12s - loss: 3.1930 - accuracy: 0.0971
on_train_batch_begin: 1615686596.234286s

9 step training time: 0.325545s

on_train_batch_end: 1615686596.558222s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.1447 - accuracy: 0.0972
on_train_batch_begin: 1615686596.558536s

10 step training time: 0.324250s

on_train_batch_end: 1615686596.881934s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.1119 - accuracy: 0.0972
on_train_batch_begin: 1615686596.882257s

11 step training time: 0.323721s

on_train_batch_end: 1615686597.208884s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.0739 - accuracy: 0.0973
on_train_batch_begin: 1615686597.209201s

12 step training time: 0.326944s

on_train_batch_end: 1615686597.534063s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.0278 - accuracy: 0.0975
on_train_batch_begin: 1615686597.534362s

13 step training time: 0.325161s

on_train_batch_end: 1615686597.857828s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.0061 - accuracy: 0.0976
on_train_batch_begin: 1615686597.858130s

14 step training time: 0.323769s

on_train_batch_end: 1615686598.184226s

15360/50000 [========>.....................] - ETA: 10s - loss: 2.9844 - accuracy: 0.0977
on_train_batch_begin: 1615686598.184532s

15 step training time: 0.326402s

on_train_batch_end: 1615686598.509703s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.9459 - accuracy: 0.0979
on_train_batch_begin: 1615686598.510009s

16 step training time: 0.325477s

on_train_batch_end: 1615686598.831119s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.9277 - accuracy: 0.0980
on_train_batch_begin: 1615686598.831438s

17 step training time: 0.321429s

on_train_batch_end: 1615686599.156012s

18432/50000 [==========>...................] - ETA: 9s - loss: 2.9009 - accuracy: 0.0981 
on_train_batch_begin: 1615686599.156311s

18 step training time: 0.324873s

on_train_batch_end: 1615686599.480539s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.8727 - accuracy: 0.0981
on_train_batch_begin: 1615686599.480849s

19 step training time: 0.324538s

on_train_batch_end: 1615686599.805208s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.8512 - accuracy: 0.0982
on_train_batch_begin: 1615686599.805507s

20 step training time: 0.324658s

on_train_batch_end: 1615686600.126660s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.8280 - accuracy: 0.0983
on_train_batch_begin: 1615686600.126962s

21 step training time: 0.321455s

on_train_batch_end: 1615686600.447504s

22528/50000 [============>.................] - ETA: 8s - loss: 2.8037 - accuracy: 0.0984
on_train_batch_begin: 1615686600.447806s

22 step training time: 0.320843s

on_train_batch_end: 1615686600.769278s

23552/50000 [=============>................] - ETA: 8s - loss: 2.7874 - accuracy: 0.0984
on_train_batch_begin: 1615686600.769575s

23 step training time: 0.321769s

on_train_batch_end: 1615686601.092026s

24576/50000 [=============>................] - ETA: 8s - loss: 2.7654 - accuracy: 0.0985
on_train_batch_begin: 1615686601.092323s

24 step training time: 0.322748s

on_train_batch_end: 1615686601.415410s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.7438 - accuracy: 0.0985
on_train_batch_begin: 1615686601.415710s

25 step training time: 0.323387s

on_train_batch_end: 1615686601.737693s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.7263 - accuracy: 0.0986
on_train_batch_begin: 1615686601.737994s

26 step training time: 0.322284s

on_train_batch_end: 1615686602.061886s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.7045 - accuracy: 0.0987
on_train_batch_begin: 1615686602.062200s

27 step training time: 0.324206s

on_train_batch_end: 1615686602.386328s

28672/50000 [================>.............] - ETA: 6s - loss: 2.6833 - accuracy: 0.0987
on_train_batch_begin: 1615686602.386756s

28 step training time: 0.324557s

on_train_batch_end: 1615686602.711486s

29696/50000 [================>.............] - ETA: 6s - loss: 2.6598 - accuracy: 0.0988
on_train_batch_begin: 1615686602.711787s

29 step training time: 0.325030s

on_train_batch_end: 1615686603.037519s

30720/50000 [=================>............] - ETA: 6s - loss: 2.6384 - accuracy: 0.0988
on_train_batch_begin: 1615686603.037830s

30 step training time: 0.326044s

on_train_batch_end: 1615686603.361682s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.6173 - accuracy: 0.0989
on_train_batch_begin: 1615686603.361987s

31 step training time: 0.324157s

on_train_batch_end: 1615686603.686459s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.5977 - accuracy: 0.0989
on_train_batch_begin: 1615686603.686779s

32 step training time: 0.324791s

on_train_batch_end: 1615686604.011811s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.5795 - accuracy: 0.0989
on_train_batch_begin: 1615686604.012112s

33 step training time: 0.325333s

on_train_batch_end: 1615686604.337314s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.5585 - accuracy: 0.0990
on_train_batch_begin: 1615686604.337621s

34 step training time: 0.325510s

on_train_batch_end: 1615686604.662652s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.5394 - accuracy: 0.0990
on_train_batch_begin: 1615686604.662950s

35 step training time: 0.325328s

on_train_batch_end: 1615686604.988159s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.5207 - accuracy: 0.0990
on_train_batch_begin: 1615686604.988463s

36 step training time: 0.325514s

on_train_batch_end: 1615686605.312641s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.5069 - accuracy: 0.0991
on_train_batch_begin: 1615686605.312944s

37 step training time: 0.324481s

on_train_batch_end: 1615686605.638825s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.4897 - accuracy: 0.0991
on_train_batch_begin: 1615686605.639138s

38 step training time: 0.326193s

on_train_batch_end: 1615686605.962274s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.4758 - accuracy: 0.0991
on_train_batch_begin: 1615686605.962570s

39 step training time: 0.323433s

on_train_batch_end: 1615686606.288147s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.4604 - accuracy: 0.0992
on_train_batch_begin: 1615686606.288443s

40 step training time: 0.325873s

on_train_batch_end: 1615686606.612506s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.4511 - accuracy: 0.0992
on_train_batch_begin: 1615686606.612796s

41 step training time: 0.324353s

on_train_batch_end: 1615686606.938395s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.4344 - accuracy: 0.0992
on_train_batch_begin: 1615686606.938693s

42 step training time: 0.325897s

on_train_batch_end: 1615686607.263160s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.4201 - accuracy: 0.0993
on_train_batch_begin: 1615686607.263486s

43 step training time: 0.324793s

on_train_batch_end: 1615686607.587986s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.4064 - accuracy: 0.0993
on_train_batch_begin: 1615686607.588283s

44 step training time: 0.324797s

on_train_batch_end: 1615686607.912571s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.3901 - accuracy: 0.0993
on_train_batch_begin: 1615686607.912879s

45 step training time: 0.324596s

on_train_batch_end: 1615686608.237258s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.3818 - accuracy: 0.0993
on_train_batch_begin: 1615686608.237560s

46 step training time: 0.324681s

on_train_batch_end: 1615686608.561180s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.3710 - accuracy: 0.0994
on_train_batch_begin: 1615686608.561477s

47 step training time: 0.323917s

on_train_batch_end: 1615686608.881541s

49152/50000 [============================>.] - ETA: 0s - loss: 2.3583 - accuracy: 0.0994
on_train_batch_begin: 1615686608.881838s

48 step training time: 0.320361s

on_train_batch_end: 1615686609.148367s

on_test_batch_begin: 1615686609.161559s

49 step training time: 0.279721s

on_epoch_end: 1615686609.929145s

Validation time: 0.767574s

Real time: 1615686609.929145s

Epoch time: 16.608120679855347s

50000/50000 [==============================] - 17s 332us/sample - loss: 2.3484 - accuracy: 0.0994 - val_loss: 7.2738 - val_accuracy: 0.0999

on_epoch_begin: 1615686609.929334s

Real time: 1615686609.929339
Epoch 5/5

on_train_batch_begin: 1615686609.932771s

on_train_batch_end: 1615686610.254033s

 1024/50000 [..............................] - ETA: 15s - loss: 1.6658 - accuracy: 0.1004
on_train_batch_begin: 1615686610.254331s

1 step training time: 0.321560s

on_train_batch_end: 1615686610.579080s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.6576 - accuracy: 0.1003
on_train_batch_begin: 1615686610.579376s

2 step training time: 0.325045s

on_train_batch_end: 1615686610.903219s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.6772 - accuracy: 0.1003
on_train_batch_begin: 1615686610.903528s

3 step training time: 0.324153s

on_train_batch_end: 1615686611.228215s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.6915 - accuracy: 0.1003
on_train_batch_begin: 1615686611.228518s

4 step training time: 0.324989s

on_train_batch_end: 1615686611.551959s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.7189 - accuracy: 0.1004
on_train_batch_begin: 1615686611.552258s

5 step training time: 0.323740s

on_train_batch_end: 1615686611.877628s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.7042 - accuracy: 0.1004
on_train_batch_begin: 1615686611.877930s

6 step training time: 0.325673s

on_train_batch_end: 1615686612.203261s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.6675 - accuracy: 0.1004
on_train_batch_begin: 1615686612.203583s

7 step training time: 0.325653s

on_train_batch_end: 1615686612.529339s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.6481 - accuracy: 0.1004
on_train_batch_begin: 1615686612.529635s

8 step training time: 0.326052s

on_train_batch_end: 1615686612.854598s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.6406 - accuracy: 0.1003
on_train_batch_begin: 1615686612.854898s

9 step training time: 0.325263s

on_train_batch_end: 1615686613.178468s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.6123 - accuracy: 0.1003
on_train_batch_begin: 1615686613.178762s

10 step training time: 0.323864s

on_train_batch_end: 1615686613.504347s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.6018 - accuracy: 0.1003
on_train_batch_begin: 1615686613.504645s

11 step training time: 0.325883s

on_train_batch_end: 1615686613.829093s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.5865 - accuracy: 0.1003
on_train_batch_begin: 1615686613.829392s

12 step training time: 0.324747s

on_train_batch_end: 1615686614.155245s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.5714 - accuracy: 0.1003
on_train_batch_begin: 1615686614.155574s

13 step training time: 0.326181s

on_train_batch_end: 1615686614.479899s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.5678 - accuracy: 0.1003
on_train_batch_begin: 1615686614.480227s

14 step training time: 0.324654s

on_train_batch_end: 1615686614.803879s

15360/50000 [========>.....................] - ETA: 10s - loss: 1.5538 - accuracy: 0.1003
on_train_batch_begin: 1615686614.804213s

15 step training time: 0.323985s

on_train_batch_end: 1615686615.129751s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.5499 - accuracy: 0.1003
on_train_batch_begin: 1615686615.130062s

16 step training time: 0.325850s

on_train_batch_end: 1615686615.455155s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.5411 - accuracy: 0.1003
on_train_batch_begin: 1615686615.455497s

17 step training time: 0.325435s

on_train_batch_end: 1615686615.780543s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.5327 - accuracy: 0.1002
on_train_batch_begin: 1615686615.780867s

18 step training time: 0.325370s

on_train_batch_end: 1615686616.106542s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.5221 - accuracy: 0.1003 
on_train_batch_begin: 1615686616.106863s

19 step training time: 0.325996s

on_train_batch_end: 1615686616.430128s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.5186 - accuracy: 0.1003
on_train_batch_begin: 1615686616.430443s

20 step training time: 0.323580s

on_train_batch_end: 1615686616.754095s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.5170 - accuracy: 0.1002
on_train_batch_begin: 1615686616.754411s

21 step training time: 0.323969s

on_train_batch_end: 1615686617.078735s

22528/50000 [============>.................] - ETA: 8s - loss: 1.5172 - accuracy: 0.1002
on_train_batch_begin: 1615686617.079051s

22 step training time: 0.324640s

on_train_batch_end: 1615686617.405289s

23552/50000 [=============>................] - ETA: 8s - loss: 1.5179 - accuracy: 0.1003
on_train_batch_begin: 1615686617.405600s

23 step training time: 0.326548s

on_train_batch_end: 1615686617.731418s

24576/50000 [=============>................] - ETA: 8s - loss: 1.5152 - accuracy: 0.1003
on_train_batch_begin: 1615686617.731715s

24 step training time: 0.326115s

on_train_batch_end: 1615686618.055602s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.5167 - accuracy: 0.1003
on_train_batch_begin: 1615686618.055904s

25 step training time: 0.324189s

on_train_batch_end: 1615686618.379789s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.5136 - accuracy: 0.1003
on_train_batch_begin: 1615686618.380088s

26 step training time: 0.324184s

on_train_batch_end: 1615686618.704691s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.5144 - accuracy: 0.1003
on_train_batch_begin: 1615686618.704994s

27 step training time: 0.324906s

on_train_batch_end: 1615686619.028231s

28672/50000 [================>.............] - ETA: 6s - loss: 1.5117 - accuracy: 0.1003
on_train_batch_begin: 1615686619.028534s

28 step training time: 0.323539s

on_train_batch_end: 1615686619.354624s

29696/50000 [================>.............] - ETA: 6s - loss: 1.5144 - accuracy: 0.1003
on_train_batch_begin: 1615686619.354926s

29 step training time: 0.326392s

on_train_batch_end: 1615686619.680837s

30720/50000 [=================>............] - ETA: 6s - loss: 1.5131 - accuracy: 0.1003
on_train_batch_begin: 1615686619.681145s

30 step training time: 0.326219s

on_train_batch_end: 1615686620.007358s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.5074 - accuracy: 0.1003
on_train_batch_begin: 1615686620.007686s

31 step training time: 0.326541s

on_train_batch_end: 1615686620.328249s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.5049 - accuracy: 0.1003
on_train_batch_begin: 1615686620.328549s

32 step training time: 0.320863s

on_train_batch_end: 1615686620.651943s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.5021 - accuracy: 0.1003
on_train_batch_begin: 1615686620.652242s

33 step training time: 0.323693s

on_train_batch_end: 1615686620.976681s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.4992 - accuracy: 0.1003
on_train_batch_begin: 1615686620.976984s

34 step training time: 0.324742s

on_train_batch_end: 1615686621.299155s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.4962 - accuracy: 0.1003
on_train_batch_begin: 1615686621.299479s

35 step training time: 0.322496s

on_train_batch_end: 1615686621.621495s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.4913 - accuracy: 0.1003
on_train_batch_begin: 1615686621.621808s

36 step training time: 0.322328s

on_train_batch_end: 1615686621.942576s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.4850 - accuracy: 0.1003
on_train_batch_begin: 1615686621.942882s

37 step training time: 0.321074s

on_train_batch_end: 1615686622.266454s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.4836 - accuracy: 0.1003
on_train_batch_begin: 1615686622.266765s

38 step training time: 0.323883s

on_train_batch_end: 1615686622.587577s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.4738 - accuracy: 0.1003
on_train_batch_begin: 1615686622.587883s

39 step training time: 0.321118s

on_train_batch_end: 1615686622.911958s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.4716 - accuracy: 0.1003
on_train_batch_begin: 1615686622.912261s

40 step training time: 0.324378s

on_train_batch_end: 1615686623.234941s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.4692 - accuracy: 0.1003
on_train_batch_begin: 1615686623.235252s

41 step training time: 0.322991s

on_train_batch_end: 1615686623.558792s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.4682 - accuracy: 0.1003
on_train_batch_begin: 1615686623.559103s

42 step training time: 0.323851s

on_train_batch_end: 1615686623.882420s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.4655 - accuracy: 0.1003
on_train_batch_begin: 1615686623.882728s

43 step training time: 0.323625s

on_train_batch_end: 1615686624.207235s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.4579 - accuracy: 0.1003
on_train_batch_begin: 1615686624.207580s

44 step training time: 0.324852s

on_train_batch_end: 1615686624.532681s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.4550 - accuracy: 0.1003
on_train_batch_begin: 1615686624.533003s

45 step training time: 0.325423s

on_train_batch_end: 1615686624.856460s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.4503 - accuracy: 0.1003
on_train_batch_begin: 1615686624.856771s

46 step training time: 0.323768s

on_train_batch_end: 1615686625.180705s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.4483 - accuracy: 0.1003
on_train_batch_begin: 1615686625.181001s

47 step training time: 0.324230s

on_train_batch_end: 1615686625.505876s

49152/50000 [============================>.] - ETA: 0s - loss: 1.4438 - accuracy: 0.1003
on_train_batch_begin: 1615686625.506176s

48 step training time: 0.325175s

on_train_batch_end: 1615686625.778502s

on_test_batch_begin: 1615686625.792135s

49 step training time: 0.285958s

on_epoch_end: 1615686626.569448s

Validation time: 0.777297s

Real time: 1615686626.569448s

Epoch time: 16.640127420425415s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.4426 - accuracy: 0.1003 - val_loss: 7.2120 - val_accuracy: 0.0999
Tempo do fit: 113.37150931358337