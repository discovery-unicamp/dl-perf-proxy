wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:32
   204800/170498071 [..............................] - ETA: 1:15
  1351680/170498071 [..............................] - ETA: 17s 
  4235264/170498071 [..............................] - ETA: 7s 
  7757824/170498071 [>.............................] - ETA: 5s
 11116544/170498071 [>.............................] - ETA: 4s
 14442496/170498071 [=>............................] - ETA: 3s
 17965056/170498071 [==>...........................] - ETA: 3s
 21504000/170498071 [==>...........................] - ETA: 3s
 25026560/170498071 [===>..........................] - ETA: 2s
 28352512/170498071 [===>..........................] - ETA: 2s
 31629312/170498071 [====>.........................] - ETA: 2s
 35053568/170498071 [=====>........................] - ETA: 2s
 38559744/170498071 [=====>........................] - ETA: 2s
 42098688/170498071 [======>.......................] - ETA: 2s
 45539328/170498071 [=======>......................] - ETA: 2s
 48734208/170498071 [=======>......................] - ETA: 2s
 52043776/170498071 [========>.....................] - ETA: 2s
 55533568/170498071 [========>.....................] - ETA: 1s
 58990592/170498071 [=========>....................] - ETA: 1s
 62513152/170498071 [=========>....................] - ETA: 1s
 65888256/170498071 [==========>...................] - ETA: 1s
 69148672/170498071 [===========>..................] - ETA: 1s
 72556544/170498071 [===========>..................] - ETA: 1s
 76013568/170498071 [============>.................] - ETA: 1s
 79503360/170498071 [============>.................] - ETA: 1s
 82976768/170498071 [=============>................] - ETA: 1s
 86269952/170498071 [==============>...............] - ETA: 1s
 89513984/170498071 [==============>...............] - ETA: 1s
 92839936/170498071 [===============>..............] - ETA: 1s
 96346112/170498071 [===============>..............] - ETA: 1s
 99868672/170498071 [================>.............] - ETA: 1s
103374848/170498071 [=================>............] - ETA: 1s
106635264/170498071 [=================>............] - ETA: 1s
109879296/170498071 [==================>...........] - ETA: 0s
113254400/170498071 [==================>...........] - ETA: 0s
116711424/170498071 [===================>..........] - ETA: 0s
120233984/170498071 [====================>.........] - ETA: 0s
123740160/170498071 [====================>.........] - ETA: 0s
127000576/170498071 [=====================>........] - ETA: 0s
130293760/170498071 [=====================>........] - ETA: 0s
133636096/170498071 [======================>.......] - ETA: 0s
137142272/170498071 [=======================>......] - ETA: 0s
140599296/170498071 [=======================>......] - ETA: 0s
144072704/170498071 [========================>.....] - ETA: 0s
147300352/170498071 [========================>.....] - ETA: 0s
150560768/170498071 [=========================>....] - ETA: 0s
153903104/170498071 [==========================>...] - ETA: 0s
157327360/170498071 [==========================>...] - ETA: 0s
160768000/170498071 [===========================>..] - ETA: 0s
164241408/170498071 [===========================>..] - ETA: 0s
167649280/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 5054464/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
14909440/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
25927680/94765736 [=======>......................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
29507584/94765736 [========>.....................] - ETA: 1s
35676160/94765736 [==========>...................] - ETA: 1s
40394752/94765736 [===========>..................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 0s
53772288/94765736 [================>.............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
62562304/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
74145792/94765736 [======================>.......] - ETA: 0s
76619776/94765736 [=======================>......] - ETA: 0s
78741504/94765736 [=======================>......] - ETA: 0s
84647936/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
91455488/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.106999397277832
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615760107.182836s

Real time: 1615760107.1828527
Epoch 1/5

on_train_batch_begin: 1615760107.939847s

on_train_batch_end: 1615760124.932678s

 1024/50000 [..............................] - ETA: 14:08 - loss: 17.9612 - accuracy: 3.0899e-04
on_train_batch_begin: 1615760124.933347s

1 step training time: 16.993499s

on_train_batch_end: 1615760125.254441s

 2048/50000 [>.............................] - ETA: 7:03 - loss: 15.3529 - accuracy: 3.4380e-04 
on_train_batch_begin: 1615760125.254828s

2 step training time: 0.321482s

on_train_batch_end: 1615760125.572209s

 3072/50000 [>.............................] - ETA: 4:40 - loss: 13.2783 - accuracy: 3.2679e-04
on_train_batch_begin: 1615760125.572560s

3 step training time: 0.317732s

on_train_batch_end: 1615760125.894086s

 4096/50000 [=>............................] - ETA: 3:29 - loss: 12.0954 - accuracy: 0.0012    
on_train_batch_begin: 1615760125.894394s

4 step training time: 0.321835s

on_train_batch_end: 1615760126.222185s

 5120/50000 [==>...........................] - ETA: 2:46 - loss: 11.2883 - accuracy: 0.0027
on_train_batch_begin: 1615760126.222486s

5 step training time: 0.328091s

on_train_batch_end: 1615760126.538218s

 6144/50000 [==>...........................] - ETA: 2:18 - loss: 10.7179 - accuracy: 0.0058
on_train_batch_begin: 1615760126.538507s

6 step training time: 0.316021s

on_train_batch_end: 1615760126.852662s

 7168/50000 [===>..........................] - ETA: 1:57 - loss: 10.3070 - accuracy: 0.0083
on_train_batch_begin: 1615760126.852964s

7 step training time: 0.314458s

on_train_batch_end: 1615760127.174202s

 8192/50000 [===>..........................] - ETA: 1:42 - loss: 9.9821 - accuracy: 0.0125 
on_train_batch_begin: 1615760127.174509s

8 step training time: 0.321545s

on_train_batch_end: 1615760127.489667s

 9216/50000 [====>.........................] - ETA: 1:29 - loss: 9.7442 - accuracy: 0.0150
on_train_batch_begin: 1615760127.489960s

9 step training time: 0.315451s

on_train_batch_end: 1615760127.806740s

10240/50000 [=====>........................] - ETA: 1:20 - loss: 9.5393 - accuracy: 0.0186
on_train_batch_begin: 1615760127.807047s

10 step training time: 0.317087s

on_train_batch_end: 1615760128.126066s

11264/50000 [=====>........................] - ETA: 1:12 - loss: 9.3684 - accuracy: 0.0219
on_train_batch_begin: 1615760128.126360s

11 step training time: 0.319313s

on_train_batch_end: 1615760128.439024s

12288/50000 [======>.......................] - ETA: 1:05 - loss: 9.2248 - accuracy: 0.0251
on_train_batch_begin: 1615760128.439324s

12 step training time: 0.312964s

on_train_batch_end: 1615760128.760603s

13312/50000 [======>.......................] - ETA: 59s - loss: 9.1087 - accuracy: 0.0270 
on_train_batch_begin: 1615760128.760907s

13 step training time: 0.321583s

on_train_batch_end: 1615760129.083005s

14336/50000 [=======>......................] - ETA: 54s - loss: 8.9959 - accuracy: 0.0308
on_train_batch_begin: 1615760129.083327s

14 step training time: 0.322421s

on_train_batch_end: 1615760129.398058s

15360/50000 [========>.....................] - ETA: 50s - loss: 8.8841 - accuracy: 0.0334
on_train_batch_begin: 1615760129.398368s

15 step training time: 0.315041s

on_train_batch_end: 1615760129.712775s

16384/50000 [========>.....................] - ETA: 46s - loss: 8.7975 - accuracy: 0.0357
on_train_batch_begin: 1615760129.713079s

16 step training time: 0.314711s

on_train_batch_end: 1615760130.031327s

17408/50000 [=========>....................] - ETA: 42s - loss: 8.7013 - accuracy: 0.0383
on_train_batch_begin: 1615760130.031628s

17 step training time: 0.318549s

on_train_batch_end: 1615760130.346324s

18432/50000 [==========>...................] - ETA: 39s - loss: 8.6209 - accuracy: 0.0404
on_train_batch_begin: 1615760130.346623s

18 step training time: 0.314995s

on_train_batch_end: 1615760130.664778s

19456/50000 [==========>...................] - ETA: 36s - loss: 8.5446 - accuracy: 0.0422
on_train_batch_begin: 1615760130.665081s

19 step training time: 0.318457s

on_train_batch_end: 1615760130.985919s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.4671 - accuracy: 0.0444
on_train_batch_begin: 1615760130.986221s

20 step training time: 0.321141s

on_train_batch_end: 1615760131.298992s

21504/50000 [===========>..................] - ETA: 31s - loss: 8.4057 - accuracy: 0.0464
on_train_batch_begin: 1615760131.299297s

21 step training time: 0.313076s

on_train_batch_end: 1615760131.620322s

22528/50000 [============>.................] - ETA: 29s - loss: 8.3480 - accuracy: 0.0479
on_train_batch_begin: 1615760131.620623s

22 step training time: 0.321326s

on_train_batch_end: 1615760131.935725s

23552/50000 [=============>................] - ETA: 27s - loss: 8.2852 - accuracy: 0.0494
on_train_batch_begin: 1615760131.936032s

23 step training time: 0.315409s

on_train_batch_end: 1615760132.252701s

24576/50000 [=============>................] - ETA: 25s - loss: 8.2232 - accuracy: 0.0509
on_train_batch_begin: 1615760132.253005s

24 step training time: 0.316973s

on_train_batch_end: 1615760132.574111s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.1729 - accuracy: 0.0526
on_train_batch_begin: 1615760132.574410s

25 step training time: 0.321405s

on_train_batch_end: 1615760132.887213s

26624/50000 [==============>...............] - ETA: 22s - loss: 8.1188 - accuracy: 0.0538
on_train_batch_begin: 1615760132.887517s

26 step training time: 0.313107s

on_train_batch_end: 1615760133.205176s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.0726 - accuracy: 0.0546
on_train_batch_begin: 1615760133.205503s

27 step training time: 0.317986s

on_train_batch_end: 1615760133.526060s

28672/50000 [================>.............] - ETA: 19s - loss: 8.0226 - accuracy: 0.0558
on_train_batch_begin: 1615760133.526363s

28 step training time: 0.320860s

on_train_batch_end: 1615760133.839329s

29696/50000 [================>.............] - ETA: 18s - loss: 7.9766 - accuracy: 0.0566
on_train_batch_begin: 1615760133.839638s

29 step training time: 0.313275s

on_train_batch_end: 1615760134.158085s

30720/50000 [=================>............] - ETA: 16s - loss: 7.9275 - accuracy: 0.0575
on_train_batch_begin: 1615760134.158387s

30 step training time: 0.318749s

on_train_batch_end: 1615760134.475412s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.8807 - accuracy: 0.0580
on_train_batch_begin: 1615760134.475718s

31 step training time: 0.317330s

on_train_batch_end: 1615760134.793164s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.8328 - accuracy: 0.0584
on_train_batch_begin: 1615760134.793493s

32 step training time: 0.317775s

on_train_batch_end: 1615760135.112813s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.7781 - accuracy: 0.0587
on_train_batch_begin: 1615760135.113121s

33 step training time: 0.319628s

on_train_batch_end: 1615760135.429858s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.7333 - accuracy: 0.0590
on_train_batch_begin: 1615760135.430144s

34 step training time: 0.317023s

on_train_batch_end: 1615760135.745265s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.6842 - accuracy: 0.0595
on_train_batch_begin: 1615760135.745572s

35 step training time: 0.315428s

on_train_batch_end: 1615760136.065288s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.6362 - accuracy: 0.0601
on_train_batch_begin: 1615760136.065610s

36 step training time: 0.320038s

on_train_batch_end: 1615760136.380389s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.5823 - accuracy: 0.0603 
on_train_batch_begin: 1615760136.380679s

37 step training time: 0.315069s

on_train_batch_end: 1615760136.698430s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.5338 - accuracy: 0.0607
on_train_batch_begin: 1615760136.698720s

38 step training time: 0.318040s

on_train_batch_end: 1615760137.016618s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.4896 - accuracy: 0.0607
on_train_batch_begin: 1615760137.016908s

39 step training time: 0.318189s

on_train_batch_end: 1615760137.330989s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.4476 - accuracy: 0.0610
on_train_batch_begin: 1615760137.331283s

40 step training time: 0.314374s

on_train_batch_end: 1615760137.652698s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.4030 - accuracy: 0.0615
on_train_batch_begin: 1615760137.652994s

41 step training time: 0.321711s

on_train_batch_end: 1615760137.967006s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.3616 - accuracy: 0.0619
on_train_batch_begin: 1615760137.967304s

42 step training time: 0.314310s

on_train_batch_end: 1615760138.284842s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.3202 - accuracy: 0.0623
on_train_batch_begin: 1615760138.285127s

43 step training time: 0.317824s

on_train_batch_end: 1615760138.606621s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.2790 - accuracy: 0.0626
on_train_batch_begin: 1615760138.606910s

44 step training time: 0.321783s

on_train_batch_end: 1615760138.920067s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.2449 - accuracy: 0.0629
on_train_batch_begin: 1615760138.920373s

45 step training time: 0.313463s

on_train_batch_end: 1615760139.240362s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.2031 - accuracy: 0.0633
on_train_batch_begin: 1615760139.240664s

46 step training time: 0.320291s

on_train_batch_end: 1615760139.559033s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.1666 - accuracy: 0.0636
on_train_batch_begin: 1615760139.559338s

47 step training time: 0.318674s

on_train_batch_end: 1615760139.873919s

49152/50000 [============================>.] - ETA: 0s - loss: 7.1270 - accuracy: 0.0638
on_train_batch_begin: 1615760139.874224s

48 step training time: 0.314886s

on_train_batch_end: 1615760145.552125s

on_test_batch_begin: 1615760145.741340s

49 step training time: 5.867116s

on_epoch_end: 1615760150.461790s

Validation time: 4.720433s

Real time: 1615760150.461790s

Epoch time: 43.27895903587341s

50000/50000 [==============================] - 43s 866us/sample - loss: 7.0974 - accuracy: 0.0640 - val_loss: 431025.8008 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615760150.462016s

Real time: 1615760150.4620214
Epoch 2/5

on_train_batch_begin: 1615760150.465505s

on_train_batch_end: 1615760150.784248s

 1024/50000 [..............................] - ETA: 15s - loss: 5.1902 - accuracy: 0.0788
on_train_batch_begin: 1615760150.784519s

1 step training time: 0.319013s

on_train_batch_end: 1615760151.105162s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.1970 - accuracy: 0.0779
on_train_batch_begin: 1615760151.105458s

2 step training time: 0.320939s

on_train_batch_end: 1615760151.421671s

 3072/50000 [>.............................] - ETA: 14s - loss: 5.2583 - accuracy: 0.0798
on_train_batch_begin: 1615760151.421946s

3 step training time: 0.316488s

on_train_batch_end: 1615760151.740283s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.1843 - accuracy: 0.0806
on_train_batch_begin: 1615760151.740556s

4 step training time: 0.318610s

on_train_batch_end: 1615760152.052963s

 5120/50000 [==>...........................] - ETA: 13s - loss: 5.2204 - accuracy: 0.0805
on_train_batch_begin: 1615760152.053256s

5 step training time: 0.312700s

on_train_batch_end: 1615760152.370112s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.2084 - accuracy: 0.0819
on_train_batch_begin: 1615760152.370397s

6 step training time: 0.317141s

on_train_batch_end: 1615760152.690077s

 7168/50000 [===>..........................] - ETA: 13s - loss: 5.2148 - accuracy: 0.0823
on_train_batch_begin: 1615760152.690358s

7 step training time: 0.319961s

on_train_batch_end: 1615760153.010047s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.2012 - accuracy: 0.0824
on_train_batch_begin: 1615760153.010331s

8 step training time: 0.319973s

on_train_batch_end: 1615760153.326118s

 9216/50000 [====>.........................] - ETA: 12s - loss: 5.1894 - accuracy: 0.0815
on_train_batch_begin: 1615760153.326401s

9 step training time: 0.316070s

on_train_batch_end: 1615760153.646370s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.1885 - accuracy: 0.0811
on_train_batch_begin: 1615760153.646661s

10 step training time: 0.320259s

on_train_batch_end: 1615760153.970244s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.1902 - accuracy: 0.0813
on_train_batch_begin: 1615760153.970536s

11 step training time: 0.323876s

on_train_batch_end: 1615760154.289430s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.1799 - accuracy: 0.0816
on_train_batch_begin: 1615760154.289711s

12 step training time: 0.319175s

on_train_batch_end: 1615760154.604686s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.1738 - accuracy: 0.0820
on_train_batch_begin: 1615760154.604962s

13 step training time: 0.315251s

on_train_batch_end: 1615760154.925970s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.1709 - accuracy: 0.0817
on_train_batch_begin: 1615760154.926259s

14 step training time: 0.321297s

on_train_batch_end: 1615760155.230597s

15360/50000 [========>.....................] - ETA: 10s - loss: 5.1449 - accuracy: 0.0816
on_train_batch_begin: 1615760155.230887s

15 step training time: 0.304628s

on_train_batch_end: 1615760155.558178s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.1272 - accuracy: 0.0820
on_train_batch_begin: 1615760155.558471s

16 step training time: 0.327584s

on_train_batch_end: 1615760155.881400s

17408/50000 [=========>....................] - ETA: 10s - loss: 5.1213 - accuracy: 0.0821
on_train_batch_begin: 1615760155.881705s

17 step training time: 0.323234s

on_train_batch_end: 1615760156.204185s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.1084 - accuracy: 0.0822 
on_train_batch_begin: 1615760156.204492s

18 step training time: 0.322787s

on_train_batch_end: 1615760156.521811s

19456/50000 [==========>...................] - ETA: 9s - loss: 5.0912 - accuracy: 0.0822
on_train_batch_begin: 1615760156.522107s

19 step training time: 0.317615s

on_train_batch_end: 1615760156.837093s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.0727 - accuracy: 0.0825
on_train_batch_begin: 1615760156.837424s

20 step training time: 0.315316s

on_train_batch_end: 1615760157.161606s

21504/50000 [===========>..................] - ETA: 8s - loss: 5.0543 - accuracy: 0.0826
on_train_batch_begin: 1615760157.161902s

21 step training time: 0.324478s

on_train_batch_end: 1615760157.483617s

22528/50000 [============>.................] - ETA: 8s - loss: 5.0432 - accuracy: 0.0826
on_train_batch_begin: 1615760157.484000s

22 step training time: 0.322098s

on_train_batch_end: 1615760157.807881s

23552/50000 [=============>................] - ETA: 8s - loss: 5.0372 - accuracy: 0.0827
on_train_batch_begin: 1615760157.808223s

23 step training time: 0.324223s

on_train_batch_end: 1615760158.129942s

24576/50000 [=============>................] - ETA: 7s - loss: 5.0215 - accuracy: 0.0826
on_train_batch_begin: 1615760158.130239s

24 step training time: 0.322016s

on_train_batch_end: 1615760158.448307s

25600/50000 [==============>...............] - ETA: 7s - loss: 5.0081 - accuracy: 0.0823
on_train_batch_begin: 1615760158.448597s

25 step training time: 0.318357s

on_train_batch_end: 1615760158.766882s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.0006 - accuracy: 0.0821
on_train_batch_begin: 1615760158.767171s

26 step training time: 0.318574s

on_train_batch_end: 1615760159.088710s

27648/50000 [===============>..............] - ETA: 6s - loss: 4.9870 - accuracy: 0.0820
on_train_batch_begin: 1615760159.089009s

27 step training time: 0.321838s

on_train_batch_end: 1615760159.411558s

28672/50000 [================>.............] - ETA: 6s - loss: 4.9772 - accuracy: 0.0816
on_train_batch_begin: 1615760159.411857s

28 step training time: 0.322848s

on_train_batch_end: 1615760159.734743s

29696/50000 [================>.............] - ETA: 6s - loss: 4.9699 - accuracy: 0.0814
on_train_batch_begin: 1615760159.735036s

29 step training time: 0.323179s

on_train_batch_end: 1615760160.055418s

30720/50000 [=================>............] - ETA: 6s - loss: 4.9566 - accuracy: 0.0810
on_train_batch_begin: 1615760160.055719s

30 step training time: 0.320683s

on_train_batch_end: 1615760160.372077s

31744/50000 [==================>...........] - ETA: 5s - loss: 4.9453 - accuracy: 0.0808
on_train_batch_begin: 1615760160.372390s

31 step training time: 0.316671s

on_train_batch_end: 1615760160.692477s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.9300 - accuracy: 0.0807
on_train_batch_begin: 1615760160.692776s

32 step training time: 0.320387s

on_train_batch_end: 1615760161.014742s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.9163 - accuracy: 0.0806
on_train_batch_begin: 1615760161.015043s

33 step training time: 0.322266s

on_train_batch_end: 1615760161.338395s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.9054 - accuracy: 0.0803
on_train_batch_begin: 1615760161.338701s

34 step training time: 0.323658s

on_train_batch_end: 1615760161.657014s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.8919 - accuracy: 0.0800
on_train_batch_begin: 1615760161.657337s

35 step training time: 0.318636s

on_train_batch_end: 1615760161.975394s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.8784 - accuracy: 0.0798
on_train_batch_begin: 1615760161.975702s

36 step training time: 0.318365s

on_train_batch_end: 1615760162.296802s

37888/50000 [=====================>........] - ETA: 3s - loss: 4.8631 - accuracy: 0.0796
on_train_batch_begin: 1615760162.297112s

37 step training time: 0.321410s

on_train_batch_end: 1615760162.618905s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.8455 - accuracy: 0.0794
on_train_batch_begin: 1615760162.619197s

38 step training time: 0.322084s

on_train_batch_end: 1615760162.940774s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.8275 - accuracy: 0.0793
on_train_batch_begin: 1615760162.941032s

39 step training time: 0.321835s

on_train_batch_end: 1615760163.258591s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.8113 - accuracy: 0.0791
on_train_batch_begin: 1615760163.258896s

40 step training time: 0.317864s

on_train_batch_end: 1615760163.577070s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.7965 - accuracy: 0.0788
on_train_batch_begin: 1615760163.577390s

41 step training time: 0.318494s

on_train_batch_end: 1615760163.898770s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.7874 - accuracy: 0.0786
on_train_batch_begin: 1615760163.899074s

42 step training time: 0.321684s

on_train_batch_end: 1615760164.221532s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.7701 - accuracy: 0.0785
on_train_batch_begin: 1615760164.221838s

43 step training time: 0.322764s

on_train_batch_end: 1615760164.546186s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.7586 - accuracy: 0.0783
on_train_batch_begin: 1615760164.546497s

44 step training time: 0.324659s

on_train_batch_end: 1615760164.871177s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.7468 - accuracy: 0.0782
on_train_batch_begin: 1615760164.871482s

45 step training time: 0.324984s

on_train_batch_end: 1615760165.195049s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.7332 - accuracy: 0.0781
on_train_batch_begin: 1615760165.195357s

46 step training time: 0.323875s

on_train_batch_end: 1615760165.518379s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.7185 - accuracy: 0.0781
on_train_batch_begin: 1615760165.518681s

47 step training time: 0.323324s

on_train_batch_end: 1615760165.838479s

49152/50000 [============================>.] - ETA: 0s - loss: 4.7013 - accuracy: 0.0781
on_train_batch_begin: 1615760165.838784s

48 step training time: 0.320103s

on_train_batch_end: 1615760166.107215s

on_test_batch_begin: 1615760166.121086s

49 step training time: 0.282301s

on_epoch_end: 1615760166.900130s

Validation time: 0.779032s

Real time: 1615760166.900130s

Epoch time: 16.438125133514404s

50000/50000 [==============================] - 16s 329us/sample - loss: 4.6865 - accuracy: 0.0781 - val_loss: 8.3780 - val_accuracy: 0.1000

on_epoch_begin: 1615760166.900321s

Real time: 1615760166.9003277
Epoch 3/5

on_train_batch_begin: 1615760166.903647s

on_train_batch_end: 1615760167.226422s

 1024/50000 [..............................] - ETA: 15s - loss: 3.8311 - accuracy: 0.0756
on_train_batch_begin: 1615760167.226765s

1 step training time: 0.323118s

on_train_batch_end: 1615760167.550459s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.7088 - accuracy: 0.0787
on_train_batch_begin: 1615760167.550784s

2 step training time: 0.324018s

on_train_batch_end: 1615760167.875816s

 3072/50000 [>.............................] - ETA: 14s - loss: 3.6957 - accuracy: 0.0789
on_train_batch_begin: 1615760167.876131s

3 step training time: 0.325348s

on_train_batch_end: 1615760168.200935s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.6595 - accuracy: 0.0799
on_train_batch_begin: 1615760168.201245s

4 step training time: 0.325114s

on_train_batch_end: 1615760168.525477s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.6634 - accuracy: 0.0802
on_train_batch_begin: 1615760168.525807s

5 step training time: 0.324562s

on_train_batch_end: 1615760168.849634s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.6476 - accuracy: 0.0802
on_train_batch_begin: 1615760168.849958s

6 step training time: 0.324151s

on_train_batch_end: 1615760169.173695s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.6247 - accuracy: 0.0809
on_train_batch_begin: 1615760169.174032s

7 step training time: 0.324074s

on_train_batch_end: 1615760169.498462s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.5990 - accuracy: 0.0816
on_train_batch_begin: 1615760169.498783s

8 step training time: 0.324751s

on_train_batch_end: 1615760169.823472s

 9216/50000 [====>.........................] - ETA: 12s - loss: 3.5777 - accuracy: 0.0820
on_train_batch_begin: 1615760169.823819s

9 step training time: 0.325035s

on_train_batch_end: 1615760170.146321s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.5471 - accuracy: 0.0826
on_train_batch_begin: 1615760170.146648s

10 step training time: 0.322829s

on_train_batch_end: 1615760170.471654s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.5392 - accuracy: 0.0831
on_train_batch_begin: 1615760170.471972s

11 step training time: 0.325324s

on_train_batch_end: 1615760170.796195s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.5163 - accuracy: 0.0837
on_train_batch_begin: 1615760170.796535s

12 step training time: 0.324562s

on_train_batch_end: 1615760171.121354s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.4963 - accuracy: 0.0840
on_train_batch_begin: 1615760171.121688s

13 step training time: 0.325154s

on_train_batch_end: 1615760171.444371s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.4852 - accuracy: 0.0843
on_train_batch_begin: 1615760171.444729s

14 step training time: 0.323041s

on_train_batch_end: 1615760171.769082s

15360/50000 [========>.....................] - ETA: 10s - loss: 3.4636 - accuracy: 0.0848
on_train_batch_begin: 1615760171.769436s

15 step training time: 0.324707s

on_train_batch_end: 1615760172.094094s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.4422 - accuracy: 0.0852
on_train_batch_begin: 1615760172.094408s

16 step training time: 0.324972s

on_train_batch_end: 1615760172.419401s

17408/50000 [=========>....................] - ETA: 10s - loss: 3.4165 - accuracy: 0.0855
on_train_batch_begin: 1615760172.419746s

17 step training time: 0.325338s

on_train_batch_end: 1615760172.744343s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.3958 - accuracy: 0.0859
on_train_batch_begin: 1615760172.744680s

18 step training time: 0.324935s

on_train_batch_end: 1615760173.069776s

19456/50000 [==========>...................] - ETA: 9s - loss: 3.3530 - accuracy: 0.0864 
on_train_batch_begin: 1615760173.070103s

19 step training time: 0.325422s

on_train_batch_end: 1615760173.393430s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.3222 - accuracy: 0.0869
on_train_batch_begin: 1615760173.393775s

20 step training time: 0.323672s

on_train_batch_end: 1615760173.717811s

21504/50000 [===========>..................] - ETA: 9s - loss: 3.2950 - accuracy: 0.0874
on_train_batch_begin: 1615760173.718136s

21 step training time: 0.324362s

on_train_batch_end: 1615760174.043849s

22528/50000 [============>.................] - ETA: 8s - loss: 3.2571 - accuracy: 0.0879
on_train_batch_begin: 1615760174.044189s

22 step training time: 0.326053s

on_train_batch_end: 1615760174.370237s

23552/50000 [=============>................] - ETA: 8s - loss: 3.2159 - accuracy: 0.0884
on_train_batch_begin: 1615760174.370607s

23 step training time: 0.326418s

on_train_batch_end: 1615760174.693936s

24576/50000 [=============>................] - ETA: 8s - loss: 3.1768 - accuracy: 0.0890
on_train_batch_begin: 1615760174.694306s

24 step training time: 0.323699s

on_train_batch_end: 1615760175.018519s

25600/50000 [==============>...............] - ETA: 7s - loss: 3.1474 - accuracy: 0.0894
on_train_batch_begin: 1615760175.018891s

25 step training time: 0.324585s

on_train_batch_end: 1615760175.343112s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.1131 - accuracy: 0.0898
on_train_batch_begin: 1615760175.343481s

26 step training time: 0.324590s

on_train_batch_end: 1615760175.668473s

27648/50000 [===============>..............] - ETA: 7s - loss: 3.0848 - accuracy: 0.0902
on_train_batch_begin: 1615760175.668829s

27 step training time: 0.325349s

on_train_batch_end: 1615760175.992489s

28672/50000 [================>.............] - ETA: 6s - loss: 3.0619 - accuracy: 0.0906
on_train_batch_begin: 1615760175.992847s

28 step training time: 0.324018s

on_train_batch_end: 1615760176.316755s

29696/50000 [================>.............] - ETA: 6s - loss: 3.0375 - accuracy: 0.0909
on_train_batch_begin: 1615760176.317098s

29 step training time: 0.324251s

on_train_batch_end: 1615760176.641641s

30720/50000 [=================>............] - ETA: 6s - loss: 3.0119 - accuracy: 0.0912
on_train_batch_begin: 1615760176.642017s

30 step training time: 0.324919s

on_train_batch_end: 1615760176.965727s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.9836 - accuracy: 0.0915
on_train_batch_begin: 1615760176.966084s

31 step training time: 0.324067s

on_train_batch_end: 1615760177.289664s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.9554 - accuracy: 0.0918
on_train_batch_begin: 1615760177.290037s

32 step training time: 0.323953s

on_train_batch_end: 1615760177.614470s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.9345 - accuracy: 0.0920
on_train_batch_begin: 1615760177.614843s

33 step training time: 0.324807s

on_train_batch_end: 1615760177.937447s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.9036 - accuracy: 0.0923
on_train_batch_begin: 1615760177.937816s

34 step training time: 0.322973s

on_train_batch_end: 1615760178.262175s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.8780 - accuracy: 0.0925
on_train_batch_begin: 1615760178.262520s

35 step training time: 0.324704s

on_train_batch_end: 1615760178.587264s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.8572 - accuracy: 0.0927
on_train_batch_begin: 1615760178.587605s

36 step training time: 0.325085s

on_train_batch_end: 1615760178.910886s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.8366 - accuracy: 0.0929
on_train_batch_begin: 1615760178.911215s

37 step training time: 0.323610s

on_train_batch_end: 1615760179.235119s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.8125 - accuracy: 0.0931
on_train_batch_begin: 1615760179.235441s

38 step training time: 0.324226s

on_train_batch_end: 1615760179.559736s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.7903 - accuracy: 0.0932
on_train_batch_begin: 1615760179.560055s

39 step training time: 0.324614s

on_train_batch_end: 1615760179.883382s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.7622 - accuracy: 0.0934
on_train_batch_begin: 1615760179.883724s

40 step training time: 0.323669s

on_train_batch_end: 1615760180.207645s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.7385 - accuracy: 0.0936
on_train_batch_begin: 1615760180.207967s

41 step training time: 0.324243s

on_train_batch_end: 1615760180.530491s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.7164 - accuracy: 0.0937
on_train_batch_begin: 1615760180.530814s

42 step training time: 0.322847s

on_train_batch_end: 1615760180.854978s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.6966 - accuracy: 0.0939
on_train_batch_begin: 1615760180.855316s

43 step training time: 0.324502s

on_train_batch_end: 1615760181.179455s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.6780 - accuracy: 0.0940
on_train_batch_begin: 1615760181.179780s

44 step training time: 0.324464s

on_train_batch_end: 1615760181.503579s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.6584 - accuracy: 0.0942
on_train_batch_begin: 1615760181.503939s

45 step training time: 0.324159s

on_train_batch_end: 1615760181.828636s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.6347 - accuracy: 0.0943
on_train_batch_begin: 1615760181.828997s

46 step training time: 0.325058s

on_train_batch_end: 1615760182.154807s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.6135 - accuracy: 0.0944
on_train_batch_begin: 1615760182.155141s

47 step training time: 0.326144s

on_train_batch_end: 1615760182.478247s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5934 - accuracy: 0.0946
on_train_batch_begin: 1615760182.478604s

48 step training time: 0.323462s

on_train_batch_end: 1615760182.749068s

on_test_batch_begin: 1615760182.763370s

49 step training time: 0.284767s

on_epoch_end: 1615760183.574111s

Validation time: 0.810724s

Real time: 1615760183.574111s

Epoch time: 16.67380404472351s

50000/50000 [==============================] - 17s 333us/sample - loss: 2.5745 - accuracy: 0.0946 - val_loss: 7.2553 - val_accuracy: 0.1000

on_epoch_begin: 1615760183.574318s

Real time: 1615760183.574324
Epoch 4/5

on_train_batch_begin: 1615760183.577750s

on_train_batch_end: 1615760183.902148s

 1024/50000 [..............................] - ETA: 15s - loss: 1.5937 - accuracy: 0.1004
on_train_batch_begin: 1615760183.902443s

1 step training time: 0.324693s

on_train_batch_end: 1615760184.225187s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.4893 - accuracy: 0.1004
on_train_batch_begin: 1615760184.225521s

2 step training time: 0.323077s

on_train_batch_end: 1615760184.550547s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.4744 - accuracy: 0.1004
on_train_batch_begin: 1615760184.550852s

3 step training time: 0.325331s

on_train_batch_end: 1615760184.874643s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.4348 - accuracy: 0.1004
on_train_batch_begin: 1615760184.874953s

4 step training time: 0.324101s

on_train_batch_end: 1615760185.199663s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.4313 - accuracy: 0.1005
on_train_batch_begin: 1615760185.199977s

5 step training time: 0.325024s

on_train_batch_end: 1615760185.523635s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.4289 - accuracy: 0.1004
on_train_batch_begin: 1615760185.523916s

6 step training time: 0.323939s

on_train_batch_end: 1615760185.845296s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.4262 - accuracy: 0.1004
on_train_batch_begin: 1615760185.845655s

7 step training time: 0.321739s

on_train_batch_end: 1615760186.169389s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.4073 - accuracy: 0.1005
on_train_batch_begin: 1615760186.169716s

8 step training time: 0.324061s

on_train_batch_end: 1615760186.494823s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.4190 - accuracy: 0.1004
on_train_batch_begin: 1615760186.495162s

9 step training time: 0.325446s

on_train_batch_end: 1615760186.819620s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.4377 - accuracy: 0.1003
on_train_batch_begin: 1615760186.819957s

10 step training time: 0.324795s

on_train_batch_end: 1615760187.143902s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.4359 - accuracy: 0.1003
on_train_batch_begin: 1615760187.144255s

11 step training time: 0.324298s

on_train_batch_end: 1615760187.476412s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.4238 - accuracy: 0.1003
on_train_batch_begin: 1615760187.476769s

12 step training time: 0.332514s

on_train_batch_end: 1615760187.802264s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.4057 - accuracy: 0.1003
on_train_batch_begin: 1615760187.802621s

13 step training time: 0.325852s

on_train_batch_end: 1615760188.125867s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.4061 - accuracy: 0.1002
on_train_batch_begin: 1615760188.126225s

14 step training time: 0.323604s

on_train_batch_end: 1615760188.449666s

15360/50000 [========>.....................] - ETA: 10s - loss: 1.4065 - accuracy: 0.1003
on_train_batch_begin: 1615760188.450024s

15 step training time: 0.323799s

on_train_batch_end: 1615760188.773273s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.4034 - accuracy: 0.1003
on_train_batch_begin: 1615760188.773660s

16 step training time: 0.323635s

on_train_batch_end: 1615760189.099588s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.4094 - accuracy: 0.1002
on_train_batch_begin: 1615760189.099948s

17 step training time: 0.326288s

on_train_batch_end: 1615760189.425621s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.4113 - accuracy: 0.1003
on_train_batch_begin: 1615760189.425979s

18 step training time: 0.326031s

on_train_batch_end: 1615760189.754112s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.4072 - accuracy: 0.1003 
on_train_batch_begin: 1615760189.754471s

19 step training time: 0.328491s

on_train_batch_end: 1615760190.083259s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.4052 - accuracy: 0.1003
on_train_batch_begin: 1615760190.083625s

20 step training time: 0.329154s

on_train_batch_end: 1615760190.409935s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.3940 - accuracy: 0.1003
on_train_batch_begin: 1615760190.410295s

21 step training time: 0.326670s

on_train_batch_end: 1615760190.735646s

22528/50000 [============>.................] - ETA: 8s - loss: 1.3887 - accuracy: 0.1003
on_train_batch_begin: 1615760190.736005s

22 step training time: 0.325709s

on_train_batch_end: 1615760191.060788s

23552/50000 [=============>................] - ETA: 8s - loss: 1.3921 - accuracy: 0.1002
on_train_batch_begin: 1615760191.061131s

23 step training time: 0.325127s

on_train_batch_end: 1615760191.383630s

24576/50000 [=============>................] - ETA: 8s - loss: 1.3849 - accuracy: 0.1002
on_train_batch_begin: 1615760191.383965s

24 step training time: 0.322834s

on_train_batch_end: 1615760191.709048s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.3784 - accuracy: 0.1002
on_train_batch_begin: 1615760191.709392s

25 step training time: 0.325427s

on_train_batch_end: 1615760192.035037s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.3731 - accuracy: 0.1002
on_train_batch_begin: 1615760192.035327s

26 step training time: 0.325935s

on_train_batch_end: 1615760192.357864s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.3685 - accuracy: 0.1002
on_train_batch_begin: 1615760192.358180s

27 step training time: 0.322853s

on_train_batch_end: 1615760192.685504s

28672/50000 [================>.............] - ETA: 6s - loss: 1.3684 - accuracy: 0.1002
on_train_batch_begin: 1615760192.685825s

28 step training time: 0.327645s

on_train_batch_end: 1615760193.010706s

29696/50000 [================>.............] - ETA: 6s - loss: 1.3648 - accuracy: 0.1002
on_train_batch_begin: 1615760193.011028s

29 step training time: 0.325203s

on_train_batch_end: 1615760193.334596s

30720/50000 [=================>............] - ETA: 6s - loss: 1.3631 - accuracy: 0.1002
on_train_batch_begin: 1615760193.334907s

30 step training time: 0.323879s

on_train_batch_end: 1615760193.658174s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.3580 - accuracy: 0.1002
on_train_batch_begin: 1615760193.658501s

31 step training time: 0.323595s

on_train_batch_end: 1615760193.982223s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.3588 - accuracy: 0.1002
on_train_batch_begin: 1615760193.982546s

32 step training time: 0.324045s

on_train_batch_end: 1615760194.307859s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.3536 - accuracy: 0.1002
on_train_batch_begin: 1615760194.308192s

33 step training time: 0.325646s

on_train_batch_end: 1615760194.633178s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.3475 - accuracy: 0.1002
on_train_batch_begin: 1615760194.633562s

34 step training time: 0.325370s

on_train_batch_end: 1615760194.960224s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.3418 - accuracy: 0.1002
on_train_batch_begin: 1615760194.960579s

35 step training time: 0.327017s

on_train_batch_end: 1615760195.287946s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.3387 - accuracy: 0.1002
on_train_batch_begin: 1615760195.288264s

36 step training time: 0.327685s

on_train_batch_end: 1615760195.617257s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.3353 - accuracy: 0.1002
on_train_batch_begin: 1615760195.617634s

37 step training time: 0.329370s

on_train_batch_end: 1615760195.945482s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.3298 - accuracy: 0.1002
on_train_batch_begin: 1615760195.945847s

38 step training time: 0.328213s

on_train_batch_end: 1615760196.270740s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.3235 - accuracy: 0.1002
on_train_batch_begin: 1615760196.271102s

39 step training time: 0.325255s

on_train_batch_end: 1615760196.595307s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.3199 - accuracy: 0.1002
on_train_batch_begin: 1615760196.595674s

40 step training time: 0.324572s

on_train_batch_end: 1615760196.920672s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.3178 - accuracy: 0.1002
on_train_batch_begin: 1615760196.921036s

41 step training time: 0.325362s

on_train_batch_end: 1615760197.245740s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.3156 - accuracy: 0.1002
on_train_batch_begin: 1615760197.246101s

42 step training time: 0.325065s

on_train_batch_end: 1615760197.570973s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.3103 - accuracy: 0.1002
on_train_batch_begin: 1615760197.571330s

43 step training time: 0.325229s

on_train_batch_end: 1615760197.894588s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.3067 - accuracy: 0.1002
on_train_batch_begin: 1615760197.894943s

44 step training time: 0.323614s

on_train_batch_end: 1615760198.219980s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.2996 - accuracy: 0.1002
on_train_batch_begin: 1615760198.220330s

45 step training time: 0.325387s

on_train_batch_end: 1615760198.542500s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.2954 - accuracy: 0.1003
on_train_batch_begin: 1615760198.542856s

46 step training time: 0.322525s

on_train_batch_end: 1615760198.867957s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.2894 - accuracy: 0.1003
on_train_batch_begin: 1615760198.868295s

47 step training time: 0.325439s

on_train_batch_end: 1615760199.192633s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2858 - accuracy: 0.1003
on_train_batch_begin: 1615760199.192971s

48 step training time: 0.324677s

on_train_batch_end: 1615760199.464455s

on_test_batch_begin: 1615760199.479692s

49 step training time: 0.286720s

on_epoch_end: 1615760200.289300s

Validation time: 0.809597s

Real time: 1615760200.289300s

Epoch time: 16.715020418167114s

50000/50000 [==============================] - 17s 334us/sample - loss: 1.2840 - accuracy: 0.1003 - val_loss: 7.4085 - val_accuracy: 0.1000

on_epoch_begin: 1615760200.289539s

Real time: 1615760200.2895436
Epoch 5/5

on_train_batch_begin: 1615760200.293067s

on_train_batch_end: 1615760200.617032s

 1024/50000 [..............................] - ETA: 15s - loss: 0.9390 - accuracy: 0.1004
on_train_batch_begin: 1615760200.617291s

1 step training time: 0.324224s

on_train_batch_end: 1615760200.941442s

 2048/50000 [>.............................] - ETA: 15s - loss: 0.9691 - accuracy: 0.1005
on_train_batch_begin: 1615760200.941740s

2 step training time: 0.324449s

on_train_batch_end: 1615760201.270279s

 3072/50000 [>.............................] - ETA: 14s - loss: 0.9398 - accuracy: 0.1004
on_train_batch_begin: 1615760201.270613s

3 step training time: 0.328873s

on_train_batch_end: 1615760201.601034s

 4096/50000 [=>............................] - ETA: 14s - loss: 0.9635 - accuracy: 0.1003
on_train_batch_begin: 1615760201.601383s

4 step training time: 0.330770s

on_train_batch_end: 1615760201.928518s

 5120/50000 [==>...........................] - ETA: 14s - loss: 0.9331 - accuracy: 0.1003
on_train_batch_begin: 1615760201.928815s

5 step training time: 0.327432s

on_train_batch_end: 1615760202.257568s

 6144/50000 [==>...........................] - ETA: 14s - loss: 0.9464 - accuracy: 0.1004
on_train_batch_begin: 1615760202.257907s

6 step training time: 0.329092s

on_train_batch_end: 1615760202.586106s

 7168/50000 [===>..........................] - ETA: 13s - loss: 0.9392 - accuracy: 0.1003
on_train_batch_begin: 1615760202.586432s

7 step training time: 0.328525s

on_train_batch_end: 1615760202.911151s

 8192/50000 [===>..........................] - ETA: 13s - loss: 0.9409 - accuracy: 0.1003
on_train_batch_begin: 1615760202.911495s

8 step training time: 0.325063s

on_train_batch_end: 1615760203.238283s

 9216/50000 [====>.........................] - ETA: 13s - loss: 0.9294 - accuracy: 0.1003
on_train_batch_begin: 1615760203.238619s

9 step training time: 0.327124s

on_train_batch_end: 1615760203.565971s

10240/50000 [=====>........................] - ETA: 12s - loss: 0.9339 - accuracy: 0.1003
on_train_batch_begin: 1615760203.566295s

10 step training time: 0.327676s

on_train_batch_end: 1615760203.896580s

11264/50000 [=====>........................] - ETA: 12s - loss: 0.9211 - accuracy: 0.1003
on_train_batch_begin: 1615760203.896902s

11 step training time: 0.330606s

on_train_batch_end: 1615760204.225720s

12288/50000 [======>.......................] - ETA: 12s - loss: 0.9159 - accuracy: 0.1003
on_train_batch_begin: 1615760204.226030s

12 step training time: 0.329128s

on_train_batch_end: 1615760204.552014s

13312/50000 [======>.......................] - ETA: 11s - loss: 0.8968 - accuracy: 0.1002
on_train_batch_begin: 1615760204.552340s

13 step training time: 0.326310s

on_train_batch_end: 1615760204.878036s

14336/50000 [=======>......................] - ETA: 11s - loss: 0.9003 - accuracy: 0.1003
on_train_batch_begin: 1615760204.878337s

14 step training time: 0.325997s

on_train_batch_end: 1615760205.205353s

15360/50000 [========>.....................] - ETA: 11s - loss: 0.8998 - accuracy: 0.1003
on_train_batch_begin: 1615760205.205652s

15 step training time: 0.327314s

on_train_batch_end: 1615760205.529529s

16384/50000 [========>.....................] - ETA: 10s - loss: 0.8947 - accuracy: 0.1003
on_train_batch_begin: 1615760205.529830s

16 step training time: 0.324179s

on_train_batch_end: 1615760205.855420s

17408/50000 [=========>....................] - ETA: 10s - loss: 0.8887 - accuracy: 0.1003
on_train_batch_begin: 1615760205.855712s

17 step training time: 0.325881s

on_train_batch_end: 1615760206.182927s

18432/50000 [==========>...................] - ETA: 10s - loss: 0.8844 - accuracy: 0.1003
on_train_batch_begin: 1615760206.183280s

18 step training time: 0.327569s

on_train_batch_end: 1615760206.511240s

19456/50000 [==========>...................] - ETA: 9s - loss: 0.8853 - accuracy: 0.1003 
on_train_batch_begin: 1615760206.511592s

19 step training time: 0.328311s

on_train_batch_end: 1615760206.841649s

20480/50000 [===========>..................] - ETA: 9s - loss: 0.8853 - accuracy: 0.1003
on_train_batch_begin: 1615760206.841950s

20 step training time: 0.330359s

on_train_batch_end: 1615760207.171558s

21504/50000 [===========>..................] - ETA: 9s - loss: 0.8815 - accuracy: 0.1003
on_train_batch_begin: 1615760207.171895s

21 step training time: 0.329944s

on_train_batch_end: 1615760207.499572s

22528/50000 [============>.................] - ETA: 8s - loss: 0.8823 - accuracy: 0.1003
on_train_batch_begin: 1615760207.499883s

22 step training time: 0.327989s

on_train_batch_end: 1615760207.826424s

23552/50000 [=============>................] - ETA: 8s - loss: 0.8838 - accuracy: 0.1003
on_train_batch_begin: 1615760207.826725s

23 step training time: 0.326842s

on_train_batch_end: 1615760208.152395s

24576/50000 [=============>................] - ETA: 8s - loss: 0.8790 - accuracy: 0.1003
on_train_batch_begin: 1615760208.152720s

24 step training time: 0.325995s

on_train_batch_end: 1615760208.480703s

25600/50000 [==============>...............] - ETA: 7s - loss: 0.8802 - accuracy: 0.1003
on_train_batch_begin: 1615760208.481059s

25 step training time: 0.328338s

on_train_batch_end: 1615760208.809022s

26624/50000 [==============>...............] - ETA: 7s - loss: 0.8813 - accuracy: 0.1003
on_train_batch_begin: 1615760208.809347s

26 step training time: 0.328288s

on_train_batch_end: 1615760209.139793s

27648/50000 [===============>..............] - ETA: 7s - loss: 0.8786 - accuracy: 0.1003
on_train_batch_begin: 1615760209.140091s

27 step training time: 0.330745s

on_train_batch_end: 1615760209.469826s

28672/50000 [================>.............] - ETA: 6s - loss: 0.8765 - accuracy: 0.1003
on_train_batch_begin: 1615760209.470120s

28 step training time: 0.330029s

on_train_batch_end: 1615760209.796795s

29696/50000 [================>.............] - ETA: 6s - loss: 0.8714 - accuracy: 0.1004
on_train_batch_begin: 1615760209.797080s

29 step training time: 0.326960s

on_train_batch_end: 1615760210.125089s

30720/50000 [=================>............] - ETA: 6s - loss: 0.8755 - accuracy: 0.1003
on_train_batch_begin: 1615760210.125384s

30 step training time: 0.328304s

on_train_batch_end: 1615760210.451439s

31744/50000 [==================>...........] - ETA: 5s - loss: 0.8743 - accuracy: 0.1004
on_train_batch_begin: 1615760210.451799s

31 step training time: 0.326415s

on_train_batch_end: 1615760210.781680s

32768/50000 [==================>...........] - ETA: 5s - loss: 0.8733 - accuracy: 0.1004
on_train_batch_begin: 1615760210.782014s

32 step training time: 0.330215s

on_train_batch_end: 1615760211.111419s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.8689 - accuracy: 0.1004
on_train_batch_begin: 1615760211.111752s

33 step training time: 0.329738s

on_train_batch_end: 1615760211.440490s

34816/50000 [===================>..........] - ETA: 4s - loss: 0.8668 - accuracy: 0.1004
on_train_batch_begin: 1615760211.440828s

34 step training time: 0.329076s

on_train_batch_end: 1615760211.768193s

35840/50000 [====================>.........] - ETA: 4s - loss: 0.8637 - accuracy: 0.1004
on_train_batch_begin: 1615760211.768534s

35 step training time: 0.327707s

on_train_batch_end: 1615760212.094585s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.8669 - accuracy: 0.1004
on_train_batch_begin: 1615760212.094911s

36 step training time: 0.326377s

on_train_batch_end: 1615760212.423297s

37888/50000 [=====================>........] - ETA: 3s - loss: 0.8670 - accuracy: 0.1004
on_train_batch_begin: 1615760212.423609s

37 step training time: 0.328698s

on_train_batch_end: 1615760212.755458s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.8664 - accuracy: 0.1003
on_train_batch_begin: 1615760212.755771s

38 step training time: 0.332163s

on_train_batch_end: 1615760213.083149s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.8650 - accuracy: 0.1003
on_train_batch_begin: 1615760213.083476s

39 step training time: 0.327704s

on_train_batch_end: 1615760213.411502s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.8649 - accuracy: 0.1003
on_train_batch_begin: 1615760213.411800s

40 step training time: 0.328324s

on_train_batch_end: 1615760213.739778s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.8676 - accuracy: 0.1003
on_train_batch_begin: 1615760213.740127s

41 step training time: 0.328326s

on_train_batch_end: 1615760214.070007s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.8666 - accuracy: 0.1004
on_train_batch_begin: 1615760214.070338s

42 step training time: 0.330211s

on_train_batch_end: 1615760214.400453s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.8623 - accuracy: 0.1004
on_train_batch_begin: 1615760214.400749s

43 step training time: 0.330411s

on_train_batch_end: 1615760214.731150s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.8631 - accuracy: 0.1004
on_train_batch_begin: 1615760214.731484s

44 step training time: 0.330736s

on_train_batch_end: 1615760215.060497s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.8635 - accuracy: 0.1004
on_train_batch_begin: 1615760215.060832s

45 step training time: 0.329348s

on_train_batch_end: 1615760215.387369s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.8611 - accuracy: 0.1003
on_train_batch_begin: 1615760215.387687s

46 step training time: 0.326855s

on_train_batch_end: 1615760215.720591s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.8624 - accuracy: 0.1004
on_train_batch_begin: 1615760215.720908s

47 step training time: 0.333221s

on_train_batch_end: 1615760216.050895s

49152/50000 [============================>.] - ETA: 0s - loss: 0.8616 - accuracy: 0.1004
on_train_batch_begin: 1615760216.051213s

48 step training time: 0.330304s

on_train_batch_end: 1615760216.321301s

on_test_batch_begin: 1615760216.338575s

49 step training time: 0.287363s

on_epoch_end: 1615760217.124829s

Validation time: 0.786242s

Real time: 1615760217.124829s

Epoch time: 16.835305213928223s

50000/50000 [==============================] - 17s 337us/sample - loss: 0.8596 - accuracy: 0.1004 - val_loss: 7.0070 - val_accuracy: 0.1000
Tempo do fit: 113.37895154953003