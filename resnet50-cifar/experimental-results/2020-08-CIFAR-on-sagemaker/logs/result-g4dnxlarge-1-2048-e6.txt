wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:55
   204800/170498071 [..............................] - ETA: 1:18
  1122304/170498071 [..............................] - ETA: 21s 
  3612672/170498071 [..............................] - ETA: 9s 
  6545408/170498071 [>.............................] - ETA: 6s
  9887744/170498071 [>.............................] - ETA: 4s
 12853248/170498071 [=>............................] - ETA: 4s
 16130048/170498071 [=>............................] - ETA: 3s
 19144704/170498071 [==>...........................] - ETA: 3s
 22405120/170498071 [==>...........................] - ETA: 3s
 25387008/170498071 [===>..........................] - ETA: 3s
 28581888/170498071 [====>.........................] - ETA: 2s
 31727616/170498071 [====>.........................] - ETA: 2s
 34971648/170498071 [=====>........................] - ETA: 2s
 37961728/170498071 [=====>........................] - ETA: 2s
 40919040/170498071 [======>.......................] - ETA: 2s
 44204032/170498071 [======>.......................] - ETA: 2s
 47144960/170498071 [=======>......................] - ETA: 2s
 50274304/170498071 [=======>......................] - ETA: 2s
 53862400/170498071 [========>.....................] - ETA: 2s
 57204736/170498071 [=========>....................] - ETA: 2s
 60284928/170498071 [=========>....................] - ETA: 2s
 63578112/170498071 [==========>...................] - ETA: 1s
 66625536/170498071 [==========>...................] - ETA: 1s
 69853184/170498071 [===========>..................] - ETA: 1s
 72916992/170498071 [===========>..................] - ETA: 1s
 76161024/170498071 [============>.................] - ETA: 1s
 79290368/170498071 [============>.................] - ETA: 1s
 82534400/170498071 [=============>................] - ETA: 1s
 85606400/170498071 [==============>...............] - ETA: 1s
 88793088/170498071 [==============>...............] - ETA: 1s
 92037120/170498071 [===============>..............] - ETA: 1s
 95002624/170498071 [===============>..............] - ETA: 1s
 98246656/170498071 [================>.............] - ETA: 1s
101212160/170498071 [================>.............] - ETA: 1s
104456192/170498071 [=================>............] - ETA: 1s
107470848/170498071 [=================>............] - ETA: 1s
110714880/170498071 [==================>...........] - ETA: 1s
113844224/170498071 [===================>..........] - ETA: 0s
117039104/170498071 [===================>..........] - ETA: 0s
120283136/170498071 [====================>.........] - ETA: 0s
123330560/170498071 [====================>.........] - ETA: 0s
126607360/170498071 [=====================>........] - ETA: 0s
129523712/170498071 [=====================>........] - ETA: 0s
132751360/170498071 [======================>.......] - ETA: 0s
135766016/170498071 [======================>.......] - ETA: 0s
139026432/170498071 [=======================>......] - ETA: 0s
142172160/170498071 [========================>.....] - ETA: 0s
145367040/170498071 [========================>.....] - ETA: 0s
148529152/170498071 [=========================>....] - ETA: 0s
151592960/170498071 [=========================>....] - ETA: 0s
154886144/170498071 [==========================>...] - ETA: 0s
157900800/170498071 [==========================>...] - ETA: 0s
161144832/170498071 [===========================>..] - ETA: 0s
164208640/170498071 [===========================>..] - ETA: 0s
167469056/170498071 [============================>.] - ETA: 0s
170450944/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 6103040/94765736 [>.............................] - ETA: 0s
11255808/94765736 [==>...........................] - ETA: 0s
16015360/94765736 [====>.........................] - ETA: 0s
21299200/94765736 [=====>........................] - ETA: 0s
26189824/94765736 [=======>......................] - ETA: 0s
30040064/94765736 [========>.....................] - ETA: 0s
36118528/94765736 [==========>...................] - ETA: 0s
41394176/94765736 [============>.................] - ETA: 0s
46342144/94765736 [=============>................] - ETA: 0s
51855360/94765736 [===============>..............] - ETA: 0s
58130432/94765736 [=================>............] - ETA: 0s
63348736/94765736 [===================>..........] - ETA: 0s
68263936/94765736 [====================>.........] - ETA: 0s
73203712/94765736 [======================>.......] - ETA: 0s
78331904/94765736 [=======================>......] - ETA: 0s
83615744/94765736 [=========================>....] - ETA: 0s
88416256/94765736 [==========================>...] - ETA: 0s
93724672/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.855348110198975
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615852997.107377s

Real time: 1615852997.1073937
Epoch 1/5

on_train_batch_begin: 1615852997.853261s

on_train_batch_end: 1615853017.466426s

 2048/50000 [>.............................] - ETA: 7:56 - loss: 18.0577 - accuracy: 1.5593e-04
on_train_batch_begin: 1615853017.467067s

1 step training time: 19.613806s

on_train_batch_end: 1615853018.107202s

 4096/50000 [=>............................] - ETA: 3:55 - loss: 13.9856 - accuracy: 3.4714e-04
on_train_batch_begin: 1615853018.107522s

2 step training time: 0.640456s

on_train_batch_end: 1615853018.755724s

 6144/50000 [==>...........................] - ETA: 2:34 - loss: 12.1225 - accuracy: 6.9904e-04
on_train_batch_begin: 1615853018.756050s

3 step training time: 0.648528s

on_train_batch_end: 1615853019.405034s

 8192/50000 [===>..........................] - ETA: 1:53 - loss: 11.1745 - accuracy: 0.0022    
on_train_batch_begin: 1615853019.405373s

4 step training time: 0.649323s

on_train_batch_end: 1615853020.052355s

10240/50000 [=====>........................] - ETA: 1:29 - loss: 10.5562 - accuracy: 0.0051
on_train_batch_begin: 1615853020.052746s

5 step training time: 0.647373s

on_train_batch_end: 1615853020.708090s

12288/50000 [======>.......................] - ETA: 1:12 - loss: 10.1141 - accuracy: 0.0087
on_train_batch_begin: 1615853020.708388s

6 step training time: 0.655642s

on_train_batch_end: 1615853021.356836s

14336/50000 [=======>......................] - ETA: 1:00 - loss: 9.7725 - accuracy: 0.0126 
on_train_batch_begin: 1615853021.357135s

7 step training time: 0.648747s

on_train_batch_end: 1615853022.005085s

16384/50000 [========>.....................] - ETA: 51s - loss: 9.5176 - accuracy: 0.0171 
on_train_batch_begin: 1615853022.005414s

8 step training time: 0.648279s

on_train_batch_end: 1615853022.642632s

18432/50000 [==========>...................] - ETA: 43s - loss: 9.3393 - accuracy: 0.0215
on_train_batch_begin: 1615853022.642954s

9 step training time: 0.637540s

on_train_batch_end: 1615853023.287720s

20480/50000 [===========>..................] - ETA: 37s - loss: 9.1642 - accuracy: 0.0255
on_train_batch_begin: 1615853023.288047s

10 step training time: 0.645093s

on_train_batch_end: 1615853023.937547s

22528/50000 [============>.................] - ETA: 32s - loss: 9.0183 - accuracy: 0.0276
on_train_batch_begin: 1615853023.937845s

11 step training time: 0.649798s

on_train_batch_end: 1615853024.584800s

24576/50000 [=============>................] - ETA: 28s - loss: 8.8849 - accuracy: 0.0298
on_train_batch_begin: 1615853024.585150s

12 step training time: 0.647305s

on_train_batch_end: 1615853025.234185s

26624/50000 [==============>...............] - ETA: 24s - loss: 8.7703 - accuracy: 0.0318
on_train_batch_begin: 1615853025.234483s

13 step training time: 0.649333s

on_train_batch_end: 1615853025.885460s

28672/50000 [================>.............] - ETA: 21s - loss: 8.6623 - accuracy: 0.0336
on_train_batch_begin: 1615853025.885902s

14 step training time: 0.651419s

on_train_batch_end: 1615853026.537620s

30720/50000 [=================>............] - ETA: 18s - loss: 8.5667 - accuracy: 0.0352
on_train_batch_begin: 1615853026.537923s

15 step training time: 0.652020s

on_train_batch_end: 1615853027.190903s

32768/50000 [==================>...........] - ETA: 15s - loss: 8.4789 - accuracy: 0.0363
on_train_batch_begin: 1615853027.191198s

16 step training time: 0.653275s

on_train_batch_end: 1615853027.834424s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.3932 - accuracy: 0.0379
on_train_batch_begin: 1615853027.834745s

17 step training time: 0.643547s

on_train_batch_end: 1615853028.475462s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.3207 - accuracy: 0.0398
on_train_batch_begin: 1615853028.475756s

18 step training time: 0.641011s

on_train_batch_end: 1615853029.119841s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.2546 - accuracy: 0.0412 
on_train_batch_begin: 1615853029.120164s

19 step training time: 0.644408s

on_train_batch_end: 1615853029.763421s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.1853 - accuracy: 0.0428
on_train_batch_begin: 1615853029.763726s

20 step training time: 0.643563s

on_train_batch_end: 1615853030.412531s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.1238 - accuracy: 0.0443
on_train_batch_begin: 1615853030.412837s

21 step training time: 0.649110s

on_train_batch_end: 1615853031.043715s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.0593 - accuracy: 0.0456
on_train_batch_begin: 1615853031.044036s

22 step training time: 0.631200s

on_train_batch_end: 1615853031.686468s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.0013 - accuracy: 0.0468
on_train_batch_begin: 1615853031.686776s

23 step training time: 0.642740s

on_train_batch_end: 1615853032.320709s

49152/50000 [============================>.] - ETA: 0s - loss: 7.9445 - accuracy: 0.0479
on_train_batch_begin: 1615853032.321016s

24 step training time: 0.634239s

on_train_batch_end: 1615853037.965131s

on_test_batch_begin: 1615853038.154253s

25 step training time: 5.833238s

on_epoch_end: 1615853043.145425s

Validation time: 4.991156s

Real time: 1615853043.145425s

Epoch time: 46.03804922103882s

50000/50000 [==============================] - 46s 921us/sample - loss: 7.9231 - accuracy: 0.0480 - val_loss: 383.6815 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615853043.145642s

Real time: 1615853043.1456468
Epoch 2/5

on_train_batch_begin: 1615853043.149086s

on_train_batch_end: 1615853043.789606s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.5359 - accuracy: 0.0744
on_train_batch_begin: 1615853043.789910s

1 step training time: 0.640824s

on_train_batch_end: 1615853044.434079s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.5138 - accuracy: 0.0735
on_train_batch_begin: 1615853044.434481s

2 step training time: 0.644571s

on_train_batch_end: 1615853045.084697s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.4647 - accuracy: 0.0726
on_train_batch_begin: 1615853045.084991s

3 step training time: 0.650510s

on_train_batch_end: 1615853045.732872s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.4206 - accuracy: 0.0728
on_train_batch_begin: 1615853045.733184s

4 step training time: 0.648193s

on_train_batch_end: 1615853046.381492s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.4075 - accuracy: 0.0750
on_train_batch_begin: 1615853046.381793s

5 step training time: 0.648609s

on_train_batch_end: 1615853047.021672s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.3696 - accuracy: 0.0744
on_train_batch_begin: 1615853047.021980s

6 step training time: 0.640187s

on_train_batch_end: 1615853047.668397s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.3351 - accuracy: 0.0746
on_train_batch_begin: 1615853047.668705s

7 step training time: 0.646726s

on_train_batch_end: 1615853048.312511s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.3203 - accuracy: 0.0742
on_train_batch_begin: 1615853048.312810s

8 step training time: 0.644104s

on_train_batch_end: 1615853048.953442s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.2979 - accuracy: 0.0741 
on_train_batch_begin: 1615853048.953742s

9 step training time: 0.640932s

on_train_batch_end: 1615853049.597407s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.2851 - accuracy: 0.0736
on_train_batch_begin: 1615853049.597705s

10 step training time: 0.643963s

on_train_batch_end: 1615853050.245862s

22528/50000 [============>.................] - ETA: 8s - loss: 6.2686 - accuracy: 0.0735
on_train_batch_begin: 1615853050.246168s

11 step training time: 0.648463s

on_train_batch_end: 1615853050.887551s

24576/50000 [=============>................] - ETA: 8s - loss: 6.2488 - accuracy: 0.0737
on_train_batch_begin: 1615853050.887858s

12 step training time: 0.641690s

on_train_batch_end: 1615853051.537332s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.2275 - accuracy: 0.0735
on_train_batch_begin: 1615853051.537631s

13 step training time: 0.649774s

on_train_batch_end: 1615853052.188220s

28672/50000 [================>.............] - ETA: 6s - loss: 6.2087 - accuracy: 0.0737
on_train_batch_begin: 1615853052.188516s

14 step training time: 0.650885s

on_train_batch_end: 1615853052.833078s

30720/50000 [=================>............] - ETA: 6s - loss: 6.1881 - accuracy: 0.0745
on_train_batch_begin: 1615853052.833373s

15 step training time: 0.644857s

on_train_batch_end: 1615853053.480865s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.1696 - accuracy: 0.0751
on_train_batch_begin: 1615853053.481161s

16 step training time: 0.647788s

on_train_batch_end: 1615853054.124160s

34816/50000 [===================>..........] - ETA: 4s - loss: 6.1435 - accuracy: 0.0758
on_train_batch_begin: 1615853054.124458s

17 step training time: 0.643297s

on_train_batch_end: 1615853054.771569s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.1350 - accuracy: 0.0758
on_train_batch_begin: 1615853054.771876s

18 step training time: 0.647418s

on_train_batch_end: 1615853055.409913s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.1153 - accuracy: 0.0762
on_train_batch_begin: 1615853055.410208s

19 step training time: 0.638331s

on_train_batch_end: 1615853056.058436s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.0952 - accuracy: 0.0763
on_train_batch_begin: 1615853056.058740s

20 step training time: 0.648533s

on_train_batch_end: 1615853056.708378s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.0736 - accuracy: 0.0769
on_train_batch_begin: 1615853056.708675s

21 step training time: 0.649935s

on_train_batch_end: 1615853057.351871s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.0545 - accuracy: 0.0771
on_train_batch_begin: 1615853057.352209s

22 step training time: 0.643534s

on_train_batch_end: 1615853057.997858s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.0375 - accuracy: 0.0773
on_train_batch_begin: 1615853057.998163s

23 step training time: 0.645953s

on_train_batch_end: 1615853058.635585s

49152/50000 [============================>.] - ETA: 0s - loss: 6.0198 - accuracy: 0.0771
on_train_batch_begin: 1615853058.635894s

24 step training time: 0.637731s

on_train_batch_end: 1615853058.910743s

on_test_batch_begin: 1615853058.930359s

25 step training time: 0.294466s

on_epoch_end: 1615853059.778670s

Validation time: 0.848299s

Real time: 1615853059.778670s

Epoch time: 16.633038759231567s

50000/50000 [==============================] - 17s 333us/sample - loss: 6.0124 - accuracy: 0.0771 - val_loss: 39479.9675 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615853059.778858s

Real time: 1615853059.7788625
Epoch 3/5

on_train_batch_begin: 1615853059.782396s

on_train_batch_end: 1615853060.420208s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.4041 - accuracy: 0.0814
on_train_batch_begin: 1615853060.420506s

1 step training time: 0.638110s

on_train_batch_end: 1615853061.068740s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.3394 - accuracy: 0.0822
on_train_batch_begin: 1615853061.069042s

2 step training time: 0.648536s

on_train_batch_end: 1615853061.714004s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.3580 - accuracy: 0.0825
on_train_batch_begin: 1615853061.714302s

3 step training time: 0.645260s

on_train_batch_end: 1615853062.362760s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.3729 - accuracy: 0.0814
on_train_batch_begin: 1615853062.363061s

4 step training time: 0.648758s

on_train_batch_end: 1615853063.004568s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.3864 - accuracy: 0.0793
on_train_batch_begin: 1615853063.004866s

5 step training time: 0.641805s

on_train_batch_end: 1615853063.645402s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.3786 - accuracy: 0.0787
on_train_batch_begin: 1615853063.645716s

6 step training time: 0.640850s

on_train_batch_end: 1615853064.287867s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.3791 - accuracy: 0.0782
on_train_batch_begin: 1615853064.288186s

7 step training time: 0.642470s

on_train_batch_end: 1615853064.931340s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.3538 - accuracy: 0.0776
on_train_batch_begin: 1615853064.931649s

8 step training time: 0.643463s

on_train_batch_end: 1615853065.578745s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.3435 - accuracy: 0.0772 
on_train_batch_begin: 1615853065.579046s

9 step training time: 0.647397s

on_train_batch_end: 1615853066.230506s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.3422 - accuracy: 0.0764
on_train_batch_begin: 1615853066.230814s

10 step training time: 0.651768s

on_train_batch_end: 1615853066.874038s

22528/50000 [============>.................] - ETA: 8s - loss: 5.3409 - accuracy: 0.0760
on_train_batch_begin: 1615853066.874347s

11 step training time: 0.643533s

on_train_batch_end: 1615853067.524237s

24576/50000 [=============>................] - ETA: 8s - loss: 5.3368 - accuracy: 0.0759
on_train_batch_begin: 1615853067.524558s

12 step training time: 0.650211s

on_train_batch_end: 1615853068.176877s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.3310 - accuracy: 0.0757
on_train_batch_begin: 1615853068.177175s

13 step training time: 0.652617s

on_train_batch_end: 1615853068.821099s

28672/50000 [================>.............] - ETA: 6s - loss: 5.3283 - accuracy: 0.0751
on_train_batch_begin: 1615853068.821395s

14 step training time: 0.644220s

on_train_batch_end: 1615853069.469084s

30720/50000 [=================>............] - ETA: 6s - loss: 5.3193 - accuracy: 0.0755
on_train_batch_begin: 1615853069.469401s

15 step training time: 0.648006s

on_train_batch_end: 1615853070.108682s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.3141 - accuracy: 0.0760
on_train_batch_begin: 1615853070.108979s

16 step training time: 0.639578s

on_train_batch_end: 1615853070.746943s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.3287 - accuracy: 0.0761
on_train_batch_begin: 1615853070.747258s

17 step training time: 0.638279s

on_train_batch_end: 1615853071.390941s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.3226 - accuracy: 0.0762
on_train_batch_begin: 1615853071.391257s

18 step training time: 0.643998s

on_train_batch_end: 1615853072.034717s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.3194 - accuracy: 0.0764
on_train_batch_begin: 1615853072.035019s

19 step training time: 0.643762s

on_train_batch_end: 1615853072.683193s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.3167 - accuracy: 0.0768
on_train_batch_begin: 1615853072.683495s

20 step training time: 0.648476s

on_train_batch_end: 1615853073.324777s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.3161 - accuracy: 0.0771
on_train_batch_begin: 1615853073.325086s

21 step training time: 0.641592s

on_train_batch_end: 1615853073.977546s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.3131 - accuracy: 0.0774
on_train_batch_begin: 1615853073.977861s

22 step training time: 0.652775s

on_train_batch_end: 1615853074.615799s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.3037 - accuracy: 0.0779
on_train_batch_begin: 1615853074.616132s

23 step training time: 0.638270s

on_train_batch_end: 1615853075.261352s

49152/50000 [============================>.] - ETA: 0s - loss: 5.2990 - accuracy: 0.0787
on_train_batch_begin: 1615853075.261657s

24 step training time: 0.645525s

on_train_batch_end: 1615853075.533362s

on_test_batch_begin: 1615853075.552900s

25 step training time: 0.291244s

on_epoch_end: 1615853076.419262s

Validation time: 0.866351s

Real time: 1615853076.419262s

Epoch time: 16.640416622161865s

50000/50000 [==============================] - 17s 333us/sample - loss: 5.3005 - accuracy: 0.0788 - val_loss: 2223.6503 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615853076.419467s

Real time: 1615853076.4194725
Epoch 4/5

on_train_batch_begin: 1615853076.422810s

on_train_batch_end: 1615853077.063597s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.0467 - accuracy: 0.0926
on_train_batch_begin: 1615853077.063898s

1 step training time: 0.641088s

on_train_batch_end: 1615853077.713186s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.1154 - accuracy: 0.0877
on_train_batch_begin: 1615853077.713489s

2 step training time: 0.649590s

on_train_batch_end: 1615853078.358749s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.1150 - accuracy: 0.0887
on_train_batch_begin: 1615853078.359048s

3 step training time: 0.645560s

on_train_batch_end: 1615853079.011121s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.1301 - accuracy: 0.0882
on_train_batch_begin: 1615853079.011417s

4 step training time: 0.652369s

on_train_batch_end: 1615853079.659465s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.0927 - accuracy: 0.0893
on_train_batch_begin: 1615853079.659764s

5 step training time: 0.648347s

on_train_batch_end: 1615853080.302842s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.1009 - accuracy: 0.0900
on_train_batch_begin: 1615853080.303147s

6 step training time: 0.643382s

on_train_batch_end: 1615853080.947583s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.0849 - accuracy: 0.0906
on_train_batch_begin: 1615853080.947906s

7 step training time: 0.644759s

on_train_batch_end: 1615853081.590150s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.0769 - accuracy: 0.0905
on_train_batch_begin: 1615853081.590449s

8 step training time: 0.642543s

on_train_batch_end: 1615853082.234493s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.0805 - accuracy: 0.0905 
on_train_batch_begin: 1615853082.234791s

9 step training time: 0.644342s

on_train_batch_end: 1615853082.880832s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.0820 - accuracy: 0.0903
on_train_batch_begin: 1615853082.881136s

10 step training time: 0.646346s

on_train_batch_end: 1615853083.531738s

22528/50000 [============>.................] - ETA: 8s - loss: 5.0867 - accuracy: 0.0902
on_train_batch_begin: 1615853083.532055s

11 step training time: 0.650919s

on_train_batch_end: 1615853084.179688s

24576/50000 [=============>................] - ETA: 8s - loss: 5.0844 - accuracy: 0.0899
on_train_batch_begin: 1615853084.179987s

12 step training time: 0.647932s

on_train_batch_end: 1615853084.828863s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.0836 - accuracy: 0.0895
on_train_batch_begin: 1615853084.829178s

13 step training time: 0.649191s

on_train_batch_end: 1615853085.478657s

28672/50000 [================>.............] - ETA: 6s - loss: 5.0786 - accuracy: 0.0895
on_train_batch_begin: 1615853085.478953s

14 step training time: 0.649776s

on_train_batch_end: 1615853086.121951s

30720/50000 [=================>............] - ETA: 6s - loss: 5.0805 - accuracy: 0.0896
on_train_batch_begin: 1615853086.122275s

15 step training time: 0.643322s

on_train_batch_end: 1615853086.775538s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.0708 - accuracy: 0.0898
on_train_batch_begin: 1615853086.775846s

16 step training time: 0.653571s

on_train_batch_end: 1615853087.416821s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.0717 - accuracy: 0.0900
on_train_batch_begin: 1615853087.417123s

17 step training time: 0.641276s

on_train_batch_end: 1615853088.061165s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.0660 - accuracy: 0.0901
on_train_batch_begin: 1615853088.061460s

18 step training time: 0.644337s

on_train_batch_end: 1615853088.701636s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.0612 - accuracy: 0.0899
on_train_batch_begin: 1615853088.701944s

19 step training time: 0.640484s

on_train_batch_end: 1615853089.347319s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.0476 - accuracy: 0.0897
on_train_batch_begin: 1615853089.347616s

20 step training time: 0.645672s

on_train_batch_end: 1615853089.991370s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.0489 - accuracy: 0.0894
on_train_batch_begin: 1615853089.991671s

21 step training time: 0.644055s

on_train_batch_end: 1615853090.637621s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.0430 - accuracy: 0.0892
on_train_batch_begin: 1615853090.637917s

22 step training time: 0.646246s

on_train_batch_end: 1615853091.276235s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.0373 - accuracy: 0.0888
on_train_batch_begin: 1615853091.276571s

23 step training time: 0.638654s

on_train_batch_end: 1615853091.920313s

49152/50000 [============================>.] - ETA: 0s - loss: 5.0380 - accuracy: 0.0884
on_train_batch_begin: 1615853091.920621s

24 step training time: 0.644051s

on_train_batch_end: 1615853092.192381s

on_test_batch_begin: 1615853092.212220s

25 step training time: 0.291599s

on_epoch_end: 1615853093.042441s

Validation time: 0.830208s

Real time: 1615853093.042441s

Epoch time: 16.62298583984375s

50000/50000 [==============================] - 17s 332us/sample - loss: 5.0370 - accuracy: 0.0884 - val_loss: 10.3531 - val_accuracy: 0.0956

on_epoch_begin: 1615853093.042629s

Real time: 1615853093.0426345
Epoch 5/5

on_train_batch_begin: 1615853093.045982s

on_train_batch_end: 1615853093.685780s

 2048/50000 [>.............................] - ETA: 15s - loss: 4.8783 - accuracy: 0.0812
on_train_batch_begin: 1615853093.686085s

1 step training time: 0.640103s

on_train_batch_end: 1615853094.333879s

 4096/50000 [=>............................] - ETA: 14s - loss: 4.8917 - accuracy: 0.0803
on_train_batch_begin: 1615853094.334190s

2 step training time: 0.648105s

on_train_batch_end: 1615853094.985161s

 6144/50000 [==>...........................] - ETA: 13s - loss: 4.8691 - accuracy: 0.0801
on_train_batch_begin: 1615853094.985492s

3 step training time: 0.651302s

on_train_batch_end: 1615853095.629441s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.8497 - accuracy: 0.0783
on_train_batch_begin: 1615853095.629744s

4 step training time: 0.644253s

on_train_batch_end: 1615853096.272833s

10240/50000 [=====>........................] - ETA: 12s - loss: 4.8561 - accuracy: 0.0770
on_train_batch_begin: 1615853096.273130s

5 step training time: 0.643386s

on_train_batch_end: 1615853096.923294s

12288/50000 [======>.......................] - ETA: 11s - loss: 4.8303 - accuracy: 0.0767
on_train_batch_begin: 1615853096.923612s

6 step training time: 0.650481s

on_train_batch_end: 1615853097.572872s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.8271 - accuracy: 0.0755
on_train_batch_begin: 1615853097.573167s

7 step training time: 0.649555s

on_train_batch_end: 1615853098.225017s

16384/50000 [========>.....................] - ETA: 10s - loss: 4.8022 - accuracy: 0.0752
on_train_batch_begin: 1615853098.225349s

8 step training time: 0.652182s

on_train_batch_end: 1615853098.878657s

18432/50000 [==========>...................] - ETA: 9s - loss: 4.7654 - accuracy: 0.0747 
on_train_batch_begin: 1615853098.878971s

9 step training time: 0.653623s

on_train_batch_end: 1615853099.522316s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.7374 - accuracy: 0.0743
on_train_batch_begin: 1615853099.522617s

10 step training time: 0.643646s

on_train_batch_end: 1615853100.167464s

22528/50000 [============>.................] - ETA: 8s - loss: 4.7182 - accuracy: 0.0735
on_train_batch_begin: 1615853100.167768s

11 step training time: 0.645150s

on_train_batch_end: 1615853100.814313s

24576/50000 [=============>................] - ETA: 8s - loss: 4.6898 - accuracy: 0.0731
on_train_batch_begin: 1615853100.814617s

12 step training time: 0.646849s

on_train_batch_end: 1615853101.461210s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.6494 - accuracy: 0.0728
on_train_batch_begin: 1615853101.461519s

13 step training time: 0.646902s

on_train_batch_end: 1615853102.114959s

28672/50000 [================>.............] - ETA: 6s - loss: 4.6077 - accuracy: 0.0730
on_train_batch_begin: 1615853102.115280s

14 step training time: 0.653761s

on_train_batch_end: 1615853102.765830s

30720/50000 [=================>............] - ETA: 6s - loss: 4.5779 - accuracy: 0.0729
on_train_batch_begin: 1615853102.766154s

15 step training time: 0.650874s

on_train_batch_end: 1615853103.422875s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.5416 - accuracy: 0.0731
on_train_batch_begin: 1615853103.423181s

16 step training time: 0.657026s

on_train_batch_end: 1615853104.070104s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.5069 - accuracy: 0.0732
on_train_batch_begin: 1615853104.070412s

17 step training time: 0.647232s

on_train_batch_end: 1615853104.725770s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.4751 - accuracy: 0.0735
on_train_batch_begin: 1615853104.726116s

18 step training time: 0.655704s

on_train_batch_end: 1615853105.382465s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.4347 - accuracy: 0.0740
on_train_batch_begin: 1615853105.382765s

19 step training time: 0.656648s

on_train_batch_end: 1615853106.035689s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.3948 - accuracy: 0.0745
on_train_batch_begin: 1615853106.035993s

20 step training time: 0.653229s

on_train_batch_end: 1615853106.686290s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.3595 - accuracy: 0.0749
on_train_batch_begin: 1615853106.686619s

21 step training time: 0.650626s

on_train_batch_end: 1615853107.333488s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.3160 - accuracy: 0.0754
on_train_batch_begin: 1615853107.333798s

22 step training time: 0.647179s

on_train_batch_end: 1615853107.981216s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.2774 - accuracy: 0.0758
on_train_batch_begin: 1615853107.981513s

23 step training time: 0.647715s

on_train_batch_end: 1615853108.630398s

49152/50000 [============================>.] - ETA: 0s - loss: 4.2387 - accuracy: 0.0763
on_train_batch_begin: 1615853108.630710s

24 step training time: 0.649197s

on_train_batch_end: 1615853108.904154s

on_test_batch_begin: 1615853108.923974s

25 step training time: 0.293264s

on_epoch_end: 1615853109.760307s

Validation time: 0.836319s

Real time: 1615853109.760307s

Epoch time: 16.717689752578735s

50000/50000 [==============================] - 17s 334us/sample - loss: 4.2170 - accuracy: 0.0764 - val_loss: 7.2872 - val_accuracy: 0.0000e+00
Tempo do fit: 116.04287433624268