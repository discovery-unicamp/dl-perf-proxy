wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:43
   122880/170498071 [..............................] - ETA: 1:40
   581632/170498071 [..............................] - ETA: 36s 
  2121728/170498071 [..............................] - ETA: 13s
  5201920/170498071 [..............................] - ETA: 7s 
  8167424/170498071 [>.............................] - ETA: 5s
 11231232/170498071 [>.............................] - ETA: 4s
 14295040/170498071 [=>............................] - ETA: 4s
 17260544/170498071 [==>...........................] - ETA: 3s
 20307968/170498071 [==>...........................] - ETA: 3s
 23502848/170498071 [===>..........................] - ETA: 3s
 26378240/170498071 [===>..........................] - ETA: 3s
 29433856/170498071 [====>.........................] - ETA: 2s
 32530432/170498071 [====>.........................] - ETA: 2s
 35479552/170498071 [=====>........................] - ETA: 2s
 38559744/170498071 [=====>........................] - ETA: 2s
 41623552/170498071 [======>.......................] - ETA: 2s
 44556288/170498071 [======>.......................] - ETA: 2s
 47685632/170498071 [=======>......................] - ETA: 2s
 50814976/170498071 [=======>......................] - ETA: 2s
 53862400/170498071 [========>.....................] - ETA: 2s
 56852480/170498071 [=========>....................] - ETA: 2s
 59924480/170498071 [=========>....................] - ETA: 2s
 63184896/170498071 [==========>...................] - ETA: 2s
 66428928/170498071 [==========>...................] - ETA: 1s
 69672960/170498071 [===========>..................] - ETA: 1s
 72966144/170498071 [===========>..................] - ETA: 1s
 76193792/170498071 [============>.................] - ETA: 1s
 79552512/170498071 [============>.................] - ETA: 1s
 82763776/170498071 [=============>................] - ETA: 1s
 86089728/170498071 [==============>...............] - ETA: 1s
 89448448/170498071 [==============>...............] - ETA: 1s
 92774400/170498071 [===============>..............] - ETA: 1s
 96034816/170498071 [===============>..............] - ETA: 1s
 99311616/170498071 [================>.............] - ETA: 1s
102604800/170498071 [=================>............] - ETA: 1s
105930752/170498071 [=================>............] - ETA: 1s
109289472/170498071 [==================>...........] - ETA: 1s
112566272/170498071 [==================>...........] - ETA: 0s
115908608/170498071 [===================>..........] - ETA: 0s
119209984/170498071 [===================>..........] - ETA: 0s
122544128/170498071 [====================>.........] - ETA: 0s
125820928/170498071 [=====================>........] - ETA: 0s
128966656/170498071 [=====================>........] - ETA: 0s
132292608/170498071 [======================>.......] - ETA: 0s
135643136/170498071 [======================>.......] - ETA: 0s
138846208/170498071 [=======================>......] - ETA: 0s
142204928/170498071 [========================>.....] - ETA: 0s
145514496/170498071 [========================>.....] - ETA: 0s
148873216/170498071 [=========================>....] - ETA: 0s
152150016/170498071 [=========================>....] - ETA: 0s
155410432/170498071 [==========================>...] - ETA: 0s
158720000/170498071 [==========================>...] - ETA: 0s
162013184/170498071 [===========================>..] - ETA: 0s
165208064/170498071 [============================>.] - ETA: 0s
168534016/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 1s
 9781248/94765736 [==>...........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
43597824/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
51380224/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
63684608/94765736 [===================>..........] - ETA: 0s
67764224/94765736 [====================>.........] - ETA: 0s
74366976/94765736 [======================>.......] - ETA: 0s
80003072/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.081953287124634
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615751438.184963s

Real time: 1615751438.1849813
Epoch 1/5

on_train_batch_begin: 1615751438.934361s

on_train_batch_end: 1615751455.864799s

 1024/50000 [..............................] - ETA: 14:05 - loss: 17.8679 - accuracy: 3.9482e-04
on_train_batch_begin: 1615751455.865397s

1 step training time: 16.931036s

on_train_batch_end: 1615751456.183491s

 2048/50000 [>.............................] - ETA: 7:01 - loss: 15.3670 - accuracy: 3.8147e-04 
on_train_batch_begin: 1615751456.183787s

2 step training time: 0.318390s

on_train_batch_end: 1615751456.504721s

 3072/50000 [>.............................] - ETA: 4:39 - loss: 13.2728 - accuracy: 5.6680e-04
on_train_batch_begin: 1615751456.505030s

3 step training time: 0.321243s

on_train_batch_end: 1615751456.828539s

 4096/50000 [=>............................] - ETA: 3:28 - loss: 12.0746 - accuracy: 9.5391e-04
on_train_batch_begin: 1615751456.828825s

4 step training time: 0.323795s

on_train_batch_end: 1615751457.149847s

 5120/50000 [==>...........................] - ETA: 2:46 - loss: 11.2969 - accuracy: 0.0014    
on_train_batch_begin: 1615751457.150118s

5 step training time: 0.321293s

on_train_batch_end: 1615751457.467679s

 6144/50000 [==>...........................] - ETA: 2:17 - loss: 10.7561 - accuracy: 0.0033
on_train_batch_begin: 1615751457.467957s

6 step training time: 0.317840s

on_train_batch_end: 1615751457.785237s

 7168/50000 [===>..........................] - ETA: 1:57 - loss: 10.3116 - accuracy: 0.0059
on_train_batch_begin: 1615751457.785527s

7 step training time: 0.317570s

on_train_batch_end: 1615751458.105248s

 8192/50000 [===>..........................] - ETA: 1:41 - loss: 9.9759 - accuracy: 0.0085 
on_train_batch_begin: 1615751458.105560s

8 step training time: 0.320033s

on_train_batch_end: 1615751458.424535s

 9216/50000 [====>.........................] - ETA: 1:29 - loss: 9.7041 - accuracy: 0.0116
on_train_batch_begin: 1615751458.424827s

9 step training time: 0.319267s

on_train_batch_end: 1615751458.741882s

10240/50000 [=====>........................] - ETA: 1:19 - loss: 9.4762 - accuracy: 0.0158
on_train_batch_begin: 1615751458.742216s

10 step training time: 0.317389s

on_train_batch_end: 1615751459.061754s

11264/50000 [=====>........................] - ETA: 1:11 - loss: 9.2724 - accuracy: 0.0195
on_train_batch_begin: 1615751459.062036s

11 step training time: 0.319819s

on_train_batch_end: 1615751459.384204s

12288/50000 [======>.......................] - ETA: 1:05 - loss: 9.1136 - accuracy: 0.0230
on_train_batch_begin: 1615751459.384469s

12 step training time: 0.322433s

on_train_batch_end: 1615751459.706913s

13312/50000 [======>.......................] - ETA: 59s - loss: 8.9682 - accuracy: 0.0259 
on_train_batch_begin: 1615751459.707167s

13 step training time: 0.322698s

on_train_batch_end: 1615751460.004854s

14336/50000 [=======>......................] - ETA: 54s - loss: 8.8280 - accuracy: 0.0278
on_train_batch_begin: 1615751460.005111s

14 step training time: 0.297944s

on_train_batch_end: 1615751460.322867s

15360/50000 [========>.....................] - ETA: 49s - loss: 8.7093 - accuracy: 0.0295
on_train_batch_begin: 1615751460.323125s

15 step training time: 0.318014s

on_train_batch_end: 1615751460.643125s

16384/50000 [========>.....................] - ETA: 46s - loss: 8.6011 - accuracy: 0.0313
on_train_batch_begin: 1615751460.643413s

16 step training time: 0.320288s

on_train_batch_end: 1615751460.967304s

17408/50000 [=========>....................] - ETA: 42s - loss: 8.4963 - accuracy: 0.0339
on_train_batch_begin: 1615751460.967597s

17 step training time: 0.324184s

on_train_batch_end: 1615751461.285805s

18432/50000 [==========>...................] - ETA: 39s - loss: 8.4031 - accuracy: 0.0360
on_train_batch_begin: 1615751461.286077s

18 step training time: 0.318480s

on_train_batch_end: 1615751461.603402s

19456/50000 [==========>...................] - ETA: 36s - loss: 8.3107 - accuracy: 0.0374
on_train_batch_begin: 1615751461.603677s

19 step training time: 0.317600s

on_train_batch_end: 1615751461.924599s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.2302 - accuracy: 0.0393
on_train_batch_begin: 1615751461.924863s

20 step training time: 0.321186s

on_train_batch_end: 1615751462.239356s

21504/50000 [===========>..................] - ETA: 31s - loss: 8.1581 - accuracy: 0.0410
on_train_batch_begin: 1615751462.239655s

21 step training time: 0.314792s

on_train_batch_end: 1615751462.558574s

22528/50000 [============>.................] - ETA: 29s - loss: 8.0900 - accuracy: 0.0420
on_train_batch_begin: 1615751462.558872s

22 step training time: 0.319217s

on_train_batch_end: 1615751462.878678s

23552/50000 [=============>................] - ETA: 27s - loss: 8.0219 - accuracy: 0.0431
on_train_batch_begin: 1615751462.878962s

23 step training time: 0.320090s

on_train_batch_end: 1615751463.197837s

24576/50000 [=============>................] - ETA: 25s - loss: 7.9695 - accuracy: 0.0439
on_train_batch_begin: 1615751463.198097s

24 step training time: 0.319135s

on_train_batch_end: 1615751463.516082s

25600/50000 [==============>...............] - ETA: 24s - loss: 7.9097 - accuracy: 0.0449
on_train_batch_begin: 1615751463.516361s

25 step training time: 0.318264s

on_train_batch_end: 1615751463.835580s

26624/50000 [==============>...............] - ETA: 22s - loss: 7.8547 - accuracy: 0.0451
on_train_batch_begin: 1615751463.835837s

26 step training time: 0.319476s

on_train_batch_end: 1615751464.157563s

27648/50000 [===============>..............] - ETA: 20s - loss: 7.8039 - accuracy: 0.0455
on_train_batch_begin: 1615751464.157860s

27 step training time: 0.322023s

on_train_batch_end: 1615751464.481542s

28672/50000 [================>.............] - ETA: 19s - loss: 7.7480 - accuracy: 0.0464
on_train_batch_begin: 1615751464.481866s

28 step training time: 0.324006s

on_train_batch_end: 1615751464.804970s

29696/50000 [================>.............] - ETA: 18s - loss: 7.6985 - accuracy: 0.0469
on_train_batch_begin: 1615751464.805271s

29 step training time: 0.323405s

on_train_batch_end: 1615751465.127742s

30720/50000 [=================>............] - ETA: 16s - loss: 7.6519 - accuracy: 0.0474
on_train_batch_begin: 1615751465.128053s

30 step training time: 0.322782s

on_train_batch_end: 1615751465.444531s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.6075 - accuracy: 0.0478
on_train_batch_begin: 1615751465.444828s

31 step training time: 0.316776s

on_train_batch_end: 1615751465.763832s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.5650 - accuracy: 0.0484
on_train_batch_begin: 1615751465.764134s

32 step training time: 0.319306s

on_train_batch_end: 1615751466.086159s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.5229 - accuracy: 0.0488
on_train_batch_begin: 1615751466.086457s

33 step training time: 0.322323s

on_train_batch_end: 1615751466.408207s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.4815 - accuracy: 0.0493
on_train_batch_begin: 1615751466.408501s

34 step training time: 0.322044s

on_train_batch_end: 1615751466.731214s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.4414 - accuracy: 0.0496
on_train_batch_begin: 1615751466.731506s

35 step training time: 0.323005s

on_train_batch_end: 1615751467.056009s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.4061 - accuracy: 0.0502
on_train_batch_begin: 1615751467.056301s

36 step training time: 0.324796s

on_train_batch_end: 1615751467.380781s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.3748 - accuracy: 0.0505 
on_train_batch_begin: 1615751467.381068s

37 step training time: 0.324767s

on_train_batch_end: 1615751467.703791s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.3373 - accuracy: 0.0507
on_train_batch_begin: 1615751467.704042s

38 step training time: 0.322974s

on_train_batch_end: 1615751468.028072s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.3036 - accuracy: 0.0510
on_train_batch_begin: 1615751468.028317s

39 step training time: 0.324275s

on_train_batch_end: 1615751468.348704s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.2682 - accuracy: 0.0513
on_train_batch_begin: 1615751468.348965s

40 step training time: 0.320647s

on_train_batch_end: 1615751468.666445s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.2341 - accuracy: 0.0515
on_train_batch_begin: 1615751468.666727s

41 step training time: 0.317762s

on_train_batch_end: 1615751468.988542s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.2041 - accuracy: 0.0516
on_train_batch_begin: 1615751468.988826s

42 step training time: 0.322099s

on_train_batch_end: 1615751469.311342s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.1754 - accuracy: 0.0516
on_train_batch_begin: 1615751469.311616s

43 step training time: 0.322791s

on_train_batch_end: 1615751469.634916s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.1417 - accuracy: 0.0516
on_train_batch_begin: 1615751469.635180s

44 step training time: 0.323564s

on_train_batch_end: 1615751469.958940s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.1094 - accuracy: 0.0517
on_train_batch_begin: 1615751469.959191s

45 step training time: 0.324011s

on_train_batch_end: 1615751470.283671s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.0789 - accuracy: 0.0517
on_train_batch_begin: 1615751470.283938s

46 step training time: 0.324746s

on_train_batch_end: 1615751470.606673s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.0481 - accuracy: 0.0517
on_train_batch_begin: 1615751470.606935s

47 step training time: 0.322998s

on_train_batch_end: 1615751470.928378s

49152/50000 [============================>.] - ETA: 0s - loss: 7.0145 - accuracy: 0.0516
on_train_batch_begin: 1615751470.928683s

48 step training time: 0.321748s

on_train_batch_end: 1615751476.763221s

on_test_batch_begin: 1615751476.949530s

49 step training time: 6.020847s

on_epoch_end: 1615751481.521924s

Validation time: 4.572379s

Real time: 1615751481.521924s

Epoch time: 43.33697247505188s

50000/50000 [==============================] - 43s 867us/sample - loss: 6.9880 - accuracy: 0.0516 - val_loss: 34.4634 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615751481.522138s

Real time: 1615751481.5221438
Epoch 2/5

on_train_batch_begin: 1615751481.525418s

on_train_batch_end: 1615751481.851271s

 1024/50000 [..............................] - ETA: 15s - loss: 5.3458 - accuracy: 0.0494
on_train_batch_begin: 1615751481.851506s

1 step training time: 0.326089s

on_train_batch_end: 1615751482.172693s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.3212 - accuracy: 0.0488
on_train_batch_begin: 1615751482.172926s

2 step training time: 0.321420s

on_train_batch_end: 1615751482.495537s

 3072/50000 [>.............................] - ETA: 14s - loss: 5.3163 - accuracy: 0.0492
on_train_batch_begin: 1615751482.495809s

3 step training time: 0.322883s

on_train_batch_end: 1615751482.818669s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.2429 - accuracy: 0.0513
on_train_batch_begin: 1615751482.818941s

4 step training time: 0.323132s

on_train_batch_end: 1615751483.141629s

 5120/50000 [==>...........................] - ETA: 14s - loss: 5.2436 - accuracy: 0.0515
on_train_batch_begin: 1615751483.141939s

5 step training time: 0.322998s

on_train_batch_end: 1615751483.465708s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.2427 - accuracy: 0.0519
on_train_batch_begin: 1615751483.465985s

6 step training time: 0.324046s

on_train_batch_end: 1615751483.790013s

 7168/50000 [===>..........................] - ETA: 13s - loss: 5.2308 - accuracy: 0.0525
on_train_batch_begin: 1615751483.790277s

7 step training time: 0.324292s

on_train_batch_end: 1615751484.117570s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.1870 - accuracy: 0.0533
on_train_batch_begin: 1615751484.117838s

8 step training time: 0.327561s

on_train_batch_end: 1615751484.442810s

 9216/50000 [====>.........................] - ETA: 12s - loss: 5.1568 - accuracy: 0.0541
on_train_batch_begin: 1615751484.443107s

9 step training time: 0.325269s

on_train_batch_end: 1615751484.767284s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.1187 - accuracy: 0.0550
on_train_batch_begin: 1615751484.767581s

10 step training time: 0.324474s

on_train_batch_end: 1615751485.093598s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.0828 - accuracy: 0.0558
on_train_batch_begin: 1615751485.093898s

11 step training time: 0.326317s

on_train_batch_end: 1615751485.418971s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.0615 - accuracy: 0.0564
on_train_batch_begin: 1615751485.419257s

12 step training time: 0.325359s

on_train_batch_end: 1615751485.757579s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.0444 - accuracy: 0.0568
on_train_batch_begin: 1615751485.757872s

13 step training time: 0.338615s

on_train_batch_end: 1615751486.081273s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.0138 - accuracy: 0.0576
on_train_batch_begin: 1615751486.081601s

14 step training time: 0.323729s

on_train_batch_end: 1615751486.401801s

15360/50000 [========>.....................] - ETA: 11s - loss: 4.9913 - accuracy: 0.0581
on_train_batch_begin: 1615751486.402115s

15 step training time: 0.320513s

on_train_batch_end: 1615751486.727152s

16384/50000 [========>.....................] - ETA: 10s - loss: 4.9632 - accuracy: 0.0586
on_train_batch_begin: 1615751486.727451s

16 step training time: 0.325336s

on_train_batch_end: 1615751487.052628s

17408/50000 [=========>....................] - ETA: 10s - loss: 4.9420 - accuracy: 0.0591
on_train_batch_begin: 1615751487.052934s

17 step training time: 0.325483s

on_train_batch_end: 1615751487.376315s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.9205 - accuracy: 0.0597
on_train_batch_begin: 1615751487.376609s

18 step training time: 0.323674s

on_train_batch_end: 1615751487.701567s

19456/50000 [==========>...................] - ETA: 9s - loss: 4.8888 - accuracy: 0.0604 
on_train_batch_begin: 1615751487.701866s

19 step training time: 0.325257s

on_train_batch_end: 1615751488.025193s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.8563 - accuracy: 0.0611
on_train_batch_begin: 1615751488.025494s

20 step training time: 0.323628s

on_train_batch_end: 1615751488.349574s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.8257 - accuracy: 0.0616
on_train_batch_begin: 1615751488.349827s

21 step training time: 0.324333s

on_train_batch_end: 1615751488.676892s

22528/50000 [============>.................] - ETA: 8s - loss: 4.7873 - accuracy: 0.0623
on_train_batch_begin: 1615751488.677164s

22 step training time: 0.327337s

on_train_batch_end: 1615751488.998931s

23552/50000 [=============>................] - ETA: 8s - loss: 4.7587 - accuracy: 0.0629
on_train_batch_begin: 1615751488.999208s

23 step training time: 0.322043s

on_train_batch_end: 1615751489.322923s

24576/50000 [=============>................] - ETA: 8s - loss: 4.7284 - accuracy: 0.0634
on_train_batch_begin: 1615751489.323217s

24 step training time: 0.324009s

on_train_batch_end: 1615751489.647684s

25600/50000 [==============>...............] - ETA: 7s - loss: 4.6936 - accuracy: 0.0640
on_train_batch_begin: 1615751489.647965s

25 step training time: 0.324748s

on_train_batch_end: 1615751489.972459s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.6608 - accuracy: 0.0647
on_train_batch_begin: 1615751489.972749s

26 step training time: 0.324784s

on_train_batch_end: 1615751490.296607s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.6226 - accuracy: 0.0652
on_train_batch_begin: 1615751490.296877s

27 step training time: 0.324128s

on_train_batch_end: 1615751490.620159s

28672/50000 [================>.............] - ETA: 6s - loss: 4.5932 - accuracy: 0.0658
on_train_batch_begin: 1615751490.620414s

28 step training time: 0.323537s

on_train_batch_end: 1615751490.943869s

29696/50000 [================>.............] - ETA: 6s - loss: 4.5603 - accuracy: 0.0664
on_train_batch_begin: 1615751490.944114s

29 step training time: 0.323700s

on_train_batch_end: 1615751491.268046s

30720/50000 [=================>............] - ETA: 6s - loss: 4.5242 - accuracy: 0.0671
on_train_batch_begin: 1615751491.268343s

30 step training time: 0.324228s

on_train_batch_end: 1615751491.595282s

31744/50000 [==================>...........] - ETA: 5s - loss: 4.4885 - accuracy: 0.0678
on_train_batch_begin: 1615751491.595576s

31 step training time: 0.327233s

on_train_batch_end: 1615751491.920114s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.4613 - accuracy: 0.0684
on_train_batch_begin: 1615751491.920383s

32 step training time: 0.324807s

on_train_batch_end: 1615751492.243979s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.4274 - accuracy: 0.0691
on_train_batch_begin: 1615751492.244240s

33 step training time: 0.323857s

on_train_batch_end: 1615751492.568509s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.4044 - accuracy: 0.0697
on_train_batch_begin: 1615751492.568792s

34 step training time: 0.324551s

on_train_batch_end: 1615751492.892708s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.3738 - accuracy: 0.0704
on_train_batch_begin: 1615751492.892973s

35 step training time: 0.324181s

on_train_batch_end: 1615751493.217734s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.3420 - accuracy: 0.0711
on_train_batch_begin: 1615751493.218010s

36 step training time: 0.325037s

on_train_batch_end: 1615751493.544783s

37888/50000 [=====================>........] - ETA: 3s - loss: 4.3141 - accuracy: 0.0718
on_train_batch_begin: 1615751493.545076s

37 step training time: 0.327066s

on_train_batch_end: 1615751493.870110s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.2811 - accuracy: 0.0724
on_train_batch_begin: 1615751493.870388s

38 step training time: 0.325311s

on_train_batch_end: 1615751494.195798s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.2501 - accuracy: 0.0731
on_train_batch_begin: 1615751494.196087s

39 step training time: 0.325699s

on_train_batch_end: 1615751494.522737s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.2209 - accuracy: 0.0736
on_train_batch_begin: 1615751494.523032s

40 step training time: 0.326945s

on_train_batch_end: 1615751494.845644s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.1916 - accuracy: 0.0742
on_train_batch_begin: 1615751494.845936s

41 step training time: 0.322904s

on_train_batch_end: 1615751495.170182s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.1629 - accuracy: 0.0748
on_train_batch_begin: 1615751495.170467s

42 step training time: 0.324531s

on_train_batch_end: 1615751495.493736s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.1382 - accuracy: 0.0753
on_train_batch_begin: 1615751495.494025s

43 step training time: 0.323558s

on_train_batch_end: 1615751495.819293s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.1108 - accuracy: 0.0758
on_train_batch_begin: 1615751495.819574s

44 step training time: 0.325548s

on_train_batch_end: 1615751496.143788s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.0845 - accuracy: 0.0763
on_train_batch_begin: 1615751496.144058s

45 step training time: 0.324485s

on_train_batch_end: 1615751496.470084s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.0572 - accuracy: 0.0769
on_train_batch_begin: 1615751496.470388s

46 step training time: 0.326329s

on_train_batch_end: 1615751496.793787s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.0283 - accuracy: 0.0773
on_train_batch_begin: 1615751496.794063s

47 step training time: 0.323675s

on_train_batch_end: 1615751497.118631s

49152/50000 [============================>.] - ETA: 0s - loss: 4.0052 - accuracy: 0.0778
on_train_batch_begin: 1615751497.118906s

48 step training time: 0.324843s

on_train_batch_end: 1615751497.387767s

on_test_batch_begin: 1615751497.397768s

49 step training time: 0.278862s

on_epoch_end: 1615751498.175428s

Validation time: 0.777648s

Real time: 1615751498.175428s

Epoch time: 16.65330171585083s

50000/50000 [==============================] - 17s 333us/sample - loss: 3.9833 - accuracy: 0.0781 - val_loss: 10.0915 - val_accuracy: 0.0999

on_epoch_begin: 1615751498.175611s

Real time: 1615751498.1756172
Epoch 3/5

on_train_batch_begin: 1615751498.178821s

on_train_batch_end: 1615751498.506145s

 1024/50000 [..............................] - ETA: 15s - loss: 2.7393 - accuracy: 0.1011
on_train_batch_begin: 1615751498.506414s

1 step training time: 0.327593s

on_train_batch_end: 1615751498.833206s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.6236 - accuracy: 0.1005
on_train_batch_begin: 1615751498.833456s

2 step training time: 0.327042s

on_train_batch_end: 1615751499.160092s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.6030 - accuracy: 0.1006
on_train_batch_begin: 1615751499.160325s

3 step training time: 0.326869s

on_train_batch_end: 1615751499.487419s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.5421 - accuracy: 0.1004
on_train_batch_begin: 1615751499.487717s

4 step training time: 0.327392s

on_train_batch_end: 1615751499.812442s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.5326 - accuracy: 0.1003
on_train_batch_begin: 1615751499.812726s

5 step training time: 0.325008s

on_train_batch_end: 1615751500.138535s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.5128 - accuracy: 0.1002
on_train_batch_begin: 1615751500.138804s

6 step training time: 0.326079s

on_train_batch_end: 1615751500.465289s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.5077 - accuracy: 0.1001
on_train_batch_begin: 1615751500.465563s

7 step training time: 0.326759s

on_train_batch_end: 1615751500.792236s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.4846 - accuracy: 0.1000
on_train_batch_begin: 1615751500.792513s

8 step training time: 0.326950s

on_train_batch_end: 1615751501.120315s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.4510 - accuracy: 0.1000
on_train_batch_begin: 1615751501.120589s

9 step training time: 0.328076s

on_train_batch_end: 1615751501.448304s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.4036 - accuracy: 0.1000
on_train_batch_begin: 1615751501.448598s

10 step training time: 0.328009s

on_train_batch_end: 1615751501.776187s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.3789 - accuracy: 0.1000
on_train_batch_begin: 1615751501.776474s

11 step training time: 0.327876s

on_train_batch_end: 1615751502.103555s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.3570 - accuracy: 0.1000
on_train_batch_begin: 1615751502.103842s

12 step training time: 0.327368s

on_train_batch_end: 1615751502.427625s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.3370 - accuracy: 0.1000
on_train_batch_begin: 1615751502.427864s

13 step training time: 0.324021s

on_train_batch_end: 1615751502.753316s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.3236 - accuracy: 0.1000
on_train_batch_begin: 1615751502.753604s

14 step training time: 0.325740s

on_train_batch_end: 1615751503.079435s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.2924 - accuracy: 0.1000
on_train_batch_begin: 1615751503.079687s

15 step training time: 0.326083s

on_train_batch_end: 1615751503.404251s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.2711 - accuracy: 0.1000
on_train_batch_begin: 1615751503.404512s

16 step training time: 0.324825s

on_train_batch_end: 1615751503.731628s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.2498 - accuracy: 0.1000
on_train_batch_begin: 1615751503.731929s

17 step training time: 0.327417s

on_train_batch_end: 1615751504.055948s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.2207 - accuracy: 0.1001
on_train_batch_begin: 1615751504.056223s

18 step training time: 0.324294s

on_train_batch_end: 1615751504.379966s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.2030 - accuracy: 0.1001 
on_train_batch_begin: 1615751504.380250s

19 step training time: 0.324027s

on_train_batch_end: 1615751504.707242s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.1856 - accuracy: 0.1001
on_train_batch_begin: 1615751504.707530s

20 step training time: 0.327280s

on_train_batch_end: 1615751505.030974s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.1682 - accuracy: 0.1001
on_train_batch_begin: 1615751505.031241s

21 step training time: 0.323710s

on_train_batch_end: 1615751505.355852s

22528/50000 [============>.................] - ETA: 8s - loss: 2.1502 - accuracy: 0.1001
on_train_batch_begin: 1615751505.356115s

22 step training time: 0.324874s

on_train_batch_end: 1615751505.679745s

23552/50000 [=============>................] - ETA: 8s - loss: 2.1324 - accuracy: 0.1001
on_train_batch_begin: 1615751505.680044s

23 step training time: 0.323929s

on_train_batch_end: 1615751506.005447s

24576/50000 [=============>................] - ETA: 8s - loss: 2.1219 - accuracy: 0.1001
on_train_batch_begin: 1615751506.005743s

24 step training time: 0.325699s

on_train_batch_end: 1615751506.331293s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.1140 - accuracy: 0.1001
on_train_batch_begin: 1615751506.331544s

25 step training time: 0.325802s

on_train_batch_end: 1615751506.658710s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.0992 - accuracy: 0.1001
on_train_batch_begin: 1615751506.659004s

26 step training time: 0.327460s

on_train_batch_end: 1615751506.986339s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.0896 - accuracy: 0.1001
on_train_batch_begin: 1615751506.986597s

27 step training time: 0.327592s

on_train_batch_end: 1615751507.313793s

28672/50000 [================>.............] - ETA: 6s - loss: 2.0777 - accuracy: 0.1001
on_train_batch_begin: 1615751507.314058s

28 step training time: 0.327461s

on_train_batch_end: 1615751507.641150s

29696/50000 [================>.............] - ETA: 6s - loss: 2.0655 - accuracy: 0.1001
on_train_batch_begin: 1615751507.641446s

29 step training time: 0.327388s

on_train_batch_end: 1615751507.966391s

30720/50000 [=================>............] - ETA: 6s - loss: 2.0573 - accuracy: 0.1001
on_train_batch_begin: 1615751507.966676s

30 step training time: 0.325230s

on_train_batch_end: 1615751508.291987s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.0461 - accuracy: 0.1001
on_train_batch_begin: 1615751508.292278s

31 step training time: 0.325602s

on_train_batch_end: 1615751508.617872s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.0338 - accuracy: 0.1001
on_train_batch_begin: 1615751508.618147s

32 step training time: 0.325869s

on_train_batch_end: 1615751508.943757s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.0190 - accuracy: 0.1001
on_train_batch_begin: 1615751508.944008s

33 step training time: 0.325861s

on_train_batch_end: 1615751509.268616s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.0094 - accuracy: 0.1002
on_train_batch_begin: 1615751509.268876s

34 step training time: 0.324868s

on_train_batch_end: 1615751509.600196s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.9972 - accuracy: 0.1002
on_train_batch_begin: 1615751509.600474s

35 step training time: 0.331598s

on_train_batch_end: 1615751509.928913s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.9858 - accuracy: 0.1002
on_train_batch_begin: 1615751509.929201s

36 step training time: 0.328727s

on_train_batch_end: 1615751510.257283s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.9740 - accuracy: 0.1002
on_train_batch_begin: 1615751510.257571s

37 step training time: 0.328369s

on_train_batch_end: 1615751510.583848s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.9634 - accuracy: 0.1002
on_train_batch_begin: 1615751510.584124s

38 step training time: 0.326553s

on_train_batch_end: 1615751510.908828s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.9497 - accuracy: 0.1002
on_train_batch_begin: 1615751510.909082s

39 step training time: 0.324959s

on_train_batch_end: 1615751511.235340s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.9370 - accuracy: 0.1002
on_train_batch_begin: 1615751511.235598s

40 step training time: 0.326516s

on_train_batch_end: 1615751511.562972s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.9245 - accuracy: 0.1002
on_train_batch_begin: 1615751511.563291s

41 step training time: 0.327693s

on_train_batch_end: 1615751511.892252s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.9140 - accuracy: 0.1002
on_train_batch_begin: 1615751511.892545s

42 step training time: 0.329253s

on_train_batch_end: 1615751512.220942s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.9034 - accuracy: 0.1002
on_train_batch_begin: 1615751512.221230s

43 step training time: 0.328686s

on_train_batch_end: 1615751512.547827s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8915 - accuracy: 0.1002
on_train_batch_begin: 1615751512.548075s

44 step training time: 0.326845s

on_train_batch_end: 1615751512.875365s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.8783 - accuracy: 0.1002
on_train_batch_begin: 1615751512.875617s

45 step training time: 0.327542s

on_train_batch_end: 1615751513.202636s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8691 - accuracy: 0.1002
on_train_batch_begin: 1615751513.202892s

46 step training time: 0.327275s

on_train_batch_end: 1615751513.527757s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.8631 - accuracy: 0.1002
on_train_batch_begin: 1615751513.528012s

47 step training time: 0.325121s

on_train_batch_end: 1615751513.853127s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8543 - accuracy: 0.1002
on_train_batch_begin: 1615751513.853420s

48 step training time: 0.325408s

on_train_batch_end: 1615751514.121747s

on_test_batch_begin: 1615751514.134267s

49 step training time: 0.280847s

on_epoch_end: 1615751514.912146s

Validation time: 0.777869s

Real time: 1615751514.912146s

Epoch time: 16.73654270172119s

50000/50000 [==============================] - 17s 335us/sample - loss: 1.8482 - accuracy: 0.1002 - val_loss: 7.4080 - val_accuracy: 2.3160e-04

on_epoch_begin: 1615751514.912325s

Real time: 1615751514.9123302
Epoch 4/5

on_train_batch_begin: 1615751514.915539s

on_train_batch_end: 1615751515.242295s

 1024/50000 [..............................] - ETA: 15s - loss: 1.1542 - accuracy: 0.1001
on_train_batch_begin: 1615751515.242520s

1 step training time: 0.326982s

on_train_batch_end: 1615751515.569798s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.1897 - accuracy: 0.1000
on_train_batch_begin: 1615751515.570045s

2 step training time: 0.327525s

on_train_batch_end: 1615751515.897258s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.3099 - accuracy: 0.1000
on_train_batch_begin: 1615751515.897565s

3 step training time: 0.327519s

on_train_batch_end: 1615751516.224417s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.2659 - accuracy: 0.1001
on_train_batch_begin: 1615751516.224680s

4 step training time: 0.327115s

on_train_batch_end: 1615751516.551034s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.2544 - accuracy: 0.1002
on_train_batch_begin: 1615751516.551305s

5 step training time: 0.326626s

on_train_batch_end: 1615751516.882638s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.2723 - accuracy: 0.1002
on_train_batch_begin: 1615751516.882925s

6 step training time: 0.331620s

on_train_batch_end: 1615751517.210513s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.2698 - accuracy: 0.1002
on_train_batch_begin: 1615751517.210769s

7 step training time: 0.327844s

on_train_batch_end: 1615751517.538204s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.2664 - accuracy: 0.1002
on_train_batch_begin: 1615751517.538465s

8 step training time: 0.327696s

on_train_batch_end: 1615751517.856401s

 9216/50000 [====>.........................] - ETA: 13s - loss: 1.2500 - accuracy: 0.1002
on_train_batch_begin: 1615751517.856653s

9 step training time: 0.318187s

on_train_batch_end: 1615751518.184658s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.2520 - accuracy: 0.1002
on_train_batch_begin: 1615751518.184941s

10 step training time: 0.328288s

on_train_batch_end: 1615751518.513078s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.2576 - accuracy: 0.1002
on_train_batch_begin: 1615751518.513350s

11 step training time: 0.328410s

on_train_batch_end: 1615751518.838659s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.2534 - accuracy: 0.1003
on_train_batch_begin: 1615751518.838920s

12 step training time: 0.325570s

on_train_batch_end: 1615751519.163408s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.2528 - accuracy: 0.1003
on_train_batch_begin: 1615751519.163661s

13 step training time: 0.324741s

on_train_batch_end: 1615751519.492070s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.2482 - accuracy: 0.1003
on_train_batch_begin: 1615751519.492340s

14 step training time: 0.328679s

on_train_batch_end: 1615751519.819377s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.2361 - accuracy: 0.1003
on_train_batch_begin: 1615751519.819638s

15 step training time: 0.327298s

on_train_batch_end: 1615751520.150311s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.2299 - accuracy: 0.1003
on_train_batch_begin: 1615751520.150604s

16 step training time: 0.330966s

on_train_batch_end: 1615751520.479043s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.2246 - accuracy: 0.1003
on_train_batch_begin: 1615751520.479313s

17 step training time: 0.328709s

on_train_batch_end: 1615751520.805918s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.2300 - accuracy: 0.1003
on_train_batch_begin: 1615751520.806177s

18 step training time: 0.326865s

on_train_batch_end: 1615751521.132457s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.2297 - accuracy: 0.1003 
on_train_batch_begin: 1615751521.132721s

19 step training time: 0.326544s

on_train_batch_end: 1615751521.447010s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.2248 - accuracy: 0.1003
on_train_batch_begin: 1615751521.447278s

20 step training time: 0.314557s

on_train_batch_end: 1615751521.779554s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.2267 - accuracy: 0.1003
on_train_batch_begin: 1615751521.779854s

21 step training time: 0.332576s

on_train_batch_end: 1615751522.107514s

22528/50000 [============>.................] - ETA: 8s - loss: 1.2214 - accuracy: 0.1003
on_train_batch_begin: 1615751522.107812s

22 step training time: 0.327958s

on_train_batch_end: 1615751522.432725s

23552/50000 [=============>................] - ETA: 8s - loss: 1.2198 - accuracy: 0.1003
on_train_batch_begin: 1615751522.433013s

23 step training time: 0.325201s

on_train_batch_end: 1615751522.762037s

24576/50000 [=============>................] - ETA: 8s - loss: 1.2172 - accuracy: 0.1003
on_train_batch_begin: 1615751522.762333s

24 step training time: 0.329320s

on_train_batch_end: 1615751523.090964s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.2117 - accuracy: 0.1003
on_train_batch_begin: 1615751523.091233s

25 step training time: 0.328900s

on_train_batch_end: 1615751523.422162s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.2127 - accuracy: 0.1003
on_train_batch_begin: 1615751523.422416s

26 step training time: 0.331183s

on_train_batch_end: 1615751523.748350s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.2138 - accuracy: 0.1003
on_train_batch_begin: 1615751523.748590s

27 step training time: 0.326173s

on_train_batch_end: 1615751524.076710s

28672/50000 [================>.............] - ETA: 6s - loss: 1.2104 - accuracy: 0.1003
on_train_batch_begin: 1615751524.077015s

28 step training time: 0.328425s

on_train_batch_end: 1615751524.405455s

29696/50000 [================>.............] - ETA: 6s - loss: 1.2049 - accuracy: 0.1003
on_train_batch_begin: 1615751524.405787s

29 step training time: 0.328772s

on_train_batch_end: 1615751524.737405s

30720/50000 [=================>............] - ETA: 6s - loss: 1.2039 - accuracy: 0.1003
on_train_batch_begin: 1615751524.737710s

30 step training time: 0.331923s

on_train_batch_end: 1615751525.067058s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.1951 - accuracy: 0.1003
on_train_batch_begin: 1615751525.067348s

31 step training time: 0.329639s

on_train_batch_end: 1615751525.394301s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.1921 - accuracy: 0.1003
on_train_batch_begin: 1615751525.394593s

32 step training time: 0.327245s

on_train_batch_end: 1615751525.721666s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.1888 - accuracy: 0.1003
on_train_batch_begin: 1615751525.721971s

33 step training time: 0.327378s

on_train_batch_end: 1615751526.054786s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.1813 - accuracy: 0.1003
on_train_batch_begin: 1615751526.055081s

34 step training time: 0.333110s

on_train_batch_end: 1615751526.383929s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.1785 - accuracy: 0.1003
on_train_batch_begin: 1615751526.384221s

35 step training time: 0.329140s

on_train_batch_end: 1615751526.711325s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.1754 - accuracy: 0.1003
on_train_batch_begin: 1615751526.711607s

36 step training time: 0.327385s

on_train_batch_end: 1615751527.039632s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.1727 - accuracy: 0.1003
on_train_batch_begin: 1615751527.039927s

37 step training time: 0.328321s

on_train_batch_end: 1615751527.370072s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.1676 - accuracy: 0.1003
on_train_batch_begin: 1615751527.370350s

38 step training time: 0.330422s

on_train_batch_end: 1615751527.699848s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.1650 - accuracy: 0.1002
on_train_batch_begin: 1615751527.700117s

39 step training time: 0.329767s

on_train_batch_end: 1615751528.026315s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.1609 - accuracy: 0.1002
on_train_batch_begin: 1615751528.026591s

40 step training time: 0.326475s

on_train_batch_end: 1615751528.353254s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.1564 - accuracy: 0.1002
on_train_batch_begin: 1615751528.353561s

41 step training time: 0.326970s

on_train_batch_end: 1615751528.681658s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.1557 - accuracy: 0.1002
on_train_batch_begin: 1615751528.681943s

42 step training time: 0.328382s

on_train_batch_end: 1615751529.006576s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.1546 - accuracy: 0.1003
on_train_batch_begin: 1615751529.006852s

43 step training time: 0.324909s

on_train_batch_end: 1615751529.336421s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.1519 - accuracy: 0.1002
on_train_batch_begin: 1615751529.336690s

44 step training time: 0.329838s

on_train_batch_end: 1615751529.667336s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.1489 - accuracy: 0.1002
on_train_batch_begin: 1615751529.667610s

45 step training time: 0.330920s

on_train_batch_end: 1615751529.995368s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.1493 - accuracy: 0.1002
on_train_batch_begin: 1615751529.995639s

46 step training time: 0.328028s

on_train_batch_end: 1615751530.323926s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1469 - accuracy: 0.1002
on_train_batch_begin: 1615751530.324219s

47 step training time: 0.328581s

on_train_batch_end: 1615751530.652559s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1463 - accuracy: 0.1002
on_train_batch_begin: 1615751530.652834s

48 step training time: 0.328615s

on_train_batch_end: 1615751530.930636s

on_test_batch_begin: 1615751530.940348s

49 step training time: 0.287514s

on_epoch_end: 1615751531.723355s

Validation time: 0.782996s

Real time: 1615751531.723355s

Epoch time: 16.811041355133057s

50000/50000 [==============================] - 17s 336us/sample - loss: 1.1467 - accuracy: 0.1002 - val_loss: 6.8863 - val_accuracy: 0.0998

on_epoch_begin: 1615751531.723537s

Real time: 1615751531.7235427
Epoch 5/5

on_train_batch_begin: 1615751531.726724s

on_train_batch_end: 1615751532.055569s

 1024/50000 [..............................] - ETA: 15s - loss: 0.9287 - accuracy: 0.1001
on_train_batch_begin: 1615751532.055859s

1 step training time: 0.329134s

on_train_batch_end: 1615751532.385197s

 2048/50000 [>.............................] - ETA: 15s - loss: 0.9031 - accuracy: 0.1002
on_train_batch_begin: 1615751532.385501s

2 step training time: 0.329642s

on_train_batch_end: 1615751532.716287s

 3072/50000 [>.............................] - ETA: 15s - loss: 0.9117 - accuracy: 0.1002
on_train_batch_begin: 1615751532.716567s

3 step training time: 0.331066s

on_train_batch_end: 1615751533.044053s

 4096/50000 [=>............................] - ETA: 14s - loss: 0.8960 - accuracy: 0.1003
on_train_batch_begin: 1615751533.044324s

4 step training time: 0.327757s

on_train_batch_end: 1615751533.373394s

 5120/50000 [==>...........................] - ETA: 14s - loss: 0.8666 - accuracy: 0.1002
on_train_batch_begin: 1615751533.373700s

5 step training time: 0.329376s

on_train_batch_end: 1615751533.705338s

 6144/50000 [==>...........................] - ETA: 14s - loss: 0.8633 - accuracy: 0.1003
on_train_batch_begin: 1615751533.705657s

6 step training time: 0.331957s

on_train_batch_end: 1615751534.032712s

 7168/50000 [===>..........................] - ETA: 13s - loss: 0.8789 - accuracy: 0.1004
on_train_batch_begin: 1615751534.032970s

7 step training time: 0.327314s

on_train_batch_end: 1615751534.359797s

 8192/50000 [===>..........................] - ETA: 13s - loss: 0.8769 - accuracy: 0.1004
on_train_batch_begin: 1615751534.360122s

8 step training time: 0.327152s

on_train_batch_end: 1615751534.695927s

 9216/50000 [====>.........................] - ETA: 13s - loss: 0.8703 - accuracy: 0.1003
on_train_batch_begin: 1615751534.696220s

9 step training time: 0.336098s

on_train_batch_end: 1615751535.024817s

10240/50000 [=====>........................] - ETA: 12s - loss: 0.8577 - accuracy: 0.1003
on_train_batch_begin: 1615751535.025109s

10 step training time: 0.328888s

on_train_batch_end: 1615751535.353616s

11264/50000 [=====>........................] - ETA: 12s - loss: 0.8621 - accuracy: 0.1003
on_train_batch_begin: 1615751535.353882s

11 step training time: 0.328773s

on_train_batch_end: 1615751535.684234s

12288/50000 [======>.......................] - ETA: 12s - loss: 0.8693 - accuracy: 0.1003
on_train_batch_begin: 1615751535.684501s

12 step training time: 0.330619s

on_train_batch_end: 1615751536.018375s

13312/50000 [======>.......................] - ETA: 11s - loss: 0.8664 - accuracy: 0.1003
on_train_batch_begin: 1615751536.018628s

13 step training time: 0.334127s

on_train_batch_end: 1615751536.345405s

14336/50000 [=======>......................] - ETA: 11s - loss: 0.8689 - accuracy: 0.1003
on_train_batch_begin: 1615751536.345710s

14 step training time: 0.327082s

on_train_batch_end: 1615751536.673567s

15360/50000 [========>.....................] - ETA: 11s - loss: 0.8732 - accuracy: 0.1003
on_train_batch_begin: 1615751536.673857s

15 step training time: 0.328147s

on_train_batch_end: 1615751537.006897s

16384/50000 [========>.....................] - ETA: 10s - loss: 0.8692 - accuracy: 0.1003
on_train_batch_begin: 1615751537.007193s

16 step training time: 0.333336s

on_train_batch_end: 1615751537.337442s

17408/50000 [=========>....................] - ETA: 10s - loss: 0.8655 - accuracy: 0.1003
on_train_batch_begin: 1615751537.337759s

17 step training time: 0.330565s

on_train_batch_end: 1615751537.665059s

18432/50000 [==========>...................] - ETA: 10s - loss: 0.8633 - accuracy: 0.1003
on_train_batch_begin: 1615751537.665347s

18 step training time: 0.327589s

on_train_batch_end: 1615751537.995504s

19456/50000 [==========>...................] - ETA: 9s - loss: 0.8578 - accuracy: 0.1003 
on_train_batch_begin: 1615751537.995771s

19 step training time: 0.330424s

on_train_batch_end: 1615751538.326865s

20480/50000 [===========>..................] - ETA: 9s - loss: 0.8549 - accuracy: 0.1003
on_train_batch_begin: 1615751538.327124s

20 step training time: 0.331353s

on_train_batch_end: 1615751538.656005s

21504/50000 [===========>..................] - ETA: 9s - loss: 0.8562 - accuracy: 0.1003
on_train_batch_begin: 1615751538.656301s

21 step training time: 0.329177s

on_train_batch_end: 1615751538.984046s

22528/50000 [============>.................] - ETA: 8s - loss: 0.8547 - accuracy: 0.1003
on_train_batch_begin: 1615751538.984302s

22 step training time: 0.328001s

on_train_batch_end: 1615751539.311205s

23552/50000 [=============>................] - ETA: 8s - loss: 0.8504 - accuracy: 0.1003
on_train_batch_begin: 1615751539.311453s

23 step training time: 0.327151s

on_train_batch_end: 1615751539.642443s

24576/50000 [=============>................] - ETA: 8s - loss: 0.8483 - accuracy: 0.1003
on_train_batch_begin: 1615751539.642700s

24 step training time: 0.331247s

on_train_batch_end: 1615751539.970887s

25600/50000 [==============>...............] - ETA: 7s - loss: 0.8490 - accuracy: 0.1003
on_train_batch_begin: 1615751539.971184s

25 step training time: 0.328484s

on_train_batch_end: 1615751540.300905s

26624/50000 [==============>...............] - ETA: 7s - loss: 0.8468 - accuracy: 0.1004
on_train_batch_begin: 1615751540.301198s

26 step training time: 0.330014s

on_train_batch_end: 1615751540.629437s

27648/50000 [===============>..............] - ETA: 7s - loss: 0.8409 - accuracy: 0.1003
on_train_batch_begin: 1615751540.629753s

27 step training time: 0.328555s

on_train_batch_end: 1615751540.958481s

28672/50000 [================>.............] - ETA: 6s - loss: 0.8405 - accuracy: 0.1003
on_train_batch_begin: 1615751540.958758s

28 step training time: 0.329005s

on_train_batch_end: 1615751541.294069s

29696/50000 [================>.............] - ETA: 6s - loss: 0.8402 - accuracy: 0.1003
on_train_batch_begin: 1615751541.294321s

29 step training time: 0.335563s

on_train_batch_end: 1615751541.622549s

30720/50000 [=================>............] - ETA: 6s - loss: 0.8401 - accuracy: 0.1003
on_train_batch_begin: 1615751541.622813s

30 step training time: 0.328492s

on_train_batch_end: 1615751541.951248s

31744/50000 [==================>...........] - ETA: 5s - loss: 0.8372 - accuracy: 0.1003
on_train_batch_begin: 1615751541.951517s

31 step training time: 0.328705s

on_train_batch_end: 1615751542.286843s

32768/50000 [==================>...........] - ETA: 5s - loss: 0.8372 - accuracy: 0.1004
on_train_batch_begin: 1615751542.287130s

32 step training time: 0.335613s

on_train_batch_end: 1615751542.618131s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.8366 - accuracy: 0.1004
on_train_batch_begin: 1615751542.618427s

33 step training time: 0.331297s

on_train_batch_end: 1615751542.945969s

34816/50000 [===================>..........] - ETA: 4s - loss: 0.8378 - accuracy: 0.1004
on_train_batch_begin: 1615751542.946255s

34 step training time: 0.327829s

on_train_batch_end: 1615751543.276232s

35840/50000 [====================>.........] - ETA: 4s - loss: 0.8367 - accuracy: 0.1003
on_train_batch_begin: 1615751543.276504s

35 step training time: 0.330249s

on_train_batch_end: 1615751543.607450s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.8354 - accuracy: 0.1003
on_train_batch_begin: 1615751543.607735s

36 step training time: 0.331231s

on_train_batch_end: 1615751543.940995s

37888/50000 [=====================>........] - ETA: 3s - loss: 0.8338 - accuracy: 0.1003
on_train_batch_begin: 1615751543.941297s

37 step training time: 0.333562s

on_train_batch_end: 1615751544.269012s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.8322 - accuracy: 0.1003
on_train_batch_begin: 1615751544.269259s

38 step training time: 0.327963s

on_train_batch_end: 1615751544.602761s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.8310 - accuracy: 0.1003
on_train_batch_begin: 1615751544.603058s

39 step training time: 0.333799s

on_train_batch_end: 1615751544.934530s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.8282 - accuracy: 0.1003
on_train_batch_begin: 1615751544.934808s

40 step training time: 0.331749s

on_train_batch_end: 1615751545.263150s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.8278 - accuracy: 0.1003
on_train_batch_begin: 1615751545.263394s

41 step training time: 0.328587s

on_train_batch_end: 1615751545.591922s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.8262 - accuracy: 0.1003
on_train_batch_begin: 1615751545.592197s

42 step training time: 0.328803s

on_train_batch_end: 1615751545.927935s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.8244 - accuracy: 0.1003
on_train_batch_begin: 1615751545.928221s

43 step training time: 0.336024s

on_train_batch_end: 1615751546.257612s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.8248 - accuracy: 0.1003
on_train_batch_begin: 1615751546.257854s

44 step training time: 0.329633s

on_train_batch_end: 1615751546.587138s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.8262 - accuracy: 0.1003
on_train_batch_begin: 1615751546.587423s

45 step training time: 0.329569s

on_train_batch_end: 1615751546.921606s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.8268 - accuracy: 0.1003
on_train_batch_begin: 1615751546.921895s

46 step training time: 0.334472s

on_train_batch_end: 1615751547.253029s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.8257 - accuracy: 0.1003
on_train_batch_begin: 1615751547.253321s

47 step training time: 0.331426s

on_train_batch_end: 1615751547.583940s

49152/50000 [============================>.] - ETA: 0s - loss: 0.8227 - accuracy: 0.1003
on_train_batch_begin: 1615751547.584219s

48 step training time: 0.330898s

on_train_batch_end: 1615751547.861982s

on_test_batch_begin: 1615751547.871606s

49 step training time: 0.287387s

on_epoch_end: 1615751548.661178s

Validation time: 0.789561s

Real time: 1615751548.661178s

Epoch time: 16.93765139579773s

50000/50000 [==============================] - 17s 339us/sample - loss: 0.8208 - accuracy: 0.1003 - val_loss: 6.7409 - val_accuracy: 0.0999
Tempo do fit: 113.87367224693298