wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:39
   204800/170498071 [..............................] - ETA: 1:16
  1105920/170498071 [..............................] - ETA: 21s 
  3514368/170498071 [..............................] - ETA: 9s 
  6840320/170498071 [>.............................] - ETA: 5s
 10199040/170498071 [>.............................] - ETA: 4s
 13508608/170498071 [=>............................] - ETA: 3s
 16883712/170498071 [=>............................] - ETA: 3s
 20103168/170498071 [==>...........................] - ETA: 3s
 23273472/170498071 [===>..........................] - ETA: 3s
 26566656/170498071 [===>..........................] - ETA: 2s
 29925376/170498071 [====>.........................] - ETA: 2s
 33284096/170498071 [====>.........................] - ETA: 2s
 36577280/170498071 [=====>........................] - ETA: 2s
 39862272/170498071 [======>.......................] - ETA: 2s
 43180032/170498071 [======>.......................] - ETA: 2s
 46489600/170498071 [=======>......................] - ETA: 2s
 49864704/170498071 [=======>......................] - ETA: 2s
 53059584/170498071 [========>.....................] - ETA: 2s
 56320000/170498071 [========>.....................] - ETA: 2s
 59596800/170498071 [=========>....................] - ETA: 1s
 62922752/170498071 [==========>...................] - ETA: 1s
 66265088/170498071 [==========>...................] - ETA: 1s
 69607424/170498071 [===========>..................] - ETA: 1s
 72925184/170498071 [===========>..................] - ETA: 1s
 76234752/170498071 [============>.................] - ETA: 1s
 79585280/170498071 [=============>................] - ETA: 1s
 82780160/170498071 [=============>................] - ETA: 1s
 85942272/170498071 [==============>...............] - ETA: 1s
 89219072/170498071 [==============>...............] - ETA: 1s
 92430336/170498071 [===============>..............] - ETA: 1s
 95789056/170498071 [===============>..............] - ETA: 1s
 99106816/170498071 [================>.............] - ETA: 1s
102424576/170498071 [=================>............] - ETA: 1s
105783296/170498071 [=================>............] - ETA: 1s
109158400/170498071 [==================>...........] - ETA: 1s
112500736/170498071 [==================>...........] - ETA: 0s
115662848/170498071 [===================>..........] - ETA: 0s
118841344/170498071 [===================>..........] - ETA: 0s
122060800/170498071 [====================>.........] - ETA: 0s
125362176/170498071 [=====================>........] - ETA: 0s
128671744/170498071 [=====================>........] - ETA: 0s
131997696/170498071 [======================>.......] - ETA: 0s
135340032/170498071 [======================>.......] - ETA: 0s
138665984/170498071 [=======================>......] - ETA: 0s
142032896/170498071 [=======================>......] - ETA: 0s
145317888/170498071 [========================>.....] - ETA: 0s
148594688/170498071 [=========================>....] - ETA: 0s
151789568/170498071 [=========================>....] - ETA: 0s
155082752/170498071 [==========================>...] - ETA: 0s
158277632/170498071 [==========================>...] - ETA: 0s
161644544/170498071 [===========================>..] - ETA: 0s
164945920/170498071 [============================>.] - ETA: 0s
168239104/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 5095424/94765736 [>.............................] - ETA: 0s
15130624/94765736 [===>..........................] - ETA: 0s
19030016/94765736 [=====>........................] - ETA: 0s
25296896/94765736 [=======>......................] - ETA: 0s
30154752/94765736 [========>.....................] - ETA: 0s
35315712/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
46694400/94765736 [=============>................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
54968320/94765736 [================>.............] - ETA: 0s
58941440/94765736 [=================>............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.824464559555054
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615678582.655200s

Real time: 1615678582.6552174
Epoch 1/5

on_train_batch_begin: 1615678583.421016s

on_train_batch_end: 1615678603.983786s

 2048/50000 [>.............................] - ETA: 8:19 - loss: 18.0312 - accuracy: 4.4370e-04
on_train_batch_begin: 1615678603.984397s

1 step training time: 20.563382s

on_train_batch_end: 1615678604.626404s

 4096/50000 [=>............................] - ETA: 4:06 - loss: 14.2622 - accuracy: 5.1713e-04
on_train_batch_begin: 1615678604.626745s

2 step training time: 0.642348s

on_train_batch_end: 1615678605.262429s

 6144/50000 [==>...........................] - ETA: 2:41 - loss: 12.2862 - accuracy: 0.0011    
on_train_batch_begin: 1615678605.262726s

3 step training time: 0.635980s

on_train_batch_end: 1615678605.903684s

 8192/50000 [===>..........................] - ETA: 1:58 - loss: 11.2571 - accuracy: 0.0023
on_train_batch_begin: 1615678605.904004s

4 step training time: 0.641278s

on_train_batch_end: 1615678606.542933s

10240/50000 [=====>........................] - ETA: 1:32 - loss: 10.5776 - accuracy: 0.0045
on_train_batch_begin: 1615678606.543227s

5 step training time: 0.639223s

on_train_batch_end: 1615678607.188117s

12288/50000 [======>.......................] - ETA: 1:15 - loss: 10.1415 - accuracy: 0.0073
on_train_batch_begin: 1615678607.188413s

6 step training time: 0.645186s

on_train_batch_end: 1615678607.823408s

14336/50000 [=======>......................] - ETA: 1:02 - loss: 9.7781 - accuracy: 0.0121 
on_train_batch_begin: 1615678607.823704s

7 step training time: 0.635291s

on_train_batch_end: 1615678608.464450s

16384/50000 [========>.....................] - ETA: 52s - loss: 9.5077 - accuracy: 0.0151 
on_train_batch_begin: 1615678608.464750s

8 step training time: 0.641046s

on_train_batch_end: 1615678609.098146s

18432/50000 [==========>...................] - ETA: 45s - loss: 9.2748 - accuracy: 0.0177
on_train_batch_begin: 1615678609.098460s

9 step training time: 0.633710s

on_train_batch_end: 1615678609.738796s

20480/50000 [===========>..................] - ETA: 39s - loss: 9.0625 - accuracy: 0.0203
on_train_batch_begin: 1615678609.739086s

10 step training time: 0.640626s

on_train_batch_end: 1615678610.371846s

22528/50000 [============>.................] - ETA: 33s - loss: 8.8786 - accuracy: 0.0218
on_train_batch_begin: 1615678610.372149s

11 step training time: 0.633063s

on_train_batch_end: 1615678611.018008s

24576/50000 [=============>................] - ETA: 29s - loss: 8.7141 - accuracy: 0.0234
on_train_batch_begin: 1615678611.018323s

12 step training time: 0.646174s

on_train_batch_end: 1615678611.652365s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.5599 - accuracy: 0.0248
on_train_batch_begin: 1615678611.652666s

13 step training time: 0.634344s

on_train_batch_end: 1615678612.294625s

28672/50000 [================>.............] - ETA: 22s - loss: 8.4341 - accuracy: 0.0257
on_train_batch_begin: 1615678612.294935s

14 step training time: 0.642269s

on_train_batch_end: 1615678612.930605s

30720/50000 [=================>............] - ETA: 19s - loss: 8.3085 - accuracy: 0.0266
on_train_batch_begin: 1615678612.930897s

15 step training time: 0.635962s

on_train_batch_end: 1615678613.570311s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.1938 - accuracy: 0.0280
on_train_batch_begin: 1615678613.570624s

16 step training time: 0.639726s

on_train_batch_end: 1615678614.212627s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.0930 - accuracy: 0.0292
on_train_batch_begin: 1615678614.212932s

17 step training time: 0.642309s

on_train_batch_end: 1615678614.849130s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.0072 - accuracy: 0.0301
on_train_batch_begin: 1615678614.849422s

18 step training time: 0.636490s

on_train_batch_end: 1615678615.489310s

38912/50000 [======================>.......] - ETA: 9s - loss: 7.9212 - accuracy: 0.0314 
on_train_batch_begin: 1615678615.489606s

19 step training time: 0.640183s

on_train_batch_end: 1615678616.133850s

40960/50000 [=======================>......] - ETA: 7s - loss: 7.8372 - accuracy: 0.0330
on_train_batch_begin: 1615678616.134137s

20 step training time: 0.644531s

on_train_batch_end: 1615678616.773990s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.7542 - accuracy: 0.0348
on_train_batch_begin: 1615678616.774282s

21 step training time: 0.640146s

on_train_batch_end: 1615678617.412233s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.6811 - accuracy: 0.0365
on_train_batch_begin: 1615678617.412529s

22 step training time: 0.638247s

on_train_batch_end: 1615678618.053396s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.6132 - accuracy: 0.0378
on_train_batch_begin: 1615678618.053699s

23 step training time: 0.641170s

on_train_batch_end: 1615678618.683383s

49152/50000 [============================>.] - ETA: 0s - loss: 7.5449 - accuracy: 0.0391
on_train_batch_begin: 1615678618.683675s

24 step training time: 0.629976s

on_train_batch_end: 1615678624.275441s

on_test_batch_begin: 1615678624.466304s

25 step training time: 5.782629s

on_epoch_end: 1615678629.459179s

Validation time: 4.992860s

Real time: 1615678629.459179s

Epoch time: 46.80397915840149s

50000/50000 [==============================] - 47s 936us/sample - loss: 7.5167 - accuracy: 0.0394 - val_loss: 2751929.5868 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615678629.459378s

Real time: 1615678629.459384
Epoch 2/5

on_train_batch_begin: 1615678629.462785s

on_train_batch_end: 1615678630.096154s

 2048/50000 [>.............................] - ETA: 14s - loss: 5.8393 - accuracy: 0.0748
on_train_batch_begin: 1615678630.096462s

1 step training time: 0.633677s

on_train_batch_end: 1615678630.735786s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.7839 - accuracy: 0.0725
on_train_batch_begin: 1615678630.736094s

2 step training time: 0.639632s

on_train_batch_end: 1615678631.375444s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.7495 - accuracy: 0.0725
on_train_batch_begin: 1615678631.375745s

3 step training time: 0.639652s

on_train_batch_end: 1615678632.014134s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.6502 - accuracy: 0.0733
on_train_batch_begin: 1615678632.014454s

4 step training time: 0.638709s

on_train_batch_end: 1615678632.653829s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.6007 - accuracy: 0.0737
on_train_batch_begin: 1615678632.654123s

5 step training time: 0.639669s

on_train_batch_end: 1615678633.293699s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.5385 - accuracy: 0.0739
on_train_batch_begin: 1615678633.293993s

6 step training time: 0.639870s

on_train_batch_end: 1615678633.935230s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.4888 - accuracy: 0.0740
on_train_batch_begin: 1615678633.935519s

7 step training time: 0.641526s

on_train_batch_end: 1615678634.580053s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.4769 - accuracy: 0.0737
on_train_batch_begin: 1615678634.580354s

8 step training time: 0.644836s

on_train_batch_end: 1615678635.224400s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.4361 - accuracy: 0.0740 
on_train_batch_begin: 1615678635.224750s

9 step training time: 0.644396s

on_train_batch_end: 1615678635.863364s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.3950 - accuracy: 0.0740
on_train_batch_begin: 1615678635.863654s

10 step training time: 0.638904s

on_train_batch_end: 1615678636.503369s

22528/50000 [============>.................] - ETA: 8s - loss: 5.3752 - accuracy: 0.0743
on_train_batch_begin: 1615678636.503665s

11 step training time: 0.640011s

on_train_batch_end: 1615678637.136738s

24576/50000 [=============>................] - ETA: 7s - loss: 5.3381 - accuracy: 0.0745
on_train_batch_begin: 1615678637.137034s

12 step training time: 0.633369s

on_train_batch_end: 1615678637.782129s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.3169 - accuracy: 0.0747
on_train_batch_begin: 1615678637.782447s

13 step training time: 0.645413s

on_train_batch_end: 1615678638.418815s

28672/50000 [================>.............] - ETA: 6s - loss: 5.2876 - accuracy: 0.0750
on_train_batch_begin: 1615678638.419101s

14 step training time: 0.636654s

on_train_batch_end: 1615678639.062732s

30720/50000 [=================>............] - ETA: 6s - loss: 5.2648 - accuracy: 0.0754
on_train_batch_begin: 1615678639.063037s

15 step training time: 0.643936s

on_train_batch_end: 1615678639.702289s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.2334 - accuracy: 0.0755
on_train_batch_begin: 1615678639.702622s

16 step training time: 0.639585s

on_train_batch_end: 1615678640.347730s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.2090 - accuracy: 0.0757
on_train_batch_begin: 1615678640.348024s

17 step training time: 0.645402s

on_train_batch_end: 1615678640.990296s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.1802 - accuracy: 0.0761
on_train_batch_begin: 1615678640.990617s

18 step training time: 0.642593s

on_train_batch_end: 1615678641.635618s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.1506 - accuracy: 0.0762
on_train_batch_begin: 1615678641.635924s

19 step training time: 0.645307s

on_train_batch_end: 1615678642.282790s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.1243 - accuracy: 0.0760
on_train_batch_begin: 1615678642.283082s

20 step training time: 0.647158s

on_train_batch_end: 1615678642.919086s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.0994 - accuracy: 0.0759
on_train_batch_begin: 1615678642.919386s

21 step training time: 0.636304s

on_train_batch_end: 1615678643.563230s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.0798 - accuracy: 0.0758
on_train_batch_begin: 1615678643.563524s

22 step training time: 0.644138s

on_train_batch_end: 1615678644.204992s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.0538 - accuracy: 0.0756
on_train_batch_begin: 1615678644.205287s

23 step training time: 0.641763s

on_train_batch_end: 1615678644.843920s

49152/50000 [============================>.] - ETA: 0s - loss: 5.0296 - accuracy: 0.0753
on_train_batch_begin: 1615678644.844218s

24 step training time: 0.638932s

on_train_batch_end: 1615678645.115884s

on_test_batch_begin: 1615678645.141909s

25 step training time: 0.297690s

on_epoch_end: 1615678645.951766s

Validation time: 0.809844s

Real time: 1615678645.951766s

Epoch time: 16.49239993095398s

50000/50000 [==============================] - 16s 330us/sample - loss: 5.0210 - accuracy: 0.0753 - val_loss: 6316.3488 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615678645.951958s

Real time: 1615678645.9519632
Epoch 3/5

on_train_batch_begin: 1615678645.955259s

on_train_batch_end: 1615678646.589731s

 2048/50000 [>.............................] - ETA: 14s - loss: 4.3451 - accuracy: 0.0724
on_train_batch_begin: 1615678646.590056s

1 step training time: 0.634797s

on_train_batch_end: 1615678647.236311s

 4096/50000 [=>............................] - ETA: 14s - loss: 4.3200 - accuracy: 0.0722
on_train_batch_begin: 1615678647.236606s

2 step training time: 0.646550s

on_train_batch_end: 1615678647.881259s

 6144/50000 [==>...........................] - ETA: 13s - loss: 4.3408 - accuracy: 0.0721
on_train_batch_begin: 1615678647.881552s

3 step training time: 0.644946s

on_train_batch_end: 1615678648.525401s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.3154 - accuracy: 0.0730
on_train_batch_begin: 1615678648.525702s

4 step training time: 0.644150s

on_train_batch_end: 1615678649.167857s

10240/50000 [=====>........................] - ETA: 12s - loss: 4.2798 - accuracy: 0.0728
on_train_batch_begin: 1615678649.168149s

5 step training time: 0.642447s

on_train_batch_end: 1615678649.809438s

12288/50000 [======>.......................] - ETA: 11s - loss: 4.2636 - accuracy: 0.0727
on_train_batch_begin: 1615678649.809729s

6 step training time: 0.641580s

on_train_batch_end: 1615678650.454133s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.2390 - accuracy: 0.0727
on_train_batch_begin: 1615678650.454440s

7 step training time: 0.644711s

on_train_batch_end: 1615678651.094576s

16384/50000 [========>.....................] - ETA: 10s - loss: 4.2268 - accuracy: 0.0726
on_train_batch_begin: 1615678651.094866s

8 step training time: 0.640426s

on_train_batch_end: 1615678651.739353s

18432/50000 [==========>...................] - ETA: 9s - loss: 4.2071 - accuracy: 0.0725 
on_train_batch_begin: 1615678651.739659s

9 step training time: 0.644793s

on_train_batch_end: 1615678652.383693s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.1865 - accuracy: 0.0725
on_train_batch_begin: 1615678652.383985s

10 step training time: 0.644326s

on_train_batch_end: 1615678653.030395s

22528/50000 [============>.................] - ETA: 8s - loss: 4.1719 - accuracy: 0.0723
on_train_batch_begin: 1615678653.030712s

11 step training time: 0.646727s

on_train_batch_end: 1615678653.677477s

24576/50000 [=============>................] - ETA: 7s - loss: 4.1635 - accuracy: 0.0722
on_train_batch_begin: 1615678653.677765s

12 step training time: 0.647053s

on_train_batch_end: 1615678654.315633s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.1415 - accuracy: 0.0723
on_train_batch_begin: 1615678654.315930s

13 step training time: 0.638165s

on_train_batch_end: 1615678654.959583s

28672/50000 [================>.............] - ETA: 6s - loss: 4.1268 - accuracy: 0.0722
on_train_batch_begin: 1615678654.959911s

14 step training time: 0.643981s

on_train_batch_end: 1615678655.599077s

30720/50000 [=================>............] - ETA: 6s - loss: 4.1081 - accuracy: 0.0722
on_train_batch_begin: 1615678655.599378s

15 step training time: 0.639467s

on_train_batch_end: 1615678656.241853s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.0879 - accuracy: 0.0723
on_train_batch_begin: 1615678656.242138s

16 step training time: 0.642760s

on_train_batch_end: 1615678656.886938s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.0664 - accuracy: 0.0725
on_train_batch_begin: 1615678656.887233s

17 step training time: 0.645095s

on_train_batch_end: 1615678657.533956s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.0489 - accuracy: 0.0727
on_train_batch_begin: 1615678657.534255s

18 step training time: 0.647022s

on_train_batch_end: 1615678658.174518s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.0271 - accuracy: 0.0730
on_train_batch_begin: 1615678658.174814s

19 step training time: 0.640559s

on_train_batch_end: 1615678658.817320s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.0101 - accuracy: 0.0733
on_train_batch_begin: 1615678658.817610s

20 step training time: 0.642796s

on_train_batch_end: 1615678659.462855s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.9904 - accuracy: 0.0736
on_train_batch_begin: 1615678659.463146s

21 step training time: 0.645537s

on_train_batch_end: 1615678660.109051s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.9752 - accuracy: 0.0737
on_train_batch_begin: 1615678660.109346s

22 step training time: 0.646199s

on_train_batch_end: 1615678660.754234s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.9673 - accuracy: 0.0738
on_train_batch_begin: 1615678660.754556s

23 step training time: 0.645210s

on_train_batch_end: 1615678661.393745s

49152/50000 [============================>.] - ETA: 0s - loss: 3.9492 - accuracy: 0.0741
on_train_batch_begin: 1615678661.394038s

24 step training time: 0.639482s

on_train_batch_end: 1615678661.666641s

on_test_batch_begin: 1615678661.691813s

25 step training time: 0.297776s

on_epoch_end: 1615678662.505805s

Validation time: 0.813980s

Real time: 1615678662.505805s

Epoch time: 16.55385947227478s

50000/50000 [==============================] - 17s 331us/sample - loss: 3.9423 - accuracy: 0.0742 - val_loss: 8.2172 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615678662.505996s

Real time: 1615678662.5060012
Epoch 4/5

on_train_batch_begin: 1615678662.509312s

on_train_batch_end: 1615678663.148102s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.2878 - accuracy: 0.0831
on_train_batch_begin: 1615678663.148396s

1 step training time: 0.639084s

on_train_batch_end: 1615678663.801403s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.2388 - accuracy: 0.0841
on_train_batch_begin: 1615678663.801692s

2 step training time: 0.653297s

on_train_batch_end: 1615678664.446478s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.2480 - accuracy: 0.0838
on_train_batch_begin: 1615678664.446780s

3 step training time: 0.645088s

on_train_batch_end: 1615678665.096346s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.2635 - accuracy: 0.0837
on_train_batch_begin: 1615678665.096644s

4 step training time: 0.649864s

on_train_batch_end: 1615678665.742649s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.2291 - accuracy: 0.0841
on_train_batch_begin: 1615678665.742938s

5 step training time: 0.646294s

on_train_batch_end: 1615678666.396397s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.1895 - accuracy: 0.0845
on_train_batch_begin: 1615678666.396693s

6 step training time: 0.653755s

on_train_batch_end: 1615678667.034621s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.1762 - accuracy: 0.0850
on_train_batch_begin: 1615678667.034911s

7 step training time: 0.638218s

on_train_batch_end: 1615678667.686091s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.1407 - accuracy: 0.0856
on_train_batch_begin: 1615678667.686380s

8 step training time: 0.651469s

on_train_batch_end: 1615678668.329588s

18432/50000 [==========>...................] - ETA: 9s - loss: 3.0942 - accuracy: 0.0863 
on_train_batch_begin: 1615678668.329909s

9 step training time: 0.643529s

on_train_batch_end: 1615678668.975522s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.0648 - accuracy: 0.0868
on_train_batch_begin: 1615678668.975812s

10 step training time: 0.645904s

on_train_batch_end: 1615678669.623536s

22528/50000 [============>.................] - ETA: 8s - loss: 3.0218 - accuracy: 0.0874
on_train_batch_begin: 1615678669.623828s

11 step training time: 0.648016s

on_train_batch_end: 1615678670.270608s

24576/50000 [=============>................] - ETA: 8s - loss: 2.9928 - accuracy: 0.0881
on_train_batch_begin: 1615678670.270904s

12 step training time: 0.647075s

on_train_batch_end: 1615678670.913346s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.9613 - accuracy: 0.0887
on_train_batch_begin: 1615678670.913642s

13 step training time: 0.642738s

on_train_batch_end: 1615678671.561075s

28672/50000 [================>.............] - ETA: 6s - loss: 2.9274 - accuracy: 0.0892
on_train_batch_begin: 1615678671.561368s

14 step training time: 0.647725s

on_train_batch_end: 1615678672.177956s

30720/50000 [=================>............] - ETA: 6s - loss: 2.8909 - accuracy: 0.0897
on_train_batch_begin: 1615678672.178249s

15 step training time: 0.616881s

on_train_batch_end: 1615678672.830860s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.8551 - accuracy: 0.0902
on_train_batch_begin: 1615678672.831166s

16 step training time: 0.652917s

on_train_batch_end: 1615678673.475522s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.8150 - accuracy: 0.0907
on_train_batch_begin: 1615678673.475818s

17 step training time: 0.644652s

on_train_batch_end: 1615678674.120687s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.7843 - accuracy: 0.0912
on_train_batch_begin: 1615678674.120994s

18 step training time: 0.645176s

on_train_batch_end: 1615678674.763238s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.7592 - accuracy: 0.0916
on_train_batch_begin: 1615678674.763534s

19 step training time: 0.642540s

on_train_batch_end: 1615678675.410542s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.7343 - accuracy: 0.0920
on_train_batch_begin: 1615678675.410843s

20 step training time: 0.647309s

on_train_batch_end: 1615678676.057752s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.7085 - accuracy: 0.0923
on_train_batch_begin: 1615678676.058045s

21 step training time: 0.647202s

on_train_batch_end: 1615678676.705656s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.6848 - accuracy: 0.0927
on_train_batch_begin: 1615678676.705954s

22 step training time: 0.647908s

on_train_batch_end: 1615678677.349818s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.6558 - accuracy: 0.0930
on_train_batch_begin: 1615678677.350128s

23 step training time: 0.644175s

on_train_batch_end: 1615678677.989457s

49152/50000 [============================>.] - ETA: 0s - loss: 2.6268 - accuracy: 0.0933
on_train_batch_begin: 1615678677.989753s

24 step training time: 0.639625s

on_train_batch_end: 1615678678.273937s

on_test_batch_begin: 1615678678.299853s

25 step training time: 0.310100s

on_epoch_end: 1615678679.127588s

Validation time: 0.827720s

Real time: 1615678679.127588s

Epoch time: 16.621604442596436s

50000/50000 [==============================] - 17s 332us/sample - loss: 2.6154 - accuracy: 0.0934 - val_loss: 7.4953 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615678679.127782s

Real time: 1615678679.1277895
Epoch 5/5

on_train_batch_begin: 1615678679.131136s

on_train_batch_end: 1615678679.772522s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.8477 - accuracy: 0.0998
on_train_batch_begin: 1615678679.772821s

1 step training time: 0.641685s

on_train_batch_end: 1615678680.422526s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.7629 - accuracy: 0.1000
on_train_batch_begin: 1615678680.422824s

2 step training time: 0.650003s

on_train_batch_end: 1615678681.068804s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.7828 - accuracy: 0.0998
on_train_batch_begin: 1615678681.069101s

3 step training time: 0.646277s

on_train_batch_end: 1615678681.719220s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.7623 - accuracy: 0.0997
on_train_batch_begin: 1615678681.719518s

4 step training time: 0.650418s

on_train_batch_end: 1615678682.366168s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.7657 - accuracy: 0.0998
on_train_batch_begin: 1615678682.366477s

5 step training time: 0.646959s

on_train_batch_end: 1615678683.013593s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.7452 - accuracy: 0.0998
on_train_batch_begin: 1615678683.013887s

6 step training time: 0.647410s

on_train_batch_end: 1615678683.656185s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.7458 - accuracy: 0.0998
on_train_batch_begin: 1615678683.656483s

7 step training time: 0.642596s

on_train_batch_end: 1615678684.304776s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.7336 - accuracy: 0.0999
on_train_batch_begin: 1615678684.305278s

8 step training time: 0.648795s

on_train_batch_end: 1615678684.952679s

18432/50000 [==========>...................] - ETA: 9s - loss: 1.7200 - accuracy: 0.0999 
on_train_batch_begin: 1615678684.953092s

9 step training time: 0.647814s

on_train_batch_end: 1615678685.599066s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.7074 - accuracy: 0.0999
on_train_batch_begin: 1615678685.599361s

10 step training time: 0.646268s

on_train_batch_end: 1615678686.248023s

22528/50000 [============>.................] - ETA: 8s - loss: 1.7006 - accuracy: 0.0999
on_train_batch_begin: 1615678686.248317s

11 step training time: 0.648957s

on_train_batch_end: 1615678686.893886s

24576/50000 [=============>................] - ETA: 8s - loss: 1.6883 - accuracy: 0.0999
on_train_batch_begin: 1615678686.894176s

12 step training time: 0.645859s

on_train_batch_end: 1615678687.547079s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.6742 - accuracy: 0.1000
on_train_batch_begin: 1615678687.547376s

13 step training time: 0.653199s

on_train_batch_end: 1615678688.193367s

28672/50000 [================>.............] - ETA: 6s - loss: 1.6586 - accuracy: 0.1000
on_train_batch_begin: 1615678688.193661s

14 step training time: 0.646286s

on_train_batch_end: 1615678688.844313s

30720/50000 [=================>............] - ETA: 6s - loss: 1.6554 - accuracy: 0.0999
on_train_batch_begin: 1615678688.844611s

15 step training time: 0.650950s

on_train_batch_end: 1615678689.484441s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.6446 - accuracy: 0.1000
on_train_batch_begin: 1615678689.484742s

16 step training time: 0.640131s

on_train_batch_end: 1615678690.132759s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.6374 - accuracy: 0.1000
on_train_batch_begin: 1615678690.133065s

17 step training time: 0.648324s

on_train_batch_end: 1615678690.776845s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.6320 - accuracy: 0.1000
on_train_batch_begin: 1615678690.777149s

18 step training time: 0.644084s

on_train_batch_end: 1615678691.426877s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.6234 - accuracy: 0.1000
on_train_batch_begin: 1615678691.427172s

19 step training time: 0.650023s

on_train_batch_end: 1615678692.075581s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.6176 - accuracy: 0.1000
on_train_batch_begin: 1615678692.075893s

20 step training time: 0.648721s

on_train_batch_end: 1615678692.726833s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.6081 - accuracy: 0.1000
on_train_batch_begin: 1615678692.727127s

21 step training time: 0.651234s

on_train_batch_end: 1615678693.375427s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.6011 - accuracy: 0.1000
on_train_batch_begin: 1615678693.375722s

22 step training time: 0.648596s

on_train_batch_end: 1615678694.024855s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.5922 - accuracy: 0.1000
on_train_batch_begin: 1615678694.025152s

23 step training time: 0.649430s

on_train_batch_end: 1615678694.663033s

49152/50000 [============================>.] - ETA: 0s - loss: 1.5850 - accuracy: 0.1000
on_train_batch_begin: 1615678694.663329s

24 step training time: 0.638177s

on_train_batch_end: 1615678694.939903s

on_test_batch_begin: 1615678694.965153s

25 step training time: 0.301824s

on_epoch_end: 1615678695.782160s

Validation time: 0.816994s

Real time: 1615678695.782160s

Epoch time: 16.654387950897217s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.5844 - accuracy: 0.1000 - val_loss: 7.5221 - val_accuracy: 0.0000e+00
Tempo do fit: 116.53680849075317