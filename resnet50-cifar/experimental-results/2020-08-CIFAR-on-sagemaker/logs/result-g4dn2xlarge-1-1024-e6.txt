wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:45
   188416/170498071 [..............................] - ETA: 1:23
  1024000/170498071 [..............................] - ETA: 23s 
  2990080/170498071 [..............................] - ETA: 10s
  5742592/170498071 [>.............................] - ETA: 6s 
  8560640/170498071 [>.............................] - ETA: 5s
 11329536/170498071 [>.............................] - ETA: 4s
 14065664/170498071 [=>............................] - ETA: 4s
 16785408/170498071 [=>............................] - ETA: 4s
 19537920/170498071 [==>...........................] - ETA: 3s
 22192128/170498071 [==>...........................] - ETA: 3s
 24125440/170498071 [===>..........................] - ETA: 3s
 26877952/170498071 [===>..........................] - ETA: 3s
 29564928/170498071 [====>.........................] - ETA: 3s
 32235520/170498071 [====>.........................] - ETA: 3s
 34873344/170498071 [=====>........................] - ETA: 3s
 37543936/170498071 [=====>........................] - ETA: 3s
 40214528/170498071 [======>.......................] - ETA: 2s
 42868736/170498071 [======>.......................] - ETA: 2s
 45096960/170498071 [======>.......................] - ETA: 2s
 47718400/170498071 [=======>......................] - ETA: 2s
 49766400/170498071 [=======>......................] - ETA: 2s
 51847168/170498071 [========>.....................] - ETA: 2s
 53927936/170498071 [========>.....................] - ETA: 2s
 56090624/170498071 [========>.....................] - ETA: 2s
 58351616/170498071 [=========>....................] - ETA: 2s
 60579840/170498071 [=========>....................] - ETA: 2s
 62595072/170498071 [==========>...................] - ETA: 2s
 64618496/170498071 [==========>...................] - ETA: 2s
 66625536/170498071 [==========>...................] - ETA: 2s
 68771840/170498071 [===========>..................] - ETA: 2s
 70819840/170498071 [===========>..................] - ETA: 2s
 72671232/170498071 [===========>..................] - ETA: 2s
 74964992/170498071 [============>.................] - ETA: 2s
 76996608/170498071 [============>.................] - ETA: 2s
 79257600/170498071 [============>.................] - ETA: 2s
 81272832/170498071 [=============>................] - ETA: 2s
 83468288/170498071 [=============>................] - ETA: 2s
 85696512/170498071 [==============>...............] - ETA: 1s
 87908352/170498071 [==============>...............] - ETA: 1s
 90185728/170498071 [==============>...............] - ETA: 1s
 92168192/170498071 [===============>..............] - ETA: 1s
 94281728/170498071 [===============>..............] - ETA: 1s
 96575488/170498071 [===============>..............] - ETA: 1s
 98639872/170498071 [================>.............] - ETA: 1s
100589568/170498071 [================>.............] - ETA: 1s
102596608/170498071 [=================>............] - ETA: 1s
105029632/170498071 [=================>............] - ETA: 1s
107634688/170498071 [=================>............] - ETA: 1s
110305280/170498071 [==================>...........] - ETA: 1s
113049600/170498071 [==================>...........] - ETA: 1s
115679232/170498071 [===================>..........] - ETA: 1s
118300672/170498071 [===================>..........] - ETA: 1s
121036800/170498071 [====================>.........] - ETA: 1s
123772928/170498071 [====================>.........] - ETA: 1s
126541824/170498071 [=====================>........] - ETA: 0s
129245184/170498071 [=====================>........] - ETA: 0s
132030464/170498071 [======================>.......] - ETA: 0s
134799360/170498071 [======================>.......] - ETA: 0s
137633792/170498071 [=======================>......] - ETA: 0s
140386304/170498071 [=======================>......] - ETA: 0s
143155200/170498071 [========================>.....] - ETA: 0s
145891328/170498071 [========================>.....] - ETA: 0s
148709376/170498071 [=========================>....] - ETA: 0s
151494656/170498071 [=========================>....] - ETA: 0s
154361856/170498071 [==========================>...] - ETA: 0s
157278208/170498071 [==========================>...] - ETA: 0s
160145408/170498071 [===========================>..] - ETA: 0s
163061760/170498071 [===========================>..] - ETA: 0s
165928960/170498071 [============================>.] - ETA: 0s
168730624/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 4s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 4669440/94765736 [>.............................] - ETA: 1s
11091968/94765736 [==>...........................] - ETA: 0s
15671296/94765736 [===>..........................] - ETA: 0s
20783104/94765736 [=====>........................] - ETA: 0s
25763840/94765736 [=======>......................] - ETA: 0s
30179328/94765736 [========>.....................] - ETA: 0s
36069376/94765736 [==========>...................] - ETA: 0s
39124992/94765736 [===========>..................] - ETA: 0s
43597824/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
49684480/94765736 [==============>...............] - ETA: 0s
54632448/94765736 [================>.............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
57712640/94765736 [=================>............] - ETA: 0s
60071936/94765736 [==================>...........] - ETA: 0s
64192512/94765736 [===================>..........] - ETA: 0s
67158016/94765736 [====================>.........] - ETA: 0s
69533696/94765736 [=====================>........] - ETA: 0s
72597504/94765736 [=====================>........] - ETA: 0s
76587008/94765736 [=======================>......] - ETA: 0s
76619776/94765736 [=======================>......] - ETA: 0s
79069184/94765736 [========================>.....] - ETA: 0s
83550208/94765736 [=========================>....] - ETA: 0s
86007808/94765736 [==========================>...] - ETA: 0s
88375296/94765736 [==========================>...] - ETA: 0s
90734592/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.671346187591553
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615854504.402434s

Real time: 1615854504.402451
Epoch 1/5

on_train_batch_begin: 1615854505.155806s

on_train_batch_end: 1615854522.587680s

 1024/50000 [..............................] - ETA: 14:29 - loss: 17.7522 - accuracy: 2.3270e-04
on_train_batch_begin: 1615854522.588284s

1 step training time: 17.432478s

on_train_batch_end: 1615854522.928786s

 2048/50000 [>.............................] - ETA: 7:13 - loss: 14.2532 - accuracy: 4.4489e-04 
on_train_batch_begin: 1615854522.929107s

2 step training time: 0.340823s

on_train_batch_end: 1615854523.267544s

 3072/50000 [>.............................] - ETA: 4:48 - loss: 12.3483 - accuracy: 0.0010    
on_train_batch_begin: 1615854523.267860s

3 step training time: 0.338752s

on_train_batch_end: 1615854523.604508s

 4096/50000 [=>............................] - ETA: 3:35 - loss: 11.3481 - accuracy: 0.0018
on_train_batch_begin: 1615854523.604803s

4 step training time: 0.336943s

on_train_batch_end: 1615854523.943782s

 5120/50000 [==>...........................] - ETA: 2:51 - loss: 10.7367 - accuracy: 0.0048
on_train_batch_begin: 1615854523.944084s

5 step training time: 0.339282s

on_train_batch_end: 1615854524.282876s

 6144/50000 [==>...........................] - ETA: 2:21 - loss: 10.3043 - accuracy: 0.0079
on_train_batch_begin: 1615854524.283174s

6 step training time: 0.339090s

on_train_batch_end: 1615854524.619515s

 7168/50000 [===>..........................] - ETA: 2:00 - loss: 9.9809 - accuracy: 0.0116 
on_train_batch_begin: 1615854524.619815s

7 step training time: 0.336641s

on_train_batch_end: 1615854524.959674s

 8192/50000 [===>..........................] - ETA: 1:44 - loss: 9.7223 - accuracy: 0.0166
on_train_batch_begin: 1615854524.959979s

8 step training time: 0.340164s

on_train_batch_end: 1615854525.296169s

 9216/50000 [====>.........................] - ETA: 1:32 - loss: 9.5221 - accuracy: 0.0199
on_train_batch_begin: 1615854525.296501s

9 step training time: 0.336522s

on_train_batch_end: 1615854525.633836s

10240/50000 [=====>........................] - ETA: 1:22 - loss: 9.3497 - accuracy: 0.0234
on_train_batch_begin: 1615854525.634136s

10 step training time: 0.337635s

on_train_batch_end: 1615854525.971665s

11264/50000 [=====>........................] - ETA: 1:14 - loss: 9.1857 - accuracy: 0.0277
on_train_batch_begin: 1615854525.971964s

11 step training time: 0.337828s

on_train_batch_end: 1615854526.308352s

12288/50000 [======>.......................] - ETA: 1:07 - loss: 9.0567 - accuracy: 0.0296
on_train_batch_begin: 1615854526.308666s

12 step training time: 0.336702s

on_train_batch_end: 1615854526.648233s

13312/50000 [======>.......................] - ETA: 1:01 - loss: 8.9380 - accuracy: 0.0324
on_train_batch_begin: 1615854526.648534s

13 step training time: 0.339868s

on_train_batch_end: 1615854526.985081s

14336/50000 [=======>......................] - ETA: 56s - loss: 8.8323 - accuracy: 0.0340 
on_train_batch_begin: 1615854526.985386s

14 step training time: 0.336852s

on_train_batch_end: 1615854527.323392s

15360/50000 [========>.....................] - ETA: 51s - loss: 8.7318 - accuracy: 0.0354
on_train_batch_begin: 1615854527.323701s

15 step training time: 0.338315s

on_train_batch_end: 1615854527.643940s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.6563 - accuracy: 0.0372
on_train_batch_begin: 1615854527.644244s

16 step training time: 0.320543s

on_train_batch_end: 1615854527.988239s

17408/50000 [=========>....................] - ETA: 44s - loss: 8.5738 - accuracy: 0.0380
on_train_batch_begin: 1615854527.988548s

17 step training time: 0.344304s

on_train_batch_end: 1615854528.322468s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.4983 - accuracy: 0.0392
on_train_batch_begin: 1615854528.322770s

18 step training time: 0.334223s

on_train_batch_end: 1615854528.661876s

19456/50000 [==========>...................] - ETA: 38s - loss: 8.4576 - accuracy: 0.0395
on_train_batch_begin: 1615854528.662177s

19 step training time: 0.339406s

on_train_batch_end: 1615854528.998453s

20480/50000 [===========>..................] - ETA: 35s - loss: 8.3968 - accuracy: 0.0413
on_train_batch_begin: 1615854528.998754s

20 step training time: 0.336577s

on_train_batch_end: 1615854529.339502s

21504/50000 [===========>..................] - ETA: 33s - loss: 8.3460 - accuracy: 0.0426
on_train_batch_begin: 1615854529.339822s

21 step training time: 0.341069s

on_train_batch_end: 1615854529.681115s

22528/50000 [============>.................] - ETA: 30s - loss: 8.2969 - accuracy: 0.0437
on_train_batch_begin: 1615854529.681424s

22 step training time: 0.341602s

on_train_batch_end: 1615854530.018401s

23552/50000 [=============>................] - ETA: 28s - loss: 8.2416 - accuracy: 0.0451
on_train_batch_begin: 1615854530.018709s

23 step training time: 0.337285s

on_train_batch_end: 1615854530.358298s

24576/50000 [=============>................] - ETA: 26s - loss: 8.1907 - accuracy: 0.0463
on_train_batch_begin: 1615854530.358592s

24 step training time: 0.339884s

on_train_batch_end: 1615854530.700407s

25600/50000 [==============>...............] - ETA: 25s - loss: 8.1497 - accuracy: 0.0475
on_train_batch_begin: 1615854530.700701s

25 step training time: 0.342108s

on_train_batch_end: 1615854531.042907s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.1082 - accuracy: 0.0487
on_train_batch_begin: 1615854531.043203s

26 step training time: 0.342502s

on_train_batch_end: 1615854531.385521s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.0655 - accuracy: 0.0498
on_train_batch_begin: 1615854531.385825s

27 step training time: 0.342622s

on_train_batch_end: 1615854531.726541s

28672/50000 [================>.............] - ETA: 20s - loss: 8.0252 - accuracy: 0.0508
on_train_batch_begin: 1615854531.726872s

28 step training time: 0.341047s

on_train_batch_end: 1615854532.064525s

29696/50000 [================>.............] - ETA: 18s - loss: 7.9879 - accuracy: 0.0515
on_train_batch_begin: 1615854532.064824s

29 step training time: 0.337952s

on_train_batch_end: 1615854532.406292s

30720/50000 [=================>............] - ETA: 17s - loss: 7.9520 - accuracy: 0.0523
on_train_batch_begin: 1615854532.406624s

30 step training time: 0.341800s

on_train_batch_end: 1615854532.747295s

31744/50000 [==================>...........] - ETA: 16s - loss: 7.9130 - accuracy: 0.0531
on_train_batch_begin: 1615854532.747602s

31 step training time: 0.340978s

on_train_batch_end: 1615854533.090203s

32768/50000 [==================>...........] - ETA: 15s - loss: 7.8818 - accuracy: 0.0536
on_train_batch_begin: 1615854533.090503s

32 step training time: 0.342902s

on_train_batch_end: 1615854533.431052s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.8475 - accuracy: 0.0545
on_train_batch_begin: 1615854533.431353s

33 step training time: 0.340850s

on_train_batch_end: 1615854533.770513s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.8175 - accuracy: 0.0550
on_train_batch_begin: 1615854533.770809s

34 step training time: 0.339456s

on_train_batch_end: 1615854534.113623s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.7903 - accuracy: 0.0547
on_train_batch_begin: 1615854534.113959s

35 step training time: 0.343150s

on_train_batch_end: 1615854534.458184s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.7564 - accuracy: 0.0548
on_train_batch_begin: 1615854534.458496s

36 step training time: 0.344537s

on_train_batch_end: 1615854534.800414s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.7313 - accuracy: 0.0550 
on_train_batch_begin: 1615854534.800716s

37 step training time: 0.342221s

on_train_batch_end: 1615854535.145112s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.7039 - accuracy: 0.0558
on_train_batch_begin: 1615854535.145407s

38 step training time: 0.344691s

on_train_batch_end: 1615854535.487707s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.6769 - accuracy: 0.0567
on_train_batch_begin: 1615854535.488019s

39 step training time: 0.342611s

on_train_batch_end: 1615854535.829367s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.6483 - accuracy: 0.0570
on_train_batch_begin: 1615854535.829670s

40 step training time: 0.341651s

on_train_batch_end: 1615854536.170588s

41984/50000 [========================>.....] - ETA: 6s - loss: 7.6213 - accuracy: 0.0574
on_train_batch_begin: 1615854536.170906s

41 step training time: 0.341236s

on_train_batch_end: 1615854536.512724s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.5919 - accuracy: 0.0578
on_train_batch_begin: 1615854536.513021s

42 step training time: 0.342116s

on_train_batch_end: 1615854536.856896s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.5671 - accuracy: 0.0579
on_train_batch_begin: 1615854536.857217s

43 step training time: 0.344196s

on_train_batch_end: 1615854537.198242s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.5418 - accuracy: 0.0580
on_train_batch_begin: 1615854537.198536s

44 step training time: 0.341319s

on_train_batch_end: 1615854537.541846s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.5180 - accuracy: 0.0581
on_train_batch_begin: 1615854537.542145s

45 step training time: 0.343610s

on_train_batch_end: 1615854537.886010s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.4948 - accuracy: 0.0583
on_train_batch_begin: 1615854537.886311s

46 step training time: 0.344165s

on_train_batch_end: 1615854538.233097s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.4730 - accuracy: 0.0587
on_train_batch_begin: 1615854538.233394s

47 step training time: 0.347083s

on_train_batch_end: 1615854538.577844s

49152/50000 [============================>.] - ETA: 0s - loss: 7.4477 - accuracy: 0.0592
on_train_batch_begin: 1615854538.578142s

48 step training time: 0.344748s

on_train_batch_end: 1615854544.707883s

on_test_batch_begin: 1615854544.895519s

49 step training time: 6.317376s

on_epoch_end: 1615854549.699706s

Validation time: 4.804170s

Real time: 1615854549.699706s

Epoch time: 45.29727220535278s

50000/50000 [==============================] - 45s 906us/sample - loss: 7.4255 - accuracy: 0.0595 - val_loss: 384900.8261 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615854549.699915s

Real time: 1615854549.6999218
Epoch 2/5

on_train_batch_begin: 1615854549.703343s

on_train_batch_end: 1615854550.050381s

 1024/50000 [..............................] - ETA: 16s - loss: 6.2585 - accuracy: 0.0732
on_train_batch_begin: 1615854550.050693s

1 step training time: 0.347350s

on_train_batch_end: 1615854550.394933s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.2561 - accuracy: 0.0746
on_train_batch_begin: 1615854550.395234s

2 step training time: 0.344541s

on_train_batch_end: 1615854550.739586s

 3072/50000 [>.............................] - ETA: 15s - loss: 6.2512 - accuracy: 0.0724
on_train_batch_begin: 1615854550.739887s

3 step training time: 0.344653s

on_train_batch_end: 1615854551.087147s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.2046 - accuracy: 0.0746
on_train_batch_begin: 1615854551.087453s

4 step training time: 0.347566s

on_train_batch_end: 1615854551.434925s

 5120/50000 [==>...........................] - ETA: 15s - loss: 6.1948 - accuracy: 0.0755
on_train_batch_begin: 1615854551.435219s

5 step training time: 0.347766s

on_train_batch_end: 1615854551.781509s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.2182 - accuracy: 0.0739
on_train_batch_begin: 1615854551.781818s

6 step training time: 0.346599s

on_train_batch_end: 1615854552.129576s

 7168/50000 [===>..........................] - ETA: 14s - loss: 6.2223 - accuracy: 0.0727
on_train_batch_begin: 1615854552.129880s

7 step training time: 0.348062s

on_train_batch_end: 1615854552.477585s

 8192/50000 [===>..........................] - ETA: 14s - loss: 6.2363 - accuracy: 0.0705
on_train_batch_begin: 1615854552.477914s

8 step training time: 0.348033s

on_train_batch_end: 1615854552.824663s

 9216/50000 [====>.........................] - ETA: 13s - loss: 6.2258 - accuracy: 0.0719
on_train_batch_begin: 1615854552.824961s

9 step training time: 0.347048s

on_train_batch_end: 1615854553.173467s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.2193 - accuracy: 0.0709
on_train_batch_begin: 1615854553.173761s

10 step training time: 0.348800s

on_train_batch_end: 1615854553.521149s

11264/50000 [=====>........................] - ETA: 13s - loss: 6.2080 - accuracy: 0.0704
on_train_batch_begin: 1615854553.521442s

11 step training time: 0.347681s

on_train_batch_end: 1615854553.866505s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.2007 - accuracy: 0.0707
on_train_batch_begin: 1615854553.866804s

12 step training time: 0.345362s

on_train_batch_end: 1615854554.218352s

13312/50000 [======>.......................] - ETA: 12s - loss: 6.1888 - accuracy: 0.0697
on_train_batch_begin: 1615854554.218647s

13 step training time: 0.351843s

on_train_batch_end: 1615854554.568357s

14336/50000 [=======>......................] - ETA: 12s - loss: 6.1863 - accuracy: 0.0708
on_train_batch_begin: 1615854554.568660s

14 step training time: 0.350013s

on_train_batch_end: 1615854554.917601s

15360/50000 [========>.....................] - ETA: 11s - loss: 6.1745 - accuracy: 0.0711
on_train_batch_begin: 1615854554.917893s

15 step training time: 0.349233s

on_train_batch_end: 1615854555.271952s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.1580 - accuracy: 0.0714
on_train_batch_begin: 1615854555.272246s

16 step training time: 0.354353s

on_train_batch_end: 1615854555.620379s

17408/50000 [=========>....................] - ETA: 11s - loss: 6.1605 - accuracy: 0.0713
on_train_batch_begin: 1615854555.620744s

17 step training time: 0.348499s

on_train_batch_end: 1615854555.972031s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.1529 - accuracy: 0.0719
on_train_batch_begin: 1615854555.972332s

18 step training time: 0.351588s

on_train_batch_end: 1615854556.323954s

19456/50000 [==========>...................] - ETA: 10s - loss: 6.1521 - accuracy: 0.0715
on_train_batch_begin: 1615854556.324251s

19 step training time: 0.351919s

on_train_batch_end: 1615854556.671427s

20480/50000 [===========>..................] - ETA: 10s - loss: 6.1507 - accuracy: 0.0723
on_train_batch_begin: 1615854556.671722s

20 step training time: 0.347471s

on_train_batch_end: 1615854557.020961s

21504/50000 [===========>..................] - ETA: 9s - loss: 6.1473 - accuracy: 0.0736 
on_train_batch_begin: 1615854557.021265s

21 step training time: 0.349543s

on_train_batch_end: 1615854557.374412s

22528/50000 [============>.................] - ETA: 9s - loss: 6.1397 - accuracy: 0.0746
on_train_batch_begin: 1615854557.374711s

22 step training time: 0.353446s

on_train_batch_end: 1615854557.725932s

23552/50000 [=============>................] - ETA: 9s - loss: 6.1409 - accuracy: 0.0752
on_train_batch_begin: 1615854557.726229s

23 step training time: 0.351519s

on_train_batch_end: 1615854558.075048s

24576/50000 [=============>................] - ETA: 8s - loss: 6.1307 - accuracy: 0.0759
on_train_batch_begin: 1615854558.075352s

24 step training time: 0.349123s

on_train_batch_end: 1615854558.426117s

25600/50000 [==============>...............] - ETA: 8s - loss: 6.1192 - accuracy: 0.0770
on_train_batch_begin: 1615854558.426444s

25 step training time: 0.351092s

on_train_batch_end: 1615854558.780149s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.1079 - accuracy: 0.0772
on_train_batch_begin: 1615854558.780459s

26 step training time: 0.354015s

on_train_batch_end: 1615854559.129774s

27648/50000 [===============>..............] - ETA: 7s - loss: 6.1026 - accuracy: 0.0773
on_train_batch_begin: 1615854559.130073s

27 step training time: 0.349614s

on_train_batch_end: 1615854559.479496s

28672/50000 [================>.............] - ETA: 7s - loss: 6.0960 - accuracy: 0.0774
on_train_batch_begin: 1615854559.479793s

28 step training time: 0.349720s

on_train_batch_end: 1615854559.833503s

29696/50000 [================>.............] - ETA: 6s - loss: 6.0871 - accuracy: 0.0776
on_train_batch_begin: 1615854559.833802s

29 step training time: 0.354009s

on_train_batch_end: 1615854560.183622s

30720/50000 [=================>............] - ETA: 6s - loss: 6.0825 - accuracy: 0.0772
on_train_batch_begin: 1615854560.183924s

30 step training time: 0.350122s

on_train_batch_end: 1615854560.535763s

31744/50000 [==================>...........] - ETA: 6s - loss: 6.0765 - accuracy: 0.0769
on_train_batch_begin: 1615854560.536077s

31 step training time: 0.352152s

on_train_batch_end: 1615854560.888463s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.0683 - accuracy: 0.0766
on_train_batch_begin: 1615854560.888764s

32 step training time: 0.352687s

on_train_batch_end: 1615854561.239770s

33792/50000 [===================>..........] - ETA: 5s - loss: 6.0579 - accuracy: 0.0766
on_train_batch_begin: 1615854561.240068s

33 step training time: 0.351304s

on_train_batch_end: 1615854561.589520s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.0475 - accuracy: 0.0767
on_train_batch_begin: 1615854561.589821s

34 step training time: 0.349753s

on_train_batch_end: 1615854561.939867s

35840/50000 [====================>.........] - ETA: 4s - loss: 6.0389 - accuracy: 0.0769
on_train_batch_begin: 1615854561.940169s

35 step training time: 0.350348s

on_train_batch_end: 1615854562.291918s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.0277 - accuracy: 0.0766
on_train_batch_begin: 1615854562.292214s

36 step training time: 0.352046s

on_train_batch_end: 1615854562.644478s

37888/50000 [=====================>........] - ETA: 4s - loss: 6.0112 - accuracy: 0.0768
on_train_batch_begin: 1615854562.644783s

37 step training time: 0.352569s

on_train_batch_end: 1615854562.998317s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.0014 - accuracy: 0.0762
on_train_batch_begin: 1615854562.998612s

38 step training time: 0.353829s

on_train_batch_end: 1615854563.352473s

39936/50000 [======================>.......] - ETA: 3s - loss: 5.9893 - accuracy: 0.0761
on_train_batch_begin: 1615854563.352842s

39 step training time: 0.354230s

on_train_batch_end: 1615854563.706467s

40960/50000 [=======================>......] - ETA: 3s - loss: 5.9800 - accuracy: 0.0758
on_train_batch_begin: 1615854563.706773s

40 step training time: 0.353931s

on_train_batch_end: 1615854564.056156s

41984/50000 [========================>.....] - ETA: 2s - loss: 5.9655 - accuracy: 0.0756
on_train_batch_begin: 1615854564.056495s

41 step training time: 0.349722s

on_train_batch_end: 1615854564.409738s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.9614 - accuracy: 0.0752
on_train_batch_begin: 1615854564.410042s

42 step training time: 0.353547s

on_train_batch_end: 1615854564.765826s

44032/50000 [=========================>....] - ETA: 2s - loss: 5.9538 - accuracy: 0.0749
on_train_batch_begin: 1615854564.766123s

43 step training time: 0.356081s

on_train_batch_end: 1615854565.119942s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.9439 - accuracy: 0.0745
on_train_batch_begin: 1615854565.120242s

44 step training time: 0.354120s

on_train_batch_end: 1615854565.474379s

46080/50000 [==========================>...] - ETA: 1s - loss: 5.9340 - accuracy: 0.0743
on_train_batch_begin: 1615854565.474676s

45 step training time: 0.354434s

on_train_batch_end: 1615854565.827008s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.9245 - accuracy: 0.0740
on_train_batch_begin: 1615854565.827309s

46 step training time: 0.352633s

on_train_batch_end: 1615854566.182159s

48128/50000 [===========================>..] - ETA: 0s - loss: 5.9124 - accuracy: 0.0738
on_train_batch_begin: 1615854566.182455s

47 step training time: 0.355146s

on_train_batch_end: 1615854566.537982s

49152/50000 [============================>.] - ETA: 0s - loss: 5.9010 - accuracy: 0.0736
on_train_batch_begin: 1615854566.538287s

48 step training time: 0.355832s

on_train_batch_end: 1615854566.825407s

on_test_batch_begin: 1615854566.837202s

49 step training time: 0.298915s

on_epoch_end: 1615854567.661371s

Validation time: 0.824157s

Real time: 1615854567.661371s

Epoch time: 17.961464166641235s

50000/50000 [==============================] - 18s 359us/sample - loss: 5.8917 - accuracy: 0.0735 - val_loss: 28.4843 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615854567.661557s

Real time: 1615854567.6615624
Epoch 3/5

on_train_batch_begin: 1615854567.664853s

on_train_batch_end: 1615854568.017258s

 1024/50000 [..............................] - ETA: 17s - loss: 4.9745 - accuracy: 0.0681
on_train_batch_begin: 1615854568.017570s

1 step training time: 0.352717s

on_train_batch_end: 1615854568.370103s

 2048/50000 [>.............................] - ETA: 16s - loss: 4.9401 - accuracy: 0.0706
on_train_batch_begin: 1615854568.370399s

2 step training time: 0.352828s

on_train_batch_end: 1615854568.729212s

 3072/50000 [>.............................] - ETA: 16s - loss: 4.9525 - accuracy: 0.0696
on_train_batch_begin: 1615854568.729511s

3 step training time: 0.359113s

on_train_batch_end: 1615854569.078280s

 4096/50000 [=>............................] - ETA: 15s - loss: 4.8898 - accuracy: 0.0702
on_train_batch_begin: 1615854569.078577s

4 step training time: 0.349066s

on_train_batch_end: 1615854569.416280s

 5120/50000 [==>...........................] - ETA: 15s - loss: 4.8685 - accuracy: 0.0709
on_train_batch_begin: 1615854569.416602s

5 step training time: 0.338025s

on_train_batch_end: 1615854569.779945s

 6144/50000 [==>...........................] - ETA: 15s - loss: 4.8531 - accuracy: 0.0708
on_train_batch_begin: 1615854569.780255s

6 step training time: 0.363653s

on_train_batch_end: 1615854570.138169s

 7168/50000 [===>..........................] - ETA: 14s - loss: 4.8448 - accuracy: 0.0702
on_train_batch_begin: 1615854570.138468s

7 step training time: 0.358213s

on_train_batch_end: 1615854570.492402s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.7916 - accuracy: 0.0714
on_train_batch_begin: 1615854570.492700s

8 step training time: 0.354232s

on_train_batch_end: 1615854570.848667s

 9216/50000 [====>.........................] - ETA: 14s - loss: 4.7612 - accuracy: 0.0715
on_train_batch_begin: 1615854570.848959s

9 step training time: 0.356259s

on_train_batch_end: 1615854571.205013s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.7551 - accuracy: 0.0715
on_train_batch_begin: 1615854571.205307s

10 step training time: 0.356348s

on_train_batch_end: 1615854571.564303s

11264/50000 [=====>........................] - ETA: 13s - loss: 4.7510 - accuracy: 0.0714
on_train_batch_begin: 1615854571.564599s

11 step training time: 0.359292s

on_train_batch_end: 1615854571.921970s

12288/50000 [======>.......................] - ETA: 13s - loss: 4.7320 - accuracy: 0.0714
on_train_batch_begin: 1615854571.922275s

12 step training time: 0.357676s

on_train_batch_end: 1615854572.278427s

13312/50000 [======>.......................] - ETA: 12s - loss: 4.7100 - accuracy: 0.0717
on_train_batch_begin: 1615854572.278728s

13 step training time: 0.356452s

on_train_batch_end: 1615854572.638353s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.6926 - accuracy: 0.0719
on_train_batch_begin: 1615854572.638649s

14 step training time: 0.359921s

on_train_batch_end: 1615854572.996330s

15360/50000 [========>.....................] - ETA: 12s - loss: 4.6749 - accuracy: 0.0724
on_train_batch_begin: 1615854572.996648s

15 step training time: 0.357999s

on_train_batch_end: 1615854573.352397s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.6427 - accuracy: 0.0730
on_train_batch_begin: 1615854573.352693s

16 step training time: 0.356046s

on_train_batch_end: 1615854573.712136s

17408/50000 [=========>....................] - ETA: 11s - loss: 4.6258 - accuracy: 0.0732
on_train_batch_begin: 1615854573.712441s

17 step training time: 0.359748s

on_train_batch_end: 1615854574.069874s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.6108 - accuracy: 0.0734
on_train_batch_begin: 1615854574.070179s

18 step training time: 0.357738s

on_train_batch_end: 1615854574.429729s

19456/50000 [==========>...................] - ETA: 10s - loss: 4.5979 - accuracy: 0.0735
on_train_batch_begin: 1615854574.430172s

19 step training time: 0.359993s

on_train_batch_end: 1615854574.789381s

20480/50000 [===========>..................] - ETA: 10s - loss: 4.5729 - accuracy: 0.0740
on_train_batch_begin: 1615854574.789678s

20 step training time: 0.359506s

on_train_batch_end: 1615854575.146080s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.5426 - accuracy: 0.0744 
on_train_batch_begin: 1615854575.146401s

21 step training time: 0.356723s

on_train_batch_end: 1615854575.505242s

22528/50000 [============>.................] - ETA: 9s - loss: 4.5421 - accuracy: 0.0742
on_train_batch_begin: 1615854575.505549s

22 step training time: 0.359148s

on_train_batch_end: 1615854575.863976s

23552/50000 [=============>................] - ETA: 9s - loss: 4.5264 - accuracy: 0.0745
on_train_batch_begin: 1615854575.864286s

23 step training time: 0.358737s

on_train_batch_end: 1615854576.222476s

24576/50000 [=============>................] - ETA: 8s - loss: 4.5154 - accuracy: 0.0747
on_train_batch_begin: 1615854576.222778s

24 step training time: 0.358492s

on_train_batch_end: 1615854576.580023s

25600/50000 [==============>...............] - ETA: 8s - loss: 4.5035 - accuracy: 0.0753
on_train_batch_begin: 1615854576.580320s

25 step training time: 0.357543s

on_train_batch_end: 1615854576.941207s

26624/50000 [==============>...............] - ETA: 8s - loss: 4.5006 - accuracy: 0.0757
on_train_batch_begin: 1615854576.941523s

26 step training time: 0.361202s

on_train_batch_end: 1615854577.300116s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.4902 - accuracy: 0.0762
on_train_batch_begin: 1615854577.300423s

27 step training time: 0.358901s

on_train_batch_end: 1615854577.658626s

28672/50000 [================>.............] - ETA: 7s - loss: 4.4763 - accuracy: 0.0769
on_train_batch_begin: 1615854577.658957s

28 step training time: 0.358533s

on_train_batch_end: 1615854578.017287s

29696/50000 [================>.............] - ETA: 7s - loss: 4.4650 - accuracy: 0.0775
on_train_batch_begin: 1615854578.017602s

29 step training time: 0.358646s

on_train_batch_end: 1615854578.377776s

30720/50000 [=================>............] - ETA: 6s - loss: 4.4522 - accuracy: 0.0780
on_train_batch_begin: 1615854578.378070s

30 step training time: 0.360468s

on_train_batch_end: 1615854578.738698s

31744/50000 [==================>...........] - ETA: 6s - loss: 4.4447 - accuracy: 0.0786
on_train_batch_begin: 1615854578.739041s

31 step training time: 0.360970s

on_train_batch_end: 1615854579.096343s

32768/50000 [==================>...........] - ETA: 6s - loss: 4.4400 - accuracy: 0.0789
on_train_batch_begin: 1615854579.096662s

32 step training time: 0.357622s

on_train_batch_end: 1615854579.454916s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.4256 - accuracy: 0.0794
on_train_batch_begin: 1615854579.455209s

33 step training time: 0.358546s

on_train_batch_end: 1615854579.816141s

34816/50000 [===================>..........] - ETA: 5s - loss: 4.4069 - accuracy: 0.0799
on_train_batch_begin: 1615854579.816470s

34 step training time: 0.361261s

on_train_batch_end: 1615854580.177745s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.3934 - accuracy: 0.0803
on_train_batch_begin: 1615854580.178040s

35 step training time: 0.361570s

on_train_batch_end: 1615854580.536102s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.3812 - accuracy: 0.0806
on_train_batch_begin: 1615854580.536437s

36 step training time: 0.358397s

on_train_batch_end: 1615854580.896287s

37888/50000 [=====================>........] - ETA: 4s - loss: 4.3640 - accuracy: 0.0809
on_train_batch_begin: 1615854580.896616s

37 step training time: 0.360180s

on_train_batch_end: 1615854581.259610s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.3483 - accuracy: 0.0811
on_train_batch_begin: 1615854581.259910s

38 step training time: 0.363294s

on_train_batch_end: 1615854581.620272s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.3404 - accuracy: 0.0812
on_train_batch_begin: 1615854581.620578s

39 step training time: 0.360667s

on_train_batch_end: 1615854581.979987s

40960/50000 [=======================>......] - ETA: 3s - loss: 4.3274 - accuracy: 0.0814
on_train_batch_begin: 1615854581.980285s

40 step training time: 0.359707s

on_train_batch_end: 1615854582.338714s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.3108 - accuracy: 0.0816
on_train_batch_begin: 1615854582.339039s

41 step training time: 0.358754s

on_train_batch_end: 1615854582.701242s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.2949 - accuracy: 0.0818
on_train_batch_begin: 1615854582.701547s

42 step training time: 0.362508s

on_train_batch_end: 1615854583.062968s

44032/50000 [=========================>....] - ETA: 2s - loss: 4.2841 - accuracy: 0.0819
on_train_batch_begin: 1615854583.063264s

43 step training time: 0.361718s

on_train_batch_end: 1615854583.426447s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.2730 - accuracy: 0.0821
on_train_batch_begin: 1615854583.426749s

44 step training time: 0.363484s

on_train_batch_end: 1615854583.788099s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.2579 - accuracy: 0.0822
on_train_batch_begin: 1615854583.788404s

45 step training time: 0.361655s

on_train_batch_end: 1615854584.147484s

47104/50000 [===========================>..] - ETA: 1s - loss: 4.2464 - accuracy: 0.0824
on_train_batch_begin: 1615854584.147812s

46 step training time: 0.359408s

on_train_batch_end: 1615854584.508186s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.2359 - accuracy: 0.0825
on_train_batch_begin: 1615854584.508477s

47 step training time: 0.360666s

on_train_batch_end: 1615854584.867935s

49152/50000 [============================>.] - ETA: 0s - loss: 4.2252 - accuracy: 0.0825
on_train_batch_begin: 1615854584.868250s

48 step training time: 0.359772s

on_train_batch_end: 1615854585.165006s

on_test_batch_begin: 1615854585.175053s

49 step training time: 0.306804s

on_epoch_end: 1615854586.015063s

Validation time: 0.839998s

Real time: 1615854586.015063s

Epoch time: 18.353516817092896s

50000/50000 [==============================] - 18s 367us/sample - loss: 4.2180 - accuracy: 0.0826 - val_loss: 7.3726 - val_accuracy: 0.0999

on_epoch_begin: 1615854586.015251s

Real time: 1615854586.015257
Epoch 4/5

on_train_batch_begin: 1615854586.018636s

on_train_batch_end: 1615854586.371811s

 1024/50000 [..............................] - ETA: 17s - loss: 3.5969 - accuracy: 0.0862
on_train_batch_begin: 1615854586.372112s

1 step training time: 0.353476s

on_train_batch_end: 1615854586.733995s

 2048/50000 [>.............................] - ETA: 16s - loss: 3.4981 - accuracy: 0.0886
on_train_batch_begin: 1615854586.734290s

2 step training time: 0.362179s

on_train_batch_end: 1615854587.099814s

 3072/50000 [>.............................] - ETA: 16s - loss: 3.5034 - accuracy: 0.0887
on_train_batch_begin: 1615854587.100114s

3 step training time: 0.365824s

on_train_batch_end: 1615854587.457763s

 4096/50000 [=>............................] - ETA: 16s - loss: 3.4945 - accuracy: 0.0886
on_train_batch_begin: 1615854587.458056s

4 step training time: 0.357941s

on_train_batch_end: 1615854587.815698s

 5120/50000 [==>...........................] - ETA: 15s - loss: 3.4699 - accuracy: 0.0894
on_train_batch_begin: 1615854587.816004s

5 step training time: 0.357948s

on_train_batch_end: 1615854588.179732s

 6144/50000 [==>...........................] - ETA: 15s - loss: 3.4948 - accuracy: 0.0888
on_train_batch_begin: 1615854588.180026s

6 step training time: 0.364022s

on_train_batch_end: 1615854588.543805s

 7168/50000 [===>..........................] - ETA: 15s - loss: 3.5024 - accuracy: 0.0892
on_train_batch_begin: 1615854588.544122s

7 step training time: 0.364096s

on_train_batch_end: 1615854588.906525s

 8192/50000 [===>..........................] - ETA: 14s - loss: 3.4785 - accuracy: 0.0895
on_train_batch_begin: 1615854588.906846s

8 step training time: 0.362724s

on_train_batch_end: 1615854589.266328s

 9216/50000 [====>.........................] - ETA: 14s - loss: 3.4784 - accuracy: 0.0897
on_train_batch_begin: 1615854589.266644s

9 step training time: 0.359798s

on_train_batch_end: 1615854589.626246s

10240/50000 [=====>........................] - ETA: 14s - loss: 3.4837 - accuracy: 0.0897
on_train_batch_begin: 1615854589.626574s

10 step training time: 0.359930s

on_train_batch_end: 1615854589.987210s

11264/50000 [=====>........................] - ETA: 13s - loss: 3.5003 - accuracy: 0.0895
on_train_batch_begin: 1615854589.987507s

11 step training time: 0.360933s

on_train_batch_end: 1615854590.348038s

12288/50000 [======>.......................] - ETA: 13s - loss: 3.5143 - accuracy: 0.0896
on_train_batch_begin: 1615854590.348348s

12 step training time: 0.360841s

on_train_batch_end: 1615854590.712869s

13312/50000 [======>.......................] - ETA: 12s - loss: 3.5144 - accuracy: 0.0897
on_train_batch_begin: 1615854590.713171s

13 step training time: 0.364823s

on_train_batch_end: 1615854591.074209s

14336/50000 [=======>......................] - ETA: 12s - loss: 3.5172 - accuracy: 0.0895
on_train_batch_begin: 1615854591.074508s

14 step training time: 0.361336s

on_train_batch_end: 1615854591.435138s

15360/50000 [========>.....................] - ETA: 12s - loss: 3.5178 - accuracy: 0.0897
on_train_batch_begin: 1615854591.435441s

15 step training time: 0.360933s

on_train_batch_end: 1615854591.795713s

16384/50000 [========>.....................] - ETA: 11s - loss: 3.5261 - accuracy: 0.0895
on_train_batch_begin: 1615854591.796015s

16 step training time: 0.360574s

on_train_batch_end: 1615854592.161844s

17408/50000 [=========>....................] - ETA: 11s - loss: 3.5348 - accuracy: 0.0894
on_train_batch_begin: 1615854592.162157s

17 step training time: 0.366142s

on_train_batch_end: 1615854592.527498s

18432/50000 [==========>...................] - ETA: 11s - loss: 3.5353 - accuracy: 0.0892
on_train_batch_begin: 1615854592.527855s

18 step training time: 0.365698s

on_train_batch_end: 1615854592.889179s

19456/50000 [==========>...................] - ETA: 10s - loss: 3.5253 - accuracy: 0.0892
on_train_batch_begin: 1615854592.889473s

19 step training time: 0.361618s

on_train_batch_end: 1615854593.254112s

20480/50000 [===========>..................] - ETA: 10s - loss: 3.5228 - accuracy: 0.0891
on_train_batch_begin: 1615854593.254409s

20 step training time: 0.364935s

on_train_batch_end: 1615854593.620039s

21504/50000 [===========>..................] - ETA: 10s - loss: 3.5295 - accuracy: 0.0889
on_train_batch_begin: 1615854593.620340s

21 step training time: 0.365931s

on_train_batch_end: 1615854593.983755s

22528/50000 [============>.................] - ETA: 9s - loss: 3.5253 - accuracy: 0.0888 
on_train_batch_begin: 1615854593.984060s

22 step training time: 0.363720s

on_train_batch_end: 1615854594.349071s

23552/50000 [=============>................] - ETA: 9s - loss: 3.5228 - accuracy: 0.0887
on_train_batch_begin: 1615854594.349369s

23 step training time: 0.365309s

on_train_batch_end: 1615854594.709772s

24576/50000 [=============>................] - ETA: 8s - loss: 3.5190 - accuracy: 0.0888
on_train_batch_begin: 1615854594.710067s

24 step training time: 0.360698s

on_train_batch_end: 1615854595.075275s

25600/50000 [==============>...............] - ETA: 8s - loss: 3.5223 - accuracy: 0.0886
on_train_batch_begin: 1615854595.075586s

25 step training time: 0.365518s

on_train_batch_end: 1615854595.439538s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.5100 - accuracy: 0.0888
on_train_batch_begin: 1615854595.439838s

26 step training time: 0.364252s

on_train_batch_end: 1615854595.780865s

27648/50000 [===============>..............] - ETA: 7s - loss: 3.5085 - accuracy: 0.0887
on_train_batch_begin: 1615854595.781169s

27 step training time: 0.341331s

on_train_batch_end: 1615854596.152408s

28672/50000 [================>.............] - ETA: 7s - loss: 3.5090 - accuracy: 0.0887
on_train_batch_begin: 1615854596.152706s

28 step training time: 0.371537s

on_train_batch_end: 1615854596.519492s

29696/50000 [================>.............] - ETA: 7s - loss: 3.5125 - accuracy: 0.0888
on_train_batch_begin: 1615854596.519792s

29 step training time: 0.367086s

on_train_batch_end: 1615854596.877652s

30720/50000 [=================>............] - ETA: 6s - loss: 3.5126 - accuracy: 0.0888
on_train_batch_begin: 1615854596.877956s

30 step training time: 0.358165s

on_train_batch_end: 1615854597.244150s

31744/50000 [==================>...........] - ETA: 6s - loss: 3.5152 - accuracy: 0.0888
on_train_batch_begin: 1615854597.244469s

31 step training time: 0.366513s

on_train_batch_end: 1615854597.612977s

32768/50000 [==================>...........] - ETA: 6s - loss: 3.5138 - accuracy: 0.0888
on_train_batch_begin: 1615854597.613280s

32 step training time: 0.368811s

on_train_batch_end: 1615854597.977737s

33792/50000 [===================>..........] - ETA: 5s - loss: 3.5120 - accuracy: 0.0888
on_train_batch_begin: 1615854597.978038s

33 step training time: 0.364758s

on_train_batch_end: 1615854598.343348s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.5091 - accuracy: 0.0888
on_train_batch_begin: 1615854598.343784s

34 step training time: 0.365747s

on_train_batch_end: 1615854598.711683s

35840/50000 [====================>.........] - ETA: 5s - loss: 3.5073 - accuracy: 0.0888
on_train_batch_begin: 1615854598.711980s

35 step training time: 0.368196s

on_train_batch_end: 1615854599.075826s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.5062 - accuracy: 0.0887
on_train_batch_begin: 1615854599.076137s

36 step training time: 0.364157s

on_train_batch_end: 1615854599.445670s

37888/50000 [=====================>........] - ETA: 4s - loss: 3.5119 - accuracy: 0.0886
on_train_batch_begin: 1615854599.445985s

37 step training time: 0.369848s

on_train_batch_end: 1615854599.808582s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.5056 - accuracy: 0.0886
on_train_batch_begin: 1615854599.808897s

38 step training time: 0.362912s

on_train_batch_end: 1615854600.173772s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.5001 - accuracy: 0.0886
on_train_batch_begin: 1615854600.174066s

39 step training time: 0.365169s

on_train_batch_end: 1615854600.544797s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.4960 - accuracy: 0.0886
on_train_batch_begin: 1615854600.545089s

40 step training time: 0.371023s

on_train_batch_end: 1615854600.909104s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.4895 - accuracy: 0.0887
on_train_batch_begin: 1615854600.909398s

41 step training time: 0.364309s

on_train_batch_end: 1615854601.273769s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.4867 - accuracy: 0.0887
on_train_batch_begin: 1615854601.274063s

42 step training time: 0.364666s

on_train_batch_end: 1615854601.639639s

44032/50000 [=========================>....] - ETA: 2s - loss: 3.4865 - accuracy: 0.0887
on_train_batch_begin: 1615854601.639948s

43 step training time: 0.365885s

on_train_batch_end: 1615854602.010550s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.4862 - accuracy: 0.0886
on_train_batch_begin: 1615854602.010879s

44 step training time: 0.370930s

on_train_batch_end: 1615854602.376518s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.4824 - accuracy: 0.0886
on_train_batch_begin: 1615854602.376817s

45 step training time: 0.365938s

on_train_batch_end: 1615854602.739754s

47104/50000 [===========================>..] - ETA: 1s - loss: 3.4775 - accuracy: 0.0887
on_train_batch_begin: 1615854602.740056s

46 step training time: 0.363239s

on_train_batch_end: 1615854603.105651s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.4742 - accuracy: 0.0887
on_train_batch_begin: 1615854603.105952s

47 step training time: 0.365897s

on_train_batch_end: 1615854603.468332s

49152/50000 [============================>.] - ETA: 0s - loss: 3.4724 - accuracy: 0.0887
on_train_batch_begin: 1615854603.468631s

48 step training time: 0.362678s

on_train_batch_end: 1615854603.777673s

on_test_batch_begin: 1615854603.792858s

49 step training time: 0.324228s

on_epoch_end: 1615854604.650160s

Validation time: 0.857282s

Real time: 1615854604.650160s

Epoch time: 18.634918689727783s

50000/50000 [==============================] - 19s 373us/sample - loss: 3.4682 - accuracy: 0.0888 - val_loss: 7.6136 - val_accuracy: 0.0999

on_epoch_begin: 1615854604.650351s

Real time: 1615854604.6503575
Epoch 5/5

on_train_batch_begin: 1615854604.653725s

on_train_batch_end: 1615854605.016242s

 1024/50000 [..............................] - ETA: 17s - loss: 3.1054 - accuracy: 0.0948
on_train_batch_begin: 1615854605.016579s

1 step training time: 0.362854s

on_train_batch_end: 1615854605.382184s

 2048/50000 [>.............................] - ETA: 17s - loss: 3.1530 - accuracy: 0.0945
on_train_batch_begin: 1615854605.382607s

2 step training time: 0.366027s

on_train_batch_end: 1615854605.757787s

 3072/50000 [>.............................] - ETA: 16s - loss: 3.1929 - accuracy: 0.0926
on_train_batch_begin: 1615854605.758084s

3 step training time: 0.375478s

on_train_batch_end: 1615854606.126579s

 4096/50000 [=>............................] - ETA: 16s - loss: 3.2223 - accuracy: 0.0923
on_train_batch_begin: 1615854606.126901s

4 step training time: 0.368817s

on_train_batch_end: 1615854606.490735s

 5120/50000 [==>...........................] - ETA: 16s - loss: 3.2201 - accuracy: 0.0913
on_train_batch_begin: 1615854606.491054s

5 step training time: 0.364153s

on_train_batch_end: 1615854606.862741s

 6144/50000 [==>...........................] - ETA: 15s - loss: 3.2000 - accuracy: 0.0906
on_train_batch_begin: 1615854606.863061s

6 step training time: 0.372007s

on_train_batch_end: 1615854607.230007s

 7168/50000 [===>..........................] - ETA: 15s - loss: 3.1941 - accuracy: 0.0902
on_train_batch_begin: 1615854607.230300s

7 step training time: 0.367239s

on_train_batch_end: 1615854607.597755s

 8192/50000 [===>..........................] - ETA: 15s - loss: 3.1746 - accuracy: 0.0902
on_train_batch_begin: 1615854607.598072s

8 step training time: 0.367772s

on_train_batch_end: 1615854607.968704s

 9216/50000 [====>.........................] - ETA: 14s - loss: 3.1623 - accuracy: 0.0898
on_train_batch_begin: 1615854607.969014s

9 step training time: 0.370942s

on_train_batch_end: 1615854608.337906s

10240/50000 [=====>........................] - ETA: 14s - loss: 3.1480 - accuracy: 0.0894
on_train_batch_begin: 1615854608.338201s

10 step training time: 0.369187s

on_train_batch_end: 1615854608.705381s

11264/50000 [=====>........................] - ETA: 13s - loss: 3.1535 - accuracy: 0.0886
on_train_batch_begin: 1615854608.705690s

11 step training time: 0.367489s

on_train_batch_end: 1615854609.072389s

12288/50000 [======>.......................] - ETA: 13s - loss: 3.1446 - accuracy: 0.0885
on_train_batch_begin: 1615854609.072687s

12 step training time: 0.366997s

on_train_batch_end: 1615854609.439133s

13312/50000 [======>.......................] - ETA: 13s - loss: 3.1482 - accuracy: 0.0882
on_train_batch_begin: 1615854609.439434s

13 step training time: 0.366747s

on_train_batch_end: 1615854609.808124s

14336/50000 [=======>......................] - ETA: 12s - loss: 3.1374 - accuracy: 0.0882
on_train_batch_begin: 1615854609.808421s

14 step training time: 0.368988s

on_train_batch_end: 1615854610.178219s

15360/50000 [========>.....................] - ETA: 12s - loss: 3.1389 - accuracy: 0.0880
on_train_batch_begin: 1615854610.178514s

15 step training time: 0.370092s

on_train_batch_end: 1615854610.547574s

16384/50000 [========>.....................] - ETA: 12s - loss: 3.1356 - accuracy: 0.0878
on_train_batch_begin: 1615854610.547873s

16 step training time: 0.369360s

on_train_batch_end: 1615854610.916524s

17408/50000 [=========>....................] - ETA: 11s - loss: 3.1426 - accuracy: 0.0875
on_train_batch_begin: 1615854610.916827s

17 step training time: 0.368953s

on_train_batch_end: 1615854611.285128s

18432/50000 [==========>...................] - ETA: 11s - loss: 3.1296 - accuracy: 0.0876
on_train_batch_begin: 1615854611.285423s

18 step training time: 0.368596s

on_train_batch_end: 1615854611.651035s

19456/50000 [==========>...................] - ETA: 10s - loss: 3.1375 - accuracy: 0.0875
on_train_batch_begin: 1615854611.651335s

19 step training time: 0.365911s

on_train_batch_end: 1615854612.018440s

20480/50000 [===========>..................] - ETA: 10s - loss: 3.1505 - accuracy: 0.0873
on_train_batch_begin: 1615854612.018742s

20 step training time: 0.367407s

on_train_batch_end: 1615854612.386433s

21504/50000 [===========>..................] - ETA: 10s - loss: 3.1428 - accuracy: 0.0875
on_train_batch_begin: 1615854612.386741s

21 step training time: 0.367999s

on_train_batch_end: 1615854612.753751s

22528/50000 [============>.................] - ETA: 9s - loss: 3.1450 - accuracy: 0.0875 
on_train_batch_begin: 1615854612.754048s

22 step training time: 0.367307s

on_train_batch_end: 1615854613.121915s

23552/50000 [=============>................] - ETA: 9s - loss: 3.1375 - accuracy: 0.0876
on_train_batch_begin: 1615854613.122229s

23 step training time: 0.368181s

on_train_batch_end: 1615854613.490706s

24576/50000 [=============>................] - ETA: 9s - loss: 3.1382 - accuracy: 0.0876
on_train_batch_begin: 1615854613.491029s

24 step training time: 0.368800s

on_train_batch_end: 1615854613.859732s

25600/50000 [==============>...............] - ETA: 8s - loss: 3.1401 - accuracy: 0.0877
on_train_batch_begin: 1615854613.860034s

25 step training time: 0.369005s

on_train_batch_end: 1615854614.225759s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.1317 - accuracy: 0.0878
on_train_batch_begin: 1615854614.226055s

26 step training time: 0.366021s

on_train_batch_end: 1615854614.591241s

27648/50000 [===============>..............] - ETA: 8s - loss: 3.1207 - accuracy: 0.0879
on_train_batch_begin: 1615854614.591538s

27 step training time: 0.365484s

on_train_batch_end: 1615854614.958657s

28672/50000 [================>.............] - ETA: 7s - loss: 3.1224 - accuracy: 0.0878
on_train_batch_begin: 1615854614.958984s

28 step training time: 0.367445s

on_train_batch_end: 1615854615.328361s

29696/50000 [================>.............] - ETA: 7s - loss: 3.1295 - accuracy: 0.0877
on_train_batch_begin: 1615854615.328657s

29 step training time: 0.369673s

on_train_batch_end: 1615854615.699200s

30720/50000 [=================>............] - ETA: 6s - loss: 3.1275 - accuracy: 0.0876
on_train_batch_begin: 1615854615.699500s

30 step training time: 0.370843s

on_train_batch_end: 1615854616.066349s

31744/50000 [==================>...........] - ETA: 6s - loss: 3.1249 - accuracy: 0.0876
on_train_batch_begin: 1615854616.066653s

31 step training time: 0.367153s

on_train_batch_end: 1615854616.433644s

32768/50000 [==================>...........] - ETA: 6s - loss: 3.1249 - accuracy: 0.0876
on_train_batch_begin: 1615854616.433941s

32 step training time: 0.367288s

on_train_batch_end: 1615854616.799923s

33792/50000 [===================>..........] - ETA: 5s - loss: 3.1221 - accuracy: 0.0876
on_train_batch_begin: 1615854616.800243s

33 step training time: 0.366302s

on_train_batch_end: 1615854617.164130s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.1227 - accuracy: 0.0876
on_train_batch_begin: 1615854617.164432s

34 step training time: 0.364190s

on_train_batch_end: 1615854617.531985s

35840/50000 [====================>.........] - ETA: 5s - loss: 3.1190 - accuracy: 0.0876
on_train_batch_begin: 1615854617.532281s

35 step training time: 0.367848s

on_train_batch_end: 1615854617.900961s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.1191 - accuracy: 0.0875
on_train_batch_begin: 1615854617.901258s

36 step training time: 0.368977s

on_train_batch_end: 1615854618.268105s

37888/50000 [=====================>........] - ETA: 4s - loss: 3.1134 - accuracy: 0.0876
on_train_batch_begin: 1615854618.268402s

37 step training time: 0.367144s

on_train_batch_end: 1615854618.635800s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.1144 - accuracy: 0.0876
on_train_batch_begin: 1615854618.636102s

38 step training time: 0.367701s

on_train_batch_end: 1615854619.004605s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.1142 - accuracy: 0.0876
on_train_batch_begin: 1615854619.004897s

39 step training time: 0.368795s

on_train_batch_end: 1615854619.375734s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.1069 - accuracy: 0.0877
on_train_batch_begin: 1615854619.376035s

40 step training time: 0.371138s

on_train_batch_end: 1615854619.741320s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.1085 - accuracy: 0.0877
on_train_batch_begin: 1615854619.741618s

41 step training time: 0.365583s

on_train_batch_end: 1615854620.106220s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.1081 - accuracy: 0.0877
on_train_batch_begin: 1615854620.106554s

42 step training time: 0.364936s

on_train_batch_end: 1615854620.473860s

44032/50000 [=========================>....] - ETA: 2s - loss: 3.1074 - accuracy: 0.0877
on_train_batch_begin: 1615854620.474155s

43 step training time: 0.367602s

on_train_batch_end: 1615854620.839853s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.1033 - accuracy: 0.0877
on_train_batch_begin: 1615854620.840150s

44 step training time: 0.365995s

on_train_batch_end: 1615854621.208540s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.0995 - accuracy: 0.0878
on_train_batch_begin: 1615854621.208838s

45 step training time: 0.368688s

on_train_batch_end: 1615854621.577495s

47104/50000 [===========================>..] - ETA: 1s - loss: 3.1012 - accuracy: 0.0878
on_train_batch_begin: 1615854621.577820s

46 step training time: 0.368981s

on_train_batch_end: 1615854621.946707s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.1028 - accuracy: 0.0877
on_train_batch_begin: 1615854621.947030s

47 step training time: 0.369211s

on_train_batch_end: 1615854622.313984s

49152/50000 [============================>.] - ETA: 0s - loss: 3.0988 - accuracy: 0.0877
on_train_batch_begin: 1615854622.314286s

48 step training time: 0.367255s

on_train_batch_end: 1615854622.614192s

on_test_batch_begin: 1615854622.625038s

49 step training time: 0.310752s

on_epoch_end: 1615854623.487607s

Validation time: 0.862555s

Real time: 1615854623.487607s

Epoch time: 18.837265491485596s

50000/50000 [==============================] - 19s 377us/sample - loss: 3.0966 - accuracy: 0.0876 - val_loss: 7.2172 - val_accuracy: 0.0999
Tempo do fit: 122.45254611968994