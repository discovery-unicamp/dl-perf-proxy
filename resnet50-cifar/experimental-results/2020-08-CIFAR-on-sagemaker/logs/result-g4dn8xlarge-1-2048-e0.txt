wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:58
   122880/170498071 [..............................] - ETA: 1:43
   483328/170498071 [..............................] - ETA: 43s 
  1253376/170498071 [..............................] - ETA: 23s
  2121728/170498071 [..............................] - ETA: 18s
  3039232/170498071 [..............................] - ETA: 15s
  4055040/170498071 [..............................] - ETA: 13s
  5185536/170498071 [..............................] - ETA: 12s
  6365184/170498071 [>.............................] - ETA: 11s
  7700480/170498071 [>.............................] - ETA: 10s
  9035776/170498071 [>.............................] - ETA: 9s 
 10518528/170498071 [>.............................] - ETA: 8s
 12001280/170498071 [=>............................] - ETA: 8s
 13557760/170498071 [=>............................] - ETA: 7s
 15204352/170498071 [=>............................] - ETA: 7s
 16834560/170498071 [=>............................] - ETA: 7s
 18505728/170498071 [==>...........................] - ETA: 6s
 20013056/170498071 [==>...........................] - ETA: 6s
 21700608/170498071 [==>...........................] - ETA: 6s
 23191552/170498071 [===>..........................] - ETA: 6s
 24633344/170498071 [===>..........................] - ETA: 6s
 26189824/170498071 [===>..........................] - ETA: 5s
 27615232/170498071 [===>..........................] - ETA: 5s
 29106176/170498071 [====>.........................] - ETA: 5s
 30547968/170498071 [====>.........................] - ETA: 5s
 32022528/170498071 [====>.........................] - ETA: 5s
 33480704/170498071 [====>.........................] - ETA: 5s
 34971648/170498071 [=====>........................] - ETA: 5s
 36478976/170498071 [=====>........................] - ETA: 5s
 37969920/170498071 [=====>........................] - ETA: 5s
 39428096/170498071 [=====>........................] - ETA: 5s
 40902656/170498071 [======>.......................] - ETA: 5s
 42393600/170498071 [======>.......................] - ETA: 4s
 43884544/170498071 [======>.......................] - ETA: 4s
 45359104/170498071 [======>.......................] - ETA: 4s
 46817280/170498071 [=======>......................] - ETA: 4s
 48308224/170498071 [=======>......................] - ETA: 4s
 49750016/170498071 [=======>......................] - ETA: 4s
 51240960/170498071 [========>.....................] - ETA: 4s
 53092352/170498071 [========>.....................] - ETA: 4s
 55435264/170498071 [========>.....................] - ETA: 4s
 58023936/170498071 [=========>....................] - ETA: 4s
 60858368/170498071 [=========>....................] - ETA: 3s
 63954944/170498071 [==========>...................] - ETA: 3s
 67133440/170498071 [==========>...................] - ETA: 3s
 70279168/170498071 [===========>..................] - ETA: 3s
 73457664/170498071 [===========>..................] - ETA: 3s
 76603392/170498071 [============>.................] - ETA: 2s
 79765504/170498071 [=============>................] - ETA: 2s
 82812928/170498071 [=============>................] - ETA: 2s
 85811200/170498071 [==============>...............] - ETA: 2s
 88940544/170498071 [==============>...............] - ETA: 2s
 92086272/170498071 [===============>..............] - ETA: 2s
 95027200/170498071 [===============>..............] - ETA: 2s
 98164736/170498071 [================>.............] - ETA: 2s
101277696/170498071 [================>.............] - ETA: 1s
104243200/170498071 [=================>............] - ETA: 1s
107356160/170498071 [=================>............] - ETA: 1s
110518272/170498071 [==================>...........] - ETA: 1s
113680384/170498071 [===================>..........] - ETA: 1s
116809728/170498071 [===================>..........] - ETA: 1s
119971840/170498071 [====================>.........] - ETA: 1s
123117568/170498071 [====================>.........] - ETA: 1s
126263296/170498071 [=====================>........] - ETA: 1s
129368064/170498071 [=====================>........] - ETA: 1s
132505600/170498071 [======================>.......] - ETA: 0s
135667712/170498071 [======================>.......] - ETA: 0s
138829824/170498071 [=======================>......] - ETA: 0s
141975552/170498071 [=======================>......] - ETA: 0s
145129472/170498071 [========================>.....] - ETA: 0s
148283392/170498071 [=========================>....] - ETA: 0s
151445504/170498071 [=========================>....] - ETA: 0s
154607616/170498071 [==========================>...] - ETA: 0s
157786112/170498071 [==========================>...] - ETA: 0s
160964608/170498071 [===========================>..] - ETA: 0s
164110336/170498071 [===========================>..] - ETA: 0s
167231488/170498071 [============================>.] - ETA: 0s
170336256/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 4s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 8601600/94765736 [=>............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
38141952/94765736 [===========>..................] - ETA: 1s
45318144/94765736 [=============>................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 1s
56598528/94765736 [================>.............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
73015296/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84680704/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.69056749343872
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598502268.135466s

Real time: 1598502268.1354835
Epoch 1/5

on_train_batch_begin: 1598502268.877030s

on_train_batch_end: 1598502290.692918s

 2048/50000 [>.............................] - ETA: 8:48 - loss: 17.8263 - accuracy: 1.4019e-04
on_train_batch_begin: 1598502290.693493s

1 step training time: 21.816463s

on_train_batch_end: 1598502291.379543s

 4096/50000 [=>............................] - ETA: 4:20 - loss: 14.2071 - accuracy: 3.0613e-04
on_train_batch_begin: 1598502291.379864s

2 step training time: 0.686371s

on_train_batch_end: 1598502292.062010s

 6144/50000 [==>...........................] - ETA: 2:50 - loss: 12.3158 - accuracy: 6.9133e-04
on_train_batch_begin: 1598502292.062316s

3 step training time: 0.682453s

on_train_batch_end: 1598502292.743010s

 8192/50000 [===>..........................] - ETA: 2:05 - loss: 11.2457 - accuracy: 0.0024    
on_train_batch_begin: 1598502292.743316s

4 step training time: 0.681000s

on_train_batch_end: 1598502293.425918s

10240/50000 [=====>........................] - ETA: 1:38 - loss: 10.6121 - accuracy: 0.0055
on_train_batch_begin: 1598502293.426219s

5 step training time: 0.682902s

on_train_batch_end: 1598502294.106792s

12288/50000 [======>.......................] - ETA: 1:19 - loss: 10.1736 - accuracy: 0.0114
on_train_batch_begin: 1598502294.107101s

6 step training time: 0.680883s

on_train_batch_end: 1598502294.794287s

14336/50000 [=======>......................] - ETA: 1:06 - loss: 9.8472 - accuracy: 0.0173 
on_train_batch_begin: 1598502294.794597s

7 step training time: 0.687496s

on_train_batch_end: 1598502295.476615s

16384/50000 [========>.....................] - ETA: 56s - loss: 9.5962 - accuracy: 0.0228 
on_train_batch_begin: 1598502295.476920s

8 step training time: 0.682323s

on_train_batch_end: 1598502296.165054s

18432/50000 [==========>...................] - ETA: 48s - loss: 9.3840 - accuracy: 0.0283
on_train_batch_begin: 1598502296.165362s

9 step training time: 0.688442s

on_train_batch_end: 1598502296.846580s

20480/50000 [===========>..................] - ETA: 41s - loss: 9.2133 - accuracy: 0.0325
on_train_batch_begin: 1598502296.846884s

10 step training time: 0.681522s

on_train_batch_end: 1598502297.537713s

22528/50000 [============>.................] - ETA: 35s - loss: 9.0565 - accuracy: 0.0360
on_train_batch_begin: 1598502297.538021s

11 step training time: 0.691137s

on_train_batch_end: 1598502298.219395s

24576/50000 [=============>................] - ETA: 31s - loss: 8.9220 - accuracy: 0.0395
on_train_batch_begin: 1598502298.219701s

12 step training time: 0.681681s

on_train_batch_end: 1598502298.902879s

26624/50000 [==============>...............] - ETA: 27s - loss: 8.8159 - accuracy: 0.0426
on_train_batch_begin: 1598502298.903185s

13 step training time: 0.683484s

on_train_batch_end: 1598502299.590784s

28672/50000 [================>.............] - ETA: 23s - loss: 8.7145 - accuracy: 0.0454
on_train_batch_begin: 1598502299.591088s

14 step training time: 0.687903s

on_train_batch_end: 1598502300.284621s

30720/50000 [=================>............] - ETA: 20s - loss: 8.6168 - accuracy: 0.0478
on_train_batch_begin: 1598502300.284918s

15 step training time: 0.693830s

on_train_batch_end: 1598502300.974657s

32768/50000 [==================>...........] - ETA: 17s - loss: 8.5315 - accuracy: 0.0494
on_train_batch_begin: 1598502300.974942s

16 step training time: 0.690024s

on_train_batch_end: 1598502301.665910s

34816/50000 [===================>..........] - ETA: 14s - loss: 8.4460 - accuracy: 0.0512
on_train_batch_begin: 1598502301.666196s

17 step training time: 0.691254s

on_train_batch_end: 1598502302.361697s

36864/50000 [=====================>........] - ETA: 12s - loss: 8.3664 - accuracy: 0.0529
on_train_batch_begin: 1598502302.362019s

18 step training time: 0.695823s

on_train_batch_end: 1598502303.047441s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.2908 - accuracy: 0.0543 
on_train_batch_begin: 1598502303.047763s

19 step training time: 0.685744s

on_train_batch_end: 1598502303.740813s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.2243 - accuracy: 0.0556
on_train_batch_begin: 1598502303.741094s

20 step training time: 0.693331s

on_train_batch_end: 1598502304.430533s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.1556 - accuracy: 0.0570
on_train_batch_begin: 1598502304.430820s

21 step training time: 0.689727s

on_train_batch_end: 1598502305.120562s

45056/50000 [==========================>...] - ETA: 4s - loss: 8.0943 - accuracy: 0.0579
on_train_batch_begin: 1598502305.120849s

22 step training time: 0.690029s

on_train_batch_end: 1598502305.815833s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.0381 - accuracy: 0.0588
on_train_batch_begin: 1598502305.816108s

23 step training time: 0.695258s

on_train_batch_end: 1598502306.505808s

49152/50000 [============================>.] - ETA: 0s - loss: 7.9816 - accuracy: 0.0596
on_train_batch_begin: 1598502306.506089s

24 step training time: 0.689982s

on_train_batch_end: 1598502312.861377s

on_test_batch_begin: 1598502313.043503s

25 step training time: 6.537413s

on_epoch_end: 1598502318.390983s

Validation time: 5.347465s

Real time: 1598502318.390983s

Epoch time: 50.25551438331604s

50000/50000 [==============================] - 50s 1ms/sample - loss: 7.9596 - accuracy: 0.0597 - val_loss: 1304.9491 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598502318.391177s

Real time: 1598502318.3911817
Epoch 2/5

on_train_batch_begin: 1598502318.394447s

on_train_batch_end: 1598502319.107986s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.5456 - accuracy: 0.0747
on_train_batch_begin: 1598502319.108279s

1 step training time: 0.713832s

on_train_batch_end: 1598502319.815460s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.5513 - accuracy: 0.0751
on_train_batch_begin: 1598502319.815742s

2 step training time: 0.707462s

on_train_batch_end: 1598502320.526127s

 6144/50000 [==>...........................] - ETA: 15s - loss: 6.5182 - accuracy: 0.0744
on_train_batch_begin: 1598502320.526408s

3 step training time: 0.710666s

on_train_batch_end: 1598502321.235323s

 8192/50000 [===>..........................] - ETA: 14s - loss: 6.4896 - accuracy: 0.0752
on_train_batch_begin: 1598502321.235601s

4 step training time: 0.709193s

on_train_batch_end: 1598502321.944778s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.4734 - accuracy: 0.0730
on_train_batch_begin: 1598502321.945057s

5 step training time: 0.709456s

on_train_batch_end: 1598502322.632375s

12288/50000 [======>.......................] - ETA: 13s - loss: 6.4563 - accuracy: 0.0716
on_train_batch_begin: 1598502322.632683s

6 step training time: 0.687626s

on_train_batch_end: 1598502323.343563s

14336/50000 [=======>......................] - ETA: 12s - loss: 6.4383 - accuracy: 0.0715
on_train_batch_begin: 1598502323.343847s

7 step training time: 0.711164s

on_train_batch_end: 1598502324.055924s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.4283 - accuracy: 0.0709
on_train_batch_begin: 1598502324.056222s

8 step training time: 0.712374s

on_train_batch_end: 1598502324.763374s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.3950 - accuracy: 0.0708
on_train_batch_begin: 1598502324.763664s

9 step training time: 0.707442s

on_train_batch_end: 1598502325.476635s

20480/50000 [===========>..................] - ETA: 10s - loss: 6.3523 - accuracy: 0.0710
on_train_batch_begin: 1598502325.476921s

10 step training time: 0.713257s

on_train_batch_end: 1598502326.188209s

22528/50000 [============>.................] - ETA: 9s - loss: 6.3183 - accuracy: 0.0701 
on_train_batch_begin: 1598502326.188530s

11 step training time: 0.711609s

on_train_batch_end: 1598502326.900643s

24576/50000 [=============>................] - ETA: 8s - loss: 6.2824 - accuracy: 0.0697
on_train_batch_begin: 1598502326.900926s

12 step training time: 0.712396s

on_train_batch_end: 1598502327.611744s

26624/50000 [==============>...............] - ETA: 8s - loss: 6.2386 - accuracy: 0.0689
on_train_batch_begin: 1598502327.612028s

13 step training time: 0.711102s

on_train_batch_end: 1598502328.327437s

28672/50000 [================>.............] - ETA: 7s - loss: 6.2002 - accuracy: 0.0680
on_train_batch_begin: 1598502328.327724s

14 step training time: 0.715696s

on_train_batch_end: 1598502329.044203s

30720/50000 [=================>............] - ETA: 6s - loss: 6.1621 - accuracy: 0.0666
on_train_batch_begin: 1598502329.044508s

15 step training time: 0.716784s

on_train_batch_end: 1598502329.759885s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.1250 - accuracy: 0.0655
on_train_batch_begin: 1598502329.760174s

16 step training time: 0.715667s

on_train_batch_end: 1598502330.469987s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.0804 - accuracy: 0.0645
on_train_batch_begin: 1598502330.470273s

17 step training time: 0.710099s

on_train_batch_end: 1598502331.194256s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.0372 - accuracy: 0.0637
on_train_batch_begin: 1598502331.194544s

18 step training time: 0.724271s

on_train_batch_end: 1598502331.911491s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.9939 - accuracy: 0.0632
on_train_batch_begin: 1598502331.911774s

19 step training time: 0.717230s

on_train_batch_end: 1598502332.620586s

40960/50000 [=======================>......] - ETA: 3s - loss: 5.9525 - accuracy: 0.0628
on_train_batch_begin: 1598502332.620871s

20 step training time: 0.709097s

on_train_batch_end: 1598502333.337330s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.9027 - accuracy: 0.0624
on_train_batch_begin: 1598502333.337614s

21 step training time: 0.716743s

on_train_batch_end: 1598502334.059038s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.8540 - accuracy: 0.0623
on_train_batch_begin: 1598502334.059340s

22 step training time: 0.721726s

on_train_batch_end: 1598502334.776824s

47104/50000 [===========================>..] - ETA: 1s - loss: 5.8072 - accuracy: 0.0622
on_train_batch_begin: 1598502334.777104s

23 step training time: 0.717764s

on_train_batch_end: 1598502335.493922s

49152/50000 [============================>.] - ETA: 0s - loss: 5.7524 - accuracy: 0.0622
on_train_batch_begin: 1598502335.494206s

24 step training time: 0.717102s

on_train_batch_end: 1598502335.795730s

on_test_batch_begin: 1598502335.857205s

25 step training time: 0.362999s

on_epoch_end: 1598502336.749327s

Validation time: 0.892108s

Real time: 1598502336.749327s

Epoch time: 18.358160257339478s

50000/50000 [==============================] - 18s 367us/sample - loss: 5.7325 - accuracy: 0.0622 - val_loss: 73.4220 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598502336.749509s

Real time: 1598502336.749514
Epoch 3/5

on_train_batch_begin: 1598502336.752768s

on_train_batch_end: 1598502337.461507s

 2048/50000 [>.............................] - ETA: 16s - loss: 4.3509 - accuracy: 0.0665
on_train_batch_begin: 1598502337.461778s

1 step training time: 0.709010s

on_train_batch_end: 1598502338.181187s

 4096/50000 [=>............................] - ETA: 16s - loss: 4.3801 - accuracy: 0.0662
on_train_batch_begin: 1598502338.181464s

2 step training time: 0.719685s

on_train_batch_end: 1598502338.903839s

 6144/50000 [==>...........................] - ETA: 15s - loss: 4.3540 - accuracy: 0.0668
on_train_batch_begin: 1598502338.904112s

3 step training time: 0.722648s

on_train_batch_end: 1598502339.629689s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.3212 - accuracy: 0.0670
on_train_batch_begin: 1598502339.629972s

4 step training time: 0.725861s

on_train_batch_end: 1598502340.346876s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.2804 - accuracy: 0.0674
on_train_batch_begin: 1598502340.347160s

5 step training time: 0.717188s

on_train_batch_end: 1598502341.070986s

12288/50000 [======>.......................] - ETA: 13s - loss: 4.2177 - accuracy: 0.0682
on_train_batch_begin: 1598502341.071268s

6 step training time: 0.724108s

on_train_batch_end: 1598502341.798156s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.1520 - accuracy: 0.0689
on_train_batch_begin: 1598502341.798446s

7 step training time: 0.727178s

on_train_batch_end: 1598502342.528047s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.0862 - accuracy: 0.0695
on_train_batch_begin: 1598502342.528341s

8 step training time: 0.729895s

on_train_batch_end: 1598502343.253858s

18432/50000 [==========>...................] - ETA: 11s - loss: 4.0397 - accuracy: 0.0703
on_train_batch_begin: 1598502343.254142s

9 step training time: 0.725801s

on_train_batch_end: 1598502343.975522s

20480/50000 [===========>..................] - ETA: 10s - loss: 3.9893 - accuracy: 0.0708
on_train_batch_begin: 1598502343.975803s

10 step training time: 0.721661s

on_train_batch_end: 1598502344.703179s

22528/50000 [============>.................] - ETA: 9s - loss: 3.9318 - accuracy: 0.0715 
on_train_batch_begin: 1598502344.703461s

11 step training time: 0.727658s

on_train_batch_end: 1598502345.434690s

24576/50000 [=============>................] - ETA: 8s - loss: 3.8969 - accuracy: 0.0719
on_train_batch_begin: 1598502345.434977s

12 step training time: 0.731515s

on_train_batch_end: 1598502346.164123s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.8528 - accuracy: 0.0725
on_train_batch_begin: 1598502346.164410s

13 step training time: 0.729433s

on_train_batch_end: 1598502346.894148s

28672/50000 [================>.............] - ETA: 7s - loss: 3.8099 - accuracy: 0.0728
on_train_batch_begin: 1598502346.894433s

14 step training time: 0.730023s

on_train_batch_end: 1598502347.622470s

30720/50000 [=================>............] - ETA: 6s - loss: 3.7669 - accuracy: 0.0733
on_train_batch_begin: 1598502347.622754s

15 step training time: 0.728321s

on_train_batch_end: 1598502348.358313s

32768/50000 [==================>...........] - ETA: 6s - loss: 3.7174 - accuracy: 0.0739
on_train_batch_begin: 1598502348.358594s

16 step training time: 0.735840s

on_train_batch_end: 1598502349.086114s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.6809 - accuracy: 0.0744
on_train_batch_begin: 1598502349.086402s

17 step training time: 0.727808s

on_train_batch_end: 1598502349.813420s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.6385 - accuracy: 0.0749
on_train_batch_begin: 1598502349.813706s

18 step training time: 0.727304s

on_train_batch_end: 1598502350.547459s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.5964 - accuracy: 0.0755
on_train_batch_begin: 1598502350.547754s

19 step training time: 0.734048s

on_train_batch_end: 1598502351.285217s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.5589 - accuracy: 0.0759
on_train_batch_begin: 1598502351.285501s

20 step training time: 0.737748s

on_train_batch_end: 1598502352.023451s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.5202 - accuracy: 0.0765
on_train_batch_begin: 1598502352.023741s

21 step training time: 0.738239s

on_train_batch_end: 1598502352.758507s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.4835 - accuracy: 0.0770
on_train_batch_begin: 1598502352.758797s

22 step training time: 0.735057s

on_train_batch_end: 1598502353.496354s

47104/50000 [===========================>..] - ETA: 1s - loss: 3.4410 - accuracy: 0.0776
on_train_batch_begin: 1598502353.496653s

23 step training time: 0.737856s

on_train_batch_end: 1598502354.235835s

49152/50000 [============================>.] - ETA: 0s - loss: 3.4017 - accuracy: 0.0781
on_train_batch_begin: 1598502354.236124s

24 step training time: 0.739471s

on_train_batch_end: 1598502354.542538s

on_test_batch_begin: 1598502354.603657s

25 step training time: 0.367533s

on_epoch_end: 1598502355.516942s

Validation time: 0.913272s

Real time: 1598502355.516942s

Epoch time: 18.767444849014282s

50000/50000 [==============================] - 19s 375us/sample - loss: 3.3836 - accuracy: 0.0782 - val_loss: 7.7343 - val_accuracy: 0.1001

on_epoch_begin: 1598502355.517125s

Real time: 1598502355.5171306
Epoch 4/5

on_train_batch_begin: 1598502355.520457s

on_train_batch_end: 1598502356.253723s

 2048/50000 [>.............................] - ETA: 17s - loss: 2.4293 - accuracy: 0.0928
on_train_batch_begin: 1598502356.254001s

1 step training time: 0.733543s

on_train_batch_end: 1598502356.997909s

 4096/50000 [=>............................] - ETA: 16s - loss: 2.3474 - accuracy: 0.0935
on_train_batch_begin: 1598502356.998212s

2 step training time: 0.744211s

on_train_batch_end: 1598502357.744925s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.3122 - accuracy: 0.0947
on_train_batch_begin: 1598502357.745200s

3 step training time: 0.746988s

on_train_batch_end: 1598502358.488222s

 8192/50000 [===>..........................] - ETA: 15s - loss: 2.2951 - accuracy: 0.0955
on_train_batch_begin: 1598502358.488533s

4 step training time: 0.743333s

on_train_batch_end: 1598502359.236714s

10240/50000 [=====>........................] - ETA: 14s - loss: 2.2434 - accuracy: 0.0961
on_train_batch_begin: 1598502359.236998s

5 step training time: 0.748466s

on_train_batch_end: 1598502359.987732s

12288/50000 [======>.......................] - ETA: 13s - loss: 2.2074 - accuracy: 0.0967
on_train_batch_begin: 1598502359.988022s

6 step training time: 0.751024s

on_train_batch_end: 1598502360.738210s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.1791 - accuracy: 0.0971
on_train_batch_begin: 1598502360.738494s

7 step training time: 0.750473s

on_train_batch_end: 1598502361.489399s

16384/50000 [========>.....................] - ETA: 12s - loss: 2.1613 - accuracy: 0.0974
on_train_batch_begin: 1598502361.489681s

8 step training time: 0.751187s

on_train_batch_end: 1598502362.241341s

18432/50000 [==========>...................] - ETA: 11s - loss: 2.1185 - accuracy: 0.0978
on_train_batch_begin: 1598502362.241634s

9 step training time: 0.751953s

on_train_batch_end: 1598502362.993542s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.0922 - accuracy: 0.0980
on_train_batch_begin: 1598502362.993823s

10 step training time: 0.752189s

on_train_batch_end: 1598502363.740871s

22528/50000 [============>.................] - ETA: 10s - loss: 2.0713 - accuracy: 0.0982
on_train_batch_begin: 1598502363.741155s

11 step training time: 0.747332s

on_train_batch_end: 1598502364.492508s

24576/50000 [=============>................] - ETA: 9s - loss: 2.0485 - accuracy: 0.0983 
on_train_batch_begin: 1598502364.492790s

12 step training time: 0.751635s

on_train_batch_end: 1598502365.245060s

26624/50000 [==============>...............] - ETA: 8s - loss: 2.0258 - accuracy: 0.0984
on_train_batch_begin: 1598502365.245341s

13 step training time: 0.752551s

on_train_batch_end: 1598502365.997529s

28672/50000 [================>.............] - ETA: 7s - loss: 1.9971 - accuracy: 0.0986
on_train_batch_begin: 1598502365.997813s

14 step training time: 0.752472s

on_train_batch_end: 1598502366.753019s

30720/50000 [=================>............] - ETA: 7s - loss: 1.9740 - accuracy: 0.0986
on_train_batch_begin: 1598502366.753298s

15 step training time: 0.755485s

on_train_batch_end: 1598502367.503038s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.9544 - accuracy: 0.0987
on_train_batch_begin: 1598502367.503314s

16 step training time: 0.750016s

on_train_batch_end: 1598502368.256218s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.9339 - accuracy: 0.0988
on_train_batch_begin: 1598502368.256515s

17 step training time: 0.753200s

on_train_batch_end: 1598502369.014952s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.9168 - accuracy: 0.0989
on_train_batch_begin: 1598502369.015231s

18 step training time: 0.758716s

on_train_batch_end: 1598502369.769352s

38912/50000 [======================>.......] - ETA: 4s - loss: 1.9043 - accuracy: 0.0990
on_train_batch_begin: 1598502369.769637s

19 step training time: 0.754406s

on_train_batch_end: 1598502370.529941s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.8856 - accuracy: 0.0990
on_train_batch_begin: 1598502370.530224s

20 step training time: 0.760587s

on_train_batch_end: 1598502371.285870s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.8727 - accuracy: 0.0991
on_train_batch_begin: 1598502371.286152s

21 step training time: 0.755929s

on_train_batch_end: 1598502372.040006s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8624 - accuracy: 0.0991
on_train_batch_begin: 1598502372.040283s

22 step training time: 0.754130s

on_train_batch_end: 1598502372.801318s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.8489 - accuracy: 0.0992
on_train_batch_begin: 1598502372.801606s

23 step training time: 0.761323s

on_train_batch_end: 1598502373.564867s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8334 - accuracy: 0.0992
on_train_batch_begin: 1598502373.565148s

24 step training time: 0.763542s

on_train_batch_end: 1598502373.880114s

on_test_batch_begin: 1598502373.940875s

25 step training time: 0.375727s

on_epoch_end: 1598502374.868377s

Validation time: 0.927489s

Real time: 1598502374.868377s

Epoch time: 19.351263761520386s

50000/50000 [==============================] - 19s 387us/sample - loss: 1.8298 - accuracy: 0.0992 - val_loss: 6.8997 - val_accuracy: 0.0957

on_epoch_begin: 1598502374.868578s

Real time: 1598502374.8685834
Epoch 5/5

on_train_batch_begin: 1598502374.871859s

on_train_batch_end: 1598502375.623416s

 2048/50000 [>.............................] - ETA: 17s - loss: 1.4356 - accuracy: 0.0999
on_train_batch_begin: 1598502375.623697s

1 step training time: 0.751838s

on_train_batch_end: 1598502376.377201s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.3666 - accuracy: 0.1000
on_train_batch_begin: 1598502376.377481s

2 step training time: 0.753784s

on_train_batch_end: 1598502377.135883s

 6144/50000 [==>...........................] - ETA: 16s - loss: 1.3807 - accuracy: 0.1000
on_train_batch_begin: 1598502377.136155s

3 step training time: 0.758674s

on_train_batch_end: 1598502377.897599s

 8192/50000 [===>..........................] - ETA: 15s - loss: 1.3630 - accuracy: 0.1001
on_train_batch_begin: 1598502377.897874s

4 step training time: 0.761719s

on_train_batch_end: 1598502378.652574s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.3592 - accuracy: 0.1001
on_train_batch_begin: 1598502378.652855s

5 step training time: 0.754981s

on_train_batch_end: 1598502379.418106s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.3518 - accuracy: 0.1001
on_train_batch_begin: 1598502379.418423s

6 step training time: 0.765568s

on_train_batch_end: 1598502380.180145s

14336/50000 [=======>......................] - ETA: 13s - loss: 1.3562 - accuracy: 0.1001
on_train_batch_begin: 1598502380.180441s

7 step training time: 0.762019s

on_train_batch_end: 1598502380.950655s

16384/50000 [========>.....................] - ETA: 12s - loss: 1.3421 - accuracy: 0.1001
on_train_batch_begin: 1598502380.950938s

8 step training time: 0.770496s

on_train_batch_end: 1598502381.716927s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.3328 - accuracy: 0.1001
on_train_batch_begin: 1598502381.717206s

9 step training time: 0.766269s

on_train_batch_end: 1598502382.483330s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.3272 - accuracy: 0.1001
on_train_batch_begin: 1598502382.483611s

10 step training time: 0.766404s

on_train_batch_end: 1598502383.257369s

22528/50000 [============>.................] - ETA: 10s - loss: 1.3221 - accuracy: 0.1001
on_train_batch_begin: 1598502383.257652s

11 step training time: 0.774041s

on_train_batch_end: 1598502384.017912s

24576/50000 [=============>................] - ETA: 9s - loss: 1.3156 - accuracy: 0.1001 
on_train_batch_begin: 1598502384.018198s

12 step training time: 0.760546s

on_train_batch_end: 1598502384.776942s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.3087 - accuracy: 0.1001
on_train_batch_begin: 1598502384.777238s

13 step training time: 0.759040s

on_train_batch_end: 1598502385.536646s

28672/50000 [================>.............] - ETA: 7s - loss: 1.2960 - accuracy: 0.1001
on_train_batch_begin: 1598502385.536928s

14 step training time: 0.759690s

on_train_batch_end: 1598502386.297475s

30720/50000 [=================>............] - ETA: 7s - loss: 1.2879 - accuracy: 0.1001
on_train_batch_begin: 1598502386.297756s

15 step training time: 0.760828s

on_train_batch_end: 1598502387.059740s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.2845 - accuracy: 0.1002
on_train_batch_begin: 1598502387.060014s

16 step training time: 0.762258s

on_train_batch_end: 1598502387.822194s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.2878 - accuracy: 0.1001
on_train_batch_begin: 1598502387.822471s

17 step training time: 0.762457s

on_train_batch_end: 1598502388.577393s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.2857 - accuracy: 0.1001
on_train_batch_begin: 1598502388.577675s

18 step training time: 0.755204s

on_train_batch_end: 1598502389.339347s

38912/50000 [======================>.......] - ETA: 4s - loss: 1.2797 - accuracy: 0.1001
on_train_batch_begin: 1598502389.339641s

19 step training time: 0.761966s

on_train_batch_end: 1598502390.099456s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.2742 - accuracy: 0.1001
on_train_batch_begin: 1598502390.099742s

20 step training time: 0.760101s

on_train_batch_end: 1598502390.863516s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.2698 - accuracy: 0.1001
on_train_batch_begin: 1598502390.863800s

21 step training time: 0.764058s

on_train_batch_end: 1598502391.628167s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.2670 - accuracy: 0.1001
on_train_batch_begin: 1598502391.628497s

22 step training time: 0.764697s

on_train_batch_end: 1598502392.388570s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.2666 - accuracy: 0.1001
on_train_batch_begin: 1598502392.388840s

23 step training time: 0.760343s

on_train_batch_end: 1598502393.151973s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2620 - accuracy: 0.1001
on_train_batch_begin: 1598502393.152251s

24 step training time: 0.763410s

on_train_batch_end: 1598502393.470641s

on_test_batch_begin: 1598502393.531670s

25 step training time: 0.379419s

on_epoch_end: 1598502394.473189s

Validation time: 0.941505s

Real time: 1598502394.473189s

Epoch time: 19.604620695114136s

50000/50000 [==============================] - 20s 392us/sample - loss: 1.2602 - accuracy: 0.1001 - val_loss: 6.8121 - val_accuracy: 0.1001
Tempo do fit: 129.7527585029602