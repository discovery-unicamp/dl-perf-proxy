wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:45
   106496/170498071 [..............................] - ETA: 1:55
   614400/170498071 [..............................] - ETA: 34s 
  2056192/170498071 [..............................] - ETA: 14s
  5152768/170498071 [..............................] - ETA: 7s 
  7905280/170498071 [>.............................] - ETA: 5s
 11182080/170498071 [>.............................] - ETA: 4s
 14499840/170498071 [=>............................] - ETA: 4s
 17563648/170498071 [==>...........................] - ETA: 3s
 20684800/170498071 [==>...........................] - ETA: 3s
 23977984/170498071 [===>..........................] - ETA: 3s
 27189248/170498071 [===>..........................] - ETA: 3s
 30334976/170498071 [====>.........................] - ETA: 2s
 33529856/170498071 [====>.........................] - ETA: 2s
 36757504/170498071 [=====>........................] - ETA: 2s
 39952384/170498071 [======>.......................] - ETA: 2s
 43171840/170498071 [======>.......................] - ETA: 2s
 46391296/170498071 [=======>......................] - ETA: 2s
 49586176/170498071 [=======>......................] - ETA: 2s
 52740096/170498071 [========>.....................] - ETA: 2s
 56025088/170498071 [========>.....................] - ETA: 2s
 59219968/170498071 [=========>....................] - ETA: 2s
 62373888/170498071 [=========>....................] - ETA: 1s
 65593344/170498071 [==========>...................] - ETA: 1s
 68853760/170498071 [===========>..................] - ETA: 1s
 71884800/170498071 [===========>..................] - ETA: 1s
 74768384/170498071 [============>.................] - ETA: 1s
 78061568/170498071 [============>.................] - ETA: 1s
 81272832/170498071 [=============>................] - ETA: 1s
 84508672/170498071 [=============>................] - ETA: 1s
 87588864/170498071 [==============>...............] - ETA: 1s
 90841088/170498071 [==============>...............] - ETA: 1s
 94076928/170498071 [===============>..............] - ETA: 1s
 97017856/170498071 [================>.............] - ETA: 1s
100245504/170498071 [================>.............] - ETA: 1s
103505920/170498071 [=================>............] - ETA: 1s
106848256/170498071 [=================>............] - ETA: 1s
109862912/170498071 [==================>...........] - ETA: 1s
113147904/170498071 [==================>...........] - ETA: 0s
116350976/170498071 [===================>..........] - ETA: 0s
119447552/170498071 [====================>.........] - ETA: 0s
122691584/170498071 [====================>.........] - ETA: 0s
125935616/170498071 [=====================>........] - ETA: 0s
129097728/170498071 [=====================>........] - ETA: 0s
132194304/170498071 [======================>.......] - ETA: 0s
135405568/170498071 [======================>.......] - ETA: 0s
138665984/170498071 [=======================>......] - ETA: 0s
141762560/170498071 [=======================>......] - ETA: 0s
144990208/170498071 [========================>.....] - ETA: 0s
148234240/170498071 [=========================>....] - ETA: 0s
149954560/170498071 [=========================>....] - ETA: 0s
152707072/170498071 [=========================>....] - ETA: 0s
155926528/170498071 [==========================>...] - ETA: 0s
159178752/170498071 [===========================>..] - ETA: 0s
162242560/170498071 [===========================>..] - ETA: 0s
165470208/170498071 [============================>.] - ETA: 0s
168689664/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 4464640/94765736 [>.............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 1s
12926976/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
20881408/94765736 [=====>........................] - ETA: 1s
24854528/94765736 [======>.......................] - ETA: 1s
29409280/94765736 [========>.....................] - ETA: 1s
35168256/94765736 [==========>...................] - ETA: 0s
40845312/94765736 [===========>..................] - ETA: 0s
44343296/94765736 [=============>................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
50954240/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
59023360/94765736 [=================>............] - ETA: 0s
62472192/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
71573504/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
79593472/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
90120192/94765736 [===========================>..] - ETA: 0s
94674944/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 26.862095594406128
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1599082013.345061s

Real time: 1599082013.3450835
Epoch 1/5

on_train_batch_begin: 1599082014.560468s

on_train_batch_end: 1599082153.331454s

 2048/50000 [>.............................] - ETA: 54:37 - loss: 17.4402 - accuracy: 1.7548e-04
on_train_batch_begin: 1599082153.332214s

1 step training time: 138.771746s

on_train_batch_end: 1599082153.613261s

 4096/50000 [=>............................] - ETA: 26:11 - loss: 14.5639 - accuracy: 4.3201e-04
on_train_batch_begin: 1599082153.613665s

2 step training time: 0.281451s

on_train_batch_end: 1599082153.893568s

 6144/50000 [==>...........................] - ETA: 16:43 - loss: 12.6756 - accuracy: 8.3478e-04
on_train_batch_begin: 1599082153.893963s

3 step training time: 0.280298s

on_train_batch_end: 1599082154.174387s

 8192/50000 [===>..........................] - ETA: 11:58 - loss: 11.5733 - accuracy: 0.0022    
on_train_batch_begin: 1599082154.174781s

4 step training time: 0.280818s

on_train_batch_end: 1599082154.456532s

10240/50000 [=====>........................] - ETA: 9:07 - loss: 10.8762 - accuracy: 0.0046 
on_train_batch_begin: 1599082154.456922s

5 step training time: 0.282142s

on_train_batch_end: 1599082154.816968s

12288/50000 [======>.......................] - ETA: 7:14 - loss: 10.3685 - accuracy: 0.0086
on_train_batch_begin: 1599082154.817351s

6 step training time: 0.360429s

on_train_batch_end: 1599082155.176280s

14336/50000 [=======>......................] - ETA: 5:52 - loss: 9.9739 - accuracy: 0.0132 
on_train_batch_begin: 1599082155.176675s

7 step training time: 0.359324s

on_train_batch_end: 1599082155.533196s

16384/50000 [========>.....................] - ETA: 4:51 - loss: 9.6719 - accuracy: 0.0169
on_train_batch_begin: 1599082155.533581s

8 step training time: 0.356906s

on_train_batch_end: 1599082155.889680s

18432/50000 [==========>...................] - ETA: 4:04 - loss: 9.4345 - accuracy: 0.0209
on_train_batch_begin: 1599082155.890060s

9 step training time: 0.356479s

on_train_batch_end: 1599082156.251132s

20480/50000 [===========>..................] - ETA: 3:25 - loss: 9.2177 - accuracy: 0.0252
on_train_batch_begin: 1599082156.251548s

10 step training time: 0.361487s

on_train_batch_end: 1599082156.609856s

22528/50000 [============>.................] - ETA: 2:54 - loss: 9.0414 - accuracy: 0.0286
on_train_batch_begin: 1599082156.610244s

11 step training time: 0.358696s

on_train_batch_end: 1599082156.975027s

24576/50000 [=============>................] - ETA: 2:28 - loss: 8.8817 - accuracy: 0.0320
on_train_batch_begin: 1599082156.975439s

12 step training time: 0.365196s

on_train_batch_end: 1599082157.333642s

26624/50000 [==============>...............] - ETA: 2:06 - loss: 8.7364 - accuracy: 0.0348
on_train_batch_begin: 1599082157.334034s

13 step training time: 0.358595s

on_train_batch_end: 1599082157.692189s

28672/50000 [================>.............] - ETA: 1:47 - loss: 8.5957 - accuracy: 0.0377
on_train_batch_begin: 1599082157.692574s

14 step training time: 0.358540s

on_train_batch_end: 1599082158.052402s

30720/50000 [=================>............] - ETA: 1:30 - loss: 8.4669 - accuracy: 0.0398
on_train_batch_begin: 1599082158.052793s

15 step training time: 0.360219s

on_train_batch_end: 1599082158.408843s

32768/50000 [==================>...........] - ETA: 1:16 - loss: 8.3485 - accuracy: 0.0420
on_train_batch_begin: 1599082158.409231s

16 step training time: 0.356438s

on_train_batch_end: 1599082158.759177s

34816/50000 [===================>..........] - ETA: 1:03 - loss: 8.2393 - accuracy: 0.0438
on_train_batch_begin: 1599082158.759597s

17 step training time: 0.350366s

on_train_batch_end: 1599082159.115967s

36864/50000 [=====================>........] - ETA: 51s - loss: 8.1331 - accuracy: 0.0455 
on_train_batch_begin: 1599082159.116359s

18 step training time: 0.356762s

on_train_batch_end: 1599082159.473136s

38912/50000 [======================>.......] - ETA: 41s - loss: 8.0399 - accuracy: 0.0471
on_train_batch_begin: 1599082159.473528s

19 step training time: 0.357169s

on_train_batch_end: 1599082159.829209s

40960/50000 [=======================>......] - ETA: 32s - loss: 7.9508 - accuracy: 0.0482
on_train_batch_begin: 1599082159.829590s

20 step training time: 0.356062s

on_train_batch_end: 1599082160.192358s

43008/50000 [========================>.....] - ETA: 23s - loss: 7.8628 - accuracy: 0.0494
on_train_batch_begin: 1599082160.192745s

21 step training time: 0.363155s

on_train_batch_end: 1599082160.548455s

45056/50000 [==========================>...] - ETA: 16s - loss: 7.7764 - accuracy: 0.0503
on_train_batch_begin: 1599082160.548840s

22 step training time: 0.356095s

on_train_batch_end: 1599082160.907220s

47104/50000 [===========================>..] - ETA: 9s - loss: 7.7004 - accuracy: 0.0512 
on_train_batch_begin: 1599082160.907636s

23 step training time: 0.358796s

on_train_batch_end: 1599082161.264951s

49152/50000 [============================>.] - ETA: 2s - loss: 7.6212 - accuracy: 0.0520
on_train_batch_begin: 1599082161.265342s

24 step training time: 0.357706s

on_train_batch_end: 1599082168.618595s

on_test_batch_begin: 1599082168.996939s

25 step training time: 7.731597s

on_epoch_end: 1599082186.214698s

Validation time: 17.217740s

Real time: 1599082186.214698s

Epoch time: 172.86963963508606s

50000/50000 [==============================] - 173s 3ms/sample - loss: 7.5904 - accuracy: 0.0521 - val_loss: 49.4109 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599082186.214972s

Real time: 1599082186.2149844
Epoch 2/5

on_train_batch_begin: 1599082186.222638s

on_train_batch_end: 1599082186.505407s

 2048/50000 [>.............................] - ETA: 6s - loss: 5.5419 - accuracy: 0.0716
on_train_batch_begin: 1599082186.505806s

1 step training time: 0.283169s

on_train_batch_end: 1599082186.861796s

 4096/50000 [=>............................] - ETA: 7s - loss: 5.4946 - accuracy: 0.0707
on_train_batch_begin: 1599082186.862179s

2 step training time: 0.356372s

on_train_batch_end: 1599082187.217442s

 6144/50000 [==>...........................] - ETA: 7s - loss: 5.4321 - accuracy: 0.0697
on_train_batch_begin: 1599082187.217817s

3 step training time: 0.355639s

on_train_batch_end: 1599082187.572150s

 8192/50000 [===>..........................] - ETA: 6s - loss: 5.3964 - accuracy: 0.0684
on_train_batch_begin: 1599082187.572522s

4 step training time: 0.354704s

on_train_batch_end: 1599082187.923971s

10240/50000 [=====>........................] - ETA: 6s - loss: 5.3414 - accuracy: 0.0683
on_train_batch_begin: 1599082187.924343s

5 step training time: 0.351821s

on_train_batch_end: 1599082188.277676s

12288/50000 [======>.......................] - ETA: 6s - loss: 5.2829 - accuracy: 0.0678
on_train_batch_begin: 1599082188.278049s

6 step training time: 0.353707s

on_train_batch_end: 1599082188.640669s

14336/50000 [=======>......................] - ETA: 6s - loss: 5.2191 - accuracy: 0.0679
on_train_batch_begin: 1599082188.641042s

7 step training time: 0.362992s

on_train_batch_end: 1599082189.003216s

16384/50000 [========>.....................] - ETA: 5s - loss: 5.1563 - accuracy: 0.0681
on_train_batch_begin: 1599082189.003632s

8 step training time: 0.362591s

on_train_batch_end: 1599082189.353733s

18432/50000 [==========>...................] - ETA: 5s - loss: 5.1053 - accuracy: 0.0682
on_train_batch_begin: 1599082189.354125s

9 step training time: 0.350493s

on_train_batch_end: 1599082189.712375s

20480/50000 [===========>..................] - ETA: 5s - loss: 5.0424 - accuracy: 0.0686
on_train_batch_begin: 1599082189.712763s

10 step training time: 0.358638s

on_train_batch_end: 1599082190.065521s

22528/50000 [============>.................] - ETA: 4s - loss: 4.9716 - accuracy: 0.0693
on_train_batch_begin: 1599082190.065918s

11 step training time: 0.353155s

on_train_batch_end: 1599082190.422647s

24576/50000 [=============>................] - ETA: 4s - loss: 4.9077 - accuracy: 0.0697
on_train_batch_begin: 1599082190.423035s

12 step training time: 0.357116s

on_train_batch_end: 1599082190.786067s

26624/50000 [==============>...............] - ETA: 4s - loss: 4.8612 - accuracy: 0.0701
on_train_batch_begin: 1599082190.786460s

13 step training time: 0.363425s

on_train_batch_end: 1599082191.144077s

28672/50000 [================>.............] - ETA: 3s - loss: 4.8016 - accuracy: 0.0706
on_train_batch_begin: 1599082191.144469s

14 step training time: 0.358009s

on_train_batch_end: 1599082191.504450s

30720/50000 [=================>............] - ETA: 3s - loss: 4.7550 - accuracy: 0.0711
on_train_batch_begin: 1599082191.504842s

15 step training time: 0.360374s

on_train_batch_end: 1599082191.869025s

32768/50000 [==================>...........] - ETA: 2s - loss: 4.7086 - accuracy: 0.0715
on_train_batch_begin: 1599082191.869415s

16 step training time: 0.364572s

on_train_batch_end: 1599082192.231300s

34816/50000 [===================>..........] - ETA: 2s - loss: 4.6574 - accuracy: 0.0721
on_train_batch_begin: 1599082192.231722s

17 step training time: 0.362308s

on_train_batch_end: 1599082192.595412s

36864/50000 [=====================>........] - ETA: 2s - loss: 4.6092 - accuracy: 0.0727
on_train_batch_begin: 1599082192.595806s

18 step training time: 0.364084s

on_train_batch_end: 1599082192.952889s

38912/50000 [======================>.......] - ETA: 1s - loss: 4.5657 - accuracy: 0.0733
on_train_batch_begin: 1599082192.953274s

19 step training time: 0.357468s

on_train_batch_end: 1599082193.315820s

40960/50000 [=======================>......] - ETA: 1s - loss: 4.5177 - accuracy: 0.0740
on_train_batch_begin: 1599082193.316202s

20 step training time: 0.362928s

on_train_batch_end: 1599082193.677002s

43008/50000 [========================>.....] - ETA: 1s - loss: 4.4670 - accuracy: 0.0748
on_train_batch_begin: 1599082193.677382s

21 step training time: 0.361180s

on_train_batch_end: 1599082194.039082s

45056/50000 [==========================>...] - ETA: 0s - loss: 4.4204 - accuracy: 0.0754
on_train_batch_begin: 1599082194.039489s

22 step training time: 0.362107s

on_train_batch_end: 1599082194.404976s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.3731 - accuracy: 0.0762
on_train_batch_begin: 1599082194.405406s

23 step training time: 0.365917s

on_train_batch_end: 1599082194.768114s

49152/50000 [============================>.] - ETA: 0s - loss: 4.3304 - accuracy: 0.0769
on_train_batch_begin: 1599082194.768490s

24 step training time: 0.363084s

on_train_batch_end: 1599082195.008717s

on_test_batch_begin: 1599082195.102895s

25 step training time: 0.334405s

on_epoch_end: 1599082195.511013s

Validation time: 0.408098s

Real time: 1599082195.511013s

Epoch time: 9.296049118041992s

50000/50000 [==============================] - 9s 186us/sample - loss: 4.3110 - accuracy: 0.0771 - val_loss: 16.2984 - val_accuracy: 0.0998

on_epoch_begin: 1599082195.511258s

Real time: 1599082195.5112672
Epoch 3/5

on_train_batch_begin: 1599082195.519100s

on_train_batch_end: 1599082195.884960s

 2048/50000 [>.............................] - ETA: 8s - loss: 2.9086 - accuracy: 0.0944
on_train_batch_begin: 1599082195.885352s

1 step training time: 0.366251s

on_train_batch_end: 1599082196.245972s

 4096/50000 [=>............................] - ETA: 8s - loss: 2.9545 - accuracy: 0.0953
on_train_batch_begin: 1599082196.246357s

2 step training time: 0.361006s

on_train_batch_end: 1599082196.603067s

 6144/50000 [==>...........................] - ETA: 7s - loss: 2.9139 - accuracy: 0.0958
on_train_batch_begin: 1599082196.603480s

3 step training time: 0.357123s

on_train_batch_end: 1599082196.960352s

 8192/50000 [===>..........................] - ETA: 7s - loss: 2.8732 - accuracy: 0.0963
on_train_batch_begin: 1599082196.960736s

4 step training time: 0.357256s

on_train_batch_end: 1599082197.313618s

10240/50000 [=====>........................] - ETA: 6s - loss: 2.8510 - accuracy: 0.0967
on_train_batch_begin: 1599082197.314001s

5 step training time: 0.353265s

on_train_batch_end: 1599082197.675964s

12288/50000 [======>.......................] - ETA: 6s - loss: 2.8279 - accuracy: 0.0969
on_train_batch_begin: 1599082197.676345s

6 step training time: 0.362344s

on_train_batch_end: 1599082198.035189s

14336/50000 [=======>......................] - ETA: 6s - loss: 2.8019 - accuracy: 0.0973
on_train_batch_begin: 1599082198.035619s

7 step training time: 0.359275s

on_train_batch_end: 1599082198.399756s

16384/50000 [========>.....................] - ETA: 5s - loss: 2.7574 - accuracy: 0.0977
on_train_batch_begin: 1599082198.400140s

8 step training time: 0.364521s

on_train_batch_end: 1599082198.766198s

18432/50000 [==========>...................] - ETA: 5s - loss: 2.7321 - accuracy: 0.0979
on_train_batch_begin: 1599082198.766583s

9 step training time: 0.366443s

on_train_batch_end: 1599082199.126993s

20480/50000 [===========>..................] - ETA: 5s - loss: 2.6946 - accuracy: 0.0982
on_train_batch_begin: 1599082199.127413s

10 step training time: 0.360829s

on_train_batch_end: 1599082199.489342s

22528/50000 [============>.................] - ETA: 4s - loss: 2.6702 - accuracy: 0.0983
on_train_batch_begin: 1599082199.489729s

11 step training time: 0.362316s

on_train_batch_end: 1599082199.847909s

24576/50000 [=============>................] - ETA: 4s - loss: 2.6445 - accuracy: 0.0985
on_train_batch_begin: 1599082199.848290s

12 step training time: 0.358561s

on_train_batch_end: 1599082200.213543s

26624/50000 [==============>...............] - ETA: 4s - loss: 2.6179 - accuracy: 0.0986
on_train_batch_begin: 1599082200.213926s

13 step training time: 0.365636s

on_train_batch_end: 1599082200.573823s

28672/50000 [================>.............] - ETA: 3s - loss: 2.5976 - accuracy: 0.0987
on_train_batch_begin: 1599082200.574209s

14 step training time: 0.360283s

on_train_batch_end: 1599082200.938281s

30720/50000 [=================>............] - ETA: 3s - loss: 2.5657 - accuracy: 0.0988
on_train_batch_begin: 1599082200.938668s

15 step training time: 0.364459s

on_train_batch_end: 1599082201.301338s

32768/50000 [==================>...........] - ETA: 3s - loss: 2.5415 - accuracy: 0.0989
on_train_batch_begin: 1599082201.301726s

16 step training time: 0.363058s

on_train_batch_end: 1599082201.665195s

34816/50000 [===================>..........] - ETA: 2s - loss: 2.5163 - accuracy: 0.0991
on_train_batch_begin: 1599082201.665590s

17 step training time: 0.363865s

on_train_batch_end: 1599082202.026889s

36864/50000 [=====================>........] - ETA: 2s - loss: 2.4921 - accuracy: 0.0991
on_train_batch_begin: 1599082202.027273s

18 step training time: 0.361683s

on_train_batch_end: 1599082202.385362s

38912/50000 [======================>.......] - ETA: 1s - loss: 2.4683 - accuracy: 0.0992
on_train_batch_begin: 1599082202.385756s

19 step training time: 0.358483s

on_train_batch_end: 1599082202.749096s

40960/50000 [=======================>......] - ETA: 1s - loss: 2.4419 - accuracy: 0.0994
on_train_batch_begin: 1599082202.749484s

20 step training time: 0.363729s

on_train_batch_end: 1599082203.110431s

43008/50000 [========================>.....] - ETA: 1s - loss: 2.4265 - accuracy: 0.0994
on_train_batch_begin: 1599082203.110816s

21 step training time: 0.361332s

on_train_batch_end: 1599082203.475037s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.4084 - accuracy: 0.0995
on_train_batch_begin: 1599082203.475444s

22 step training time: 0.364628s

on_train_batch_end: 1599082203.838425s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.3888 - accuracy: 0.0995
on_train_batch_begin: 1599082203.838813s

23 step training time: 0.363369s

on_train_batch_end: 1599082204.195679s

49152/50000 [============================>.] - ETA: 0s - loss: 2.3682 - accuracy: 0.0996
on_train_batch_begin: 1599082204.196064s

24 step training time: 0.357251s

on_train_batch_end: 1599082204.397478s

on_test_batch_begin: 1599082204.488205s

25 step training time: 0.292141s

on_epoch_end: 1599082204.898203s

Validation time: 0.409979s

Real time: 1599082204.898203s

Epoch time: 9.38695740699768s

50000/50000 [==============================] - 9s 188us/sample - loss: 2.3603 - accuracy: 0.0996 - val_loss: 8.7734 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599082204.898458s

Real time: 1599082204.8984673
Epoch 4/5

on_train_batch_begin: 1599082204.906014s

on_train_batch_end: 1599082205.259855s

 2048/50000 [>.............................] - ETA: 8s - loss: 1.8626 - accuracy: 0.1015
on_train_batch_begin: 1599082205.260233s

1 step training time: 0.354220s

on_train_batch_end: 1599082205.619710s

 4096/50000 [=>............................] - ETA: 8s - loss: 1.8553 - accuracy: 0.1010
on_train_batch_begin: 1599082205.620089s

2 step training time: 0.359855s

on_train_batch_end: 1599082205.978510s

 6144/50000 [==>...........................] - ETA: 7s - loss: 1.8291 - accuracy: 0.1008
on_train_batch_begin: 1599082205.978882s

3 step training time: 0.358794s

on_train_batch_end: 1599082206.344292s

 8192/50000 [===>..........................] - ETA: 7s - loss: 1.8399 - accuracy: 0.1007
on_train_batch_begin: 1599082206.344674s

4 step training time: 0.365792s

on_train_batch_end: 1599082206.706708s

10240/50000 [=====>........................] - ETA: 7s - loss: 1.8463 - accuracy: 0.1006
on_train_batch_begin: 1599082206.707083s

5 step training time: 0.362409s

on_train_batch_end: 1599082207.071959s

12288/50000 [======>.......................] - ETA: 6s - loss: 1.8571 - accuracy: 0.1007
on_train_batch_begin: 1599082207.072337s

6 step training time: 0.365255s

on_train_batch_end: 1599082207.435665s

14336/50000 [=======>......................] - ETA: 6s - loss: 1.8607 - accuracy: 0.1008
on_train_batch_begin: 1599082207.436040s

7 step training time: 0.363703s

on_train_batch_end: 1599082207.799842s

16384/50000 [========>.....................] - ETA: 5s - loss: 1.8520 - accuracy: 0.1008
on_train_batch_begin: 1599082207.800222s

8 step training time: 0.364182s

on_train_batch_end: 1599082208.163536s

18432/50000 [==========>...................] - ETA: 5s - loss: 1.8504 - accuracy: 0.1009
on_train_batch_begin: 1599082208.163908s

9 step training time: 0.363686s

on_train_batch_end: 1599082208.525297s

20480/50000 [===========>..................] - ETA: 5s - loss: 1.8502 - accuracy: 0.1008
on_train_batch_begin: 1599082208.525679s

10 step training time: 0.361771s

on_train_batch_end: 1599082208.881926s

22528/50000 [============>.................] - ETA: 4s - loss: 1.8550 - accuracy: 0.1008
on_train_batch_begin: 1599082208.882301s

11 step training time: 0.356622s

on_train_batch_end: 1599082209.244481s

24576/50000 [=============>................] - ETA: 4s - loss: 1.8506 - accuracy: 0.1008
on_train_batch_begin: 1599082209.244859s

12 step training time: 0.362558s

on_train_batch_end: 1599082209.608666s

26624/50000 [==============>...............] - ETA: 4s - loss: 1.8428 - accuracy: 0.1008
on_train_batch_begin: 1599082209.609041s

13 step training time: 0.364182s

on_train_batch_end: 1599082209.972441s

28672/50000 [================>.............] - ETA: 3s - loss: 1.8355 - accuracy: 0.1008
on_train_batch_begin: 1599082209.972814s

14 step training time: 0.363773s

on_train_batch_end: 1599082210.333100s

30720/50000 [=================>............] - ETA: 3s - loss: 1.8293 - accuracy: 0.1008
on_train_batch_begin: 1599082210.333472s

15 step training time: 0.360658s

on_train_batch_end: 1599082210.697491s

32768/50000 [==================>...........] - ETA: 3s - loss: 1.8208 - accuracy: 0.1009
on_train_batch_begin: 1599082210.697868s

16 step training time: 0.364396s

on_train_batch_end: 1599082211.059842s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.8125 - accuracy: 0.1008
on_train_batch_begin: 1599082211.060219s

17 step training time: 0.362351s

on_train_batch_end: 1599082211.416815s

36864/50000 [=====================>........] - ETA: 2s - loss: 1.8041 - accuracy: 0.1008
on_train_batch_begin: 1599082211.417186s

18 step training time: 0.356967s

on_train_batch_end: 1599082211.773425s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.7893 - accuracy: 0.1008
on_train_batch_begin: 1599082211.773799s

19 step training time: 0.356613s

on_train_batch_end: 1599082212.125695s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.7845 - accuracy: 0.1008
on_train_batch_begin: 1599082212.126067s

20 step training time: 0.352268s

on_train_batch_end: 1599082212.488046s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.7746 - accuracy: 0.1008
on_train_batch_begin: 1599082212.488423s

21 step training time: 0.362356s

on_train_batch_end: 1599082212.852763s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.7693 - accuracy: 0.1009
on_train_batch_begin: 1599082212.853142s

22 step training time: 0.364719s

on_train_batch_end: 1599082213.217553s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7612 - accuracy: 0.1009
on_train_batch_begin: 1599082213.217933s

23 step training time: 0.364791s

on_train_batch_end: 1599082213.581572s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7501 - accuracy: 0.1009
on_train_batch_begin: 1599082213.581947s

24 step training time: 0.364014s

on_train_batch_end: 1599082213.820674s

on_test_batch_begin: 1599082213.911218s

25 step training time: 0.329271s

on_epoch_end: 1599082214.317858s

Validation time: 0.406622s

Real time: 1599082214.317858s

Epoch time: 9.41941213607788s

50000/50000 [==============================] - 9s 188us/sample - loss: 1.7496 - accuracy: 0.1009 - val_loss: 6.7233 - val_accuracy: 0.1001

on_epoch_begin: 1599082214.318107s

Real time: 1599082214.3181162
Epoch 5/5

on_train_batch_begin: 1599082214.326035s

on_train_batch_end: 1599082214.685965s

 2048/50000 [>.............................] - ETA: 8s - loss: 1.4282 - accuracy: 0.1011
on_train_batch_begin: 1599082214.686353s

1 step training time: 0.360317s

on_train_batch_end: 1599082215.044804s

 4096/50000 [=>............................] - ETA: 8s - loss: 1.3556 - accuracy: 0.1012
on_train_batch_begin: 1599082215.045183s

2 step training time: 0.358830s

on_train_batch_end: 1599082215.405796s

 6144/50000 [==>...........................] - ETA: 7s - loss: 1.4113 - accuracy: 0.1012
on_train_batch_begin: 1599082215.406181s

3 step training time: 0.360999s

on_train_batch_end: 1599082215.769494s

 8192/50000 [===>..........................] - ETA: 7s - loss: 1.3858 - accuracy: 0.1011
on_train_batch_begin: 1599082215.769874s

4 step training time: 0.363692s

on_train_batch_end: 1599082216.128850s

10240/50000 [=====>........................] - ETA: 7s - loss: 1.3813 - accuracy: 0.1011
on_train_batch_begin: 1599082216.129223s

5 step training time: 0.359349s

on_train_batch_end: 1599082216.490646s

12288/50000 [======>.......................] - ETA: 6s - loss: 1.3737 - accuracy: 0.1011
on_train_batch_begin: 1599082216.491021s

6 step training time: 0.361798s

on_train_batch_end: 1599082216.847563s

14336/50000 [=======>......................] - ETA: 6s - loss: 1.3758 - accuracy: 0.1011
on_train_batch_begin: 1599082216.847941s

7 step training time: 0.356920s

on_train_batch_end: 1599082217.210582s

16384/50000 [========>.....................] - ETA: 5s - loss: 1.3780 - accuracy: 0.1011
on_train_batch_begin: 1599082217.210957s

8 step training time: 0.363016s

on_train_batch_end: 1599082217.573514s

18432/50000 [==========>...................] - ETA: 5s - loss: 1.3913 - accuracy: 0.1011
on_train_batch_begin: 1599082217.573901s

9 step training time: 0.362944s

on_train_batch_end: 1599082217.939601s

20480/50000 [===========>..................] - ETA: 5s - loss: 1.4136 - accuracy: 0.1010
on_train_batch_begin: 1599082217.939989s

10 step training time: 0.366088s

on_train_batch_end: 1599082218.304575s

22528/50000 [============>.................] - ETA: 4s - loss: 1.4236 - accuracy: 0.1010
on_train_batch_begin: 1599082218.304957s

11 step training time: 0.364968s

on_train_batch_end: 1599082218.668971s

24576/50000 [=============>................] - ETA: 4s - loss: 1.4102 - accuracy: 0.1010
on_train_batch_begin: 1599082218.669355s

12 step training time: 0.364398s

on_train_batch_end: 1599082219.034063s

26624/50000 [==============>...............] - ETA: 4s - loss: 1.4029 - accuracy: 0.1010
on_train_batch_begin: 1599082219.034449s

13 step training time: 0.365094s

on_train_batch_end: 1599082219.397988s

28672/50000 [================>.............] - ETA: 3s - loss: 1.4009 - accuracy: 0.1010
on_train_batch_begin: 1599082219.398372s

14 step training time: 0.363924s

on_train_batch_end: 1599082219.762586s

30720/50000 [=================>............] - ETA: 3s - loss: 1.3888 - accuracy: 0.1010
on_train_batch_begin: 1599082219.762976s

15 step training time: 0.364604s

on_train_batch_end: 1599082220.122700s

32768/50000 [==================>...........] - ETA: 3s - loss: 1.3806 - accuracy: 0.1011
on_train_batch_begin: 1599082220.123089s

16 step training time: 0.360113s

on_train_batch_end: 1599082220.484399s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.3863 - accuracy: 0.1010
on_train_batch_begin: 1599082220.484786s

17 step training time: 0.361697s

on_train_batch_end: 1599082220.844698s

36864/50000 [=====================>........] - ETA: 2s - loss: 1.3883 - accuracy: 0.1011
on_train_batch_begin: 1599082220.845086s

18 step training time: 0.360300s

on_train_batch_end: 1599082221.205841s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.3886 - accuracy: 0.1011
on_train_batch_begin: 1599082221.206225s

19 step training time: 0.361139s

on_train_batch_end: 1599082221.566571s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.3866 - accuracy: 0.1011
on_train_batch_begin: 1599082221.566955s

20 step training time: 0.360730s

on_train_batch_end: 1599082221.929936s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.3916 - accuracy: 0.1011
on_train_batch_begin: 1599082221.930309s

21 step training time: 0.363355s

on_train_batch_end: 1599082222.293427s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.3938 - accuracy: 0.1011
on_train_batch_begin: 1599082222.293806s

22 step training time: 0.363497s

on_train_batch_end: 1599082222.658257s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.3910 - accuracy: 0.1011
on_train_batch_begin: 1599082222.658638s

23 step training time: 0.364831s

on_train_batch_end: 1599082223.020175s

49152/50000 [============================>.] - ETA: 0s - loss: 1.3887 - accuracy: 0.1011
on_train_batch_begin: 1599082223.020555s

24 step training time: 0.361917s

on_train_batch_end: 1599082223.260362s

on_test_batch_begin: 1599082223.350652s

25 step training time: 0.330097s

on_epoch_end: 1599082223.759611s

Validation time: 0.408942s

Real time: 1599082223.759611s

Epoch time: 9.441517114639282s

50000/50000 [==============================] - 9s 189us/sample - loss: 1.3934 - accuracy: 0.1011 - val_loss: 7.0980 - val_accuracy: 0.0998
Tempo do fit: 214.33364748954773