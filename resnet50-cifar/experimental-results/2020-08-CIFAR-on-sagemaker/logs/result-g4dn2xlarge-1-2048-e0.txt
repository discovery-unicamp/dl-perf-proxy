wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:29
   188416/170498071 [..............................] - ETA: 1:19
  1425408/170498071 [..............................] - ETA: 16s 
  4300800/170498071 [..............................] - ETA: 7s 
  7905280/170498071 [>.............................] - ETA: 5s
 11444224/170498071 [=>............................] - ETA: 4s
 15065088/170498071 [=>............................] - ETA: 3s
 18702336/170498071 [==>...........................] - ETA: 3s
 21946368/170498071 [==>...........................] - ETA: 3s
 25272320/170498071 [===>..........................] - ETA: 2s
 28876800/170498071 [====>.........................] - ETA: 2s
 32415744/170498071 [====>.........................] - ETA: 2s
 36003840/170498071 [=====>........................] - ETA: 2s
 39313408/170498071 [=====>........................] - ETA: 2s
 42786816/170498071 [======>.......................] - ETA: 2s
 46342144/170498071 [=======>......................] - ETA: 2s
 49938432/170498071 [=======>......................] - ETA: 2s
 53256192/170498071 [========>.....................] - ETA: 1s
 56565760/170498071 [========>.....................] - ETA: 1s
 60121088/170498071 [=========>....................] - ETA: 1s
 63660032/170498071 [==========>...................] - ETA: 1s
 67248128/170498071 [==========>...................] - ETA: 1s
 70492160/170498071 [===========>..................] - ETA: 1s
 73924608/170498071 [============>.................] - ETA: 1s
 77365248/170498071 [============>.................] - ETA: 1s
 80945152/170498071 [=============>................] - ETA: 1s
 84484096/170498071 [=============>................] - ETA: 1s
 87760896/170498071 [==============>...............] - ETA: 1s
 91209728/170498071 [===============>..............] - ETA: 1s
 94642176/170498071 [===============>..............] - ETA: 1s
 98230272/170498071 [================>.............] - ETA: 1s
101736448/170498071 [================>.............] - ETA: 1s
105046016/170498071 [=================>............] - ETA: 1s
108503040/170498071 [==================>...........] - ETA: 0s
111951872/170498071 [==================>...........] - ETA: 0s
115548160/170498071 [===================>..........] - ETA: 0s
118972416/170498071 [===================>..........] - ETA: 0s
122363904/170498071 [====================>.........] - ETA: 0s
125804544/170498071 [=====================>........] - ETA: 0s
129196032/170498071 [=====================>........] - ETA: 0s
132571136/170498071 [======================>.......] - ETA: 0s
135684096/170498071 [======================>.......] - ETA: 0s
138960896/170498071 [=======================>......] - ETA: 0s
142270464/170498071 [========================>.....] - ETA: 0s
145596416/170498071 [========================>.....] - ETA: 0s
148905984/170498071 [=========================>....] - ETA: 0s
152182784/170498071 [=========================>....] - ETA: 0s
155426816/170498071 [==========================>...] - ETA: 0s
158687232/170498071 [==========================>...] - ETA: 0s
161931264/170498071 [===========================>..] - ETA: 0s
165109760/170498071 [============================>.] - ETA: 0s
168386560/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 12s
 3710976/94765736 [>.............................] - ETA: 1s 
 9388032/94765736 [=>............................] - ETA: 1s
18530304/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 1s
26853376/94765736 [=======>......................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
36913152/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 1s
38141952/94765736 [===========>..................] - ETA: 1s
40509440/94765736 [===========>..................] - ETA: 1s
47071232/94765736 [=============>................] - ETA: 1s
49209344/94765736 [==============>...............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
75087872/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
83763200/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94011392/94765736 [============================>.] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 17.319105625152588
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598495007.718160s

Real time: 1598495007.7181787
Epoch 1/5

on_train_batch_begin: 1598495008.479427s

on_train_batch_end: 1598495029.278981s

 2048/50000 [>.............................] - ETA: 8:24 - loss: 17.8351 - accuracy: 1.0014e-04
on_train_batch_begin: 1598495029.279622s

1 step training time: 20.800195s

on_train_batch_end: 1598495029.951393s

 4096/50000 [=>............................] - ETA: 4:09 - loss: 14.0346 - accuracy: 3.3748e-04
on_train_batch_begin: 1598495029.951707s

2 step training time: 0.672085s

on_train_batch_end: 1598495030.619947s

 6144/50000 [==>...........................] - ETA: 2:43 - loss: 12.1523 - accuracy: 6.7496e-04
on_train_batch_begin: 1598495030.620287s

3 step training time: 0.668580s

on_train_batch_end: 1598495031.288909s

 8192/50000 [===>..........................] - ETA: 2:00 - loss: 11.1459 - accuracy: 0.0021    
on_train_batch_begin: 1598495031.289211s

4 step training time: 0.668924s

on_train_batch_end: 1598495031.961515s

10240/50000 [=====>........................] - ETA: 1:34 - loss: 10.5255 - accuracy: 0.0050
on_train_batch_begin: 1598495031.961805s

5 step training time: 0.672594s

on_train_batch_end: 1598495032.630468s

12288/50000 [======>.......................] - ETA: 1:16 - loss: 10.1138 - accuracy: 0.0093
on_train_batch_begin: 1598495032.630777s

6 step training time: 0.668972s

on_train_batch_end: 1598495033.297256s

14336/50000 [=======>......................] - ETA: 1:03 - loss: 9.7942 - accuracy: 0.0143 
on_train_batch_begin: 1598495033.297546s

7 step training time: 0.666769s

on_train_batch_end: 1598495033.966004s

16384/50000 [========>.....................] - ETA: 53s - loss: 9.5288 - accuracy: 0.0184 
on_train_batch_begin: 1598495033.966318s

8 step training time: 0.668772s

on_train_batch_end: 1598495034.633039s

18432/50000 [==========>...................] - ETA: 46s - loss: 9.3302 - accuracy: 0.0230
on_train_batch_begin: 1598495034.633360s

9 step training time: 0.667042s

on_train_batch_end: 1598495035.296872s

20480/50000 [===========>..................] - ETA: 39s - loss: 9.1623 - accuracy: 0.0264
on_train_batch_begin: 1598495035.297182s

10 step training time: 0.663822s

on_train_batch_end: 1598495035.964613s

22528/50000 [============>.................] - ETA: 34s - loss: 9.0151 - accuracy: 0.0298
on_train_batch_begin: 1598495035.964926s

11 step training time: 0.667744s

on_train_batch_end: 1598495036.631561s

24576/50000 [=============>................] - ETA: 29s - loss: 8.8877 - accuracy: 0.0331
on_train_batch_begin: 1598495036.631872s

12 step training time: 0.666946s

on_train_batch_end: 1598495037.300533s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.7815 - accuracy: 0.0357
on_train_batch_begin: 1598495037.300857s

13 step training time: 0.668985s

on_train_batch_end: 1598495037.968529s

28672/50000 [================>.............] - ETA: 22s - loss: 8.6797 - accuracy: 0.0373
on_train_batch_begin: 1598495037.968821s

14 step training time: 0.667964s

on_train_batch_end: 1598495038.634323s

30720/50000 [=================>............] - ETA: 19s - loss: 8.5944 - accuracy: 0.0396
on_train_batch_begin: 1598495038.634608s

15 step training time: 0.665788s

on_train_batch_end: 1598495039.306892s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.5136 - accuracy: 0.0415
on_train_batch_begin: 1598495039.307245s

16 step training time: 0.672637s

on_train_batch_end: 1598495039.975384s

34816/50000 [===================>..........] - ETA: 14s - loss: 8.4370 - accuracy: 0.0440
on_train_batch_begin: 1598495039.975699s

17 step training time: 0.668453s

on_train_batch_end: 1598495040.646475s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.3662 - accuracy: 0.0458
on_train_batch_begin: 1598495040.646768s

18 step training time: 0.671069s

on_train_batch_end: 1598495041.316682s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.3062 - accuracy: 0.0470 
on_train_batch_begin: 1598495041.316981s

19 step training time: 0.670213s

on_train_batch_end: 1598495041.985508s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.2498 - accuracy: 0.0480
on_train_batch_begin: 1598495041.985800s

20 step training time: 0.668819s

on_train_batch_end: 1598495042.657231s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.1937 - accuracy: 0.0494
on_train_batch_begin: 1598495042.657520s

21 step training time: 0.671720s

on_train_batch_end: 1598495043.328545s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.1443 - accuracy: 0.0508
on_train_batch_begin: 1598495043.328836s

22 step training time: 0.671316s

on_train_batch_end: 1598495044.000924s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.0945 - accuracy: 0.0521
on_train_batch_begin: 1598495044.001211s

23 step training time: 0.672375s

on_train_batch_end: 1598495044.668779s

49152/50000 [============================>.] - ETA: 0s - loss: 8.0525 - accuracy: 0.0537
on_train_batch_begin: 1598495044.669071s

24 step training time: 0.667860s

on_train_batch_end: 1598495050.647236s

on_test_batch_begin: 1598495050.830298s

25 step training time: 6.161227s

on_epoch_end: 1598495055.994018s

Validation time: 5.163705s

Real time: 1598495055.994018s

Epoch time: 48.27585434913635s

50000/50000 [==============================] - 48s 966us/sample - loss: 8.0335 - accuracy: 0.0538 - val_loss: 82977.9790 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598495055.994213s

Real time: 1598495055.9942188
Epoch 2/5

on_train_batch_begin: 1598495055.997633s

on_train_batch_end: 1598495056.650175s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.9264 - accuracy: 0.0957
on_train_batch_begin: 1598495056.650483s

1 step training time: 0.652850s

on_train_batch_end: 1598495057.335770s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.9172 - accuracy: 0.0960
on_train_batch_begin: 1598495057.336089s

2 step training time: 0.685606s

on_train_batch_end: 1598495058.008877s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.8948 - accuracy: 0.0952
on_train_batch_begin: 1598495058.009166s

3 step training time: 0.673077s

on_train_batch_end: 1598495058.685138s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.9072 - accuracy: 0.0939
on_train_batch_begin: 1598495058.685480s

4 step training time: 0.676313s

on_train_batch_end: 1598495059.360213s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.8929 - accuracy: 0.0931
on_train_batch_begin: 1598495059.360524s

5 step training time: 0.675044s

on_train_batch_end: 1598495060.037624s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.8834 - accuracy: 0.0932
on_train_batch_begin: 1598495060.037943s

6 step training time: 0.677419s

on_train_batch_end: 1598495060.714773s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.8655 - accuracy: 0.0931
on_train_batch_begin: 1598495060.715082s

7 step training time: 0.677139s

on_train_batch_end: 1598495061.393741s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.8603 - accuracy: 0.0920
on_train_batch_begin: 1598495061.394034s

8 step training time: 0.678951s

on_train_batch_end: 1598495062.074649s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.8482 - accuracy: 0.0915
on_train_batch_begin: 1598495062.074942s

9 step training time: 0.680909s

on_train_batch_end: 1598495062.752468s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.8382 - accuracy: 0.0915 
on_train_batch_begin: 1598495062.752810s

10 step training time: 0.677867s

on_train_batch_end: 1598495063.431217s

22528/50000 [============>.................] - ETA: 9s - loss: 6.8266 - accuracy: 0.0913
on_train_batch_begin: 1598495063.431506s

11 step training time: 0.678696s

on_train_batch_end: 1598495064.109750s

24576/50000 [=============>................] - ETA: 8s - loss: 6.8041 - accuracy: 0.0905
on_train_batch_begin: 1598495064.110041s

12 step training time: 0.678535s

on_train_batch_end: 1598495064.789608s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.7939 - accuracy: 0.0902
on_train_batch_begin: 1598495064.789913s

13 step training time: 0.679872s

on_train_batch_end: 1598495065.473450s

28672/50000 [================>.............] - ETA: 7s - loss: 6.7840 - accuracy: 0.0892
on_train_batch_begin: 1598495065.473768s

14 step training time: 0.683855s

on_train_batch_end: 1598495066.150051s

30720/50000 [=================>............] - ETA: 6s - loss: 6.7703 - accuracy: 0.0894
on_train_batch_begin: 1598495066.150370s

15 step training time: 0.676602s

on_train_batch_end: 1598495066.828869s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.7567 - accuracy: 0.0896
on_train_batch_begin: 1598495066.829169s

16 step training time: 0.678799s

on_train_batch_end: 1598495067.506479s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.7455 - accuracy: 0.0899
on_train_batch_begin: 1598495067.506778s

17 step training time: 0.677608s

on_train_batch_end: 1598495068.185517s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.7342 - accuracy: 0.0899
on_train_batch_begin: 1598495068.185825s

18 step training time: 0.679048s

on_train_batch_end: 1598495068.867802s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.7328 - accuracy: 0.0901
on_train_batch_begin: 1598495068.868117s

19 step training time: 0.682292s

on_train_batch_end: 1598495069.551238s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.7250 - accuracy: 0.0900
on_train_batch_begin: 1598495069.551534s

20 step training time: 0.683417s

on_train_batch_end: 1598495070.229391s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.7130 - accuracy: 0.0900
on_train_batch_begin: 1598495070.229709s

21 step training time: 0.678175s

on_train_batch_end: 1598495070.912738s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.6965 - accuracy: 0.0899
on_train_batch_begin: 1598495070.913054s

22 step training time: 0.683345s

on_train_batch_end: 1598495071.597780s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.6853 - accuracy: 0.0899
on_train_batch_begin: 1598495071.598081s

23 step training time: 0.685027s

on_train_batch_end: 1598495072.275491s

49152/50000 [============================>.] - ETA: 0s - loss: 6.6755 - accuracy: 0.0897
on_train_batch_begin: 1598495072.275803s

24 step training time: 0.677722s

on_train_batch_end: 1598495072.563976s

on_test_batch_begin: 1598495072.589866s

25 step training time: 0.314063s

on_epoch_end: 1598495073.456497s

Validation time: 0.866618s

Real time: 1598495073.456497s

Epoch time: 17.46229600906372s

50000/50000 [==============================] - 17s 349us/sample - loss: 6.6689 - accuracy: 0.0896 - val_loss: 27482.3364 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598495073.456687s

Real time: 1598495073.456692
Epoch 3/5

on_train_batch_begin: 1598495073.460032s

on_train_batch_end: 1598495074.138046s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.4645 - accuracy: 0.0827
on_train_batch_begin: 1598495074.138346s

1 step training time: 0.678314s

on_train_batch_end: 1598495074.823611s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.3807 - accuracy: 0.0869
on_train_batch_begin: 1598495074.823929s

2 step training time: 0.685582s

on_train_batch_end: 1598495075.511152s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.3730 - accuracy: 0.0890
on_train_batch_begin: 1598495075.511443s

3 step training time: 0.687514s

on_train_batch_end: 1598495076.195065s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.3861 - accuracy: 0.0880
on_train_batch_begin: 1598495076.195351s

4 step training time: 0.683908s

on_train_batch_end: 1598495076.883573s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.3664 - accuracy: 0.0835
on_train_batch_begin: 1598495076.883879s

5 step training time: 0.688528s

on_train_batch_end: 1598495077.563221s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.3615 - accuracy: 0.0846
on_train_batch_begin: 1598495077.563532s

6 step training time: 0.679653s

on_train_batch_end: 1598495078.252064s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.3684 - accuracy: 0.0833
on_train_batch_begin: 1598495078.252358s

7 step training time: 0.688826s

on_train_batch_end: 1598495078.933461s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.3691 - accuracy: 0.0835
on_train_batch_begin: 1598495078.933747s

8 step training time: 0.681389s

on_train_batch_end: 1598495079.621788s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.3762 - accuracy: 0.0843
on_train_batch_begin: 1598495079.622089s

9 step training time: 0.688342s

on_train_batch_end: 1598495080.311090s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.3735 - accuracy: 0.0846 
on_train_batch_begin: 1598495080.311384s

10 step training time: 0.689295s

on_train_batch_end: 1598495081.001853s

22528/50000 [============>.................] - ETA: 9s - loss: 6.3799 - accuracy: 0.0841
on_train_batch_begin: 1598495081.002151s

11 step training time: 0.690768s

on_train_batch_end: 1598495081.691587s

24576/50000 [=============>................] - ETA: 8s - loss: 6.3816 - accuracy: 0.0833
on_train_batch_begin: 1598495081.691885s

12 step training time: 0.689734s

on_train_batch_end: 1598495082.380983s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.3781 - accuracy: 0.0825
on_train_batch_begin: 1598495082.381276s

13 step training time: 0.689391s

on_train_batch_end: 1598495083.067547s

28672/50000 [================>.............] - ETA: 7s - loss: 6.3896 - accuracy: 0.0799
on_train_batch_begin: 1598495083.067860s

14 step training time: 0.686584s

on_train_batch_end: 1598495083.755584s

30720/50000 [=================>............] - ETA: 6s - loss: 6.3893 - accuracy: 0.0780
on_train_batch_begin: 1598495083.755877s

15 step training time: 0.688017s

on_train_batch_end: 1598495084.444093s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.3782 - accuracy: 0.0768
on_train_batch_begin: 1598495084.444378s

16 step training time: 0.688501s

on_train_batch_end: 1598495085.136842s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.3742 - accuracy: 0.0754
on_train_batch_begin: 1598495085.137156s

17 step training time: 0.692778s

on_train_batch_end: 1598495085.832166s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.3616 - accuracy: 0.0741
on_train_batch_begin: 1598495085.832464s

18 step training time: 0.695307s

on_train_batch_end: 1598495086.525303s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.3492 - accuracy: 0.0725
on_train_batch_begin: 1598495086.525596s

19 step training time: 0.693132s

on_train_batch_end: 1598495087.216286s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.3342 - accuracy: 0.0710
on_train_batch_begin: 1598495087.216573s

20 step training time: 0.690977s

on_train_batch_end: 1598495087.907355s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.3196 - accuracy: 0.0696
on_train_batch_begin: 1598495087.907643s

21 step training time: 0.691070s

on_train_batch_end: 1598495088.606487s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.3014 - accuracy: 0.0683
on_train_batch_begin: 1598495088.606799s

22 step training time: 0.699156s

on_train_batch_end: 1598495089.297613s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.2865 - accuracy: 0.0671
on_train_batch_begin: 1598495089.297905s

23 step training time: 0.691106s

on_train_batch_end: 1598495089.983169s

49152/50000 [============================>.] - ETA: 0s - loss: 6.2699 - accuracy: 0.0661
on_train_batch_begin: 1598495089.983464s

24 step training time: 0.685558s

on_train_batch_end: 1598495090.281460s

on_test_batch_begin: 1598495090.306610s

25 step training time: 0.323147s

on_epoch_end: 1598495091.182628s

Validation time: 0.876005s

Real time: 1598495091.182628s

Epoch time: 17.725952863693237s

50000/50000 [==============================] - 18s 355us/sample - loss: 6.2646 - accuracy: 0.0659 - val_loss: 7.6895 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598495091.182834s

Real time: 1598495091.1828399
Epoch 4/5

on_train_batch_begin: 1598495091.186182s

on_train_batch_end: 1598495091.876965s

 2048/50000 [>.............................] - ETA: 16s - loss: 5.6869 - accuracy: 0.0484
on_train_batch_begin: 1598495091.877261s

1 step training time: 0.691079s

on_train_batch_end: 1598495092.574093s

 4096/50000 [=>............................] - ETA: 15s - loss: 5.5981 - accuracy: 0.0511
on_train_batch_begin: 1598495092.574382s

2 step training time: 0.697121s

on_train_batch_end: 1598495093.265665s

 6144/50000 [==>...........................] - ETA: 14s - loss: 5.5614 - accuracy: 0.0510
on_train_batch_begin: 1598495093.265954s

3 step training time: 0.691572s

on_train_batch_end: 1598495093.962320s

 8192/50000 [===>..........................] - ETA: 14s - loss: 5.5110 - accuracy: 0.0517
on_train_batch_begin: 1598495093.962619s

4 step training time: 0.696666s

on_train_batch_end: 1598495094.661503s

10240/50000 [=====>........................] - ETA: 13s - loss: 5.4506 - accuracy: 0.0522
on_train_batch_begin: 1598495094.661790s

5 step training time: 0.699171s

on_train_batch_end: 1598495095.354988s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.4009 - accuracy: 0.0531
on_train_batch_begin: 1598495095.355305s

6 step training time: 0.693515s

on_train_batch_end: 1598495096.055476s

14336/50000 [=======>......................] - ETA: 12s - loss: 5.3486 - accuracy: 0.0541
on_train_batch_begin: 1598495096.055787s

7 step training time: 0.700482s

on_train_batch_end: 1598495096.754247s

16384/50000 [========>.....................] - ETA: 11s - loss: 5.2909 - accuracy: 0.0550
on_train_batch_begin: 1598495096.754560s

8 step training time: 0.698772s

on_train_batch_end: 1598495097.449034s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.2357 - accuracy: 0.0558
on_train_batch_begin: 1598495097.449349s

9 step training time: 0.694789s

on_train_batch_end: 1598495098.152024s

20480/50000 [===========>..................] - ETA: 10s - loss: 5.1698 - accuracy: 0.0566
on_train_batch_begin: 1598495098.152327s

10 step training time: 0.702978s

on_train_batch_end: 1598495098.856402s

22528/50000 [============>.................] - ETA: 9s - loss: 5.1131 - accuracy: 0.0575 
on_train_batch_begin: 1598495098.856720s

11 step training time: 0.704394s

on_train_batch_end: 1598495099.554834s

24576/50000 [=============>................] - ETA: 8s - loss: 5.0565 - accuracy: 0.0583
on_train_batch_begin: 1598495099.555131s

12 step training time: 0.698411s

on_train_batch_end: 1598495100.256887s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.9913 - accuracy: 0.0594
on_train_batch_begin: 1598495100.257181s

13 step training time: 0.702050s

on_train_batch_end: 1598495100.955438s

28672/50000 [================>.............] - ETA: 7s - loss: 4.9411 - accuracy: 0.0605
on_train_batch_begin: 1598495100.955730s

14 step training time: 0.698549s

on_train_batch_end: 1598495101.654603s

30720/50000 [=================>............] - ETA: 6s - loss: 4.8796 - accuracy: 0.0617
on_train_batch_begin: 1598495101.654894s

15 step training time: 0.699164s

on_train_batch_end: 1598495102.351107s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.8166 - accuracy: 0.0630
on_train_batch_begin: 1598495102.351413s

16 step training time: 0.696519s

on_train_batch_end: 1598495103.054801s

34816/50000 [===================>..........] - ETA: 5s - loss: 4.7464 - accuracy: 0.0643
on_train_batch_begin: 1598495103.055098s

17 step training time: 0.703684s

on_train_batch_end: 1598495103.751452s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.6786 - accuracy: 0.0656
on_train_batch_begin: 1598495103.751762s

18 step training time: 0.696664s

on_train_batch_end: 1598495104.454196s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.6203 - accuracy: 0.0668
on_train_batch_begin: 1598495104.454511s

19 step training time: 0.702749s

on_train_batch_end: 1598495105.159431s

40960/50000 [=======================>......] - ETA: 3s - loss: 4.5555 - accuracy: 0.0681
on_train_batch_begin: 1598495105.159730s

20 step training time: 0.705220s

on_train_batch_end: 1598495105.861723s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.4882 - accuracy: 0.0693
on_train_batch_begin: 1598495105.862013s

21 step training time: 0.702282s

on_train_batch_end: 1598495106.565524s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.4165 - accuracy: 0.0705
on_train_batch_begin: 1598495106.565834s

22 step training time: 0.703821s

on_train_batch_end: 1598495107.272185s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.3498 - accuracy: 0.0717
on_train_batch_begin: 1598495107.272519s

23 step training time: 0.706685s

on_train_batch_end: 1598495107.963494s

49152/50000 [============================>.] - ETA: 0s - loss: 4.2795 - accuracy: 0.0728
on_train_batch_begin: 1598495107.963803s

24 step training time: 0.691284s

on_train_batch_end: 1598495108.265578s

on_test_batch_begin: 1598495108.290984s

25 step training time: 0.327181s

on_epoch_end: 1598495109.172330s

Validation time: 0.881333s

Real time: 1598495109.172330s

Epoch time: 17.98950695991516s

50000/50000 [==============================] - 18s 360us/sample - loss: 4.2517 - accuracy: 0.0730 - val_loss: 7.6720 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598495109.172532s

Real time: 1598495109.1725373
Epoch 5/5

on_train_batch_begin: 1598495109.175908s

on_train_batch_end: 1598495109.875927s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.6153 - accuracy: 0.0994
on_train_batch_begin: 1598495109.876245s

1 step training time: 0.700336s

on_train_batch_end: 1598495110.588225s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.4870 - accuracy: 0.0995
on_train_batch_begin: 1598495110.588522s

2 step training time: 0.712277s

on_train_batch_end: 1598495111.294355s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.4367 - accuracy: 0.0994
on_train_batch_begin: 1598495111.294665s

3 step training time: 0.706143s

on_train_batch_end: 1598495111.999670s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.3833 - accuracy: 0.0994
on_train_batch_begin: 1598495111.999995s

4 step training time: 0.705330s

on_train_batch_end: 1598495112.702934s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.3667 - accuracy: 0.0995
on_train_batch_begin: 1598495112.703264s

5 step training time: 0.703269s

on_train_batch_end: 1598495113.412945s

12288/50000 [======>.......................] - ETA: 13s - loss: 2.3350 - accuracy: 0.0995
on_train_batch_begin: 1598495113.413233s

6 step training time: 0.709969s

on_train_batch_end: 1598495114.120877s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.2944 - accuracy: 0.0996
on_train_batch_begin: 1598495114.121169s

7 step training time: 0.707937s

on_train_batch_end: 1598495114.825511s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.2597 - accuracy: 0.0997
on_train_batch_begin: 1598495114.825809s

8 step training time: 0.704640s

on_train_batch_end: 1598495115.532912s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.2469 - accuracy: 0.0997
on_train_batch_begin: 1598495115.533206s

9 step training time: 0.707396s

on_train_batch_end: 1598495116.238226s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.2362 - accuracy: 0.0997
on_train_batch_begin: 1598495116.238522s

10 step training time: 0.705316s

on_train_batch_end: 1598495116.946790s

22528/50000 [============>.................] - ETA: 9s - loss: 2.2070 - accuracy: 0.0998 
on_train_batch_begin: 1598495116.947087s

11 step training time: 0.708565s

on_train_batch_end: 1598495117.651634s

24576/50000 [=============>................] - ETA: 8s - loss: 2.1837 - accuracy: 0.0998
on_train_batch_begin: 1598495117.651925s

12 step training time: 0.704838s

on_train_batch_end: 1598495118.362515s

26624/50000 [==============>...............] - ETA: 8s - loss: 2.1586 - accuracy: 0.0998
on_train_batch_begin: 1598495118.362804s

13 step training time: 0.710879s

on_train_batch_end: 1598495119.068912s

28672/50000 [================>.............] - ETA: 7s - loss: 2.1395 - accuracy: 0.0998
on_train_batch_begin: 1598495119.069209s

14 step training time: 0.706405s

on_train_batch_end: 1598495119.772410s

30720/50000 [=================>............] - ETA: 6s - loss: 2.1181 - accuracy: 0.0999
on_train_batch_begin: 1598495119.772703s

15 step training time: 0.703494s

on_train_batch_end: 1598495120.481424s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.1067 - accuracy: 0.0999
on_train_batch_begin: 1598495120.481724s

16 step training time: 0.709021s

on_train_batch_end: 1598495121.188652s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.0858 - accuracy: 0.0999
on_train_batch_begin: 1598495121.188991s

17 step training time: 0.707268s

on_train_batch_end: 1598495121.902040s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.0629 - accuracy: 0.0999
on_train_batch_begin: 1598495121.902349s

18 step training time: 0.713358s

on_train_batch_end: 1598495122.609244s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.0460 - accuracy: 0.0999
on_train_batch_begin: 1598495122.609563s

19 step training time: 0.707214s

on_train_batch_end: 1598495123.320050s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.0276 - accuracy: 0.0999
on_train_batch_begin: 1598495123.320377s

20 step training time: 0.710814s

on_train_batch_end: 1598495124.030488s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.0088 - accuracy: 0.0999
on_train_batch_begin: 1598495124.030800s

21 step training time: 0.710423s

on_train_batch_end: 1598495124.742782s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.9903 - accuracy: 0.0999
on_train_batch_begin: 1598495124.743092s

22 step training time: 0.712293s

on_train_batch_end: 1598495125.453095s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.9798 - accuracy: 0.0999
on_train_batch_begin: 1598495125.453412s

23 step training time: 0.710320s

on_train_batch_end: 1598495126.152527s

49152/50000 [============================>.] - ETA: 0s - loss: 1.9651 - accuracy: 0.0999
on_train_batch_begin: 1598495126.152826s

24 step training time: 0.699413s

on_train_batch_end: 1598495126.458041s

on_test_batch_begin: 1598495126.483544s

25 step training time: 0.330718s

on_epoch_end: 1598495127.373442s

Validation time: 0.889887s

Real time: 1598495127.373442s

Epoch time: 18.200920343399048s

50000/50000 [==============================] - 18s 364us/sample - loss: 1.9569 - accuracy: 0.0999 - val_loss: 7.3045 - val_accuracy: 0.0000e+00
Tempo do fit: 123.02621650695801