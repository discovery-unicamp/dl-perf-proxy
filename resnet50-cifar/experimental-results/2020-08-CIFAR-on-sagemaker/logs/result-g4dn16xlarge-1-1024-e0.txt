wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:46
   221184/170498071 [..............................] - ETA: 1:11
  1171456/170498071 [..............................] - ETA: 20s 
  3170304/170498071 [..............................] - ETA: 10s
  5873664/170498071 [>.............................] - ETA: 6s 
  8740864/170498071 [>.............................] - ETA: 5s
 11657216/170498071 [=>............................] - ETA: 4s
 14327808/170498071 [=>............................] - ETA: 4s
 17096704/170498071 [==>...........................] - ETA: 4s
 19980288/170498071 [==>...........................] - ETA: 3s
 22765568/170498071 [===>..........................] - ETA: 3s
 25583616/170498071 [===>..........................] - ETA: 3s
 28286976/170498071 [===>..........................] - ETA: 3s
 30990336/170498071 [====>.........................] - ETA: 3s
 33726464/170498071 [====>.........................] - ETA: 3s
 36511744/170498071 [=====>........................] - ETA: 2s
 39346176/170498071 [=====>........................] - ETA: 2s
 42049536/170498071 [======>.......................] - ETA: 2s
 44802048/170498071 [======>.......................] - ETA: 2s
 47587328/170498071 [=======>......................] - ETA: 2s
 50372608/170498071 [=======>......................] - ETA: 2s
 53174272/170498071 [========>.....................] - ETA: 2s
 55959552/170498071 [========>.....................] - ETA: 2s
 58679296/170498071 [=========>....................] - ETA: 2s
 61448192/170498071 [=========>....................] - ETA: 2s
 64233472/170498071 [==========>...................] - ETA: 2s
 67035136/170498071 [==========>...................] - ETA: 2s
 69828608/170498071 [===========>..................] - ETA: 2s
 72556544/170498071 [===========>..................] - ETA: 1s
 75325440/170498071 [============>.................] - ETA: 1s
 78094336/170498071 [============>.................] - ETA: 1s
 80846848/170498071 [=============>................] - ETA: 1s
 83599360/170498071 [=============>................] - ETA: 1s
 86384640/170498071 [==============>...............] - ETA: 1s
 89169920/170498071 [==============>...............] - ETA: 1s
 91947008/170498071 [===============>..............] - ETA: 1s
 94691328/170498071 [===============>..............] - ETA: 1s
 97492992/170498071 [================>.............] - ETA: 1s
100294656/170498071 [================>.............] - ETA: 1s
103030784/170498071 [=================>............] - ETA: 1s
105816064/170498071 [=================>............] - ETA: 1s
108552192/170498071 [==================>...........] - ETA: 1s
111353856/170498071 [==================>...........] - ETA: 1s
114106368/170498071 [===================>..........] - ETA: 1s
116826112/170498071 [===================>..........] - ETA: 1s
119578624/170498071 [====================>.........] - ETA: 0s
122331136/170498071 [====================>.........] - ETA: 0s
125083648/170498071 [=====================>........] - ETA: 0s
128016384/170498071 [=====================>........] - ETA: 0s
130793472/170498071 [======================>.......] - ETA: 0s
133472256/170498071 [======================>.......] - ETA: 0s
136241152/170498071 [======================>.......] - ETA: 0s
138919936/170498071 [=======================>......] - ETA: 0s
141582336/170498071 [=======================>......] - ETA: 0s
144195584/170498071 [========================>.....] - ETA: 0s
146956288/170498071 [========================>.....] - ETA: 0s
149610496/170498071 [=========================>....] - ETA: 0s
152313856/170498071 [=========================>....] - ETA: 0s
155017216/170498071 [==========================>...] - ETA: 0s
157802496/170498071 [==========================>...] - ETA: 0s
160546816/170498071 [===========================>..] - ETA: 0s
163274752/170498071 [===========================>..] - ETA: 0s
166010880/170498071 [============================>.] - ETA: 0s
168910848/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 6s
 5840896/94765736 [>.............................] - ETA: 2s
 8552448/94765736 [=>............................] - ETA: 2s
12926976/94765736 [===>..........................] - ETA: 1s
17121280/94765736 [====>.........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
29409280/94765736 [========>.....................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 0s
56573952/94765736 [================>.............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
65175552/94765736 [===================>..........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
66510848/94765736 [====================>.........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
82206720/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
86007808/94765736 [==========================>...] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.522053241729736
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598505135.338322s

Real time: 1598505135.338338
Epoch 1/5

on_train_batch_begin: 1598505136.083319s

on_train_batch_end: 1598505153.258284s

 1024/50000 [..............................] - ETA: 14:17 - loss: 18.0019 - accuracy: 2.1839e-04
on_train_batch_begin: 1598505153.258902s

1 step training time: 17.175583s

on_train_batch_end: 1598505153.601757s

 2048/50000 [>.............................] - ETA: 7:07 - loss: 15.2531 - accuracy: 4.1389e-04 
on_train_batch_begin: 1598505153.602106s

2 step training time: 0.343204s

on_train_batch_end: 1598505153.934963s

 3072/50000 [>.............................] - ETA: 4:44 - loss: 13.2028 - accuracy: 4.6412e-04
on_train_batch_begin: 1598505153.935262s

3 step training time: 0.333156s

on_train_batch_end: 1598505154.273538s

 4096/50000 [=>............................] - ETA: 3:32 - loss: 11.9838 - accuracy: 0.0015    
on_train_batch_begin: 1598505154.273817s

4 step training time: 0.338555s

on_train_batch_end: 1598505154.605965s

 5120/50000 [==>...........................] - ETA: 2:48 - loss: 11.2163 - accuracy: 0.0033
on_train_batch_begin: 1598505154.606255s

5 step training time: 0.332438s

on_train_batch_end: 1598505154.946440s

 6144/50000 [==>...........................] - ETA: 2:19 - loss: 10.6596 - accuracy: 0.0067
on_train_batch_begin: 1598505154.946746s

6 step training time: 0.340491s

on_train_batch_end: 1598505155.284731s

 7168/50000 [===>..........................] - ETA: 1:59 - loss: 10.2506 - accuracy: 0.0106
on_train_batch_begin: 1598505155.285060s

7 step training time: 0.338315s

on_train_batch_end: 1598505155.621464s

 8192/50000 [===>..........................] - ETA: 1:43 - loss: 9.9366 - accuracy: 0.0152 
on_train_batch_begin: 1598505155.621788s

8 step training time: 0.336728s

on_train_batch_end: 1598505155.960888s

 9216/50000 [====>.........................] - ETA: 1:31 - loss: 9.7107 - accuracy: 0.0198
on_train_batch_begin: 1598505155.961192s

9 step training time: 0.339403s

on_train_batch_end: 1598505156.301468s

10240/50000 [=====>........................] - ETA: 1:21 - loss: 9.5039 - accuracy: 0.0240
on_train_batch_begin: 1598505156.301799s

10 step training time: 0.340607s

on_train_batch_end: 1598505156.640074s

11264/50000 [=====>........................] - ETA: 1:13 - loss: 9.3453 - accuracy: 0.0268
on_train_batch_begin: 1598505156.640386s

11 step training time: 0.338587s

on_train_batch_end: 1598505156.977429s

12288/50000 [======>.......................] - ETA: 1:06 - loss: 9.2049 - accuracy: 0.0306
on_train_batch_begin: 1598505156.977729s

12 step training time: 0.337343s

on_train_batch_end: 1598505157.316278s

13312/50000 [======>.......................] - ETA: 1:00 - loss: 9.0982 - accuracy: 0.0334
on_train_batch_begin: 1598505157.316565s

13 step training time: 0.338836s

on_train_batch_end: 1598505157.654261s

14336/50000 [=======>......................] - ETA: 55s - loss: 8.9845 - accuracy: 0.0361 
on_train_batch_begin: 1598505157.654516s

14 step training time: 0.337950s

on_train_batch_end: 1598505157.992037s

15360/50000 [========>.....................] - ETA: 51s - loss: 8.8794 - accuracy: 0.0370
on_train_batch_begin: 1598505157.992311s

15 step training time: 0.337795s

on_train_batch_end: 1598505158.330008s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.7823 - accuracy: 0.0396
on_train_batch_begin: 1598505158.330290s

16 step training time: 0.337980s

on_train_batch_end: 1598505158.667962s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.7101 - accuracy: 0.0418
on_train_batch_begin: 1598505158.668230s

17 step training time: 0.337940s

on_train_batch_end: 1598505159.009102s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.6300 - accuracy: 0.0440
on_train_batch_begin: 1598505159.009376s

18 step training time: 0.341146s

on_train_batch_end: 1598505159.346987s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.5632 - accuracy: 0.0462
on_train_batch_begin: 1598505159.347266s

19 step training time: 0.337890s

on_train_batch_end: 1598505159.684874s

20480/50000 [===========>..................] - ETA: 35s - loss: 8.4918 - accuracy: 0.0483
on_train_batch_begin: 1598505159.685175s

20 step training time: 0.337909s

on_train_batch_end: 1598505160.024535s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.4289 - accuracy: 0.0487
on_train_batch_begin: 1598505160.024825s

21 step training time: 0.339649s

on_train_batch_end: 1598505160.364553s

22528/50000 [============>.................] - ETA: 30s - loss: 8.3664 - accuracy: 0.0494
on_train_batch_begin: 1598505160.364845s

22 step training time: 0.340020s

on_train_batch_end: 1598505160.703974s

23552/50000 [=============>................] - ETA: 28s - loss: 8.3081 - accuracy: 0.0509
on_train_batch_begin: 1598505160.704295s

23 step training time: 0.339450s

on_train_batch_end: 1598505161.044385s

24576/50000 [=============>................] - ETA: 26s - loss: 8.2509 - accuracy: 0.0513
on_train_batch_begin: 1598505161.044685s

24 step training time: 0.340390s

on_train_batch_end: 1598505161.385861s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.2052 - accuracy: 0.0521
on_train_batch_begin: 1598505161.386206s

25 step training time: 0.341521s

on_train_batch_end: 1598505161.723329s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.1536 - accuracy: 0.0531
on_train_batch_begin: 1598505161.723674s

26 step training time: 0.337468s

on_train_batch_end: 1598505162.063610s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.1066 - accuracy: 0.0536
on_train_batch_begin: 1598505162.063918s

27 step training time: 0.340245s

on_train_batch_end: 1598505162.407306s

28672/50000 [================>.............] - ETA: 20s - loss: 8.0613 - accuracy: 0.0541
on_train_batch_begin: 1598505162.407597s

28 step training time: 0.343678s

on_train_batch_end: 1598505162.747728s

29696/50000 [================>.............] - ETA: 18s - loss: 8.0183 - accuracy: 0.0553
on_train_batch_begin: 1598505162.748011s

29 step training time: 0.340414s

on_train_batch_end: 1598505163.086484s

30720/50000 [=================>............] - ETA: 17s - loss: 7.9747 - accuracy: 0.0560
on_train_batch_begin: 1598505163.086761s

30 step training time: 0.338749s

on_train_batch_end: 1598505163.430595s

31744/50000 [==================>...........] - ETA: 16s - loss: 7.9362 - accuracy: 0.0569
on_train_batch_begin: 1598505163.430888s

31 step training time: 0.344127s

on_train_batch_end: 1598505163.771465s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.9025 - accuracy: 0.0574
on_train_batch_begin: 1598505163.771775s

32 step training time: 0.340888s

on_train_batch_end: 1598505164.115323s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.8668 - accuracy: 0.0581
on_train_batch_begin: 1598505164.115647s

33 step training time: 0.343872s

on_train_batch_end: 1598505164.457734s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.8311 - accuracy: 0.0585
on_train_batch_begin: 1598505164.458025s

34 step training time: 0.342378s

on_train_batch_end: 1598505164.799005s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.7997 - accuracy: 0.0588
on_train_batch_begin: 1598505164.799296s

35 step training time: 0.341271s

on_train_batch_end: 1598505165.139855s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.7651 - accuracy: 0.0591
on_train_batch_begin: 1598505165.140179s

36 step training time: 0.340883s

on_train_batch_end: 1598505165.481128s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.7293 - accuracy: 0.0593 
on_train_batch_begin: 1598505165.481434s

37 step training time: 0.341254s

on_train_batch_end: 1598505165.820912s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.6922 - accuracy: 0.0597
on_train_batch_begin: 1598505165.821204s

38 step training time: 0.339770s

on_train_batch_end: 1598505166.163424s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.6632 - accuracy: 0.0600
on_train_batch_begin: 1598505166.163756s

39 step training time: 0.342552s

on_train_batch_end: 1598505166.507909s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.6321 - accuracy: 0.0603
on_train_batch_begin: 1598505166.508223s

40 step training time: 0.344467s

on_train_batch_end: 1598505166.853405s

41984/50000 [========================>.....] - ETA: 6s - loss: 7.6038 - accuracy: 0.0604
on_train_batch_begin: 1598505166.853708s

41 step training time: 0.345485s

on_train_batch_end: 1598505167.199589s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.5749 - accuracy: 0.0605
on_train_batch_begin: 1598505167.199900s

42 step training time: 0.346192s

on_train_batch_end: 1598505167.540787s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.5468 - accuracy: 0.0606
on_train_batch_begin: 1598505167.541074s

43 step training time: 0.341174s

on_train_batch_end: 1598505167.880514s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.5189 - accuracy: 0.0607
on_train_batch_begin: 1598505167.880799s

44 step training time: 0.339725s

on_train_batch_end: 1598505168.221525s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.4925 - accuracy: 0.0609
on_train_batch_begin: 1598505168.221802s

45 step training time: 0.341003s

on_train_batch_end: 1598505168.565535s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.4656 - accuracy: 0.0613
on_train_batch_begin: 1598505168.565788s

46 step training time: 0.343986s

on_train_batch_end: 1598505168.922172s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.4392 - accuracy: 0.0615
on_train_batch_begin: 1598505168.922400s

47 step training time: 0.356612s

on_train_batch_end: 1598505169.260810s

49152/50000 [============================>.] - ETA: 0s - loss: 7.4113 - accuracy: 0.0617
on_train_batch_begin: 1598505169.261071s

48 step training time: 0.338671s

on_train_batch_end: 1598505175.459419s

on_test_batch_begin: 1598505175.648375s

49 step training time: 6.387303s

on_epoch_end: 1598505180.573716s

Validation time: 4.925321s

Real time: 1598505180.573716s

Epoch time: 45.23539876937866s

50000/50000 [==============================] - 45s 905us/sample - loss: 7.3867 - accuracy: 0.0619 - val_loss: 9191.7130 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598505180.573933s

Real time: 1598505180.5739388
Epoch 2/5

on_train_batch_begin: 1598505180.577323s

on_train_batch_end: 1598505180.927603s

 1024/50000 [..............................] - ETA: 16s - loss: 6.0404 - accuracy: 0.0754
on_train_batch_begin: 1598505180.927868s

1 step training time: 0.350544s

on_train_batch_end: 1598505181.275440s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.0185 - accuracy: 0.0695
on_train_batch_begin: 1598505181.275730s

2 step training time: 0.347862s

on_train_batch_end: 1598505181.621665s

 3072/50000 [>.............................] - ETA: 16s - loss: 5.9742 - accuracy: 0.0690
on_train_batch_begin: 1598505181.621987s

3 step training time: 0.346256s

on_train_batch_end: 1598505181.970043s

 4096/50000 [=>............................] - ETA: 15s - loss: 5.9805 - accuracy: 0.0677
on_train_batch_begin: 1598505181.970307s

4 step training time: 0.348320s

on_train_batch_end: 1598505182.317774s

 5120/50000 [==>...........................] - ETA: 15s - loss: 5.9446 - accuracy: 0.0673
on_train_batch_begin: 1598505182.318035s

5 step training time: 0.347728s

on_train_batch_end: 1598505182.666740s

 6144/50000 [==>...........................] - ETA: 14s - loss: 5.9351 - accuracy: 0.0705
on_train_batch_begin: 1598505182.666997s

6 step training time: 0.348962s

on_train_batch_end: 1598505183.016877s

 7168/50000 [===>..........................] - ETA: 14s - loss: 5.9083 - accuracy: 0.0720
on_train_batch_begin: 1598505183.017131s

7 step training time: 0.350134s

on_train_batch_end: 1598505183.362360s

 8192/50000 [===>..........................] - ETA: 14s - loss: 5.8895 - accuracy: 0.0719
on_train_batch_begin: 1598505183.362615s

8 step training time: 0.345484s

on_train_batch_end: 1598505183.709423s

 9216/50000 [====>.........................] - ETA: 13s - loss: 5.8623 - accuracy: 0.0719
on_train_batch_begin: 1598505183.709677s

9 step training time: 0.347062s

on_train_batch_end: 1598505184.058904s

10240/50000 [=====>........................] - ETA: 13s - loss: 5.8519 - accuracy: 0.0710
on_train_batch_begin: 1598505184.059158s

10 step training time: 0.349482s

on_train_batch_end: 1598505184.409399s

11264/50000 [=====>........................] - ETA: 13s - loss: 5.8204 - accuracy: 0.0716
on_train_batch_begin: 1598505184.409657s

11 step training time: 0.350498s

on_train_batch_end: 1598505184.758437s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.7983 - accuracy: 0.0707
on_train_batch_begin: 1598505184.758697s

12 step training time: 0.349040s

on_train_batch_end: 1598505185.105699s

13312/50000 [======>.......................] - ETA: 12s - loss: 5.7817 - accuracy: 0.0700
on_train_batch_begin: 1598505185.105967s

13 step training time: 0.347270s

on_train_batch_end: 1598505185.454164s

14336/50000 [=======>......................] - ETA: 12s - loss: 5.7525 - accuracy: 0.0696
on_train_batch_begin: 1598505185.454474s

14 step training time: 0.348507s

on_train_batch_end: 1598505185.803960s

15360/50000 [========>.....................] - ETA: 11s - loss: 5.7417 - accuracy: 0.0687
on_train_batch_begin: 1598505185.804287s

15 step training time: 0.349813s

on_train_batch_end: 1598505186.152723s

16384/50000 [========>.....................] - ETA: 11s - loss: 5.7151 - accuracy: 0.0683
on_train_batch_begin: 1598505186.153006s

16 step training time: 0.348719s

on_train_batch_end: 1598505186.503158s

17408/50000 [=========>....................] - ETA: 11s - loss: 5.6975 - accuracy: 0.0678
on_train_batch_begin: 1598505186.503482s

17 step training time: 0.350476s

on_train_batch_end: 1598505186.854056s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.6829 - accuracy: 0.0670
on_train_batch_begin: 1598505186.854390s

18 step training time: 0.350909s

on_train_batch_end: 1598505187.204889s

19456/50000 [==========>...................] - ETA: 10s - loss: 5.6666 - accuracy: 0.0665
on_train_batch_begin: 1598505187.205182s

19 step training time: 0.350792s

on_train_batch_end: 1598505187.552320s

20480/50000 [===========>..................] - ETA: 10s - loss: 5.6458 - accuracy: 0.0661
on_train_batch_begin: 1598505187.552597s

20 step training time: 0.347414s

on_train_batch_end: 1598505187.901113s

21504/50000 [===========>..................] - ETA: 9s - loss: 5.6189 - accuracy: 0.0657 
on_train_batch_begin: 1598505187.901393s

21 step training time: 0.348796s

on_train_batch_end: 1598505188.251107s

22528/50000 [============>.................] - ETA: 9s - loss: 5.6020 - accuracy: 0.0652
on_train_batch_begin: 1598505188.251379s

22 step training time: 0.349987s

on_train_batch_end: 1598505188.601980s

23552/50000 [=============>................] - ETA: 9s - loss: 5.5844 - accuracy: 0.0650
on_train_batch_begin: 1598505188.602252s

23 step training time: 0.350873s

on_train_batch_end: 1598505188.951866s

24576/50000 [=============>................] - ETA: 8s - loss: 5.5604 - accuracy: 0.0650
on_train_batch_begin: 1598505188.952146s

24 step training time: 0.349895s

on_train_batch_end: 1598505189.303252s

25600/50000 [==============>...............] - ETA: 8s - loss: 5.5405 - accuracy: 0.0648
on_train_batch_begin: 1598505189.303535s

25 step training time: 0.351389s

on_train_batch_end: 1598505189.653880s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.5116 - accuracy: 0.0647
on_train_batch_begin: 1598505189.654187s

26 step training time: 0.350652s

on_train_batch_end: 1598505190.005411s

27648/50000 [===============>..............] - ETA: 7s - loss: 5.4835 - accuracy: 0.0647
on_train_batch_begin: 1598505190.005696s

27 step training time: 0.351509s

on_train_batch_end: 1598505190.356311s

28672/50000 [================>.............] - ETA: 7s - loss: 5.4567 - accuracy: 0.0644
on_train_batch_begin: 1598505190.356598s

28 step training time: 0.350902s

on_train_batch_end: 1598505190.708495s

29696/50000 [================>.............] - ETA: 6s - loss: 5.4340 - accuracy: 0.0642
on_train_batch_begin: 1598505190.708797s

29 step training time: 0.352198s

on_train_batch_end: 1598505191.063432s

30720/50000 [=================>............] - ETA: 6s - loss: 5.4110 - accuracy: 0.0641
on_train_batch_begin: 1598505191.063760s

30 step training time: 0.354963s

on_train_batch_end: 1598505191.413326s

31744/50000 [==================>...........] - ETA: 6s - loss: 5.3915 - accuracy: 0.0640
on_train_batch_begin: 1598505191.413610s

31 step training time: 0.349850s

on_train_batch_end: 1598505191.764963s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.3768 - accuracy: 0.0639
on_train_batch_begin: 1598505191.765311s

32 step training time: 0.351702s

on_train_batch_end: 1598505192.117766s

33792/50000 [===================>..........] - ETA: 5s - loss: 5.3558 - accuracy: 0.0640
on_train_batch_begin: 1598505192.118083s

33 step training time: 0.352772s

on_train_batch_end: 1598505192.471388s

34816/50000 [===================>..........] - ETA: 5s - loss: 5.3267 - accuracy: 0.0641
on_train_batch_begin: 1598505192.471655s

34 step training time: 0.353572s

on_train_batch_end: 1598505192.827983s

35840/50000 [====================>.........] - ETA: 4s - loss: 5.3007 - accuracy: 0.0644
on_train_batch_begin: 1598505192.828240s

35 step training time: 0.356585s

on_train_batch_end: 1598505193.177591s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.2719 - accuracy: 0.0647
on_train_batch_begin: 1598505193.177851s

36 step training time: 0.349611s

on_train_batch_end: 1598505193.525872s

37888/50000 [=====================>........] - ETA: 4s - loss: 5.2459 - accuracy: 0.0651
on_train_batch_begin: 1598505193.526133s

37 step training time: 0.348283s

on_train_batch_end: 1598505193.885266s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.2214 - accuracy: 0.0653
on_train_batch_begin: 1598505193.885535s

38 step training time: 0.359401s

on_train_batch_end: 1598505194.237278s

39936/50000 [======================>.......] - ETA: 3s - loss: 5.1971 - accuracy: 0.0656
on_train_batch_begin: 1598505194.237546s

39 step training time: 0.352011s

on_train_batch_end: 1598505194.592901s

40960/50000 [=======================>......] - ETA: 3s - loss: 5.1731 - accuracy: 0.0659
on_train_batch_begin: 1598505194.593211s

40 step training time: 0.355665s

on_train_batch_end: 1598505194.947769s

41984/50000 [========================>.....] - ETA: 2s - loss: 5.1489 - accuracy: 0.0662
on_train_batch_begin: 1598505194.948051s

41 step training time: 0.354840s

on_train_batch_end: 1598505195.303167s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.1265 - accuracy: 0.0665
on_train_batch_begin: 1598505195.303446s

42 step training time: 0.355395s

on_train_batch_end: 1598505195.657418s

44032/50000 [=========================>....] - ETA: 2s - loss: 5.1016 - accuracy: 0.0668
on_train_batch_begin: 1598505195.657700s

43 step training time: 0.354254s

on_train_batch_end: 1598505196.010212s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.0793 - accuracy: 0.0670
on_train_batch_begin: 1598505196.010500s

44 step training time: 0.352800s

on_train_batch_end: 1598505196.363784s

46080/50000 [==========================>...] - ETA: 1s - loss: 5.0585 - accuracy: 0.0673
on_train_batch_begin: 1598505196.364099s

45 step training time: 0.353599s

on_train_batch_end: 1598505196.717807s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.0325 - accuracy: 0.0676
on_train_batch_begin: 1598505196.718152s

46 step training time: 0.354053s

on_train_batch_end: 1598505197.075376s

48128/50000 [===========================>..] - ETA: 0s - loss: 5.0056 - accuracy: 0.0680
on_train_batch_begin: 1598505197.075727s

47 step training time: 0.357575s

on_train_batch_end: 1598505197.429430s

49152/50000 [============================>.] - ETA: 0s - loss: 4.9763 - accuracy: 0.0684
on_train_batch_begin: 1598505197.429719s

48 step training time: 0.353992s

on_train_batch_end: 1598505197.717261s

on_test_batch_begin: 1598505197.731089s

49 step training time: 0.301370s

on_epoch_end: 1598505198.588581s

Validation time: 0.857481s

Real time: 1598505198.588581s

Epoch time: 18.014662742614746s

50000/50000 [==============================] - 18s 360us/sample - loss: 4.9536 - accuracy: 0.0686 - val_loss: 7.3465 - val_accuracy: 0.0999

on_epoch_begin: 1598505198.588781s

Real time: 1598505198.5887868
Epoch 3/5

on_train_batch_begin: 1598505198.592118s

on_train_batch_end: 1598505198.944330s

 1024/50000 [..............................] - ETA: 17s - loss: 3.7691 - accuracy: 0.0870
on_train_batch_begin: 1598505198.944557s

1 step training time: 0.352439s

on_train_batch_end: 1598505199.296527s

 2048/50000 [>.............................] - ETA: 16s - loss: 3.7756 - accuracy: 0.0882
on_train_batch_begin: 1598505199.296745s

2 step training time: 0.352188s

on_train_batch_end: 1598505199.657922s

 3072/50000 [>.............................] - ETA: 16s - loss: 3.7683 - accuracy: 0.0887
on_train_batch_begin: 1598505199.658143s

3 step training time: 0.361399s

on_train_batch_end: 1598505200.014807s

 4096/50000 [=>............................] - ETA: 15s - loss: 3.7092 - accuracy: 0.0900
on_train_batch_begin: 1598505200.015045s

4 step training time: 0.356902s

on_train_batch_end: 1598505200.368461s

 5120/50000 [==>...........................] - ETA: 15s - loss: 3.6770 - accuracy: 0.0904
on_train_batch_begin: 1598505200.368678s

5 step training time: 0.353632s

on_train_batch_end: 1598505200.722904s

 6144/50000 [==>...........................] - ETA: 15s - loss: 3.5912 - accuracy: 0.0912
on_train_batch_begin: 1598505200.723159s

6 step training time: 0.354481s

on_train_batch_end: 1598505201.076688s

 7168/50000 [===>..........................] - ETA: 14s - loss: 3.5727 - accuracy: 0.0916
on_train_batch_begin: 1598505201.076942s

7 step training time: 0.353784s

on_train_batch_end: 1598505201.434741s

 8192/50000 [===>..........................] - ETA: 14s - loss: 3.5727 - accuracy: 0.0920
on_train_batch_begin: 1598505201.434977s

8 step training time: 0.358034s

on_train_batch_end: 1598505201.790349s

 9216/50000 [====>.........................] - ETA: 14s - loss: 3.5577 - accuracy: 0.0925
on_train_batch_begin: 1598505201.790669s

9 step training time: 0.355693s

on_train_batch_end: 1598505202.146167s

10240/50000 [=====>........................] - ETA: 13s - loss: 3.5380 - accuracy: 0.0927
on_train_batch_begin: 1598505202.146474s

10 step training time: 0.355805s

on_train_batch_end: 1598505202.503268s

11264/50000 [=====>........................] - ETA: 13s - loss: 3.5073 - accuracy: 0.0928
on_train_batch_begin: 1598505202.503558s

11 step training time: 0.357084s

on_train_batch_end: 1598505202.860661s

12288/50000 [======>.......................] - ETA: 13s - loss: 3.4702 - accuracy: 0.0930
on_train_batch_begin: 1598505202.860945s

12 step training time: 0.357387s

on_train_batch_end: 1598505203.215420s

13312/50000 [======>.......................] - ETA: 12s - loss: 3.4437 - accuracy: 0.0932
on_train_batch_begin: 1598505203.215726s

13 step training time: 0.354781s

on_train_batch_end: 1598505203.573418s

14336/50000 [=======>......................] - ETA: 12s - loss: 3.4201 - accuracy: 0.0934
on_train_batch_begin: 1598505203.573669s

14 step training time: 0.357944s

on_train_batch_end: 1598505203.933155s

15360/50000 [========>.....................] - ETA: 12s - loss: 3.3843 - accuracy: 0.0937
on_train_batch_begin: 1598505203.933439s

15 step training time: 0.359770s

on_train_batch_end: 1598505204.288630s

16384/50000 [========>.....................] - ETA: 11s - loss: 3.3496 - accuracy: 0.0941
on_train_batch_begin: 1598505204.288911s

16 step training time: 0.355472s

on_train_batch_end: 1598505204.646015s

17408/50000 [=========>....................] - ETA: 11s - loss: 3.3067 - accuracy: 0.0944
on_train_batch_begin: 1598505204.646291s

17 step training time: 0.357379s

on_train_batch_end: 1598505205.003124s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.2713 - accuracy: 0.0947
on_train_batch_begin: 1598505205.003414s

18 step training time: 0.357124s

on_train_batch_end: 1598505205.362613s

19456/50000 [==========>...................] - ETA: 10s - loss: 3.2315 - accuracy: 0.0950
on_train_batch_begin: 1598505205.362892s

19 step training time: 0.359478s

on_train_batch_end: 1598505205.721287s

20480/50000 [===========>..................] - ETA: 10s - loss: 3.2001 - accuracy: 0.0952
on_train_batch_begin: 1598505205.721564s

20 step training time: 0.358671s

on_train_batch_end: 1598505206.078267s

21504/50000 [===========>..................] - ETA: 9s - loss: 3.1727 - accuracy: 0.0954 
on_train_batch_begin: 1598505206.078556s

21 step training time: 0.356992s

on_train_batch_end: 1598505206.435857s

22528/50000 [============>.................] - ETA: 9s - loss: 3.1406 - accuracy: 0.0956
on_train_batch_begin: 1598505206.436100s

22 step training time: 0.357544s

on_train_batch_end: 1598505206.794906s

23552/50000 [=============>................] - ETA: 9s - loss: 3.1147 - accuracy: 0.0958
on_train_batch_begin: 1598505206.795230s

23 step training time: 0.359130s

on_train_batch_end: 1598505207.156217s

24576/50000 [=============>................] - ETA: 8s - loss: 3.0914 - accuracy: 0.0959
on_train_batch_begin: 1598505207.156516s

24 step training time: 0.361285s

on_train_batch_end: 1598505207.513556s

25600/50000 [==============>...............] - ETA: 8s - loss: 3.0549 - accuracy: 0.0961
on_train_batch_begin: 1598505207.513841s

25 step training time: 0.357325s

on_train_batch_end: 1598505207.873575s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.0212 - accuracy: 0.0963
on_train_batch_begin: 1598505207.873817s

26 step training time: 0.359977s

on_train_batch_end: 1598505208.233303s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.9934 - accuracy: 0.0965
on_train_batch_begin: 1598505208.233566s

27 step training time: 0.359749s

on_train_batch_end: 1598505208.590563s

28672/50000 [================>.............] - ETA: 7s - loss: 2.9768 - accuracy: 0.0966
on_train_batch_begin: 1598505208.590825s

28 step training time: 0.357259s

on_train_batch_end: 1598505208.949423s

29696/50000 [================>.............] - ETA: 7s - loss: 2.9575 - accuracy: 0.0967
on_train_batch_begin: 1598505208.949658s

29 step training time: 0.358834s

on_train_batch_end: 1598505209.307200s

30720/50000 [=================>............] - ETA: 6s - loss: 2.9343 - accuracy: 0.0969
on_train_batch_begin: 1598505209.307461s

30 step training time: 0.357803s

on_train_batch_end: 1598505209.667037s

31744/50000 [==================>...........] - ETA: 6s - loss: 2.9134 - accuracy: 0.0970
on_train_batch_begin: 1598505209.667280s

31 step training time: 0.359819s

on_train_batch_end: 1598505210.024879s

32768/50000 [==================>...........] - ETA: 6s - loss: 2.8962 - accuracy: 0.0971
on_train_batch_begin: 1598505210.025131s

32 step training time: 0.357851s

on_train_batch_end: 1598505210.385919s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.8733 - accuracy: 0.0972
on_train_batch_begin: 1598505210.386186s

33 step training time: 0.361055s

on_train_batch_end: 1598505210.745636s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.8526 - accuracy: 0.0973
on_train_batch_begin: 1598505210.745909s

34 step training time: 0.359723s

on_train_batch_end: 1598505211.101111s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.8318 - accuracy: 0.0974
on_train_batch_begin: 1598505211.101380s

35 step training time: 0.355472s

on_train_batch_end: 1598505211.459696s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.8192 - accuracy: 0.0975
on_train_batch_begin: 1598505211.459965s

36 step training time: 0.358584s

on_train_batch_end: 1598505211.823831s

37888/50000 [=====================>........] - ETA: 4s - loss: 2.8050 - accuracy: 0.0975
on_train_batch_begin: 1598505211.824164s

37 step training time: 0.364199s

on_train_batch_end: 1598505212.183056s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.7885 - accuracy: 0.0976
on_train_batch_begin: 1598505212.183354s

38 step training time: 0.359190s

on_train_batch_end: 1598505212.541746s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.7731 - accuracy: 0.0976
on_train_batch_begin: 1598505212.542040s

39 step training time: 0.358686s

on_train_batch_end: 1598505212.902390s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.7589 - accuracy: 0.0977
on_train_batch_begin: 1598505212.902675s

40 step training time: 0.360635s

on_train_batch_end: 1598505213.266884s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.7397 - accuracy: 0.0977
on_train_batch_begin: 1598505213.267130s

41 step training time: 0.364455s

on_train_batch_end: 1598505213.627128s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.7231 - accuracy: 0.0978
on_train_batch_begin: 1598505213.627392s

42 step training time: 0.360262s

on_train_batch_end: 1598505213.987153s

44032/50000 [=========================>....] - ETA: 2s - loss: 2.7066 - accuracy: 0.0979
on_train_batch_begin: 1598505213.987398s

43 step training time: 0.360007s

on_train_batch_end: 1598505214.345097s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.6957 - accuracy: 0.0979
on_train_batch_begin: 1598505214.345387s

44 step training time: 0.357988s

on_train_batch_end: 1598505214.705662s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.6784 - accuracy: 0.0980
on_train_batch_begin: 1598505214.705934s

45 step training time: 0.360548s

on_train_batch_end: 1598505215.068375s

47104/50000 [===========================>..] - ETA: 1s - loss: 2.6593 - accuracy: 0.0980
on_train_batch_begin: 1598505215.068618s

46 step training time: 0.362684s

on_train_batch_end: 1598505215.430883s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.6453 - accuracy: 0.0981
on_train_batch_begin: 1598505215.431154s

47 step training time: 0.362536s

on_train_batch_end: 1598505215.788891s

49152/50000 [============================>.] - ETA: 0s - loss: 2.6286 - accuracy: 0.0981
on_train_batch_begin: 1598505215.789227s

48 step training time: 0.358073s

on_train_batch_end: 1598505216.083349s

on_test_batch_begin: 1598505216.098762s

49 step training time: 0.309535s

on_epoch_end: 1598505216.953055s

Validation time: 0.854282s

Real time: 1598505216.953055s

Epoch time: 18.36428713798523s

50000/50000 [==============================] - 18s 367us/sample - loss: 2.6145 - accuracy: 0.0982 - val_loss: 7.6450 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598505216.953258s

Real time: 1598505216.953263
Epoch 4/5

on_train_batch_begin: 1598505216.956660s

on_train_batch_end: 1598505217.314882s

 1024/50000 [..............................] - ETA: 17s - loss: 1.7483 - accuracy: 0.0999
on_train_batch_begin: 1598505217.315090s

1 step training time: 0.358430s

on_train_batch_end: 1598505217.672894s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.7812 - accuracy: 0.1002
on_train_batch_begin: 1598505217.673095s

2 step training time: 0.358005s

on_train_batch_end: 1598505218.041063s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.8119 - accuracy: 0.1002
on_train_batch_begin: 1598505218.041346s

3 step training time: 0.368251s

on_train_batch_end: 1598505218.405796s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.7770 - accuracy: 0.1002
on_train_batch_begin: 1598505218.406033s

4 step training time: 0.364687s

on_train_batch_end: 1598505218.768391s

 5120/50000 [==>...........................] - ETA: 15s - loss: 1.7820 - accuracy: 0.1002
on_train_batch_begin: 1598505218.768587s

5 step training time: 0.362554s

on_train_batch_end: 1598505219.132985s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.7979 - accuracy: 0.1002
on_train_batch_begin: 1598505219.133179s

6 step training time: 0.364592s

on_train_batch_end: 1598505219.498115s

 7168/50000 [===>..........................] - ETA: 15s - loss: 1.7901 - accuracy: 0.1001
on_train_batch_begin: 1598505219.498307s

7 step training time: 0.365128s

on_train_batch_end: 1598505219.861542s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.7817 - accuracy: 0.1001
on_train_batch_begin: 1598505219.861749s

8 step training time: 0.363442s

on_train_batch_end: 1598505220.211606s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.7688 - accuracy: 0.1001
on_train_batch_begin: 1598505220.211843s

9 step training time: 0.350094s

on_train_batch_end: 1598505220.576937s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.7581 - accuracy: 0.1001
on_train_batch_begin: 1598505220.577152s

10 step training time: 0.365309s

on_train_batch_end: 1598505220.939463s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.7596 - accuracy: 0.1001
on_train_batch_begin: 1598505220.939710s

11 step training time: 0.362558s

on_train_batch_end: 1598505221.301824s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.7494 - accuracy: 0.1000
on_train_batch_begin: 1598505221.302044s

12 step training time: 0.362334s

on_train_batch_end: 1598505221.664601s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.7512 - accuracy: 0.1001
on_train_batch_begin: 1598505221.664859s

13 step training time: 0.362815s

on_train_batch_end: 1598505222.030288s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.7437 - accuracy: 0.1001
on_train_batch_begin: 1598505222.030547s

14 step training time: 0.365689s

on_train_batch_end: 1598505222.392939s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.7420 - accuracy: 0.1001
on_train_batch_begin: 1598505222.393167s

15 step training time: 0.362620s

on_train_batch_end: 1598505222.757133s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.7538 - accuracy: 0.1001
on_train_batch_begin: 1598505222.757360s

16 step training time: 0.364193s

on_train_batch_end: 1598505223.119175s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.7651 - accuracy: 0.1001
on_train_batch_begin: 1598505223.119399s

17 step training time: 0.362039s

on_train_batch_end: 1598505223.465535s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.7797 - accuracy: 0.1000
on_train_batch_begin: 1598505223.465780s

18 step training time: 0.346381s

on_train_batch_end: 1598505223.836087s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.7781 - accuracy: 0.1001
on_train_batch_begin: 1598505223.836316s

19 step training time: 0.370537s

on_train_batch_end: 1598505224.203841s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.7783 - accuracy: 0.1001
on_train_batch_begin: 1598505224.204118s

20 step training time: 0.367802s

on_train_batch_end: 1598505224.563512s

21504/50000 [===========>..................] - ETA: 10s - loss: 1.7742 - accuracy: 0.1001
on_train_batch_begin: 1598505224.563789s

21 step training time: 0.359671s

on_train_batch_end: 1598505224.924015s

22528/50000 [============>.................] - ETA: 9s - loss: 1.7728 - accuracy: 0.1001 
on_train_batch_begin: 1598505224.924265s

22 step training time: 0.360476s

on_train_batch_end: 1598505225.288251s

23552/50000 [=============>................] - ETA: 9s - loss: 1.7725 - accuracy: 0.1001
on_train_batch_begin: 1598505225.288501s

23 step training time: 0.364235s

on_train_batch_end: 1598505225.653672s

24576/50000 [=============>................] - ETA: 9s - loss: 1.7744 - accuracy: 0.1001
on_train_batch_begin: 1598505225.653932s

24 step training time: 0.365431s

on_train_batch_end: 1598505226.018715s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.7778 - accuracy: 0.1001
on_train_batch_begin: 1598505226.018962s

25 step training time: 0.365030s

on_train_batch_end: 1598505226.385782s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.7803 - accuracy: 0.1001
on_train_batch_begin: 1598505226.386026s

26 step training time: 0.367064s

on_train_batch_end: 1598505226.750060s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.7756 - accuracy: 0.1001
on_train_batch_begin: 1598505226.750327s

27 step training time: 0.364301s

on_train_batch_end: 1598505227.116501s

28672/50000 [================>.............] - ETA: 7s - loss: 1.7675 - accuracy: 0.1001
on_train_batch_begin: 1598505227.116761s

28 step training time: 0.366434s

on_train_batch_end: 1598505227.482837s

29696/50000 [================>.............] - ETA: 7s - loss: 1.7615 - accuracy: 0.1001
on_train_batch_begin: 1598505227.483087s

29 step training time: 0.366326s

on_train_batch_end: 1598505227.847268s

30720/50000 [=================>............] - ETA: 6s - loss: 1.7557 - accuracy: 0.1001
on_train_batch_begin: 1598505227.847511s

30 step training time: 0.364424s

on_train_batch_end: 1598505228.212479s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.7513 - accuracy: 0.1001
on_train_batch_begin: 1598505228.212719s

31 step training time: 0.365209s

on_train_batch_end: 1598505228.577972s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.7448 - accuracy: 0.1001
on_train_batch_begin: 1598505228.578196s

32 step training time: 0.365476s

on_train_batch_end: 1598505228.944820s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.7417 - accuracy: 0.1001
on_train_batch_begin: 1598505228.945058s

33 step training time: 0.366862s

on_train_batch_end: 1598505229.312203s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.7373 - accuracy: 0.1001
on_train_batch_begin: 1598505229.312448s

34 step training time: 0.367390s

on_train_batch_end: 1598505229.677302s

35840/50000 [====================>.........] - ETA: 5s - loss: 1.7333 - accuracy: 0.1001
on_train_batch_begin: 1598505229.677522s

35 step training time: 0.365074s

on_train_batch_end: 1598505230.044411s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.7328 - accuracy: 0.1001
on_train_batch_begin: 1598505230.044761s

36 step training time: 0.367239s

on_train_batch_end: 1598505230.411193s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.7281 - accuracy: 0.1001
on_train_batch_begin: 1598505230.411503s

37 step training time: 0.366742s

on_train_batch_end: 1598505230.775815s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.7224 - accuracy: 0.1001
on_train_batch_begin: 1598505230.776079s

38 step training time: 0.364576s

on_train_batch_end: 1598505231.140070s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.7185 - accuracy: 0.1001
on_train_batch_begin: 1598505231.140299s

39 step training time: 0.364219s

on_train_batch_end: 1598505231.507869s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.7175 - accuracy: 0.1002
on_train_batch_begin: 1598505231.508108s

40 step training time: 0.367809s

on_train_batch_end: 1598505231.872736s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.7117 - accuracy: 0.1001
on_train_batch_begin: 1598505231.872999s

41 step training time: 0.364892s

on_train_batch_end: 1598505232.238644s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.7041 - accuracy: 0.1002
on_train_batch_begin: 1598505232.238903s

42 step training time: 0.365903s

on_train_batch_end: 1598505232.606040s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.7004 - accuracy: 0.1001
on_train_batch_begin: 1598505232.606293s

43 step training time: 0.367391s

on_train_batch_end: 1598505232.969810s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.6902 - accuracy: 0.1002
on_train_batch_begin: 1598505232.970060s

44 step training time: 0.363767s

on_train_batch_end: 1598505233.337298s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.6821 - accuracy: 0.1002
on_train_batch_begin: 1598505233.337546s

45 step training time: 0.367486s

on_train_batch_end: 1598505233.705434s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.6762 - accuracy: 0.1002
on_train_batch_begin: 1598505233.705660s

46 step training time: 0.368114s

on_train_batch_end: 1598505234.069284s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.6725 - accuracy: 0.1002
on_train_batch_begin: 1598505234.069515s

47 step training time: 0.363855s

on_train_batch_end: 1598505234.435467s

49152/50000 [============================>.] - ETA: 0s - loss: 1.6667 - accuracy: 0.1002
on_train_batch_begin: 1598505234.435714s

48 step training time: 0.366199s

on_train_batch_end: 1598505234.738309s

on_test_batch_begin: 1598505234.755578s

49 step training time: 0.319864s

on_epoch_end: 1598505235.621634s

Validation time: 0.866046s

Real time: 1598505235.621634s

Epoch time: 18.66838526725769s

50000/50000 [==============================] - 19s 373us/sample - loss: 1.6608 - accuracy: 0.1002 - val_loss: 7.3734 - val_accuracy: 0.0999

on_epoch_begin: 1598505235.621806s

Real time: 1598505235.6218112
Epoch 5/5

on_train_batch_begin: 1598505235.625062s

on_train_batch_end: 1598505235.994221s

 1024/50000 [..............................] - ETA: 17s - loss: 1.1887 - accuracy: 0.1007
on_train_batch_begin: 1598505235.994432s

1 step training time: 0.369370s

on_train_batch_end: 1598505236.360996s

 2048/50000 [>.............................] - ETA: 17s - loss: 1.1870 - accuracy: 0.1005
on_train_batch_begin: 1598505236.361202s

2 step training time: 0.366769s

on_train_batch_end: 1598505236.729897s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.1854 - accuracy: 0.1004
on_train_batch_begin: 1598505236.730097s

3 step training time: 0.368895s

on_train_batch_end: 1598505237.098295s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.1505 - accuracy: 0.1003
on_train_batch_begin: 1598505237.098509s

4 step training time: 0.368412s

on_train_batch_end: 1598505237.462888s

 5120/50000 [==>...........................] - ETA: 16s - loss: 1.1420 - accuracy: 0.1003
on_train_batch_begin: 1598505237.463113s

5 step training time: 0.364604s

on_train_batch_end: 1598505237.827262s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.1343 - accuracy: 0.1003
on_train_batch_begin: 1598505237.827487s

6 step training time: 0.364374s

on_train_batch_end: 1598505238.195404s

 7168/50000 [===>..........................] - ETA: 15s - loss: 1.1457 - accuracy: 0.1003
on_train_batch_begin: 1598505238.195615s

7 step training time: 0.368128s

on_train_batch_end: 1598505238.561502s

 8192/50000 [===>..........................] - ETA: 15s - loss: 1.1408 - accuracy: 0.1003
on_train_batch_begin: 1598505238.561720s

8 step training time: 0.366105s

on_train_batch_end: 1598505238.928092s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.1366 - accuracy: 0.1003
on_train_batch_begin: 1598505238.928314s

9 step training time: 0.366594s

on_train_batch_end: 1598505239.292422s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.1439 - accuracy: 0.1003
on_train_batch_begin: 1598505239.292649s

10 step training time: 0.364335s

on_train_batch_end: 1598505239.661122s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.1508 - accuracy: 0.1004
on_train_batch_begin: 1598505239.661337s

11 step training time: 0.368688s

on_train_batch_end: 1598505240.029155s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.1570 - accuracy: 0.1004
on_train_batch_begin: 1598505240.029400s

12 step training time: 0.368063s

on_train_batch_end: 1598505240.397067s

13312/50000 [======>.......................] - ETA: 13s - loss: 1.1650 - accuracy: 0.1004
on_train_batch_begin: 1598505240.397294s

13 step training time: 0.367894s

on_train_batch_end: 1598505240.766467s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.1642 - accuracy: 0.1004
on_train_batch_begin: 1598505240.766710s

14 step training time: 0.369416s

on_train_batch_end: 1598505241.136319s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.1674 - accuracy: 0.1003
on_train_batch_begin: 1598505241.136559s

15 step training time: 0.369848s

on_train_batch_end: 1598505241.506720s

16384/50000 [========>.....................] - ETA: 12s - loss: 1.1722 - accuracy: 0.1003
on_train_batch_begin: 1598505241.506989s

16 step training time: 0.370430s

on_train_batch_end: 1598505241.876642s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.1748 - accuracy: 0.1003
on_train_batch_begin: 1598505241.876911s

17 step training time: 0.369922s

on_train_batch_end: 1598505242.245731s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.1808 - accuracy: 0.1003
on_train_batch_begin: 1598505242.245987s

18 step training time: 0.369075s

on_train_batch_end: 1598505242.612847s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.1855 - accuracy: 0.1003
on_train_batch_begin: 1598505242.613094s

19 step training time: 0.367107s

on_train_batch_end: 1598505242.982511s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.1845 - accuracy: 0.1003
on_train_batch_begin: 1598505242.982753s

20 step training time: 0.369658s

on_train_batch_end: 1598505243.354451s

21504/50000 [===========>..................] - ETA: 10s - loss: 1.1801 - accuracy: 0.1003
on_train_batch_begin: 1598505243.354695s

21 step training time: 0.371942s

on_train_batch_end: 1598505243.721511s

22528/50000 [============>.................] - ETA: 9s - loss: 1.1818 - accuracy: 0.1003 
on_train_batch_begin: 1598505243.721734s

22 step training time: 0.367039s

on_train_batch_end: 1598505244.089705s

23552/50000 [=============>................] - ETA: 9s - loss: 1.1765 - accuracy: 0.1003
on_train_batch_begin: 1598505244.089927s

23 step training time: 0.368193s

on_train_batch_end: 1598505244.460434s

24576/50000 [=============>................] - ETA: 9s - loss: 1.1725 - accuracy: 0.1003
on_train_batch_begin: 1598505244.460667s

24 step training time: 0.370740s

on_train_batch_end: 1598505244.830741s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.1682 - accuracy: 0.1003
on_train_batch_begin: 1598505244.831000s

25 step training time: 0.370333s

on_train_batch_end: 1598505245.200779s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.1694 - accuracy: 0.1003
on_train_batch_begin: 1598505245.201005s

26 step training time: 0.370006s

on_train_batch_end: 1598505245.568962s

27648/50000 [===============>..............] - ETA: 8s - loss: 1.1687 - accuracy: 0.1003
on_train_batch_begin: 1598505245.569193s

27 step training time: 0.368188s

on_train_batch_end: 1598505245.940245s

28672/50000 [================>.............] - ETA: 7s - loss: 1.1727 - accuracy: 0.1003
on_train_batch_begin: 1598505245.940486s

28 step training time: 0.371294s

on_train_batch_end: 1598505246.310148s

29696/50000 [================>.............] - ETA: 7s - loss: 1.1671 - accuracy: 0.1003
on_train_batch_begin: 1598505246.310384s

29 step training time: 0.369897s

on_train_batch_end: 1598505246.679146s

30720/50000 [=================>............] - ETA: 6s - loss: 1.1678 - accuracy: 0.1003
on_train_batch_begin: 1598505246.679361s

30 step training time: 0.368978s

on_train_batch_end: 1598505247.051013s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.1712 - accuracy: 0.1003
on_train_batch_begin: 1598505247.051272s

31 step training time: 0.371911s

on_train_batch_end: 1598505247.416813s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.1671 - accuracy: 0.1003
on_train_batch_begin: 1598505247.417048s

32 step training time: 0.365776s

on_train_batch_end: 1598505247.785706s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.1689 - accuracy: 0.1003
on_train_batch_begin: 1598505247.785945s

33 step training time: 0.368898s

on_train_batch_end: 1598505248.158594s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.1674 - accuracy: 0.1003
on_train_batch_begin: 1598505248.158832s

34 step training time: 0.372887s

on_train_batch_end: 1598505248.527659s

35840/50000 [====================>.........] - ETA: 5s - loss: 1.1667 - accuracy: 0.1003
on_train_batch_begin: 1598505248.527878s

35 step training time: 0.369046s

on_train_batch_end: 1598505248.897431s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.1670 - accuracy: 0.1003
on_train_batch_begin: 1598505248.897663s

36 step training time: 0.369785s

on_train_batch_end: 1598505249.269688s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.1653 - accuracy: 0.1003
on_train_batch_begin: 1598505249.269906s

37 step training time: 0.372243s

on_train_batch_end: 1598505249.642214s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.1658 - accuracy: 0.1003
on_train_batch_begin: 1598505249.642439s

38 step training time: 0.372533s

on_train_batch_end: 1598505250.013558s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.1638 - accuracy: 0.1003
on_train_batch_begin: 1598505250.013804s

39 step training time: 0.371365s

on_train_batch_end: 1598505250.384674s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.1628 - accuracy: 0.1003
on_train_batch_begin: 1598505250.384904s

40 step training time: 0.371099s

on_train_batch_end: 1598505250.756611s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.1620 - accuracy: 0.1003
on_train_batch_begin: 1598505250.756837s

41 step training time: 0.371933s

on_train_batch_end: 1598505251.130172s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.1609 - accuracy: 0.1003
on_train_batch_begin: 1598505251.130422s

42 step training time: 0.373585s

on_train_batch_end: 1598505251.501726s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.1641 - accuracy: 0.1003
on_train_batch_begin: 1598505251.501970s

43 step training time: 0.371548s

on_train_batch_end: 1598505251.873626s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.1627 - accuracy: 0.1003
on_train_batch_begin: 1598505251.873990s

44 step training time: 0.372020s

on_train_batch_end: 1598505252.246295s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.1586 - accuracy: 0.1003
on_train_batch_begin: 1598505252.246590s

45 step training time: 0.372600s

on_train_batch_end: 1598505252.615968s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.1547 - accuracy: 0.1003
on_train_batch_begin: 1598505252.616178s

46 step training time: 0.369589s

on_train_batch_end: 1598505252.989677s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1522 - accuracy: 0.1003
on_train_batch_begin: 1598505252.989960s

47 step training time: 0.373782s

on_train_batch_end: 1598505253.357769s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1508 - accuracy: 0.1003
on_train_batch_begin: 1598505253.358047s

48 step training time: 0.368087s

on_train_batch_end: 1598505253.667157s

on_test_batch_begin: 1598505253.681178s

49 step training time: 0.323131s

on_epoch_end: 1598505254.556278s

Validation time: 0.875089s

Real time: 1598505254.556278s

Epoch time: 18.934486150741577s

50000/50000 [==============================] - 19s 379us/sample - loss: 1.1500 - accuracy: 0.1003 - val_loss: 6.8611 - val_accuracy: 0.1001
Tempo do fit: 122.58453059196472