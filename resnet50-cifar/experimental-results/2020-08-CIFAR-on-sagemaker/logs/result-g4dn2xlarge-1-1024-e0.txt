wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:58
   188416/170498071 [..............................] - ETA: 1:06
   811008/170498071 [..............................] - ETA: 25s 
  2334720/170498071 [..............................] - ETA: 12s
  5545984/170498071 [..............................] - ETA: 6s 
  8765440/170498071 [>.............................] - ETA: 5s
 11960320/170498071 [=>............................] - ETA: 4s
 15114240/170498071 [=>............................] - ETA: 3s
 18325504/170498071 [==>...........................] - ETA: 3s
 21536768/170498071 [==>...........................] - ETA: 3s
 24748032/170498071 [===>..........................] - ETA: 3s
 27942912/170498071 [===>..........................] - ETA: 2s
 31170560/170498071 [====>.........................] - ETA: 2s
 34398208/170498071 [=====>........................] - ETA: 2s
 37617664/170498071 [=====>........................] - ETA: 2s
 40804352/170498071 [======>.......................] - ETA: 2s
 42721280/170498071 [======>.......................] - ETA: 2s
 47046656/170498071 [=======>......................] - ETA: 2s
 50266112/170498071 [=======>......................] - ETA: 2s
 53403648/170498071 [========>.....................] - ETA: 2s
 56598528/170498071 [========>.....................] - ETA: 2s
 59711488/170498071 [=========>....................] - ETA: 2s
 62922752/170498071 [==========>...................] - ETA: 1s
 66109440/170498071 [==========>...................] - ETA: 1s
 69328896/170498071 [===========>..................] - ETA: 1s
 72474624/170498071 [===========>..................] - ETA: 1s
 75603968/170498071 [============>.................] - ETA: 1s
 78807040/170498071 [============>.................] - ETA: 1s
 81993728/170498071 [=============>................] - ETA: 1s
 85123072/170498071 [=============>................] - ETA: 1s
 88350720/170498071 [==============>...............] - ETA: 1s
 91512832/170498071 [===============>..............] - ETA: 1s
 94609408/170498071 [===============>..............] - ETA: 1s
 97771520/170498071 [================>.............] - ETA: 1s
100950016/170498071 [================>.............] - ETA: 1s
104161280/170498071 [=================>............] - ETA: 1s
107339776/170498071 [=================>............] - ETA: 1s
110551040/170498071 [==================>...........] - ETA: 1s
113729536/170498071 [===================>..........] - ETA: 0s
116924416/170498071 [===================>..........] - ETA: 0s
120102912/170498071 [====================>.........] - ETA: 0s
123297792/170498071 [====================>.........] - ETA: 0s
126476288/170498071 [=====================>........] - ETA: 0s
129671168/170498071 [=====================>........] - ETA: 0s
132882432/170498071 [======================>.......] - ETA: 0s
136077312/170498071 [======================>.......] - ETA: 0s
139239424/170498071 [=======================>......] - ETA: 0s
142434304/170498071 [========================>.....] - ETA: 0s
145612800/170498071 [========================>.....] - ETA: 0s
148807680/170498071 [=========================>....] - ETA: 0s
152035328/170498071 [=========================>....] - ETA: 0s
155222016/170498071 [==========================>...] - ETA: 0s
158425088/170498071 [==========================>...] - ETA: 0s
161619968/170498071 [===========================>..] - ETA: 0s
164831232/170498071 [============================>.] - ETA: 0s
168026112/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 6s
 5611520/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
16850944/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 1s
19234816/94765736 [=====>........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
35184640/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 0s
54247424/94765736 [================>.............] - ETA: 0s
59441152/94765736 [=================>............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
66510848/94765736 [====================>.........] - ETA: 0s
68870144/94765736 [====================>.........] - ETA: 0s
75014144/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.6770920753479
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598492589.122293s

Real time: 1598492589.1223114
Epoch 1/5

on_train_batch_begin: 1598492589.877620s

on_train_batch_end: 1598492606.892673s

 1024/50000 [..............................] - ETA: 14:09 - loss: 17.9534 - accuracy: 1.8024e-04
on_train_batch_begin: 1598492606.893265s

1 step training time: 17.015646s

on_train_batch_end: 1598492607.225196s

 2048/50000 [>.............................] - ETA: 7:03 - loss: 15.8424 - accuracy: 1.3685e-04 
on_train_batch_begin: 1598492607.225505s

2 step training time: 0.332240s

on_train_batch_end: 1598492607.558428s

 3072/50000 [>.............................] - ETA: 4:41 - loss: 13.6702 - accuracy: 1.9042e-04
on_train_batch_begin: 1598492607.558709s

3 step training time: 0.333204s

on_train_batch_end: 1598492607.891943s

 4096/50000 [=>............................] - ETA: 3:30 - loss: 12.3229 - accuracy: 6.4516e-04
on_train_batch_begin: 1598492607.892223s

4 step training time: 0.333513s

on_train_batch_end: 1598492608.221778s

 5120/50000 [==>...........................] - ETA: 2:47 - loss: 11.4954 - accuracy: 0.0023    
on_train_batch_begin: 1598492608.222064s

5 step training time: 0.329841s

on_train_batch_end: 1598492608.557471s

 6144/50000 [==>...........................] - ETA: 2:18 - loss: 10.9208 - accuracy: 0.0056
on_train_batch_begin: 1598492608.557763s

6 step training time: 0.335699s

on_train_batch_end: 1598492608.891116s

 7168/50000 [===>..........................] - ETA: 1:58 - loss: 10.4851 - accuracy: 0.0095
on_train_batch_begin: 1598492608.891412s

7 step training time: 0.333649s

on_train_batch_end: 1598492609.218895s

 8192/50000 [===>..........................] - ETA: 1:42 - loss: 10.1575 - accuracy: 0.0131
on_train_batch_begin: 1598492609.219202s

8 step training time: 0.327790s

on_train_batch_end: 1598492609.553363s

 9216/50000 [====>.........................] - ETA: 1:30 - loss: 9.8821 - accuracy: 0.0160 
on_train_batch_begin: 1598492609.553646s

9 step training time: 0.334444s

on_train_batch_end: 1598492609.886909s

10240/50000 [=====>........................] - ETA: 1:20 - loss: 9.6577 - accuracy: 0.0200
on_train_batch_begin: 1598492609.887192s

10 step training time: 0.333546s

on_train_batch_end: 1598492610.215798s

11264/50000 [=====>........................] - ETA: 1:12 - loss: 9.4566 - accuracy: 0.0227
on_train_batch_begin: 1598492610.216100s

11 step training time: 0.328908s

on_train_batch_end: 1598492610.552739s

12288/50000 [======>.......................] - ETA: 1:05 - loss: 9.2781 - accuracy: 0.0256
on_train_batch_begin: 1598492610.553029s

12 step training time: 0.336929s

on_train_batch_end: 1598492610.884041s

13312/50000 [======>.......................] - ETA: 59s - loss: 9.1198 - accuracy: 0.0294 
on_train_batch_begin: 1598492610.884341s

13 step training time: 0.331312s

on_train_batch_end: 1598492611.213085s

14336/50000 [=======>......................] - ETA: 54s - loss: 8.9801 - accuracy: 0.0323
on_train_batch_begin: 1598492611.213388s

14 step training time: 0.329048s

on_train_batch_end: 1598492611.547750s

15360/50000 [========>.....................] - ETA: 50s - loss: 8.8632 - accuracy: 0.0347
on_train_batch_begin: 1598492611.548032s

15 step training time: 0.334644s

on_train_batch_end: 1598492611.881183s

16384/50000 [========>.....................] - ETA: 46s - loss: 8.7451 - accuracy: 0.0370
on_train_batch_begin: 1598492611.881476s

16 step training time: 0.333444s

on_train_batch_end: 1598492612.213203s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.6458 - accuracy: 0.0393
on_train_batch_begin: 1598492612.213530s

17 step training time: 0.332053s

on_train_batch_end: 1598492612.546562s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.5559 - accuracy: 0.0413
on_train_batch_begin: 1598492612.546856s

18 step training time: 0.333326s

on_train_batch_end: 1598492612.879211s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.4651 - accuracy: 0.0431
on_train_batch_begin: 1598492612.879504s

19 step training time: 0.332648s

on_train_batch_end: 1598492613.216619s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.3799 - accuracy: 0.0453
on_train_batch_begin: 1598492613.216916s

20 step training time: 0.337412s

on_train_batch_end: 1598492613.550120s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.3018 - accuracy: 0.0468
on_train_batch_begin: 1598492613.550451s

21 step training time: 0.333535s

on_train_batch_end: 1598492613.884692s

22528/50000 [============>.................] - ETA: 30s - loss: 8.2250 - accuracy: 0.0478
on_train_batch_begin: 1598492613.884997s

22 step training time: 0.334546s

on_train_batch_end: 1598492614.225233s

23552/50000 [=============>................] - ETA: 28s - loss: 8.1592 - accuracy: 0.0493
on_train_batch_begin: 1598492614.225524s

23 step training time: 0.340527s

on_train_batch_end: 1598492614.560168s

24576/50000 [=============>................] - ETA: 26s - loss: 8.0926 - accuracy: 0.0501
on_train_batch_begin: 1598492614.560496s

24 step training time: 0.334972s

on_train_batch_end: 1598492614.894263s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.0328 - accuracy: 0.0508
on_train_batch_begin: 1598492614.894557s

25 step training time: 0.334060s

on_train_batch_end: 1598492615.232590s

26624/50000 [==============>...............] - ETA: 22s - loss: 7.9752 - accuracy: 0.0515
on_train_batch_begin: 1598492615.232902s

26 step training time: 0.338346s

on_train_batch_end: 1598492615.569694s

27648/50000 [===============>..............] - ETA: 21s - loss: 7.9175 - accuracy: 0.0525
on_train_batch_begin: 1598492615.570016s

27 step training time: 0.337114s

on_train_batch_end: 1598492615.905482s

28672/50000 [================>.............] - ETA: 19s - loss: 7.8628 - accuracy: 0.0534
on_train_batch_begin: 1598492615.905792s

28 step training time: 0.335776s

on_train_batch_end: 1598492616.238707s

29696/50000 [================>.............] - ETA: 18s - loss: 7.8100 - accuracy: 0.0537
on_train_batch_begin: 1598492616.239015s

29 step training time: 0.333223s

on_train_batch_end: 1598492616.577043s

30720/50000 [=================>............] - ETA: 17s - loss: 7.7599 - accuracy: 0.0542
on_train_batch_begin: 1598492616.577349s

30 step training time: 0.338334s

on_train_batch_end: 1598492616.910834s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.7087 - accuracy: 0.0546
on_train_batch_begin: 1598492616.911141s

31 step training time: 0.333792s

on_train_batch_end: 1598492617.248553s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.6580 - accuracy: 0.0553
on_train_batch_begin: 1598492617.248856s

32 step training time: 0.337715s

on_train_batch_end: 1598492617.582474s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.6075 - accuracy: 0.0555
on_train_batch_begin: 1598492617.582784s

33 step training time: 0.333928s

on_train_batch_end: 1598492617.918694s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.5604 - accuracy: 0.0561
on_train_batch_begin: 1598492617.919001s

34 step training time: 0.336217s

on_train_batch_end: 1598492618.252970s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.5122 - accuracy: 0.0568
on_train_batch_begin: 1598492618.253275s

35 step training time: 0.334274s

on_train_batch_end: 1598492618.589959s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.4685 - accuracy: 0.0576
on_train_batch_begin: 1598492618.590298s

36 step training time: 0.337023s

on_train_batch_end: 1598492618.923928s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.4236 - accuracy: 0.0583 
on_train_batch_begin: 1598492618.924244s

37 step training time: 0.333946s

on_train_batch_end: 1598492619.261910s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.3802 - accuracy: 0.0587
on_train_batch_begin: 1598492619.262215s

38 step training time: 0.337971s

on_train_batch_end: 1598492619.599380s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.3386 - accuracy: 0.0593
on_train_batch_begin: 1598492619.599661s

39 step training time: 0.337446s

on_train_batch_end: 1598492619.932163s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.3001 - accuracy: 0.0597
on_train_batch_begin: 1598492619.932456s

40 step training time: 0.332795s

on_train_batch_end: 1598492620.266897s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.2560 - accuracy: 0.0599
on_train_batch_begin: 1598492620.267193s

41 step training time: 0.334737s

on_train_batch_end: 1598492620.604401s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.2135 - accuracy: 0.0601
on_train_batch_begin: 1598492620.604689s

42 step training time: 0.337496s

on_train_batch_end: 1598492620.940681s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.1766 - accuracy: 0.0603
on_train_batch_begin: 1598492620.940968s

43 step training time: 0.336279s

on_train_batch_end: 1598492621.274794s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.1419 - accuracy: 0.0604
on_train_batch_begin: 1598492621.275102s

44 step training time: 0.334133s

on_train_batch_end: 1598492621.613798s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.1027 - accuracy: 0.0606
on_train_batch_begin: 1598492621.614081s

45 step training time: 0.338979s

on_train_batch_end: 1598492621.952849s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.0653 - accuracy: 0.0606
on_train_batch_begin: 1598492621.953133s

46 step training time: 0.339052s

on_train_batch_end: 1598492622.288528s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.0304 - accuracy: 0.0607
on_train_batch_begin: 1598492622.288815s

47 step training time: 0.335682s

on_train_batch_end: 1598492622.626417s

49152/50000 [============================>.] - ETA: 0s - loss: 6.9997 - accuracy: 0.0607
on_train_batch_begin: 1598492622.626709s

48 step training time: 0.337894s

on_train_batch_end: 1598492628.705839s

on_test_batch_begin: 1598492628.889639s

49 step training time: 6.262930s

on_epoch_end: 1598492633.591563s

Validation time: 4.701910s

Real time: 1598492633.591563s

Epoch time: 44.46927094459534s

50000/50000 [==============================] - 44s 889us/sample - loss: 6.9701 - accuracy: 0.0607 - val_loss: 44256.7499 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598492633.591781s

Real time: 1598492633.591787
Epoch 2/5

on_train_batch_begin: 1598492633.595179s

on_train_batch_end: 1598492633.938046s

 1024/50000 [..............................] - ETA: 16s - loss: 5.3030 - accuracy: 0.0649
on_train_batch_begin: 1598492633.938362s

1 step training time: 0.343183s

on_train_batch_end: 1598492634.279416s

 2048/50000 [>.............................] - ETA: 16s - loss: 5.1861 - accuracy: 0.0669
on_train_batch_begin: 1598492634.279727s

2 step training time: 0.341365s

on_train_batch_end: 1598492634.616683s

 3072/50000 [>.............................] - ETA: 15s - loss: 5.2264 - accuracy: 0.0696
on_train_batch_begin: 1598492634.616974s

3 step training time: 0.337247s

on_train_batch_end: 1598492634.961042s

 4096/50000 [=>............................] - ETA: 15s - loss: 5.2064 - accuracy: 0.0706
on_train_batch_begin: 1598492634.961346s

4 step training time: 0.344372s

on_train_batch_end: 1598492635.320399s

 5120/50000 [==>...........................] - ETA: 15s - loss: 5.1871 - accuracy: 0.0713
on_train_batch_begin: 1598492635.320705s

5 step training time: 0.359359s

on_train_batch_end: 1598492635.662818s

 6144/50000 [==>...........................] - ETA: 14s - loss: 5.1615 - accuracy: 0.0731
on_train_batch_begin: 1598492635.663114s

6 step training time: 0.342410s

on_train_batch_end: 1598492636.002703s

 7168/50000 [===>..........................] - ETA: 14s - loss: 5.1672 - accuracy: 0.0741
on_train_batch_begin: 1598492636.002993s

7 step training time: 0.339879s

on_train_batch_end: 1598492636.343887s

 8192/50000 [===>..........................] - ETA: 14s - loss: 5.1411 - accuracy: 0.0750
on_train_batch_begin: 1598492636.344178s

8 step training time: 0.341185s

on_train_batch_end: 1598492636.687622s

 9216/50000 [====>.........................] - ETA: 13s - loss: 5.1407 - accuracy: 0.0751
on_train_batch_begin: 1598492636.687930s

9 step training time: 0.343752s

on_train_batch_end: 1598492637.030329s

10240/50000 [=====>........................] - ETA: 13s - loss: 5.1060 - accuracy: 0.0758
on_train_batch_begin: 1598492637.030642s

10 step training time: 0.342712s

on_train_batch_end: 1598492637.373375s

11264/50000 [=====>........................] - ETA: 13s - loss: 5.0949 - accuracy: 0.0761
on_train_batch_begin: 1598492637.373676s

11 step training time: 0.343034s

on_train_batch_end: 1598492637.716441s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.0854 - accuracy: 0.0753
on_train_batch_begin: 1598492637.716750s

12 step training time: 0.343074s

on_train_batch_end: 1598492638.059030s

13312/50000 [======>.......................] - ETA: 12s - loss: 5.0608 - accuracy: 0.0749
on_train_batch_begin: 1598492638.059350s

13 step training time: 0.342600s

on_train_batch_end: 1598492638.402112s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.0524 - accuracy: 0.0745
on_train_batch_begin: 1598492638.402419s

14 step training time: 0.343069s

on_train_batch_end: 1598492638.743503s

15360/50000 [========>.....................] - ETA: 11s - loss: 5.0367 - accuracy: 0.0744
on_train_batch_begin: 1598492638.743795s

15 step training time: 0.341377s

on_train_batch_end: 1598492639.081942s

16384/50000 [========>.....................] - ETA: 11s - loss: 5.0155 - accuracy: 0.0744
on_train_batch_begin: 1598492639.082246s

16 step training time: 0.338451s

on_train_batch_end: 1598492639.427492s

17408/50000 [=========>....................] - ETA: 10s - loss: 4.9901 - accuracy: 0.0742
on_train_batch_begin: 1598492639.427781s

17 step training time: 0.345535s

on_train_batch_end: 1598492639.770351s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.9779 - accuracy: 0.0742
on_train_batch_begin: 1598492639.770639s

18 step training time: 0.342858s

on_train_batch_end: 1598492640.115047s

19456/50000 [==========>...................] - ETA: 10s - loss: 4.9642 - accuracy: 0.0743
on_train_batch_begin: 1598492640.115336s

19 step training time: 0.344697s

on_train_batch_end: 1598492640.458876s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.9471 - accuracy: 0.0742 
on_train_batch_begin: 1598492640.459174s

20 step training time: 0.343838s

on_train_batch_end: 1598492640.802832s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.9260 - accuracy: 0.0741
on_train_batch_begin: 1598492640.803123s

21 step training time: 0.343949s

on_train_batch_end: 1598492641.147367s

22528/50000 [============>.................] - ETA: 9s - loss: 4.9139 - accuracy: 0.0738
on_train_batch_begin: 1598492641.147653s

22 step training time: 0.344530s

on_train_batch_end: 1598492641.492384s

23552/50000 [=============>................] - ETA: 8s - loss: 4.9153 - accuracy: 0.0733
on_train_batch_begin: 1598492641.492696s

23 step training time: 0.345043s

on_train_batch_end: 1598492641.837136s

24576/50000 [=============>................] - ETA: 8s - loss: 4.9065 - accuracy: 0.0731
on_train_batch_begin: 1598492641.837433s

24 step training time: 0.344737s

on_train_batch_end: 1598492642.185150s

25600/50000 [==============>...............] - ETA: 8s - loss: 4.8906 - accuracy: 0.0729
on_train_batch_begin: 1598492642.185436s

25 step training time: 0.348003s

on_train_batch_end: 1598492642.529995s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.8762 - accuracy: 0.0728
on_train_batch_begin: 1598492642.530289s

26 step training time: 0.344853s

on_train_batch_end: 1598492642.874169s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.8674 - accuracy: 0.0726
on_train_batch_begin: 1598492642.874449s

27 step training time: 0.344160s

on_train_batch_end: 1598492643.219271s

28672/50000 [================>.............] - ETA: 7s - loss: 4.8653 - accuracy: 0.0727
on_train_batch_begin: 1598492643.219578s

28 step training time: 0.345129s

on_train_batch_end: 1598492643.563251s

29696/50000 [================>.............] - ETA: 6s - loss: 4.8549 - accuracy: 0.0725
on_train_batch_begin: 1598492643.563551s

29 step training time: 0.343973s

on_train_batch_end: 1598492643.907493s

30720/50000 [=================>............] - ETA: 6s - loss: 4.8483 - accuracy: 0.0726
on_train_batch_begin: 1598492643.907807s

30 step training time: 0.344256s

on_train_batch_end: 1598492644.253444s

31744/50000 [==================>...........] - ETA: 6s - loss: 4.8416 - accuracy: 0.0725
on_train_batch_begin: 1598492644.253759s

31 step training time: 0.345952s

on_train_batch_end: 1598492644.597968s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.8379 - accuracy: 0.0723
on_train_batch_begin: 1598492644.598267s

32 step training time: 0.344507s

on_train_batch_end: 1598492644.943106s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.8325 - accuracy: 0.0722
on_train_batch_begin: 1598492644.943398s

33 step training time: 0.345132s

on_train_batch_end: 1598492645.288894s

34816/50000 [===================>..........] - ETA: 5s - loss: 4.8253 - accuracy: 0.0722
on_train_batch_begin: 1598492645.289182s

34 step training time: 0.345783s

on_train_batch_end: 1598492645.635350s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.8115 - accuracy: 0.0723
on_train_batch_begin: 1598492645.635643s

35 step training time: 0.346462s

on_train_batch_end: 1598492645.981585s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.8087 - accuracy: 0.0723
on_train_batch_begin: 1598492645.981876s

36 step training time: 0.346232s

on_train_batch_end: 1598492646.329025s

37888/50000 [=====================>........] - ETA: 4s - loss: 4.8013 - accuracy: 0.0725
on_train_batch_begin: 1598492646.329316s

37 step training time: 0.347440s

on_train_batch_end: 1598492646.674071s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.7950 - accuracy: 0.0725
on_train_batch_begin: 1598492646.674359s

38 step training time: 0.345043s

on_train_batch_end: 1598492647.018037s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.7896 - accuracy: 0.0725
on_train_batch_begin: 1598492647.018319s

39 step training time: 0.343960s

on_train_batch_end: 1598492647.362153s

40960/50000 [=======================>......] - ETA: 3s - loss: 4.7795 - accuracy: 0.0723
on_train_batch_begin: 1598492647.362454s

40 step training time: 0.344135s

on_train_batch_end: 1598492647.709041s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.7631 - accuracy: 0.0723
on_train_batch_begin: 1598492647.709327s

41 step training time: 0.346873s

on_train_batch_end: 1598492648.055837s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.7472 - accuracy: 0.0722
on_train_batch_begin: 1598492648.056156s

42 step training time: 0.346829s

on_train_batch_end: 1598492648.402490s

44032/50000 [=========================>....] - ETA: 2s - loss: 4.7332 - accuracy: 0.0722
on_train_batch_begin: 1598492648.402807s

43 step training time: 0.346651s

on_train_batch_end: 1598492648.748984s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.7177 - accuracy: 0.0722
on_train_batch_begin: 1598492648.749297s

44 step training time: 0.346490s

on_train_batch_end: 1598492649.093184s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.6980 - accuracy: 0.0723
on_train_batch_begin: 1598492649.093496s

45 step training time: 0.344199s

on_train_batch_end: 1598492649.440041s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.6795 - accuracy: 0.0723
on_train_batch_begin: 1598492649.440376s

46 step training time: 0.346880s

on_train_batch_end: 1598492649.785444s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.6601 - accuracy: 0.0724
on_train_batch_begin: 1598492649.785744s

47 step training time: 0.345368s

on_train_batch_end: 1598492650.129990s

49152/50000 [============================>.] - ETA: 0s - loss: 4.6389 - accuracy: 0.0725
on_train_batch_begin: 1598492650.130295s

48 step training time: 0.344551s

on_train_batch_end: 1598492650.417376s

on_test_batch_begin: 1598492650.427897s

49 step training time: 0.297603s

on_epoch_end: 1598492651.248230s

Validation time: 0.820318s

Real time: 1598492651.248230s

Epoch time: 17.65645980834961s

50000/50000 [==============================] - 18s 353us/sample - loss: 4.6240 - accuracy: 0.0725 - val_loss: 7.5692 - val_accuracy: 0.0999

on_epoch_begin: 1598492651.248442s

Real time: 1598492651.2484474
Epoch 3/5

on_train_batch_begin: 1598492651.251787s

on_train_batch_end: 1598492651.599930s

 1024/50000 [..............................] - ETA: 16s - loss: 3.8157 - accuracy: 0.0768
on_train_batch_begin: 1598492651.600226s

1 step training time: 0.348439s

on_train_batch_end: 1598492651.965261s

 2048/50000 [>.............................] - ETA: 16s - loss: 3.7020 - accuracy: 0.0780
on_train_batch_begin: 1598492651.965560s

2 step training time: 0.365334s

on_train_batch_end: 1598492652.309985s

 3072/50000 [>.............................] - ETA: 16s - loss: 3.6003 - accuracy: 0.0791
on_train_batch_begin: 1598492652.310278s

3 step training time: 0.344719s

on_train_batch_end: 1598492652.656789s

 4096/50000 [=>............................] - ETA: 15s - loss: 3.5548 - accuracy: 0.0807
on_train_batch_begin: 1598492652.657084s

4 step training time: 0.346806s

on_train_batch_end: 1598492653.005485s

 5120/50000 [==>...........................] - ETA: 15s - loss: 3.4815 - accuracy: 0.0820
on_train_batch_begin: 1598492653.005789s

5 step training time: 0.348705s

on_train_batch_end: 1598492653.354845s

 6144/50000 [==>...........................] - ETA: 15s - loss: 3.4210 - accuracy: 0.0830
on_train_batch_begin: 1598492653.355141s

6 step training time: 0.349353s

on_train_batch_end: 1598492653.701439s

 7168/50000 [===>..........................] - ETA: 14s - loss: 3.3964 - accuracy: 0.0838
on_train_batch_begin: 1598492653.701727s

7 step training time: 0.346586s

on_train_batch_end: 1598492654.051198s

 8192/50000 [===>..........................] - ETA: 14s - loss: 3.3723 - accuracy: 0.0849
on_train_batch_begin: 1598492654.051489s

8 step training time: 0.349762s

on_train_batch_end: 1598492654.401352s

 9216/50000 [====>.........................] - ETA: 13s - loss: 3.3336 - accuracy: 0.0859
on_train_batch_begin: 1598492654.401660s

9 step training time: 0.350171s

on_train_batch_end: 1598492654.750071s

10240/50000 [=====>........................] - ETA: 13s - loss: 3.2969 - accuracy: 0.0865
on_train_batch_begin: 1598492654.750376s

10 step training time: 0.348716s

on_train_batch_end: 1598492655.103237s

11264/50000 [=====>........................] - ETA: 13s - loss: 3.2621 - accuracy: 0.0871
on_train_batch_begin: 1598492655.103526s

11 step training time: 0.353150s

on_train_batch_end: 1598492655.450162s

12288/50000 [======>.......................] - ETA: 12s - loss: 3.2356 - accuracy: 0.0877
on_train_batch_begin: 1598492655.450454s

12 step training time: 0.346928s

on_train_batch_end: 1598492655.798644s

13312/50000 [======>.......................] - ETA: 12s - loss: 3.2221 - accuracy: 0.0882
on_train_batch_begin: 1598492655.798946s

13 step training time: 0.348492s

on_train_batch_end: 1598492656.147131s

14336/50000 [=======>......................] - ETA: 12s - loss: 3.1872 - accuracy: 0.0889
on_train_batch_begin: 1598492656.147448s

14 step training time: 0.348502s

on_train_batch_end: 1598492656.495957s

15360/50000 [========>.....................] - ETA: 11s - loss: 3.1562 - accuracy: 0.0895
on_train_batch_begin: 1598492656.496265s

15 step training time: 0.348817s

on_train_batch_end: 1598492656.845245s

16384/50000 [========>.....................] - ETA: 11s - loss: 3.1075 - accuracy: 0.0901
on_train_batch_begin: 1598492656.845549s

16 step training time: 0.349283s

on_train_batch_end: 1598492657.193227s

17408/50000 [=========>....................] - ETA: 11s - loss: 3.0736 - accuracy: 0.0907
on_train_batch_begin: 1598492657.193553s

17 step training time: 0.348004s

on_train_batch_end: 1598492657.542291s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.0457 - accuracy: 0.0913
on_train_batch_begin: 1598492657.542595s

18 step training time: 0.349043s

on_train_batch_end: 1598492657.891319s

19456/50000 [==========>...................] - ETA: 10s - loss: 3.0188 - accuracy: 0.0917
on_train_batch_begin: 1598492657.891636s

19 step training time: 0.349041s

on_train_batch_end: 1598492658.241987s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.9907 - accuracy: 0.0921
on_train_batch_begin: 1598492658.242287s

20 step training time: 0.350651s

on_train_batch_end: 1598492658.591978s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.9600 - accuracy: 0.0925 
on_train_batch_begin: 1598492658.592280s

21 step training time: 0.349993s

on_train_batch_end: 1598492658.939554s

22528/50000 [============>.................] - ETA: 9s - loss: 2.9451 - accuracy: 0.0928
on_train_batch_begin: 1598492658.939886s

22 step training time: 0.347605s

on_train_batch_end: 1598492659.291713s

23552/50000 [=============>................] - ETA: 9s - loss: 2.9217 - accuracy: 0.0931
on_train_batch_begin: 1598492659.292005s

23 step training time: 0.352120s

on_train_batch_end: 1598492659.642872s

24576/50000 [=============>................] - ETA: 8s - loss: 2.9066 - accuracy: 0.0934
on_train_batch_begin: 1598492659.643166s

24 step training time: 0.351161s

on_train_batch_end: 1598492659.992252s

25600/50000 [==============>...............] - ETA: 8s - loss: 2.8846 - accuracy: 0.0936
on_train_batch_begin: 1598492659.992566s

25 step training time: 0.349400s

on_train_batch_end: 1598492660.345820s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.8609 - accuracy: 0.0939
on_train_batch_begin: 1598492660.346132s

26 step training time: 0.353566s

on_train_batch_end: 1598492660.696495s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.8508 - accuracy: 0.0941
on_train_batch_begin: 1598492660.696795s

27 step training time: 0.350663s

on_train_batch_end: 1598492661.046623s

28672/50000 [================>.............] - ETA: 7s - loss: 2.8318 - accuracy: 0.0944
on_train_batch_begin: 1598492661.046953s

28 step training time: 0.350158s

on_train_batch_end: 1598492661.397365s

29696/50000 [================>.............] - ETA: 6s - loss: 2.8259 - accuracy: 0.0945
on_train_batch_begin: 1598492661.397673s

29 step training time: 0.350720s

on_train_batch_end: 1598492661.750144s

30720/50000 [=================>............] - ETA: 6s - loss: 2.8191 - accuracy: 0.0947
on_train_batch_begin: 1598492661.750439s

30 step training time: 0.352765s

on_train_batch_end: 1598492662.100275s

31744/50000 [==================>...........] - ETA: 6s - loss: 2.8128 - accuracy: 0.0949
on_train_batch_begin: 1598492662.100593s

31 step training time: 0.350155s

on_train_batch_end: 1598492662.450097s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.7976 - accuracy: 0.0950
on_train_batch_begin: 1598492662.450395s

32 step training time: 0.349802s

on_train_batch_end: 1598492662.803138s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.7781 - accuracy: 0.0952
on_train_batch_begin: 1598492662.803438s

33 step training time: 0.353043s

on_train_batch_end: 1598492663.157596s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.7656 - accuracy: 0.0953
on_train_batch_begin: 1598492663.157912s

34 step training time: 0.354473s

on_train_batch_end: 1598492663.510293s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.7489 - accuracy: 0.0955
on_train_batch_begin: 1598492663.510609s

35 step training time: 0.352697s

on_train_batch_end: 1598492663.864376s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.7286 - accuracy: 0.0956
on_train_batch_begin: 1598492663.864689s

36 step training time: 0.354080s

on_train_batch_end: 1598492664.216180s

37888/50000 [=====================>........] - ETA: 4s - loss: 2.7131 - accuracy: 0.0957
on_train_batch_begin: 1598492664.216512s

37 step training time: 0.351823s

on_train_batch_end: 1598492664.568641s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.7008 - accuracy: 0.0958
on_train_batch_begin: 1598492664.568951s

38 step training time: 0.352438s

on_train_batch_end: 1598492664.924638s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.6904 - accuracy: 0.0959
on_train_batch_begin: 1598492664.924945s

39 step training time: 0.355994s

on_train_batch_end: 1598492665.277900s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.6784 - accuracy: 0.0960
on_train_batch_begin: 1598492665.278196s

40 step training time: 0.353250s

on_train_batch_end: 1598492665.632648s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.6616 - accuracy: 0.0961
on_train_batch_begin: 1598492665.632946s

41 step training time: 0.354751s

on_train_batch_end: 1598492665.984188s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.6503 - accuracy: 0.0962
on_train_batch_begin: 1598492665.984505s

42 step training time: 0.351558s

on_train_batch_end: 1598492666.338197s

44032/50000 [=========================>....] - ETA: 2s - loss: 2.6436 - accuracy: 0.0963
on_train_batch_begin: 1598492666.338485s

43 step training time: 0.353981s

on_train_batch_end: 1598492666.692096s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.6299 - accuracy: 0.0964
on_train_batch_begin: 1598492666.692398s

44 step training time: 0.353913s

on_train_batch_end: 1598492667.043370s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.6204 - accuracy: 0.0965
on_train_batch_begin: 1598492667.043655s

45 step training time: 0.351257s

on_train_batch_end: 1598492667.402691s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.6103 - accuracy: 0.0966
on_train_batch_begin: 1598492667.402980s

46 step training time: 0.359325s

on_train_batch_end: 1598492667.756506s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.6013 - accuracy: 0.0967
on_train_batch_begin: 1598492667.756785s

47 step training time: 0.353805s

on_train_batch_end: 1598492668.109775s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5939 - accuracy: 0.0967
on_train_batch_begin: 1598492668.110084s

48 step training time: 0.353299s

on_train_batch_end: 1598492668.405844s

on_test_batch_begin: 1598492668.420269s

49 step training time: 0.310185s

on_epoch_end: 1598492669.245319s

Validation time: 0.825037s

Real time: 1598492669.245319s

Epoch time: 17.99688959121704s

50000/50000 [==============================] - 18s 360us/sample - loss: 2.5874 - accuracy: 0.0968 - val_loss: 7.1324 - val_accuracy: 0.1001

on_epoch_begin: 1598492669.245517s

Real time: 1598492669.245522
Epoch 4/5

on_train_batch_begin: 1598492669.248802s

on_train_batch_end: 1598492669.602096s

 1024/50000 [..............................] - ETA: 17s - loss: 2.1931 - accuracy: 0.1002
on_train_batch_begin: 1598492669.602391s

1 step training time: 0.353589s

on_train_batch_end: 1598492669.953830s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.1050 - accuracy: 0.0999
on_train_batch_begin: 1598492669.954117s

2 step training time: 0.351726s

on_train_batch_end: 1598492670.314258s

 3072/50000 [>.............................] - ETA: 16s - loss: 2.0809 - accuracy: 0.1001
on_train_batch_begin: 1598492670.314542s

3 step training time: 0.360425s

on_train_batch_end: 1598492670.671567s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.0724 - accuracy: 0.1002
on_train_batch_begin: 1598492670.671872s

4 step training time: 0.357330s

on_train_batch_end: 1598492671.030028s

 5120/50000 [==>...........................] - ETA: 15s - loss: 2.0633 - accuracy: 0.1001
on_train_batch_begin: 1598492671.030318s

5 step training time: 0.358447s

on_train_batch_end: 1598492671.388126s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.0609 - accuracy: 0.1001
on_train_batch_begin: 1598492671.388446s

6 step training time: 0.358127s

on_train_batch_end: 1598492671.745323s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.0556 - accuracy: 0.1001
on_train_batch_begin: 1598492671.745613s

7 step training time: 0.357168s

on_train_batch_end: 1598492672.102932s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.0400 - accuracy: 0.1001
on_train_batch_begin: 1598492672.103229s

8 step training time: 0.357616s

on_train_batch_end: 1598492672.460520s

 9216/50000 [====>.........................] - ETA: 14s - loss: 2.0089 - accuracy: 0.1002
on_train_batch_begin: 1598492672.460815s

9 step training time: 0.357586s

on_train_batch_end: 1598492672.816392s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.9748 - accuracy: 0.1003
on_train_batch_begin: 1598492672.816679s

10 step training time: 0.355864s

on_train_batch_end: 1598492673.176041s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.9691 - accuracy: 0.1003
on_train_batch_begin: 1598492673.176348s

11 step training time: 0.359669s

on_train_batch_end: 1598492673.532043s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.9585 - accuracy: 0.1003
on_train_batch_begin: 1598492673.532339s

12 step training time: 0.355991s

on_train_batch_end: 1598492673.889185s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.9417 - accuracy: 0.1003
on_train_batch_begin: 1598492673.889465s

13 step training time: 0.357126s

on_train_batch_end: 1598492674.245880s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.9324 - accuracy: 0.1003
on_train_batch_begin: 1598492674.246189s

14 step training time: 0.356723s

on_train_batch_end: 1598492674.606035s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.9240 - accuracy: 0.1002
on_train_batch_begin: 1598492674.606331s

15 step training time: 0.360142s

on_train_batch_end: 1598492674.960721s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.9057 - accuracy: 0.1003
on_train_batch_begin: 1598492674.961022s

16 step training time: 0.354691s

on_train_batch_end: 1598492675.316809s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.8887 - accuracy: 0.1003
on_train_batch_begin: 1598492675.317136s

17 step training time: 0.356115s

on_train_batch_end: 1598492675.675068s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.8773 - accuracy: 0.1003
on_train_batch_begin: 1598492675.675384s

18 step training time: 0.358247s

on_train_batch_end: 1598492676.033137s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.8620 - accuracy: 0.1003
on_train_batch_begin: 1598492676.033432s

19 step training time: 0.358049s

on_train_batch_end: 1598492676.385350s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.8492 - accuracy: 0.1003
on_train_batch_begin: 1598492676.385645s

20 step training time: 0.352213s

on_train_batch_end: 1598492676.744746s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.8420 - accuracy: 0.1003 
on_train_batch_begin: 1598492676.745033s

21 step training time: 0.359388s

on_train_batch_end: 1598492677.102198s

22528/50000 [============>.................] - ETA: 9s - loss: 1.8287 - accuracy: 0.1003
on_train_batch_begin: 1598492677.102491s

22 step training time: 0.357459s

on_train_batch_end: 1598492677.461755s

23552/50000 [=============>................] - ETA: 9s - loss: 1.8198 - accuracy: 0.1003
on_train_batch_begin: 1598492677.462055s

23 step training time: 0.359564s

on_train_batch_end: 1598492677.820577s

24576/50000 [=============>................] - ETA: 8s - loss: 1.8137 - accuracy: 0.1003
on_train_batch_begin: 1598492677.820891s

24 step training time: 0.358836s

on_train_batch_end: 1598492678.182828s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.8066 - accuracy: 0.1003
on_train_batch_begin: 1598492678.183136s

25 step training time: 0.362245s

on_train_batch_end: 1598492678.542940s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.7996 - accuracy: 0.1003
on_train_batch_begin: 1598492678.543251s

26 step training time: 0.360115s

on_train_batch_end: 1598492678.901354s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.7922 - accuracy: 0.1003
on_train_batch_begin: 1598492678.901654s

27 step training time: 0.358403s

on_train_batch_end: 1598492679.264388s

28672/50000 [================>.............] - ETA: 7s - loss: 1.7824 - accuracy: 0.1003
on_train_batch_begin: 1598492679.264685s

28 step training time: 0.363031s

on_train_batch_end: 1598492679.623572s

29696/50000 [================>.............] - ETA: 7s - loss: 1.7691 - accuracy: 0.1003
on_train_batch_begin: 1598492679.623850s

29 step training time: 0.359165s

on_train_batch_end: 1598492679.980317s

30720/50000 [=================>............] - ETA: 6s - loss: 1.7535 - accuracy: 0.1003
on_train_batch_begin: 1598492679.980600s

30 step training time: 0.356750s

on_train_batch_end: 1598492680.341923s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.7458 - accuracy: 0.1003
on_train_batch_begin: 1598492680.342208s

31 step training time: 0.361607s

on_train_batch_end: 1598492680.703093s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.7359 - accuracy: 0.1003
on_train_batch_begin: 1598492680.703388s

32 step training time: 0.361180s

on_train_batch_end: 1598492681.062449s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.7312 - accuracy: 0.1003
on_train_batch_begin: 1598492681.062738s

33 step training time: 0.359350s

on_train_batch_end: 1598492681.423161s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.7224 - accuracy: 0.1003
on_train_batch_begin: 1598492681.423439s

34 step training time: 0.360701s

on_train_batch_end: 1598492681.781711s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.7131 - accuracy: 0.1003
on_train_batch_begin: 1598492681.781979s

35 step training time: 0.358540s

on_train_batch_end: 1598492682.144362s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.7037 - accuracy: 0.1003
on_train_batch_begin: 1598492682.144661s

36 step training time: 0.362683s

on_train_batch_end: 1598492682.505377s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.6956 - accuracy: 0.1003
on_train_batch_begin: 1598492682.505655s

37 step training time: 0.360994s

on_train_batch_end: 1598492682.864575s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.6890 - accuracy: 0.1003
on_train_batch_begin: 1598492682.864851s

38 step training time: 0.359196s

on_train_batch_end: 1598492683.226512s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.6806 - accuracy: 0.1003
on_train_batch_begin: 1598492683.226798s

39 step training time: 0.361946s

on_train_batch_end: 1598492683.589027s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.6717 - accuracy: 0.1003
on_train_batch_begin: 1598492683.589309s

40 step training time: 0.362511s

on_train_batch_end: 1598492683.949487s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.6665 - accuracy: 0.1003
on_train_batch_begin: 1598492683.949789s

41 step training time: 0.360481s

on_train_batch_end: 1598492684.310599s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.6552 - accuracy: 0.1003
on_train_batch_begin: 1598492684.310904s

42 step training time: 0.361114s

on_train_batch_end: 1598492684.671111s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.6453 - accuracy: 0.1003
on_train_batch_begin: 1598492684.671422s

43 step training time: 0.360519s

on_train_batch_end: 1598492685.032885s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.6320 - accuracy: 0.1003
on_train_batch_begin: 1598492685.033167s

44 step training time: 0.361745s

on_train_batch_end: 1598492685.393954s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.6234 - accuracy: 0.1003
on_train_batch_begin: 1598492685.394242s

45 step training time: 0.361075s

on_train_batch_end: 1598492685.751916s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.6139 - accuracy: 0.1003
on_train_batch_begin: 1598492685.752207s

46 step training time: 0.357965s

on_train_batch_end: 1598492686.116986s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.6086 - accuracy: 0.1003
on_train_batch_begin: 1598492686.117267s

47 step training time: 0.365061s

on_train_batch_end: 1598492686.480835s

49152/50000 [============================>.] - ETA: 0s - loss: 1.5999 - accuracy: 0.1003
on_train_batch_begin: 1598492686.481167s

48 step training time: 0.363899s

on_train_batch_end: 1598492686.777844s

on_test_batch_begin: 1598492686.789278s

49 step training time: 0.308111s

on_epoch_end: 1598492687.632821s

Validation time: 0.843531s

Real time: 1598492687.632821s

Epoch time: 18.38731598854065s

50000/50000 [==============================] - 18s 368us/sample - loss: 1.5940 - accuracy: 0.1003 - val_loss: 6.8498 - val_accuracy: 0.1000

on_epoch_begin: 1598492687.633004s

Real time: 1598492687.633009
Epoch 5/5

on_train_batch_begin: 1598492687.636219s

on_train_batch_end: 1598492687.994933s

 1024/50000 [..............................] - ETA: 17s - loss: 1.1535 - accuracy: 0.1001
on_train_batch_begin: 1598492687.995203s

1 step training time: 0.358985s

on_train_batch_end: 1598492688.353217s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.1336 - accuracy: 0.1000
on_train_batch_begin: 1598492688.353511s

2 step training time: 0.358308s

on_train_batch_end: 1598492688.721448s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.1145 - accuracy: 0.1001
on_train_batch_begin: 1598492688.721729s

3 step training time: 0.368218s

on_train_batch_end: 1598492689.082685s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.1111 - accuracy: 0.1002
on_train_batch_begin: 1598492689.082989s

4 step training time: 0.361260s

on_train_batch_end: 1598492689.444954s

 5120/50000 [==>...........................] - ETA: 15s - loss: 1.1090 - accuracy: 0.1002
on_train_batch_begin: 1598492689.445256s

5 step training time: 0.362267s

on_train_batch_end: 1598492689.809144s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.0920 - accuracy: 0.1002
on_train_batch_begin: 1598492689.809438s

6 step training time: 0.364181s

on_train_batch_end: 1598492690.172178s

 7168/50000 [===>..........................] - ETA: 15s - loss: 1.0807 - accuracy: 0.1002
on_train_batch_begin: 1598492690.172503s

7 step training time: 0.363065s

on_train_batch_end: 1598492690.536771s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.0754 - accuracy: 0.1003
on_train_batch_begin: 1598492690.537053s

8 step training time: 0.364551s

on_train_batch_end: 1598492690.900633s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.0724 - accuracy: 0.1003
on_train_batch_begin: 1598492690.900956s

9 step training time: 0.363903s

on_train_batch_end: 1598492691.264373s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.0708 - accuracy: 0.1003
on_train_batch_begin: 1598492691.264678s

10 step training time: 0.363722s

on_train_batch_end: 1598492691.626884s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.0678 - accuracy: 0.1003
on_train_batch_begin: 1598492691.627187s

11 step training time: 0.362509s

on_train_batch_end: 1598492691.989664s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.0634 - accuracy: 0.1004
on_train_batch_begin: 1598492691.989982s

12 step training time: 0.362795s

on_train_batch_end: 1598492692.352207s

13312/50000 [======>.......................] - ETA: 13s - loss: 1.0611 - accuracy: 0.1004
on_train_batch_begin: 1598492692.352530s

13 step training time: 0.362547s

on_train_batch_end: 1598492692.714071s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.0566 - accuracy: 0.1003
on_train_batch_begin: 1598492692.714380s

14 step training time: 0.361851s

on_train_batch_end: 1598492693.076829s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.0576 - accuracy: 0.1004
on_train_batch_begin: 1598492693.077124s

15 step training time: 0.362743s

on_train_batch_end: 1598492693.442068s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.0626 - accuracy: 0.1003
on_train_batch_begin: 1598492693.442359s

16 step training time: 0.365236s

on_train_batch_end: 1598492693.806675s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.0676 - accuracy: 0.1003
on_train_batch_begin: 1598492693.806971s

17 step training time: 0.364611s

on_train_batch_end: 1598492694.173013s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.0600 - accuracy: 0.1004
on_train_batch_begin: 1598492694.173403s

18 step training time: 0.366432s

on_train_batch_end: 1598492694.536087s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.0557 - accuracy: 0.1003
on_train_batch_begin: 1598492694.536396s

19 step training time: 0.362993s

on_train_batch_end: 1598492694.902303s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.0518 - accuracy: 0.1004
on_train_batch_begin: 1598492694.902616s

20 step training time: 0.366220s

on_train_batch_end: 1598492695.268528s

21504/50000 [===========>..................] - ETA: 10s - loss: 1.0461 - accuracy: 0.1003
on_train_batch_begin: 1598492695.268821s

21 step training time: 0.366206s

on_train_batch_end: 1598492695.631316s

22528/50000 [============>.................] - ETA: 9s - loss: 1.0363 - accuracy: 0.1003 
on_train_batch_begin: 1598492695.631611s

22 step training time: 0.362790s

on_train_batch_end: 1598492695.996548s

23552/50000 [=============>................] - ETA: 9s - loss: 1.0337 - accuracy: 0.1003
on_train_batch_begin: 1598492695.996841s

23 step training time: 0.365230s

on_train_batch_end: 1598492696.363853s

24576/50000 [=============>................] - ETA: 9s - loss: 1.0298 - accuracy: 0.1003
on_train_batch_begin: 1598492696.364139s

24 step training time: 0.367298s

on_train_batch_end: 1598492696.727749s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.0231 - accuracy: 0.1003
on_train_batch_begin: 1598492696.728042s

25 step training time: 0.363902s

on_train_batch_end: 1598492697.091429s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.0187 - accuracy: 0.1003
on_train_batch_begin: 1598492697.091721s

26 step training time: 0.363679s

on_train_batch_end: 1598492697.454976s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.0151 - accuracy: 0.1003
on_train_batch_begin: 1598492697.455279s

27 step training time: 0.363558s

on_train_batch_end: 1598492697.819691s

28672/50000 [================>.............] - ETA: 7s - loss: 1.0137 - accuracy: 0.1003
on_train_batch_begin: 1598492697.819981s

28 step training time: 0.364702s

on_train_batch_end: 1598492698.185840s

29696/50000 [================>.............] - ETA: 7s - loss: 1.0104 - accuracy: 0.1003
on_train_batch_begin: 1598492698.186151s

29 step training time: 0.366170s

on_train_batch_end: 1598492698.548386s

30720/50000 [=================>............] - ETA: 6s - loss: 1.0067 - accuracy: 0.1003
on_train_batch_begin: 1598492698.548678s

30 step training time: 0.362527s

on_train_batch_end: 1598492698.914386s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.0015 - accuracy: 0.1003
on_train_batch_begin: 1598492698.914686s

31 step training time: 0.366008s

on_train_batch_end: 1598492699.279263s

32768/50000 [==================>...........] - ETA: 6s - loss: 0.9990 - accuracy: 0.1003
on_train_batch_begin: 1598492699.279604s

32 step training time: 0.364918s

on_train_batch_end: 1598492699.646311s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.9982 - accuracy: 0.1003
on_train_batch_begin: 1598492699.646610s

33 step training time: 0.367006s

on_train_batch_end: 1598492700.010985s

34816/50000 [===================>..........] - ETA: 5s - loss: 0.9953 - accuracy: 0.1004
on_train_batch_begin: 1598492700.011292s

34 step training time: 0.364682s

on_train_batch_end: 1598492700.375856s

35840/50000 [====================>.........] - ETA: 5s - loss: 0.9954 - accuracy: 0.1004
on_train_batch_begin: 1598492700.376173s

35 step training time: 0.364881s

on_train_batch_end: 1598492700.743302s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.9926 - accuracy: 0.1004
on_train_batch_begin: 1598492700.743612s

36 step training time: 0.367438s

on_train_batch_end: 1598492701.110319s

37888/50000 [=====================>........] - ETA: 4s - loss: 0.9896 - accuracy: 0.1004
on_train_batch_begin: 1598492701.110630s

37 step training time: 0.367018s

on_train_batch_end: 1598492701.476578s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.9862 - accuracy: 0.1004
on_train_batch_begin: 1598492701.476870s

38 step training time: 0.366241s

on_train_batch_end: 1598492701.840832s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.9843 - accuracy: 0.1004
on_train_batch_begin: 1598492701.841130s

39 step training time: 0.364260s

on_train_batch_end: 1598492702.207439s

40960/50000 [=======================>......] - ETA: 3s - loss: 0.9817 - accuracy: 0.1004
on_train_batch_begin: 1598492702.207734s

40 step training time: 0.366604s

on_train_batch_end: 1598492702.573049s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.9841 - accuracy: 0.1004
on_train_batch_begin: 1598492702.573338s

41 step training time: 0.365603s

on_train_batch_end: 1598492702.937267s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.9837 - accuracy: 0.1004
on_train_batch_begin: 1598492702.937577s

42 step training time: 0.364239s

on_train_batch_end: 1598492703.305332s

44032/50000 [=========================>....] - ETA: 2s - loss: 0.9838 - accuracy: 0.1004
on_train_batch_begin: 1598492703.305625s

43 step training time: 0.368049s

on_train_batch_end: 1598492703.672896s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.9840 - accuracy: 0.1004
on_train_batch_begin: 1598492703.673186s

44 step training time: 0.367560s

on_train_batch_end: 1598492704.041152s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.9829 - accuracy: 0.1004
on_train_batch_begin: 1598492704.041460s

45 step training time: 0.368274s

on_train_batch_end: 1598492704.410937s

47104/50000 [===========================>..] - ETA: 1s - loss: 0.9817 - accuracy: 0.1004
on_train_batch_begin: 1598492704.411217s

46 step training time: 0.369757s

on_train_batch_end: 1598492704.778487s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9795 - accuracy: 0.1004
on_train_batch_begin: 1598492704.778802s

47 step training time: 0.367585s

on_train_batch_end: 1598492705.143483s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9790 - accuracy: 0.1004
on_train_batch_begin: 1598492705.143774s

48 step training time: 0.364972s

on_train_batch_end: 1598492705.446980s

on_test_batch_begin: 1598492705.458451s

49 step training time: 0.314677s

on_epoch_end: 1598492706.306692s

Validation time: 0.848230s

Real time: 1598492706.306692s

Epoch time: 18.6737003326416s

50000/50000 [==============================] - 19s 373us/sample - loss: 0.9783 - accuracy: 0.1004 - val_loss: 6.6596 - val_accuracy: 0.1002
Tempo do fit: 120.55399560928345