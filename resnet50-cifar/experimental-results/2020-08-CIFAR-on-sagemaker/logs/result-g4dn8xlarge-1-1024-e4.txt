wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:53
   204800/170498071 [..............................] - ETA: 1:17
  1155072/170498071 [..............................] - ETA: 21s 
  3809280/170498071 [..............................] - ETA: 8s 
  7168000/170498071 [>.............................] - ETA: 5s
 10420224/170498071 [>.............................] - ETA: 4s
 13787136/170498071 [=>............................] - ETA: 3s
 17113088/170498071 [==>...........................] - ETA: 3s
 20414464/170498071 [==>...........................] - ETA: 3s
 23601152/170498071 [===>..........................] - ETA: 3s
 26796032/170498071 [===>..........................] - ETA: 2s
 30007296/170498071 [====>.........................] - ETA: 2s
 33300480/170498071 [====>.........................] - ETA: 2s
 36495360/170498071 [=====>........................] - ETA: 2s
 39804928/170498071 [======>.......................] - ETA: 2s
 43147264/170498071 [======>.......................] - ETA: 2s
 46391296/170498071 [=======>......................] - ETA: 2s
 49700864/170498071 [=======>......................] - ETA: 2s
 53026816/170498071 [========>.....................] - ETA: 2s
 55132160/170498071 [========>.....................] - ETA: 2s
 58875904/170498071 [=========>....................] - ETA: 2s
 62218240/170498071 [=========>....................] - ETA: 1s
 65544192/170498071 [==========>...................] - ETA: 1s
 67395584/170498071 [==========>...................] - ETA: 1s
 70557696/170498071 [===========>..................] - ETA: 1s
 73900032/170498071 [============>.................] - ETA: 1s
 77094912/170498071 [============>.................] - ETA: 1s
 80355328/170498071 [=============>................] - ETA: 1s
 83615744/170498071 [=============>................] - ETA: 1s
 85876736/170498071 [==============>...............] - ETA: 1s
 89120768/170498071 [==============>...............] - ETA: 1s
 91807744/170498071 [===============>..............] - ETA: 1s
 95100928/170498071 [===============>..............] - ETA: 1s
 98066432/170498071 [================>.............] - ETA: 1s
101244928/170498071 [================>.............] - ETA: 1s
104620032/170498071 [=================>............] - ETA: 1s
107814912/170498071 [=================>............] - ETA: 1s
111157248/170498071 [==================>...........] - ETA: 1s
114499584/170498071 [===================>..........] - ETA: 0s
117776384/170498071 [===================>..........] - ETA: 0s
120889344/170498071 [====================>.........] - ETA: 0s
124198912/170498071 [====================>.........] - ETA: 0s
127459328/170498071 [=====================>........] - ETA: 0s
130785280/170498071 [======================>.......] - ETA: 0s
134029312/170498071 [======================>.......] - ETA: 0s
137289728/170498071 [=======================>......] - ETA: 0s
140550144/170498071 [=======================>......] - ETA: 0s
143794176/170498071 [========================>.....] - ETA: 0s
147087360/170498071 [========================>.....] - ETA: 0s
150380544/170498071 [=========================>....] - ETA: 0s
153755648/170498071 [==========================>...] - ETA: 0s
157048832/170498071 [==========================>...] - ETA: 0s
160325632/170498071 [===========================>..] - ETA: 0s
163651584/170498071 [===========================>..] - ETA: 0s
166928384/170498071 [============================>.] - ETA: 0s
170221568/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 9158656/94765736 [=>............................] - ETA: 0s
15720448/94765736 [===>..........................] - ETA: 0s
20611072/94765736 [=====>........................] - ETA: 0s
25796608/94765736 [=======>......................] - ETA: 0s
31023104/94765736 [========>.....................] - ETA: 0s
35995648/94765736 [==========>...................] - ETA: 0s
41377792/94765736 [============>.................] - ETA: 0s
46039040/94765736 [=============>................] - ETA: 0s
50814976/94765736 [===============>..............] - ETA: 0s
56369152/94765736 [================>.............] - ETA: 0s
57212928/94765736 [=================>............] - ETA: 0s
64544768/94765736 [===================>..........] - ETA: 0s
71368704/94765736 [=====================>........] - ETA: 0s
73703424/94765736 [======================>.......] - ETA: 0s
78856192/94765736 [=======================>......] - ETA: 0s
80363520/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94060544/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.446579217910767
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615688441.108897s

Real time: 1615688441.1089146
Epoch 1/5

on_train_batch_begin: 1615688441.861706s

on_train_batch_end: 1615688460.011771s

 1024/50000 [..............................] - ETA: 15:04 - loss: 17.6972 - accuracy: 1.7166e-04
on_train_batch_begin: 1615688460.012371s

1 step training time: 18.150665s

on_train_batch_end: 1615688460.340878s

 2048/50000 [>.............................] - ETA: 7:30 - loss: 15.7038 - accuracy: 3.7003e-04 
on_train_batch_begin: 1615688460.341184s

2 step training time: 0.328813s

on_train_batch_end: 1615688460.657702s

 3072/50000 [>.............................] - ETA: 4:58 - loss: 13.6759 - accuracy: 4.3933e-04
on_train_batch_begin: 1615688460.658010s

3 step training time: 0.316826s

on_train_batch_end: 1615688460.982049s

 4096/50000 [=>............................] - ETA: 3:42 - loss: 12.4101 - accuracy: 0.0011    
on_train_batch_begin: 1615688460.982335s

4 step training time: 0.324325s

on_train_batch_end: 1615688461.310566s

 5120/50000 [==>...........................] - ETA: 2:57 - loss: 11.5342 - accuracy: 0.0024
on_train_batch_begin: 1615688461.310847s

5 step training time: 0.328512s

on_train_batch_end: 1615688461.638999s

 6144/50000 [==>...........................] - ETA: 2:26 - loss: 10.9461 - accuracy: 0.0040
on_train_batch_begin: 1615688461.639307s

6 step training time: 0.328460s

on_train_batch_end: 1615688461.965364s

 7168/50000 [===>..........................] - ETA: 2:04 - loss: 10.4798 - accuracy: 0.0080
on_train_batch_begin: 1615688461.965662s

7 step training time: 0.326355s

on_train_batch_end: 1615688462.290628s

 8192/50000 [===>..........................] - ETA: 1:48 - loss: 10.1013 - accuracy: 0.0121
on_train_batch_begin: 1615688462.290920s

8 step training time: 0.325258s

on_train_batch_end: 1615688462.617738s

 9216/50000 [====>.........................] - ETA: 1:35 - loss: 9.7939 - accuracy: 0.0157 
on_train_batch_begin: 1615688462.618043s

9 step training time: 0.327123s

on_train_batch_end: 1615688462.943021s

10240/50000 [=====>........................] - ETA: 1:24 - loss: 9.5616 - accuracy: 0.0202
on_train_batch_begin: 1615688462.943307s

10 step training time: 0.325264s

on_train_batch_end: 1615688463.268321s

11264/50000 [=====>........................] - ETA: 1:16 - loss: 9.3879 - accuracy: 0.0219
on_train_batch_begin: 1615688463.268616s

11 step training time: 0.325309s

on_train_batch_end: 1615688463.593973s

12288/50000 [======>.......................] - ETA: 1:09 - loss: 9.2096 - accuracy: 0.0255
on_train_batch_begin: 1615688463.594260s

12 step training time: 0.325644s

on_train_batch_end: 1615688463.918794s

13312/50000 [======>.......................] - ETA: 1:02 - loss: 9.0532 - accuracy: 0.0291
on_train_batch_begin: 1615688463.919103s

13 step training time: 0.324843s

on_train_batch_end: 1615688464.246325s

14336/50000 [=======>......................] - ETA: 57s - loss: 8.9208 - accuracy: 0.0322 
on_train_batch_begin: 1615688464.246630s

14 step training time: 0.327527s

on_train_batch_end: 1615688464.571642s

15360/50000 [========>.....................] - ETA: 52s - loss: 8.8036 - accuracy: 0.0337
on_train_batch_begin: 1615688464.571958s

15 step training time: 0.325329s

on_train_batch_end: 1615688464.898162s

16384/50000 [========>.....................] - ETA: 48s - loss: 8.6906 - accuracy: 0.0368
on_train_batch_begin: 1615688464.898466s

16 step training time: 0.326508s

on_train_batch_end: 1615688465.229248s

17408/50000 [=========>....................] - ETA: 45s - loss: 8.5863 - accuracy: 0.0386
on_train_batch_begin: 1615688465.229574s

17 step training time: 0.331109s

on_train_batch_end: 1615688465.559063s

18432/50000 [==========>...................] - ETA: 41s - loss: 8.4879 - accuracy: 0.0406
on_train_batch_begin: 1615688465.559373s

18 step training time: 0.329798s

on_train_batch_end: 1615688465.886430s

19456/50000 [==========>...................] - ETA: 38s - loss: 8.3961 - accuracy: 0.0425
on_train_batch_begin: 1615688465.886729s

19 step training time: 0.327356s

on_train_batch_end: 1615688466.212581s

20480/50000 [===========>..................] - ETA: 36s - loss: 8.3091 - accuracy: 0.0440
on_train_batch_begin: 1615688466.212873s

20 step training time: 0.326144s

on_train_batch_end: 1615688466.538444s

21504/50000 [===========>..................] - ETA: 33s - loss: 8.2309 - accuracy: 0.0450
on_train_batch_begin: 1615688466.538734s

21 step training time: 0.325861s

on_train_batch_end: 1615688466.864686s

22528/50000 [============>.................] - ETA: 31s - loss: 8.1525 - accuracy: 0.0463
on_train_batch_begin: 1615688466.864982s

22 step training time: 0.326248s

on_train_batch_end: 1615688467.190305s

23552/50000 [=============>................] - ETA: 29s - loss: 8.0801 - accuracy: 0.0471
on_train_batch_begin: 1615688467.190591s

23 step training time: 0.325609s

on_train_batch_end: 1615688467.515986s

24576/50000 [=============>................] - ETA: 27s - loss: 8.0090 - accuracy: 0.0484
on_train_batch_begin: 1615688467.516276s

24 step training time: 0.325685s

on_train_batch_end: 1615688467.842719s

25600/50000 [==============>...............] - ETA: 25s - loss: 7.9440 - accuracy: 0.0494
on_train_batch_begin: 1615688467.843011s

25 step training time: 0.326735s

on_train_batch_end: 1615688468.170771s

26624/50000 [==============>...............] - ETA: 23s - loss: 7.8800 - accuracy: 0.0499
on_train_batch_begin: 1615688468.171066s

26 step training time: 0.328054s

on_train_batch_end: 1615688468.501830s

27648/50000 [===============>..............] - ETA: 22s - loss: 7.8120 - accuracy: 0.0507
on_train_batch_begin: 1615688468.502116s

27 step training time: 0.331051s

on_train_batch_end: 1615688468.829257s

28672/50000 [================>.............] - ETA: 20s - loss: 7.7524 - accuracy: 0.0511
on_train_batch_begin: 1615688468.829590s

28 step training time: 0.327474s

on_train_batch_end: 1615688469.157618s

29696/50000 [================>.............] - ETA: 19s - loss: 7.6934 - accuracy: 0.0514
on_train_batch_begin: 1615688469.157902s

29 step training time: 0.328312s

on_train_batch_end: 1615688469.485936s

30720/50000 [=================>............] - ETA: 17s - loss: 7.6309 - accuracy: 0.0519
on_train_batch_begin: 1615688469.486233s

30 step training time: 0.328331s

on_train_batch_end: 1615688469.814434s

31744/50000 [==================>...........] - ETA: 16s - loss: 7.5776 - accuracy: 0.0523
on_train_batch_begin: 1615688469.814720s

31 step training time: 0.328487s

on_train_batch_end: 1615688470.142473s

32768/50000 [==================>...........] - ETA: 15s - loss: 7.5216 - accuracy: 0.0524
on_train_batch_begin: 1615688470.142757s

32 step training time: 0.328037s

on_train_batch_end: 1615688470.472606s

33792/50000 [===================>..........] - ETA: 14s - loss: 7.4704 - accuracy: 0.0524
on_train_batch_begin: 1615688470.472887s

33 step training time: 0.330131s

on_train_batch_end: 1615688470.802260s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.4193 - accuracy: 0.0523
on_train_batch_begin: 1615688470.802555s

34 step training time: 0.329668s

on_train_batch_end: 1615688471.127967s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.3650 - accuracy: 0.0524
on_train_batch_begin: 1615688471.128263s

35 step training time: 0.325707s

on_train_batch_end: 1615688471.454407s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.3128 - accuracy: 0.0524
on_train_batch_begin: 1615688471.454709s

36 step training time: 0.326446s

on_train_batch_end: 1615688471.786390s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.2617 - accuracy: 0.0525 
on_train_batch_begin: 1615688471.786690s

37 step training time: 0.331981s

on_train_batch_end: 1615688472.118907s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.2149 - accuracy: 0.0524
on_train_batch_begin: 1615688472.119201s

38 step training time: 0.332511s

on_train_batch_end: 1615688472.446723s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.1658 - accuracy: 0.0524
on_train_batch_begin: 1615688472.447017s

39 step training time: 0.327816s

on_train_batch_end: 1615688472.772852s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.1194 - accuracy: 0.0524
on_train_batch_begin: 1615688472.773163s

40 step training time: 0.326146s

on_train_batch_end: 1615688473.103368s

41984/50000 [========================>.....] - ETA: 6s - loss: 7.0722 - accuracy: 0.0525
on_train_batch_begin: 1615688473.103672s

41 step training time: 0.330509s

on_train_batch_end: 1615688473.438842s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.0209 - accuracy: 0.0526
on_train_batch_begin: 1615688473.439129s

42 step training time: 0.335457s

on_train_batch_end: 1615688473.768314s

44032/50000 [=========================>....] - ETA: 4s - loss: 6.9709 - accuracy: 0.0528
on_train_batch_begin: 1615688473.768619s

43 step training time: 0.329490s

on_train_batch_end: 1615688474.095804s

45056/50000 [==========================>...] - ETA: 3s - loss: 6.9220 - accuracy: 0.0530
on_train_batch_begin: 1615688474.096106s

44 step training time: 0.327487s

on_train_batch_end: 1615688474.429967s

46080/50000 [==========================>...] - ETA: 2s - loss: 6.8743 - accuracy: 0.0532
on_train_batch_begin: 1615688474.430264s

45 step training time: 0.334158s

on_train_batch_end: 1615688474.763005s

47104/50000 [===========================>..] - ETA: 2s - loss: 6.8261 - accuracy: 0.0534
on_train_batch_begin: 1615688474.763318s

46 step training time: 0.333055s

on_train_batch_end: 1615688475.092609s

48128/50000 [===========================>..] - ETA: 1s - loss: 6.7821 - accuracy: 0.0537
on_train_batch_begin: 1615688475.092907s

47 step training time: 0.329589s

on_train_batch_end: 1615688475.424932s

49152/50000 [============================>.] - ETA: 0s - loss: 6.7336 - accuracy: 0.0540
on_train_batch_begin: 1615688475.425221s

48 step training time: 0.332314s

on_train_batch_end: 1615688481.381753s

on_test_batch_begin: 1615688481.568857s

49 step training time: 6.143636s

on_epoch_end: 1615688486.211482s

Validation time: 4.642610s

Real time: 1615688486.211482s

Epoch time: 45.10258460044861s

50000/50000 [==============================] - 45s 902us/sample - loss: 6.6924 - accuracy: 0.0542 - val_loss: 25.7821 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615688486.211690s

Real time: 1615688486.2116957
Epoch 2/5

on_train_batch_begin: 1615688486.215142s

on_train_batch_end: 1615688486.552712s

 1024/50000 [..............................] - ETA: 16s - loss: 4.0956 - accuracy: 0.0776
on_train_batch_begin: 1615688486.553017s

1 step training time: 0.337875s

on_train_batch_end: 1615688486.883877s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.9546 - accuracy: 0.0819
on_train_batch_begin: 1615688486.884178s

2 step training time: 0.331161s

on_train_batch_end: 1615688487.216345s

 3072/50000 [>.............................] - ETA: 15s - loss: 3.8854 - accuracy: 0.0838
on_train_batch_begin: 1615688487.216648s

3 step training time: 0.332470s

on_train_batch_end: 1615688487.549160s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.8416 - accuracy: 0.0858
on_train_batch_begin: 1615688487.549492s

4 step training time: 0.332844s

on_train_batch_end: 1615688487.880026s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.8092 - accuracy: 0.0866
on_train_batch_begin: 1615688487.880322s

5 step training time: 0.330830s

on_train_batch_end: 1615688488.216343s

 6144/50000 [==>...........................] - ETA: 14s - loss: 3.7885 - accuracy: 0.0871
on_train_batch_begin: 1615688488.216639s

6 step training time: 0.336317s

on_train_batch_end: 1615688488.547643s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.7901 - accuracy: 0.0878
on_train_batch_begin: 1615688488.547926s

7 step training time: 0.331287s

on_train_batch_end: 1615688488.881811s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.7445 - accuracy: 0.0884
on_train_batch_begin: 1615688488.882096s

8 step training time: 0.334170s

on_train_batch_end: 1615688489.214547s

 9216/50000 [====>.........................] - ETA: 13s - loss: 3.6851 - accuracy: 0.0887
on_train_batch_begin: 1615688489.214828s

9 step training time: 0.332732s

on_train_batch_end: 1615688489.548858s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.6503 - accuracy: 0.0892
on_train_batch_begin: 1615688489.549153s

10 step training time: 0.334325s

on_train_batch_end: 1615688489.880939s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.6153 - accuracy: 0.0896
on_train_batch_begin: 1615688489.881242s

11 step training time: 0.332089s

on_train_batch_end: 1615688490.211055s

12288/50000 [======>.......................] - ETA: 12s - loss: 3.5757 - accuracy: 0.0899
on_train_batch_begin: 1615688490.211356s

12 step training time: 0.330114s

on_train_batch_end: 1615688490.546858s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.5398 - accuracy: 0.0905
on_train_batch_begin: 1615688490.547157s

13 step training time: 0.335801s

on_train_batch_end: 1615688490.881245s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.5114 - accuracy: 0.0909
on_train_batch_begin: 1615688490.881566s

14 step training time: 0.334409s

on_train_batch_end: 1615688491.216473s

15360/50000 [========>.....................] - ETA: 11s - loss: 3.4815 - accuracy: 0.0912
on_train_batch_begin: 1615688491.216740s

15 step training time: 0.335174s

on_train_batch_end: 1615688491.548590s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.4520 - accuracy: 0.0915
on_train_batch_begin: 1615688491.548887s

16 step training time: 0.332147s

on_train_batch_end: 1615688491.882508s

17408/50000 [=========>....................] - ETA: 10s - loss: 3.4219 - accuracy: 0.0919
on_train_batch_begin: 1615688491.882796s

17 step training time: 0.333909s

on_train_batch_end: 1615688492.218129s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.3966 - accuracy: 0.0922
on_train_batch_begin: 1615688492.218417s

18 step training time: 0.335621s

on_train_batch_end: 1615688492.552301s

19456/50000 [==========>...................] - ETA: 9s - loss: 3.3699 - accuracy: 0.0926 
on_train_batch_begin: 1615688492.552577s

19 step training time: 0.334160s

on_train_batch_end: 1615688492.886176s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.3512 - accuracy: 0.0928
on_train_batch_begin: 1615688492.886462s

20 step training time: 0.333885s

on_train_batch_end: 1615688493.219970s

21504/50000 [===========>..................] - ETA: 9s - loss: 3.3324 - accuracy: 0.0931
on_train_batch_begin: 1615688493.220257s

21 step training time: 0.333795s

on_train_batch_end: 1615688493.555820s

22528/50000 [============>.................] - ETA: 8s - loss: 3.3224 - accuracy: 0.0934
on_train_batch_begin: 1615688493.556114s

22 step training time: 0.335857s

on_train_batch_end: 1615688493.892770s

23552/50000 [=============>................] - ETA: 8s - loss: 3.2960 - accuracy: 0.0937
on_train_batch_begin: 1615688493.893055s

23 step training time: 0.336941s

on_train_batch_end: 1615688494.225503s

24576/50000 [=============>................] - ETA: 8s - loss: 3.2831 - accuracy: 0.0939
on_train_batch_begin: 1615688494.225792s

24 step training time: 0.332737s

on_train_batch_end: 1615688494.560979s

25600/50000 [==============>...............] - ETA: 7s - loss: 3.2646 - accuracy: 0.0941
on_train_batch_begin: 1615688494.561279s

25 step training time: 0.335487s

on_train_batch_end: 1615688494.895824s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.2550 - accuracy: 0.0943
on_train_batch_begin: 1615688494.896119s

26 step training time: 0.334840s

on_train_batch_end: 1615688495.230194s

27648/50000 [===============>..............] - ETA: 7s - loss: 3.2394 - accuracy: 0.0946
on_train_batch_begin: 1615688495.230491s

27 step training time: 0.334372s

on_train_batch_end: 1615688495.565567s

28672/50000 [================>.............] - ETA: 6s - loss: 3.2295 - accuracy: 0.0947
on_train_batch_begin: 1615688495.565861s

28 step training time: 0.335370s

on_train_batch_end: 1615688495.902316s

29696/50000 [================>.............] - ETA: 6s - loss: 3.2184 - accuracy: 0.0949
on_train_batch_begin: 1615688495.902615s

29 step training time: 0.336754s

on_train_batch_end: 1615688496.233733s

30720/50000 [=================>............] - ETA: 6s - loss: 3.2090 - accuracy: 0.0951
on_train_batch_begin: 1615688496.234015s

30 step training time: 0.331400s

on_train_batch_end: 1615688496.564860s

31744/50000 [==================>...........] - ETA: 5s - loss: 3.1976 - accuracy: 0.0952
on_train_batch_begin: 1615688496.565146s

31 step training time: 0.331132s

on_train_batch_end: 1615688496.902238s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.1844 - accuracy: 0.0954
on_train_batch_begin: 1615688496.902513s

32 step training time: 0.337366s

on_train_batch_end: 1615688497.239994s

33792/50000 [===================>..........] - ETA: 5s - loss: 3.1689 - accuracy: 0.0955
on_train_batch_begin: 1615688497.240267s

33 step training time: 0.337754s

on_train_batch_end: 1615688497.568651s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.1573 - accuracy: 0.0956
on_train_batch_begin: 1615688497.568948s

34 step training time: 0.328681s

on_train_batch_end: 1615688497.904855s

35840/50000 [====================>.........] - ETA: 4s - loss: 3.1447 - accuracy: 0.0957
on_train_batch_begin: 1615688497.905143s

35 step training time: 0.336195s

on_train_batch_end: 1615688498.240498s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.1307 - accuracy: 0.0958
on_train_batch_begin: 1615688498.240788s

36 step training time: 0.335645s

on_train_batch_end: 1615688498.572140s

37888/50000 [=====================>........] - ETA: 3s - loss: 3.1162 - accuracy: 0.0959
on_train_batch_begin: 1615688498.572436s

37 step training time: 0.331648s

on_train_batch_end: 1615688498.907694s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.0998 - accuracy: 0.0960
on_train_batch_begin: 1615688498.907979s

38 step training time: 0.335544s

on_train_batch_end: 1615688499.241307s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.0818 - accuracy: 0.0961
on_train_batch_begin: 1615688499.241591s

39 step training time: 0.333612s

on_train_batch_end: 1615688499.575844s

40960/50000 [=======================>......] - ETA: 2s - loss: 3.0644 - accuracy: 0.0962
on_train_batch_begin: 1615688499.576142s

40 step training time: 0.334550s

on_train_batch_end: 1615688499.911803s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.0498 - accuracy: 0.0963
on_train_batch_begin: 1615688499.912101s

41 step training time: 0.335959s

on_train_batch_end: 1615688500.246099s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.0394 - accuracy: 0.0964
on_train_batch_begin: 1615688500.246367s

42 step training time: 0.334266s

on_train_batch_end: 1615688500.580583s

44032/50000 [=========================>....] - ETA: 1s - loss: 3.0198 - accuracy: 0.0965
on_train_batch_begin: 1615688500.580850s

43 step training time: 0.334483s

on_train_batch_end: 1615688500.917414s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.0060 - accuracy: 0.0966
on_train_batch_begin: 1615688500.917706s

44 step training time: 0.336856s

on_train_batch_end: 1615688501.251526s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.9963 - accuracy: 0.0967
on_train_batch_begin: 1615688501.251828s

45 step training time: 0.334121s

on_train_batch_end: 1615688501.589332s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.9864 - accuracy: 0.0967
on_train_batch_begin: 1615688501.589667s

46 step training time: 0.337839s

on_train_batch_end: 1615688501.923467s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.9761 - accuracy: 0.0968
on_train_batch_begin: 1615688501.923771s

47 step training time: 0.334104s

on_train_batch_end: 1615688502.260350s

49152/50000 [============================>.] - ETA: 0s - loss: 2.9636 - accuracy: 0.0969
on_train_batch_begin: 1615688502.260643s

48 step training time: 0.336873s

on_train_batch_end: 1615688502.537555s

on_test_batch_begin: 1615688502.548881s

49 step training time: 0.288238s

on_epoch_end: 1615688503.347087s

Validation time: 0.798194s

Real time: 1615688503.347087s

Epoch time: 17.135407209396362s

50000/50000 [==============================] - 17s 343us/sample - loss: 2.9548 - accuracy: 0.0969 - val_loss: 8.3572 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615688503.347280s

Real time: 1615688503.347285
Epoch 3/5

on_train_batch_begin: 1615688503.350583s

on_train_batch_end: 1615688503.685110s

 1024/50000 [..............................] - ETA: 16s - loss: 2.2818 - accuracy: 0.1000
on_train_batch_begin: 1615688503.685440s

1 step training time: 0.334857s

on_train_batch_end: 1615688504.024685s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.2633 - accuracy: 0.1005
on_train_batch_begin: 1615688504.024967s

2 step training time: 0.339528s

on_train_batch_end: 1615688504.358972s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.1828 - accuracy: 0.1003
on_train_batch_begin: 1615688504.359247s

3 step training time: 0.334280s

on_train_batch_end: 1615688504.697858s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.1801 - accuracy: 0.1003
on_train_batch_begin: 1615688504.698133s

4 step training time: 0.338885s

on_train_batch_end: 1615688505.037625s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.1843 - accuracy: 0.1003
on_train_batch_begin: 1615688505.037927s

5 step training time: 0.339795s

on_train_batch_end: 1615688505.372799s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.1965 - accuracy: 0.1001
on_train_batch_begin: 1615688505.373098s

6 step training time: 0.335170s

on_train_batch_end: 1615688505.710250s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.1841 - accuracy: 0.1001
on_train_batch_begin: 1615688505.710551s

7 step training time: 0.337453s

on_train_batch_end: 1615688506.051093s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.1928 - accuracy: 0.1001
on_train_batch_begin: 1615688506.051386s

8 step training time: 0.340836s

on_train_batch_end: 1615688506.387871s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.1773 - accuracy: 0.1001
on_train_batch_begin: 1615688506.388151s

9 step training time: 0.336765s

on_train_batch_end: 1615688506.725628s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.1562 - accuracy: 0.1001
on_train_batch_begin: 1615688506.725902s

10 step training time: 0.337751s

on_train_batch_end: 1615688507.062914s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.1476 - accuracy: 0.1001
on_train_batch_begin: 1615688507.063175s

11 step training time: 0.337273s

on_train_batch_end: 1615688507.399393s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.1369 - accuracy: 0.1002
on_train_batch_begin: 1615688507.399656s

12 step training time: 0.336480s

on_train_batch_end: 1615688507.737814s

13312/50000 [======>.......................] - ETA: 12s - loss: 2.1159 - accuracy: 0.1002
on_train_batch_begin: 1615688507.738095s

13 step training time: 0.338439s

on_train_batch_end: 1615688508.073748s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.1074 - accuracy: 0.1002
on_train_batch_begin: 1615688508.074041s

14 step training time: 0.335946s

on_train_batch_end: 1615688508.411059s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.0992 - accuracy: 0.1002
on_train_batch_begin: 1615688508.411333s

15 step training time: 0.337292s

on_train_batch_end: 1615688508.752202s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.1044 - accuracy: 0.1001
on_train_batch_begin: 1615688508.752484s

16 step training time: 0.341151s

on_train_batch_end: 1615688509.088476s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.0934 - accuracy: 0.1002
on_train_batch_begin: 1615688509.088765s

17 step training time: 0.336281s

on_train_batch_end: 1615688509.427216s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.0844 - accuracy: 0.1002
on_train_batch_begin: 1615688509.427467s

18 step training time: 0.338702s

on_train_batch_end: 1615688509.766918s

19456/50000 [==========>...................] - ETA: 10s - loss: 2.0771 - accuracy: 0.1002
on_train_batch_begin: 1615688509.767199s

19 step training time: 0.339732s

on_train_batch_end: 1615688510.105698s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.0625 - accuracy: 0.1002 
on_train_batch_begin: 1615688510.105996s

20 step training time: 0.338797s

on_train_batch_end: 1615688510.443239s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.0613 - accuracy: 0.1002
on_train_batch_begin: 1615688510.443519s

21 step training time: 0.337523s

on_train_batch_end: 1615688510.781489s

22528/50000 [============>.................] - ETA: 9s - loss: 2.0449 - accuracy: 0.1002
on_train_batch_begin: 1615688510.781774s

22 step training time: 0.338255s

on_train_batch_end: 1615688511.119565s

23552/50000 [=============>................] - ETA: 8s - loss: 2.0371 - accuracy: 0.1002
on_train_batch_begin: 1615688511.119857s

23 step training time: 0.338084s

on_train_batch_end: 1615688511.455044s

24576/50000 [=============>................] - ETA: 8s - loss: 2.0257 - accuracy: 0.1002
on_train_batch_begin: 1615688511.455330s

24 step training time: 0.335473s

on_train_batch_end: 1615688511.794074s

25600/50000 [==============>...............] - ETA: 8s - loss: 2.0157 - accuracy: 0.1002
on_train_batch_begin: 1615688511.794354s

25 step training time: 0.339024s

on_train_batch_end: 1615688512.131711s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.0047 - accuracy: 0.1002
on_train_batch_begin: 1615688512.132004s

26 step training time: 0.337650s

on_train_batch_end: 1615688512.468912s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.9905 - accuracy: 0.1002
on_train_batch_begin: 1615688512.469181s

27 step training time: 0.337177s

on_train_batch_end: 1615688512.809500s

28672/50000 [================>.............] - ETA: 7s - loss: 1.9834 - accuracy: 0.1002
on_train_batch_begin: 1615688512.809776s

28 step training time: 0.340595s

on_train_batch_end: 1615688513.146330s

29696/50000 [================>.............] - ETA: 6s - loss: 1.9775 - accuracy: 0.1002
on_train_batch_begin: 1615688513.146604s

29 step training time: 0.336828s

on_train_batch_end: 1615688513.484608s

30720/50000 [=================>............] - ETA: 6s - loss: 1.9670 - accuracy: 0.1002
on_train_batch_begin: 1615688513.484875s

30 step training time: 0.338271s

on_train_batch_end: 1615688513.825505s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.9633 - accuracy: 0.1002
on_train_batch_begin: 1615688513.825781s

31 step training time: 0.340906s

on_train_batch_end: 1615688514.163105s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.9576 - accuracy: 0.1002
on_train_batch_begin: 1615688514.163399s

32 step training time: 0.337619s

on_train_batch_end: 1615688514.499357s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.9505 - accuracy: 0.1002
on_train_batch_begin: 1615688514.499645s

33 step training time: 0.336246s

on_train_batch_end: 1615688514.839187s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.9351 - accuracy: 0.1002
on_train_batch_begin: 1615688514.839478s

34 step training time: 0.339834s

on_train_batch_end: 1615688515.178278s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.9248 - accuracy: 0.1002
on_train_batch_begin: 1615688515.178577s

35 step training time: 0.339098s

on_train_batch_end: 1615688515.515476s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.9185 - accuracy: 0.1002
on_train_batch_begin: 1615688515.515761s

36 step training time: 0.337184s

on_train_batch_end: 1615688515.855770s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.9088 - accuracy: 0.1002
on_train_batch_begin: 1615688515.856057s

37 step training time: 0.340295s

on_train_batch_end: 1615688516.199101s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.8993 - accuracy: 0.1001
on_train_batch_begin: 1615688516.199402s

38 step training time: 0.343345s

on_train_batch_end: 1615688516.539399s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.8887 - accuracy: 0.1002
on_train_batch_begin: 1615688516.539671s

39 step training time: 0.340269s

on_train_batch_end: 1615688516.879615s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.8855 - accuracy: 0.1002
on_train_batch_begin: 1615688516.879885s

40 step training time: 0.340214s

on_train_batch_end: 1615688517.217860s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.8793 - accuracy: 0.1002
on_train_batch_begin: 1615688517.218126s

41 step training time: 0.338241s

on_train_batch_end: 1615688517.555957s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.8697 - accuracy: 0.1002
on_train_batch_begin: 1615688517.556247s

42 step training time: 0.338122s

on_train_batch_end: 1615688517.897687s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.8591 - accuracy: 0.1002
on_train_batch_begin: 1615688517.897984s

43 step training time: 0.341736s

on_train_batch_end: 1615688518.235401s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8507 - accuracy: 0.1002
on_train_batch_begin: 1615688518.235693s

44 step training time: 0.337710s

on_train_batch_end: 1615688518.572595s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.8402 - accuracy: 0.1002
on_train_batch_begin: 1615688518.572879s

45 step training time: 0.337185s

on_train_batch_end: 1615688518.914148s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8325 - accuracy: 0.1002
on_train_batch_begin: 1615688518.914434s

46 step training time: 0.341555s

on_train_batch_end: 1615688519.255750s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.8265 - accuracy: 0.1002
on_train_batch_begin: 1615688519.256048s

47 step training time: 0.341614s

on_train_batch_end: 1615688519.593496s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8190 - accuracy: 0.1002
on_train_batch_begin: 1615688519.593789s

48 step training time: 0.337740s

on_train_batch_end: 1615688519.873992s

on_test_batch_begin: 1615688519.890408s

49 step training time: 0.296620s

on_epoch_end: 1615688520.691374s

Validation time: 0.800955s

Real time: 1615688520.691374s

Epoch time: 17.344103574752808s

50000/50000 [==============================] - 17s 347us/sample - loss: 1.8113 - accuracy: 0.1002 - val_loss: 6.9642 - val_accuracy: 0.1000

on_epoch_begin: 1615688520.691554s

Real time: 1615688520.69156
Epoch 4/5

on_train_batch_begin: 1615688520.694876s

on_train_batch_end: 1615688521.031221s

 1024/50000 [..............................] - ETA: 16s - loss: 1.3103 - accuracy: 0.0998
on_train_batch_begin: 1615688521.031486s

1 step training time: 0.336609s

on_train_batch_end: 1615688521.371130s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.3285 - accuracy: 0.1000
on_train_batch_begin: 1615688521.371403s

2 step training time: 0.339917s

on_train_batch_end: 1615688521.712779s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.3533 - accuracy: 0.1001
on_train_batch_begin: 1615688521.713045s

3 step training time: 0.341642s

on_train_batch_end: 1615688522.053434s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.3443 - accuracy: 0.1001
on_train_batch_begin: 1615688522.053731s

4 step training time: 0.340687s

on_train_batch_end: 1615688522.393388s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.3436 - accuracy: 0.1001
on_train_batch_begin: 1615688522.393679s

5 step training time: 0.339948s

on_train_batch_end: 1615688522.731844s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.3206 - accuracy: 0.1001
on_train_batch_begin: 1615688522.732106s

6 step training time: 0.338427s

on_train_batch_end: 1615688523.071071s

 7168/50000 [===>..........................] - ETA: 14s - loss: 1.3130 - accuracy: 0.1001
on_train_batch_begin: 1615688523.071321s

7 step training time: 0.339214s

on_train_batch_end: 1615688523.412765s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.2940 - accuracy: 0.1001
on_train_batch_begin: 1615688523.413027s

8 step training time: 0.341707s

on_train_batch_end: 1615688523.751417s

 9216/50000 [====>.........................] - ETA: 13s - loss: 1.2803 - accuracy: 0.1001
on_train_batch_begin: 1615688523.751707s

9 step training time: 0.338680s

on_train_batch_end: 1615688524.089230s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.2725 - accuracy: 0.1001
on_train_batch_begin: 1615688524.089550s

10 step training time: 0.337843s

on_train_batch_end: 1615688524.431096s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.2636 - accuracy: 0.1002
on_train_batch_begin: 1615688524.431389s

11 step training time: 0.341839s

on_train_batch_end: 1615688524.773764s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.2611 - accuracy: 0.1001
on_train_batch_begin: 1615688524.774048s

12 step training time: 0.342659s

on_train_batch_end: 1615688525.114251s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.2578 - accuracy: 0.1002
on_train_batch_begin: 1615688525.114555s

13 step training time: 0.340506s

on_train_batch_end: 1615688525.456505s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.2659 - accuracy: 0.1002
on_train_batch_begin: 1615688525.456806s

14 step training time: 0.342251s

on_train_batch_end: 1615688525.795135s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.2710 - accuracy: 0.1001
on_train_batch_begin: 1615688525.795433s

15 step training time: 0.338627s

on_train_batch_end: 1615688526.136160s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.2638 - accuracy: 0.1002
on_train_batch_begin: 1615688526.136458s

16 step training time: 0.341025s

on_train_batch_end: 1615688526.478421s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.2566 - accuracy: 0.1002
on_train_batch_begin: 1615688526.478719s

17 step training time: 0.342262s

on_train_batch_end: 1615688526.819535s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.2510 - accuracy: 0.1002
on_train_batch_begin: 1615688526.819804s

18 step training time: 0.341085s

on_train_batch_end: 1615688527.181681s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.2432 - accuracy: 0.1002
on_train_batch_begin: 1615688527.181938s

19 step training time: 0.362134s

on_train_batch_end: 1615688527.519983s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.2378 - accuracy: 0.1002 
on_train_batch_begin: 1615688527.520231s

20 step training time: 0.338294s

on_train_batch_end: 1615688527.849941s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.2421 - accuracy: 0.1002
on_train_batch_begin: 1615688527.850198s

21 step training time: 0.329967s

on_train_batch_end: 1615688528.191315s

22528/50000 [============>.................] - ETA: 9s - loss: 1.2371 - accuracy: 0.1002
on_train_batch_begin: 1615688528.191584s

22 step training time: 0.341386s

on_train_batch_end: 1615688528.535230s

23552/50000 [=============>................] - ETA: 8s - loss: 1.2313 - accuracy: 0.1002
on_train_batch_begin: 1615688528.535541s

23 step training time: 0.343956s

on_train_batch_end: 1615688528.876777s

24576/50000 [=============>................] - ETA: 8s - loss: 1.2323 - accuracy: 0.1002
on_train_batch_begin: 1615688528.877071s

24 step training time: 0.341531s

on_train_batch_end: 1615688529.218725s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.2287 - accuracy: 0.1002
on_train_batch_begin: 1615688529.219000s

25 step training time: 0.341929s

on_train_batch_end: 1615688529.562740s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.2216 - accuracy: 0.1002
on_train_batch_begin: 1615688529.563014s

26 step training time: 0.344013s

on_train_batch_end: 1615688529.904219s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.2149 - accuracy: 0.1002
on_train_batch_begin: 1615688529.904505s

27 step training time: 0.341491s

on_train_batch_end: 1615688530.242423s

28672/50000 [================>.............] - ETA: 7s - loss: 1.2140 - accuracy: 0.1002
on_train_batch_begin: 1615688530.242716s

28 step training time: 0.338211s

on_train_batch_end: 1615688530.586102s

29696/50000 [================>.............] - ETA: 6s - loss: 1.2069 - accuracy: 0.1002
on_train_batch_begin: 1615688530.586400s

29 step training time: 0.343684s

on_train_batch_end: 1615688530.929615s

30720/50000 [=================>............] - ETA: 6s - loss: 1.2041 - accuracy: 0.1002
on_train_batch_begin: 1615688530.929909s

30 step training time: 0.343508s

on_train_batch_end: 1615688531.267546s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.2035 - accuracy: 0.1002
on_train_batch_begin: 1615688531.267812s

31 step training time: 0.337904s

on_train_batch_end: 1615688531.610617s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.1985 - accuracy: 0.1002
on_train_batch_begin: 1615688531.610863s

32 step training time: 0.343050s

on_train_batch_end: 1615688531.952625s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.1962 - accuracy: 0.1002
on_train_batch_begin: 1615688531.952875s

33 step training time: 0.342012s

on_train_batch_end: 1615688532.295072s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.1944 - accuracy: 0.1002
on_train_batch_begin: 1615688532.295329s

34 step training time: 0.342455s

on_train_batch_end: 1615688532.634808s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.1914 - accuracy: 0.1002
on_train_batch_begin: 1615688532.635102s

35 step training time: 0.339773s

on_train_batch_end: 1615688532.977682s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.1931 - accuracy: 0.1002
on_train_batch_begin: 1615688532.977965s

36 step training time: 0.342863s

on_train_batch_end: 1615688533.320463s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.1906 - accuracy: 0.1002
on_train_batch_begin: 1615688533.320719s

37 step training time: 0.342753s

on_train_batch_end: 1615688533.662517s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.1870 - accuracy: 0.1002
on_train_batch_begin: 1615688533.662757s

38 step training time: 0.342038s

on_train_batch_end: 1615688534.004333s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.1857 - accuracy: 0.1002
on_train_batch_begin: 1615688534.004610s

39 step training time: 0.341853s

on_train_batch_end: 1615688534.349892s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.1825 - accuracy: 0.1002
on_train_batch_begin: 1615688534.350163s

40 step training time: 0.345553s

on_train_batch_end: 1615688534.694578s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.1783 - accuracy: 0.1002
on_train_batch_begin: 1615688534.694867s

41 step training time: 0.344705s

on_train_batch_end: 1615688535.038729s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.1782 - accuracy: 0.1002
on_train_batch_begin: 1615688535.039002s

42 step training time: 0.344135s

on_train_batch_end: 1615688535.382944s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.1754 - accuracy: 0.1002
on_train_batch_begin: 1615688535.383243s

43 step training time: 0.344241s

on_train_batch_end: 1615688535.725295s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.1754 - accuracy: 0.1002
on_train_batch_begin: 1615688535.725587s

44 step training time: 0.342344s

on_train_batch_end: 1615688536.065842s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.1736 - accuracy: 0.1002
on_train_batch_begin: 1615688536.066123s

45 step training time: 0.340536s

on_train_batch_end: 1615688536.409928s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.1703 - accuracy: 0.1002
on_train_batch_begin: 1615688536.410187s

46 step training time: 0.344064s

on_train_batch_end: 1615688536.752770s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1687 - accuracy: 0.1002
on_train_batch_begin: 1615688536.753057s

47 step training time: 0.342870s

on_train_batch_end: 1615688537.095854s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1669 - accuracy: 0.1002
on_train_batch_begin: 1615688537.096140s

48 step training time: 0.343083s

on_train_batch_end: 1615688537.381995s

on_test_batch_begin: 1615688537.394176s

49 step training time: 0.298036s

on_epoch_end: 1615688538.204381s

Validation time: 0.810194s

Real time: 1615688538.204381s

Epoch time: 17.51283621788025s

50000/50000 [==============================] - 18s 350us/sample - loss: 1.1628 - accuracy: 0.1002 - val_loss: 6.9819 - val_accuracy: 0.0999

on_epoch_begin: 1615688538.204560s

Real time: 1615688538.2045655
Epoch 5/5

on_train_batch_begin: 1615688538.207841s

on_train_batch_end: 1615688538.546135s

 1024/50000 [..............................] - ETA: 16s - loss: 0.8081 - accuracy: 0.1009
on_train_batch_begin: 1615688538.546407s

1 step training time: 0.338566s

on_train_batch_end: 1615688538.889502s

 2048/50000 [>.............................] - ETA: 16s - loss: 0.8211 - accuracy: 0.1005
on_train_batch_begin: 1615688538.889787s

2 step training time: 0.343381s

on_train_batch_end: 1615688539.234063s

 3072/50000 [>.............................] - ETA: 15s - loss: 0.8355 - accuracy: 0.1004
on_train_batch_begin: 1615688539.234331s

3 step training time: 0.344543s

on_train_batch_end: 1615688539.575465s

 4096/50000 [=>............................] - ETA: 15s - loss: 0.8242 - accuracy: 0.1006
on_train_batch_begin: 1615688539.575706s

4 step training time: 0.341376s

on_train_batch_end: 1615688539.918336s

 5120/50000 [==>...........................] - ETA: 15s - loss: 0.8536 - accuracy: 0.1003
on_train_batch_begin: 1615688539.918601s

5 step training time: 0.342894s

on_train_batch_end: 1615688540.262573s

 6144/50000 [==>...........................] - ETA: 14s - loss: 0.8603 - accuracy: 0.1003
on_train_batch_begin: 1615688540.262830s

6 step training time: 0.344229s

on_train_batch_end: 1615688540.607197s

 7168/50000 [===>..........................] - ETA: 14s - loss: 0.8599 - accuracy: 0.1004
on_train_batch_begin: 1615688540.607489s

7 step training time: 0.344660s

on_train_batch_end: 1615688540.952718s

 8192/50000 [===>..........................] - ETA: 14s - loss: 0.8599 - accuracy: 0.1004
on_train_batch_begin: 1615688540.953011s

8 step training time: 0.345522s

on_train_batch_end: 1615688541.294941s

 9216/50000 [====>.........................] - ETA: 13s - loss: 0.8510 - accuracy: 0.1003
on_train_batch_begin: 1615688541.295204s

9 step training time: 0.342193s

on_train_batch_end: 1615688541.637306s

10240/50000 [=====>........................] - ETA: 13s - loss: 0.8443 - accuracy: 0.1003
on_train_batch_begin: 1615688541.637597s

10 step training time: 0.342393s

on_train_batch_end: 1615688541.980984s

11264/50000 [=====>........................] - ETA: 12s - loss: 0.8483 - accuracy: 0.1003
on_train_batch_begin: 1615688541.981279s

11 step training time: 0.343682s

on_train_batch_end: 1615688542.325831s

12288/50000 [======>.......................] - ETA: 12s - loss: 0.8383 - accuracy: 0.1003
on_train_batch_begin: 1615688542.326123s

12 step training time: 0.344844s

on_train_batch_end: 1615688542.670191s

13312/50000 [======>.......................] - ETA: 12s - loss: 0.8428 - accuracy: 0.1003
on_train_batch_begin: 1615688542.670484s

13 step training time: 0.344361s

on_train_batch_end: 1615688543.014684s

14336/50000 [=======>......................] - ETA: 11s - loss: 0.8480 - accuracy: 0.1003
on_train_batch_begin: 1615688543.014975s

14 step training time: 0.344491s

on_train_batch_end: 1615688543.355422s

15360/50000 [========>.....................] - ETA: 11s - loss: 0.8424 - accuracy: 0.1004
on_train_batch_begin: 1615688543.355688s

15 step training time: 0.340713s

on_train_batch_end: 1615688543.700966s

16384/50000 [========>.....................] - ETA: 11s - loss: 0.8441 - accuracy: 0.1004
on_train_batch_begin: 1615688543.701227s

16 step training time: 0.345539s

on_train_batch_end: 1615688544.045553s

17408/50000 [=========>....................] - ETA: 10s - loss: 0.8483 - accuracy: 0.1004
on_train_batch_begin: 1615688544.045815s

17 step training time: 0.344588s

on_train_batch_end: 1615688544.389514s

18432/50000 [==========>...................] - ETA: 10s - loss: 0.8440 - accuracy: 0.1004
on_train_batch_begin: 1615688544.389773s

18 step training time: 0.343959s

on_train_batch_end: 1615688544.734857s

19456/50000 [==========>...................] - ETA: 10s - loss: 0.8447 - accuracy: 0.1004
on_train_batch_begin: 1615688544.735147s

19 step training time: 0.345373s

on_train_batch_end: 1615688545.077671s

20480/50000 [===========>..................] - ETA: 9s - loss: 0.8447 - accuracy: 0.1004 
on_train_batch_begin: 1615688545.077953s

20 step training time: 0.342806s

on_train_batch_end: 1615688545.423537s

21504/50000 [===========>..................] - ETA: 9s - loss: 0.8404 - accuracy: 0.1004
on_train_batch_begin: 1615688545.423798s

21 step training time: 0.345845s

on_train_batch_end: 1615688545.768852s

22528/50000 [============>.................] - ETA: 9s - loss: 0.8351 - accuracy: 0.1004
on_train_batch_begin: 1615688545.769134s

22 step training time: 0.345336s

on_train_batch_end: 1615688546.114933s

23552/50000 [=============>................] - ETA: 8s - loss: 0.8363 - accuracy: 0.1004
on_train_batch_begin: 1615688546.115221s

23 step training time: 0.346087s

on_train_batch_end: 1615688546.459442s

24576/50000 [=============>................] - ETA: 8s - loss: 0.8353 - accuracy: 0.1004
on_train_batch_begin: 1615688546.459719s

24 step training time: 0.344498s

on_train_batch_end: 1615688546.805840s

25600/50000 [==============>...............] - ETA: 8s - loss: 0.8337 - accuracy: 0.1004
on_train_batch_begin: 1615688546.806133s

25 step training time: 0.346414s

on_train_batch_end: 1615688547.152030s

26624/50000 [==============>...............] - ETA: 7s - loss: 0.8317 - accuracy: 0.1004
on_train_batch_begin: 1615688547.152322s

26 step training time: 0.346189s

on_train_batch_end: 1615688547.497007s

27648/50000 [===============>..............] - ETA: 7s - loss: 0.8325 - accuracy: 0.1004
on_train_batch_begin: 1615688547.497290s

27 step training time: 0.344968s

on_train_batch_end: 1615688547.838522s

28672/50000 [================>.............] - ETA: 7s - loss: 0.8329 - accuracy: 0.1004
on_train_batch_begin: 1615688547.838817s

28 step training time: 0.341527s

on_train_batch_end: 1615688548.186810s

29696/50000 [================>.............] - ETA: 6s - loss: 0.8317 - accuracy: 0.1004
on_train_batch_begin: 1615688548.187100s

29 step training time: 0.348283s

on_train_batch_end: 1615688548.531844s

30720/50000 [=================>............] - ETA: 6s - loss: 0.8300 - accuracy: 0.1004
on_train_batch_begin: 1615688548.532103s

30 step training time: 0.345003s

on_train_batch_end: 1615688548.878071s

31744/50000 [==================>...........] - ETA: 6s - loss: 0.8289 - accuracy: 0.1004
on_train_batch_begin: 1615688548.878359s

31 step training time: 0.346256s

on_train_batch_end: 1615688549.222506s

32768/50000 [==================>...........] - ETA: 5s - loss: 0.8261 - accuracy: 0.1004
on_train_batch_begin: 1615688549.222790s

32 step training time: 0.344431s

on_train_batch_end: 1615688549.568585s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.8261 - accuracy: 0.1004
on_train_batch_begin: 1615688549.568859s

33 step training time: 0.346068s

on_train_batch_end: 1615688549.915881s

34816/50000 [===================>..........] - ETA: 5s - loss: 0.8269 - accuracy: 0.1004
on_train_batch_begin: 1615688549.916149s

34 step training time: 0.347291s

on_train_batch_end: 1615688550.257377s

35840/50000 [====================>.........] - ETA: 4s - loss: 0.8287 - accuracy: 0.1004
on_train_batch_begin: 1615688550.257655s

35 step training time: 0.341506s

on_train_batch_end: 1615688550.603898s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.8310 - accuracy: 0.1004
on_train_batch_begin: 1615688550.604191s

36 step training time: 0.346536s

on_train_batch_end: 1615688550.948895s

37888/50000 [=====================>........] - ETA: 4s - loss: 0.8294 - accuracy: 0.1004
on_train_batch_begin: 1615688550.949191s

37 step training time: 0.345000s

on_train_batch_end: 1615688551.295153s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.8288 - accuracy: 0.1004
on_train_batch_begin: 1615688551.295437s

38 step training time: 0.346246s

on_train_batch_end: 1615688551.639536s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.8262 - accuracy: 0.1004
on_train_batch_begin: 1615688551.639807s

39 step training time: 0.344370s

on_train_batch_end: 1615688551.983442s

40960/50000 [=======================>......] - ETA: 3s - loss: 0.8223 - accuracy: 0.1004
on_train_batch_begin: 1615688551.983712s

40 step training time: 0.343905s

on_train_batch_end: 1615688552.330012s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.8221 - accuracy: 0.1004
on_train_batch_begin: 1615688552.330278s

41 step training time: 0.346565s

on_train_batch_end: 1615688552.676187s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.8212 - accuracy: 0.1004
on_train_batch_begin: 1615688552.676449s

42 step training time: 0.346171s

on_train_batch_end: 1615688553.016602s

44032/50000 [=========================>....] - ETA: 2s - loss: 0.8203 - accuracy: 0.1004
on_train_batch_begin: 1615688553.016896s

43 step training time: 0.340447s

on_train_batch_end: 1615688553.360690s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.8224 - accuracy: 0.1004
on_train_batch_begin: 1615688553.360961s

44 step training time: 0.344065s

on_train_batch_end: 1615688553.703173s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.8224 - accuracy: 0.1004
on_train_batch_begin: 1615688553.703434s

45 step training time: 0.342473s

on_train_batch_end: 1615688554.050197s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.8200 - accuracy: 0.1004
on_train_batch_begin: 1615688554.050474s

46 step training time: 0.347040s

on_train_batch_end: 1615688554.392745s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.8192 - accuracy: 0.1004
on_train_batch_begin: 1615688554.393014s

47 step training time: 0.342540s

on_train_batch_end: 1615688554.735611s

49152/50000 [============================>.] - ETA: 0s - loss: 0.8185 - accuracy: 0.1004
on_train_batch_begin: 1615688554.735849s

48 step training time: 0.342835s

on_train_batch_end: 1615688555.024906s

on_test_batch_begin: 1615688555.040546s

49 step training time: 0.304697s

on_epoch_end: 1615688555.866451s

Validation time: 0.825889s

Real time: 1615688555.866451s

Epoch time: 17.661900997161865s

50000/50000 [==============================] - 18s 353us/sample - loss: 0.8174 - accuracy: 0.1004 - val_loss: 7.1682 - val_accuracy: 0.0999
Tempo do fit: 118.18190455436707