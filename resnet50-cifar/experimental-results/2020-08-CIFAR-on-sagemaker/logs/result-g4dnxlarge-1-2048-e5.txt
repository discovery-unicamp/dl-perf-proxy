wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:32
   221184/170498071 [..............................] - ETA: 1:07
  1581056/170498071 [..............................] - ETA: 14s 
  4677632/170498071 [..............................] - ETA: 6s 
  7872512/170498071 [>.............................] - ETA: 4s
 11198464/170498071 [>.............................] - ETA: 4s
 14671872/170498071 [=>............................] - ETA: 3s
 18227200/170498071 [==>...........................] - ETA: 3s
 21700608/170498071 [==>...........................] - ETA: 3s
 25223168/170498071 [===>..........................] - ETA: 2s
 28516352/170498071 [====>.........................] - ETA: 2s
 32038912/170498071 [====>.........................] - ETA: 2s
 35594240/170498071 [=====>........................] - ETA: 2s
 39133184/170498071 [=====>........................] - ETA: 2s
 42491904/170498071 [======>.......................] - ETA: 2s
 45948928/170498071 [=======>......................] - ETA: 2s
 49520640/170498071 [=======>......................] - ETA: 2s
 53092352/170498071 [========>.....................] - ETA: 1s
 56500224/170498071 [========>.....................] - ETA: 1s
 59817984/170498071 [=========>....................] - ETA: 1s
 63430656/170498071 [==========>...................] - ETA: 1s
 66969600/170498071 [==========>...................] - ETA: 1s
 69902336/170498071 [===========>..................] - ETA: 1s
 73801728/170498071 [===========>..................] - ETA: 1s
 77307904/170498071 [============>.................] - ETA: 1s
 80896000/170498071 [=============>................] - ETA: 1s
 84467712/170498071 [=============>................] - ETA: 1s
 87859200/170498071 [==============>...............] - ETA: 1s
 91267072/170498071 [===============>..............] - ETA: 1s
 94691328/170498071 [===============>..............] - ETA: 1s
 98394112/170498071 [================>.............] - ETA: 1s
101851136/170498071 [================>.............] - ETA: 1s
105209856/170498071 [=================>............] - ETA: 1s
108617728/170498071 [==================>...........] - ETA: 0s
112238592/170498071 [==================>...........] - ETA: 0s
115859456/170498071 [===================>..........] - ETA: 0s
119152640/170498071 [===================>..........] - ETA: 0s
122544128/170498071 [====================>.........] - ETA: 0s
126066688/170498071 [=====================>........] - ETA: 0s
129703936/170498071 [=====================>........] - ETA: 0s
133160960/170498071 [======================>.......] - ETA: 0s
136552448/170498071 [=======================>......] - ETA: 0s
139976704/170498071 [=======================>......] - ETA: 0s
143572992/170498071 [========================>.....] - ETA: 0s
147202048/170498071 [========================>.....] - ETA: 0s
150577152/170498071 [=========================>....] - ETA: 0s
153952256/170498071 [==========================>...] - ETA: 0s
157540352/170498071 [==========================>...] - ETA: 0s
161177600/170498071 [===========================>..] - ETA: 0s
164503552/170498071 [===========================>..] - ETA: 0s
167895040/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 1114112/94765736 [..............................] - ETA: 5s
 3842048/94765736 [>.............................] - ETA: 2s
 9388032/94765736 [=>............................] - ETA: 1s
15720448/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
22413312/94765736 [======>.......................] - ETA: 1s
29908992/94765736 [========>.....................] - ETA: 0s
36143104/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
46407680/94765736 [=============>................] - ETA: 0s
48308224/94765736 [==============>...............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
71090176/94765736 [=====================>........] - ETA: 0s
75964416/94765736 [=======================>......] - ETA: 0s
82690048/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
87195648/94765736 [==========================>...] - ETA: 0s
90734592/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.6315279006958
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615749145.239865s

Real time: 1615749145.2398822
Epoch 1/5

on_train_batch_begin: 1615749146.009924s

on_train_batch_end: 1615749166.102445s

 2048/50000 [>.............................] - ETA: 8:08 - loss: 17.7114 - accuracy: 3.6335e-04
on_train_batch_begin: 1615749166.103046s

1 step training time: 20.093122s

on_train_batch_end: 1615749166.773026s

 4096/50000 [=>............................] - ETA: 4:01 - loss: 13.6488 - accuracy: 4.3082e-04
on_train_batch_begin: 1615749166.773332s

2 step training time: 0.670286s

on_train_batch_end: 1615749167.438462s

 6144/50000 [==>...........................] - ETA: 2:38 - loss: 11.8431 - accuracy: 9.1481e-04
on_train_batch_begin: 1615749167.438759s

3 step training time: 0.665427s

on_train_batch_end: 1615749168.099746s

 8192/50000 [===>..........................] - ETA: 1:56 - loss: 10.9115 - accuracy: 0.0025    
on_train_batch_begin: 1615749168.100049s

4 step training time: 0.661290s

on_train_batch_end: 1615749168.770222s

10240/50000 [=====>........................] - ETA: 1:31 - loss: 10.3465 - accuracy: 0.0059
on_train_batch_begin: 1615749168.770515s

5 step training time: 0.670465s

on_train_batch_end: 1615749169.445885s

12288/50000 [======>.......................] - ETA: 1:14 - loss: 9.9193 - accuracy: 0.0107 
on_train_batch_begin: 1615749169.446192s

6 step training time: 0.675677s

on_train_batch_end: 1615749170.115868s

14336/50000 [=======>......................] - ETA: 1:01 - loss: 9.6233 - accuracy: 0.0159
on_train_batch_begin: 1615749170.116178s

7 step training time: 0.669986s

on_train_batch_end: 1615749170.789279s

16384/50000 [========>.....................] - ETA: 52s - loss: 9.3907 - accuracy: 0.0194 
on_train_batch_begin: 1615749170.789599s

8 step training time: 0.673421s

on_train_batch_end: 1615749171.465464s

18432/50000 [==========>...................] - ETA: 44s - loss: 9.1872 - accuracy: 0.0224
on_train_batch_begin: 1615749171.465765s

9 step training time: 0.676165s

on_train_batch_end: 1615749172.145478s

20480/50000 [===========>..................] - ETA: 38s - loss: 9.0169 - accuracy: 0.0254
on_train_batch_begin: 1615749172.145775s

10 step training time: 0.680010s

on_train_batch_end: 1615749172.824176s

22528/50000 [============>.................] - ETA: 33s - loss: 8.8948 - accuracy: 0.0274
on_train_batch_begin: 1615749172.824493s

11 step training time: 0.678718s

on_train_batch_end: 1615749173.501903s

24576/50000 [=============>................] - ETA: 29s - loss: 8.7702 - accuracy: 0.0301
on_train_batch_begin: 1615749173.502211s

12 step training time: 0.677717s

on_train_batch_end: 1615749174.183624s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.6733 - accuracy: 0.0327
on_train_batch_begin: 1615749174.183921s

13 step training time: 0.681711s

on_train_batch_end: 1615749174.855166s

28672/50000 [================>.............] - ETA: 22s - loss: 8.5815 - accuracy: 0.0356
on_train_batch_begin: 1615749174.855464s

14 step training time: 0.671543s

on_train_batch_end: 1615749175.525146s

30720/50000 [=================>............] - ETA: 19s - loss: 8.4938 - accuracy: 0.0384
on_train_batch_begin: 1615749175.525459s

15 step training time: 0.669994s

on_train_batch_end: 1615749176.199630s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.4123 - accuracy: 0.0408
on_train_batch_begin: 1615749176.199936s

16 step training time: 0.674477s

on_train_batch_end: 1615749176.845598s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.3413 - accuracy: 0.0437
on_train_batch_begin: 1615749176.845891s

17 step training time: 0.645956s

on_train_batch_end: 1615749177.533542s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.2727 - accuracy: 0.0462
on_train_batch_begin: 1615749177.533836s

18 step training time: 0.687944s

on_train_batch_end: 1615749178.203145s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.2051 - accuracy: 0.0471 
on_train_batch_begin: 1615749178.203440s

19 step training time: 0.669604s

on_train_batch_end: 1615749178.886097s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.1526 - accuracy: 0.0482
on_train_batch_begin: 1615749178.886392s

20 step training time: 0.682952s

on_train_batch_end: 1615749179.554831s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.0927 - accuracy: 0.0495
on_train_batch_begin: 1615749179.555126s

21 step training time: 0.668734s

on_train_batch_end: 1615749180.232745s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.0396 - accuracy: 0.0509
on_train_batch_begin: 1615749180.233043s

22 step training time: 0.677917s

on_train_batch_end: 1615749180.906609s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.9913 - accuracy: 0.0522
on_train_batch_begin: 1615749180.906915s

23 step training time: 0.673871s

on_train_batch_end: 1615749181.582289s

49152/50000 [============================>.] - ETA: 0s - loss: 7.9462 - accuracy: 0.0530
on_train_batch_begin: 1615749181.582603s

24 step training time: 0.675689s

on_train_batch_end: 1615749187.667610s

on_test_batch_begin: 1615749187.856352s

25 step training time: 6.273748s

on_epoch_end: 1615749193.088063s

Validation time: 5.231694s

Real time: 1615749193.088063s

Epoch time: 47.84819746017456s

50000/50000 [==============================] - 48s 957us/sample - loss: 7.9284 - accuracy: 0.0532 - val_loss: 7995.2998 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615749193.088276s

Real time: 1615749193.0882807
Epoch 2/5

on_train_batch_begin: 1615749193.091726s

on_train_batch_end: 1615749193.773461s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.8866 - accuracy: 0.0757
on_train_batch_begin: 1615749193.773760s

1 step training time: 0.682034s

on_train_batch_end: 1615749194.464156s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.8012 - accuracy: 0.0746
on_train_batch_begin: 1615749194.464526s

2 step training time: 0.690766s

on_train_batch_end: 1615749195.148423s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.7503 - accuracy: 0.0752
on_train_batch_begin: 1615749195.148718s

3 step training time: 0.684192s

on_train_batch_end: 1615749195.842843s

 8192/50000 [===>..........................] - ETA: 14s - loss: 6.7372 - accuracy: 0.0736
on_train_batch_begin: 1615749195.843141s

4 step training time: 0.694424s

on_train_batch_end: 1615749196.533404s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.7110 - accuracy: 0.0731
on_train_batch_begin: 1615749196.533699s

5 step training time: 0.690558s

on_train_batch_end: 1615749197.223082s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.6876 - accuracy: 0.0734
on_train_batch_begin: 1615749197.223376s

6 step training time: 0.689677s

on_train_batch_end: 1615749197.903920s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.6701 - accuracy: 0.0743
on_train_batch_begin: 1615749197.904230s

7 step training time: 0.680855s

on_train_batch_end: 1615749198.594333s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.6442 - accuracy: 0.0755
on_train_batch_begin: 1615749198.594650s

8 step training time: 0.690419s

on_train_batch_end: 1615749199.283981s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.6223 - accuracy: 0.0765
on_train_batch_begin: 1615749199.284291s

9 step training time: 0.689641s

on_train_batch_end: 1615749199.975235s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.6111 - accuracy: 0.0763 
on_train_batch_begin: 1615749199.975532s

10 step training time: 0.691242s

on_train_batch_end: 1615749200.656971s

22528/50000 [============>.................] - ETA: 9s - loss: 6.5901 - accuracy: 0.0766
on_train_batch_begin: 1615749200.657279s

11 step training time: 0.681746s

on_train_batch_end: 1615749201.346403s

24576/50000 [=============>................] - ETA: 8s - loss: 6.5723 - accuracy: 0.0763
on_train_batch_begin: 1615749201.346706s

12 step training time: 0.689428s

on_train_batch_end: 1615749202.037348s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.5486 - accuracy: 0.0765
on_train_batch_begin: 1615749202.037671s

13 step training time: 0.690965s

on_train_batch_end: 1615749202.737179s

28672/50000 [================>.............] - ETA: 7s - loss: 6.5233 - accuracy: 0.0767
on_train_batch_begin: 1615749202.737496s

14 step training time: 0.699824s

on_train_batch_end: 1615749203.435861s

30720/50000 [=================>............] - ETA: 6s - loss: 6.4996 - accuracy: 0.0763
on_train_batch_begin: 1615749203.436161s

15 step training time: 0.698665s

on_train_batch_end: 1615749204.126310s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.4641 - accuracy: 0.0760
on_train_batch_begin: 1615749204.126602s

16 step training time: 0.690441s

on_train_batch_end: 1615749204.827906s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.4280 - accuracy: 0.0754
on_train_batch_begin: 1615749204.828213s

17 step training time: 0.701611s

on_train_batch_end: 1615749205.529320s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.3861 - accuracy: 0.0749
on_train_batch_begin: 1615749205.529635s

18 step training time: 0.701422s

on_train_batch_end: 1615749206.219018s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.3377 - accuracy: 0.0742
on_train_batch_begin: 1615749206.219309s

19 step training time: 0.689673s

on_train_batch_end: 1615749206.921914s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.2927 - accuracy: 0.0734
on_train_batch_begin: 1615749206.922213s

20 step training time: 0.702904s

on_train_batch_end: 1615749207.618588s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.2535 - accuracy: 0.0727
on_train_batch_begin: 1615749207.618892s

21 step training time: 0.696679s

on_train_batch_end: 1615749208.310701s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.2103 - accuracy: 0.0721
on_train_batch_begin: 1615749208.311000s

22 step training time: 0.692109s

on_train_batch_end: 1615749209.008025s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.1685 - accuracy: 0.0717
on_train_batch_begin: 1615749209.008328s

23 step training time: 0.697327s

on_train_batch_end: 1615749209.696189s

49152/50000 [============================>.] - ETA: 0s - loss: 6.1258 - accuracy: 0.0714
on_train_batch_begin: 1615749209.696485s

24 step training time: 0.688157s

on_train_batch_end: 1615749209.990444s

on_test_batch_begin: 1615749210.010566s

25 step training time: 0.314080s

on_epoch_end: 1615749210.930525s

Validation time: 0.919948s

Real time: 1615749210.930525s

Epoch time: 17.84226155281067s

50000/50000 [==============================] - 18s 357us/sample - loss: 6.1052 - accuracy: 0.0714 - val_loss: 11.5252 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615749210.930722s

Real time: 1615749210.930727
Epoch 3/5

on_train_batch_begin: 1615749210.934093s

on_train_batch_end: 1615749211.624900s

 2048/50000 [>.............................] - ETA: 16s - loss: 4.8390 - accuracy: 0.0641
on_train_batch_begin: 1615749211.625232s

1 step training time: 0.691139s

on_train_batch_end: 1615749212.328228s

 4096/50000 [=>............................] - ETA: 15s - loss: 4.8200 - accuracy: 0.0648
on_train_batch_begin: 1615749212.328532s

2 step training time: 0.703299s

on_train_batch_end: 1615749213.017652s

 6144/50000 [==>...........................] - ETA: 14s - loss: 4.7606 - accuracy: 0.0657
on_train_batch_begin: 1615749213.017951s

3 step training time: 0.689419s

on_train_batch_end: 1615749213.724948s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.7056 - accuracy: 0.0659
on_train_batch_begin: 1615749213.725264s

4 step training time: 0.707314s

on_train_batch_end: 1615749214.428722s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.6474 - accuracy: 0.0668
on_train_batch_begin: 1615749214.429017s

5 step training time: 0.703753s

on_train_batch_end: 1615749215.128551s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.5818 - accuracy: 0.0678
on_train_batch_begin: 1615749215.128850s

6 step training time: 0.699833s

on_train_batch_end: 1615749215.831580s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.5217 - accuracy: 0.0690
on_train_batch_begin: 1615749215.831883s

7 step training time: 0.703033s

on_train_batch_end: 1615749216.526510s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.4811 - accuracy: 0.0699
on_train_batch_begin: 1615749216.526811s

8 step training time: 0.694929s

on_train_batch_end: 1615749217.230412s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.4232 - accuracy: 0.0711
on_train_batch_begin: 1615749217.230709s

9 step training time: 0.703897s

on_train_batch_end: 1615749217.942125s

20480/50000 [===========>..................] - ETA: 10s - loss: 4.3719 - accuracy: 0.0721
on_train_batch_begin: 1615749217.942419s

10 step training time: 0.711710s

on_train_batch_end: 1615749218.650061s

22528/50000 [============>.................] - ETA: 9s - loss: 4.3153 - accuracy: 0.0731 
on_train_batch_begin: 1615749218.650364s

11 step training time: 0.707945s

on_train_batch_end: 1615749219.358995s

24576/50000 [=============>................] - ETA: 8s - loss: 4.2811 - accuracy: 0.0739
on_train_batch_begin: 1615749219.359293s

12 step training time: 0.708929s

on_train_batch_end: 1615749220.069119s

26624/50000 [==============>...............] - ETA: 8s - loss: 4.2518 - accuracy: 0.0746
on_train_batch_begin: 1615749220.069453s

13 step training time: 0.710161s

on_train_batch_end: 1615749220.786650s

28672/50000 [================>.............] - ETA: 7s - loss: 4.2056 - accuracy: 0.0754
on_train_batch_begin: 1615749220.786946s

14 step training time: 0.717493s

on_train_batch_end: 1615749221.492902s

30720/50000 [=================>............] - ETA: 6s - loss: 4.1744 - accuracy: 0.0759
on_train_batch_begin: 1615749221.493194s

15 step training time: 0.706248s

on_train_batch_end: 1615749222.205291s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.1471 - accuracy: 0.0766
on_train_batch_begin: 1615749222.205606s

16 step training time: 0.712412s

on_train_batch_end: 1615749222.916081s

34816/50000 [===================>..........] - ETA: 5s - loss: 4.1174 - accuracy: 0.0773
on_train_batch_begin: 1615749222.916384s

17 step training time: 0.710778s

on_train_batch_end: 1615749223.620048s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.0907 - accuracy: 0.0780
on_train_batch_begin: 1615749223.620354s

18 step training time: 0.703971s

on_train_batch_end: 1615749224.329545s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.0638 - accuracy: 0.0789
on_train_batch_begin: 1615749224.329841s

19 step training time: 0.709486s

on_train_batch_end: 1615749225.036501s

40960/50000 [=======================>......] - ETA: 3s - loss: 4.0390 - accuracy: 0.0795
on_train_batch_begin: 1615749225.036805s

20 step training time: 0.706965s

on_train_batch_end: 1615749225.749546s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.0222 - accuracy: 0.0800
on_train_batch_begin: 1615749225.749859s

21 step training time: 0.713053s

on_train_batch_end: 1615749226.470814s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.0110 - accuracy: 0.0805
on_train_batch_begin: 1615749226.471110s

22 step training time: 0.721251s

on_train_batch_end: 1615749227.178663s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.9900 - accuracy: 0.0811
on_train_batch_begin: 1615749227.178970s

23 step training time: 0.707860s

on_train_batch_end: 1615749227.893046s

49152/50000 [============================>.] - ETA: 0s - loss: 3.9762 - accuracy: 0.0815
on_train_batch_begin: 1615749227.893354s

24 step training time: 0.714384s

on_train_batch_end: 1615749228.201875s

on_test_batch_begin: 1615749228.221328s

25 step training time: 0.327974s

on_epoch_end: 1615749229.139321s

Validation time: 0.917966s

Real time: 1615749229.139321s

Epoch time: 18.208612203598022s

50000/50000 [==============================] - 18s 364us/sample - loss: 3.9700 - accuracy: 0.0816 - val_loss: 7.6631 - val_accuracy: 0.1001

on_epoch_begin: 1615749229.139519s

Real time: 1615749229.1395252
Epoch 4/5

on_train_batch_begin: 1615749229.142955s

on_train_batch_end: 1615749229.855466s

 2048/50000 [>.............................] - ETA: 16s - loss: 3.4253 - accuracy: 0.0923
on_train_batch_begin: 1615749229.855766s

1 step training time: 0.712811s

on_train_batch_end: 1615749230.564798s

 4096/50000 [=>............................] - ETA: 15s - loss: 3.3665 - accuracy: 0.0932
on_train_batch_begin: 1615749230.565103s

2 step training time: 0.709337s

on_train_batch_end: 1615749231.271249s

 6144/50000 [==>...........................] - ETA: 15s - loss: 3.3594 - accuracy: 0.0933
on_train_batch_begin: 1615749231.271551s

3 step training time: 0.706448s

on_train_batch_end: 1615749231.986398s

 8192/50000 [===>..........................] - ETA: 14s - loss: 3.3372 - accuracy: 0.0937
on_train_batch_begin: 1615749231.986696s

4 step training time: 0.715144s

on_train_batch_end: 1615749232.701188s

10240/50000 [=====>........................] - ETA: 13s - loss: 3.3364 - accuracy: 0.0939
on_train_batch_begin: 1615749232.701514s

5 step training time: 0.714818s

on_train_batch_end: 1615749233.409607s

12288/50000 [======>.......................] - ETA: 13s - loss: 3.3088 - accuracy: 0.0940
on_train_batch_begin: 1615749233.409905s

6 step training time: 0.708391s

on_train_batch_end: 1615749234.122514s

14336/50000 [=======>......................] - ETA: 12s - loss: 3.2892 - accuracy: 0.0942
on_train_batch_begin: 1615749234.122837s

7 step training time: 0.712932s

on_train_batch_end: 1615749234.833302s

16384/50000 [========>.....................] - ETA: 11s - loss: 3.2815 - accuracy: 0.0945
on_train_batch_begin: 1615749234.833631s

8 step training time: 0.710794s

on_train_batch_end: 1615749235.557142s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.2585 - accuracy: 0.0947
on_train_batch_begin: 1615749235.557475s

9 step training time: 0.723844s

on_train_batch_end: 1615749236.272391s

20480/50000 [===========>..................] - ETA: 10s - loss: 3.2451 - accuracy: 0.0949
on_train_batch_begin: 1615749236.272685s

10 step training time: 0.715210s

on_train_batch_end: 1615749236.990139s

22528/50000 [============>.................] - ETA: 9s - loss: 3.2463 - accuracy: 0.0950 
on_train_batch_begin: 1615749236.990429s

11 step training time: 0.717744s

on_train_batch_end: 1615749237.712923s

24576/50000 [=============>................] - ETA: 8s - loss: 3.2163 - accuracy: 0.0953
on_train_batch_begin: 1615749237.713220s

12 step training time: 0.722791s

on_train_batch_end: 1615749238.425532s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.2059 - accuracy: 0.0953
on_train_batch_begin: 1615749238.425833s

13 step training time: 0.712612s

on_train_batch_end: 1615749239.152124s

28672/50000 [================>.............] - ETA: 7s - loss: 3.1910 - accuracy: 0.0955
on_train_batch_begin: 1615749239.152429s

14 step training time: 0.726596s

on_train_batch_end: 1615749239.880676s

30720/50000 [=================>............] - ETA: 6s - loss: 3.1665 - accuracy: 0.0958
on_train_batch_begin: 1615749239.880966s

15 step training time: 0.728537s

on_train_batch_end: 1615749240.602845s

32768/50000 [==================>...........] - ETA: 6s - loss: 3.1584 - accuracy: 0.0958
on_train_batch_begin: 1615749240.603156s

16 step training time: 0.722190s

on_train_batch_end: 1615749241.325762s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.1420 - accuracy: 0.0959
on_train_batch_begin: 1615749241.326247s

17 step training time: 0.723091s

on_train_batch_end: 1615749242.062385s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.1213 - accuracy: 0.0961
on_train_batch_begin: 1615749242.062807s

18 step training time: 0.736559s

on_train_batch_end: 1615749242.788327s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.1114 - accuracy: 0.0963
on_train_batch_begin: 1615749242.788751s

19 step training time: 0.725945s

on_train_batch_end: 1615749243.505220s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.1028 - accuracy: 0.0965
on_train_batch_begin: 1615749243.505580s

20 step training time: 0.716829s

on_train_batch_end: 1615749244.233589s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.0871 - accuracy: 0.0966
on_train_batch_begin: 1615749244.233888s

21 step training time: 0.728308s

on_train_batch_end: 1615749244.957661s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.0743 - accuracy: 0.0967
on_train_batch_begin: 1615749244.957970s

22 step training time: 0.724082s

on_train_batch_end: 1615749245.682417s

47104/50000 [===========================>..] - ETA: 1s - loss: 3.0637 - accuracy: 0.0968
on_train_batch_begin: 1615749245.682717s

23 step training time: 0.724747s

on_train_batch_end: 1615749246.404906s

49152/50000 [============================>.] - ETA: 0s - loss: 3.0499 - accuracy: 0.0969
on_train_batch_begin: 1615749246.405198s

24 step training time: 0.722481s

on_train_batch_end: 1615749246.714604s

on_test_batch_begin: 1615749246.734601s

25 step training time: 0.329403s

on_epoch_end: 1615749247.664762s

Validation time: 0.930150s

Real time: 1615749247.664762s

Epoch time: 18.525253534317017s

50000/50000 [==============================] - 19s 371us/sample - loss: 3.0418 - accuracy: 0.0970 - val_loss: 8.3676 - val_accuracy: 0.0846

on_epoch_begin: 1615749247.664971s

Real time: 1615749247.6649783
Epoch 5/5

on_train_batch_begin: 1615749247.668419s

on_train_batch_end: 1615749248.396306s

 2048/50000 [>.............................] - ETA: 17s - loss: 2.6099 - accuracy: 0.0987
on_train_batch_begin: 1615749248.396601s

1 step training time: 0.728182s

on_train_batch_end: 1615749249.132236s

 4096/50000 [=>............................] - ETA: 16s - loss: 2.6175 - accuracy: 0.0980
on_train_batch_begin: 1615749249.132535s

2 step training time: 0.735934s

on_train_batch_end: 1615749249.860324s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.5844 - accuracy: 0.0980
on_train_batch_begin: 1615749249.860627s

3 step training time: 0.728092s

on_train_batch_end: 1615749250.595505s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.5599 - accuracy: 0.0981
on_train_batch_begin: 1615749250.595811s

4 step training time: 0.735183s

on_train_batch_end: 1615749251.320767s

10240/50000 [=====>........................] - ETA: 14s - loss: 2.5340 - accuracy: 0.0983
on_train_batch_begin: 1615749251.321065s

5 step training time: 0.725254s

on_train_batch_end: 1615749252.050624s

12288/50000 [======>.......................] - ETA: 13s - loss: 2.4659 - accuracy: 0.0984
on_train_batch_begin: 1615749252.050921s

6 step training time: 0.729856s

on_train_batch_end: 1615749252.779567s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.4114 - accuracy: 0.0987
on_train_batch_begin: 1615749252.779863s

7 step training time: 0.728941s

on_train_batch_end: 1615749253.503511s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.3640 - accuracy: 0.0989
on_train_batch_begin: 1615749253.503804s

8 step training time: 0.723942s

on_train_batch_end: 1615749254.236378s

18432/50000 [==========>...................] - ETA: 11s - loss: 2.3414 - accuracy: 0.0991
on_train_batch_begin: 1615749254.236684s

9 step training time: 0.732880s

on_train_batch_end: 1615749254.967767s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.3168 - accuracy: 0.0991
on_train_batch_begin: 1615749254.968078s

10 step training time: 0.731394s

on_train_batch_end: 1615749255.699120s

22528/50000 [============>.................] - ETA: 9s - loss: 2.2943 - accuracy: 0.0992 
on_train_batch_begin: 1615749255.699422s

11 step training time: 0.731345s

on_train_batch_end: 1615749256.434565s

24576/50000 [=============>................] - ETA: 9s - loss: 2.2747 - accuracy: 0.0992
on_train_batch_begin: 1615749256.434864s

12 step training time: 0.735441s

on_train_batch_end: 1615749257.158988s

26624/50000 [==============>...............] - ETA: 8s - loss: 2.2529 - accuracy: 0.0993
on_train_batch_begin: 1615749257.159291s

13 step training time: 0.724427s

on_train_batch_end: 1615749257.886747s

28672/50000 [================>.............] - ETA: 7s - loss: 2.2248 - accuracy: 0.0994
on_train_batch_begin: 1615749257.887051s

14 step training time: 0.727761s

on_train_batch_end: 1615749258.616225s

30720/50000 [=================>............] - ETA: 6s - loss: 2.2067 - accuracy: 0.0994
on_train_batch_begin: 1615749258.616524s

15 step training time: 0.729473s

on_train_batch_end: 1615749259.343420s

32768/50000 [==================>...........] - ETA: 6s - loss: 2.1832 - accuracy: 0.0994
on_train_batch_begin: 1615749259.343730s

16 step training time: 0.727206s

on_train_batch_end: 1615749260.071311s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.1613 - accuracy: 0.0995
on_train_batch_begin: 1615749260.071616s

17 step training time: 0.727885s

on_train_batch_end: 1615749260.800295s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.1423 - accuracy: 0.0995
on_train_batch_begin: 1615749260.800597s

18 step training time: 0.728982s

on_train_batch_end: 1615749261.524298s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.1227 - accuracy: 0.0996
on_train_batch_begin: 1615749261.524592s

19 step training time: 0.723995s

on_train_batch_end: 1615749262.250063s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.1006 - accuracy: 0.0996
on_train_batch_begin: 1615749262.250364s

20 step training time: 0.725772s

on_train_batch_end: 1615749262.972562s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.0844 - accuracy: 0.0996
on_train_batch_begin: 1615749262.972858s

21 step training time: 0.722494s

on_train_batch_end: 1615749263.711455s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.0719 - accuracy: 0.0996
on_train_batch_begin: 1615749263.711752s

22 step training time: 0.738895s

on_train_batch_end: 1615749264.451816s

47104/50000 [===========================>..] - ETA: 1s - loss: 2.0555 - accuracy: 0.0997
on_train_batch_begin: 1615749264.452151s

23 step training time: 0.740398s

on_train_batch_end: 1615749265.177572s

49152/50000 [============================>.] - ETA: 0s - loss: 2.0387 - accuracy: 0.0997
on_train_batch_begin: 1615749265.177876s

24 step training time: 0.725725s

on_train_batch_end: 1615749265.485394s

on_test_batch_begin: 1615749265.505128s

25 step training time: 0.327253s

on_epoch_end: 1615749266.447011s

Validation time: 0.941873s

Real time: 1615749266.447011s

Epoch time: 18.782048225402832s

50000/50000 [==============================] - 19s 376us/sample - loss: 2.0312 - accuracy: 0.0997 - val_loss: 7.2172 - val_accuracy: 0.1001
Tempo do fit: 124.67842483520508