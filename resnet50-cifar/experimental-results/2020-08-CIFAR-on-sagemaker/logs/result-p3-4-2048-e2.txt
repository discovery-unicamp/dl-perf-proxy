wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:46
   221184/170498071 [..............................] - ETA: 1:11
  1236992/170498071 [..............................] - ETA: 19s 
  4005888/170498071 [..............................] - ETA: 8s 
  7380992/170498071 [>.............................] - ETA: 5s
 10764288/170498071 [>.............................] - ETA: 4s
 14114816/170498071 [=>............................] - ETA: 3s
 17473536/170498071 [==>...........................] - ETA: 3s
 20652032/170498071 [==>...........................] - ETA: 3s
 23879680/170498071 [===>..........................] - ETA: 3s
 27230208/170498071 [===>..........................] - ETA: 2s
 30580736/170498071 [====>.........................] - ETA: 2s
 33939456/170498071 [====>.........................] - ETA: 2s
 37314560/170498071 [=====>........................] - ETA: 2s
 40673280/170498071 [======>.......................] - ETA: 2s
 44048384/170498071 [======>.......................] - ETA: 2s
 47210496/170498071 [=======>......................] - ETA: 2s
 50487296/170498071 [=======>......................] - ETA: 2s
 53747712/170498071 [========>.....................] - ETA: 2s
 57065472/170498071 [=========>....................] - ETA: 2s
 60440576/170498071 [=========>....................] - ETA: 1s
 63807488/170498071 [==========>...................] - ETA: 1s
 67182592/170498071 [==========>...................] - ETA: 1s
 70574080/170498071 [===========>..................] - ETA: 1s
 73883648/170498071 [============>.................] - ETA: 1s
 77209600/170498071 [============>.................] - ETA: 1s
 80519168/170498071 [=============>................] - ETA: 1s
 83861504/170498071 [=============>................] - ETA: 1s
 87236608/170498071 [==============>...............] - ETA: 1s
 90603520/170498071 [==============>...............] - ETA: 1s
 93986816/170498071 [===============>..............] - ETA: 1s
 97353728/170498071 [================>.............] - ETA: 1s
100573184/170498071 [================>.............] - ETA: 1s
103915520/170498071 [=================>............] - ETA: 1s
107143168/170498071 [=================>............] - ETA: 1s
110387200/170498071 [==================>...........] - ETA: 0s
113762304/170498071 [===================>..........] - ETA: 0s
117121024/170498071 [===================>..........] - ETA: 0s
120496128/170498071 [====================>.........] - ETA: 0s
123863040/170498071 [====================>.........] - ETA: 0s
127229952/170498071 [=====================>........] - ETA: 0s
130375680/170498071 [=====================>........] - ETA: 0s
133718016/170498071 [======================>.......] - ETA: 0s
137011200/170498071 [=======================>......] - ETA: 0s
140255232/170498071 [=======================>......] - ETA: 0s
143630336/170498071 [========================>.....] - ETA: 0s
146972672/170498071 [========================>.....] - ETA: 0s
150347776/170498071 [=========================>....] - ETA: 0s
153714688/170498071 [==========================>...] - ETA: 0s
157048832/170498071 [==========================>...] - ETA: 0s
160391168/170498071 [===========================>..] - ETA: 0s
163700736/170498071 [===========================>..] - ETA: 0s
167010304/170498071 [============================>.] - ETA: 0s
170352640/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 2s
 6365184/94765736 [=>............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 0s
11747328/94765736 [==>...........................] - ETA: 1s
17858560/94765736 [====>.........................] - ETA: 0s
20217856/94765736 [=====>........................] - ETA: 0s
27435008/94765736 [=======>......................] - ETA: 0s
32481280/94765736 [=========>....................] - ETA: 0s
38281216/94765736 [===========>..................] - ETA: 0s
43589632/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
47595520/94765736 [==============>...............] - ETA: 0s
53264384/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
59416576/94765736 [=================>............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
66510848/94765736 [====================>.........] - ETA: 0s
70418432/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
75964416/94765736 [=======================>......] - ETA: 0s
81346560/94765736 [========================>.....] - ETA: 0s
84115456/94765736 [=========================>....] - ETA: 0s
86007808/94765736 [==========================>...] - ETA: 0s
87990272/94765736 [==========================>...] - ETA: 0s
91078656/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 21.32948899269104
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1609199240.940207s

Real time: 1609199240.9402325
Epoch 1/5

on_train_batch_begin: 1609199241.981602s

on_train_batch_end: 1609199305.957357s

 2048/50000 [>.............................] - ETA: 25:22 - loss: 17.5055 - accuracy: 1.4496e-04
on_train_batch_begin: 1609199305.958240s

1 step training time: 63.976638s

on_train_batch_end: 1609199306.049363s

 4096/50000 [=>............................] - ETA: 12:09 - loss: 14.7535 - accuracy: 2.6608e-04
on_train_batch_begin: 1609199306.049862s

2 step training time: 0.091622s

on_train_batch_end: 1609199306.137899s

 6144/50000 [==>...........................] - ETA: 7:45 - loss: 12.7856 - accuracy: 4.6062e-04 
on_train_batch_begin: 1609199306.138410s

3 step training time: 0.088548s

on_train_batch_end: 1609199306.226939s

 8192/50000 [===>..........................] - ETA: 5:33 - loss: 11.7079 - accuracy: 0.0015    
on_train_batch_begin: 1609199306.227428s

4 step training time: 0.089018s

on_train_batch_end: 1609199306.316246s

10240/50000 [=====>........................] - ETA: 4:13 - loss: 10.9948 - accuracy: 0.0046
on_train_batch_begin: 1609199306.316726s

5 step training time: 0.089298s

on_train_batch_end: 1609199306.409426s

12288/50000 [======>.......................] - ETA: 3:20 - loss: 10.4889 - accuracy: 0.0095
on_train_batch_begin: 1609199306.409908s

6 step training time: 0.093182s

on_train_batch_end: 1609199306.497031s

14336/50000 [=======>......................] - ETA: 2:43 - loss: 10.1252 - accuracy: 0.0147
on_train_batch_begin: 1609199306.497511s

7 step training time: 0.087603s

on_train_batch_end: 1609199306.584880s

16384/50000 [========>.....................] - ETA: 2:14 - loss: 9.8291 - accuracy: 0.0193 
on_train_batch_begin: 1609199306.585362s

8 step training time: 0.087850s

on_train_batch_end: 1609199306.673942s

18432/50000 [==========>...................] - ETA: 1:52 - loss: 9.5814 - accuracy: 0.0232
on_train_batch_begin: 1609199306.674452s

9 step training time: 0.089090s

on_train_batch_end: 1609199306.763164s

20480/50000 [===========>..................] - ETA: 1:34 - loss: 9.3810 - accuracy: 0.0274
on_train_batch_begin: 1609199306.763628s

10 step training time: 0.089176s

on_train_batch_end: 1609199306.851428s

22528/50000 [============>.................] - ETA: 1:20 - loss: 9.2001 - accuracy: 0.0310
on_train_batch_begin: 1609199306.851884s

11 step training time: 0.088256s

on_train_batch_end: 1609199306.940232s

24576/50000 [=============>................] - ETA: 1:08 - loss: 9.0444 - accuracy: 0.0345
on_train_batch_begin: 1609199306.940687s

12 step training time: 0.088803s

on_train_batch_end: 1609199307.027291s

26624/50000 [==============>...............] - ETA: 58s - loss: 8.9173 - accuracy: 0.0378 
on_train_batch_begin: 1609199307.027747s

13 step training time: 0.087059s

on_train_batch_end: 1609199307.116766s

28672/50000 [================>.............] - ETA: 49s - loss: 8.7982 - accuracy: 0.0411
on_train_batch_begin: 1609199307.117228s

14 step training time: 0.089482s

on_train_batch_end: 1609199307.204967s

30720/50000 [=================>............] - ETA: 41s - loss: 8.6922 - accuracy: 0.0436
on_train_batch_begin: 1609199307.205417s

15 step training time: 0.088189s

on_train_batch_end: 1609199307.292665s

32768/50000 [==================>...........] - ETA: 34s - loss: 8.5963 - accuracy: 0.0460
on_train_batch_begin: 1609199307.293120s

16 step training time: 0.087702s

on_train_batch_end: 1609199307.383832s

34816/50000 [===================>..........] - ETA: 28s - loss: 8.5061 - accuracy: 0.0479
on_train_batch_begin: 1609199307.384291s

17 step training time: 0.091172s

on_train_batch_end: 1609199307.470642s

36864/50000 [=====================>........] - ETA: 23s - loss: 8.4223 - accuracy: 0.0499
on_train_batch_begin: 1609199307.471092s

18 step training time: 0.086800s

on_train_batch_end: 1609199307.558986s

38912/50000 [======================>.......] - ETA: 18s - loss: 8.3474 - accuracy: 0.0517
on_train_batch_begin: 1609199307.559434s

19 step training time: 0.088342s

on_train_batch_end: 1609199307.646525s

40960/50000 [=======================>......] - ETA: 14s - loss: 8.2727 - accuracy: 0.0532
on_train_batch_begin: 1609199307.646979s

20 step training time: 0.087545s

on_train_batch_end: 1609199307.735495s

43008/50000 [========================>.....] - ETA: 10s - loss: 8.2063 - accuracy: 0.0545
on_train_batch_begin: 1609199307.735949s

21 step training time: 0.088970s

on_train_batch_end: 1609199307.823025s

45056/50000 [==========================>...] - ETA: 7s - loss: 8.1406 - accuracy: 0.0555 
on_train_batch_begin: 1609199307.823480s

22 step training time: 0.087531s

on_train_batch_end: 1609199307.910655s

47104/50000 [===========================>..] - ETA: 4s - loss: 8.0802 - accuracy: 0.0566
on_train_batch_begin: 1609199307.911110s

23 step training time: 0.087630s

on_train_batch_end: 1609199307.995692s

49152/50000 [============================>.] - ETA: 1s - loss: 8.0228 - accuracy: 0.0576
on_train_batch_begin: 1609199307.996143s

24 step training time: 0.085033s

on_train_batch_end: 1609199309.019768s

on_test_batch_begin: 1609199309.334349s

25 step training time: 1.338206s

on_epoch_end: 1609199316.311843s

Validation time: 6.977471s

Real time: 1609199316.311843s

Epoch time: 75.37164092063904s

50000/50000 [==============================] - 75s 2ms/sample - loss: 8.0039 - accuracy: 0.0578 - val_loss: 3846.2939 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609199316.312156s

Real time: 1609199316.3121696
Epoch 2/5

on_train_batch_begin: 1609199316.318220s

on_train_batch_end: 1609199316.409671s

 2048/50000 [>.............................] - ETA: 2s - loss: 6.6805 - accuracy: 0.0789
on_train_batch_begin: 1609199316.410176s

1 step training time: 0.091956s

on_train_batch_end: 1609199316.499814s

 4096/50000 [=>............................] - ETA: 2s - loss: 6.6683 - accuracy: 0.0833
on_train_batch_begin: 1609199316.500282s

2 step training time: 0.090106s

on_train_batch_end: 1609199316.588151s

 6144/50000 [==>...........................] - ETA: 1s - loss: 6.6620 - accuracy: 0.0838
on_train_batch_begin: 1609199316.588618s

3 step training time: 0.088336s

on_train_batch_end: 1609199316.676139s

 8192/50000 [===>..........................] - ETA: 1s - loss: 6.6477 - accuracy: 0.0837
on_train_batch_begin: 1609199316.676610s

4 step training time: 0.087992s

on_train_batch_end: 1609199316.764778s

10240/50000 [=====>........................] - ETA: 1s - loss: 6.6444 - accuracy: 0.0833
on_train_batch_begin: 1609199316.765247s

5 step training time: 0.088638s

on_train_batch_end: 1609199316.858302s

12288/50000 [======>.......................] - ETA: 1s - loss: 6.6214 - accuracy: 0.0839
on_train_batch_begin: 1609199316.858774s

6 step training time: 0.093526s

on_train_batch_end: 1609199316.945973s

14336/50000 [=======>......................] - ETA: 1s - loss: 6.6168 - accuracy: 0.0843
on_train_batch_begin: 1609199316.946461s

7 step training time: 0.087687s

on_train_batch_end: 1609199317.037560s

16384/50000 [========>.....................] - ETA: 1s - loss: 6.6056 - accuracy: 0.0844
on_train_batch_begin: 1609199317.038033s

8 step training time: 0.091572s

on_train_batch_end: 1609199317.127400s

18432/50000 [==========>...................] - ETA: 1s - loss: 6.5922 - accuracy: 0.0845
on_train_batch_begin: 1609199317.127856s

9 step training time: 0.089823s

on_train_batch_end: 1609199317.215038s

20480/50000 [===========>..................] - ETA: 1s - loss: 6.5776 - accuracy: 0.0854
on_train_batch_begin: 1609199317.215500s

10 step training time: 0.087645s

on_train_batch_end: 1609199317.306147s

22528/50000 [============>.................] - ETA: 1s - loss: 6.5708 - accuracy: 0.0852
on_train_batch_begin: 1609199317.306609s

11 step training time: 0.091109s

on_train_batch_end: 1609199317.393465s

24576/50000 [=============>................] - ETA: 1s - loss: 6.5526 - accuracy: 0.0853
on_train_batch_begin: 1609199317.393920s

12 step training time: 0.087312s

on_train_batch_end: 1609199317.483969s

26624/50000 [==============>...............] - ETA: 1s - loss: 6.5448 - accuracy: 0.0858
on_train_batch_begin: 1609199317.484433s

13 step training time: 0.090513s

on_train_batch_end: 1609199317.571375s

28672/50000 [================>.............] - ETA: 0s - loss: 6.5314 - accuracy: 0.0858
on_train_batch_begin: 1609199317.571840s

14 step training time: 0.087407s

on_train_batch_end: 1609199317.659311s

30720/50000 [=================>............] - ETA: 0s - loss: 6.5226 - accuracy: 0.0858
on_train_batch_begin: 1609199317.659764s

15 step training time: 0.087924s

on_train_batch_end: 1609199317.747332s

32768/50000 [==================>...........] - ETA: 0s - loss: 6.5124 - accuracy: 0.0864
on_train_batch_begin: 1609199317.747790s

16 step training time: 0.088026s

on_train_batch_end: 1609199317.843718s

34816/50000 [===================>..........] - ETA: 0s - loss: 6.5049 - accuracy: 0.0868
on_train_batch_begin: 1609199317.844179s

17 step training time: 0.096390s

on_train_batch_end: 1609199317.931668s

36864/50000 [=====================>........] - ETA: 0s - loss: 6.4920 - accuracy: 0.0867
on_train_batch_begin: 1609199317.932129s

18 step training time: 0.087949s

on_train_batch_end: 1609199318.024235s

38912/50000 [======================>.......] - ETA: 0s - loss: 6.4842 - accuracy: 0.0871
on_train_batch_begin: 1609199318.024694s

19 step training time: 0.092566s

on_train_batch_end: 1609199318.112241s

40960/50000 [=======================>......] - ETA: 0s - loss: 6.4743 - accuracy: 0.0873
on_train_batch_begin: 1609199318.112693s

20 step training time: 0.087999s

on_train_batch_end: 1609199318.200037s

43008/50000 [========================>.....] - ETA: 0s - loss: 6.4612 - accuracy: 0.0875
on_train_batch_begin: 1609199318.200489s

21 step training time: 0.087796s

on_train_batch_end: 1609199318.288227s

45056/50000 [==========================>...] - ETA: 0s - loss: 6.4457 - accuracy: 0.0876
on_train_batch_begin: 1609199318.288682s

22 step training time: 0.088193s

on_train_batch_end: 1609199318.376137s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.4295 - accuracy: 0.0878
on_train_batch_begin: 1609199318.376592s

23 step training time: 0.087910s

on_train_batch_end: 1609199318.463399s

49152/50000 [============================>.] - ETA: 0s - loss: 6.4147 - accuracy: 0.0878
on_train_batch_begin: 1609199318.463855s

24 step training time: 0.087263s

on_train_batch_end: 1609199318.537177s

on_test_batch_begin: 1609199318.622103s

25 step training time: 0.158247s

on_epoch_end: 1609199318.947726s

Validation time: 0.325599s

Real time: 1609199318.947726s

Epoch time: 2.635589122772217s

50000/50000 [==============================] - 3s 53us/sample - loss: 6.4105 - accuracy: 0.0878 - val_loss: 7.6510 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609199318.948048s

Real time: 1609199318.9480603
Epoch 3/5

on_train_batch_begin: 1609199318.955022s

on_train_batch_end: 1609199319.048073s

 2048/50000 [>.............................] - ETA: 2s - loss: 6.0794 - accuracy: 0.0866
on_train_batch_begin: 1609199319.048539s

1 step training time: 0.093517s

on_train_batch_end: 1609199319.137613s

 4096/50000 [=>............................] - ETA: 2s - loss: 6.0184 - accuracy: 0.0894
on_train_batch_begin: 1609199319.138099s

2 step training time: 0.089560s

on_train_batch_end: 1609199319.224234s

 6144/50000 [==>...........................] - ETA: 1s - loss: 6.0392 - accuracy: 0.0890
on_train_batch_begin: 1609199319.224695s

3 step training time: 0.086596s

on_train_batch_end: 1609199319.312518s

 8192/50000 [===>..........................] - ETA: 1s - loss: 6.0102 - accuracy: 0.0875
on_train_batch_begin: 1609199319.312985s

4 step training time: 0.088290s

on_train_batch_end: 1609199319.406618s

10240/50000 [=====>........................] - ETA: 1s - loss: 6.0120 - accuracy: 0.0879
on_train_batch_begin: 1609199319.407080s

5 step training time: 0.094095s

on_train_batch_end: 1609199319.495961s

12288/50000 [======>.......................] - ETA: 1s - loss: 5.9851 - accuracy: 0.0878
on_train_batch_begin: 1609199319.496424s

6 step training time: 0.089344s

on_train_batch_end: 1609199319.588223s

14336/50000 [=======>......................] - ETA: 1s - loss: 5.9754 - accuracy: 0.0874
on_train_batch_begin: 1609199319.588680s

7 step training time: 0.092256s

on_train_batch_end: 1609199319.676715s

16384/50000 [========>.....................] - ETA: 1s - loss: 5.9573 - accuracy: 0.0865
on_train_batch_begin: 1609199319.677179s

8 step training time: 0.088499s

on_train_batch_end: 1609199319.765969s

18432/50000 [==========>...................] - ETA: 1s - loss: 5.9530 - accuracy: 0.0860
on_train_batch_begin: 1609199319.766460s

9 step training time: 0.089282s

on_train_batch_end: 1609199319.853910s

20480/50000 [===========>..................] - ETA: 1s - loss: 5.9533 - accuracy: 0.0856
on_train_batch_begin: 1609199319.854414s

10 step training time: 0.087953s

on_train_batch_end: 1609199319.941986s

22528/50000 [============>.................] - ETA: 1s - loss: 5.9444 - accuracy: 0.0855
on_train_batch_begin: 1609199319.942478s

11 step training time: 0.088064s

on_train_batch_end: 1609199320.029791s

24576/50000 [=============>................] - ETA: 1s - loss: 5.9349 - accuracy: 0.0856
on_train_batch_begin: 1609199320.030294s

12 step training time: 0.087816s

on_train_batch_end: 1609199320.118902s

26624/50000 [==============>...............] - ETA: 1s - loss: 5.9204 - accuracy: 0.0851
on_train_batch_begin: 1609199320.119361s

13 step training time: 0.089067s

on_train_batch_end: 1609199320.207340s

28672/50000 [================>.............] - ETA: 0s - loss: 5.9105 - accuracy: 0.0842
on_train_batch_begin: 1609199320.207799s

14 step training time: 0.088439s

on_train_batch_end: 1609199320.301139s

30720/50000 [=================>............] - ETA: 0s - loss: 5.8966 - accuracy: 0.0833
on_train_batch_begin: 1609199320.301592s

15 step training time: 0.093793s

on_train_batch_end: 1609199320.387259s

32768/50000 [==================>...........] - ETA: 0s - loss: 5.8812 - accuracy: 0.0820
on_train_batch_begin: 1609199320.387714s

16 step training time: 0.086122s

on_train_batch_end: 1609199320.476903s

34816/50000 [===================>..........] - ETA: 0s - loss: 5.8715 - accuracy: 0.0807
on_train_batch_begin: 1609199320.477358s

17 step training time: 0.089643s

on_train_batch_end: 1609199320.566234s

36864/50000 [=====================>........] - ETA: 0s - loss: 5.8592 - accuracy: 0.0793
on_train_batch_begin: 1609199320.566684s

18 step training time: 0.089326s

on_train_batch_end: 1609199320.652934s

38912/50000 [======================>.......] - ETA: 0s - loss: 5.8424 - accuracy: 0.0782
on_train_batch_begin: 1609199320.653391s

19 step training time: 0.086707s

on_train_batch_end: 1609199320.742323s

40960/50000 [=======================>......] - ETA: 0s - loss: 5.8231 - accuracy: 0.0774
on_train_batch_begin: 1609199320.742774s

20 step training time: 0.089383s

on_train_batch_end: 1609199320.829499s

43008/50000 [========================>.....] - ETA: 0s - loss: 5.8058 - accuracy: 0.0765
on_train_batch_begin: 1609199320.829957s

21 step training time: 0.087183s

on_train_batch_end: 1609199320.924504s

45056/50000 [==========================>...] - ETA: 0s - loss: 5.7852 - accuracy: 0.0756
on_train_batch_begin: 1609199320.924958s

22 step training time: 0.095001s

on_train_batch_end: 1609199321.014764s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.7603 - accuracy: 0.0747
on_train_batch_begin: 1609199321.015222s

23 step training time: 0.090263s

on_train_batch_end: 1609199321.102995s

49152/50000 [============================>.] - ETA: 0s - loss: 5.7337 - accuracy: 0.0741
on_train_batch_begin: 1609199321.103451s

24 step training time: 0.088229s

on_train_batch_end: 1609199321.174051s

on_test_batch_begin: 1609199321.257092s

25 step training time: 0.153641s

on_epoch_end: 1609199321.576982s

Validation time: 0.319866s

Real time: 1609199321.576982s

Epoch time: 2.6289544105529785s

50000/50000 [==============================] - 3s 53us/sample - loss: 5.7227 - accuracy: 0.0740 - val_loss: 7.6265 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609199321.577287s

Real time: 1609199321.5772989
Epoch 4/5

on_train_batch_begin: 1609199321.584575s

on_train_batch_end: 1609199321.678583s

 2048/50000 [>.............................] - ETA: 2s - loss: 4.8467 - accuracy: 0.0624
on_train_batch_begin: 1609199321.679041s

1 step training time: 0.094467s

on_train_batch_end: 1609199321.769617s

 4096/50000 [=>............................] - ETA: 2s - loss: 4.8891 - accuracy: 0.0611
on_train_batch_begin: 1609199321.770108s

2 step training time: 0.091067s

on_train_batch_end: 1609199321.857193s

 6144/50000 [==>...........................] - ETA: 1s - loss: 4.8977 - accuracy: 0.0607
on_train_batch_begin: 1609199321.857643s

3 step training time: 0.087535s

on_train_batch_end: 1609199321.949380s

 8192/50000 [===>..........................] - ETA: 1s - loss: 4.8175 - accuracy: 0.0617
on_train_batch_begin: 1609199321.949843s

4 step training time: 0.092200s

on_train_batch_end: 1609199322.038701s

10240/50000 [=====>........................] - ETA: 1s - loss: 4.7918 - accuracy: 0.0621
on_train_batch_begin: 1609199322.039160s

5 step training time: 0.089317s

on_train_batch_end: 1609199322.127412s

12288/50000 [======>.......................] - ETA: 1s - loss: 4.7511 - accuracy: 0.0628
on_train_batch_begin: 1609199322.127872s

6 step training time: 0.088712s

on_train_batch_end: 1609199322.217907s

14336/50000 [=======>......................] - ETA: 1s - loss: 4.7081 - accuracy: 0.0636
on_train_batch_begin: 1609199322.218395s

7 step training time: 0.090523s

on_train_batch_end: 1609199322.306072s

16384/50000 [========>.....................] - ETA: 1s - loss: 4.6523 - accuracy: 0.0644
on_train_batch_begin: 1609199322.306530s

8 step training time: 0.088135s

on_train_batch_end: 1609199322.394959s

18432/50000 [==========>...................] - ETA: 1s - loss: 4.6108 - accuracy: 0.0653
on_train_batch_begin: 1609199322.395415s

9 step training time: 0.088884s

on_train_batch_end: 1609199322.483753s

20480/50000 [===========>..................] - ETA: 1s - loss: 4.5478 - accuracy: 0.0664
on_train_batch_begin: 1609199322.484217s

10 step training time: 0.088803s

on_train_batch_end: 1609199322.571147s

22528/50000 [============>.................] - ETA: 1s - loss: 4.4947 - accuracy: 0.0674
on_train_batch_begin: 1609199322.571604s

11 step training time: 0.087386s

on_train_batch_end: 1609199322.665425s

24576/50000 [=============>................] - ETA: 1s - loss: 4.4438 - accuracy: 0.0685
on_train_batch_begin: 1609199322.665881s

12 step training time: 0.094278s

on_train_batch_end: 1609199322.753819s

26624/50000 [==============>...............] - ETA: 1s - loss: 4.3778 - accuracy: 0.0696
on_train_batch_begin: 1609199322.754313s

13 step training time: 0.088432s

on_train_batch_end: 1609199322.841383s

28672/50000 [================>.............] - ETA: 0s - loss: 4.3048 - accuracy: 0.0708
on_train_batch_begin: 1609199322.841843s

14 step training time: 0.087530s

on_train_batch_end: 1609199322.929228s

30720/50000 [=================>............] - ETA: 0s - loss: 4.2341 - accuracy: 0.0722
on_train_batch_begin: 1609199322.929687s

15 step training time: 0.087844s

on_train_batch_end: 1609199323.018265s

32768/50000 [==================>...........] - ETA: 0s - loss: 4.1551 - accuracy: 0.0733
on_train_batch_begin: 1609199323.018730s

16 step training time: 0.089043s

on_train_batch_end: 1609199323.107068s

34816/50000 [===================>..........] - ETA: 0s - loss: 4.0730 - accuracy: 0.0746
on_train_batch_begin: 1609199323.107535s

17 step training time: 0.088805s

on_train_batch_end: 1609199323.194736s

36864/50000 [=====================>........] - ETA: 0s - loss: 4.0070 - accuracy: 0.0758
on_train_batch_begin: 1609199323.195197s

18 step training time: 0.087662s

on_train_batch_end: 1609199323.282963s

38912/50000 [======================>.......] - ETA: 0s - loss: 3.9516 - accuracy: 0.0769
on_train_batch_begin: 1609199323.283423s

19 step training time: 0.088226s

on_train_batch_end: 1609199323.371261s

40960/50000 [=======================>......] - ETA: 0s - loss: 3.8884 - accuracy: 0.0780
on_train_batch_begin: 1609199323.371726s

20 step training time: 0.088302s

on_train_batch_end: 1609199323.459962s

43008/50000 [========================>.....] - ETA: 0s - loss: 3.8236 - accuracy: 0.0790
on_train_batch_begin: 1609199323.460423s

21 step training time: 0.088697s

on_train_batch_end: 1609199323.548896s

45056/50000 [==========================>...] - ETA: 0s - loss: 3.7506 - accuracy: 0.0799
on_train_batch_begin: 1609199323.549358s

22 step training time: 0.088935s

on_train_batch_end: 1609199323.641369s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.6899 - accuracy: 0.0808
on_train_batch_begin: 1609199323.641829s

23 step training time: 0.092471s

on_train_batch_end: 1609199323.725704s

49152/50000 [============================>.] - ETA: 0s - loss: 3.6335 - accuracy: 0.0816
on_train_batch_begin: 1609199323.726191s

24 step training time: 0.084362s

on_train_batch_end: 1609199323.795331s

on_test_batch_begin: 1609199323.878645s

25 step training time: 0.152454s

on_epoch_end: 1609199324.214814s

Validation time: 0.336151s

Real time: 1609199324.214814s

Epoch time: 2.637544870376587s

50000/50000 [==============================] - 3s 53us/sample - loss: 3.6081 - accuracy: 0.0817 - val_loss: 7.4024 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609199324.215111s

Real time: 1609199324.2151213
Epoch 5/5

on_train_batch_begin: 1609199324.221202s

on_train_batch_end: 1609199324.317107s

 2048/50000 [>.............................] - ETA: 2s - loss: 2.1432 - accuracy: 0.1004
on_train_batch_begin: 1609199324.317567s

1 step training time: 0.096365s

on_train_batch_end: 1609199324.405552s

 4096/50000 [=>............................] - ETA: 2s - loss: 2.1115 - accuracy: 0.1005
on_train_batch_begin: 1609199324.406006s

2 step training time: 0.088440s

on_train_batch_end: 1609199324.491904s

 6144/50000 [==>...........................] - ETA: 1s - loss: 2.0672 - accuracy: 0.1004
on_train_batch_begin: 1609199324.492361s

3 step training time: 0.086355s

on_train_batch_end: 1609199324.585467s

 8192/50000 [===>..........................] - ETA: 1s - loss: 2.0214 - accuracy: 0.1004
on_train_batch_begin: 1609199324.585925s

4 step training time: 0.093564s

on_train_batch_end: 1609199324.673727s

10240/50000 [=====>........................] - ETA: 1s - loss: 1.9976 - accuracy: 0.1005
on_train_batch_begin: 1609199324.674236s

5 step training time: 0.088311s

on_train_batch_end: 1609199324.763862s

12288/50000 [======>.......................] - ETA: 1s - loss: 2.0121 - accuracy: 0.1004
on_train_batch_begin: 1609199324.764323s

6 step training time: 0.090087s

on_train_batch_end: 1609199324.853230s

14336/50000 [=======>......................] - ETA: 1s - loss: 1.9888 - accuracy: 0.1004
on_train_batch_begin: 1609199324.853690s

7 step training time: 0.089367s

on_train_batch_end: 1609199324.941932s

16384/50000 [========>.....................] - ETA: 1s - loss: 1.9778 - accuracy: 0.1004
on_train_batch_begin: 1609199324.942420s

8 step training time: 0.088730s

on_train_batch_end: 1609199325.030332s

18432/50000 [==========>...................] - ETA: 1s - loss: 1.9624 - accuracy: 0.1005
on_train_batch_begin: 1609199325.030786s

9 step training time: 0.088366s

on_train_batch_end: 1609199325.119232s

20480/50000 [===========>..................] - ETA: 1s - loss: 1.9484 - accuracy: 0.1005
on_train_batch_begin: 1609199325.119684s

10 step training time: 0.088898s

on_train_batch_end: 1609199325.209026s

22528/50000 [============>.................] - ETA: 1s - loss: 1.9351 - accuracy: 0.1005
on_train_batch_begin: 1609199325.209483s

11 step training time: 0.089799s

on_train_batch_end: 1609199325.298358s

24576/50000 [=============>................] - ETA: 1s - loss: 1.9138 - accuracy: 0.1005
on_train_batch_begin: 1609199325.298814s

12 step training time: 0.089331s

on_train_batch_end: 1609199325.394172s

26624/50000 [==============>...............] - ETA: 1s - loss: 1.8889 - accuracy: 0.1005
on_train_batch_begin: 1609199325.394631s

13 step training time: 0.095817s

on_train_batch_end: 1609199325.481021s

28672/50000 [================>.............] - ETA: 0s - loss: 1.8709 - accuracy: 0.1005
on_train_batch_begin: 1609199325.481480s

14 step training time: 0.086849s

on_train_batch_end: 1609199325.568941s

30720/50000 [=================>............] - ETA: 0s - loss: 1.8532 - accuracy: 0.1005
on_train_batch_begin: 1609199325.569417s

15 step training time: 0.087937s

on_train_batch_end: 1609199325.655662s

32768/50000 [==================>...........] - ETA: 0s - loss: 1.8368 - accuracy: 0.1005
on_train_batch_begin: 1609199325.656159s

16 step training time: 0.086742s

on_train_batch_end: 1609199325.746499s

34816/50000 [===================>..........] - ETA: 0s - loss: 1.8226 - accuracy: 0.1005
on_train_batch_begin: 1609199325.746955s

17 step training time: 0.090795s

on_train_batch_end: 1609199325.835704s

36864/50000 [=====================>........] - ETA: 0s - loss: 1.8031 - accuracy: 0.1005
on_train_batch_begin: 1609199325.836160s

18 step training time: 0.089205s

on_train_batch_end: 1609199325.927058s

38912/50000 [======================>.......] - ETA: 0s - loss: 1.7861 - accuracy: 0.1005
on_train_batch_begin: 1609199325.927539s

19 step training time: 0.091379s

on_train_batch_end: 1609199326.017870s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.7715 - accuracy: 0.1005
on_train_batch_begin: 1609199326.018445s

20 step training time: 0.090907s

on_train_batch_end: 1609199326.106462s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.7569 - accuracy: 0.1005
on_train_batch_begin: 1609199326.106914s

21 step training time: 0.088469s

on_train_batch_end: 1609199326.195272s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.7457 - accuracy: 0.1005
on_train_batch_begin: 1609199326.195729s

22 step training time: 0.088814s

on_train_batch_end: 1609199326.285502s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7333 - accuracy: 0.1005
on_train_batch_begin: 1609199326.285957s

23 step training time: 0.090228s

on_train_batch_end: 1609199326.370244s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7207 - accuracy: 0.1005
on_train_batch_begin: 1609199326.370699s

24 step training time: 0.084743s

on_train_batch_end: 1609199326.443181s

on_test_batch_begin: 1609199326.526076s

25 step training time: 0.155377s

on_epoch_end: 1609199326.861559s

Validation time: 0.335463s

Real time: 1609199326.861559s

Epoch time: 2.6464669704437256s

50000/50000 [==============================] - 3s 53us/sample - loss: 1.7181 - accuracy: 0.1005 - val_loss: 7.5272 - val_accuracy: 0.0966
Tempo do fit: 90.53236865997314