wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:13
   139264/170498071 [..............................] - ETA: 1:26
   679936/170498071 [..............................] - ETA: 30s 
  2007040/170498071 [..............................] - ETA: 14s
  4087808/170498071 [..............................] - ETA: 9s 
  6168576/170498071 [>.............................] - ETA: 7s
  8331264/170498071 [>.............................] - ETA: 6s
 10543104/170498071 [>.............................] - ETA: 5s
 12886016/170498071 [=>............................] - ETA: 5s
 15261696/170498071 [=>............................] - ETA: 4s
 17620992/170498071 [==>...........................] - ETA: 4s
 19963904/170498071 [==>...........................] - ETA: 4s
 22274048/170498071 [==>...........................] - ETA: 4s
 24649728/170498071 [===>..........................] - ETA: 4s
 27025408/170498071 [===>..........................] - ETA: 3s
 29335552/170498071 [====>.........................] - ETA: 3s
 31711232/170498071 [====>.........................] - ETA: 3s
 34021376/170498071 [====>.........................] - ETA: 3s
 36364288/170498071 [=====>........................] - ETA: 3s
 38739968/170498071 [=====>........................] - ETA: 3s
 41066496/170498071 [======>.......................] - ETA: 3s
 43425792/170498071 [======>.......................] - ETA: 3s
 45785088/170498071 [=======>......................] - ETA: 3s
 48078848/170498071 [=======>......................] - ETA: 3s
 50356224/170498071 [=======>......................] - ETA: 2s
 52305920/170498071 [========>.....................] - ETA: 2s
 54075392/170498071 [========>.....................] - ETA: 2s
 55566336/170498071 [========>.....................] - ETA: 2s
 57057280/170498071 [=========>....................] - ETA: 2s
 58564608/170498071 [=========>....................] - ETA: 2s
 60055552/170498071 [=========>....................] - ETA: 2s
 61546496/170498071 [=========>....................] - ETA: 2s
 63053824/170498071 [==========>...................] - ETA: 2s
 64544768/170498071 [==========>...................] - ETA: 2s
 66035712/170498071 [==========>...................] - ETA: 2s
 67543040/170498071 [==========>...................] - ETA: 2s
 69033984/170498071 [===========>..................] - ETA: 2s
 70524928/170498071 [===========>..................] - ETA: 2s
 72032256/170498071 [===========>..................] - ETA: 2s
 73523200/170498071 [===========>..................] - ETA: 2s
 75030528/170498071 [============>.................] - ETA: 2s
 76521472/170498071 [============>.................] - ETA: 2s
 78012416/170498071 [============>.................] - ETA: 2s
 79519744/170498071 [============>.................] - ETA: 2s
 81010688/170498071 [=============>................] - ETA: 2s
 82501632/170498071 [=============>................] - ETA: 2s
 84008960/170498071 [=============>................] - ETA: 2s
 85499904/170498071 [==============>...............] - ETA: 2s
 86990848/170498071 [==============>...............] - ETA: 2s
 88498176/170498071 [==============>...............] - ETA: 2s
 89989120/170498071 [==============>...............] - ETA: 2s
 91480064/170498071 [===============>..............] - ETA: 2s
 92987392/170498071 [===============>..............] - ETA: 2s
 94478336/170498071 [===============>..............] - ETA: 2s
 95969280/170498071 [===============>..............] - ETA: 2s
 97476608/170498071 [================>.............] - ETA: 2s
 98967552/170498071 [================>.............] - ETA: 2s
100458496/170498071 [================>.............] - ETA: 2s
101965824/170498071 [================>.............] - ETA: 1s
103456768/170498071 [=================>............] - ETA: 1s
104964096/170498071 [=================>............] - ETA: 1s
106389504/170498071 [=================>............] - ETA: 1s
107814912/170498071 [=================>............] - ETA: 1s
109453312/170498071 [==================>...........] - ETA: 1s
111665152/170498071 [==================>...........] - ETA: 1s
113811456/170498071 [===================>..........] - ETA: 1s
116023296/170498071 [===================>..........] - ETA: 1s
118235136/170498071 [===================>..........] - ETA: 1s
120446976/170498071 [====================>.........] - ETA: 1s
122658816/170498071 [====================>.........] - ETA: 1s
124674048/170498071 [====================>.........] - ETA: 1s
126754816/170498071 [=====================>........] - ETA: 1s
128901120/170498071 [=====================>........] - ETA: 1s
131006464/170498071 [======================>.......] - ETA: 1s
132931584/170498071 [======================>.......] - ETA: 1s
134635520/170498071 [======================>.......] - ETA: 1s
135995392/170498071 [======================>.......] - ETA: 0s
137355264/170498071 [=======================>......] - ETA: 0s
138731520/170498071 [=======================>......] - ETA: 0s
140091392/170498071 [=======================>......] - ETA: 0s
141467648/170498071 [=======================>......] - ETA: 0s
142827520/170498071 [========================>.....] - ETA: 0s
144187392/170498071 [========================>.....] - ETA: 0s
145498112/170498071 [========================>.....] - ETA: 0s
146825216/170498071 [========================>.....] - ETA: 0s
148119552/170498071 [=========================>....] - ETA: 0s
149446656/170498071 [=========================>....] - ETA: 0s
150773760/170498071 [=========================>....] - ETA: 0s
152100864/170498071 [=========================>....] - ETA: 0s
153427968/170498071 [=========================>....] - ETA: 0s
154738688/170498071 [==========================>...] - ETA: 0s
156098560/170498071 [==========================>...] - ETA: 0s
157442048/170498071 [==========================>...] - ETA: 0s
158769152/170498071 [==========================>...] - ETA: 0s
160096256/170498071 [===========================>..] - ETA: 0s
161439744/170498071 [===========================>..] - ETA: 0s
162783232/170498071 [===========================>..] - ETA: 0s
164110336/170498071 [===========================>..] - ETA: 0s
165445632/170498071 [============================>.] - ETA: 0s
166780928/170498071 [============================>.] - ETA: 0s
168116224/170498071 [============================>.] - ETA: 0s
169435136/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 5s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 4186112/94765736 [>.............................] - ETA: 1s
14704640/94765736 [===>..........................] - ETA: 0s
20021248/94765736 [=====>........................] - ETA: 0s
24059904/94765736 [======>.......................] - ETA: 0s
30629888/94765736 [========>.....................] - ETA: 0s
35201024/94765736 [==========>...................] - ETA: 0s
39501824/94765736 [===========>..................] - ETA: 0s
45924352/94765736 [=============>................] - ETA: 0s
50905088/94765736 [===============>..............] - ETA: 0s
55762944/94765736 [================>.............] - ETA: 0s
58105856/94765736 [=================>............] - ETA: 0s
62701568/94765736 [==================>...........] - ETA: 0s
68575232/94765736 [====================>.........] - ETA: 0s
74342400/94765736 [======================>.......] - ETA: 0s
79036416/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
93528064/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 15.249918460845947
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615676679.172037s

Real time: 1615676679.1720545
Epoch 1/5

on_train_batch_begin: 1615676679.936713s

on_train_batch_end: 1615676700.005765s

 2048/50000 [>.............................] - ETA: 8:07 - loss: 17.6864 - accuracy: 9.5367e-05
on_train_batch_begin: 1615676700.006364s

1 step training time: 20.069651s

on_train_batch_end: 1615676700.648964s

 4096/50000 [=>............................] - ETA: 4:00 - loss: 13.6799 - accuracy: 3.5536e-04
on_train_batch_begin: 1615676700.649323s

2 step training time: 0.642960s

on_train_batch_end: 1615676701.298052s

 6144/50000 [==>...........................] - ETA: 2:37 - loss: 11.9232 - accuracy: 6.4071e-04
on_train_batch_begin: 1615676701.298371s

3 step training time: 0.649047s

on_train_batch_end: 1615676701.937707s

 8192/50000 [===>..........................] - ETA: 1:56 - loss: 10.9382 - accuracy: 0.0029    
on_train_batch_begin: 1615676701.938060s

4 step training time: 0.639689s

on_train_batch_end: 1615676702.586325s

10240/50000 [=====>........................] - ETA: 1:30 - loss: 10.3437 - accuracy: 0.0059
on_train_batch_begin: 1615676702.586643s

5 step training time: 0.648584s

on_train_batch_end: 1615676703.239511s

12288/50000 [======>.......................] - ETA: 1:13 - loss: 9.9274 - accuracy: 0.0130 
on_train_batch_begin: 1615676703.239850s

6 step training time: 0.653207s

on_train_batch_end: 1615676703.890115s

14336/50000 [=======>......................] - ETA: 1:01 - loss: 9.6126 - accuracy: 0.0178
on_train_batch_begin: 1615676703.890427s

7 step training time: 0.650577s

on_train_batch_end: 1615676704.554644s

16384/50000 [========>.....................] - ETA: 52s - loss: 9.3716 - accuracy: 0.0232 
on_train_batch_begin: 1615676704.554949s

8 step training time: 0.664522s

on_train_batch_end: 1615676705.202801s

18432/50000 [==========>...................] - ETA: 44s - loss: 9.1747 - accuracy: 0.0270
on_train_batch_begin: 1615676705.203121s

9 step training time: 0.648172s

on_train_batch_end: 1615676705.845393s

20480/50000 [===========>..................] - ETA: 38s - loss: 9.0106 - accuracy: 0.0310
on_train_batch_begin: 1615676705.845704s

10 step training time: 0.642583s

on_train_batch_end: 1615676706.488983s

22528/50000 [============>.................] - ETA: 33s - loss: 8.8651 - accuracy: 0.0337
on_train_batch_begin: 1615676706.489304s

11 step training time: 0.643600s

on_train_batch_end: 1615676707.136413s

24576/50000 [=============>................] - ETA: 28s - loss: 8.7396 - accuracy: 0.0343
on_train_batch_begin: 1615676707.136709s

12 step training time: 0.647405s

on_train_batch_end: 1615676707.783273s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.6253 - accuracy: 0.0343
on_train_batch_begin: 1615676707.783567s

13 step training time: 0.646858s

on_train_batch_end: 1615676708.435042s

28672/50000 [================>.............] - ETA: 21s - loss: 8.5240 - accuracy: 0.0361
on_train_batch_begin: 1615676708.435337s

14 step training time: 0.651770s

on_train_batch_end: 1615676709.084466s

30720/50000 [=================>............] - ETA: 18s - loss: 8.4440 - accuracy: 0.0379
on_train_batch_begin: 1615676709.084757s

15 step training time: 0.649420s

on_train_batch_end: 1615676709.730751s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.3533 - accuracy: 0.0399
on_train_batch_begin: 1615676709.731052s

16 step training time: 0.646295s

on_train_batch_end: 1615676710.387061s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.2859 - accuracy: 0.0414
on_train_batch_begin: 1615676710.387376s

17 step training time: 0.656324s

on_train_batch_end: 1615676711.046072s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.2162 - accuracy: 0.0430
on_train_batch_begin: 1615676711.046384s

18 step training time: 0.659009s

on_train_batch_end: 1615676711.692808s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.1534 - accuracy: 0.0438 
on_train_batch_begin: 1615676711.693122s

19 step training time: 0.646738s

on_train_batch_end: 1615676712.340966s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.0866 - accuracy: 0.0452
on_train_batch_begin: 1615676712.341299s

20 step training time: 0.648177s

on_train_batch_end: 1615676712.987136s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.0262 - accuracy: 0.0452
on_train_batch_begin: 1615676712.987456s

21 step training time: 0.646157s

on_train_batch_end: 1615676713.632099s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.9684 - accuracy: 0.0459
on_train_batch_begin: 1615676713.632405s

22 step training time: 0.644949s

on_train_batch_end: 1615676714.279725s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.9093 - accuracy: 0.0471
on_train_batch_begin: 1615676714.280037s

23 step training time: 0.647632s

on_train_batch_end: 1615676714.914777s

49152/50000 [============================>.] - ETA: 0s - loss: 7.8568 - accuracy: 0.0481
on_train_batch_begin: 1615676714.915090s

24 step training time: 0.635053s

on_train_batch_end: 1615676720.582947s

on_test_batch_begin: 1615676720.771649s

25 step training time: 5.856559s

on_epoch_end: 1615676725.801855s

Validation time: 5.030191s

Real time: 1615676725.801855s

Epoch time: 46.62981677055359s

50000/50000 [==============================] - 47s 933us/sample - loss: 7.8374 - accuracy: 0.0483 - val_loss: 5694.3983 - val_accuracy: 0.1001

on_epoch_begin: 1615676725.802064s

Real time: 1615676725.8020713
Epoch 2/5

on_train_batch_begin: 1615676725.805473s

on_train_batch_end: 1615676726.444625s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.5167 - accuracy: 0.0636
on_train_batch_begin: 1615676726.444927s

1 step training time: 0.639454s

on_train_batch_end: 1615676727.091071s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.4811 - accuracy: 0.0675
on_train_batch_begin: 1615676727.091378s

2 step training time: 0.646450s

on_train_batch_end: 1615676727.734552s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.4220 - accuracy: 0.0680
on_train_batch_begin: 1615676727.734872s

3 step training time: 0.643494s

on_train_batch_end: 1615676728.387085s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.4124 - accuracy: 0.0699
on_train_batch_begin: 1615676728.387396s

4 step training time: 0.652524s

on_train_batch_end: 1615676729.035202s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.3883 - accuracy: 0.0670
on_train_batch_begin: 1615676729.035516s

5 step training time: 0.648120s

on_train_batch_end: 1615676729.680147s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.3408 - accuracy: 0.0678
on_train_batch_begin: 1615676729.680439s

6 step training time: 0.644923s

on_train_batch_end: 1615676730.332622s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.3840 - accuracy: 0.0635
on_train_batch_begin: 1615676730.332920s

7 step training time: 0.652481s

on_train_batch_end: 1615676730.983503s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.3576 - accuracy: 0.0650
on_train_batch_begin: 1615676730.983817s

8 step training time: 0.650897s

on_train_batch_end: 1615676731.632540s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.3442 - accuracy: 0.0660 
on_train_batch_begin: 1615676731.632847s

9 step training time: 0.649030s

on_train_batch_end: 1615676732.277115s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.3294 - accuracy: 0.0669
on_train_batch_begin: 1615676732.277462s

10 step training time: 0.644616s

on_train_batch_end: 1615676732.914522s

22528/50000 [============>.................] - ETA: 8s - loss: 6.3054 - accuracy: 0.0680
on_train_batch_begin: 1615676732.914838s

11 step training time: 0.637375s

on_train_batch_end: 1615676733.525787s

24576/50000 [=============>................] - ETA: 7s - loss: 6.2907 - accuracy: 0.0686
on_train_batch_begin: 1615676733.526088s

12 step training time: 0.611250s

on_train_batch_end: 1615676734.175312s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.2732 - accuracy: 0.0699
on_train_batch_begin: 1615676734.175624s

13 step training time: 0.649536s

on_train_batch_end: 1615676734.818718s

28672/50000 [================>.............] - ETA: 6s - loss: 6.2458 - accuracy: 0.0709
on_train_batch_begin: 1615676734.819011s

14 step training time: 0.643387s

on_train_batch_end: 1615676735.470358s

30720/50000 [=================>............] - ETA: 6s - loss: 6.2215 - accuracy: 0.0714
on_train_batch_begin: 1615676735.470656s

15 step training time: 0.651644s

on_train_batch_end: 1615676736.119906s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.2061 - accuracy: 0.0717
on_train_batch_begin: 1615676736.120205s

16 step training time: 0.649550s

on_train_batch_end: 1615676736.770006s

34816/50000 [===================>..........] - ETA: 4s - loss: 6.1805 - accuracy: 0.0722
on_train_batch_begin: 1615676736.770301s

17 step training time: 0.650096s

on_train_batch_end: 1615676737.416887s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.1596 - accuracy: 0.0720
on_train_batch_begin: 1615676737.417234s

18 step training time: 0.646933s

on_train_batch_end: 1615676738.065213s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.1396 - accuracy: 0.0722
on_train_batch_begin: 1615676738.065527s

19 step training time: 0.648293s

on_train_batch_end: 1615676738.713701s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.1242 - accuracy: 0.0724
on_train_batch_begin: 1615676738.713998s

20 step training time: 0.648470s

on_train_batch_end: 1615676739.357689s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.1122 - accuracy: 0.0723
on_train_batch_begin: 1615676739.357994s

21 step training time: 0.643996s

on_train_batch_end: 1615676740.006356s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.0955 - accuracy: 0.0723
on_train_batch_begin: 1615676740.006687s

22 step training time: 0.648693s

on_train_batch_end: 1615676740.661309s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.0764 - accuracy: 0.0723
on_train_batch_begin: 1615676740.661626s

23 step training time: 0.654939s

on_train_batch_end: 1615676741.309968s

49152/50000 [============================>.] - ETA: 0s - loss: 6.0596 - accuracy: 0.0722
on_train_batch_begin: 1615676741.310286s

24 step training time: 0.648660s

on_train_batch_end: 1615676741.593794s

on_test_batch_begin: 1615676741.614071s

25 step training time: 0.303785s

on_epoch_end: 1615676742.488142s

Validation time: 0.874059s

Real time: 1615676742.488142s

Epoch time: 16.686087369918823s

50000/50000 [==============================] - 17s 334us/sample - loss: 6.0538 - accuracy: 0.0722 - val_loss: 219.9506 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615676742.488343s

Real time: 1615676742.48835
Epoch 3/5

on_train_batch_begin: 1615676742.491694s

on_train_batch_end: 1615676743.134275s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.6317 - accuracy: 0.0715
on_train_batch_begin: 1615676743.134577s

1 step training time: 0.642882s

on_train_batch_end: 1615676743.789518s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.5893 - accuracy: 0.0715
on_train_batch_begin: 1615676743.789826s

2 step training time: 0.655250s

on_train_batch_end: 1615676744.441845s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.5750 - accuracy: 0.0716
on_train_batch_begin: 1615676744.442156s

3 step training time: 0.652329s

on_train_batch_end: 1615676745.090508s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.5350 - accuracy: 0.0731
on_train_batch_begin: 1615676745.090823s

4 step training time: 0.648667s

on_train_batch_end: 1615676745.750691s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.5182 - accuracy: 0.0737
on_train_batch_begin: 1615676745.751007s

5 step training time: 0.660184s

on_train_batch_end: 1615676746.401939s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.5029 - accuracy: 0.0741
on_train_batch_begin: 1615676746.402241s

6 step training time: 0.651234s

on_train_batch_end: 1615676747.048987s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.4934 - accuracy: 0.0750
on_train_batch_begin: 1615676747.049306s

7 step training time: 0.647065s

on_train_batch_end: 1615676747.701376s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.4768 - accuracy: 0.0751
on_train_batch_begin: 1615676747.701682s

8 step training time: 0.652376s

on_train_batch_end: 1615676748.345743s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.4531 - accuracy: 0.0766
on_train_batch_begin: 1615676748.346042s

9 step training time: 0.644361s

on_train_batch_end: 1615676748.993445s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.4375 - accuracy: 0.0770 
on_train_batch_begin: 1615676748.993762s

10 step training time: 0.647720s

on_train_batch_end: 1615676749.643482s

22528/50000 [============>.................] - ETA: 8s - loss: 5.4205 - accuracy: 0.0769
on_train_batch_begin: 1615676749.643797s

11 step training time: 0.650035s

on_train_batch_end: 1615676750.297940s

24576/50000 [=============>................] - ETA: 8s - loss: 5.4065 - accuracy: 0.0771
on_train_batch_begin: 1615676750.298235s

12 step training time: 0.654437s

on_train_batch_end: 1615676750.948568s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.3996 - accuracy: 0.0768
on_train_batch_begin: 1615676750.948864s

13 step training time: 0.650630s

on_train_batch_end: 1615676751.608236s

28672/50000 [================>.............] - ETA: 6s - loss: 5.3848 - accuracy: 0.0774
on_train_batch_begin: 1615676751.608526s

14 step training time: 0.659662s

on_train_batch_end: 1615676752.264888s

30720/50000 [=================>............] - ETA: 6s - loss: 5.3708 - accuracy: 0.0778
on_train_batch_begin: 1615676752.265209s

15 step training time: 0.656683s

on_train_batch_end: 1615676752.912151s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.3572 - accuracy: 0.0777
on_train_batch_begin: 1615676752.912492s

16 step training time: 0.647282s

on_train_batch_end: 1615676753.557789s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.3429 - accuracy: 0.0781
on_train_batch_begin: 1615676753.558098s

17 step training time: 0.645606s

on_train_batch_end: 1615676754.209185s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.3302 - accuracy: 0.0781
on_train_batch_begin: 1615676754.209483s

18 step training time: 0.651386s

on_train_batch_end: 1615676754.859913s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.3111 - accuracy: 0.0781
on_train_batch_begin: 1615676754.860233s

19 step training time: 0.650750s

on_train_batch_end: 1615676755.507608s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.2878 - accuracy: 0.0781
on_train_batch_begin: 1615676755.507950s

20 step training time: 0.647717s

on_train_batch_end: 1615676756.153851s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.2744 - accuracy: 0.0779
on_train_batch_begin: 1615676756.154184s

21 step training time: 0.646234s

on_train_batch_end: 1615676756.799766s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.2654 - accuracy: 0.0776
on_train_batch_begin: 1615676756.800081s

22 step training time: 0.645897s

on_train_batch_end: 1615676757.455322s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.2540 - accuracy: 0.0773
on_train_batch_begin: 1615676757.455653s

23 step training time: 0.655573s

on_train_batch_end: 1615676758.111024s

49152/50000 [============================>.] - ETA: 0s - loss: 5.2431 - accuracy: 0.0772
on_train_batch_begin: 1615676758.111340s

24 step training time: 0.655687s

on_train_batch_end: 1615676758.394981s

on_test_batch_begin: 1615676758.414967s

25 step training time: 0.303627s

on_epoch_end: 1615676759.290754s

Validation time: 0.875776s

Real time: 1615676759.290754s

Epoch time: 16.802420139312744s

50000/50000 [==============================] - 17s 336us/sample - loss: 5.2386 - accuracy: 0.0771 - val_loss: 7.8216 - val_accuracy: 0.1001

on_epoch_begin: 1615676759.290946s

Real time: 1615676759.2909513
Epoch 4/5

on_train_batch_begin: 1615676759.294365s

on_train_batch_end: 1615676759.937136s

 2048/50000 [>.............................] - ETA: 15s - loss: 4.7963 - accuracy: 0.0749
on_train_batch_begin: 1615676759.937487s

1 step training time: 0.643122s

on_train_batch_end: 1615676760.595644s

 4096/50000 [=>............................] - ETA: 14s - loss: 4.7924 - accuracy: 0.0734
on_train_batch_begin: 1615676760.595941s

2 step training time: 0.658454s

on_train_batch_end: 1615676761.251490s

 6144/50000 [==>...........................] - ETA: 13s - loss: 4.7813 - accuracy: 0.0720
on_train_batch_begin: 1615676761.251781s

3 step training time: 0.655839s

on_train_batch_end: 1615676761.900851s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.7337 - accuracy: 0.0723
on_train_batch_begin: 1615676761.901147s

4 step training time: 0.649367s

on_train_batch_end: 1615676762.548167s

10240/50000 [=====>........................] - ETA: 12s - loss: 4.7188 - accuracy: 0.0718
on_train_batch_begin: 1615676762.548555s

5 step training time: 0.647408s

on_train_batch_end: 1615676763.205479s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.6998 - accuracy: 0.0715
on_train_batch_begin: 1615676763.205779s

6 step training time: 0.657223s

on_train_batch_end: 1615676763.861349s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.6610 - accuracy: 0.0717
on_train_batch_begin: 1615676763.861651s

7 step training time: 0.655872s

on_train_batch_end: 1615676764.516815s

16384/50000 [========>.....................] - ETA: 10s - loss: 4.6136 - accuracy: 0.0723
on_train_batch_begin: 1615676764.517147s

8 step training time: 0.655496s

on_train_batch_end: 1615676765.171528s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.5888 - accuracy: 0.0727
on_train_batch_begin: 1615676765.171824s

9 step training time: 0.654678s

on_train_batch_end: 1615676765.833894s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.5683 - accuracy: 0.0730 
on_train_batch_begin: 1615676765.834192s

10 step training time: 0.662368s

on_train_batch_end: 1615676766.487805s

22528/50000 [============>.................] - ETA: 8s - loss: 4.5351 - accuracy: 0.0734
on_train_batch_begin: 1615676766.488111s

11 step training time: 0.653919s

on_train_batch_end: 1615676767.142626s

24576/50000 [=============>................] - ETA: 8s - loss: 4.4942 - accuracy: 0.0741
on_train_batch_begin: 1615676767.142917s

12 step training time: 0.654806s

on_train_batch_end: 1615676767.794965s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.4431 - accuracy: 0.0749
on_train_batch_begin: 1615676767.795291s

13 step training time: 0.652374s

on_train_batch_end: 1615676768.451263s

28672/50000 [================>.............] - ETA: 6s - loss: 4.4070 - accuracy: 0.0756
on_train_batch_begin: 1615676768.451578s

14 step training time: 0.656287s

on_train_batch_end: 1615676769.106340s

30720/50000 [=================>............] - ETA: 6s - loss: 4.3646 - accuracy: 0.0760
on_train_batch_begin: 1615676769.106665s

15 step training time: 0.655087s

on_train_batch_end: 1615676769.756366s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.3371 - accuracy: 0.0763
on_train_batch_begin: 1615676769.756714s

16 step training time: 0.650049s

on_train_batch_end: 1615676770.408197s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.3019 - accuracy: 0.0769
on_train_batch_begin: 1615676770.408491s

17 step training time: 0.651777s

on_train_batch_end: 1615676771.064349s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.2711 - accuracy: 0.0775
on_train_batch_begin: 1615676771.064661s

18 step training time: 0.656170s

on_train_batch_end: 1615676771.719566s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.2336 - accuracy: 0.0781
on_train_batch_begin: 1615676771.719880s

19 step training time: 0.655219s

on_train_batch_end: 1615676772.366927s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.1965 - accuracy: 0.0786
on_train_batch_begin: 1615676772.367244s

20 step training time: 0.647365s

on_train_batch_end: 1615676773.013348s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.1628 - accuracy: 0.0792
on_train_batch_begin: 1615676773.013654s

21 step training time: 0.646410s

on_train_batch_end: 1615676773.659908s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.1314 - accuracy: 0.0796
on_train_batch_begin: 1615676773.660224s

22 step training time: 0.646570s

on_train_batch_end: 1615676774.312083s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.1031 - accuracy: 0.0800
on_train_batch_begin: 1615676774.312393s

23 step training time: 0.652169s

on_train_batch_end: 1615676774.960958s

49152/50000 [============================>.] - ETA: 0s - loss: 4.0741 - accuracy: 0.0804
on_train_batch_begin: 1615676774.961290s

24 step training time: 0.648897s

on_train_batch_end: 1615676775.244675s

on_test_batch_begin: 1615676775.264191s

25 step training time: 0.302901s

on_epoch_end: 1615676776.126835s

Validation time: 0.862632s

Real time: 1615676776.126835s

Epoch time: 16.83590006828308s

50000/50000 [==============================] - 17s 337us/sample - loss: 4.0632 - accuracy: 0.0805 - val_loss: 7.1678 - val_accuracy: 0.1001

on_epoch_begin: 1615676776.127030s

Real time: 1615676776.1270366
Epoch 5/5

on_train_batch_begin: 1615676776.130548s

on_train_batch_end: 1615676776.772384s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.2934 - accuracy: 0.0904
on_train_batch_begin: 1615676776.772696s

1 step training time: 0.642148s

on_train_batch_end: 1615676777.430357s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.2926 - accuracy: 0.0906
on_train_batch_begin: 1615676777.430647s

2 step training time: 0.657951s

on_train_batch_end: 1615676778.084799s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.2774 - accuracy: 0.0908
on_train_batch_begin: 1615676778.085212s

3 step training time: 0.654565s

on_train_batch_end: 1615676778.734106s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.2882 - accuracy: 0.0907
on_train_batch_begin: 1615676778.734401s

4 step training time: 0.649189s

on_train_batch_end: 1615676779.386716s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.2681 - accuracy: 0.0906
on_train_batch_begin: 1615676779.387043s

5 step training time: 0.652641s

on_train_batch_end: 1615676780.036780s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.2637 - accuracy: 0.0903
on_train_batch_begin: 1615676780.037107s

6 step training time: 0.650064s

on_train_batch_end: 1615676780.690784s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.2384 - accuracy: 0.0906
on_train_batch_begin: 1615676780.691096s

7 step training time: 0.653989s

on_train_batch_end: 1615676781.340899s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.2214 - accuracy: 0.0907
on_train_batch_begin: 1615676781.341227s

8 step training time: 0.650131s

on_train_batch_end: 1615676781.988499s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.2227 - accuracy: 0.0908
on_train_batch_begin: 1615676781.988818s

9 step training time: 0.647592s

on_train_batch_end: 1615676782.649369s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.2196 - accuracy: 0.0904 
on_train_batch_begin: 1615676782.649682s

10 step training time: 0.660863s

on_train_batch_end: 1615676783.304940s

22528/50000 [============>.................] - ETA: 8s - loss: 3.2087 - accuracy: 0.0903
on_train_batch_begin: 1615676783.305267s

11 step training time: 0.655585s

on_train_batch_end: 1615676783.957115s

24576/50000 [=============>................] - ETA: 8s - loss: 3.1964 - accuracy: 0.0905
on_train_batch_begin: 1615676783.957452s

12 step training time: 0.652185s

on_train_batch_end: 1615676784.614201s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.1908 - accuracy: 0.0910
on_train_batch_begin: 1615676784.614514s

13 step training time: 0.657062s

on_train_batch_end: 1615676785.272030s

28672/50000 [================>.............] - ETA: 6s - loss: 3.1807 - accuracy: 0.0913
on_train_batch_begin: 1615676785.272448s

14 step training time: 0.657933s

on_train_batch_end: 1615676785.934473s

30720/50000 [=================>............] - ETA: 6s - loss: 3.1739 - accuracy: 0.0917
on_train_batch_begin: 1615676785.934789s

15 step training time: 0.662341s

on_train_batch_end: 1615676786.587545s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.1614 - accuracy: 0.0919
on_train_batch_begin: 1615676786.587876s

16 step training time: 0.653087s

on_train_batch_end: 1615676787.247234s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.1452 - accuracy: 0.0919
on_train_batch_begin: 1615676787.247544s

17 step training time: 0.659668s

on_train_batch_end: 1615676787.905002s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.1261 - accuracy: 0.0920
on_train_batch_begin: 1615676787.905344s

18 step training time: 0.657799s

on_train_batch_end: 1615676788.555728s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.0994 - accuracy: 0.0923
on_train_batch_begin: 1615676788.556039s

19 step training time: 0.650695s

on_train_batch_end: 1615676789.204741s

40960/50000 [=======================>......] - ETA: 2s - loss: 3.0739 - accuracy: 0.0925
on_train_batch_begin: 1615676789.205053s

20 step training time: 0.649014s

on_train_batch_end: 1615676789.864849s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.0447 - accuracy: 0.0928
on_train_batch_begin: 1615676789.865180s

21 step training time: 0.660127s

on_train_batch_end: 1615676790.517688s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.0172 - accuracy: 0.0930
on_train_batch_begin: 1615676790.518017s

22 step training time: 0.652836s

on_train_batch_end: 1615676791.173629s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.9849 - accuracy: 0.0933
on_train_batch_begin: 1615676791.173941s

23 step training time: 0.655924s

on_train_batch_end: 1615676791.830657s

49152/50000 [============================>.] - ETA: 0s - loss: 2.9541 - accuracy: 0.0935
on_train_batch_begin: 1615676791.830968s

24 step training time: 0.657027s

on_train_batch_end: 1615676792.110289s

on_test_batch_begin: 1615676792.129773s

25 step training time: 0.298805s

on_epoch_end: 1615676792.988733s

Validation time: 0.858945s

Real time: 1615676792.988733s

Epoch time: 16.861711740493774s

50000/50000 [==============================] - 17s 337us/sample - loss: 2.9439 - accuracy: 0.0935 - val_loss: 8.3100 - val_accuracy: 0.1001
Tempo do fit: 117.26546001434326