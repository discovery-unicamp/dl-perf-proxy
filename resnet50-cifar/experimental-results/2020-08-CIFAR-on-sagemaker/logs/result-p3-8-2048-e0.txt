wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:07
   106496/170498071 [..............................] - ETA: 1:57
   417792/170498071 [..............................] - ETA: 50s 
  1662976/170498071 [..............................] - ETA: 17s
  4792320/170498071 [..............................] - ETA: 7s 
  7856128/170498071 [>.............................] - ETA: 5s
 10985472/170498071 [>.............................] - ETA: 4s
 14106624/170498071 [=>............................] - ETA: 4s
 17211392/170498071 [==>...........................] - ETA: 3s
 20144128/170498071 [==>...........................] - ETA: 3s
 23175168/170498071 [===>..........................] - ETA: 3s
 26271744/170498071 [===>..........................] - ETA: 3s
 29384704/170498071 [====>.........................] - ETA: 3s
 32243712/170498071 [====>.........................] - ETA: 2s
 35184640/170498071 [=====>........................] - ETA: 2s
 38297600/170498071 [=====>........................] - ETA: 2s
 41295872/170498071 [======>.......................] - ETA: 2s
 44425216/170498071 [======>.......................] - ETA: 2s
 47538176/170498071 [=======>......................] - ETA: 2s
 50577408/170498071 [=======>......................] - ETA: 2s
 53272576/170498071 [========>.....................] - ETA: 2s
 56320000/170498071 [========>.....................] - ETA: 2s
 59056128/170498071 [=========>....................] - ETA: 2s
 62382080/170498071 [=========>....................] - ETA: 2s
 65019904/170498071 [==========>...................] - ETA: 2s
 67854336/170498071 [==========>...................] - ETA: 1s
 70918144/170498071 [===========>..................] - ETA: 1s
 73900032/170498071 [============>.................] - ETA: 1s
 76439552/170498071 [============>.................] - ETA: 1s
 79552512/170498071 [============>.................] - ETA: 1s
 82681856/170498071 [=============>................] - ETA: 1s
 85499904/170498071 [==============>...............] - ETA: 1s
 88203264/170498071 [==============>...............] - ETA: 1s
 91299840/170498071 [===============>..............] - ETA: 1s
 94396416/170498071 [===============>..............] - ETA: 1s
 97255424/170498071 [================>.............] - ETA: 1s
100179968/170498071 [================>.............] - ETA: 1s
103309312/170498071 [=================>............] - ETA: 1s
106455040/170498071 [=================>............] - ETA: 1s
109289472/170498071 [==================>...........] - ETA: 1s
112418816/170498071 [==================>...........] - ETA: 1s
115564544/170498071 [===================>..........] - ETA: 0s
118611968/170498071 [===================>..........] - ETA: 0s
121724928/170498071 [====================>.........] - ETA: 0s
124723200/170498071 [====================>.........] - ETA: 0s
127696896/170498071 [=====================>........] - ETA: 0s
130605056/170498071 [=====================>........] - ETA: 0s
133570560/170498071 [======================>.......] - ETA: 0s
136699904/170498071 [=======================>......] - ETA: 0s
139812864/170498071 [=======================>......] - ETA: 0s
142811136/170498071 [========================>.....] - ETA: 0s
145940480/170498071 [========================>.....] - ETA: 0s
149053440/170498071 [=========================>....] - ETA: 0s
152117248/170498071 [=========================>....] - ETA: 0s
155246592/170498071 [==========================>...] - ETA: 0s
158359552/170498071 [==========================>...] - ETA: 0s
161488896/170498071 [===========================>..] - ETA: 0s
164331520/170498071 [===========================>..] - ETA: 0s
167354368/170498071 [============================>.] - ETA: 0s
170344448/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 5s
 5947392/94765736 [>.............................] - ETA: 0s
11763712/94765736 [==>...........................] - ETA: 0s
18022400/94765736 [====>.........................] - ETA: 0s
23019520/94765736 [======>.......................] - ETA: 0s
28000256/94765736 [=======>......................] - ETA: 0s
33038336/94765736 [=========>....................] - ETA: 0s
38043648/94765736 [===========>..................] - ETA: 0s
43008000/94765736 [============>.................] - ETA: 0s
48046080/94765736 [==============>...............] - ETA: 0s
53035008/94765736 [===============>..............] - ETA: 0s
58064896/94765736 [=================>............] - ETA: 0s
63062016/94765736 [==================>...........] - ETA: 0s
68050944/94765736 [====================>.........] - ETA: 0s
73031680/94765736 [======================>.......] - ETA: 0s
78045184/94765736 [=======================>......] - ETA: 0s
78331904/94765736 [=======================>......] - ETA: 0s
81477632/94765736 [========================>.....] - ETA: 0s
87957504/94765736 [==========================>...] - ETA: 0s
94126080/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 28.887312650680542
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1599840347.891793s

Real time: 1599840347.8918164
Epoch 1/5

on_train_batch_begin: 1599840348.902407s

on_train_batch_end: 1599840475.500358s

 2048/50000 [>.............................] - ETA: 49:47 - loss: 17.4495 - accuracy: 1.6975e-04
on_train_batch_begin: 1599840475.501065s

1 step training time: 126.598659s

on_train_batch_end: 1599840475.577554s

 4096/50000 [=>............................] - ETA: 23:50 - loss: 14.6985 - accuracy: 3.5286e-04
on_train_batch_begin: 1599840475.577939s

2 step training time: 0.076873s

on_train_batch_end: 1599840475.654461s

 6144/50000 [==>...........................] - ETA: 15:11 - loss: 12.8190 - accuracy: 7.1081e-04
on_train_batch_begin: 1599840475.654844s

3 step training time: 0.076905s

on_train_batch_end: 1599840475.733862s

 8192/50000 [===>..........................] - ETA: 10:52 - loss: 11.7339 - accuracy: 0.0020    
on_train_batch_begin: 1599840475.734244s

4 step training time: 0.079401s

on_train_batch_end: 1599840475.806981s

10240/50000 [=====>........................] - ETA: 8:16 - loss: 11.0084 - accuracy: 0.0044 
on_train_batch_begin: 1599840475.807366s

5 step training time: 0.073122s

on_train_batch_end: 1599840475.884048s

12288/50000 [======>.......................] - ETA: 6:32 - loss: 10.4935 - accuracy: 0.0086
on_train_batch_begin: 1599840475.884426s

6 step training time: 0.077060s

on_train_batch_end: 1599840475.956494s

14336/50000 [=======>......................] - ETA: 5:18 - loss: 10.0942 - accuracy: 0.0135
on_train_batch_begin: 1599840475.956882s

7 step training time: 0.072456s

on_train_batch_end: 1599840476.029875s

16384/50000 [========>.....................] - ETA: 4:22 - loss: 9.7752 - accuracy: 0.0188 
on_train_batch_begin: 1599840476.030249s

8 step training time: 0.073367s

on_train_batch_end: 1599840476.105485s

18432/50000 [==========>...................] - ETA: 3:39 - loss: 9.5075 - accuracy: 0.0229
on_train_batch_begin: 1599840476.105852s

9 step training time: 0.075603s

on_train_batch_end: 1599840476.179280s

20480/50000 [===========>..................] - ETA: 3:04 - loss: 9.2884 - accuracy: 0.0254
on_train_batch_begin: 1599840476.179686s

10 step training time: 0.073834s

on_train_batch_end: 1599840476.252240s

22528/50000 [============>.................] - ETA: 2:36 - loss: 9.0866 - accuracy: 0.0282
on_train_batch_begin: 1599840476.252623s

11 step training time: 0.072937s

on_train_batch_end: 1599840476.325725s

24576/50000 [=============>................] - ETA: 2:12 - loss: 8.9050 - accuracy: 0.0319
on_train_batch_begin: 1599840476.326100s

12 step training time: 0.073477s

on_train_batch_end: 1599840476.404400s

26624/50000 [==============>...............] - ETA: 1:52 - loss: 8.7453 - accuracy: 0.0346
on_train_batch_begin: 1599840476.404777s

13 step training time: 0.078677s

on_train_batch_end: 1599840476.478869s

28672/50000 [================>.............] - ETA: 1:35 - loss: 8.5947 - accuracy: 0.0368
on_train_batch_begin: 1599840476.479251s

14 step training time: 0.074474s

on_train_batch_end: 1599840476.553469s

30720/50000 [=================>............] - ETA: 1:20 - loss: 8.4664 - accuracy: 0.0386
on_train_batch_begin: 1599840476.553868s

15 step training time: 0.074617s

on_train_batch_end: 1599840476.631087s

32768/50000 [==================>...........] - ETA: 1:07 - loss: 8.3501 - accuracy: 0.0404
on_train_batch_begin: 1599840476.631517s

16 step training time: 0.077649s

on_train_batch_end: 1599840476.710947s

34816/50000 [===================>..........] - ETA: 56s - loss: 8.2360 - accuracy: 0.0420 
on_train_batch_begin: 1599840476.711315s

17 step training time: 0.079799s

on_train_batch_end: 1599840476.784616s

36864/50000 [=====================>........] - ETA: 45s - loss: 8.1342 - accuracy: 0.0431
on_train_batch_begin: 1599840476.785020s

18 step training time: 0.073705s

on_train_batch_end: 1599840476.866145s

38912/50000 [======================>.......] - ETA: 36s - loss: 8.0382 - accuracy: 0.0439
on_train_batch_begin: 1599840476.866534s

19 step training time: 0.081514s

on_train_batch_end: 1599840476.945398s

40960/50000 [=======================>......] - ETA: 28s - loss: 7.9430 - accuracy: 0.0447
on_train_batch_begin: 1599840476.945782s

20 step training time: 0.079248s

on_train_batch_end: 1599840477.026042s

43008/50000 [========================>.....] - ETA: 20s - loss: 7.8579 - accuracy: 0.0455
on_train_batch_begin: 1599840477.026425s

21 step training time: 0.080642s

on_train_batch_end: 1599840477.099802s

45056/50000 [==========================>...] - ETA: 14s - loss: 7.7768 - accuracy: 0.0462
on_train_batch_begin: 1599840477.100175s

22 step training time: 0.073750s

on_train_batch_end: 1599840477.172576s

47104/50000 [===========================>..] - ETA: 7s - loss: 7.6987 - accuracy: 0.0470 
on_train_batch_begin: 1599840477.172981s

23 step training time: 0.072807s

on_train_batch_end: 1599840477.244849s

49152/50000 [============================>.] - ETA: 2s - loss: 7.6288 - accuracy: 0.0476
on_train_batch_begin: 1599840477.245222s

24 step training time: 0.072241s

on_train_batch_end: 1599840478.240376s

on_test_batch_begin: 1599840478.631557s

25 step training time: 1.386335s

on_epoch_end: 1599840490.545092s

Validation time: 11.913515s

Real time: 1599840490.545092s

Epoch time: 142.65330123901367s

50000/50000 [==============================] - 143s 3ms/sample - loss: 7.6016 - accuracy: 0.0476 - val_loss: 48633.2377 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599840490.545367s

Real time: 1599840490.5453763
Epoch 2/5

on_train_batch_begin: 1599840490.553375s

on_train_batch_end: 1599840490.630420s

 2048/50000 [>.............................] - ETA: 1s - loss: 5.7919 - accuracy: 0.0594
on_train_batch_begin: 1599840490.630812s

1 step training time: 0.077436s

on_train_batch_end: 1599840490.704325s

 4096/50000 [=>............................] - ETA: 1s - loss: 5.6976 - accuracy: 0.0626
on_train_batch_begin: 1599840490.704709s

2 step training time: 0.073897s

on_train_batch_end: 1599840490.782668s

 6144/50000 [==>...........................] - ETA: 1s - loss: 5.6300 - accuracy: 0.0617
on_train_batch_begin: 1599840490.783052s

3 step training time: 0.078344s

on_train_batch_end: 1599840490.860154s

 8192/50000 [===>..........................] - ETA: 1s - loss: 5.5711 - accuracy: 0.0625
on_train_batch_begin: 1599840490.860538s

4 step training time: 0.077485s

on_train_batch_end: 1599840490.932031s

10240/50000 [=====>........................] - ETA: 1s - loss: 5.5126 - accuracy: 0.0627
on_train_batch_begin: 1599840490.932416s

5 step training time: 0.071878s

on_train_batch_end: 1599840491.006619s

12288/50000 [======>.......................] - ETA: 1s - loss: 5.4721 - accuracy: 0.0628
on_train_batch_begin: 1599840491.007007s

6 step training time: 0.074591s

on_train_batch_end: 1599840491.081331s

14336/50000 [=======>......................] - ETA: 1s - loss: 5.4296 - accuracy: 0.0628
on_train_batch_begin: 1599840491.081718s

7 step training time: 0.074711s

on_train_batch_end: 1599840491.161223s

16384/50000 [========>.....................] - ETA: 1s - loss: 5.3945 - accuracy: 0.0629
on_train_batch_begin: 1599840491.161605s

8 step training time: 0.079887s

on_train_batch_end: 1599840491.235364s

18432/50000 [==========>...................] - ETA: 1s - loss: 5.3633 - accuracy: 0.0625
on_train_batch_begin: 1599840491.235789s

9 step training time: 0.074184s

on_train_batch_end: 1599840491.309165s

20480/50000 [===========>..................] - ETA: 1s - loss: 5.3243 - accuracy: 0.0625
on_train_batch_begin: 1599840491.309551s

10 step training time: 0.073763s

on_train_batch_end: 1599840491.384092s

22528/50000 [============>.................] - ETA: 1s - loss: 5.2870 - accuracy: 0.0626
on_train_batch_begin: 1599840491.384479s

11 step training time: 0.074927s

on_train_batch_end: 1599840491.455852s

24576/50000 [=============>................] - ETA: 0s - loss: 5.2453 - accuracy: 0.0626
on_train_batch_begin: 1599840491.456237s

12 step training time: 0.071758s

on_train_batch_end: 1599840491.531639s

26624/50000 [==============>...............] - ETA: 0s - loss: 5.2146 - accuracy: 0.0627
on_train_batch_begin: 1599840491.532063s

13 step training time: 0.075827s

on_train_batch_end: 1599840491.608665s

28672/50000 [================>.............] - ETA: 0s - loss: 5.1777 - accuracy: 0.0630
on_train_batch_begin: 1599840491.609052s

14 step training time: 0.076988s

on_train_batch_end: 1599840491.682260s

30720/50000 [=================>............] - ETA: 0s - loss: 5.1459 - accuracy: 0.0631
on_train_batch_begin: 1599840491.682644s

15 step training time: 0.073592s

on_train_batch_end: 1599840491.762295s

32768/50000 [==================>...........] - ETA: 0s - loss: 5.1087 - accuracy: 0.0633
on_train_batch_begin: 1599840491.762680s

16 step training time: 0.080036s

on_train_batch_end: 1599840491.842303s

34816/50000 [===================>..........] - ETA: 0s - loss: 5.0698 - accuracy: 0.0637
on_train_batch_begin: 1599840491.842729s

17 step training time: 0.080050s

on_train_batch_end: 1599840491.917473s

36864/50000 [=====================>........] - ETA: 0s - loss: 5.0304 - accuracy: 0.0642
on_train_batch_begin: 1599840491.917861s

18 step training time: 0.075131s

on_train_batch_end: 1599840491.994104s

38912/50000 [======================>.......] - ETA: 0s - loss: 4.9947 - accuracy: 0.0646
on_train_batch_begin: 1599840491.994502s

19 step training time: 0.076641s

on_train_batch_end: 1599840492.069903s

40960/50000 [=======================>......] - ETA: 0s - loss: 4.9624 - accuracy: 0.0650
on_train_batch_begin: 1599840492.070311s

20 step training time: 0.075809s

on_train_batch_end: 1599840492.145338s

43008/50000 [========================>.....] - ETA: 0s - loss: 4.9259 - accuracy: 0.0654
on_train_batch_begin: 1599840492.145726s

21 step training time: 0.075416s

on_train_batch_end: 1599840492.219147s

45056/50000 [==========================>...] - ETA: 0s - loss: 4.8889 - accuracy: 0.0659
on_train_batch_begin: 1599840492.219562s

22 step training time: 0.073836s

on_train_batch_end: 1599840492.291265s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.8557 - accuracy: 0.0663
on_train_batch_begin: 1599840492.291679s

23 step training time: 0.072117s

on_train_batch_end: 1599840492.369754s

49152/50000 [============================>.] - ETA: 0s - loss: 4.8227 - accuracy: 0.0668
on_train_batch_begin: 1599840492.370159s

24 step training time: 0.078480s

on_train_batch_end: 1599840492.437656s

on_test_batch_begin: 1599840492.597562s

25 step training time: 0.227403s

on_epoch_end: 1599840492.946641s

Validation time: 0.349059s

Real time: 1599840492.946641s

Epoch time: 2.4012904167175293s

50000/50000 [==============================] - 2s 48us/sample - loss: 4.8093 - accuracy: 0.0669 - val_loss: 852.9098 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599840492.946919s

Real time: 1599840492.946928
Epoch 3/5

on_train_batch_begin: 1599840492.954812s

on_train_batch_end: 1599840493.039442s

 2048/50000 [>.............................] - ETA: 2s - loss: 3.8119 - accuracy: 0.0809
on_train_batch_begin: 1599840493.039918s

1 step training time: 0.085106s

on_train_batch_end: 1599840493.114753s

 4096/50000 [=>............................] - ETA: 1s - loss: 3.8106 - accuracy: 0.0788
on_train_batch_begin: 1599840493.115190s

2 step training time: 0.075271s

on_train_batch_end: 1599840493.191962s

 6144/50000 [==>...........................] - ETA: 1s - loss: 3.8008 - accuracy: 0.0794
on_train_batch_begin: 1599840493.192398s

3 step training time: 0.077208s

on_train_batch_end: 1599840493.269404s

 8192/50000 [===>..........................] - ETA: 1s - loss: 3.8028 - accuracy: 0.0794
on_train_batch_begin: 1599840493.269843s

4 step training time: 0.077445s

on_train_batch_end: 1599840493.348731s

10240/50000 [=====>........................] - ETA: 1s - loss: 3.7577 - accuracy: 0.0796
on_train_batch_begin: 1599840493.349194s

5 step training time: 0.079351s

on_train_batch_end: 1599840493.423707s

12288/50000 [======>.......................] - ETA: 1s - loss: 3.7571 - accuracy: 0.0797
on_train_batch_begin: 1599840493.424146s

6 step training time: 0.074952s

on_train_batch_end: 1599840493.503672s

14336/50000 [=======>......................] - ETA: 1s - loss: 3.7251 - accuracy: 0.0802
on_train_batch_begin: 1599840493.504152s

7 step training time: 0.080006s

on_train_batch_end: 1599840493.582234s

16384/50000 [========>.....................] - ETA: 1s - loss: 3.6631 - accuracy: 0.0811
on_train_batch_begin: 1599840493.582684s

8 step training time: 0.078532s

on_train_batch_end: 1599840493.655841s

18432/50000 [==========>...................] - ETA: 1s - loss: 3.6351 - accuracy: 0.0815
on_train_batch_begin: 1599840493.656269s

9 step training time: 0.073585s

on_train_batch_end: 1599840493.732353s

20480/50000 [===========>..................] - ETA: 1s - loss: 3.5965 - accuracy: 0.0821
on_train_batch_begin: 1599840493.732800s

10 step training time: 0.076531s

on_train_batch_end: 1599840493.807549s

22528/50000 [============>.................] - ETA: 1s - loss: 3.5716 - accuracy: 0.0826
on_train_batch_begin: 1599840493.807986s

11 step training time: 0.075186s

on_train_batch_end: 1599840493.879757s

24576/50000 [=============>................] - ETA: 0s - loss: 3.5385 - accuracy: 0.0834
on_train_batch_begin: 1599840493.880193s

12 step training time: 0.072207s

on_train_batch_end: 1599840493.952882s

26624/50000 [==============>...............] - ETA: 0s - loss: 3.5182 - accuracy: 0.0839
on_train_batch_begin: 1599840493.953319s

13 step training time: 0.073127s

on_train_batch_end: 1599840494.028948s

28672/50000 [================>.............] - ETA: 0s - loss: 3.4908 - accuracy: 0.0846
on_train_batch_begin: 1599840494.029411s

14 step training time: 0.076091s

on_train_batch_end: 1599840494.103774s

30720/50000 [=================>............] - ETA: 0s - loss: 3.4568 - accuracy: 0.0853
on_train_batch_begin: 1599840494.104208s

15 step training time: 0.074797s

on_train_batch_end: 1599840494.177481s

32768/50000 [==================>...........] - ETA: 0s - loss: 3.4216 - accuracy: 0.0859
on_train_batch_begin: 1599840494.177958s

16 step training time: 0.073750s

on_train_batch_end: 1599840494.259978s

34816/50000 [===================>..........] - ETA: 0s - loss: 3.3980 - accuracy: 0.0864
on_train_batch_begin: 1599840494.260413s

17 step training time: 0.082455s

on_train_batch_end: 1599840494.339280s

36864/50000 [=====================>........] - ETA: 0s - loss: 3.3783 - accuracy: 0.0868
on_train_batch_begin: 1599840494.339739s

18 step training time: 0.079326s

on_train_batch_end: 1599840494.411901s

38912/50000 [======================>.......] - ETA: 0s - loss: 3.3557 - accuracy: 0.0872
on_train_batch_begin: 1599840494.412352s

19 step training time: 0.072613s

on_train_batch_end: 1599840494.491700s

40960/50000 [=======================>......] - ETA: 0s - loss: 3.3348 - accuracy: 0.0877
on_train_batch_begin: 1599840494.492177s

20 step training time: 0.079825s

on_train_batch_end: 1599840494.565514s

43008/50000 [========================>.....] - ETA: 0s - loss: 3.3174 - accuracy: 0.0881
on_train_batch_begin: 1599840494.565983s

21 step training time: 0.073806s

on_train_batch_end: 1599840494.644372s

45056/50000 [==========================>...] - ETA: 0s - loss: 3.3063 - accuracy: 0.0885
on_train_batch_begin: 1599840494.644810s

22 step training time: 0.078827s

on_train_batch_end: 1599840494.721915s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.2879 - accuracy: 0.0890
on_train_batch_begin: 1599840494.722356s

23 step training time: 0.077547s

on_train_batch_end: 1599840494.800684s

49152/50000 [============================>.] - ETA: 0s - loss: 3.2691 - accuracy: 0.0894
on_train_batch_begin: 1599840494.801120s

24 step training time: 0.078764s

on_train_batch_end: 1599840494.865649s

on_test_batch_begin: 1599840495.021555s

25 step training time: 0.220434s

on_epoch_end: 1599840495.347646s

Validation time: 0.326056s

Real time: 1599840495.347646s

Epoch time: 2.4007458686828613s

50000/50000 [==============================] - 2s 48us/sample - loss: 3.2617 - accuracy: 0.0894 - val_loss: 7.4000 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599840495.347925s

Real time: 1599840495.3479342
Epoch 4/5

on_train_batch_begin: 1599840495.356405s

on_train_batch_end: 1599840495.440453s

 2048/50000 [>.............................] - ETA: 2s - loss: 2.7078 - accuracy: 0.0990
on_train_batch_begin: 1599840495.440906s

1 step training time: 0.084501s

on_train_batch_end: 1599840495.517122s

 4096/50000 [=>............................] - ETA: 1s - loss: 2.7738 - accuracy: 0.0993
on_train_batch_begin: 1599840495.517587s

2 step training time: 0.076681s

on_train_batch_end: 1599840495.593798s

 6144/50000 [==>...........................] - ETA: 1s - loss: 2.7082 - accuracy: 0.0996
on_train_batch_begin: 1599840495.594232s

3 step training time: 0.076645s

on_train_batch_end: 1599840495.669625s

 8192/50000 [===>..........................] - ETA: 1s - loss: 2.6832 - accuracy: 0.0996
on_train_batch_begin: 1599840495.670059s

4 step training time: 0.075827s

on_train_batch_end: 1599840495.744385s

10240/50000 [=====>........................] - ETA: 1s - loss: 2.6732 - accuracy: 0.0995
on_train_batch_begin: 1599840495.744848s

5 step training time: 0.074789s

on_train_batch_end: 1599840495.823600s

12288/50000 [======>.......................] - ETA: 1s - loss: 2.6536 - accuracy: 0.0995
on_train_batch_begin: 1599840495.824065s

6 step training time: 0.079218s

on_train_batch_end: 1599840495.898576s

14336/50000 [=======>......................] - ETA: 1s - loss: 2.6578 - accuracy: 0.0993
on_train_batch_begin: 1599840495.899032s

7 step training time: 0.074966s

on_train_batch_end: 1599840495.974845s

16384/50000 [========>.....................] - ETA: 1s - loss: 2.6458 - accuracy: 0.0993
on_train_batch_begin: 1599840495.975298s

8 step training time: 0.076266s

on_train_batch_end: 1599840496.051696s

18432/50000 [==========>...................] - ETA: 1s - loss: 2.6587 - accuracy: 0.0993
on_train_batch_begin: 1599840496.052089s

9 step training time: 0.076791s

on_train_batch_end: 1599840496.126699s

20480/50000 [===========>..................] - ETA: 1s - loss: 2.6451 - accuracy: 0.0992
on_train_batch_begin: 1599840496.127163s

10 step training time: 0.075074s

on_train_batch_end: 1599840496.203337s

22528/50000 [============>.................] - ETA: 1s - loss: 2.6427 - accuracy: 0.0991
on_train_batch_begin: 1599840496.203823s

11 step training time: 0.076660s

on_train_batch_end: 1599840496.282999s

24576/50000 [=============>................] - ETA: 0s - loss: 2.6370 - accuracy: 0.0990
on_train_batch_begin: 1599840496.283478s

12 step training time: 0.079655s

on_train_batch_end: 1599840496.360622s

26624/50000 [==============>...............] - ETA: 0s - loss: 2.6287 - accuracy: 0.0989
on_train_batch_begin: 1599840496.361095s

13 step training time: 0.077617s

on_train_batch_end: 1599840496.438128s

28672/50000 [================>.............] - ETA: 0s - loss: 2.6297 - accuracy: 0.0990
on_train_batch_begin: 1599840496.438584s

14 step training time: 0.077488s

on_train_batch_end: 1599840496.514431s

30720/50000 [=================>............] - ETA: 0s - loss: 2.6269 - accuracy: 0.0989
on_train_batch_begin: 1599840496.514932s

15 step training time: 0.076348s

on_train_batch_end: 1599840496.591509s

32768/50000 [==================>...........] - ETA: 0s - loss: 2.6287 - accuracy: 0.0989
on_train_batch_begin: 1599840496.591975s

16 step training time: 0.077044s

on_train_batch_end: 1599840496.674605s

34816/50000 [===================>..........] - ETA: 0s - loss: 2.6175 - accuracy: 0.0990
on_train_batch_begin: 1599840496.675098s

17 step training time: 0.083123s

on_train_batch_end: 1599840496.755918s

36864/50000 [=====================>........] - ETA: 0s - loss: 2.6115 - accuracy: 0.0991
on_train_batch_begin: 1599840496.756366s

18 step training time: 0.081267s

on_train_batch_end: 1599840496.834558s

38912/50000 [======================>.......] - ETA: 0s - loss: 2.6102 - accuracy: 0.0991
on_train_batch_begin: 1599840496.835027s

19 step training time: 0.078662s

on_train_batch_end: 1599840496.911978s

40960/50000 [=======================>......] - ETA: 0s - loss: 2.6062 - accuracy: 0.0992
on_train_batch_begin: 1599840496.912488s

20 step training time: 0.077460s

on_train_batch_end: 1599840496.987077s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.5982 - accuracy: 0.0992
on_train_batch_begin: 1599840496.987564s

21 step training time: 0.075076s

on_train_batch_end: 1599840497.064855s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.5907 - accuracy: 0.0993
on_train_batch_begin: 1599840497.065325s

22 step training time: 0.077761s

on_train_batch_end: 1599840497.143576s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.5874 - accuracy: 0.0993
on_train_batch_begin: 1599840497.144049s

23 step training time: 0.078725s

on_train_batch_end: 1599840497.216197s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5816 - accuracy: 0.0994
on_train_batch_begin: 1599840497.216665s

24 step training time: 0.072616s

on_train_batch_end: 1599840497.285185s

on_test_batch_begin: 1599840497.443561s

25 step training time: 0.226895s

on_epoch_end: 1599840497.786910s

Validation time: 0.343323s

Real time: 1599840497.786910s

Epoch time: 2.4389984607696533s

50000/50000 [==============================] - 2s 49us/sample - loss: 2.5772 - accuracy: 0.0994 - val_loss: 7.5451 - val_accuracy: 0.0998

on_epoch_begin: 1599840497.787163s

Real time: 1599840497.7871726
Epoch 5/5

on_train_batch_begin: 1599840497.795756s

on_train_batch_end: 1599840497.877159s

 2048/50000 [>.............................] - ETA: 2s - loss: 2.1762 - accuracy: 0.1000
on_train_batch_begin: 1599840497.877545s

1 step training time: 0.081789s

on_train_batch_end: 1599840497.953809s

 4096/50000 [=>............................] - ETA: 1s - loss: 2.1869 - accuracy: 0.1003
on_train_batch_begin: 1599840497.954227s

2 step training time: 0.076682s

on_train_batch_end: 1599840498.028764s

 6144/50000 [==>...........................] - ETA: 1s - loss: 2.2341 - accuracy: 0.1002
on_train_batch_begin: 1599840498.029179s

3 step training time: 0.074952s

on_train_batch_end: 1599840498.104015s

 8192/50000 [===>..........................] - ETA: 1s - loss: 2.2516 - accuracy: 0.1004
on_train_batch_begin: 1599840498.104401s

4 step training time: 0.075222s

on_train_batch_end: 1599840498.182302s

10240/50000 [=====>........................] - ETA: 1s - loss: 2.2377 - accuracy: 0.1007
on_train_batch_begin: 1599840498.182709s

5 step training time: 0.078308s

on_train_batch_end: 1599840498.254271s

12288/50000 [======>.......................] - ETA: 1s - loss: 2.2033 - accuracy: 0.1007
on_train_batch_begin: 1599840498.254663s

6 step training time: 0.071953s

on_train_batch_end: 1599840498.326940s

14336/50000 [=======>......................] - ETA: 1s - loss: 2.1852 - accuracy: 0.1008
on_train_batch_begin: 1599840498.327323s

7 step training time: 0.072660s

on_train_batch_end: 1599840498.399828s

16384/50000 [========>.....................] - ETA: 1s - loss: 2.1727 - accuracy: 0.1008
on_train_batch_begin: 1599840498.400203s

8 step training time: 0.072880s

on_train_batch_end: 1599840498.475317s

18432/50000 [==========>...................] - ETA: 1s - loss: 2.1755 - accuracy: 0.1007
on_train_batch_begin: 1599840498.475726s

9 step training time: 0.075524s

on_train_batch_end: 1599840498.549534s

20480/50000 [===========>..................] - ETA: 1s - loss: 2.1786 - accuracy: 0.1006
on_train_batch_begin: 1599840498.549927s

10 step training time: 0.074201s

on_train_batch_end: 1599840498.622700s

22528/50000 [============>.................] - ETA: 1s - loss: 2.1734 - accuracy: 0.1007
on_train_batch_begin: 1599840498.623095s

11 step training time: 0.073168s

on_train_batch_end: 1599840498.699677s

24576/50000 [=============>................] - ETA: 0s - loss: 2.1559 - accuracy: 0.1007
on_train_batch_begin: 1599840498.700053s

12 step training time: 0.076958s

on_train_batch_end: 1599840498.775963s

26624/50000 [==============>...............] - ETA: 0s - loss: 2.1464 - accuracy: 0.1007
on_train_batch_begin: 1599840498.776364s

13 step training time: 0.076311s

on_train_batch_end: 1599840498.853146s

28672/50000 [================>.............] - ETA: 0s - loss: 2.1418 - accuracy: 0.1007
on_train_batch_begin: 1599840498.853523s

14 step training time: 0.077160s

on_train_batch_end: 1599840498.927717s

30720/50000 [=================>............] - ETA: 0s - loss: 2.1293 - accuracy: 0.1008
on_train_batch_begin: 1599840498.928096s

15 step training time: 0.074573s

on_train_batch_end: 1599840499.001026s

32768/50000 [==================>...........] - ETA: 0s - loss: 2.1233 - accuracy: 0.1008
on_train_batch_begin: 1599840499.001413s

16 step training time: 0.073317s

on_train_batch_end: 1599840499.075444s

34816/50000 [===================>..........] - ETA: 0s - loss: 2.1178 - accuracy: 0.1008
on_train_batch_begin: 1599840499.075823s

17 step training time: 0.074410s

on_train_batch_end: 1599840499.149493s

36864/50000 [=====================>........] - ETA: 0s - loss: 2.1137 - accuracy: 0.1008
on_train_batch_begin: 1599840499.149951s

18 step training time: 0.074128s

on_train_batch_end: 1599840499.231758s

38912/50000 [======================>.......] - ETA: 0s - loss: 2.1138 - accuracy: 0.1008
on_train_batch_begin: 1599840499.232198s

19 step training time: 0.082247s

on_train_batch_end: 1599840499.307600s

40960/50000 [=======================>......] - ETA: 0s - loss: 2.1069 - accuracy: 0.1009
on_train_batch_begin: 1599840499.308036s

20 step training time: 0.075837s

on_train_batch_end: 1599840499.386514s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.0979 - accuracy: 0.1009
on_train_batch_begin: 1599840499.386948s

21 step training time: 0.078912s

on_train_batch_end: 1599840499.462766s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.0915 - accuracy: 0.1009
on_train_batch_begin: 1599840499.463205s

22 step training time: 0.076257s

on_train_batch_end: 1599840499.543683s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.0916 - accuracy: 0.1009
on_train_batch_begin: 1599840499.544124s

23 step training time: 0.080919s

on_train_batch_end: 1599840499.618210s

49152/50000 [============================>.] - ETA: 0s - loss: 2.0876 - accuracy: 0.1009
on_train_batch_begin: 1599840499.618680s

24 step training time: 0.074556s

on_train_batch_end: 1599840499.686629s

on_test_batch_begin: 1599840499.846330s

25 step training time: 0.227651s

on_epoch_end: 1599840500.188043s

Validation time: 0.341687s

Real time: 1599840500.188043s

Epoch time: 2.4008960723876953s

50000/50000 [==============================] - 2s 48us/sample - loss: 2.0866 - accuracy: 0.1009 - val_loss: 7.4930 - val_accuracy: 8.3089e-04
Tempo do fit: 156.44138932228088