wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:50
   204800/170498071 [..............................] - ETA: 1:17
   925696/170498071 [..............................] - ETA: 26s 
  3219456/170498071 [..............................] - ETA: 10s
  6529024/170498071 [>.............................] - ETA: 6s 
  9822208/170498071 [>.............................] - ETA: 4s
 13099008/170498071 [=>............................] - ETA: 4s
 16384000/170498071 [=>............................] - ETA: 3s
 19685376/170498071 [==>...........................] - ETA: 3s
 22994944/170498071 [===>..........................] - ETA: 3s
 26304512/170498071 [===>..........................] - ETA: 3s
 29499392/170498071 [====>.........................] - ETA: 2s
 32677888/170498071 [====>.........................] - ETA: 2s
 35921920/170498071 [=====>........................] - ETA: 2s
 39149568/170498071 [=====>........................] - ETA: 2s
 42450944/170498071 [======>.......................] - ETA: 2s
 45768704/170498071 [=======>......................] - ETA: 2s
 49045504/170498071 [=======>......................] - ETA: 2s
 52338688/170498071 [========>.....................] - ETA: 2s
 55631872/170498071 [========>.....................] - ETA: 2s
 58925056/170498071 [=========>....................] - ETA: 1s
 62185472/170498071 [=========>....................] - ETA: 1s
 65462272/170498071 [==========>...................] - ETA: 1s
 68608000/170498071 [===========>..................] - ETA: 1s
 71786496/170498071 [===========>..................] - ETA: 1s
 74981376/170498071 [============>.................] - ETA: 1s
 78274560/170498071 [============>.................] - ETA: 1s
 81485824/170498071 [=============>................] - ETA: 1s
 84795392/170498071 [=============>................] - ETA: 1s
 88055808/170498071 [==============>...............] - ETA: 1s
 91250688/170498071 [===============>..............] - ETA: 1s
 94511104/170498071 [===============>..............] - ETA: 1s
 97820672/170498071 [================>.............] - ETA: 1s
101130240/170498071 [================>.............] - ETA: 1s
104431616/170498071 [=================>............] - ETA: 1s
107732992/170498071 [=================>............] - ETA: 1s
110895104/170498071 [==================>...........] - ETA: 0s
114089984/170498071 [===================>..........] - ETA: 0s
117268480/170498071 [===================>..........] - ETA: 0s
120512512/170498071 [====================>.........] - ETA: 0s
123723776/170498071 [====================>.........] - ETA: 0s
127008768/170498071 [=====================>........] - ETA: 0s
130293760/170498071 [=====================>........] - ETA: 0s
133554176/170498071 [======================>.......] - ETA: 0s
136806400/170498071 [=======================>......] - ETA: 0s
140124160/170498071 [=======================>......] - ETA: 0s
143400960/170498071 [========================>.....] - ETA: 0s
146694144/170498071 [========================>.....] - ETA: 0s
149970944/170498071 [=========================>....] - ETA: 0s
153198592/170498071 [=========================>....] - ETA: 0s
156377088/170498071 [==========================>...] - ETA: 0s
159637504/170498071 [===========================>..] - ETA: 0s
162906112/170498071 [===========================>..] - ETA: 0s
166141952/170498071 [============================>.] - ETA: 0s
169459712/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 6299648/94765736 [>.............................] - ETA: 0s
11313152/94765736 [==>...........................] - ETA: 0s
16408576/94765736 [====>.........................] - ETA: 0s
21422080/94765736 [=====>........................] - ETA: 0s
26443776/94765736 [=======>......................] - ETA: 0s
31055872/94765736 [========>.....................] - ETA: 0s
36405248/94765736 [==========>...................] - ETA: 0s
41459712/94765736 [============>.................] - ETA: 0s
46448640/94765736 [=============>................] - ETA: 0s
51503104/94765736 [===============>..............] - ETA: 0s
56573952/94765736 [================>.............] - ETA: 0s
61521920/94765736 [==================>...........] - ETA: 0s
66609152/94765736 [====================>.........] - ETA: 0s
71696384/94765736 [=====================>........] - ETA: 0s
76791808/94765736 [=======================>......] - ETA: 0s
81707008/94765736 [========================>.....] - ETA: 0s
86687744/94765736 [==========================>...] - ETA: 0s
91725824/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 16.923370361328125
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598509110.796681s

Real time: 1598509110.7966964
Epoch 1/5

on_train_batch_begin: 1598509111.573591s

on_train_batch_end: 1598509157.491369s

 1024/50000 [..............................] - ETA: 37:13 - loss: 17.2413 - accuracy: 6.4850e-05
on_train_batch_begin: 1598509157.491985s

1 step training time: 45.918394s

on_train_batch_end: 1598509157.629514s

 2048/50000 [>.............................] - ETA: 18:16 - loss: 15.2994 - accuracy: 1.9073e-04
on_train_batch_begin: 1598509157.629826s

2 step training time: 0.137841s

on_train_batch_end: 1598509157.767604s

 3072/50000 [>.............................] - ETA: 11:57 - loss: 13.4872 - accuracy: 3.9546e-04
on_train_batch_begin: 1598509157.767907s

3 step training time: 0.138081s

on_train_batch_end: 1598509157.904973s

 4096/50000 [=>............................] - ETA: 8:47 - loss: 12.3146 - accuracy: 8.3160e-04 
on_train_batch_begin: 1598509157.905272s

4 step training time: 0.137366s

on_train_batch_end: 1598509158.042014s

 5120/50000 [==>...........................] - ETA: 6:54 - loss: 11.5133 - accuracy: 0.0014    
on_train_batch_begin: 1598509158.042311s

5 step training time: 0.137038s

on_train_batch_end: 1598509158.178096s

 6144/50000 [==>...........................] - ETA: 5:38 - loss: 10.8939 - accuracy: 0.0028
on_train_batch_begin: 1598509158.178397s

6 step training time: 0.136086s

on_train_batch_end: 1598509158.316480s

 7168/50000 [===>..........................] - ETA: 4:43 - loss: 10.4240 - accuracy: 0.0049
on_train_batch_begin: 1598509158.316771s

7 step training time: 0.138373s

on_train_batch_end: 1598509158.453915s

 8192/50000 [===>..........................] - ETA: 4:03 - loss: 10.0748 - accuracy: 0.0073
on_train_batch_begin: 1598509158.454208s

8 step training time: 0.137437s

on_train_batch_end: 1598509158.592630s

 9216/50000 [====>.........................] - ETA: 3:31 - loss: 9.7733 - accuracy: 0.0103 
on_train_batch_begin: 1598509158.592934s

9 step training time: 0.138726s

on_train_batch_end: 1598509158.729033s

10240/50000 [=====>........................] - ETA: 3:06 - loss: 9.5230 - accuracy: 0.0132
on_train_batch_begin: 1598509158.729332s

10 step training time: 0.136398s

on_train_batch_end: 1598509158.866176s

11264/50000 [=====>........................] - ETA: 2:45 - loss: 9.2992 - accuracy: 0.0161
on_train_batch_begin: 1598509158.866499s

11 step training time: 0.137168s

on_train_batch_end: 1598509159.005501s

12288/50000 [======>.......................] - ETA: 2:27 - loss: 9.1113 - accuracy: 0.0191
on_train_batch_begin: 1598509159.005806s

12 step training time: 0.139307s

on_train_batch_end: 1598509159.140939s

13312/50000 [======>.......................] - ETA: 2:13 - loss: 8.9368 - accuracy: 0.0215
on_train_batch_begin: 1598509159.141272s

13 step training time: 0.135466s

on_train_batch_end: 1598509159.278301s

14336/50000 [=======>......................] - ETA: 2:00 - loss: 8.7760 - accuracy: 0.0244
on_train_batch_begin: 1598509159.278632s

14 step training time: 0.137360s

on_train_batch_end: 1598509159.416091s

15360/50000 [========>.....................] - ETA: 1:49 - loss: 8.6463 - accuracy: 0.0266
on_train_batch_begin: 1598509159.416382s

15 step training time: 0.137750s

on_train_batch_end: 1598509159.551152s

16384/50000 [========>.....................] - ETA: 1:40 - loss: 8.5261 - accuracy: 0.0296
on_train_batch_begin: 1598509159.551460s

16 step training time: 0.135077s

on_train_batch_end: 1598509159.688383s

17408/50000 [=========>....................] - ETA: 1:31 - loss: 8.4115 - accuracy: 0.0320
on_train_batch_begin: 1598509159.688672s

17 step training time: 0.137212s

on_train_batch_end: 1598509159.824330s

18432/50000 [==========>...................] - ETA: 1:23 - loss: 8.3043 - accuracy: 0.0348
on_train_batch_begin: 1598509159.824623s

18 step training time: 0.135952s

on_train_batch_end: 1598509159.964415s

19456/50000 [==========>...................] - ETA: 1:17 - loss: 8.2125 - accuracy: 0.0368
on_train_batch_begin: 1598509159.964700s

19 step training time: 0.140076s

on_train_batch_end: 1598509160.104397s

20480/50000 [===========>..................] - ETA: 1:11 - loss: 8.1269 - accuracy: 0.0390
on_train_batch_begin: 1598509160.104688s

20 step training time: 0.139989s

on_train_batch_end: 1598509160.241656s

21504/50000 [===========>..................] - ETA: 1:05 - loss: 8.0408 - accuracy: 0.0407
on_train_batch_begin: 1598509160.241968s

21 step training time: 0.137280s

on_train_batch_end: 1598509160.378734s

22528/50000 [============>.................] - ETA: 1:00 - loss: 7.9618 - accuracy: 0.0423
on_train_batch_begin: 1598509160.379027s

22 step training time: 0.137058s

on_train_batch_end: 1598509160.515723s

23552/50000 [=============>................] - ETA: 55s - loss: 7.8801 - accuracy: 0.0435 
on_train_batch_begin: 1598509160.516014s

23 step training time: 0.136987s

on_train_batch_end: 1598509160.655103s

24576/50000 [=============>................] - ETA: 51s - loss: 7.8063 - accuracy: 0.0447
on_train_batch_begin: 1598509160.655404s

24 step training time: 0.139390s

on_train_batch_end: 1598509160.793221s

25600/50000 [==============>...............] - ETA: 47s - loss: 7.7438 - accuracy: 0.0456
on_train_batch_begin: 1598509160.793512s

25 step training time: 0.138108s

on_train_batch_end: 1598509160.929083s

26624/50000 [==============>...............] - ETA: 44s - loss: 7.6725 - accuracy: 0.0468
on_train_batch_begin: 1598509160.929372s

26 step training time: 0.135860s

on_train_batch_end: 1598509161.065676s

27648/50000 [===============>..............] - ETA: 40s - loss: 7.6079 - accuracy: 0.0479
on_train_batch_begin: 1598509161.065966s

27 step training time: 0.136594s

on_train_batch_end: 1598509161.202578s

28672/50000 [================>.............] - ETA: 37s - loss: 7.5446 - accuracy: 0.0492
on_train_batch_begin: 1598509161.202885s

28 step training time: 0.136919s

on_train_batch_end: 1598509161.339778s

29696/50000 [================>.............] - ETA: 34s - loss: 7.4838 - accuracy: 0.0504
on_train_batch_begin: 1598509161.340096s

29 step training time: 0.137212s

on_train_batch_end: 1598509161.477515s

30720/50000 [=================>............] - ETA: 31s - loss: 7.4183 - accuracy: 0.0516
on_train_batch_begin: 1598509161.477801s

30 step training time: 0.137705s

on_train_batch_end: 1598509161.615615s

31744/50000 [==================>...........] - ETA: 29s - loss: 7.3574 - accuracy: 0.0526
on_train_batch_begin: 1598509161.615907s

31 step training time: 0.138107s

on_train_batch_end: 1598509161.751940s

32768/50000 [==================>...........] - ETA: 26s - loss: 7.3043 - accuracy: 0.0534
on_train_batch_begin: 1598509161.752236s

32 step training time: 0.136328s

on_train_batch_end: 1598509161.891850s

33792/50000 [===================>..........] - ETA: 24s - loss: 7.2482 - accuracy: 0.0541
on_train_batch_begin: 1598509161.892137s

33 step training time: 0.139901s

on_train_batch_end: 1598509162.028065s

34816/50000 [===================>..........] - ETA: 22s - loss: 7.1979 - accuracy: 0.0546
on_train_batch_begin: 1598509162.028353s

34 step training time: 0.136216s

on_train_batch_end: 1598509162.165097s

35840/50000 [====================>.........] - ETA: 20s - loss: 7.1415 - accuracy: 0.0556
on_train_batch_begin: 1598509162.165379s

35 step training time: 0.137026s

on_train_batch_end: 1598509162.301697s

36864/50000 [=====================>........] - ETA: 18s - loss: 7.0894 - accuracy: 0.0562
on_train_batch_begin: 1598509162.301986s

36 step training time: 0.136607s

on_train_batch_end: 1598509162.440320s

37888/50000 [=====================>........] - ETA: 16s - loss: 7.0378 - accuracy: 0.0566
on_train_batch_begin: 1598509162.440613s

37 step training time: 0.138627s

on_train_batch_end: 1598509162.577234s

38912/50000 [======================>.......] - ETA: 14s - loss: 6.9891 - accuracy: 0.0570
on_train_batch_begin: 1598509162.577520s

38 step training time: 0.136907s

on_train_batch_end: 1598509162.715201s

39936/50000 [======================>.......] - ETA: 13s - loss: 6.9421 - accuracy: 0.0573
on_train_batch_begin: 1598509162.715486s

39 step training time: 0.137966s

on_train_batch_end: 1598509162.851255s

40960/50000 [=======================>......] - ETA: 11s - loss: 6.8945 - accuracy: 0.0575
on_train_batch_begin: 1598509162.851556s

40 step training time: 0.136070s

on_train_batch_end: 1598509162.991894s

41984/50000 [========================>.....] - ETA: 9s - loss: 6.8457 - accuracy: 0.0580 
on_train_batch_begin: 1598509162.992182s

41 step training time: 0.140626s

on_train_batch_end: 1598509163.130957s

43008/50000 [========================>.....] - ETA: 8s - loss: 6.8013 - accuracy: 0.0583
on_train_batch_begin: 1598509163.131260s

42 step training time: 0.139078s

on_train_batch_end: 1598509163.267669s

44032/50000 [=========================>....] - ETA: 7s - loss: 6.7563 - accuracy: 0.0587
on_train_batch_begin: 1598509163.267957s

43 step training time: 0.136697s

on_train_batch_end: 1598509163.404073s

45056/50000 [==========================>...] - ETA: 5s - loss: 6.7124 - accuracy: 0.0590
on_train_batch_begin: 1598509163.404359s

44 step training time: 0.136401s

on_train_batch_end: 1598509163.540850s

46080/50000 [==========================>...] - ETA: 4s - loss: 6.6733 - accuracy: 0.0592
on_train_batch_begin: 1598509163.541144s

45 step training time: 0.136785s

on_train_batch_end: 1598509163.679892s

47104/50000 [===========================>..] - ETA: 3s - loss: 6.6320 - accuracy: 0.0595
on_train_batch_begin: 1598509163.680215s

46 step training time: 0.139071s

on_train_batch_end: 1598509163.816346s

48128/50000 [===========================>..] - ETA: 2s - loss: 6.5920 - accuracy: 0.0597
on_train_batch_begin: 1598509163.816630s

47 step training time: 0.136415s

on_train_batch_end: 1598509163.953012s

49152/50000 [============================>.] - ETA: 0s - loss: 6.5501 - accuracy: 0.0599
on_train_batch_begin: 1598509163.953307s

48 step training time: 0.136677s

on_train_batch_end: 1598509166.763844s

on_test_batch_begin: 1598509167.000592s

49 step training time: 3.047285s

on_epoch_end: 1598509171.989488s

Validation time: 4.988880s

Real time: 1598509171.989488s

Epoch time: 61.19280958175659s

50000/50000 [==============================] - 61s 1ms/sample - loss: 6.5197 - accuracy: 0.0601 - val_loss: 7.6289 - val_accuracy: 0.0999

on_epoch_begin: 1598509171.989669s

Real time: 1598509171.9896736
Epoch 2/5

on_train_batch_begin: 1598509171.994238s

on_train_batch_end: 1598509172.136144s

 1024/50000 [..............................] - ETA: 7s - loss: 4.4839 - accuracy: 0.0649
on_train_batch_begin: 1598509172.136423s

1 step training time: 0.142184s

on_train_batch_end: 1598509172.272986s

 2048/50000 [>.............................] - ETA: 6s - loss: 4.4286 - accuracy: 0.0664
on_train_batch_begin: 1598509172.273268s

2 step training time: 0.136845s

on_train_batch_end: 1598509172.411233s

 3072/50000 [>.............................] - ETA: 6s - loss: 4.3884 - accuracy: 0.0673
on_train_batch_begin: 1598509172.411515s

3 step training time: 0.138247s

on_train_batch_end: 1598509172.549689s

 4096/50000 [=>............................] - ETA: 6s - loss: 4.3696 - accuracy: 0.0673
on_train_batch_begin: 1598509172.550004s

4 step training time: 0.138489s

on_train_batch_end: 1598509172.688518s

 5120/50000 [==>...........................] - ETA: 6s - loss: 4.3093 - accuracy: 0.0684
on_train_batch_begin: 1598509172.688807s

5 step training time: 0.138803s

on_train_batch_end: 1598509172.824534s

 6144/50000 [==>...........................] - ETA: 5s - loss: 4.2445 - accuracy: 0.0693
on_train_batch_begin: 1598509172.824818s

6 step training time: 0.136011s

on_train_batch_end: 1598509172.962384s

 7168/50000 [===>..........................] - ETA: 5s - loss: 4.2226 - accuracy: 0.0694
on_train_batch_begin: 1598509172.962686s

7 step training time: 0.137868s

on_train_batch_end: 1598509173.099734s

 8192/50000 [===>..........................] - ETA: 5s - loss: 4.1631 - accuracy: 0.0702
on_train_batch_begin: 1598509173.100047s

8 step training time: 0.137361s

on_train_batch_end: 1598509173.239230s

 9216/50000 [====>.........................] - ETA: 5s - loss: 4.1114 - accuracy: 0.0713
on_train_batch_begin: 1598509173.239514s

9 step training time: 0.139467s

on_train_batch_end: 1598509173.378366s

10240/50000 [=====>........................] - ETA: 5s - loss: 4.0737 - accuracy: 0.0721
on_train_batch_begin: 1598509173.378674s

10 step training time: 0.139160s

on_train_batch_end: 1598509173.514328s

11264/50000 [=====>........................] - ETA: 5s - loss: 4.0372 - accuracy: 0.0726
on_train_batch_begin: 1598509173.514648s

11 step training time: 0.135974s

on_train_batch_end: 1598509173.652173s

12288/50000 [======>.......................] - ETA: 5s - loss: 3.9871 - accuracy: 0.0734
on_train_batch_begin: 1598509173.652458s

12 step training time: 0.137810s

on_train_batch_end: 1598509173.788896s

13312/50000 [======>.......................] - ETA: 4s - loss: 3.9476 - accuracy: 0.0740
on_train_batch_begin: 1598509173.789186s

13 step training time: 0.136728s

on_train_batch_end: 1598509173.927834s

14336/50000 [=======>......................] - ETA: 4s - loss: 3.9174 - accuracy: 0.0748
on_train_batch_begin: 1598509173.928117s

14 step training time: 0.138932s

on_train_batch_end: 1598509174.065971s

15360/50000 [========>.....................] - ETA: 4s - loss: 3.8924 - accuracy: 0.0754
on_train_batch_begin: 1598509174.066256s

15 step training time: 0.138139s

on_train_batch_end: 1598509174.202378s

16384/50000 [========>.....................] - ETA: 4s - loss: 3.8556 - accuracy: 0.0762
on_train_batch_begin: 1598509174.202684s

16 step training time: 0.136428s

on_train_batch_end: 1598509174.340996s

17408/50000 [=========>....................] - ETA: 4s - loss: 3.8279 - accuracy: 0.0768
on_train_batch_begin: 1598509174.341314s

17 step training time: 0.138630s

on_train_batch_end: 1598509174.479081s

18432/50000 [==========>...................] - ETA: 4s - loss: 3.7945 - accuracy: 0.0776
on_train_batch_begin: 1598509174.479374s

18 step training time: 0.138060s

on_train_batch_end: 1598509174.618433s

19456/50000 [==========>...................] - ETA: 4s - loss: 3.7604 - accuracy: 0.0783
on_train_batch_begin: 1598509174.618743s

19 step training time: 0.139368s

on_train_batch_end: 1598509174.755716s

20480/50000 [===========>..................] - ETA: 3s - loss: 3.7190 - accuracy: 0.0790
on_train_batch_begin: 1598509174.755996s

20 step training time: 0.137253s

on_train_batch_end: 1598509174.892093s

21504/50000 [===========>..................] - ETA: 3s - loss: 3.6907 - accuracy: 0.0797
on_train_batch_begin: 1598509174.892392s

21 step training time: 0.136396s

on_train_batch_end: 1598509175.029617s

22528/50000 [============>.................] - ETA: 3s - loss: 3.6622 - accuracy: 0.0805
on_train_batch_begin: 1598509175.029902s

22 step training time: 0.137509s

on_train_batch_end: 1598509175.168507s

23552/50000 [=============>................] - ETA: 3s - loss: 3.6271 - accuracy: 0.0812
on_train_batch_begin: 1598509175.168793s

23 step training time: 0.138891s

on_train_batch_end: 1598509175.306704s

24576/50000 [=============>................] - ETA: 3s - loss: 3.5977 - accuracy: 0.0819
on_train_batch_begin: 1598509175.306989s

24 step training time: 0.138196s

on_train_batch_end: 1598509175.443110s

25600/50000 [==============>...............] - ETA: 3s - loss: 3.5608 - accuracy: 0.0825
on_train_batch_begin: 1598509175.443393s

25 step training time: 0.136404s

on_train_batch_end: 1598509175.581076s

26624/50000 [==============>...............] - ETA: 3s - loss: 3.5285 - accuracy: 0.0830
on_train_batch_begin: 1598509175.581380s

26 step training time: 0.137986s

on_train_batch_end: 1598509175.721473s

27648/50000 [===============>..............] - ETA: 3s - loss: 3.4970 - accuracy: 0.0836
on_train_batch_begin: 1598509175.721751s

27 step training time: 0.140372s

on_train_batch_end: 1598509175.860273s

28672/50000 [================>.............] - ETA: 2s - loss: 3.4738 - accuracy: 0.0841
on_train_batch_begin: 1598509175.860563s

28 step training time: 0.138811s

on_train_batch_end: 1598509175.999098s

29696/50000 [================>.............] - ETA: 2s - loss: 3.4460 - accuracy: 0.0848
on_train_batch_begin: 1598509175.999381s

29 step training time: 0.138818s

on_train_batch_end: 1598509176.136799s

30720/50000 [=================>............] - ETA: 2s - loss: 3.4221 - accuracy: 0.0852
on_train_batch_begin: 1598509176.137079s

30 step training time: 0.137698s

on_train_batch_end: 1598509176.274587s

31744/50000 [==================>...........] - ETA: 2s - loss: 3.3920 - accuracy: 0.0857
on_train_batch_begin: 1598509176.274870s

31 step training time: 0.137791s

on_train_batch_end: 1598509176.412957s

32768/50000 [==================>...........] - ETA: 2s - loss: 3.3654 - accuracy: 0.0862
on_train_batch_begin: 1598509176.413247s

32 step training time: 0.138377s

on_train_batch_end: 1598509176.553691s

33792/50000 [===================>..........] - ETA: 2s - loss: 3.3471 - accuracy: 0.0866
on_train_batch_begin: 1598509176.553969s

33 step training time: 0.140723s

on_train_batch_end: 1598509176.692738s

34816/50000 [===================>..........] - ETA: 2s - loss: 3.3218 - accuracy: 0.0870
on_train_batch_begin: 1598509176.693026s

34 step training time: 0.139057s

on_train_batch_end: 1598509176.833444s

35840/50000 [====================>.........] - ETA: 1s - loss: 3.3003 - accuracy: 0.0874
on_train_batch_begin: 1598509176.833729s

35 step training time: 0.140702s

on_train_batch_end: 1598509176.971609s

36864/50000 [=====================>........] - ETA: 1s - loss: 3.2789 - accuracy: 0.0878
on_train_batch_begin: 1598509176.971920s

36 step training time: 0.138192s

on_train_batch_end: 1598509177.109231s

37888/50000 [=====================>........] - ETA: 1s - loss: 3.2626 - accuracy: 0.0881
on_train_batch_begin: 1598509177.109514s

37 step training time: 0.137593s

on_train_batch_end: 1598509177.247970s

38912/50000 [======================>.......] - ETA: 1s - loss: 3.2486 - accuracy: 0.0885
on_train_batch_begin: 1598509177.248266s

38 step training time: 0.138752s

on_train_batch_end: 1598509177.385709s

39936/50000 [======================>.......] - ETA: 1s - loss: 3.2330 - accuracy: 0.0888
on_train_batch_begin: 1598509177.385995s

39 step training time: 0.137729s

on_train_batch_end: 1598509177.525691s

40960/50000 [=======================>......] - ETA: 1s - loss: 3.2229 - accuracy: 0.0890
on_train_batch_begin: 1598509177.525978s

40 step training time: 0.139983s

on_train_batch_end: 1598509177.664942s

41984/50000 [========================>.....] - ETA: 1s - loss: 3.2106 - accuracy: 0.0893
on_train_batch_begin: 1598509177.665228s

41 step training time: 0.139251s

on_train_batch_end: 1598509177.803652s

43008/50000 [========================>.....] - ETA: 0s - loss: 3.1951 - accuracy: 0.0895
on_train_batch_begin: 1598509177.803939s

42 step training time: 0.138710s

on_train_batch_end: 1598509177.941005s

44032/50000 [=========================>....] - ETA: 0s - loss: 3.1838 - accuracy: 0.0897
on_train_batch_begin: 1598509177.941334s

43 step training time: 0.137396s

on_train_batch_end: 1598509178.079682s

45056/50000 [==========================>...] - ETA: 0s - loss: 3.1736 - accuracy: 0.0900
on_train_batch_begin: 1598509178.079990s

44 step training time: 0.138655s

on_train_batch_end: 1598509178.218440s

46080/50000 [==========================>...] - ETA: 0s - loss: 3.1585 - accuracy: 0.0902
on_train_batch_begin: 1598509178.218749s

45 step training time: 0.138759s

on_train_batch_end: 1598509178.360128s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.1434 - accuracy: 0.0905
on_train_batch_begin: 1598509178.360421s

46 step training time: 0.141672s

on_train_batch_end: 1598509178.500864s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.1314 - accuracy: 0.0907
on_train_batch_begin: 1598509178.501176s

47 step training time: 0.140755s

on_train_batch_end: 1598509178.639678s

49152/50000 [============================>.] - ETA: 0s - loss: 3.1144 - accuracy: 0.0909
on_train_batch_begin: 1598509178.639988s

48 step training time: 0.138813s

on_train_batch_end: 1598509178.765734s

on_test_batch_begin: 1598509178.786741s

49 step training time: 0.146753s

on_epoch_end: 1598509179.091714s

Validation time: 0.304961s

Real time: 1598509179.091714s

Epoch time: 7.1020567417144775s

50000/50000 [==============================] - 7s 142us/sample - loss: 3.1056 - accuracy: 0.0910 - val_loss: 7.1847 - val_accuracy: 0.0999

on_epoch_begin: 1598509179.091892s

Real time: 1598509179.0918965
Epoch 3/5

on_train_batch_begin: 1598509179.096283s

on_train_batch_end: 1598509179.235157s

 1024/50000 [..............................] - ETA: 6s - loss: 2.2532 - accuracy: 0.1006
on_train_batch_begin: 1598509179.235445s

1 step training time: 0.139162s

on_train_batch_end: 1598509179.373786s

 2048/50000 [>.............................] - ETA: 6s - loss: 2.2593 - accuracy: 0.1006
on_train_batch_begin: 1598509179.374076s

2 step training time: 0.138632s

on_train_batch_end: 1598509179.514771s

 3072/50000 [>.............................] - ETA: 6s - loss: 2.2213 - accuracy: 0.1005
on_train_batch_begin: 1598509179.515064s

3 step training time: 0.140987s

on_train_batch_end: 1598509179.652467s

 4096/50000 [=>............................] - ETA: 6s - loss: 2.2099 - accuracy: 0.1006
on_train_batch_begin: 1598509179.652755s

4 step training time: 0.137692s

on_train_batch_end: 1598509179.790995s

 5120/50000 [==>...........................] - ETA: 6s - loss: 2.2005 - accuracy: 0.1004
on_train_batch_begin: 1598509179.791321s

5 step training time: 0.138565s

on_train_batch_end: 1598509179.929847s

 6144/50000 [==>...........................] - ETA: 5s - loss: 2.1408 - accuracy: 0.1005
on_train_batch_begin: 1598509179.930166s

6 step training time: 0.138846s

on_train_batch_end: 1598509180.068953s

 7168/50000 [===>..........................] - ETA: 5s - loss: 2.1293 - accuracy: 0.1004
on_train_batch_begin: 1598509180.069241s

7 step training time: 0.139074s

on_train_batch_end: 1598509180.207833s

 8192/50000 [===>..........................] - ETA: 5s - loss: 2.1103 - accuracy: 0.1005
on_train_batch_begin: 1598509180.208117s

8 step training time: 0.138876s

on_train_batch_end: 1598509180.347202s

 9216/50000 [====>.........................] - ETA: 5s - loss: 2.0893 - accuracy: 0.1005
on_train_batch_begin: 1598509180.347490s

9 step training time: 0.139373s

on_train_batch_end: 1598509180.485693s

10240/50000 [=====>........................] - ETA: 5s - loss: 2.0871 - accuracy: 0.1005
on_train_batch_begin: 1598509180.485976s

10 step training time: 0.138486s

on_train_batch_end: 1598509180.624219s

11264/50000 [=====>........................] - ETA: 5s - loss: 2.0645 - accuracy: 0.1005
on_train_batch_begin: 1598509180.624508s

11 step training time: 0.138532s

on_train_batch_end: 1598509180.761839s

12288/50000 [======>.......................] - ETA: 5s - loss: 2.0533 - accuracy: 0.1006
on_train_batch_begin: 1598509180.762127s

12 step training time: 0.137619s

on_train_batch_end: 1598509180.901819s

13312/50000 [======>.......................] - ETA: 4s - loss: 2.0367 - accuracy: 0.1007
on_train_batch_begin: 1598509180.902123s

13 step training time: 0.139996s

on_train_batch_end: 1598509181.042403s

14336/50000 [=======>......................] - ETA: 4s - loss: 2.0292 - accuracy: 0.1007
on_train_batch_begin: 1598509181.042718s

14 step training time: 0.140596s

on_train_batch_end: 1598509181.180828s

15360/50000 [========>.....................] - ETA: 4s - loss: 2.0216 - accuracy: 0.1007
on_train_batch_begin: 1598509181.181134s

15 step training time: 0.138416s

on_train_batch_end: 1598509181.318726s

16384/50000 [========>.....................] - ETA: 4s - loss: 2.0240 - accuracy: 0.1007
on_train_batch_begin: 1598509181.319014s

16 step training time: 0.137880s

on_train_batch_end: 1598509181.456198s

17408/50000 [=========>....................] - ETA: 4s - loss: 2.0132 - accuracy: 0.1007
on_train_batch_begin: 1598509181.456483s

17 step training time: 0.137470s

on_train_batch_end: 1598509181.593957s

18432/50000 [==========>...................] - ETA: 4s - loss: 2.0061 - accuracy: 0.1007
on_train_batch_begin: 1598509181.594242s

18 step training time: 0.137759s

on_train_batch_end: 1598509181.733838s

19456/50000 [==========>...................] - ETA: 4s - loss: 1.9942 - accuracy: 0.1007
on_train_batch_begin: 1598509181.734124s

19 step training time: 0.139882s

on_train_batch_end: 1598509181.874475s

20480/50000 [===========>..................] - ETA: 4s - loss: 1.9787 - accuracy: 0.1007
on_train_batch_begin: 1598509181.874790s

20 step training time: 0.140666s

on_train_batch_end: 1598509182.013890s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.9649 - accuracy: 0.1008
on_train_batch_begin: 1598509182.014178s

21 step training time: 0.139388s

on_train_batch_end: 1598509182.151160s

22528/50000 [============>.................] - ETA: 3s - loss: 1.9536 - accuracy: 0.1007
on_train_batch_begin: 1598509182.151471s

22 step training time: 0.137294s

on_train_batch_end: 1598509182.289178s

23552/50000 [=============>................] - ETA: 3s - loss: 1.9413 - accuracy: 0.1008
on_train_batch_begin: 1598509182.289470s

23 step training time: 0.137999s

on_train_batch_end: 1598509182.428863s

24576/50000 [=============>................] - ETA: 3s - loss: 1.9202 - accuracy: 0.1008
on_train_batch_begin: 1598509182.429147s

24 step training time: 0.139677s

on_train_batch_end: 1598509182.569911s

25600/50000 [==============>...............] - ETA: 3s - loss: 1.9150 - accuracy: 0.1008
on_train_batch_begin: 1598509182.570225s

25 step training time: 0.141079s

on_train_batch_end: 1598509182.710918s

26624/50000 [==============>...............] - ETA: 3s - loss: 1.9088 - accuracy: 0.1008
on_train_batch_begin: 1598509182.711247s

26 step training time: 0.141022s

on_train_batch_end: 1598509182.851362s

27648/50000 [===============>..............] - ETA: 3s - loss: 1.8998 - accuracy: 0.1008
on_train_batch_begin: 1598509182.851645s

27 step training time: 0.140398s

on_train_batch_end: 1598509182.990965s

28672/50000 [================>.............] - ETA: 2s - loss: 1.8944 - accuracy: 0.1008
on_train_batch_begin: 1598509182.991269s

28 step training time: 0.139624s

on_train_batch_end: 1598509183.130348s

29696/50000 [================>.............] - ETA: 2s - loss: 1.8868 - accuracy: 0.1008
on_train_batch_begin: 1598509183.130657s

29 step training time: 0.139388s

on_train_batch_end: 1598509183.267897s

30720/50000 [=================>............] - ETA: 2s - loss: 1.8778 - accuracy: 0.1008
on_train_batch_begin: 1598509183.268190s

30 step training time: 0.137534s

on_train_batch_end: 1598509183.406527s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.8747 - accuracy: 0.1008
on_train_batch_begin: 1598509183.406812s

31 step training time: 0.138622s

on_train_batch_end: 1598509183.546875s

32768/50000 [==================>...........] - ETA: 2s - loss: 1.8667 - accuracy: 0.1008
on_train_batch_begin: 1598509183.547157s

32 step training time: 0.140344s

on_train_batch_end: 1598509183.686747s

33792/50000 [===================>..........] - ETA: 2s - loss: 1.8597 - accuracy: 0.1008
on_train_batch_begin: 1598509183.687037s

33 step training time: 0.139881s

on_train_batch_end: 1598509183.826189s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.8535 - accuracy: 0.1008
on_train_batch_begin: 1598509183.826491s

34 step training time: 0.139454s

on_train_batch_end: 1598509183.966587s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.8443 - accuracy: 0.1008
on_train_batch_begin: 1598509183.966870s

35 step training time: 0.140378s

on_train_batch_end: 1598509184.107733s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.8370 - accuracy: 0.1009
on_train_batch_begin: 1598509184.108019s

36 step training time: 0.141149s

on_train_batch_end: 1598509184.246207s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.8293 - accuracy: 0.1009
on_train_batch_begin: 1598509184.246510s

37 step training time: 0.138491s

on_train_batch_end: 1598509184.383287s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.8272 - accuracy: 0.1009
on_train_batch_begin: 1598509184.383566s

38 step training time: 0.137056s

on_train_batch_end: 1598509184.521239s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.8215 - accuracy: 0.1009
on_train_batch_begin: 1598509184.521524s

39 step training time: 0.137958s

on_train_batch_end: 1598509184.660903s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.8115 - accuracy: 0.1009
on_train_batch_begin: 1598509184.661214s

40 step training time: 0.139690s

on_train_batch_end: 1598509184.801499s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.8071 - accuracy: 0.1009
on_train_batch_begin: 1598509184.801786s

41 step training time: 0.140572s

on_train_batch_end: 1598509184.941786s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.7970 - accuracy: 0.1009
on_train_batch_begin: 1598509184.942073s

42 step training time: 0.140286s

on_train_batch_end: 1598509185.080989s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.7890 - accuracy: 0.1009
on_train_batch_begin: 1598509185.081298s

43 step training time: 0.139226s

on_train_batch_end: 1598509185.218592s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.7821 - accuracy: 0.1009
on_train_batch_begin: 1598509185.218877s

44 step training time: 0.137578s

on_train_batch_end: 1598509185.355563s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.7752 - accuracy: 0.1009
on_train_batch_begin: 1598509185.355846s

45 step training time: 0.136970s

on_train_batch_end: 1598509185.494384s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7729 - accuracy: 0.1009
on_train_batch_begin: 1598509185.494695s

46 step training time: 0.138848s

on_train_batch_end: 1598509185.633729s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7660 - accuracy: 0.1009
on_train_batch_begin: 1598509185.634016s

47 step training time: 0.139321s

on_train_batch_end: 1598509185.774815s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7583 - accuracy: 0.1009
on_train_batch_begin: 1598509185.775101s

48 step training time: 0.141086s

on_train_batch_end: 1598509185.900428s

on_test_batch_begin: 1598509185.920112s

49 step training time: 0.145010s

on_epoch_end: 1598509186.240971s

Validation time: 0.320847s

Real time: 1598509186.240971s

Epoch time: 7.149089097976685s

50000/50000 [==============================] - 7s 143us/sample - loss: 1.7523 - accuracy: 0.1010 - val_loss: 7.7091 - val_accuracy: 0.0999

on_epoch_begin: 1598509186.241157s

Real time: 1598509186.2411618
Epoch 4/5

on_train_batch_begin: 1598509186.245408s

on_train_batch_end: 1598509186.385939s

 1024/50000 [..............................] - ETA: 6s - loss: 1.2368 - accuracy: 0.1012
on_train_batch_begin: 1598509186.386208s

1 step training time: 0.140800s

on_train_batch_end: 1598509186.526052s

 2048/50000 [>.............................] - ETA: 6s - loss: 1.2116 - accuracy: 0.1007
on_train_batch_begin: 1598509186.526333s

2 step training time: 0.140125s

on_train_batch_end: 1598509186.665038s

 3072/50000 [>.............................] - ETA: 6s - loss: 1.2506 - accuracy: 0.1008
on_train_batch_begin: 1598509186.665331s

3 step training time: 0.138999s

on_train_batch_end: 1598509186.802669s

 4096/50000 [=>............................] - ETA: 6s - loss: 1.2452 - accuracy: 0.1009
on_train_batch_begin: 1598509186.802960s

4 step training time: 0.137629s

on_train_batch_end: 1598509186.940271s

 5120/50000 [==>...........................] - ETA: 6s - loss: 1.2613 - accuracy: 0.1008
on_train_batch_begin: 1598509186.940557s

5 step training time: 0.137597s

on_train_batch_end: 1598509187.079353s

 6144/50000 [==>...........................] - ETA: 5s - loss: 1.2729 - accuracy: 0.1010
on_train_batch_begin: 1598509187.079639s

6 step training time: 0.139082s

on_train_batch_end: 1598509187.220484s

 7168/50000 [===>..........................] - ETA: 5s - loss: 1.2869 - accuracy: 0.1010
on_train_batch_begin: 1598509187.220777s

7 step training time: 0.141138s

on_train_batch_end: 1598509187.359584s

 8192/50000 [===>..........................] - ETA: 5s - loss: 1.2820 - accuracy: 0.1011
on_train_batch_begin: 1598509187.359866s

8 step training time: 0.139089s

on_train_batch_end: 1598509187.500145s

 9216/50000 [====>.........................] - ETA: 5s - loss: 1.2948 - accuracy: 0.1011
on_train_batch_begin: 1598509187.500433s

9 step training time: 0.140567s

on_train_batch_end: 1598509187.641814s

10240/50000 [=====>........................] - ETA: 5s - loss: 1.3000 - accuracy: 0.1011
on_train_batch_begin: 1598509187.642124s

10 step training time: 0.141691s

on_train_batch_end: 1598509187.783401s

11264/50000 [=====>........................] - ETA: 5s - loss: 1.2904 - accuracy: 0.1011
on_train_batch_begin: 1598509187.783682s

11 step training time: 0.141557s

on_train_batch_end: 1598509187.923766s

12288/50000 [======>.......................] - ETA: 5s - loss: 1.2925 - accuracy: 0.1013
on_train_batch_begin: 1598509187.924055s

12 step training time: 0.140374s

on_train_batch_end: 1598509188.062707s

13312/50000 [======>.......................] - ETA: 5s - loss: 1.3059 - accuracy: 0.1012
on_train_batch_begin: 1598509188.062997s

13 step training time: 0.138942s

on_train_batch_end: 1598509188.200463s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.2970 - accuracy: 0.1012
on_train_batch_begin: 1598509188.200753s

14 step training time: 0.137756s

on_train_batch_end: 1598509188.338041s

15360/50000 [========>.....................] - ETA: 4s - loss: 1.2895 - accuracy: 0.1012
on_train_batch_begin: 1598509188.338332s

15 step training time: 0.137579s

on_train_batch_end: 1598509188.477717s

16384/50000 [========>.....................] - ETA: 4s - loss: 1.2946 - accuracy: 0.1012
on_train_batch_begin: 1598509188.478019s

16 step training time: 0.139686s

on_train_batch_end: 1598509188.617814s

17408/50000 [=========>....................] - ETA: 4s - loss: 1.2924 - accuracy: 0.1011
on_train_batch_begin: 1598509188.618098s

17 step training time: 0.140080s

on_train_batch_end: 1598509188.759426s

18432/50000 [==========>...................] - ETA: 4s - loss: 1.2914 - accuracy: 0.1012
on_train_batch_begin: 1598509188.759709s

18 step training time: 0.141611s

on_train_batch_end: 1598509188.900617s

19456/50000 [==========>...................] - ETA: 4s - loss: 1.2912 - accuracy: 0.1012
on_train_batch_begin: 1598509188.900908s

19 step training time: 0.141199s

on_train_batch_end: 1598509189.041095s

20480/50000 [===========>..................] - ETA: 4s - loss: 1.2889 - accuracy: 0.1012
on_train_batch_begin: 1598509189.041391s

20 step training time: 0.140483s

on_train_batch_end: 1598509189.180497s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.2862 - accuracy: 0.1012
on_train_batch_begin: 1598509189.180783s

21 step training time: 0.139393s

on_train_batch_end: 1598509189.318090s

22528/50000 [============>.................] - ETA: 3s - loss: 1.2800 - accuracy: 0.1012
on_train_batch_begin: 1598509189.318376s

22 step training time: 0.137592s

on_train_batch_end: 1598509189.457402s

23552/50000 [=============>................] - ETA: 3s - loss: 1.2718 - accuracy: 0.1011
on_train_batch_begin: 1598509189.457691s

23 step training time: 0.139316s

on_train_batch_end: 1598509189.594739s

24576/50000 [=============>................] - ETA: 3s - loss: 1.2673 - accuracy: 0.1011
on_train_batch_begin: 1598509189.595027s

24 step training time: 0.137336s

on_train_batch_end: 1598509189.733976s

25600/50000 [==============>...............] - ETA: 3s - loss: 1.2681 - accuracy: 0.1012
on_train_batch_begin: 1598509189.734271s

25 step training time: 0.139244s

on_train_batch_end: 1598509189.874877s

26624/50000 [==============>...............] - ETA: 3s - loss: 1.2656 - accuracy: 0.1012
on_train_batch_begin: 1598509189.875165s

26 step training time: 0.140894s

on_train_batch_end: 1598509190.016710s

27648/50000 [===============>..............] - ETA: 3s - loss: 1.2588 - accuracy: 0.1012
on_train_batch_begin: 1598509190.016998s

27 step training time: 0.141833s

on_train_batch_end: 1598509190.157089s

28672/50000 [================>.............] - ETA: 2s - loss: 1.2568 - accuracy: 0.1012
on_train_batch_begin: 1598509190.157387s

28 step training time: 0.140389s

on_train_batch_end: 1598509190.296089s

29696/50000 [================>.............] - ETA: 2s - loss: 1.2505 - accuracy: 0.1012
on_train_batch_begin: 1598509190.296372s

29 step training time: 0.138984s

on_train_batch_end: 1598509190.435407s

30720/50000 [=================>............] - ETA: 2s - loss: 1.2423 - accuracy: 0.1012
on_train_batch_begin: 1598509190.435703s

30 step training time: 0.139331s

on_train_batch_end: 1598509190.572937s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.2346 - accuracy: 0.1011
on_train_batch_begin: 1598509190.573227s

31 step training time: 0.137524s

on_train_batch_end: 1598509190.711220s

32768/50000 [==================>...........] - ETA: 2s - loss: 1.2314 - accuracy: 0.1011
on_train_batch_begin: 1598509190.711511s

32 step training time: 0.138284s

on_train_batch_end: 1598509190.850597s

33792/50000 [===================>..........] - ETA: 2s - loss: 1.2266 - accuracy: 0.1011
on_train_batch_begin: 1598509190.850890s

33 step training time: 0.139379s

on_train_batch_end: 1598509190.991252s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.2197 - accuracy: 0.1011
on_train_batch_begin: 1598509190.991536s

34 step training time: 0.140646s

on_train_batch_end: 1598509191.132140s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.2175 - accuracy: 0.1011
on_train_batch_begin: 1598509191.132449s

35 step training time: 0.140913s

on_train_batch_end: 1598509191.272776s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.2164 - accuracy: 0.1011
on_train_batch_begin: 1598509191.273062s

36 step training time: 0.140614s

on_train_batch_end: 1598509191.411464s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.2151 - accuracy: 0.1011
on_train_batch_begin: 1598509191.411748s

37 step training time: 0.138686s

on_train_batch_end: 1598509191.548903s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.2121 - accuracy: 0.1011
on_train_batch_begin: 1598509191.549190s

38 step training time: 0.137442s

on_train_batch_end: 1598509191.686656s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.2073 - accuracy: 0.1011
on_train_batch_begin: 1598509191.686947s

39 step training time: 0.137757s

on_train_batch_end: 1598509191.827551s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.2036 - accuracy: 0.1011
on_train_batch_begin: 1598509191.827835s

40 step training time: 0.140888s

on_train_batch_end: 1598509191.967666s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.2011 - accuracy: 0.1011
on_train_batch_begin: 1598509191.967948s

41 step training time: 0.140113s

on_train_batch_end: 1598509192.108541s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.1998 - accuracy: 0.1011
on_train_batch_begin: 1598509192.108829s

42 step training time: 0.140881s

on_train_batch_end: 1598509192.249593s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.1975 - accuracy: 0.1011
on_train_batch_begin: 1598509192.249891s

43 step training time: 0.141062s

on_train_batch_end: 1598509192.390113s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.1948 - accuracy: 0.1011
on_train_batch_begin: 1598509192.390402s

44 step training time: 0.140511s

on_train_batch_end: 1598509192.528271s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.1941 - accuracy: 0.1011
on_train_batch_begin: 1598509192.528548s

45 step training time: 0.138146s

on_train_batch_end: 1598509192.666357s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.1913 - accuracy: 0.1011
on_train_batch_begin: 1598509192.666670s

46 step training time: 0.138123s

on_train_batch_end: 1598509192.804105s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1892 - accuracy: 0.1011
on_train_batch_begin: 1598509192.804386s

47 step training time: 0.137716s

on_train_batch_end: 1598509192.943258s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1867 - accuracy: 0.1011
on_train_batch_begin: 1598509192.943544s

48 step training time: 0.139158s

on_train_batch_end: 1598509193.070510s

on_test_batch_begin: 1598509193.088314s

49 step training time: 0.144770s

on_epoch_end: 1598509193.408524s

Validation time: 0.320198s

Real time: 1598509193.408524s

Epoch time: 7.167377710342407s

50000/50000 [==============================] - 7s 143us/sample - loss: 1.1861 - accuracy: 0.1011 - val_loss: 7.0396 - val_accuracy: 0.1001

on_epoch_begin: 1598509193.408696s

Real time: 1598509193.4087007
Epoch 5/5

on_train_batch_begin: 1598509193.413319s

on_train_batch_end: 1598509193.552896s

 1024/50000 [..............................] - ETA: 6s - loss: 0.9755 - accuracy: 0.1015
on_train_batch_begin: 1598509193.553165s

1 step training time: 0.139847s

on_train_batch_end: 1598509193.692667s

 2048/50000 [>.............................] - ETA: 6s - loss: 0.9626 - accuracy: 0.1011
on_train_batch_begin: 1598509193.692938s

2 step training time: 0.139772s

on_train_batch_end: 1598509193.832777s

 3072/50000 [>.............................] - ETA: 6s - loss: 0.9392 - accuracy: 0.1012
on_train_batch_begin: 1598509193.833052s

3 step training time: 0.140115s

on_train_batch_end: 1598509193.971884s

 4096/50000 [=>............................] - ETA: 6s - loss: 0.9542 - accuracy: 0.1011
on_train_batch_begin: 1598509193.972164s

4 step training time: 0.139112s

on_train_batch_end: 1598509194.111412s

 5120/50000 [==>...........................] - ETA: 6s - loss: 0.9623 - accuracy: 0.1012
on_train_batch_begin: 1598509194.111695s

5 step training time: 0.139531s

on_train_batch_end: 1598509194.249138s

 6144/50000 [==>...........................] - ETA: 6s - loss: 0.9560 - accuracy: 0.1012
on_train_batch_begin: 1598509194.249422s

6 step training time: 0.137727s

on_train_batch_end: 1598509194.387035s

 7168/50000 [===>..........................] - ETA: 5s - loss: 0.9437 - accuracy: 0.1013
on_train_batch_begin: 1598509194.387319s

7 step training time: 0.137897s

on_train_batch_end: 1598509194.526746s

 8192/50000 [===>..........................] - ETA: 5s - loss: 0.9310 - accuracy: 0.1014
on_train_batch_begin: 1598509194.527050s

8 step training time: 0.139731s

on_train_batch_end: 1598509194.667910s

 9216/50000 [====>.........................] - ETA: 5s - loss: 0.9275 - accuracy: 0.1013
on_train_batch_begin: 1598509194.668194s

9 step training time: 0.141144s

on_train_batch_end: 1598509194.809149s

10240/50000 [=====>........................] - ETA: 5s - loss: 0.9266 - accuracy: 0.1013
on_train_batch_begin: 1598509194.809435s

10 step training time: 0.141241s

on_train_batch_end: 1598509194.950021s

11264/50000 [=====>........................] - ETA: 5s - loss: 0.9365 - accuracy: 0.1013
on_train_batch_begin: 1598509194.950310s

11 step training time: 0.140876s

on_train_batch_end: 1598509195.092307s

12288/50000 [======>.......................] - ETA: 5s - loss: 0.9289 - accuracy: 0.1013
on_train_batch_begin: 1598509195.092597s

12 step training time: 0.142286s

on_train_batch_end: 1598509195.231488s

13312/50000 [======>.......................] - ETA: 5s - loss: 0.9288 - accuracy: 0.1014
on_train_batch_begin: 1598509195.231783s

13 step training time: 0.139187s

on_train_batch_end: 1598509195.371796s

14336/50000 [=======>......................] - ETA: 4s - loss: 0.9278 - accuracy: 0.1013
on_train_batch_begin: 1598509195.372103s

14 step training time: 0.140319s

on_train_batch_end: 1598509195.509952s

15360/50000 [========>.....................] - ETA: 4s - loss: 0.9239 - accuracy: 0.1013
on_train_batch_begin: 1598509195.510240s

15 step training time: 0.138138s

on_train_batch_end: 1598509195.646834s

16384/50000 [========>.....................] - ETA: 4s - loss: 0.9239 - accuracy: 0.1013
on_train_batch_begin: 1598509195.647112s

16 step training time: 0.136872s

on_train_batch_end: 1598509195.786094s

17408/50000 [=========>....................] - ETA: 4s - loss: 0.9194 - accuracy: 0.1013
on_train_batch_begin: 1598509195.786376s

17 step training time: 0.139264s

on_train_batch_end: 1598509195.927534s

18432/50000 [==========>...................] - ETA: 4s - loss: 0.9130 - accuracy: 0.1014
on_train_batch_begin: 1598509195.927816s

18 step training time: 0.141440s

on_train_batch_end: 1598509196.067976s

19456/50000 [==========>...................] - ETA: 4s - loss: 0.9054 - accuracy: 0.1014
on_train_batch_begin: 1598509196.068262s

19 step training time: 0.140446s

on_train_batch_end: 1598509196.207966s

20480/50000 [===========>..................] - ETA: 4s - loss: 0.9047 - accuracy: 0.1014
on_train_batch_begin: 1598509196.208248s

20 step training time: 0.139986s

on_train_batch_end: 1598509196.346535s

21504/50000 [===========>..................] - ETA: 3s - loss: 0.9023 - accuracy: 0.1014
on_train_batch_begin: 1598509196.346834s

21 step training time: 0.138586s

on_train_batch_end: 1598509196.484813s

22528/50000 [============>.................] - ETA: 3s - loss: 0.8972 - accuracy: 0.1014
on_train_batch_begin: 1598509196.485114s

22 step training time: 0.138280s

on_train_batch_end: 1598509196.624787s

23552/50000 [=============>................] - ETA: 3s - loss: 0.8955 - accuracy: 0.1014
on_train_batch_begin: 1598509196.625073s

23 step training time: 0.139959s

on_train_batch_end: 1598509196.762616s

24576/50000 [=============>................] - ETA: 3s - loss: 0.8954 - accuracy: 0.1015
on_train_batch_begin: 1598509196.762907s

24 step training time: 0.137834s

on_train_batch_end: 1598509196.901821s

25600/50000 [==============>...............] - ETA: 3s - loss: 0.8942 - accuracy: 0.1014
on_train_batch_begin: 1598509196.902102s

25 step training time: 0.139195s

on_train_batch_end: 1598509197.043039s

26624/50000 [==============>...............] - ETA: 3s - loss: 0.8909 - accuracy: 0.1014
on_train_batch_begin: 1598509197.043327s

26 step training time: 0.141225s

on_train_batch_end: 1598509197.182935s

27648/50000 [===============>..............] - ETA: 3s - loss: 0.8922 - accuracy: 0.1014
on_train_batch_begin: 1598509197.183218s

27 step training time: 0.139891s

on_train_batch_end: 1598509197.322580s

28672/50000 [================>.............] - ETA: 2s - loss: 0.8959 - accuracy: 0.1014
on_train_batch_begin: 1598509197.322876s

28 step training time: 0.139658s

on_train_batch_end: 1598509197.461250s

29696/50000 [================>.............] - ETA: 2s - loss: 0.8955 - accuracy: 0.1014
on_train_batch_begin: 1598509197.461529s

29 step training time: 0.138654s

on_train_batch_end: 1598509197.599800s

30720/50000 [=================>............] - ETA: 2s - loss: 0.8933 - accuracy: 0.1014
on_train_batch_begin: 1598509197.600112s

30 step training time: 0.138583s

on_train_batch_end: 1598509197.739266s

31744/50000 [==================>...........] - ETA: 2s - loss: 0.8912 - accuracy: 0.1014
on_train_batch_begin: 1598509197.739545s

31 step training time: 0.139433s

on_train_batch_end: 1598509197.878031s

32768/50000 [==================>...........] - ETA: 2s - loss: 0.8906 - accuracy: 0.1014
on_train_batch_begin: 1598509197.878315s

32 step training time: 0.138770s

on_train_batch_end: 1598509198.019361s

33792/50000 [===================>..........] - ETA: 2s - loss: 0.8897 - accuracy: 0.1014
on_train_batch_begin: 1598509198.019642s

33 step training time: 0.141327s

on_train_batch_end: 1598509198.161018s

34816/50000 [===================>..........] - ETA: 2s - loss: 0.8868 - accuracy: 0.1014
on_train_batch_begin: 1598509198.161313s

34 step training time: 0.141671s

on_train_batch_end: 1598509198.301773s

35840/50000 [====================>.........] - ETA: 1s - loss: 0.8845 - accuracy: 0.1014
on_train_batch_begin: 1598509198.302050s

35 step training time: 0.140737s

on_train_batch_end: 1598509198.444353s

36864/50000 [=====================>........] - ETA: 1s - loss: 0.8811 - accuracy: 0.1014
on_train_batch_begin: 1598509198.444648s

36 step training time: 0.142599s

on_train_batch_end: 1598509198.585269s

37888/50000 [=====================>........] - ETA: 1s - loss: 0.8815 - accuracy: 0.1014
on_train_batch_begin: 1598509198.585554s

37 step training time: 0.140906s

on_train_batch_end: 1598509198.725475s

38912/50000 [======================>.......] - ETA: 1s - loss: 0.8803 - accuracy: 0.1014
on_train_batch_begin: 1598509198.725757s

38 step training time: 0.140203s

on_train_batch_end: 1598509198.864413s

39936/50000 [======================>.......] - ETA: 1s - loss: 0.8811 - accuracy: 0.1014
on_train_batch_begin: 1598509198.864693s

39 step training time: 0.138936s

on_train_batch_end: 1598509199.003323s

40960/50000 [=======================>......] - ETA: 1s - loss: 0.8798 - accuracy: 0.1014
on_train_batch_begin: 1598509199.003603s

40 step training time: 0.138910s

on_train_batch_end: 1598509199.142664s

41984/50000 [========================>.....] - ETA: 1s - loss: 0.8817 - accuracy: 0.1014
on_train_batch_begin: 1598509199.142959s

41 step training time: 0.139355s

on_train_batch_end: 1598509199.281838s

43008/50000 [========================>.....] - ETA: 0s - loss: 0.8818 - accuracy: 0.1014
on_train_batch_begin: 1598509199.282115s

42 step training time: 0.139156s

on_train_batch_end: 1598509199.422522s

44032/50000 [=========================>....] - ETA: 0s - loss: 0.8809 - accuracy: 0.1014
on_train_batch_begin: 1598509199.422809s

43 step training time: 0.140694s

on_train_batch_end: 1598509199.564190s

45056/50000 [==========================>...] - ETA: 0s - loss: 0.8807 - accuracy: 0.1014
on_train_batch_begin: 1598509199.564464s

44 step training time: 0.141655s

on_train_batch_end: 1598509199.706580s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.8783 - accuracy: 0.1014
on_train_batch_begin: 1598509199.706861s

45 step training time: 0.142397s

on_train_batch_end: 1598509199.847424s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.8793 - accuracy: 0.1014
on_train_batch_begin: 1598509199.847709s

46 step training time: 0.140848s

on_train_batch_end: 1598509199.988828s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.8792 - accuracy: 0.1014
on_train_batch_begin: 1598509199.989114s

47 step training time: 0.141405s

on_train_batch_end: 1598509200.130813s

49152/50000 [============================>.] - ETA: 0s - loss: 0.8784 - accuracy: 0.1014
on_train_batch_begin: 1598509200.131114s

48 step training time: 0.142000s

on_train_batch_end: 1598509200.257266s

on_test_batch_begin: 1598509200.288128s

49 step training time: 0.157014s

on_epoch_end: 1598509200.612157s

Validation time: 0.324017s

Real time: 1598509200.612157s

Epoch time: 7.203471660614014s

50000/50000 [==============================] - 7s 144us/sample - loss: 0.8754 - accuracy: 0.1014 - val_loss: 6.7283 - val_accuracy: 0.1001
Tempo do fit: 93.13703966140747