wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:08
   139264/170498071 [..............................] - ETA: 1:30
   499712/170498071 [..............................] - ETA: 42s 
  1761280/170498071 [..............................] - ETA: 16s
  3776512/170498071 [..............................] - ETA: 9s 
  5595136/170498071 [..............................] - ETA: 8s
  7593984/170498071 [>.............................] - ETA: 6s
  9478144/170498071 [>.............................] - ETA: 6s
 11264000/170498071 [>.............................] - ETA: 6s
 13262848/170498071 [=>............................] - ETA: 5s
 15147008/170498071 [=>............................] - ETA: 5s
 16998400/170498071 [=>............................] - ETA: 5s
 18972672/170498071 [==>...........................] - ETA: 5s
 20832256/170498071 [==>...........................] - ETA: 4s
 22700032/170498071 [==>...........................] - ETA: 4s
 24649728/170498071 [===>..........................] - ETA: 4s
 26599424/170498071 [===>..........................] - ETA: 4s
 28475392/170498071 [====>.........................] - ETA: 4s
 30351360/170498071 [====>.........................] - ETA: 4s
 32661504/170498071 [====>.........................] - ETA: 4s
 35528704/170498071 [=====>........................] - ETA: 3s
 38690816/170498071 [=====>........................] - ETA: 3s
 41844736/170498071 [======>.......................] - ETA: 3s
 45080576/170498071 [======>.......................] - ETA: 3s
 48340992/170498071 [=======>......................] - ETA: 3s
 51535872/170498071 [========>.....................] - ETA: 2s
 54779904/170498071 [========>.....................] - ETA: 2s
 58056704/170498071 [=========>....................] - ETA: 2s
 61349888/170498071 [=========>....................] - ETA: 2s
 64610304/170498071 [==========>...................] - ETA: 2s
 67837952/170498071 [==========>...................] - ETA: 2s
 71081984/170498071 [===========>..................] - ETA: 2s
 74375168/170498071 [============>.................] - ETA: 2s
 77684736/170498071 [============>.................] - ETA: 2s
 80945152/170498071 [=============>................] - ETA: 1s
 84189184/170498071 [=============>................] - ETA: 1s
 87384064/170498071 [==============>...............] - ETA: 1s
 90578944/170498071 [==============>...............] - ETA: 1s
 93773824/170498071 [===============>..............] - ETA: 1s
 97083392/170498071 [================>.............] - ETA: 1s
100376576/170498071 [================>.............] - ETA: 1s
103268352/170498071 [=================>............] - ETA: 1s
107601920/170498071 [=================>............] - ETA: 1s
110813184/170498071 [==================>...........] - ETA: 1s
114057216/170498071 [===================>..........] - ETA: 1s
117268480/170498071 [===================>..........] - ETA: 1s
120578048/170498071 [====================>.........] - ETA: 0s
123789312/170498071 [====================>.........] - ETA: 0s
127016960/170498071 [=====================>........] - ETA: 0s
130342912/170498071 [=====================>........] - ETA: 0s
133586944/170498071 [======================>.......] - ETA: 0s
136863744/170498071 [=======================>......] - ETA: 0s
140156928/170498071 [=======================>......] - ETA: 0s
143417344/170498071 [========================>.....] - ETA: 0s
146710528/170498071 [========================>.....] - ETA: 0s
149921792/170498071 [=========================>....] - ETA: 0s
153165824/170498071 [=========================>....] - ETA: 0s
156360704/170498071 [==========================>...] - ETA: 0s
159604736/170498071 [===========================>..] - ETA: 0s
162791424/170498071 [===========================>..] - ETA: 0s
166076416/170498071 [============================>.] - ETA: 0s
169304064/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 7536640/94765736 [=>............................] - ETA: 0s
 9781248/94765736 [==>...........................] - ETA: 0s
12828672/94765736 [===>..........................] - ETA: 1s
15294464/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
20021248/94765736 [=====>........................] - ETA: 1s
27279360/94765736 [=======>......................] - ETA: 1s
30195712/94765736 [========>.....................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
43769856/94765736 [============>.................] - ETA: 0s
45957120/94765736 [=============>................] - ETA: 0s
52985856/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
60071936/94765736 [==================>...........] - ETA: 0s
62439424/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
74022912/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
83107840/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.393386125564575
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598497191.903253s

Real time: 1598497191.903269
Epoch 1/5

on_train_batch_begin: 1598497192.651314s

on_train_batch_end: 1598497209.554864s

 1024/50000 [..............................] - ETA: 14:04 - loss: 17.6824 - accuracy: 9.0599e-05
on_train_batch_begin: 1598497209.555461s

1 step training time: 16.904148s

on_train_batch_end: 1598497209.891112s

 2048/50000 [>.............................] - ETA: 7:01 - loss: 13.6369 - accuracy: 2.7895e-04 
on_train_batch_begin: 1598497209.891443s

2 step training time: 0.335982s

on_train_batch_end: 1598497210.225241s

 3072/50000 [>.............................] - ETA: 4:39 - loss: 11.9390 - accuracy: 4.4505e-04
on_train_batch_begin: 1598497210.225532s

3 step training time: 0.334088s

on_train_batch_end: 1598497210.558155s

 4096/50000 [=>............................] - ETA: 3:29 - loss: 10.9472 - accuracy: 0.0015    
on_train_batch_begin: 1598497210.558420s

4 step training time: 0.332888s

on_train_batch_end: 1598497210.893536s

 5120/50000 [==>...........................] - ETA: 2:46 - loss: 10.3672 - accuracy: 0.0039
on_train_batch_begin: 1598497210.893810s

5 step training time: 0.335390s

on_train_batch_end: 1598497211.226414s

 6144/50000 [==>...........................] - ETA: 2:17 - loss: 9.9815 - accuracy: 0.0062 
on_train_batch_begin: 1598497211.226682s

6 step training time: 0.332872s

on_train_batch_end: 1598497211.562255s

 7168/50000 [===>..........................] - ETA: 1:57 - loss: 9.6628 - accuracy: 0.0099
on_train_batch_begin: 1598497211.562528s

7 step training time: 0.335846s

on_train_batch_end: 1598497211.900782s

 8192/50000 [===>..........................] - ETA: 1:42 - loss: 9.4264 - accuracy: 0.0127
on_train_batch_begin: 1598497211.901084s

8 step training time: 0.338556s

on_train_batch_end: 1598497212.234321s

 9216/50000 [====>.........................] - ETA: 1:29 - loss: 9.2029 - accuracy: 0.0173
on_train_batch_begin: 1598497212.234600s

9 step training time: 0.333516s

on_train_batch_end: 1598497212.568423s

10240/50000 [=====>........................] - ETA: 1:20 - loss: 9.0352 - accuracy: 0.0216
on_train_batch_begin: 1598497212.568713s

10 step training time: 0.334114s

on_train_batch_end: 1598497212.926289s

11264/50000 [=====>........................] - ETA: 1:12 - loss: 8.8892 - accuracy: 0.0248
on_train_batch_begin: 1598497212.926586s

11 step training time: 0.357873s

on_train_batch_end: 1598497213.257076s

12288/50000 [======>.......................] - ETA: 1:05 - loss: 8.7616 - accuracy: 0.0275
on_train_batch_begin: 1598497213.257374s

12 step training time: 0.330788s

on_train_batch_end: 1598497213.584232s

13312/50000 [======>.......................] - ETA: 59s - loss: 8.6523 - accuracy: 0.0298 
on_train_batch_begin: 1598497213.584512s

13 step training time: 0.327138s

on_train_batch_end: 1598497213.924421s

14336/50000 [=======>......................] - ETA: 54s - loss: 8.5452 - accuracy: 0.0313
on_train_batch_begin: 1598497213.924696s

14 step training time: 0.340184s

on_train_batch_end: 1598497214.258433s

15360/50000 [========>.....................] - ETA: 50s - loss: 8.4652 - accuracy: 0.0324
on_train_batch_begin: 1598497214.258693s

15 step training time: 0.333997s

on_train_batch_end: 1598497214.593808s

16384/50000 [========>.....................] - ETA: 46s - loss: 8.3773 - accuracy: 0.0342
on_train_batch_begin: 1598497214.594068s

16 step training time: 0.335375s

on_train_batch_end: 1598497214.930756s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.2860 - accuracy: 0.0353
on_train_batch_begin: 1598497214.930995s

17 step training time: 0.336926s

on_train_batch_end: 1598497215.266048s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.2070 - accuracy: 0.0367
on_train_batch_begin: 1598497215.266279s

18 step training time: 0.335284s

on_train_batch_end: 1598497215.598737s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.1293 - accuracy: 0.0381
on_train_batch_begin: 1598497215.598965s

19 step training time: 0.332686s

on_train_batch_end: 1598497215.935176s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.0628 - accuracy: 0.0392
on_train_batch_begin: 1598497215.935443s

20 step training time: 0.336478s

on_train_batch_end: 1598497216.272867s

21504/50000 [===========>..................] - ETA: 32s - loss: 7.9988 - accuracy: 0.0402
on_train_batch_begin: 1598497216.273104s

21 step training time: 0.337661s

on_train_batch_end: 1598497216.608391s

22528/50000 [============>.................] - ETA: 30s - loss: 7.9309 - accuracy: 0.0418
on_train_batch_begin: 1598497216.608645s

22 step training time: 0.335541s

on_train_batch_end: 1598497216.944884s

23552/50000 [=============>................] - ETA: 28s - loss: 7.8734 - accuracy: 0.0429
on_train_batch_begin: 1598497216.945151s

23 step training time: 0.336505s

on_train_batch_end: 1598497217.284243s

24576/50000 [=============>................] - ETA: 26s - loss: 7.8113 - accuracy: 0.0437
on_train_batch_begin: 1598497217.284499s

24 step training time: 0.339348s

on_train_batch_end: 1598497217.622335s

25600/50000 [==============>...............] - ETA: 24s - loss: 7.7498 - accuracy: 0.0448
on_train_batch_begin: 1598497217.622615s

25 step training time: 0.338116s

on_train_batch_end: 1598497217.956759s

26624/50000 [==============>...............] - ETA: 22s - loss: 7.6949 - accuracy: 0.0454
on_train_batch_begin: 1598497217.957056s

26 step training time: 0.334440s

on_train_batch_end: 1598497218.297010s

27648/50000 [===============>..............] - ETA: 21s - loss: 7.6429 - accuracy: 0.0462
on_train_batch_begin: 1598497218.297292s

27 step training time: 0.340237s

on_train_batch_end: 1598497218.633430s

28672/50000 [================>.............] - ETA: 19s - loss: 7.5897 - accuracy: 0.0466
on_train_batch_begin: 1598497218.633705s

28 step training time: 0.336413s

on_train_batch_end: 1598497218.971126s

29696/50000 [================>.............] - ETA: 18s - loss: 7.5301 - accuracy: 0.0475
on_train_batch_begin: 1598497218.971394s

29 step training time: 0.337689s

on_train_batch_end: 1598497219.308757s

30720/50000 [=================>............] - ETA: 17s - loss: 7.4775 - accuracy: 0.0482
on_train_batch_begin: 1598497219.309010s

30 step training time: 0.337616s

on_train_batch_end: 1598497219.646583s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.4200 - accuracy: 0.0493
on_train_batch_begin: 1598497219.646816s

31 step training time: 0.337806s

on_train_batch_end: 1598497219.986262s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.3640 - accuracy: 0.0501
on_train_batch_begin: 1598497219.986514s

32 step training time: 0.339698s

on_train_batch_end: 1598497220.323532s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.3131 - accuracy: 0.0507
on_train_batch_begin: 1598497220.323765s

33 step training time: 0.337251s

on_train_batch_end: 1598497220.661148s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.2656 - accuracy: 0.0512
on_train_batch_begin: 1598497220.661376s

34 step training time: 0.337611s

on_train_batch_end: 1598497221.003479s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.2166 - accuracy: 0.0518
on_train_batch_begin: 1598497221.003712s

35 step training time: 0.342336s

on_train_batch_end: 1598497221.343824s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.1666 - accuracy: 0.0523
on_train_batch_begin: 1598497221.344061s

36 step training time: 0.340349s

on_train_batch_end: 1598497221.680554s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.1221 - accuracy: 0.0526 
on_train_batch_begin: 1598497221.680832s

37 step training time: 0.336771s

on_train_batch_end: 1598497222.018647s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.0765 - accuracy: 0.0528
on_train_batch_begin: 1598497222.018937s

38 step training time: 0.338105s

on_train_batch_end: 1598497222.357635s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.0350 - accuracy: 0.0529
on_train_batch_begin: 1598497222.357914s

39 step training time: 0.338977s

on_train_batch_end: 1598497222.695577s

40960/50000 [=======================>......] - ETA: 6s - loss: 6.9892 - accuracy: 0.0533
on_train_batch_begin: 1598497222.695863s

40 step training time: 0.337948s

on_train_batch_end: 1598497223.037357s

41984/50000 [========================>.....] - ETA: 5s - loss: 6.9446 - accuracy: 0.0535
on_train_batch_begin: 1598497223.037647s

41 step training time: 0.341784s

on_train_batch_end: 1598497223.374578s

43008/50000 [========================>.....] - ETA: 5s - loss: 6.8992 - accuracy: 0.0538
on_train_batch_begin: 1598497223.374872s

42 step training time: 0.337225s

on_train_batch_end: 1598497223.713634s

44032/50000 [=========================>....] - ETA: 4s - loss: 6.8563 - accuracy: 0.0542
on_train_batch_begin: 1598497223.713909s

43 step training time: 0.339038s

on_train_batch_end: 1598497224.054433s

45056/50000 [==========================>...] - ETA: 3s - loss: 6.8169 - accuracy: 0.0547
on_train_batch_begin: 1598497224.054674s

44 step training time: 0.340765s

on_train_batch_end: 1598497224.395991s

46080/50000 [==========================>...] - ETA: 2s - loss: 6.7777 - accuracy: 0.0551
on_train_batch_begin: 1598497224.396213s

45 step training time: 0.341539s

on_train_batch_end: 1598497224.733852s

47104/50000 [===========================>..] - ETA: 2s - loss: 6.7408 - accuracy: 0.0554
on_train_batch_begin: 1598497224.734103s

46 step training time: 0.337890s

on_train_batch_end: 1598497225.076168s

48128/50000 [===========================>..] - ETA: 1s - loss: 6.7009 - accuracy: 0.0559
on_train_batch_begin: 1598497225.076427s

47 step training time: 0.342324s

on_train_batch_end: 1598497225.417732s

49152/50000 [============================>.] - ETA: 0s - loss: 6.6627 - accuracy: 0.0563
on_train_batch_begin: 1598497225.417961s

48 step training time: 0.341534s

on_train_batch_end: 1598497231.635246s

on_test_batch_begin: 1598497231.822483s

49 step training time: 6.404522s

on_epoch_end: 1598497236.577603s

Validation time: 4.755105s

Real time: 1598497236.577603s

Epoch time: 44.67435050010681s

50000/50000 [==============================] - 45s 893us/sample - loss: 6.6273 - accuracy: 0.0567 - val_loss: 24.9981 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598497236.577816s

Real time: 1598497236.5778222
Epoch 2/5

on_train_batch_begin: 1598497236.581335s

on_train_batch_end: 1598497236.930934s

 1024/50000 [..............................] - ETA: 16s - loss: 4.6262 - accuracy: 0.0745
on_train_batch_begin: 1598497236.931167s

1 step training time: 0.349832s

on_train_batch_end: 1598497237.273687s

 2048/50000 [>.............................] - ETA: 16s - loss: 4.5486 - accuracy: 0.0797
on_train_batch_begin: 1598497237.273924s

2 step training time: 0.342757s

on_train_batch_end: 1598497237.618502s

 3072/50000 [>.............................] - ETA: 15s - loss: 4.6380 - accuracy: 0.0773
on_train_batch_begin: 1598497237.618723s

3 step training time: 0.344799s

on_train_batch_end: 1598497237.970336s

 4096/50000 [=>............................] - ETA: 15s - loss: 4.6302 - accuracy: 0.0776
on_train_batch_begin: 1598497237.970582s

4 step training time: 0.351859s

on_train_batch_end: 1598497238.316133s

 5120/50000 [==>...........................] - ETA: 15s - loss: 4.6252 - accuracy: 0.0779
on_train_batch_begin: 1598497238.316397s

5 step training time: 0.345815s

on_train_batch_end: 1598497238.660759s

 6144/50000 [==>...........................] - ETA: 14s - loss: 4.6311 - accuracy: 0.0798
on_train_batch_begin: 1598497238.661020s

6 step training time: 0.344623s

on_train_batch_end: 1598497239.008466s

 7168/50000 [===>..........................] - ETA: 14s - loss: 4.6393 - accuracy: 0.0800
on_train_batch_begin: 1598497239.008741s

7 step training time: 0.347720s

on_train_batch_end: 1598497239.352538s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.6144 - accuracy: 0.0809
on_train_batch_begin: 1598497239.352827s

8 step training time: 0.344087s

on_train_batch_end: 1598497239.695610s

 9216/50000 [====>.........................] - ETA: 13s - loss: 4.6125 - accuracy: 0.0807
on_train_batch_begin: 1598497239.695890s

9 step training time: 0.343063s

on_train_batch_end: 1598497240.042501s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.6224 - accuracy: 0.0798
on_train_batch_begin: 1598497240.042788s

10 step training time: 0.346898s

on_train_batch_end: 1598497240.387790s

11264/50000 [=====>........................] - ETA: 13s - loss: 4.6187 - accuracy: 0.0788
on_train_batch_begin: 1598497240.388046s

11 step training time: 0.345258s

on_train_batch_end: 1598497240.737246s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.6065 - accuracy: 0.0779
on_train_batch_begin: 1598497240.737502s

12 step training time: 0.349455s

on_train_batch_end: 1598497241.080887s

13312/50000 [======>.......................] - ETA: 12s - loss: 4.5753 - accuracy: 0.0774
on_train_batch_begin: 1598497241.081139s

13 step training time: 0.343637s

on_train_batch_end: 1598497241.425989s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.5435 - accuracy: 0.0770
on_train_batch_begin: 1598497241.426226s

14 step training time: 0.345087s

on_train_batch_end: 1598497241.771771s

15360/50000 [========>.....................] - ETA: 11s - loss: 4.5153 - accuracy: 0.0767
on_train_batch_begin: 1598497241.772061s

15 step training time: 0.345835s

on_train_batch_end: 1598497242.116541s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.4904 - accuracy: 0.0764
on_train_batch_begin: 1598497242.116838s

16 step training time: 0.344778s

on_train_batch_end: 1598497242.461876s

17408/50000 [=========>....................] - ETA: 11s - loss: 4.4482 - accuracy: 0.0764
on_train_batch_begin: 1598497242.462124s

17 step training time: 0.345285s

on_train_batch_end: 1598497242.810041s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.4247 - accuracy: 0.0764
on_train_batch_begin: 1598497242.810338s

18 step training time: 0.348215s

on_train_batch_end: 1598497243.159840s

19456/50000 [==========>...................] - ETA: 10s - loss: 4.3932 - accuracy: 0.0765
on_train_batch_begin: 1598497243.160115s

19 step training time: 0.349776s

on_train_batch_end: 1598497243.508005s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.3697 - accuracy: 0.0765 
on_train_batch_begin: 1598497243.508282s

20 step training time: 0.348167s

on_train_batch_end: 1598497243.859526s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.3364 - accuracy: 0.0768
on_train_batch_begin: 1598497243.859802s

21 step training time: 0.351520s

on_train_batch_end: 1598497244.205529s

22528/50000 [============>.................] - ETA: 9s - loss: 4.3136 - accuracy: 0.0770
on_train_batch_begin: 1598497244.205781s

22 step training time: 0.345979s

on_train_batch_end: 1598497244.551735s

23552/50000 [=============>................] - ETA: 8s - loss: 4.2877 - accuracy: 0.0772
on_train_batch_begin: 1598497244.551961s

23 step training time: 0.346180s

on_train_batch_end: 1598497244.898622s

24576/50000 [=============>................] - ETA: 8s - loss: 4.2666 - accuracy: 0.0773
on_train_batch_begin: 1598497244.898855s

24 step training time: 0.346894s

on_train_batch_end: 1598497245.249734s

25600/50000 [==============>...............] - ETA: 8s - loss: 4.2415 - accuracy: 0.0776
on_train_batch_begin: 1598497245.249982s

25 step training time: 0.351127s

on_train_batch_end: 1598497245.599701s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.2118 - accuracy: 0.0779
on_train_batch_begin: 1598497245.599939s

26 step training time: 0.349957s

on_train_batch_end: 1598497245.950550s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.1951 - accuracy: 0.0782
on_train_batch_begin: 1598497245.950779s

27 step training time: 0.350840s

on_train_batch_end: 1598497246.300086s

28672/50000 [================>.............] - ETA: 7s - loss: 4.1674 - accuracy: 0.0784
on_train_batch_begin: 1598497246.300303s

28 step training time: 0.349524s

on_train_batch_end: 1598497246.649968s

29696/50000 [================>.............] - ETA: 6s - loss: 4.1381 - accuracy: 0.0789
on_train_batch_begin: 1598497246.650205s

29 step training time: 0.349902s

on_train_batch_end: 1598497247.001320s

30720/50000 [=================>............] - ETA: 6s - loss: 4.1134 - accuracy: 0.0792
on_train_batch_begin: 1598497247.001561s

30 step training time: 0.351356s

on_train_batch_end: 1598497247.351350s

31744/50000 [==================>...........] - ETA: 6s - loss: 4.0868 - accuracy: 0.0796
on_train_batch_begin: 1598497247.351586s

31 step training time: 0.350025s

on_train_batch_end: 1598497247.698370s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.0633 - accuracy: 0.0800
on_train_batch_begin: 1598497247.698622s

32 step training time: 0.347036s

on_train_batch_end: 1598497248.047463s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.0406 - accuracy: 0.0804
on_train_batch_begin: 1598497248.047750s

33 step training time: 0.349128s

on_train_batch_end: 1598497248.399159s

34816/50000 [===================>..........] - ETA: 5s - loss: 4.0117 - accuracy: 0.0808
on_train_batch_begin: 1598497248.399441s

34 step training time: 0.351691s

on_train_batch_end: 1598497248.752311s

35840/50000 [====================>.........] - ETA: 4s - loss: 3.9822 - accuracy: 0.0811
on_train_batch_begin: 1598497248.752566s

35 step training time: 0.353125s

on_train_batch_end: 1598497249.103826s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.9548 - accuracy: 0.0815
on_train_batch_begin: 1598497249.104065s

36 step training time: 0.351499s

on_train_batch_end: 1598497249.433642s

37888/50000 [=====================>........] - ETA: 4s - loss: 3.9289 - accuracy: 0.0818
on_train_batch_begin: 1598497249.433890s

37 step training time: 0.329824s

on_train_batch_end: 1598497249.787600s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.9010 - accuracy: 0.0822
on_train_batch_begin: 1598497249.787852s

38 step training time: 0.353962s

on_train_batch_end: 1598497250.137883s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.8770 - accuracy: 0.0825
on_train_batch_begin: 1598497250.138147s

39 step training time: 0.350295s

on_train_batch_end: 1598497250.485996s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.8574 - accuracy: 0.0828
on_train_batch_begin: 1598497250.486259s

40 step training time: 0.348112s

on_train_batch_end: 1598497250.837322s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.8357 - accuracy: 0.0831
on_train_batch_begin: 1598497250.837578s

41 step training time: 0.351320s

on_train_batch_end: 1598497251.189698s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.8143 - accuracy: 0.0835
on_train_batch_begin: 1598497251.189959s

42 step training time: 0.352380s

on_train_batch_end: 1598497251.539254s

44032/50000 [=========================>....] - ETA: 2s - loss: 3.7937 - accuracy: 0.0838
on_train_batch_begin: 1598497251.539488s

43 step training time: 0.349530s

on_train_batch_end: 1598497251.891443s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.7749 - accuracy: 0.0841
on_train_batch_begin: 1598497251.891757s

44 step training time: 0.352269s

on_train_batch_end: 1598497252.245963s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.7565 - accuracy: 0.0845
on_train_batch_begin: 1598497252.246230s

45 step training time: 0.354473s

on_train_batch_end: 1598497252.600364s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.7402 - accuracy: 0.0847
on_train_batch_begin: 1598497252.600599s

46 step training time: 0.354368s

on_train_batch_end: 1598497252.952074s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.7194 - accuracy: 0.0850
on_train_batch_begin: 1598497252.952368s

47 step training time: 0.351769s

on_train_batch_end: 1598497253.307063s

49152/50000 [============================>.] - ETA: 0s - loss: 3.7025 - accuracy: 0.0853
on_train_batch_begin: 1598497253.307343s

48 step training time: 0.354975s

on_train_batch_end: 1598497253.602588s

on_test_batch_begin: 1598497253.617313s

49 step training time: 0.309969s

on_epoch_end: 1598497254.433354s

Validation time: 0.816031s

Real time: 1598497254.433354s

Epoch time: 17.855546712875366s

50000/50000 [==============================] - 18s 357us/sample - loss: 3.6897 - accuracy: 0.0855 - val_loss: 6.9117 - val_accuracy: 0.1000

on_epoch_begin: 1598497254.433537s

Real time: 1598497254.4335423
Epoch 3/5

on_train_batch_begin: 1598497254.436822s

on_train_batch_end: 1598497254.788350s

 1024/50000 [..............................] - ETA: 16s - loss: 2.8460 - accuracy: 0.0979
on_train_batch_begin: 1598497254.788616s

1 step training time: 0.351795s

on_train_batch_end: 1598497255.138426s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.8777 - accuracy: 0.0973
on_train_batch_begin: 1598497255.138666s

2 step training time: 0.350049s

on_train_batch_end: 1598497255.491484s

 3072/50000 [>.............................] - ETA: 16s - loss: 2.8176 - accuracy: 0.0987
on_train_batch_begin: 1598497255.491704s

3 step training time: 0.353039s

on_train_batch_end: 1598497255.846605s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.7989 - accuracy: 0.0982
on_train_batch_begin: 1598497255.846828s

4 step training time: 0.355124s

on_train_batch_end: 1598497256.198270s

 5120/50000 [==>...........................] - ETA: 15s - loss: 2.8012 - accuracy: 0.0980
on_train_batch_begin: 1598497256.198506s

5 step training time: 0.351678s

on_train_batch_end: 1598497256.554781s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.7979 - accuracy: 0.0979
on_train_batch_begin: 1598497256.555014s

6 step training time: 0.356508s

on_train_batch_end: 1598497256.910070s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.7662 - accuracy: 0.0981
on_train_batch_begin: 1598497256.910301s

7 step training time: 0.355287s

on_train_batch_end: 1598497257.261385s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.7612 - accuracy: 0.0984
on_train_batch_begin: 1598497257.261608s

8 step training time: 0.351306s

on_train_batch_end: 1598497257.615904s

 9216/50000 [====>.........................] - ETA: 14s - loss: 2.7548 - accuracy: 0.0985
on_train_batch_begin: 1598497257.616132s

9 step training time: 0.354524s

on_train_batch_end: 1598497257.969506s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.7123 - accuracy: 0.0987
on_train_batch_begin: 1598497257.969781s

10 step training time: 0.353650s

on_train_batch_end: 1598497258.326045s

11264/50000 [=====>........................] - ETA: 13s - loss: 2.6971 - accuracy: 0.0988
on_train_batch_begin: 1598497258.326281s

11 step training time: 0.356500s

on_train_batch_end: 1598497258.680379s

12288/50000 [======>.......................] - ETA: 13s - loss: 2.6804 - accuracy: 0.0989
on_train_batch_begin: 1598497258.680668s

12 step training time: 0.354387s

on_train_batch_end: 1598497259.036391s

13312/50000 [======>.......................] - ETA: 12s - loss: 2.6679 - accuracy: 0.0991
on_train_batch_begin: 1598497259.036666s

13 step training time: 0.355998s

on_train_batch_end: 1598497259.393141s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.6733 - accuracy: 0.0991
on_train_batch_begin: 1598497259.393393s

14 step training time: 0.356727s

on_train_batch_end: 1598497259.750686s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.6591 - accuracy: 0.0991
on_train_batch_begin: 1598497259.750937s

15 step training time: 0.357544s

on_train_batch_end: 1598497260.108662s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.6416 - accuracy: 0.0992
on_train_batch_begin: 1598497260.108939s

16 step training time: 0.358002s

on_train_batch_end: 1598497260.463688s

17408/50000 [=========>....................] - ETA: 11s - loss: 2.6498 - accuracy: 0.0990
on_train_batch_begin: 1598497260.463941s

17 step training time: 0.355002s

on_train_batch_end: 1598497260.821085s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.6401 - accuracy: 0.0991
on_train_batch_begin: 1598497260.821330s

18 step training time: 0.357388s

on_train_batch_end: 1598497261.175018s

19456/50000 [==========>...................] - ETA: 10s - loss: 2.6347 - accuracy: 0.0991
on_train_batch_begin: 1598497261.175317s

19 step training time: 0.353987s

on_train_batch_end: 1598497261.531932s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.6297 - accuracy: 0.0991
on_train_batch_begin: 1598497261.532217s

20 step training time: 0.356900s

on_train_batch_end: 1598497261.887350s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.6229 - accuracy: 0.0991 
on_train_batch_begin: 1598497261.887665s

21 step training time: 0.355448s

on_train_batch_end: 1598497262.245007s

22528/50000 [============>.................] - ETA: 9s - loss: 2.6147 - accuracy: 0.0991
on_train_batch_begin: 1598497262.245282s

22 step training time: 0.357617s

on_train_batch_end: 1598497262.600929s

23552/50000 [=============>................] - ETA: 9s - loss: 2.6011 - accuracy: 0.0992
on_train_batch_begin: 1598497262.601187s

23 step training time: 0.355905s

on_train_batch_end: 1598497262.958028s

24576/50000 [=============>................] - ETA: 8s - loss: 2.5858 - accuracy: 0.0992
on_train_batch_begin: 1598497262.958331s

24 step training time: 0.357144s

on_train_batch_end: 1598497263.314268s

25600/50000 [==============>...............] - ETA: 8s - loss: 2.5756 - accuracy: 0.0993
on_train_batch_begin: 1598497263.314551s

25 step training time: 0.356220s

on_train_batch_end: 1598497263.670985s

26624/50000 [==============>...............] - ETA: 8s - loss: 2.5629 - accuracy: 0.0994
on_train_batch_begin: 1598497263.671273s

26 step training time: 0.356722s

on_train_batch_end: 1598497264.030171s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.5580 - accuracy: 0.0994
on_train_batch_begin: 1598497264.030439s

27 step training time: 0.359166s

on_train_batch_end: 1598497264.384836s

28672/50000 [================>.............] - ETA: 7s - loss: 2.5422 - accuracy: 0.0994
on_train_batch_begin: 1598497264.385065s

28 step training time: 0.354626s

on_train_batch_end: 1598497264.742588s

29696/50000 [================>.............] - ETA: 7s - loss: 2.5311 - accuracy: 0.0994
on_train_batch_begin: 1598497264.742823s

29 step training time: 0.357757s

on_train_batch_end: 1598497265.100516s

30720/50000 [=================>............] - ETA: 6s - loss: 2.5220 - accuracy: 0.0994
on_train_batch_begin: 1598497265.100745s

30 step training time: 0.357922s

on_train_batch_end: 1598497265.455607s

31744/50000 [==================>...........] - ETA: 6s - loss: 2.5091 - accuracy: 0.0995
on_train_batch_begin: 1598497265.455853s

31 step training time: 0.355108s

on_train_batch_end: 1598497265.814279s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.5013 - accuracy: 0.0995
on_train_batch_begin: 1598497265.814576s

32 step training time: 0.358723s

on_train_batch_end: 1598497266.170671s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.4876 - accuracy: 0.0995
on_train_batch_begin: 1598497266.170929s

33 step training time: 0.356353s

on_train_batch_end: 1598497266.529515s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.4807 - accuracy: 0.0996
on_train_batch_begin: 1598497266.529749s

34 step training time: 0.358820s

on_train_batch_end: 1598497266.888102s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.4760 - accuracy: 0.0996
on_train_batch_begin: 1598497266.888329s

35 step training time: 0.358580s

on_train_batch_end: 1598497267.248649s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.4707 - accuracy: 0.0996
on_train_batch_begin: 1598497267.248918s

36 step training time: 0.360588s

on_train_batch_end: 1598497267.608444s

37888/50000 [=====================>........] - ETA: 4s - loss: 2.4730 - accuracy: 0.0996
on_train_batch_begin: 1598497267.608678s

37 step training time: 0.359760s

on_train_batch_end: 1598497267.966996s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.4676 - accuracy: 0.0996
on_train_batch_begin: 1598497267.967261s

38 step training time: 0.358583s

on_train_batch_end: 1598497268.324813s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.4670 - accuracy: 0.0996
on_train_batch_begin: 1598497268.325053s

39 step training time: 0.357792s

on_train_batch_end: 1598497268.684804s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.4589 - accuracy: 0.0996
on_train_batch_begin: 1598497268.685103s

40 step training time: 0.360050s

on_train_batch_end: 1598497269.044679s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.4562 - accuracy: 0.0997
on_train_batch_begin: 1598497269.044960s

41 step training time: 0.359857s

on_train_batch_end: 1598497269.402491s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.4555 - accuracy: 0.0997
on_train_batch_begin: 1598497269.402725s

42 step training time: 0.357765s

on_train_batch_end: 1598497269.762187s

44032/50000 [=========================>....] - ETA: 2s - loss: 2.4509 - accuracy: 0.0997
on_train_batch_begin: 1598497269.762451s

43 step training time: 0.359726s

on_train_batch_end: 1598497270.122073s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.4498 - accuracy: 0.0997
on_train_batch_begin: 1598497270.122316s

44 step training time: 0.359865s

on_train_batch_end: 1598497270.481056s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.4455 - accuracy: 0.0997
on_train_batch_begin: 1598497270.481300s

45 step training time: 0.358984s

on_train_batch_end: 1598497270.837979s

47104/50000 [===========================>..] - ETA: 1s - loss: 2.4411 - accuracy: 0.0997
on_train_batch_begin: 1598497270.838200s

46 step training time: 0.356900s

on_train_batch_end: 1598497271.200466s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.4397 - accuracy: 0.0997
on_train_batch_begin: 1598497271.200703s

47 step training time: 0.362503s

on_train_batch_end: 1598497271.558880s

49152/50000 [============================>.] - ETA: 0s - loss: 2.4401 - accuracy: 0.0997
on_train_batch_begin: 1598497271.559116s

48 step training time: 0.358413s

on_train_batch_end: 1598497271.853776s

on_test_batch_begin: 1598497271.863938s

49 step training time: 0.304822s

on_epoch_end: 1598497272.687430s

Validation time: 0.823482s

Real time: 1598497272.687430s

Epoch time: 18.253902912139893s

50000/50000 [==============================] - 18s 365us/sample - loss: 2.4392 - accuracy: 0.0997 - val_loss: 7.6351 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598497272.687634s

Real time: 1598497272.6876419
Epoch 4/5

on_train_batch_begin: 1598497272.690979s

on_train_batch_end: 1598497273.048096s

 1024/50000 [..............................] - ETA: 17s - loss: 2.3985 - accuracy: 0.0994
on_train_batch_begin: 1598497273.048392s

1 step training time: 0.357413s

on_train_batch_end: 1598497273.405361s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.3901 - accuracy: 0.0994
on_train_batch_begin: 1598497273.405608s

2 step training time: 0.357216s

on_train_batch_end: 1598497273.770923s

 3072/50000 [>.............................] - ETA: 16s - loss: 2.3491 - accuracy: 0.0998
on_train_batch_begin: 1598497273.771201s

3 step training time: 0.365593s

on_train_batch_end: 1598497274.131287s

 4096/50000 [=>............................] - ETA: 16s - loss: 2.2858 - accuracy: 0.0999
on_train_batch_begin: 1598497274.131539s

4 step training time: 0.360338s

on_train_batch_end: 1598497274.490098s

 5120/50000 [==>...........................] - ETA: 15s - loss: 2.2655 - accuracy: 0.0998
on_train_batch_begin: 1598497274.490352s

5 step training time: 0.358814s

on_train_batch_end: 1598497274.851464s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.2477 - accuracy: 0.0998
on_train_batch_begin: 1598497274.851703s

6 step training time: 0.361351s

on_train_batch_end: 1598497275.190767s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.2486 - accuracy: 0.0997
on_train_batch_begin: 1598497275.191014s

7 step training time: 0.339311s

on_train_batch_end: 1598497275.563571s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.2376 - accuracy: 0.0997
on_train_batch_begin: 1598497275.563805s

8 step training time: 0.372792s

on_train_batch_end: 1598497275.931948s

 9216/50000 [====>.........................] - ETA: 14s - loss: 2.2262 - accuracy: 0.0999
on_train_batch_begin: 1598497275.932175s

9 step training time: 0.368370s

on_train_batch_end: 1598497276.287083s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.1959 - accuracy: 0.1000
on_train_batch_begin: 1598497276.287333s

10 step training time: 0.355158s

on_train_batch_end: 1598497276.646511s

11264/50000 [=====>........................] - ETA: 13s - loss: 2.1821 - accuracy: 0.1000
on_train_batch_begin: 1598497276.646757s

11 step training time: 0.359424s

on_train_batch_end: 1598497277.009976s

12288/50000 [======>.......................] - ETA: 13s - loss: 2.1484 - accuracy: 0.1000
on_train_batch_begin: 1598497277.010223s

12 step training time: 0.363466s

on_train_batch_end: 1598497277.368197s

13312/50000 [======>.......................] - ETA: 12s - loss: 2.1448 - accuracy: 0.1000
on_train_batch_begin: 1598497277.368450s

13 step training time: 0.358227s

on_train_batch_end: 1598497277.731733s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.1348 - accuracy: 0.1000
on_train_batch_begin: 1598497277.731970s

14 step training time: 0.363520s

on_train_batch_end: 1598497278.094368s

15360/50000 [========>.....................] - ETA: 12s - loss: 2.1224 - accuracy: 0.1000
on_train_batch_begin: 1598497278.094623s

15 step training time: 0.362653s

on_train_batch_end: 1598497278.453138s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.1118 - accuracy: 0.1000
on_train_batch_begin: 1598497278.453377s

16 step training time: 0.358754s

on_train_batch_end: 1598497278.813800s

17408/50000 [=========>....................] - ETA: 11s - loss: 2.1040 - accuracy: 0.1000
on_train_batch_begin: 1598497278.814088s

17 step training time: 0.360711s

on_train_batch_end: 1598497279.177924s

18432/50000 [==========>...................] - ETA: 11s - loss: 2.0886 - accuracy: 0.1000
on_train_batch_begin: 1598497279.178203s

18 step training time: 0.364115s

on_train_batch_end: 1598497279.541481s

19456/50000 [==========>...................] - ETA: 10s - loss: 2.0777 - accuracy: 0.1000
on_train_batch_begin: 1598497279.541725s

19 step training time: 0.363522s

on_train_batch_end: 1598497279.903141s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.0664 - accuracy: 0.1000
on_train_batch_begin: 1598497279.903407s

20 step training time: 0.361682s

on_train_batch_end: 1598497280.265452s

21504/50000 [===========>..................] - ETA: 10s - loss: 2.0594 - accuracy: 0.1001
on_train_batch_begin: 1598497280.265723s

21 step training time: 0.362317s

on_train_batch_end: 1598497280.625695s

22528/50000 [============>.................] - ETA: 9s - loss: 2.0533 - accuracy: 0.1001 
on_train_batch_begin: 1598497280.625946s

22 step training time: 0.360223s

on_train_batch_end: 1598497280.989403s

23552/50000 [=============>................] - ETA: 9s - loss: 2.0414 - accuracy: 0.1001
on_train_batch_begin: 1598497280.989658s

23 step training time: 0.363712s

on_train_batch_end: 1598497281.353120s

24576/50000 [=============>................] - ETA: 8s - loss: 2.0357 - accuracy: 0.1000
on_train_batch_begin: 1598497281.353384s

24 step training time: 0.363726s

on_train_batch_end: 1598497281.715879s

25600/50000 [==============>...............] - ETA: 8s - loss: 2.0310 - accuracy: 0.1001
on_train_batch_begin: 1598497281.716140s

25 step training time: 0.362756s

on_train_batch_end: 1598497282.080506s

26624/50000 [==============>...............] - ETA: 8s - loss: 2.0206 - accuracy: 0.1000
on_train_batch_begin: 1598497282.080840s

26 step training time: 0.364700s

on_train_batch_end: 1598497282.445070s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.0170 - accuracy: 0.1001
on_train_batch_begin: 1598497282.445359s

27 step training time: 0.364519s

on_train_batch_end: 1598497282.807491s

28672/50000 [================>.............] - ETA: 7s - loss: 2.0060 - accuracy: 0.1001
on_train_batch_begin: 1598497282.807820s

28 step training time: 0.362461s

on_train_batch_end: 1598497283.170176s

29696/50000 [================>.............] - ETA: 7s - loss: 1.9928 - accuracy: 0.1001
on_train_batch_begin: 1598497283.170468s

29 step training time: 0.362648s

on_train_batch_end: 1598497283.532362s

30720/50000 [=================>............] - ETA: 6s - loss: 1.9800 - accuracy: 0.1001
on_train_batch_begin: 1598497283.532622s

30 step training time: 0.362154s

on_train_batch_end: 1598497283.898842s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.9728 - accuracy: 0.1001
on_train_batch_begin: 1598497283.899131s

31 step training time: 0.366509s

on_train_batch_end: 1598497284.263992s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.9658 - accuracy: 0.1001
on_train_batch_begin: 1598497284.264258s

32 step training time: 0.365127s

on_train_batch_end: 1598497284.629999s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.9590 - accuracy: 0.1001
on_train_batch_begin: 1598497284.630257s

33 step training time: 0.365999s

on_train_batch_end: 1598497284.993903s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.9561 - accuracy: 0.1001
on_train_batch_begin: 1598497284.994170s

34 step training time: 0.363913s

on_train_batch_end: 1598497285.357387s

35840/50000 [====================>.........] - ETA: 5s - loss: 1.9455 - accuracy: 0.1001
on_train_batch_begin: 1598497285.357642s

35 step training time: 0.363472s

on_train_batch_end: 1598497285.719503s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.9434 - accuracy: 0.1001
on_train_batch_begin: 1598497285.719730s

36 step training time: 0.362088s

on_train_batch_end: 1598497286.084211s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.9384 - accuracy: 0.1001
on_train_batch_begin: 1598497286.084435s

37 step training time: 0.364704s

on_train_batch_end: 1598497286.446620s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.9301 - accuracy: 0.1001
on_train_batch_begin: 1598497286.446847s

38 step training time: 0.362412s

on_train_batch_end: 1598497286.810489s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.9220 - accuracy: 0.1001
on_train_batch_begin: 1598497286.810737s

39 step training time: 0.363890s

on_train_batch_end: 1598497287.175221s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.9165 - accuracy: 0.1001
on_train_batch_begin: 1598497287.175467s

40 step training time: 0.364730s

on_train_batch_end: 1598497287.537388s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.9104 - accuracy: 0.1001
on_train_batch_begin: 1598497287.537629s

41 step training time: 0.362162s

on_train_batch_end: 1598497287.904086s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.9038 - accuracy: 0.1001
on_train_batch_begin: 1598497287.904317s

42 step training time: 0.366688s

on_train_batch_end: 1598497288.271718s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.8985 - accuracy: 0.1001
on_train_batch_begin: 1598497288.271961s

43 step training time: 0.367645s

on_train_batch_end: 1598497288.637803s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8932 - accuracy: 0.1001
on_train_batch_begin: 1598497288.638071s

44 step training time: 0.366109s

on_train_batch_end: 1598497289.001206s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.8896 - accuracy: 0.1001
on_train_batch_begin: 1598497289.001470s

45 step training time: 0.363399s

on_train_batch_end: 1598497289.368937s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.8809 - accuracy: 0.1001
on_train_batch_begin: 1598497289.369180s

46 step training time: 0.367710s

on_train_batch_end: 1598497289.736339s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.8741 - accuracy: 0.1001
on_train_batch_begin: 1598497289.736579s

47 step training time: 0.367399s

on_train_batch_end: 1598497290.098276s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8689 - accuracy: 0.1001
on_train_batch_begin: 1598497290.098522s

48 step training time: 0.361943s

on_train_batch_end: 1598497290.400265s

on_test_batch_begin: 1598497290.411600s

49 step training time: 0.313077s

on_epoch_end: 1598497291.249322s

Validation time: 0.837713s

Real time: 1598497291.249322s

Epoch time: 18.561694383621216s

50000/50000 [==============================] - 19s 371us/sample - loss: 1.8621 - accuracy: 0.1001 - val_loss: 7.1543 - val_accuracy: 0.0999

on_epoch_begin: 1598497291.249503s

Real time: 1598497291.2495081
Epoch 5/5

on_train_batch_begin: 1598497291.252811s

on_train_batch_end: 1598497291.614458s

 1024/50000 [..............................] - ETA: 17s - loss: 1.2841 - accuracy: 0.1006
on_train_batch_begin: 1598497291.614668s

1 step training time: 0.361857s

on_train_batch_end: 1598497291.976470s

 2048/50000 [>.............................] - ETA: 17s - loss: 1.4119 - accuracy: 0.1002
on_train_batch_begin: 1598497291.976757s

2 step training time: 0.362089s

on_train_batch_end: 1598497292.348660s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.3767 - accuracy: 0.1002
on_train_batch_begin: 1598497292.348925s

3 step training time: 0.372168s

on_train_batch_end: 1598497292.711874s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.3571 - accuracy: 0.1001
on_train_batch_begin: 1598497292.712144s

4 step training time: 0.363219s

on_train_batch_end: 1598497293.079095s

 5120/50000 [==>...........................] - ETA: 16s - loss: 1.3772 - accuracy: 0.1001
on_train_batch_begin: 1598497293.079382s

5 step training time: 0.367238s

on_train_batch_end: 1598497293.449065s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.3972 - accuracy: 0.1001
on_train_batch_begin: 1598497293.449328s

6 step training time: 0.369946s

on_train_batch_end: 1598497293.816178s

 7168/50000 [===>..........................] - ETA: 15s - loss: 1.3782 - accuracy: 0.1001
on_train_batch_begin: 1598497293.816453s

7 step training time: 0.367125s

on_train_batch_end: 1598497294.183541s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.3689 - accuracy: 0.1002
on_train_batch_begin: 1598497294.183793s

8 step training time: 0.367340s

on_train_batch_end: 1598497294.548585s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.3587 - accuracy: 0.1002
on_train_batch_begin: 1598497294.548840s

9 step training time: 0.365047s

on_train_batch_end: 1598497294.915350s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.3785 - accuracy: 0.1002
on_train_batch_begin: 1598497294.915590s

10 step training time: 0.366750s

on_train_batch_end: 1598497295.283663s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.3983 - accuracy: 0.1002
on_train_batch_begin: 1598497295.283904s

11 step training time: 0.368314s

on_train_batch_end: 1598497295.648931s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.3953 - accuracy: 0.1002
on_train_batch_begin: 1598497295.649174s

12 step training time: 0.365270s

on_train_batch_end: 1598497296.013538s

13312/50000 [======>.......................] - ETA: 13s - loss: 1.3863 - accuracy: 0.1002
on_train_batch_begin: 1598497296.013841s

13 step training time: 0.364666s

on_train_batch_end: 1598497296.383022s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.3795 - accuracy: 0.1002
on_train_batch_begin: 1598497296.383286s

14 step training time: 0.369445s

on_train_batch_end: 1598497296.752417s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.3726 - accuracy: 0.1002
on_train_batch_begin: 1598497296.752642s

15 step training time: 0.369357s

on_train_batch_end: 1598497297.123086s

16384/50000 [========>.....................] - ETA: 12s - loss: 1.3665 - accuracy: 0.1002
on_train_batch_begin: 1598497297.123330s

16 step training time: 0.370687s

on_train_batch_end: 1598497297.491533s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.3630 - accuracy: 0.1002
on_train_batch_begin: 1598497297.491777s

17 step training time: 0.368447s

on_train_batch_end: 1598497297.857767s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.3656 - accuracy: 0.1002
on_train_batch_begin: 1598497297.858005s

18 step training time: 0.366227s

on_train_batch_end: 1598497298.226843s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.3519 - accuracy: 0.1002
on_train_batch_begin: 1598497298.227087s

19 step training time: 0.369083s

on_train_batch_end: 1598497298.594608s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.3537 - accuracy: 0.1002
on_train_batch_begin: 1598497298.594847s

20 step training time: 0.367760s

on_train_batch_end: 1598497298.966632s

21504/50000 [===========>..................] - ETA: 10s - loss: 1.3462 - accuracy: 0.1003
on_train_batch_begin: 1598497298.966905s

21 step training time: 0.372058s

on_train_batch_end: 1598497299.334014s

22528/50000 [============>.................] - ETA: 9s - loss: 1.3481 - accuracy: 0.1003 
on_train_batch_begin: 1598497299.334272s

22 step training time: 0.367367s

on_train_batch_end: 1598497299.702697s

23552/50000 [=============>................] - ETA: 9s - loss: 1.3476 - accuracy: 0.1003
on_train_batch_begin: 1598497299.702972s

23 step training time: 0.368700s

on_train_batch_end: 1598497300.072659s

24576/50000 [=============>................] - ETA: 9s - loss: 1.3472 - accuracy: 0.1003
on_train_batch_begin: 1598497300.072930s

24 step training time: 0.369958s

on_train_batch_end: 1598497300.440401s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.3430 - accuracy: 0.1003
on_train_batch_begin: 1598497300.440632s

25 step training time: 0.367702s

on_train_batch_end: 1598497300.808951s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.3404 - accuracy: 0.1002
on_train_batch_begin: 1598497300.809175s

26 step training time: 0.368543s

on_train_batch_end: 1598497301.182324s

27648/50000 [===============>..............] - ETA: 8s - loss: 1.3359 - accuracy: 0.1002
on_train_batch_begin: 1598497301.182565s

27 step training time: 0.373390s

on_train_batch_end: 1598497301.552277s

28672/50000 [================>.............] - ETA: 7s - loss: 1.3288 - accuracy: 0.1002
on_train_batch_begin: 1598497301.552506s

28 step training time: 0.369941s

on_train_batch_end: 1598497301.921611s

29696/50000 [================>.............] - ETA: 7s - loss: 1.3227 - accuracy: 0.1002
on_train_batch_begin: 1598497301.921910s

29 step training time: 0.369403s

on_train_batch_end: 1598497302.296435s

30720/50000 [=================>............] - ETA: 6s - loss: 1.3216 - accuracy: 0.1002
on_train_batch_begin: 1598497302.296693s

30 step training time: 0.374784s

on_train_batch_end: 1598497302.664114s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.3148 - accuracy: 0.1002
on_train_batch_begin: 1598497302.664350s

31 step training time: 0.367657s

on_train_batch_end: 1598497303.031856s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.3128 - accuracy: 0.1002
on_train_batch_begin: 1598497303.032149s

32 step training time: 0.367799s

on_train_batch_end: 1598497303.404215s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.3135 - accuracy: 0.1002
on_train_batch_begin: 1598497303.404490s

33 step training time: 0.372341s

on_train_batch_end: 1598497303.774760s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.3131 - accuracy: 0.1002
on_train_batch_begin: 1598497303.775044s

34 step training time: 0.370553s

on_train_batch_end: 1598497304.141671s

35840/50000 [====================>.........] - ETA: 5s - loss: 1.3116 - accuracy: 0.1002
on_train_batch_begin: 1598497304.141935s

35 step training time: 0.366891s

on_train_batch_end: 1598497304.512750s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.3098 - accuracy: 0.1002
on_train_batch_begin: 1598497304.513025s

36 step training time: 0.371090s

on_train_batch_end: 1598497304.884134s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.3076 - accuracy: 0.1002
on_train_batch_begin: 1598497304.884364s

37 step training time: 0.371339s

on_train_batch_end: 1598497305.254802s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.3074 - accuracy: 0.1002
on_train_batch_begin: 1598497305.255035s

38 step training time: 0.370671s

on_train_batch_end: 1598497305.627574s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.3080 - accuracy: 0.1002
on_train_batch_begin: 1598497305.627811s

39 step training time: 0.372776s

on_train_batch_end: 1598497305.998690s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.3006 - accuracy: 0.1002
on_train_batch_begin: 1598497305.998935s

40 step training time: 0.371125s

on_train_batch_end: 1598497306.369055s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.2995 - accuracy: 0.1002
on_train_batch_begin: 1598497306.369287s

41 step training time: 0.370352s

on_train_batch_end: 1598497306.740761s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.2963 - accuracy: 0.1002
on_train_batch_begin: 1598497306.741025s

42 step training time: 0.371737s

on_train_batch_end: 1598497307.112420s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.2916 - accuracy: 0.1002
on_train_batch_begin: 1598497307.112663s

43 step training time: 0.371638s

on_train_batch_end: 1598497307.499148s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.2853 - accuracy: 0.1002
on_train_batch_begin: 1598497307.499414s

44 step training time: 0.386751s

on_train_batch_end: 1598497307.869195s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.2825 - accuracy: 0.1002
on_train_batch_begin: 1598497307.869454s

45 step training time: 0.370039s

on_train_batch_end: 1598497308.244815s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.2770 - accuracy: 0.1002
on_train_batch_begin: 1598497308.245086s

46 step training time: 0.375632s

on_train_batch_end: 1598497308.615227s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.2716 - accuracy: 0.1002
on_train_batch_begin: 1598497308.615488s

47 step training time: 0.370402s

on_train_batch_end: 1598497308.984402s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2672 - accuracy: 0.1002
on_train_batch_begin: 1598497308.984689s

48 step training time: 0.369201s

on_train_batch_end: 1598497309.295750s

on_test_batch_begin: 1598497309.305653s

49 step training time: 0.320964s

on_epoch_end: 1598497310.160886s

Validation time: 0.855223s

Real time: 1598497310.160886s

Epoch time: 18.911393880844116s

50000/50000 [==============================] - 19s 378us/sample - loss: 1.2656 - accuracy: 0.1002 - val_loss: 7.1439 - val_accuracy: 0.0999
Tempo do fit: 121.65925812721252