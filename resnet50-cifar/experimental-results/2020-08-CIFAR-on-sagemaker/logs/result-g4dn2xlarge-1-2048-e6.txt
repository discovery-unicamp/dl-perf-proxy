wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:15
   204800/170498071 [..............................] - ETA: 1:13
  1171456/170498071 [..............................] - ETA: 20s 
  3858432/170498071 [..............................] - ETA: 8s 
  6922240/170498071 [>.............................] - ETA: 5s
  9904128/170498071 [>.............................] - ETA: 4s
 12836864/170498071 [=>............................] - ETA: 4s
 15507456/170498071 [=>............................] - ETA: 4s
 18505728/170498071 [==>...........................] - ETA: 3s
 21487616/170498071 [==>...........................] - ETA: 3s
 24469504/170498071 [===>..........................] - ETA: 3s
 27418624/170498071 [===>..........................] - ETA: 3s
 30416896/170498071 [====>.........................] - ETA: 3s
 33398784/170498071 [====>.........................] - ETA: 2s
 36397056/170498071 [=====>........................] - ETA: 2s
 39378944/170498071 [=====>........................] - ETA: 2s
 42344448/170498071 [======>.......................] - ETA: 2s
 45244416/170498071 [======>.......................] - ETA: 2s
 48242688/170498071 [=======>......................] - ETA: 2s
 51240960/170498071 [========>.....................] - ETA: 2s
 54157312/170498071 [========>.....................] - ETA: 2s
 57155584/170498071 [=========>....................] - ETA: 2s
 60088320/170498071 [=========>....................] - ETA: 2s
 63070208/170498071 [==========>...................] - ETA: 2s
 66068480/170498071 [==========>...................] - ETA: 1s
 69001216/170498071 [===========>..................] - ETA: 1s
 71983104/170498071 [===========>..................] - ETA: 1s
 74948608/170498071 [============>.................] - ETA: 1s
 77897728/170498071 [============>.................] - ETA: 1s
 80846848/170498071 [=============>................] - ETA: 1s
 83861504/170498071 [=============>................] - ETA: 1s
 86728704/170498071 [==============>...............] - ETA: 1s
 89677824/170498071 [==============>...............] - ETA: 1s
 92610560/170498071 [===============>..............] - ETA: 1s
 95510528/170498071 [===============>..............] - ETA: 1s
 98476032/170498071 [================>.............] - ETA: 1s
101408768/170498071 [================>.............] - ETA: 1s
104325120/170498071 [=================>............] - ETA: 1s
107323392/170498071 [=================>............] - ETA: 1s
110272512/170498071 [==================>...........] - ETA: 1s
113123328/170498071 [==================>...........] - ETA: 1s
116105216/170498071 [===================>..........] - ETA: 0s
119103488/170498071 [===================>..........] - ETA: 0s
122085376/170498071 [====================>.........] - ETA: 0s
125018112/170498071 [====================>.........] - ETA: 0s
128016384/170498071 [=====================>........] - ETA: 0s
130883584/170498071 [======================>.......] - ETA: 0s
133881856/170498071 [======================>.......] - ETA: 0s
136798208/170498071 [=======================>......] - ETA: 0s
139993088/170498071 [=======================>......] - ETA: 0s
143417344/170498071 [========================>.....] - ETA: 0s
146972672/170498071 [========================>.....] - ETA: 0s
150462464/170498071 [=========================>....] - ETA: 0s
153870336/170498071 [==========================>...] - ETA: 0s
157294592/170498071 [==========================>...] - ETA: 0s
160735232/170498071 [===========================>..] - ETA: 0s
164298752/170498071 [===========================>..] - ETA: 0s
167747584/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 1966080/94765736 [..............................] - ETA: 11s
 9388032/94765736 [=>............................] - ETA: 3s 
10567680/94765736 [==>...........................] - ETA: 3s
15024128/94765736 [===>..........................] - ETA: 2s
18841600/94765736 [====>.........................] - ETA: 2s
28131328/94765736 [=======>......................] - ETA: 1s
31391744/94765736 [========>.....................] - ETA: 1s
32956416/94765736 [=========>....................] - ETA: 1s
35315712/94765736 [==========>...................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
41893888/94765736 [============>.................] - ETA: 1s
42475520/94765736 [============>.................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 1s
49111040/94765736 [==============>...............] - ETA: 1s
55410688/94765736 [================>.............] - ETA: 1s
57368576/94765736 [=================>............] - ETA: 1s
60071936/94765736 [==================>...........] - ETA: 1s
63709184/94765736 [===================>..........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
73310208/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
86007808/94765736 [==========================>...] - ETA: 0s
88711168/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.863354921340942
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615854100.377369s

Real time: 1615854100.377388
Epoch 1/5

on_train_batch_begin: 1615854101.142779s

on_train_batch_end: 1615854122.949744s

 2048/50000 [>.............................] - ETA: 8:48 - loss: 17.8458 - accuracy: 2.7061e-04
on_train_batch_begin: 1615854122.950364s

1 step training time: 21.807585s

on_train_batch_end: 1615854123.600637s

 4096/50000 [=>............................] - ETA: 4:20 - loss: 14.2576 - accuracy: 2.8503e-04
on_train_batch_begin: 1615854123.600970s

2 step training time: 0.650606s

on_train_batch_end: 1615854124.262514s

 6144/50000 [==>...........................] - ETA: 2:50 - loss: 12.3256 - accuracy: 7.4935e-04
on_train_batch_begin: 1615854124.262830s

3 step training time: 0.661860s

on_train_batch_end: 1615854124.916080s

 8192/50000 [===>..........................] - ETA: 2:05 - loss: 11.2909 - accuracy: 0.0022    
on_train_batch_begin: 1615854124.916394s

4 step training time: 0.653563s

on_train_batch_end: 1615854125.571244s

10240/50000 [=====>........................] - ETA: 1:37 - loss: 10.6212 - accuracy: 0.0051
on_train_batch_begin: 1615854125.571579s

5 step training time: 0.655185s

on_train_batch_end: 1615854126.228208s

12288/50000 [======>.......................] - ETA: 1:19 - loss: 10.1348 - accuracy: 0.0094
on_train_batch_begin: 1615854126.228520s

6 step training time: 0.656941s

on_train_batch_end: 1615854126.886467s

14336/50000 [=======>......................] - ETA: 1:05 - loss: 9.7760 - accuracy: 0.0142 
on_train_batch_begin: 1615854126.886786s

7 step training time: 0.658266s

on_train_batch_end: 1615854127.540937s

16384/50000 [========>.....................] - ETA: 55s - loss: 9.4987 - accuracy: 0.0205 
on_train_batch_begin: 1615854127.541261s

8 step training time: 0.654475s

on_train_batch_end: 1615854128.200261s

18432/50000 [==========>...................] - ETA: 47s - loss: 9.2682 - accuracy: 0.0257
on_train_batch_begin: 1615854128.200613s

9 step training time: 0.659352s

on_train_batch_end: 1615854128.852452s

20480/50000 [===========>..................] - ETA: 41s - loss: 9.0798 - accuracy: 0.0311
on_train_batch_begin: 1615854128.852765s

10 step training time: 0.652152s

on_train_batch_end: 1615854129.485669s

22528/50000 [============>.................] - ETA: 35s - loss: 8.9249 - accuracy: 0.0361
on_train_batch_begin: 1615854129.485974s

11 step training time: 0.633209s

on_train_batch_end: 1615854130.153605s

24576/50000 [=============>................] - ETA: 30s - loss: 8.7768 - accuracy: 0.0392
on_train_batch_begin: 1615854130.153915s

12 step training time: 0.667942s

on_train_batch_end: 1615854130.802915s

26624/50000 [==============>...............] - ETA: 26s - loss: 8.6461 - accuracy: 0.0433
on_train_batch_begin: 1615854130.803240s

13 step training time: 0.649324s

on_train_batch_end: 1615854131.465578s

28672/50000 [================>.............] - ETA: 23s - loss: 8.5303 - accuracy: 0.0470
on_train_batch_begin: 1615854131.465894s

14 step training time: 0.662655s

on_train_batch_end: 1615854132.117720s

30720/50000 [=================>............] - ETA: 19s - loss: 8.4277 - accuracy: 0.0497
on_train_batch_begin: 1615854132.118036s

15 step training time: 0.652141s

on_train_batch_end: 1615854132.772161s

32768/50000 [==================>...........] - ETA: 17s - loss: 8.3350 - accuracy: 0.0519
on_train_batch_begin: 1615854132.772467s

16 step training time: 0.654431s

on_train_batch_end: 1615854133.420699s

34816/50000 [===================>..........] - ETA: 14s - loss: 8.2519 - accuracy: 0.0538
on_train_batch_begin: 1615854133.421016s

17 step training time: 0.648549s

on_train_batch_end: 1615854134.076612s

36864/50000 [=====================>........] - ETA: 12s - loss: 8.1691 - accuracy: 0.0554
on_train_batch_begin: 1615854134.076916s

18 step training time: 0.655901s

on_train_batch_end: 1615854134.735100s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.0938 - accuracy: 0.0559 
on_train_batch_begin: 1615854134.735420s

19 step training time: 0.658504s

on_train_batch_end: 1615854135.391893s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.0203 - accuracy: 0.0572
on_train_batch_begin: 1615854135.392230s

20 step training time: 0.656810s

on_train_batch_end: 1615854136.055590s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.9510 - accuracy: 0.0584
on_train_batch_begin: 1615854136.055894s

21 step training time: 0.663664s

on_train_batch_end: 1615854136.710035s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.8838 - accuracy: 0.0595
on_train_batch_begin: 1615854136.710348s

22 step training time: 0.654454s

on_train_batch_end: 1615854137.373457s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.8201 - accuracy: 0.0600
on_train_batch_begin: 1615854137.373767s

23 step training time: 0.663419s

on_train_batch_end: 1615854138.024460s

49152/50000 [============================>.] - ETA: 0s - loss: 7.7593 - accuracy: 0.0607
on_train_batch_begin: 1615854138.024777s

24 step training time: 0.651010s

on_train_batch_end: 1615854143.902939s

on_test_batch_begin: 1615854144.089796s

25 step training time: 6.065019s

on_epoch_end: 1615854149.280893s

Validation time: 5.191080s

Real time: 1615854149.280893s

Epoch time: 48.903525590896606s

50000/50000 [==============================] - 49s 978us/sample - loss: 7.7353 - accuracy: 0.0606 - val_loss: 29584.7344 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615854149.281125s

Real time: 1615854149.2811317
Epoch 2/5

on_train_batch_begin: 1615854149.284820s

on_train_batch_end: 1615854149.939010s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.1977 - accuracy: 0.0635
on_train_batch_begin: 1615854149.939324s

1 step training time: 0.654505s

on_train_batch_end: 1615854150.605004s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.1259 - accuracy: 0.0603
on_train_batch_begin: 1615854150.605322s

2 step training time: 0.665997s

on_train_batch_end: 1615854151.260091s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.0457 - accuracy: 0.0589
on_train_batch_begin: 1615854151.260397s

3 step training time: 0.655075s

on_train_batch_end: 1615854151.927521s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.0150 - accuracy: 0.0543
on_train_batch_begin: 1615854151.927820s

4 step training time: 0.667423s

on_train_batch_end: 1615854152.595382s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.9621 - accuracy: 0.0583
on_train_batch_begin: 1615854152.595688s

5 step training time: 0.667868s

on_train_batch_end: 1615854153.259402s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.9267 - accuracy: 0.0615
on_train_batch_begin: 1615854153.259711s

6 step training time: 0.664023s

on_train_batch_end: 1615854153.917611s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.8939 - accuracy: 0.0646
on_train_batch_begin: 1615854153.917931s

7 step training time: 0.658220s

on_train_batch_end: 1615854154.582319s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.8570 - accuracy: 0.0666
on_train_batch_begin: 1615854154.582645s

8 step training time: 0.664714s

on_train_batch_end: 1615854155.241591s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.8175 - accuracy: 0.0674
on_train_batch_begin: 1615854155.241898s

9 step training time: 0.659252s

on_train_batch_end: 1615854155.900899s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.7726 - accuracy: 0.0678 
on_train_batch_begin: 1615854155.901209s

10 step training time: 0.659311s

on_train_batch_end: 1615854156.569695s

22528/50000 [============>.................] - ETA: 8s - loss: 5.7361 - accuracy: 0.0677
on_train_batch_begin: 1615854156.570000s

11 step training time: 0.668792s

on_train_batch_end: 1615854157.236341s

24576/50000 [=============>................] - ETA: 8s - loss: 5.6819 - accuracy: 0.0679
on_train_batch_begin: 1615854157.236645s

12 step training time: 0.666645s

on_train_batch_end: 1615854157.907380s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.6489 - accuracy: 0.0676
on_train_batch_begin: 1615854157.907688s

13 step training time: 0.671043s

on_train_batch_end: 1615854158.575578s

28672/50000 [================>.............] - ETA: 6s - loss: 5.6134 - accuracy: 0.0673
on_train_batch_begin: 1615854158.575885s

14 step training time: 0.668197s

on_train_batch_end: 1615854159.239529s

30720/50000 [=================>............] - ETA: 6s - loss: 5.5718 - accuracy: 0.0669
on_train_batch_begin: 1615854159.239830s

15 step training time: 0.663945s

on_train_batch_end: 1615854159.907936s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.5322 - accuracy: 0.0665
on_train_batch_begin: 1615854159.908240s

16 step training time: 0.668410s

on_train_batch_end: 1615854160.575442s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.4917 - accuracy: 0.0662
on_train_batch_begin: 1615854160.575750s

17 step training time: 0.667511s

on_train_batch_end: 1615854161.243536s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.4549 - accuracy: 0.0661
on_train_batch_begin: 1615854161.243847s

18 step training time: 0.668097s

on_train_batch_end: 1615854161.912151s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.4185 - accuracy: 0.0659
on_train_batch_begin: 1615854161.912457s

19 step training time: 0.668609s

on_train_batch_end: 1615854162.583121s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.3869 - accuracy: 0.0658
on_train_batch_begin: 1615854162.583443s

20 step training time: 0.670986s

on_train_batch_end: 1615854163.251166s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.3437 - accuracy: 0.0659
on_train_batch_begin: 1615854163.251482s

21 step training time: 0.668039s

on_train_batch_end: 1615854163.919054s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.3034 - accuracy: 0.0659
on_train_batch_begin: 1615854163.919370s

22 step training time: 0.667888s

on_train_batch_end: 1615854164.584927s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.2740 - accuracy: 0.0658
on_train_batch_begin: 1615854164.585223s

23 step training time: 0.665853s

on_train_batch_end: 1615854165.247181s

49152/50000 [============================>.] - ETA: 0s - loss: 5.2430 - accuracy: 0.0658
on_train_batch_begin: 1615854165.247494s

24 step training time: 0.662271s

on_train_batch_end: 1615854165.536814s

on_test_batch_begin: 1615854165.563940s

25 step training time: 0.316445s

on_epoch_end: 1615854166.406724s

Validation time: 0.842768s

Real time: 1615854166.406724s

Epoch time: 17.125609874725342s

50000/50000 [==============================] - 17s 343us/sample - loss: 5.2384 - accuracy: 0.0657 - val_loss: 17632.0638 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615854166.406924s

Real time: 1615854166.4069293
Epoch 3/5

on_train_batch_begin: 1615854166.410334s

on_train_batch_end: 1615854167.075024s

 2048/50000 [>.............................] - ETA: 15s - loss: 4.3536 - accuracy: 0.0670
on_train_batch_begin: 1615854167.075340s

1 step training time: 0.665006s

on_train_batch_end: 1615854167.746658s

 4096/50000 [=>............................] - ETA: 15s - loss: 4.3842 - accuracy: 0.0670
on_train_batch_begin: 1615854167.746972s

2 step training time: 0.671631s

on_train_batch_end: 1615854168.415038s

 6144/50000 [==>...........................] - ETA: 14s - loss: 4.4198 - accuracy: 0.0646
on_train_batch_begin: 1615854168.415394s

3 step training time: 0.668422s

on_train_batch_end: 1615854169.089197s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.4144 - accuracy: 0.0678
on_train_batch_begin: 1615854169.089545s

4 step training time: 0.674151s

on_train_batch_end: 1615854169.764476s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.4402 - accuracy: 0.0700
on_train_batch_begin: 1615854169.764773s

5 step training time: 0.675228s

on_train_batch_end: 1615854170.416559s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.4595 - accuracy: 0.0709
on_train_batch_begin: 1615854170.416876s

6 step training time: 0.652103s

on_train_batch_end: 1615854171.101268s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.4431 - accuracy: 0.0709
on_train_batch_begin: 1615854171.101596s

7 step training time: 0.684720s

on_train_batch_end: 1615854171.771760s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.4169 - accuracy: 0.0710
on_train_batch_begin: 1615854171.772112s

8 step training time: 0.670516s

on_train_batch_end: 1615854172.450118s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.3719 - accuracy: 0.0710
on_train_batch_begin: 1615854172.450432s

9 step training time: 0.678319s

on_train_batch_end: 1615854173.126477s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.3562 - accuracy: 0.0710 
on_train_batch_begin: 1615854173.126772s

10 step training time: 0.676341s

on_train_batch_end: 1615854173.802725s

22528/50000 [============>.................] - ETA: 9s - loss: 4.3303 - accuracy: 0.0710
on_train_batch_begin: 1615854173.803029s

11 step training time: 0.676256s

on_train_batch_end: 1615854174.476747s

24576/50000 [=============>................] - ETA: 8s - loss: 4.2898 - accuracy: 0.0712
on_train_batch_begin: 1615854174.477068s

12 step training time: 0.674039s

on_train_batch_end: 1615854175.147271s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.2573 - accuracy: 0.0717
on_train_batch_begin: 1615854175.147584s

13 step training time: 0.670516s

on_train_batch_end: 1615854175.826330s

28672/50000 [================>.............] - ETA: 7s - loss: 4.2267 - accuracy: 0.0719
on_train_batch_begin: 1615854175.826728s

14 step training time: 0.679144s

on_train_batch_end: 1615854176.501166s

30720/50000 [=================>............] - ETA: 6s - loss: 4.2039 - accuracy: 0.0721
on_train_batch_begin: 1615854176.501493s

15 step training time: 0.674765s

on_train_batch_end: 1615854177.183775s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.1703 - accuracy: 0.0726
on_train_batch_begin: 1615854177.184097s

16 step training time: 0.682604s

on_train_batch_end: 1615854177.853379s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.1437 - accuracy: 0.0732
on_train_batch_begin: 1615854177.853728s

17 step training time: 0.669631s

on_train_batch_end: 1615854178.529874s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.1036 - accuracy: 0.0740
on_train_batch_begin: 1615854178.530175s

18 step training time: 0.676448s

on_train_batch_end: 1615854179.205354s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.0645 - accuracy: 0.0749
on_train_batch_begin: 1615854179.205682s

19 step training time: 0.675506s

on_train_batch_end: 1615854179.883339s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.0262 - accuracy: 0.0756
on_train_batch_begin: 1615854179.883648s

20 step training time: 0.677966s

on_train_batch_end: 1615854180.557550s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.9919 - accuracy: 0.0764
on_train_batch_begin: 1615854180.557861s

21 step training time: 0.674214s

on_train_batch_end: 1615854181.233648s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.9522 - accuracy: 0.0771
on_train_batch_begin: 1615854181.233947s

22 step training time: 0.676086s

on_train_batch_end: 1615854181.913068s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.9149 - accuracy: 0.0779
on_train_batch_begin: 1615854181.913368s

23 step training time: 0.679421s

on_train_batch_end: 1615854182.582799s

49152/50000 [============================>.] - ETA: 0s - loss: 3.8764 - accuracy: 0.0786
on_train_batch_begin: 1615854182.583135s

24 step training time: 0.669766s

on_train_batch_end: 1615854182.871567s

on_test_batch_begin: 1615854182.898273s

25 step training time: 0.315138s

on_epoch_end: 1615854183.756286s

Validation time: 0.857996s

Real time: 1615854183.756286s

Epoch time: 17.34937858581543s

50000/50000 [==============================] - 17s 347us/sample - loss: 3.8671 - accuracy: 0.0787 - val_loss: 35957.5853 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615854183.756510s

Real time: 1615854183.7565153
Epoch 4/5

on_train_batch_begin: 1615854183.759986s

on_train_batch_end: 1615854184.433032s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.8830 - accuracy: 0.0955
on_train_batch_begin: 1615854184.433337s

1 step training time: 0.673351s

on_train_batch_end: 1615854185.114670s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.8050 - accuracy: 0.0967
on_train_batch_begin: 1615854185.114979s

2 step training time: 0.681642s

on_train_batch_end: 1615854185.795415s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.8369 - accuracy: 0.0970
on_train_batch_begin: 1615854185.795723s

3 step training time: 0.680744s

on_train_batch_end: 1615854186.476649s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.7977 - accuracy: 0.0973
on_train_batch_begin: 1615854186.476959s

4 step training time: 0.681236s

on_train_batch_end: 1615854187.159217s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.7575 - accuracy: 0.0975
on_train_batch_begin: 1615854187.159529s

5 step training time: 0.682570s

on_train_batch_end: 1615854187.837742s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.7287 - accuracy: 0.0976
on_train_batch_begin: 1615854187.838051s

6 step training time: 0.678522s

on_train_batch_end: 1615854188.516001s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.7151 - accuracy: 0.0978
on_train_batch_begin: 1615854188.516306s

7 step training time: 0.678255s

on_train_batch_end: 1615854189.193387s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.6680 - accuracy: 0.0981
on_train_batch_begin: 1615854189.193711s

8 step training time: 0.677405s

on_train_batch_end: 1615854189.875486s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.6301 - accuracy: 0.0982
on_train_batch_begin: 1615854189.875798s

9 step training time: 0.682087s

on_train_batch_end: 1615854190.553963s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.6077 - accuracy: 0.0984 
on_train_batch_begin: 1615854190.554262s

10 step training time: 0.678464s

on_train_batch_end: 1615854191.239607s

22528/50000 [============>.................] - ETA: 9s - loss: 2.5791 - accuracy: 0.0985
on_train_batch_begin: 1615854191.239917s

11 step training time: 0.685654s

on_train_batch_end: 1615854191.921381s

24576/50000 [=============>................] - ETA: 8s - loss: 2.5481 - accuracy: 0.0986
on_train_batch_begin: 1615854191.921730s

12 step training time: 0.681813s

on_train_batch_end: 1615854192.607234s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.5265 - accuracy: 0.0986
on_train_batch_begin: 1615854192.607530s

13 step training time: 0.685800s

on_train_batch_end: 1615854193.287650s

28672/50000 [================>.............] - ETA: 7s - loss: 2.5127 - accuracy: 0.0987
on_train_batch_begin: 1615854193.287968s

14 step training time: 0.680438s

on_train_batch_end: 1615854193.966255s

30720/50000 [=================>............] - ETA: 6s - loss: 2.4936 - accuracy: 0.0988
on_train_batch_begin: 1615854193.966582s

15 step training time: 0.678614s

on_train_batch_end: 1615854194.649684s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.4728 - accuracy: 0.0988
on_train_batch_begin: 1615854194.649987s

16 step training time: 0.683405s

on_train_batch_end: 1615854195.330671s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.4536 - accuracy: 0.0989
on_train_batch_begin: 1615854195.330983s

17 step training time: 0.680996s

on_train_batch_end: 1615854196.017005s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.4421 - accuracy: 0.0989
on_train_batch_begin: 1615854196.017318s

18 step training time: 0.686336s

on_train_batch_end: 1615854196.699227s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.4273 - accuracy: 0.0990
on_train_batch_begin: 1615854196.699528s

19 step training time: 0.682210s

on_train_batch_end: 1615854197.382407s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.4120 - accuracy: 0.0990
on_train_batch_begin: 1615854197.382720s

20 step training time: 0.683192s

on_train_batch_end: 1615854198.067542s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.3946 - accuracy: 0.0991
on_train_batch_begin: 1615854198.067846s

21 step training time: 0.685125s

on_train_batch_end: 1615854198.752056s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.3873 - accuracy: 0.0991
on_train_batch_begin: 1615854198.752372s

22 step training time: 0.684526s

on_train_batch_end: 1615854199.440629s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.3731 - accuracy: 0.0992
on_train_batch_begin: 1615854199.440926s

23 step training time: 0.688554s

on_train_batch_end: 1615854200.121678s

49152/50000 [============================>.] - ETA: 0s - loss: 2.3625 - accuracy: 0.0992
on_train_batch_begin: 1615854200.122022s

24 step training time: 0.681097s

on_train_batch_end: 1615854200.417181s

on_test_batch_begin: 1615854200.443985s

25 step training time: 0.321962s

on_epoch_end: 1615854201.308277s

Validation time: 0.864276s

Real time: 1615854201.308277s

Epoch time: 17.55178666114807s

50000/50000 [==============================] - 18s 351us/sample - loss: 2.3583 - accuracy: 0.0992 - val_loss: 5910.3244 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615854201.308548s

Real time: 1615854201.3085546
Epoch 5/5

on_train_batch_begin: 1615854201.313327s

on_train_batch_end: 1615854201.990310s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.9888 - accuracy: 0.1000
on_train_batch_begin: 1615854201.990623s

1 step training time: 0.677297s

on_train_batch_end: 1615854202.678259s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.9491 - accuracy: 0.0998
on_train_batch_begin: 1615854202.678572s

2 step training time: 0.687949s

on_train_batch_end: 1615854203.362213s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.9623 - accuracy: 0.0998
on_train_batch_begin: 1615854203.362535s

3 step training time: 0.683963s

on_train_batch_end: 1615854204.046817s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.9468 - accuracy: 0.0998
on_train_batch_begin: 1615854204.047132s

4 step training time: 0.684597s

on_train_batch_end: 1615854204.709374s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.9383 - accuracy: 0.0998
on_train_batch_begin: 1615854204.709699s

5 step training time: 0.662566s

on_train_batch_end: 1615854205.406793s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.9178 - accuracy: 0.0999
on_train_batch_begin: 1615854205.407090s

6 step training time: 0.697391s

on_train_batch_end: 1615854206.089364s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.9397 - accuracy: 0.0999
on_train_batch_begin: 1615854206.089726s

7 step training time: 0.682636s

on_train_batch_end: 1615854206.782408s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.9451 - accuracy: 0.0999
on_train_batch_begin: 1615854206.782724s

8 step training time: 0.692999s

on_train_batch_end: 1615854207.467540s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.9465 - accuracy: 0.0999
on_train_batch_begin: 1615854207.467843s

9 step training time: 0.685118s

on_train_batch_end: 1615854208.148839s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.9406 - accuracy: 0.0999 
on_train_batch_begin: 1615854208.149146s

10 step training time: 0.681303s

on_train_batch_end: 1615854208.834433s

22528/50000 [============>.................] - ETA: 9s - loss: 1.9205 - accuracy: 0.0999
on_train_batch_begin: 1615854208.834730s

11 step training time: 0.685585s

on_train_batch_end: 1615854209.517064s

24576/50000 [=============>................] - ETA: 8s - loss: 1.9132 - accuracy: 0.0999
on_train_batch_begin: 1615854209.517374s

12 step training time: 0.682644s

on_train_batch_end: 1615854210.186647s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.9058 - accuracy: 0.0999
on_train_batch_begin: 1615854210.186959s

13 step training time: 0.669584s

on_train_batch_end: 1615854210.878714s

28672/50000 [================>.............] - ETA: 7s - loss: 1.8992 - accuracy: 0.0999
on_train_batch_begin: 1615854210.879014s

14 step training time: 0.692056s

on_train_batch_end: 1615854211.563060s

30720/50000 [=================>............] - ETA: 6s - loss: 1.8851 - accuracy: 0.0999
on_train_batch_begin: 1615854211.563378s

15 step training time: 0.684363s

on_train_batch_end: 1615854212.249226s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.8819 - accuracy: 0.0999
on_train_batch_begin: 1615854212.249561s

16 step training time: 0.686183s

on_train_batch_end: 1615854212.933560s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.8763 - accuracy: 0.0999
on_train_batch_begin: 1615854212.933862s

17 step training time: 0.684301s

on_train_batch_end: 1615854213.617162s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.8674 - accuracy: 0.1000
on_train_batch_begin: 1615854213.617495s

18 step training time: 0.683634s

on_train_batch_end: 1615854214.304428s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.8758 - accuracy: 0.1000
on_train_batch_begin: 1615854214.304739s

19 step training time: 0.687244s

on_train_batch_end: 1615854214.997209s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.8757 - accuracy: 0.0999
on_train_batch_begin: 1615854214.997554s

20 step training time: 0.692815s

on_train_batch_end: 1615854215.682484s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.8758 - accuracy: 0.0999
on_train_batch_begin: 1615854215.682802s

21 step training time: 0.685248s

on_train_batch_end: 1615854216.371031s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8762 - accuracy: 0.0999
on_train_batch_begin: 1615854216.371327s

22 step training time: 0.688525s

on_train_batch_end: 1615854217.057449s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8781 - accuracy: 0.0999
on_train_batch_begin: 1615854217.057768s

23 step training time: 0.686441s

on_train_batch_end: 1615854217.738925s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8784 - accuracy: 0.0999
on_train_batch_begin: 1615854217.739223s

24 step training time: 0.681455s

on_train_batch_end: 1615854218.029769s

on_test_batch_begin: 1615854218.056132s

25 step training time: 0.316908s

on_epoch_end: 1615854218.922679s

Validation time: 0.866530s

Real time: 1615854218.922679s

Epoch time: 17.61414361000061s

50000/50000 [==============================] - 18s 352us/sample - loss: 1.8793 - accuracy: 0.0999 - val_loss: 7.2501 - val_accuracy: 0.0998
Tempo do fit: 122.00665307044983