wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 6:53
   204800/170498071 [..............................] - ETA: 1:12
  1433600/170498071 [..............................] - ETA: 16s 
  4489216/170498071 [..............................] - ETA: 6s 
  8069120/170498071 [>.............................] - ETA: 4s
 11411456/170498071 [=>............................] - ETA: 4s
 14999552/170498071 [=>............................] - ETA: 3s
 18636800/170498071 [==>...........................] - ETA: 3s
 22126592/170498071 [==>...........................] - ETA: 2s
 25403392/170498071 [===>..........................] - ETA: 2s
 29007872/170498071 [====>.........................] - ETA: 2s
 32595968/170498071 [====>.........................] - ETA: 2s
 36167680/170498071 [=====>........................] - ETA: 2s
 39428096/170498071 [=====>........................] - ETA: 2s
 42917888/170498071 [======>.......................] - ETA: 2s
 46456832/170498071 [=======>......................] - ETA: 2s
 50061312/170498071 [=======>......................] - ETA: 2s
 53460992/170498071 [========>.....................] - ETA: 1s
 56729600/170498071 [========>.....................] - ETA: 1s
 60252160/170498071 [=========>....................] - ETA: 1s
 63676416/170498071 [==========>...................] - ETA: 1s
 66822144/170498071 [==========>...................] - ETA: 1s
 70017024/170498071 [===========>..................] - ETA: 1s
 73310208/170498071 [===========>..................] - ETA: 1s
 76849152/170498071 [============>.................] - ETA: 1s
 80289792/170498071 [=============>................] - ETA: 1s
 83795968/170498071 [=============>................] - ETA: 1s
 87244800/170498071 [==============>...............] - ETA: 1s
 90652672/170498071 [==============>...............] - ETA: 1s
 94224384/170498071 [===============>..............] - ETA: 1s
 97558528/170498071 [================>.............] - ETA: 1s
101130240/170498071 [================>.............] - ETA: 1s
104538112/170498071 [=================>............] - ETA: 1s
108060672/170498071 [==================>...........] - ETA: 0s
111534080/170498071 [==================>...........] - ETA: 0s
114991104/170498071 [===================>..........] - ETA: 0s
118497280/170498071 [===================>..........] - ETA: 0s
121937920/170498071 [====================>.........] - ETA: 0s
125452288/170498071 [=====================>........] - ETA: 0s
128835584/170498071 [=====================>........] - ETA: 0s
132423680/170498071 [======================>.......] - ETA: 0s
135815168/170498071 [======================>.......] - ETA: 0s
139337728/170498071 [=======================>......] - ETA: 0s
142761984/170498071 [========================>.....] - ETA: 0s
146219008/170498071 [========================>.....] - ETA: 0s
149757952/170498071 [=========================>....] - ETA: 0s
153182208/170498071 [=========================>....] - ETA: 0s
156688384/170498071 [==========================>...] - ETA: 0s
160161792/170498071 [===========================>..] - ETA: 0s
163651584/170498071 [===========================>..] - ETA: 0s
167141376/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 5406720/94765736 [>.............................] - ETA: 0s
13336576/94765736 [===>..........................] - ETA: 0s
17981440/94765736 [====>.........................] - ETA: 0s
23306240/94765736 [======>.......................] - ETA: 0s
28352512/94765736 [=======>......................] - ETA: 0s
33349632/94765736 [=========>....................] - ETA: 0s
38305792/94765736 [===========>..................] - ETA: 0s
43368448/94765736 [============>.................] - ETA: 0s
48455680/94765736 [==============>...............] - ETA: 0s
53403648/94765736 [===============>..............] - ETA: 0s
58408960/94765736 [=================>............] - ETA: 0s
63471616/94765736 [===================>..........] - ETA: 0s
68485120/94765736 [====================>.........] - ETA: 0s
73416704/94765736 [======================>.......] - ETA: 0s
78454784/94765736 [=======================>......] - ETA: 0s
83476480/94765736 [=========================>....] - ETA: 0s
88424448/94765736 [==========================>...] - ETA: 0s
93405184/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 20.777485370635986
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1609199656.060763s

Real time: 1609199656.0607831
Epoch 1/5

on_train_batch_begin: 1609199657.003272s

on_train_batch_end: 1609199716.541136s

 1024/50000 [..............................] - ETA: 48:12 - loss: 17.3958 - accuracy: 2.6703e-04
on_train_batch_begin: 1609199716.541857s

1 step training time: 59.538585s

on_train_batch_end: 1609199716.611652s

 2048/50000 [>.............................] - ETA: 23:37 - loss: 15.6776 - accuracy: 3.1281e-04
on_train_batch_begin: 1609199716.612067s

2 step training time: 0.070210s

on_train_batch_end: 1609199716.676491s

 3072/50000 [>.............................] - ETA: 15:25 - loss: 13.7811 - accuracy: 3.3569e-04
on_train_batch_begin: 1609199716.676891s

3 step training time: 0.064824s

on_train_batch_end: 1609199716.741729s

 4096/50000 [=>............................] - ETA: 11:20 - loss: 12.5101 - accuracy: 8.0204e-04
on_train_batch_begin: 1609199716.742134s

4 step training time: 0.065243s

on_train_batch_end: 1609199716.807489s

 5120/50000 [==>...........................] - ETA: 8:52 - loss: 11.6209 - accuracy: 0.0018     
on_train_batch_begin: 1609199716.807887s

5 step training time: 0.065753s

on_train_batch_end: 1609199716.874107s

 6144/50000 [==>...........................] - ETA: 7:14 - loss: 10.9964 - accuracy: 0.0032
on_train_batch_begin: 1609199716.874508s

6 step training time: 0.066621s

on_train_batch_end: 1609199716.939412s

 7168/50000 [===>..........................] - ETA: 6:03 - loss: 10.5286 - accuracy: 0.0061
on_train_batch_begin: 1609199716.939803s

7 step training time: 0.065295s

on_train_batch_end: 1609199717.008427s

 8192/50000 [===>..........................] - ETA: 5:11 - loss: 10.1607 - accuracy: 0.0088
on_train_batch_begin: 1609199717.008819s

8 step training time: 0.069016s

on_train_batch_end: 1609199717.074812s

 9216/50000 [====>.........................] - ETA: 4:30 - loss: 9.8514 - accuracy: 0.0124 
on_train_batch_begin: 1609199717.075207s

9 step training time: 0.066388s

on_train_batch_end: 1609199717.139685s

10240/50000 [=====>........................] - ETA: 3:57 - loss: 9.5935 - accuracy: 0.0152
on_train_batch_begin: 1609199717.140075s

10 step training time: 0.064868s

on_train_batch_end: 1609199717.209093s

11264/50000 [=====>........................] - ETA: 3:30 - loss: 9.3774 - accuracy: 0.0186
on_train_batch_begin: 1609199717.209487s

11 step training time: 0.069412s

on_train_batch_end: 1609199717.274243s

12288/50000 [======>.......................] - ETA: 3:07 - loss: 9.1886 - accuracy: 0.0210
on_train_batch_begin: 1609199717.274703s

12 step training time: 0.065216s

on_train_batch_end: 1609199717.344315s

13312/50000 [======>.......................] - ETA: 2:48 - loss: 9.0153 - accuracy: 0.0231
on_train_batch_begin: 1609199717.344703s

13 step training time: 0.070000s

on_train_batch_end: 1609199717.413125s

14336/50000 [=======>......................] - ETA: 2:32 - loss: 8.8619 - accuracy: 0.0256
on_train_batch_begin: 1609199717.413521s

14 step training time: 0.068818s

on_train_batch_end: 1609199717.481114s

15360/50000 [========>.....................] - ETA: 2:18 - loss: 8.7253 - accuracy: 0.0278
on_train_batch_begin: 1609199717.481514s

15 step training time: 0.067993s

on_train_batch_end: 1609199717.547945s

16384/50000 [========>.....................] - ETA: 2:06 - loss: 8.6012 - accuracy: 0.0295
on_train_batch_begin: 1609199717.548339s

16 step training time: 0.066824s

on_train_batch_end: 1609199717.616831s

17408/50000 [=========>....................] - ETA: 1:55 - loss: 8.4839 - accuracy: 0.0309
on_train_batch_begin: 1609199717.617221s

17 step training time: 0.068882s

on_train_batch_end: 1609199717.682865s

18432/50000 [==========>...................] - ETA: 1:45 - loss: 8.3788 - accuracy: 0.0326
on_train_batch_begin: 1609199717.683259s

18 step training time: 0.066038s

on_train_batch_end: 1609199717.750447s

19456/50000 [==========>...................] - ETA: 1:36 - loss: 8.2626 - accuracy: 0.0340
on_train_batch_begin: 1609199717.750874s

19 step training time: 0.067616s

on_train_batch_end: 1609199717.816350s

20480/50000 [===========>..................] - ETA: 1:29 - loss: 8.1572 - accuracy: 0.0353
on_train_batch_begin: 1609199717.816750s

20 step training time: 0.065875s

on_train_batch_end: 1609199717.881954s

21504/50000 [===========>..................] - ETA: 1:21 - loss: 8.0595 - accuracy: 0.0362
on_train_batch_begin: 1609199717.882349s

21 step training time: 0.065599s

on_train_batch_end: 1609199717.948061s

22528/50000 [============>.................] - ETA: 1:15 - loss: 7.9646 - accuracy: 0.0368
on_train_batch_begin: 1609199717.948450s

22 step training time: 0.066101s

on_train_batch_end: 1609199718.012955s

23552/50000 [=============>................] - ETA: 1:09 - loss: 7.8684 - accuracy: 0.0375
on_train_batch_begin: 1609199718.013345s

23 step training time: 0.064896s

on_train_batch_end: 1609199718.076833s

24576/50000 [=============>................] - ETA: 1:04 - loss: 7.7724 - accuracy: 0.0382
on_train_batch_begin: 1609199718.077223s

24 step training time: 0.063877s

on_train_batch_end: 1609199718.144804s

25600/50000 [==============>...............] - ETA: 59s - loss: 7.6795 - accuracy: 0.0389 
on_train_batch_begin: 1609199718.145191s

25 step training time: 0.067969s

on_train_batch_end: 1609199718.214949s

26624/50000 [==============>...............] - ETA: 54s - loss: 7.5925 - accuracy: 0.0397
on_train_batch_begin: 1609199718.215346s

26 step training time: 0.070155s

on_train_batch_end: 1609199718.285123s

27648/50000 [===============>..............] - ETA: 50s - loss: 7.5073 - accuracy: 0.0405
on_train_batch_begin: 1609199718.285537s

27 step training time: 0.070191s

on_train_batch_end: 1609199718.353792s

28672/50000 [================>.............] - ETA: 46s - loss: 7.4249 - accuracy: 0.0414
on_train_batch_begin: 1609199718.354179s

28 step training time: 0.068642s

on_train_batch_end: 1609199718.423111s

29696/50000 [================>.............] - ETA: 42s - loss: 7.3434 - accuracy: 0.0423
on_train_batch_begin: 1609199718.423497s

29 step training time: 0.069318s

on_train_batch_end: 1609199718.488798s

30720/50000 [=================>............] - ETA: 39s - loss: 7.2631 - accuracy: 0.0433
on_train_batch_begin: 1609199718.489186s

30 step training time: 0.065689s

on_train_batch_end: 1609199718.553599s

31744/50000 [==================>...........] - ETA: 35s - loss: 7.1848 - accuracy: 0.0443
on_train_batch_begin: 1609199718.553988s

31 step training time: 0.064802s

on_train_batch_end: 1609199718.619151s

32768/50000 [==================>...........] - ETA: 32s - loss: 7.0969 - accuracy: 0.0454
on_train_batch_begin: 1609199718.619541s

32 step training time: 0.065553s

on_train_batch_end: 1609199718.682689s

33792/50000 [===================>..........] - ETA: 30s - loss: 7.0161 - accuracy: 0.0464
on_train_batch_begin: 1609199718.683107s

33 step training time: 0.063566s

on_train_batch_end: 1609199718.746969s

34816/50000 [===================>..........] - ETA: 27s - loss: 6.9372 - accuracy: 0.0474
on_train_batch_begin: 1609199718.747360s

34 step training time: 0.064252s

on_train_batch_end: 1609199718.812752s

35840/50000 [====================>.........] - ETA: 24s - loss: 6.8638 - accuracy: 0.0484
on_train_batch_begin: 1609199718.813136s

35 step training time: 0.065777s

on_train_batch_end: 1609199718.878519s

36864/50000 [=====================>........] - ETA: 22s - loss: 6.7864 - accuracy: 0.0494
on_train_batch_begin: 1609199718.878937s

36 step training time: 0.065801s

on_train_batch_end: 1609199718.943850s

37888/50000 [=====================>........] - ETA: 20s - loss: 6.7114 - accuracy: 0.0505
on_train_batch_begin: 1609199718.944237s

37 step training time: 0.065300s

on_train_batch_end: 1609199719.012115s

38912/50000 [======================>.......] - ETA: 17s - loss: 6.6317 - accuracy: 0.0515
on_train_batch_begin: 1609199719.012503s

38 step training time: 0.068266s

on_train_batch_end: 1609199719.077235s

39936/50000 [======================>.......] - ETA: 15s - loss: 6.5562 - accuracy: 0.0526
on_train_batch_begin: 1609199719.077621s

39 step training time: 0.065117s

on_train_batch_end: 1609199719.141087s

40960/50000 [=======================>......] - ETA: 13s - loss: 6.4844 - accuracy: 0.0536
on_train_batch_begin: 1609199719.141462s

40 step training time: 0.063842s

on_train_batch_end: 1609199719.211114s

41984/50000 [========================>.....] - ETA: 12s - loss: 6.4139 - accuracy: 0.0546
on_train_batch_begin: 1609199719.211487s

41 step training time: 0.070025s

on_train_batch_end: 1609199719.276770s

43008/50000 [========================>.....] - ETA: 10s - loss: 6.3373 - accuracy: 0.0556
on_train_batch_begin: 1609199719.277137s

42 step training time: 0.065650s

on_train_batch_end: 1609199719.340595s

44032/50000 [=========================>....] - ETA: 8s - loss: 6.2679 - accuracy: 0.0565 
on_train_batch_begin: 1609199719.340972s

43 step training time: 0.063835s

on_train_batch_end: 1609199719.405662s

45056/50000 [==========================>...] - ETA: 6s - loss: 6.1959 - accuracy: 0.0574
on_train_batch_begin: 1609199719.406034s

44 step training time: 0.065062s

on_train_batch_end: 1609199719.471454s

46080/50000 [==========================>...] - ETA: 5s - loss: 6.1327 - accuracy: 0.0583
on_train_batch_begin: 1609199719.471838s

45 step training time: 0.065805s

on_train_batch_end: 1609199719.536367s

47104/50000 [===========================>..] - ETA: 3s - loss: 6.0673 - accuracy: 0.0592
on_train_batch_begin: 1609199719.536748s

46 step training time: 0.064909s

on_train_batch_end: 1609199719.600980s

48128/50000 [===========================>..] - ETA: 2s - loss: 5.9986 - accuracy: 0.0601
on_train_batch_begin: 1609199719.601350s

47 step training time: 0.064603s

on_train_batch_end: 1609199719.666328s

49152/50000 [============================>.] - ETA: 1s - loss: 5.9362 - accuracy: 0.0609
on_train_batch_begin: 1609199719.666708s

48 step training time: 0.065358s

on_train_batch_end: 1609199720.649031s

on_test_batch_begin: 1609199720.937593s

49 step training time: 1.270885s

on_epoch_end: 1609199727.508959s

Validation time: 6.571346s

Real time: 1609199727.508959s

Epoch time: 71.44820046424866s

50000/50000 [==============================] - 71s 1ms/sample - loss: 5.8875 - accuracy: 0.0614 - val_loss: 53.4401 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609199727.509225s

Real time: 1609199727.509235
Epoch 2/5

on_train_batch_begin: 1609199727.514959s

on_train_batch_end: 1609199727.584190s

 1024/50000 [..............................] - ETA: 3s - loss: 2.6662 - accuracy: 0.0998
on_train_batch_begin: 1609199727.584563s

1 step training time: 0.069604s

on_train_batch_end: 1609199727.650076s

 2048/50000 [>.............................] - ETA: 3s - loss: 2.6562 - accuracy: 0.0998
on_train_batch_begin: 1609199727.650445s

2 step training time: 0.065882s

on_train_batch_end: 1609199727.713588s

 3072/50000 [>.............................] - ETA: 3s - loss: 2.6894 - accuracy: 0.1000
on_train_batch_begin: 1609199727.713959s

3 step training time: 0.063514s

on_train_batch_end: 1609199727.778771s

 4096/50000 [=>............................] - ETA: 3s - loss: 2.6799 - accuracy: 0.1000
on_train_batch_begin: 1609199727.779149s

4 step training time: 0.065190s

on_train_batch_end: 1609199727.842110s

 5120/50000 [==>...........................] - ETA: 2s - loss: 2.6491 - accuracy: 0.1002
on_train_batch_begin: 1609199727.842485s

5 step training time: 0.063337s

on_train_batch_end: 1609199727.907957s

 6144/50000 [==>...........................] - ETA: 2s - loss: 2.6064 - accuracy: 0.1001
on_train_batch_begin: 1609199727.908338s

6 step training time: 0.065853s

on_train_batch_end: 1609199727.973279s

 7168/50000 [===>..........................] - ETA: 2s - loss: 2.6124 - accuracy: 0.1000
on_train_batch_begin: 1609199727.973655s

7 step training time: 0.065317s

on_train_batch_end: 1609199728.040276s

 8192/50000 [===>..........................] - ETA: 2s - loss: 2.5911 - accuracy: 0.1001
on_train_batch_begin: 1609199728.040652s

8 step training time: 0.066997s

on_train_batch_end: 1609199728.107960s

 9216/50000 [====>.........................] - ETA: 2s - loss: 2.5855 - accuracy: 0.1003
on_train_batch_begin: 1609199728.108337s

9 step training time: 0.067685s

on_train_batch_end: 1609199728.173990s

10240/50000 [=====>........................] - ETA: 2s - loss: 2.5510 - accuracy: 0.1004
on_train_batch_begin: 1609199728.174365s

10 step training time: 0.066028s

on_train_batch_end: 1609199728.239895s

11264/50000 [=====>........................] - ETA: 2s - loss: 2.5282 - accuracy: 0.1004
on_train_batch_begin: 1609199728.240268s

11 step training time: 0.065903s

on_train_batch_end: 1609199728.304392s

12288/50000 [======>.......................] - ETA: 2s - loss: 2.5047 - accuracy: 0.1004
on_train_batch_begin: 1609199728.304770s

12 step training time: 0.064502s

on_train_batch_end: 1609199728.372903s

13312/50000 [======>.......................] - ETA: 2s - loss: 2.5005 - accuracy: 0.1004
on_train_batch_begin: 1609199728.373276s

13 step training time: 0.068506s

on_train_batch_end: 1609199728.438135s

14336/50000 [=======>......................] - ETA: 2s - loss: 2.4960 - accuracy: 0.1005
on_train_batch_begin: 1609199728.438508s

14 step training time: 0.065232s

on_train_batch_end: 1609199728.503364s

15360/50000 [========>.....................] - ETA: 2s - loss: 2.4858 - accuracy: 0.1005
on_train_batch_begin: 1609199728.503741s

15 step training time: 0.065233s

on_train_batch_end: 1609199728.565837s

16384/50000 [========>.....................] - ETA: 2s - loss: 2.4841 - accuracy: 0.1005
on_train_batch_begin: 1609199728.566209s

16 step training time: 0.062468s

on_train_batch_end: 1609199728.634654s

17408/50000 [=========>....................] - ETA: 2s - loss: 2.4704 - accuracy: 0.1005
on_train_batch_begin: 1609199728.635059s

17 step training time: 0.068850s

on_train_batch_end: 1609199728.699498s

18432/50000 [==========>...................] - ETA: 2s - loss: 2.4705 - accuracy: 0.1005
on_train_batch_begin: 1609199728.699873s

18 step training time: 0.064814s

on_train_batch_end: 1609199728.767828s

19456/50000 [==========>...................] - ETA: 1s - loss: 2.4637 - accuracy: 0.1005
on_train_batch_begin: 1609199728.768209s

19 step training time: 0.068336s

on_train_batch_end: 1609199728.832613s

20480/50000 [===========>..................] - ETA: 1s - loss: 2.4518 - accuracy: 0.1005
on_train_batch_begin: 1609199728.832989s

20 step training time: 0.064780s

on_train_batch_end: 1609199728.898987s

21504/50000 [===========>..................] - ETA: 1s - loss: 2.4435 - accuracy: 0.1005
on_train_batch_begin: 1609199728.899363s

21 step training time: 0.066375s

on_train_batch_end: 1609199728.963533s

22528/50000 [============>.................] - ETA: 1s - loss: 2.4325 - accuracy: 0.1005
on_train_batch_begin: 1609199728.963908s

22 step training time: 0.064545s

on_train_batch_end: 1609199729.027851s

23552/50000 [=============>................] - ETA: 1s - loss: 2.4216 - accuracy: 0.1005
on_train_batch_begin: 1609199729.028230s

23 step training time: 0.064322s

on_train_batch_end: 1609199729.092205s

24576/50000 [=============>................] - ETA: 1s - loss: 2.4126 - accuracy: 0.1005
on_train_batch_begin: 1609199729.092581s

24 step training time: 0.064351s

on_train_batch_end: 1609199729.161270s

25600/50000 [==============>...............] - ETA: 1s - loss: 2.4041 - accuracy: 0.1005
on_train_batch_begin: 1609199729.161645s

25 step training time: 0.069064s

on_train_batch_end: 1609199729.225285s

26624/50000 [==============>...............] - ETA: 1s - loss: 2.3946 - accuracy: 0.1005
on_train_batch_begin: 1609199729.225658s

26 step training time: 0.064013s

on_train_batch_end: 1609199729.289132s

27648/50000 [===============>..............] - ETA: 1s - loss: 2.3893 - accuracy: 0.1006
on_train_batch_begin: 1609199729.289503s

27 step training time: 0.063845s

on_train_batch_end: 1609199729.353616s

28672/50000 [================>.............] - ETA: 1s - loss: 2.3800 - accuracy: 0.1006
on_train_batch_begin: 1609199729.353991s

28 step training time: 0.064488s

on_train_batch_end: 1609199729.415408s

29696/50000 [================>.............] - ETA: 1s - loss: 2.3731 - accuracy: 0.1006
on_train_batch_begin: 1609199729.415777s

29 step training time: 0.061786s

on_train_batch_end: 1609199729.477950s

30720/50000 [=================>............] - ETA: 1s - loss: 2.3652 - accuracy: 0.1006
on_train_batch_begin: 1609199729.478325s

30 step training time: 0.062548s

on_train_batch_end: 1609199729.544210s

31744/50000 [==================>...........] - ETA: 1s - loss: 2.3606 - accuracy: 0.1006
on_train_batch_begin: 1609199729.544591s

31 step training time: 0.066267s

on_train_batch_end: 1609199729.610290s

32768/50000 [==================>...........] - ETA: 1s - loss: 2.3547 - accuracy: 0.1007
on_train_batch_begin: 1609199729.610664s

32 step training time: 0.066073s

on_train_batch_end: 1609199729.678980s

33792/50000 [===================>..........] - ETA: 1s - loss: 2.3521 - accuracy: 0.1007
on_train_batch_begin: 1609199729.679361s

33 step training time: 0.068697s

on_train_batch_end: 1609199729.746086s

34816/50000 [===================>..........] - ETA: 0s - loss: 2.3476 - accuracy: 0.1006
on_train_batch_begin: 1609199729.746460s

34 step training time: 0.067098s

on_train_batch_end: 1609199729.810123s

35840/50000 [====================>.........] - ETA: 0s - loss: 2.3423 - accuracy: 0.1007
on_train_batch_begin: 1609199729.810491s

35 step training time: 0.064031s

on_train_batch_end: 1609199729.875904s

36864/50000 [=====================>........] - ETA: 0s - loss: 2.3381 - accuracy: 0.1007
on_train_batch_begin: 1609199729.876278s

36 step training time: 0.065787s

on_train_batch_end: 1609199729.941602s

37888/50000 [=====================>........] - ETA: 0s - loss: 2.3239 - accuracy: 0.1007
on_train_batch_begin: 1609199729.941972s

37 step training time: 0.065694s

on_train_batch_end: 1609199730.006144s

38912/50000 [======================>.......] - ETA: 0s - loss: 2.3181 - accuracy: 0.1007
on_train_batch_begin: 1609199730.006513s

38 step training time: 0.064542s

on_train_batch_end: 1609199730.072070s

39936/50000 [======================>.......] - ETA: 0s - loss: 2.3096 - accuracy: 0.1007
on_train_batch_begin: 1609199730.072445s

39 step training time: 0.065932s

on_train_batch_end: 1609199730.137115s

40960/50000 [=======================>......] - ETA: 0s - loss: 2.2984 - accuracy: 0.1007
on_train_batch_begin: 1609199730.137486s

40 step training time: 0.065041s

on_train_batch_end: 1609199730.202675s

41984/50000 [========================>.....] - ETA: 0s - loss: 2.2908 - accuracy: 0.1007
on_train_batch_begin: 1609199730.203075s

41 step training time: 0.065589s

on_train_batch_end: 1609199730.268802s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.2817 - accuracy: 0.1007
on_train_batch_begin: 1609199730.269172s

42 step training time: 0.066097s

on_train_batch_end: 1609199730.335157s

44032/50000 [=========================>....] - ETA: 0s - loss: 2.2684 - accuracy: 0.1007
on_train_batch_begin: 1609199730.335531s

43 step training time: 0.066358s

on_train_batch_end: 1609199730.400341s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.2568 - accuracy: 0.1007
on_train_batch_begin: 1609199730.400710s

44 step training time: 0.065180s

on_train_batch_end: 1609199730.469102s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.2444 - accuracy: 0.1007
on_train_batch_begin: 1609199730.469471s

45 step training time: 0.068761s

on_train_batch_end: 1609199730.534109s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.2354 - accuracy: 0.1007
on_train_batch_begin: 1609199730.534482s

46 step training time: 0.065011s

on_train_batch_end: 1609199730.602359s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.2275 - accuracy: 0.1007
on_train_batch_begin: 1609199730.602759s

47 step training time: 0.068276s

on_train_batch_end: 1609199730.667113s

49152/50000 [============================>.] - ETA: 0s - loss: 2.2139 - accuracy: 0.1007
on_train_batch_begin: 1609199730.667485s

48 step training time: 0.064726s

on_train_batch_end: 1609199730.733069s

on_test_batch_begin: 1609199730.755731s

49 step training time: 0.088246s

on_epoch_end: 1609199730.995973s

Validation time: 0.240227s

Real time: 1609199730.995973s

Epoch time: 3.486759662628174s

50000/50000 [==============================] - 3s 70us/sample - loss: 2.2076 - accuracy: 0.1007 - val_loss: 7.2553 - val_accuracy: 0.1001

on_epoch_begin: 1609199730.996218s

Real time: 1609199730.9962275
Epoch 3/5

on_train_batch_begin: 1609199731.001994s

on_train_batch_end: 1609199731.068225s

 1024/50000 [..............................] - ETA: 3s - loss: 1.5128 - accuracy: 0.1007
on_train_batch_begin: 1609199731.068601s

1 step training time: 0.066607s

on_train_batch_end: 1609199731.137003s

 2048/50000 [>.............................] - ETA: 3s - loss: 1.5366 - accuracy: 0.1009
on_train_batch_begin: 1609199731.137371s

2 step training time: 0.068770s

on_train_batch_end: 1609199731.200954s

 3072/50000 [>.............................] - ETA: 3s - loss: 1.5589 - accuracy: 0.1012
on_train_batch_begin: 1609199731.201320s

3 step training time: 0.063950s

on_train_batch_end: 1609199731.266366s

 4096/50000 [=>............................] - ETA: 3s - loss: 1.5602 - accuracy: 0.1013
on_train_batch_begin: 1609199731.266762s

4 step training time: 0.065442s

on_train_batch_end: 1609199731.330066s

 5120/50000 [==>...........................] - ETA: 2s - loss: 1.5823 - accuracy: 0.1012
on_train_batch_begin: 1609199731.330435s

5 step training time: 0.063672s

on_train_batch_end: 1609199731.396569s

 6144/50000 [==>...........................] - ETA: 2s - loss: 1.5848 - accuracy: 0.1011
on_train_batch_begin: 1609199731.396944s

6 step training time: 0.066509s

on_train_batch_end: 1609199731.461854s

 7168/50000 [===>..........................] - ETA: 2s - loss: 1.5905 - accuracy: 0.1011
on_train_batch_begin: 1609199731.462222s

7 step training time: 0.065278s

on_train_batch_end: 1609199731.525979s

 8192/50000 [===>..........................] - ETA: 2s - loss: 1.6006 - accuracy: 0.1011
on_train_batch_begin: 1609199731.526350s

8 step training time: 0.064128s

on_train_batch_end: 1609199731.590795s

 9216/50000 [====>.........................] - ETA: 2s - loss: 1.5938 - accuracy: 0.1012
on_train_batch_begin: 1609199731.591170s

9 step training time: 0.064820s

on_train_batch_end: 1609199731.661362s

10240/50000 [=====>........................] - ETA: 2s - loss: 1.5901 - accuracy: 0.1012
on_train_batch_begin: 1609199731.661735s

10 step training time: 0.070565s

on_train_batch_end: 1609199731.727435s

11264/50000 [=====>........................] - ETA: 2s - loss: 1.5848 - accuracy: 0.1011
on_train_batch_begin: 1609199731.727806s

11 step training time: 0.066071s

on_train_batch_end: 1609199731.792808s

12288/50000 [======>.......................] - ETA: 2s - loss: 1.5788 - accuracy: 0.1011
on_train_batch_begin: 1609199731.793187s

12 step training time: 0.065381s

on_train_batch_end: 1609199731.857392s

13312/50000 [======>.......................] - ETA: 2s - loss: 1.5755 - accuracy: 0.1011
on_train_batch_begin: 1609199731.857762s

13 step training time: 0.064575s

on_train_batch_end: 1609199731.921948s

14336/50000 [=======>......................] - ETA: 2s - loss: 1.5729 - accuracy: 0.1010
on_train_batch_begin: 1609199731.922318s

14 step training time: 0.064555s

on_train_batch_end: 1609199731.986374s

15360/50000 [========>.....................] - ETA: 2s - loss: 1.5766 - accuracy: 0.1009
on_train_batch_begin: 1609199731.986781s

15 step training time: 0.064464s

on_train_batch_end: 1609199732.050929s

16384/50000 [========>.....................] - ETA: 2s - loss: 1.5640 - accuracy: 0.1009
on_train_batch_begin: 1609199732.051304s

16 step training time: 0.064523s

on_train_batch_end: 1609199732.115678s

17408/50000 [=========>....................] - ETA: 2s - loss: 1.5530 - accuracy: 0.1009
on_train_batch_begin: 1609199732.116052s

17 step training time: 0.064748s

on_train_batch_end: 1609199732.187283s

18432/50000 [==========>...................] - ETA: 2s - loss: 1.5497 - accuracy: 0.1009
on_train_batch_begin: 1609199732.187660s

18 step training time: 0.071607s

on_train_batch_end: 1609199732.252647s

19456/50000 [==========>...................] - ETA: 1s - loss: 1.5508 - accuracy: 0.1010
on_train_batch_begin: 1609199732.253022s

19 step training time: 0.065363s

on_train_batch_end: 1609199732.317100s

20480/50000 [===========>..................] - ETA: 1s - loss: 1.5570 - accuracy: 0.1010
on_train_batch_begin: 1609199732.317473s

20 step training time: 0.064451s

on_train_batch_end: 1609199732.382205s

21504/50000 [===========>..................] - ETA: 1s - loss: 1.5541 - accuracy: 0.1010
on_train_batch_begin: 1609199732.382579s

21 step training time: 0.065105s

on_train_batch_end: 1609199732.446677s

22528/50000 [============>.................] - ETA: 1s - loss: 1.5607 - accuracy: 0.1010
on_train_batch_begin: 1609199732.447078s

22 step training time: 0.064500s

on_train_batch_end: 1609199732.515949s

23552/50000 [=============>................] - ETA: 1s - loss: 1.5569 - accuracy: 0.1010
on_train_batch_begin: 1609199732.516326s

23 step training time: 0.069248s

on_train_batch_end: 1609199732.580498s

24576/50000 [=============>................] - ETA: 1s - loss: 1.5594 - accuracy: 0.1010
on_train_batch_begin: 1609199732.580870s

24 step training time: 0.064543s

on_train_batch_end: 1609199732.645017s

25600/50000 [==============>...............] - ETA: 1s - loss: 1.5552 - accuracy: 0.1011
on_train_batch_begin: 1609199732.645385s

25 step training time: 0.064515s

on_train_batch_end: 1609199732.713211s

26624/50000 [==============>...............] - ETA: 1s - loss: 1.5514 - accuracy: 0.1011
on_train_batch_begin: 1609199732.713582s

26 step training time: 0.068197s

on_train_batch_end: 1609199732.779322s

27648/50000 [===============>..............] - ETA: 1s - loss: 1.5493 - accuracy: 0.1011
on_train_batch_begin: 1609199732.779693s

27 step training time: 0.066111s

on_train_batch_end: 1609199732.848221s

28672/50000 [================>.............] - ETA: 1s - loss: 1.5475 - accuracy: 0.1011
on_train_batch_begin: 1609199732.848606s

28 step training time: 0.068913s

on_train_batch_end: 1609199732.912265s

29696/50000 [================>.............] - ETA: 1s - loss: 1.5464 - accuracy: 0.1011
on_train_batch_begin: 1609199732.912639s

29 step training time: 0.064033s

on_train_batch_end: 1609199732.978839s

30720/50000 [=================>............] - ETA: 1s - loss: 1.5458 - accuracy: 0.1011
on_train_batch_begin: 1609199732.979213s

30 step training time: 0.066574s

on_train_batch_end: 1609199733.044018s

31744/50000 [==================>...........] - ETA: 1s - loss: 1.5430 - accuracy: 0.1011
on_train_batch_begin: 1609199733.044415s

31 step training time: 0.065202s

on_train_batch_end: 1609199733.107318s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.5390 - accuracy: 0.1011
on_train_batch_begin: 1609199733.107692s

32 step training time: 0.063277s

on_train_batch_end: 1609199733.175334s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.5343 - accuracy: 0.1011
on_train_batch_begin: 1609199733.175711s

33 step training time: 0.068019s

on_train_batch_end: 1609199733.241403s

34816/50000 [===================>..........] - ETA: 0s - loss: 1.5286 - accuracy: 0.1011
on_train_batch_begin: 1609199733.241775s

34 step training time: 0.066064s

on_train_batch_end: 1609199733.309715s

35840/50000 [====================>.........] - ETA: 0s - loss: 1.5231 - accuracy: 0.1011
on_train_batch_begin: 1609199733.310090s

35 step training time: 0.068315s

on_train_batch_end: 1609199733.375336s

36864/50000 [=====================>........] - ETA: 0s - loss: 1.5242 - accuracy: 0.1010
on_train_batch_begin: 1609199733.375707s

36 step training time: 0.065617s

on_train_batch_end: 1609199733.442137s

37888/50000 [=====================>........] - ETA: 0s - loss: 1.5185 - accuracy: 0.1010
on_train_batch_begin: 1609199733.442512s

37 step training time: 0.066805s

on_train_batch_end: 1609199733.510507s

38912/50000 [======================>.......] - ETA: 0s - loss: 1.5113 - accuracy: 0.1010
on_train_batch_begin: 1609199733.510911s

38 step training time: 0.068399s

on_train_batch_end: 1609199733.575741s

39936/50000 [======================>.......] - ETA: 0s - loss: 1.5079 - accuracy: 0.1010
on_train_batch_begin: 1609199733.576134s

39 step training time: 0.065223s

on_train_batch_end: 1609199733.642092s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.5021 - accuracy: 0.1010
on_train_batch_begin: 1609199733.642465s

40 step training time: 0.066331s

on_train_batch_end: 1609199733.708600s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.4963 - accuracy: 0.1011
on_train_batch_begin: 1609199733.708975s

41 step training time: 0.066510s

on_train_batch_end: 1609199733.772723s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.4908 - accuracy: 0.1011
on_train_batch_begin: 1609199733.773098s

42 step training time: 0.064123s

on_train_batch_end: 1609199733.838990s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.4885 - accuracy: 0.1011
on_train_batch_begin: 1609199733.839364s

43 step training time: 0.066266s

on_train_batch_end: 1609199733.906362s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.4824 - accuracy: 0.1011
on_train_batch_begin: 1609199733.906767s

44 step training time: 0.067404s

on_train_batch_end: 1609199733.970337s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.4776 - accuracy: 0.1011
on_train_batch_begin: 1609199733.970713s

45 step training time: 0.063946s

on_train_batch_end: 1609199734.038697s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.4730 - accuracy: 0.1011
on_train_batch_begin: 1609199734.039095s

46 step training time: 0.068382s

on_train_batch_end: 1609199734.106507s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.4669 - accuracy: 0.1011
on_train_batch_begin: 1609199734.106910s

47 step training time: 0.067815s

on_train_batch_end: 1609199734.170225s

49152/50000 [============================>.] - ETA: 0s - loss: 1.4654 - accuracy: 0.1011
on_train_batch_begin: 1609199734.170594s

48 step training time: 0.063684s

on_train_batch_end: 1609199734.236921s

on_test_batch_begin: 1609199734.256920s

49 step training time: 0.086326s

on_epoch_end: 1609199734.502283s

Validation time: 0.245350s

Real time: 1609199734.502283s

Epoch time: 3.5060746669769287s

50000/50000 [==============================] - 4s 70us/sample - loss: 1.4599 - accuracy: 0.1011 - val_loss: 7.2591 - val_accuracy: 0.0999

on_epoch_begin: 1609199734.502527s

Real time: 1609199734.5025365
Epoch 4/5

on_train_batch_begin: 1609199734.508163s

on_train_batch_end: 1609199734.574839s

 1024/50000 [..............................] - ETA: 3s - loss: 1.1467 - accuracy: 0.1011
on_train_batch_begin: 1609199734.575218s

1 step training time: 0.067055s

on_train_batch_end: 1609199734.642915s

 2048/50000 [>.............................] - ETA: 3s - loss: 1.0911 - accuracy: 0.1009
on_train_batch_begin: 1609199734.643289s

2 step training time: 0.068072s

on_train_batch_end: 1609199734.707632s

 3072/50000 [>.............................] - ETA: 3s - loss: 1.0414 - accuracy: 0.1012
on_train_batch_begin: 1609199734.708008s

3 step training time: 0.064719s

on_train_batch_end: 1609199734.778496s

 4096/50000 [=>............................] - ETA: 3s - loss: 1.0661 - accuracy: 0.1012
on_train_batch_begin: 1609199734.778897s

4 step training time: 0.070889s

on_train_batch_end: 1609199734.847853s

 5120/50000 [==>...........................] - ETA: 3s - loss: 1.0979 - accuracy: 0.1012
on_train_batch_begin: 1609199734.848227s

5 step training time: 0.069330s

on_train_batch_end: 1609199734.918260s

 6144/50000 [==>...........................] - ETA: 2s - loss: 1.0721 - accuracy: 0.1012
on_train_batch_begin: 1609199734.918627s

6 step training time: 0.070400s

on_train_batch_end: 1609199734.984102s

 7168/50000 [===>..........................] - ETA: 2s - loss: 1.0790 - accuracy: 0.1013
on_train_batch_begin: 1609199734.984472s

7 step training time: 0.065845s

on_train_batch_end: 1609199735.052669s

 8192/50000 [===>..........................] - ETA: 2s - loss: 1.0879 - accuracy: 0.1013
on_train_batch_begin: 1609199735.053046s

8 step training time: 0.068573s

on_train_batch_end: 1609199735.120804s

 9216/50000 [====>.........................] - ETA: 2s - loss: 1.0784 - accuracy: 0.1013
on_train_batch_begin: 1609199735.121174s

9 step training time: 0.068129s

on_train_batch_end: 1609199735.185054s

10240/50000 [=====>........................] - ETA: 2s - loss: 1.0703 - accuracy: 0.1013
on_train_batch_begin: 1609199735.185426s

10 step training time: 0.064251s

on_train_batch_end: 1609199735.253289s

11264/50000 [=====>........................] - ETA: 2s - loss: 1.0701 - accuracy: 0.1012
on_train_batch_begin: 1609199735.253658s

11 step training time: 0.068232s

on_train_batch_end: 1609199735.318297s

12288/50000 [======>.......................] - ETA: 2s - loss: 1.0676 - accuracy: 0.1012
on_train_batch_begin: 1609199735.318665s

12 step training time: 0.065007s

on_train_batch_end: 1609199735.386143s

13312/50000 [======>.......................] - ETA: 2s - loss: 1.0580 - accuracy: 0.1013
on_train_batch_begin: 1609199735.386526s

13 step training time: 0.067861s

on_train_batch_end: 1609199735.456894s

14336/50000 [=======>......................] - ETA: 2s - loss: 1.0683 - accuracy: 0.1013
on_train_batch_begin: 1609199735.457308s

14 step training time: 0.070781s

on_train_batch_end: 1609199735.522682s

15360/50000 [========>.....................] - ETA: 2s - loss: 1.0653 - accuracy: 0.1013
on_train_batch_begin: 1609199735.523123s

15 step training time: 0.065815s

on_train_batch_end: 1609199735.587682s

16384/50000 [========>.....................] - ETA: 2s - loss: 1.0698 - accuracy: 0.1013
on_train_batch_begin: 1609199735.588093s

16 step training time: 0.064970s

on_train_batch_end: 1609199735.656247s

17408/50000 [=========>....................] - ETA: 2s - loss: 1.0654 - accuracy: 0.1013
on_train_batch_begin: 1609199735.656661s

17 step training time: 0.068568s

on_train_batch_end: 1609199735.722406s

18432/50000 [==========>...................] - ETA: 2s - loss: 1.0584 - accuracy: 0.1013
on_train_batch_begin: 1609199735.722839s

18 step training time: 0.066178s

on_train_batch_end: 1609199735.787689s

19456/50000 [==========>...................] - ETA: 2s - loss: 1.0581 - accuracy: 0.1013
on_train_batch_begin: 1609199735.788100s

19 step training time: 0.065261s

on_train_batch_end: 1609199735.851174s

20480/50000 [===========>..................] - ETA: 1s - loss: 1.0595 - accuracy: 0.1013
on_train_batch_begin: 1609199735.851589s

20 step training time: 0.063490s

on_train_batch_end: 1609199735.917322s

21504/50000 [===========>..................] - ETA: 1s - loss: 1.0572 - accuracy: 0.1013
on_train_batch_begin: 1609199735.917731s

21 step training time: 0.066141s

on_train_batch_end: 1609199735.982607s

22528/50000 [============>.................] - ETA: 1s - loss: 1.0542 - accuracy: 0.1013
on_train_batch_begin: 1609199735.983041s

22 step training time: 0.065310s

on_train_batch_end: 1609199736.049253s

23552/50000 [=============>................] - ETA: 1s - loss: 1.0591 - accuracy: 0.1013
on_train_batch_begin: 1609199736.049656s

23 step training time: 0.066615s

on_train_batch_end: 1609199736.117832s

24576/50000 [=============>................] - ETA: 1s - loss: 1.0569 - accuracy: 0.1013
on_train_batch_begin: 1609199736.118229s

24 step training time: 0.068573s

on_train_batch_end: 1609199736.185125s

25600/50000 [==============>...............] - ETA: 1s - loss: 1.0530 - accuracy: 0.1013
on_train_batch_begin: 1609199736.185525s

25 step training time: 0.067296s

on_train_batch_end: 1609199736.252183s

26624/50000 [==============>...............] - ETA: 1s - loss: 1.0492 - accuracy: 0.1013
on_train_batch_begin: 1609199736.252581s

26 step training time: 0.067056s

on_train_batch_end: 1609199736.317930s

27648/50000 [===============>..............] - ETA: 1s - loss: 1.0455 - accuracy: 0.1013
on_train_batch_begin: 1609199736.318331s

27 step training time: 0.065750s

on_train_batch_end: 1609199736.382159s

28672/50000 [================>.............] - ETA: 1s - loss: 1.0399 - accuracy: 0.1013
on_train_batch_begin: 1609199736.382562s

28 step training time: 0.064231s

on_train_batch_end: 1609199736.447472s

29696/50000 [================>.............] - ETA: 1s - loss: 1.0363 - accuracy: 0.1013
on_train_batch_begin: 1609199736.447876s

29 step training time: 0.065314s

on_train_batch_end: 1609199736.514057s

30720/50000 [=================>............] - ETA: 1s - loss: 1.0307 - accuracy: 0.1013
on_train_batch_begin: 1609199736.514461s

30 step training time: 0.066584s

on_train_batch_end: 1609199736.584738s

31744/50000 [==================>...........] - ETA: 1s - loss: 1.0285 - accuracy: 0.1013
on_train_batch_begin: 1609199736.585144s

31 step training time: 0.070683s

on_train_batch_end: 1609199736.652834s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.0273 - accuracy: 0.1013
on_train_batch_begin: 1609199736.653233s

32 step training time: 0.068090s

on_train_batch_end: 1609199736.717532s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.0248 - accuracy: 0.1013
on_train_batch_begin: 1609199736.717931s

33 step training time: 0.064697s

on_train_batch_end: 1609199736.783134s

34816/50000 [===================>..........] - ETA: 0s - loss: 1.0278 - accuracy: 0.1013
on_train_batch_begin: 1609199736.783537s

34 step training time: 0.065607s

on_train_batch_end: 1609199736.850850s

35840/50000 [====================>.........] - ETA: 0s - loss: 1.0277 - accuracy: 0.1013
on_train_batch_begin: 1609199736.851255s

35 step training time: 0.067717s

on_train_batch_end: 1609199736.920413s

36864/50000 [=====================>........] - ETA: 0s - loss: 1.0272 - accuracy: 0.1013
on_train_batch_begin: 1609199736.920820s

36 step training time: 0.069566s

on_train_batch_end: 1609199736.989092s

37888/50000 [=====================>........] - ETA: 0s - loss: 1.0270 - accuracy: 0.1013
on_train_batch_begin: 1609199736.989492s

37 step training time: 0.068672s

on_train_batch_end: 1609199737.060861s

38912/50000 [======================>.......] - ETA: 0s - loss: 1.0260 - accuracy: 0.1013
on_train_batch_begin: 1609199737.061270s

38 step training time: 0.071778s

on_train_batch_end: 1609199737.125755s

39936/50000 [======================>.......] - ETA: 0s - loss: 1.0208 - accuracy: 0.1013
on_train_batch_begin: 1609199737.126158s

39 step training time: 0.064888s

on_train_batch_end: 1609199737.189819s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.0169 - accuracy: 0.1013
on_train_batch_begin: 1609199737.190222s

40 step training time: 0.064064s

on_train_batch_end: 1609199737.255455s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.0180 - accuracy: 0.1013
on_train_batch_begin: 1609199737.255852s

41 step training time: 0.065630s

on_train_batch_end: 1609199737.324872s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.0140 - accuracy: 0.1013
on_train_batch_begin: 1609199737.325272s

42 step training time: 0.069420s

on_train_batch_end: 1609199737.390841s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.0137 - accuracy: 0.1013
on_train_batch_begin: 1609199737.391220s

43 step training time: 0.065948s

on_train_batch_end: 1609199737.456197s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.0111 - accuracy: 0.1013
on_train_batch_begin: 1609199737.456570s

44 step training time: 0.065350s

on_train_batch_end: 1609199737.521221s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.0092 - accuracy: 0.1013
on_train_batch_begin: 1609199737.521596s

45 step training time: 0.065026s

on_train_batch_end: 1609199737.590236s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.0079 - accuracy: 0.1013
on_train_batch_begin: 1609199737.590609s

46 step training time: 0.069013s

on_train_batch_end: 1609199737.654632s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.0076 - accuracy: 0.1013
on_train_batch_begin: 1609199737.655061s

47 step training time: 0.064452s

on_train_batch_end: 1609199737.719286s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0044 - accuracy: 0.1013
on_train_batch_begin: 1609199737.719661s

48 step training time: 0.064599s

on_train_batch_end: 1609199737.782569s

on_test_batch_begin: 1609199737.805401s

49 step training time: 0.085741s

on_epoch_end: 1609199738.051770s

Validation time: 0.246355s

Real time: 1609199738.051770s

Epoch time: 3.54925537109375s

50000/50000 [==============================] - 4s 71us/sample - loss: 1.0028 - accuracy: 0.1013 - val_loss: 6.7208 - val_accuracy: 0.0998

on_epoch_begin: 1609199738.052030s

Real time: 1609199738.05204
Epoch 5/5

on_train_batch_begin: 1609199738.057860s

on_train_batch_end: 1609199738.123371s

 1024/50000 [..............................] - ETA: 3s - loss: 0.6539 - accuracy: 0.1015
on_train_batch_begin: 1609199738.123761s

1 step training time: 0.065900s

on_train_batch_end: 1609199738.192131s

 2048/50000 [>.............................] - ETA: 3s - loss: 0.6474 - accuracy: 0.1014
on_train_batch_begin: 1609199738.192516s

2 step training time: 0.068755s

on_train_batch_end: 1609199738.257664s

 3072/50000 [>.............................] - ETA: 3s - loss: 0.6740 - accuracy: 0.1015
on_train_batch_begin: 1609199738.258052s

3 step training time: 0.065536s

on_train_batch_end: 1609199738.322456s

 4096/50000 [=>............................] - ETA: 3s - loss: 0.6796 - accuracy: 0.1015
on_train_batch_begin: 1609199738.322877s

4 step training time: 0.064825s

on_train_batch_end: 1609199738.387278s

 5120/50000 [==>...........................] - ETA: 2s - loss: 0.6891 - accuracy: 0.1014
on_train_batch_begin: 1609199738.387669s

5 step training time: 0.064792s

on_train_batch_end: 1609199738.452208s

 6144/50000 [==>...........................] - ETA: 2s - loss: 0.6937 - accuracy: 0.1015
on_train_batch_begin: 1609199738.452599s

6 step training time: 0.064930s

on_train_batch_end: 1609199738.524099s

 7168/50000 [===>..........................] - ETA: 2s - loss: 0.7221 - accuracy: 0.1016
on_train_batch_begin: 1609199738.524475s

7 step training time: 0.071876s

on_train_batch_end: 1609199738.590861s

 8192/50000 [===>..........................] - ETA: 2s - loss: 0.7180 - accuracy: 0.1016
on_train_batch_begin: 1609199738.591235s

8 step training time: 0.066760s

on_train_batch_end: 1609199738.655814s

 9216/50000 [====>.........................] - ETA: 2s - loss: 0.7131 - accuracy: 0.1015
on_train_batch_begin: 1609199738.656187s

9 step training time: 0.064951s

on_train_batch_end: 1609199738.721164s

10240/50000 [=====>........................] - ETA: 2s - loss: 0.7189 - accuracy: 0.1015
on_train_batch_begin: 1609199738.721536s

10 step training time: 0.065350s

on_train_batch_end: 1609199738.786293s

11264/50000 [=====>........................] - ETA: 2s - loss: 0.7223 - accuracy: 0.1015
on_train_batch_begin: 1609199738.786671s

11 step training time: 0.065135s

on_train_batch_end: 1609199738.850459s

12288/50000 [======>.......................] - ETA: 2s - loss: 0.7262 - accuracy: 0.1016
on_train_batch_begin: 1609199738.850862s

12 step training time: 0.064191s

on_train_batch_end: 1609199738.916054s

13312/50000 [======>.......................] - ETA: 2s - loss: 0.7317 - accuracy: 0.1016
on_train_batch_begin: 1609199738.916428s

13 step training time: 0.065566s

on_train_batch_end: 1609199738.981604s

14336/50000 [=======>......................] - ETA: 2s - loss: 0.7235 - accuracy: 0.1015
on_train_batch_begin: 1609199738.981973s

14 step training time: 0.065546s

on_train_batch_end: 1609199739.048145s

15360/50000 [========>.....................] - ETA: 2s - loss: 0.7293 - accuracy: 0.1016
on_train_batch_begin: 1609199739.048521s

15 step training time: 0.066548s

on_train_batch_end: 1609199739.116467s

16384/50000 [========>.....................] - ETA: 2s - loss: 0.7296 - accuracy: 0.1015
on_train_batch_begin: 1609199739.116845s

16 step training time: 0.068323s

on_train_batch_end: 1609199739.181368s

17408/50000 [=========>....................] - ETA: 2s - loss: 0.7200 - accuracy: 0.1015
on_train_batch_begin: 1609199739.181741s

17 step training time: 0.064896s

on_train_batch_end: 1609199739.247919s

18432/50000 [==========>...................] - ETA: 2s - loss: 0.7245 - accuracy: 0.1016
on_train_batch_begin: 1609199739.248289s

18 step training time: 0.066548s

on_train_batch_end: 1609199739.311791s

19456/50000 [==========>...................] - ETA: 1s - loss: 0.7249 - accuracy: 0.1016
on_train_batch_begin: 1609199739.312160s

19 step training time: 0.063871s

on_train_batch_end: 1609199739.381393s

20480/50000 [===========>..................] - ETA: 1s - loss: 0.7316 - accuracy: 0.1016
on_train_batch_begin: 1609199739.381768s

20 step training time: 0.069607s

on_train_batch_end: 1609199739.448828s

21504/50000 [===========>..................] - ETA: 1s - loss: 0.7282 - accuracy: 0.1016
on_train_batch_begin: 1609199739.449198s

21 step training time: 0.067430s

on_train_batch_end: 1609199739.518420s

22528/50000 [============>.................] - ETA: 1s - loss: 0.7262 - accuracy: 0.1016
on_train_batch_begin: 1609199739.518813s

22 step training time: 0.069614s

on_train_batch_end: 1609199739.585233s

23552/50000 [=============>................] - ETA: 1s - loss: 0.7307 - accuracy: 0.1016
on_train_batch_begin: 1609199739.585613s

23 step training time: 0.066800s

on_train_batch_end: 1609199739.650787s

24576/50000 [=============>................] - ETA: 1s - loss: 0.7255 - accuracy: 0.1015
on_train_batch_begin: 1609199739.651159s

24 step training time: 0.065546s

on_train_batch_end: 1609199739.715877s

25600/50000 [==============>...............] - ETA: 1s - loss: 0.7267 - accuracy: 0.1015
on_train_batch_begin: 1609199739.716285s

25 step training time: 0.065126s

on_train_batch_end: 1609199739.784778s

26624/50000 [==============>...............] - ETA: 1s - loss: 0.7268 - accuracy: 0.1015
on_train_batch_begin: 1609199739.785151s

26 step training time: 0.068866s

on_train_batch_end: 1609199739.850962s

27648/50000 [===============>..............] - ETA: 1s - loss: 0.7255 - accuracy: 0.1016
on_train_batch_begin: 1609199739.851341s

27 step training time: 0.066190s

on_train_batch_end: 1609199739.916691s

28672/50000 [================>.............] - ETA: 1s - loss: 0.7283 - accuracy: 0.1015
on_train_batch_begin: 1609199739.917062s

28 step training time: 0.065721s

on_train_batch_end: 1609199739.982200s

29696/50000 [================>.............] - ETA: 1s - loss: 0.7302 - accuracy: 0.1015
on_train_batch_begin: 1609199739.982574s

29 step training time: 0.065512s

on_train_batch_end: 1609199740.047854s

30720/50000 [=================>............] - ETA: 1s - loss: 0.7278 - accuracy: 0.1015
on_train_batch_begin: 1609199740.048231s

30 step training time: 0.065658s

on_train_batch_end: 1609199740.117419s

31744/50000 [==================>...........] - ETA: 1s - loss: 0.7312 - accuracy: 0.1016
on_train_batch_begin: 1609199740.117788s

31 step training time: 0.069557s

on_train_batch_end: 1609199740.187506s

32768/50000 [==================>...........] - ETA: 1s - loss: 0.7311 - accuracy: 0.1016
on_train_batch_begin: 1609199740.187875s

32 step training time: 0.070086s

on_train_batch_end: 1609199740.257169s

33792/50000 [===================>..........] - ETA: 1s - loss: 0.7322 - accuracy: 0.1015
on_train_batch_begin: 1609199740.257576s

33 step training time: 0.069701s

on_train_batch_end: 1609199740.321984s

34816/50000 [===================>..........] - ETA: 0s - loss: 0.7300 - accuracy: 0.1016
on_train_batch_begin: 1609199740.322418s

34 step training time: 0.064843s

on_train_batch_end: 1609199740.387330s

35840/50000 [====================>.........] - ETA: 0s - loss: 0.7298 - accuracy: 0.1016
on_train_batch_begin: 1609199740.387727s

35 step training time: 0.065309s

on_train_batch_end: 1609199740.453211s

36864/50000 [=====================>........] - ETA: 0s - loss: 0.7265 - accuracy: 0.1016
on_train_batch_begin: 1609199740.453611s

36 step training time: 0.065884s

on_train_batch_end: 1609199740.518642s

37888/50000 [=====================>........] - ETA: 0s - loss: 0.7269 - accuracy: 0.1015
on_train_batch_begin: 1609199740.519081s

37 step training time: 0.065470s

on_train_batch_end: 1609199740.584358s

38912/50000 [======================>.......] - ETA: 0s - loss: 0.7248 - accuracy: 0.1015
on_train_batch_begin: 1609199740.584763s

38 step training time: 0.065682s

on_train_batch_end: 1609199740.651457s

39936/50000 [======================>.......] - ETA: 0s - loss: 0.7252 - accuracy: 0.1015
on_train_batch_begin: 1609199740.651834s

39 step training time: 0.067071s

on_train_batch_end: 1609199740.715135s

40960/50000 [=======================>......] - ETA: 0s - loss: 0.7232 - accuracy: 0.1015
on_train_batch_begin: 1609199740.715512s

40 step training time: 0.063678s

on_train_batch_end: 1609199740.780272s

41984/50000 [========================>.....] - ETA: 0s - loss: 0.7241 - accuracy: 0.1015
on_train_batch_begin: 1609199740.780645s

41 step training time: 0.065134s

on_train_batch_end: 1609199740.845433s

43008/50000 [========================>.....] - ETA: 0s - loss: 0.7231 - accuracy: 0.1015
on_train_batch_begin: 1609199740.845803s

42 step training time: 0.065158s

on_train_batch_end: 1609199740.910072s

44032/50000 [=========================>....] - ETA: 0s - loss: 0.7210 - accuracy: 0.1015
on_train_batch_begin: 1609199740.910448s

43 step training time: 0.064644s

on_train_batch_end: 1609199740.975008s

45056/50000 [==========================>...] - ETA: 0s - loss: 0.7207 - accuracy: 0.1015
on_train_batch_begin: 1609199740.975389s

44 step training time: 0.064941s

on_train_batch_end: 1609199741.043356s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.7206 - accuracy: 0.1015
on_train_batch_begin: 1609199741.043727s

45 step training time: 0.068338s

on_train_batch_end: 1609199741.108291s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.7199 - accuracy: 0.1015
on_train_batch_begin: 1609199741.108665s

46 step training time: 0.064938s

on_train_batch_end: 1609199741.174633s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.7202 - accuracy: 0.1015
on_train_batch_begin: 1609199741.175030s

47 step training time: 0.066365s

on_train_batch_end: 1609199741.239718s

49152/50000 [============================>.] - ETA: 0s - loss: 0.7193 - accuracy: 0.1015
on_train_batch_begin: 1609199741.240111s

48 step training time: 0.065081s

on_train_batch_end: 1609199741.302166s

on_test_batch_begin: 1609199741.325070s

49 step training time: 0.084959s

on_epoch_end: 1609199741.573605s

Validation time: 0.248520s

Real time: 1609199741.573605s

Epoch time: 3.521587371826172s

50000/50000 [==============================] - 4s 70us/sample - loss: 0.7193 - accuracy: 0.1015 - val_loss: 6.2051 - val_accuracy: 0.0999
Tempo do fit: 89.41702342033386