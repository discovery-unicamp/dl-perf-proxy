wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:37
   204800/170498071 [..............................] - ETA: 1:16
   827392/170498071 [..............................] - ETA: 30s 
  2990080/170498071 [..............................] - ETA: 11s
  6365184/170498071 [>.............................] - ETA: 6s 
  9691136/170498071 [>.............................] - ETA: 4s
 13017088/170498071 [=>............................] - ETA: 4s
 16343040/170498071 [=>............................] - ETA: 3s
 19521536/170498071 [==>...........................] - ETA: 3s
 22847488/170498071 [===>..........................] - ETA: 3s
 26173440/170498071 [===>..........................] - ETA: 3s
 29351936/170498071 [====>.........................] - ETA: 2s
 32595968/170498071 [====>.........................] - ETA: 2s
 35921920/170498071 [=====>........................] - ETA: 2s
 39247872/170498071 [=====>........................] - ETA: 2s
 42557440/170498071 [======>.......................] - ETA: 2s
 45801472/170498071 [=======>......................] - ETA: 2s
 49102848/170498071 [=======>......................] - ETA: 2s
 52387840/170498071 [========>.....................] - ETA: 2s
 55730176/170498071 [========>.....................] - ETA: 2s
 58949632/170498071 [=========>....................] - ETA: 1s
 62218240/170498071 [=========>....................] - ETA: 1s
 65478656/170498071 [==========>...................] - ETA: 1s
 68788224/170498071 [===========>..................] - ETA: 1s
 72056832/170498071 [===========>..................] - ETA: 1s
 75358208/170498071 [============>.................] - ETA: 1s
 78675968/170498071 [============>.................] - ETA: 1s
 81928192/170498071 [=============>................] - ETA: 1s
 85213184/170498071 [=============>................] - ETA: 1s
 88498176/170498071 [==============>...............] - ETA: 1s
 91856896/170498071 [===============>..............] - ETA: 1s
 95133696/170498071 [===============>..............] - ETA: 1s
 98459648/170498071 [================>.............] - ETA: 1s
101752832/170498071 [================>.............] - ETA: 1s
105005056/170498071 [=================>............] - ETA: 1s
108224512/170498071 [==================>...........] - ETA: 1s
111599616/170498071 [==================>...........] - ETA: 0s
114860032/170498071 [===================>..........] - ETA: 0s
118169600/170498071 [===================>..........] - ETA: 0s
121536512/170498071 [====================>.........] - ETA: 0s
124805120/170498071 [====================>.........] - ETA: 0s
128147456/170498071 [=====================>........] - ETA: 0s
131325952/170498071 [======================>.......] - ETA: 0s
134692864/170498071 [======================>.......] - ETA: 0s
137895936/170498071 [=======================>......] - ETA: 0s
141156352/170498071 [=======================>......] - ETA: 0s
144465920/170498071 [========================>.....] - ETA: 0s
147759104/170498071 [========================>.....] - ETA: 0s
151117824/170498071 [=========================>....] - ETA: 0s
154411008/170498071 [==========================>...] - ETA: 0s
157753344/170498071 [==========================>...] - ETA: 0s
160964608/170498071 [===========================>..] - ETA: 0s
164249600/170498071 [===========================>..] - ETA: 0s
167469056/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 6930432/94765736 [=>............................] - ETA: 0s
11444224/94765736 [==>...........................] - ETA: 0s
19398656/94765736 [=====>........................] - ETA: 0s
26198016/94765736 [=======>......................] - ETA: 0s
31219712/94765736 [========>.....................] - ETA: 0s
36159488/94765736 [==========>...................] - ETA: 0s
40984576/94765736 [===========>..................] - ETA: 0s
46227456/94765736 [=============>................] - ETA: 0s
51388416/94765736 [===============>..............] - ETA: 0s
56303616/94765736 [================>.............] - ETA: 0s
62504960/94765736 [==================>...........] - ETA: 0s
66510848/94765736 [====================>.........] - ETA: 0s
67158016/94765736 [====================>.........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.406801223754883
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615855482.223872s

Real time: 1615855482.223891
Epoch 1/5

on_train_batch_begin: 1615855482.998998s

on_train_batch_end: 1615855500.771582s

 1024/50000 [..............................] - ETA: 14:47 - loss: 17.8152 - accuracy: 2.0409e-04
on_train_batch_begin: 1615855500.772214s

1 step training time: 17.773216s

on_train_batch_end: 1615855501.094949s

 2048/50000 [>.............................] - ETA: 7:21 - loss: 15.0567 - accuracy: 4.0531e-04 
on_train_batch_begin: 1615855501.095282s

2 step training time: 0.323068s

on_train_batch_end: 1615855501.415036s

 3072/50000 [>.............................] - ETA: 4:53 - loss: 12.9479 - accuracy: 6.9650e-04
on_train_batch_begin: 1615855501.415359s

3 step training time: 0.320077s

on_train_batch_end: 1615855501.736870s

 4096/50000 [=>............................] - ETA: 3:38 - loss: 11.7606 - accuracy: 0.0017    
on_train_batch_begin: 1615855501.737194s

4 step training time: 0.321835s

on_train_batch_end: 1615855502.058008s

 5120/50000 [==>...........................] - ETA: 2:53 - loss: 11.0423 - accuracy: 0.0029
on_train_batch_begin: 1615855502.058312s

5 step training time: 0.321118s

on_train_batch_end: 1615855502.379237s

 6144/50000 [==>...........................] - ETA: 2:23 - loss: 10.5566 - accuracy: 0.0059
on_train_batch_begin: 1615855502.379588s

6 step training time: 0.321276s

on_train_batch_end: 1615855502.700255s

 7168/50000 [===>..........................] - ETA: 2:02 - loss: 10.2072 - accuracy: 0.0092
on_train_batch_begin: 1615855502.700567s

7 step training time: 0.320979s

on_train_batch_end: 1615855503.021122s

 8192/50000 [===>..........................] - ETA: 1:46 - loss: 9.8943 - accuracy: 0.0145 
on_train_batch_begin: 1615855503.021440s

8 step training time: 0.320873s

on_train_batch_end: 1615855503.342775s

 9216/50000 [====>.........................] - ETA: 1:33 - loss: 9.6567 - accuracy: 0.0188
on_train_batch_begin: 1615855503.343084s

9 step training time: 0.321644s

on_train_batch_end: 1615855503.665483s

10240/50000 [=====>........................] - ETA: 1:23 - loss: 9.4573 - accuracy: 0.0229
on_train_batch_begin: 1615855503.665809s

10 step training time: 0.322725s

on_train_batch_end: 1615855503.987656s

11264/50000 [=====>........................] - ETA: 1:14 - loss: 9.2918 - accuracy: 0.0277
on_train_batch_begin: 1615855503.987983s

11 step training time: 0.322174s

on_train_batch_end: 1615855504.310656s

12288/50000 [======>.......................] - ETA: 1:07 - loss: 9.1547 - accuracy: 0.0322
on_train_batch_begin: 1615855504.310978s

12 step training time: 0.322995s

on_train_batch_end: 1615855504.630334s

13312/50000 [======>.......................] - ETA: 1:01 - loss: 9.0367 - accuracy: 0.0359
on_train_batch_begin: 1615855504.630646s

13 step training time: 0.319668s

on_train_batch_end: 1615855504.948854s

14336/50000 [=======>......................] - ETA: 56s - loss: 8.9314 - accuracy: 0.0386 
on_train_batch_begin: 1615855504.949159s

14 step training time: 0.318513s

on_train_batch_end: 1615855505.270575s

15360/50000 [========>.....................] - ETA: 51s - loss: 8.8479 - accuracy: 0.0410
on_train_batch_begin: 1615855505.270893s

15 step training time: 0.321734s

on_train_batch_end: 1615855505.592371s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.7638 - accuracy: 0.0433
on_train_batch_begin: 1615855505.592685s

16 step training time: 0.321792s

on_train_batch_end: 1615855505.915698s

17408/50000 [=========>....................] - ETA: 44s - loss: 8.6893 - accuracy: 0.0459
on_train_batch_begin: 1615855505.916002s

17 step training time: 0.323316s

on_train_batch_end: 1615855506.238865s

18432/50000 [==========>...................] - ETA: 41s - loss: 8.6275 - accuracy: 0.0480
on_train_batch_begin: 1615855506.239169s

18 step training time: 0.323168s

on_train_batch_end: 1615855506.557875s

19456/50000 [==========>...................] - ETA: 38s - loss: 8.5684 - accuracy: 0.0494
on_train_batch_begin: 1615855506.558177s

19 step training time: 0.319008s

on_train_batch_end: 1615855506.877184s

20480/50000 [===========>..................] - ETA: 35s - loss: 8.5075 - accuracy: 0.0507
on_train_batch_begin: 1615855506.877491s

20 step training time: 0.319314s

on_train_batch_end: 1615855507.198775s

21504/50000 [===========>..................] - ETA: 33s - loss: 8.4510 - accuracy: 0.0523
on_train_batch_begin: 1615855507.199086s

21 step training time: 0.321595s

on_train_batch_end: 1615855507.520565s

22528/50000 [============>.................] - ETA: 30s - loss: 8.4025 - accuracy: 0.0537
on_train_batch_begin: 1615855507.520903s

22 step training time: 0.321817s

on_train_batch_end: 1615855507.841200s

23552/50000 [=============>................] - ETA: 28s - loss: 8.3507 - accuracy: 0.0550
on_train_batch_begin: 1615855507.841507s

23 step training time: 0.320604s

on_train_batch_end: 1615855508.157063s

24576/50000 [=============>................] - ETA: 26s - loss: 8.3088 - accuracy: 0.0561
on_train_batch_begin: 1615855508.157375s

24 step training time: 0.315869s

on_train_batch_end: 1615855508.478574s

25600/50000 [==============>...............] - ETA: 25s - loss: 8.2634 - accuracy: 0.0573
on_train_batch_begin: 1615855508.478894s

25 step training time: 0.321519s

on_train_batch_end: 1615855508.801445s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.2208 - accuracy: 0.0583
on_train_batch_begin: 1615855508.801767s

26 step training time: 0.322873s

on_train_batch_end: 1615855509.123350s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.1791 - accuracy: 0.0595
on_train_batch_begin: 1615855509.123652s

27 step training time: 0.321885s

on_train_batch_end: 1615855509.443559s

28672/50000 [================>.............] - ETA: 20s - loss: 8.1583 - accuracy: 0.0592
on_train_batch_begin: 1615855509.443867s

28 step training time: 0.320216s

on_train_batch_end: 1615855509.763198s

29696/50000 [================>.............] - ETA: 18s - loss: 8.1252 - accuracy: 0.0602
on_train_batch_begin: 1615855509.763502s

29 step training time: 0.319635s

on_train_batch_end: 1615855510.085220s

30720/50000 [=================>............] - ETA: 17s - loss: 8.0922 - accuracy: 0.0614
on_train_batch_begin: 1615855510.085523s

30 step training time: 0.322021s

on_train_batch_end: 1615855510.407660s

31744/50000 [==================>...........] - ETA: 16s - loss: 8.0615 - accuracy: 0.0622
on_train_batch_begin: 1615855510.407962s

31 step training time: 0.322439s

on_train_batch_end: 1615855510.732293s

32768/50000 [==================>...........] - ETA: 14s - loss: 8.0263 - accuracy: 0.0631
on_train_batch_begin: 1615855510.732601s

32 step training time: 0.324640s

on_train_batch_end: 1615855511.056598s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.9959 - accuracy: 0.0639
on_train_batch_begin: 1615855511.056935s

33 step training time: 0.324333s

on_train_batch_end: 1615855511.378643s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.9659 - accuracy: 0.0640
on_train_batch_begin: 1615855511.378953s

34 step training time: 0.322018s

on_train_batch_end: 1615855511.703450s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.9355 - accuracy: 0.0646
on_train_batch_begin: 1615855511.703763s

35 step training time: 0.324810s

on_train_batch_end: 1615855512.030327s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.9107 - accuracy: 0.0655
on_train_batch_begin: 1615855512.030634s

36 step training time: 0.326871s

on_train_batch_end: 1615855512.355213s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.8801 - accuracy: 0.0660 
on_train_batch_begin: 1615855512.355525s

37 step training time: 0.324891s

on_train_batch_end: 1615855512.678216s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.8507 - accuracy: 0.0667
on_train_batch_begin: 1615855512.678532s

38 step training time: 0.323007s

on_train_batch_end: 1615855513.001637s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.8225 - accuracy: 0.0674
on_train_batch_begin: 1615855513.001953s

39 step training time: 0.323421s

on_train_batch_end: 1615855513.323694s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.7957 - accuracy: 0.0678
on_train_batch_begin: 1615855513.324003s

40 step training time: 0.322050s

on_train_batch_end: 1615855513.643763s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.7732 - accuracy: 0.0683
on_train_batch_begin: 1615855513.644070s

41 step training time: 0.320068s

on_train_batch_end: 1615855513.966517s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.7438 - accuracy: 0.0686
on_train_batch_begin: 1615855513.966821s

42 step training time: 0.322750s

on_train_batch_end: 1615855514.287567s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.7168 - accuracy: 0.0691
on_train_batch_begin: 1615855514.287873s

43 step training time: 0.321052s

on_train_batch_end: 1615855514.610057s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.6915 - accuracy: 0.0695
on_train_batch_begin: 1615855514.610377s

44 step training time: 0.322504s

on_train_batch_end: 1615855514.932504s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.6646 - accuracy: 0.0699
on_train_batch_begin: 1615855514.932841s

45 step training time: 0.322464s

on_train_batch_end: 1615855515.255555s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.6418 - accuracy: 0.0703
on_train_batch_begin: 1615855515.255875s

46 step training time: 0.323034s

on_train_batch_end: 1615855515.581167s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.6172 - accuracy: 0.0705
on_train_batch_begin: 1615855515.581479s

47 step training time: 0.325603s

on_train_batch_end: 1615855515.905411s

49152/50000 [============================>.] - ETA: 0s - loss: 7.5934 - accuracy: 0.0707
on_train_batch_begin: 1615855515.905720s

48 step training time: 0.324241s

on_train_batch_end: 1615855521.598258s

on_test_batch_begin: 1615855521.789407s

49 step training time: 5.883687s

on_epoch_end: 1615855526.460426s

Validation time: 4.671002s

Real time: 1615855526.460426s

Epoch time: 44.23655390739441s

50000/50000 [==============================] - 44s 885us/sample - loss: 7.5756 - accuracy: 0.0706 - val_loss: 3836.3816 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615855526.460647s

Real time: 1615855526.4606524
Epoch 2/5

on_train_batch_begin: 1615855526.464188s

on_train_batch_end: 1615855526.785547s

 1024/50000 [..............................] - ETA: 15s - loss: 6.2508 - accuracy: 0.0821
on_train_batch_begin: 1615855526.785857s

1 step training time: 0.321669s

on_train_batch_end: 1615855527.108685s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.2149 - accuracy: 0.0829
on_train_batch_begin: 1615855527.109002s

2 step training time: 0.323146s

on_train_batch_end: 1615855527.431879s

 3072/50000 [>.............................] - ETA: 14s - loss: 6.2523 - accuracy: 0.0853
on_train_batch_begin: 1615855527.432181s

3 step training time: 0.323178s

on_train_batch_end: 1615855527.754860s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.3071 - accuracy: 0.0838
on_train_batch_begin: 1615855527.755177s

4 step training time: 0.322996s

on_train_batch_end: 1615855528.079021s

 5120/50000 [==>...........................] - ETA: 14s - loss: 6.3518 - accuracy: 0.0863
on_train_batch_begin: 1615855528.079326s

5 step training time: 0.324150s

on_train_batch_end: 1615855528.402161s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.3259 - accuracy: 0.0869
on_train_batch_begin: 1615855528.402465s

6 step training time: 0.323139s

on_train_batch_end: 1615855528.725972s

 7168/50000 [===>..........................] - ETA: 13s - loss: 6.3053 - accuracy: 0.0860
on_train_batch_begin: 1615855528.726280s

7 step training time: 0.323815s

on_train_batch_end: 1615855529.049672s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.2886 - accuracy: 0.0865
on_train_batch_begin: 1615855529.049972s

8 step training time: 0.323692s

on_train_batch_end: 1615855529.374479s

 9216/50000 [====>.........................] - ETA: 12s - loss: 6.2598 - accuracy: 0.0866
on_train_batch_begin: 1615855529.374781s

9 step training time: 0.324809s

on_train_batch_end: 1615855529.699281s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.2703 - accuracy: 0.0863
on_train_batch_begin: 1615855529.699603s

10 step training time: 0.324822s

on_train_batch_end: 1615855530.023777s

11264/50000 [=====>........................] - ETA: 12s - loss: 6.2596 - accuracy: 0.0865
on_train_batch_begin: 1615855530.024080s

11 step training time: 0.324477s

on_train_batch_end: 1615855530.347668s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.2548 - accuracy: 0.0861
on_train_batch_begin: 1615855530.347974s

12 step training time: 0.323894s

on_train_batch_end: 1615855530.671971s

13312/50000 [======>.......................] - ETA: 11s - loss: 6.2438 - accuracy: 0.0855
on_train_batch_begin: 1615855530.672281s

13 step training time: 0.324307s

on_train_batch_end: 1615855530.997555s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.2432 - accuracy: 0.0854
on_train_batch_begin: 1615855530.997857s

14 step training time: 0.325577s

on_train_batch_end: 1615855531.322123s

15360/50000 [========>.....................] - ETA: 10s - loss: 6.2199 - accuracy: 0.0861
on_train_batch_begin: 1615855531.322423s

15 step training time: 0.324565s

on_train_batch_end: 1615855531.646799s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.2113 - accuracy: 0.0856
on_train_batch_begin: 1615855531.647102s

16 step training time: 0.324679s

on_train_batch_end: 1615855531.970862s

17408/50000 [=========>....................] - ETA: 10s - loss: 6.1993 - accuracy: 0.0847
on_train_batch_begin: 1615855531.971166s

17 step training time: 0.324064s

on_train_batch_end: 1615855532.294917s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.1792 - accuracy: 0.0842 
on_train_batch_begin: 1615855532.295223s

18 step training time: 0.324056s

on_train_batch_end: 1615855532.618854s

19456/50000 [==========>...................] - ETA: 9s - loss: 6.1696 - accuracy: 0.0831
on_train_batch_begin: 1615855532.619153s

19 step training time: 0.323931s

on_train_batch_end: 1615855532.943913s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.1581 - accuracy: 0.0824
on_train_batch_begin: 1615855532.944213s

20 step training time: 0.325059s

on_train_batch_end: 1615855533.268408s

21504/50000 [===========>..................] - ETA: 9s - loss: 6.1471 - accuracy: 0.0812
on_train_batch_begin: 1615855533.268719s

21 step training time: 0.324507s

on_train_batch_end: 1615855533.592622s

22528/50000 [============>.................] - ETA: 8s - loss: 6.1277 - accuracy: 0.0807
on_train_batch_begin: 1615855533.592958s

22 step training time: 0.324239s

on_train_batch_end: 1615855533.916854s

23552/50000 [=============>................] - ETA: 8s - loss: 6.1188 - accuracy: 0.0803
on_train_batch_begin: 1615855533.917163s

23 step training time: 0.324204s

on_train_batch_end: 1615855534.235934s

24576/50000 [=============>................] - ETA: 8s - loss: 6.1039 - accuracy: 0.0802
on_train_batch_begin: 1615855534.236242s

24 step training time: 0.319079s

on_train_batch_end: 1615855534.556525s

25600/50000 [==============>...............] - ETA: 7s - loss: 6.0887 - accuracy: 0.0800
on_train_batch_begin: 1615855534.556851s

25 step training time: 0.320610s

on_train_batch_end: 1615855534.876333s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.0703 - accuracy: 0.0796
on_train_batch_begin: 1615855534.876641s

26 step training time: 0.319789s

on_train_batch_end: 1615855535.199260s

27648/50000 [===============>..............] - ETA: 7s - loss: 6.0509 - accuracy: 0.0793
on_train_batch_begin: 1615855535.199574s

27 step training time: 0.322933s

on_train_batch_end: 1615855535.523385s

28672/50000 [================>.............] - ETA: 6s - loss: 6.0315 - accuracy: 0.0792
on_train_batch_begin: 1615855535.523697s

28 step training time: 0.324123s

on_train_batch_end: 1615855535.845405s

29696/50000 [================>.............] - ETA: 6s - loss: 6.0164 - accuracy: 0.0789
on_train_batch_begin: 1615855535.845720s

29 step training time: 0.322023s

on_train_batch_end: 1615855536.168913s

30720/50000 [=================>............] - ETA: 6s - loss: 6.0026 - accuracy: 0.0784
on_train_batch_begin: 1615855536.169220s

30 step training time: 0.323500s

on_train_batch_end: 1615855536.491972s

31744/50000 [==================>...........] - ETA: 5s - loss: 5.9854 - accuracy: 0.0783
on_train_batch_begin: 1615855536.492297s

31 step training time: 0.323076s

on_train_batch_end: 1615855536.815834s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.9666 - accuracy: 0.0782
on_train_batch_begin: 1615855536.816145s

32 step training time: 0.323848s

on_train_batch_end: 1615855537.139283s

33792/50000 [===================>..........] - ETA: 5s - loss: 5.9527 - accuracy: 0.0780
on_train_batch_begin: 1615855537.139592s

33 step training time: 0.323447s

on_train_batch_end: 1615855537.464191s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.9387 - accuracy: 0.0779
on_train_batch_begin: 1615855537.464495s

34 step training time: 0.324903s

on_train_batch_end: 1615855537.790061s

35840/50000 [====================>.........] - ETA: 4s - loss: 5.9183 - accuracy: 0.0776
on_train_batch_begin: 1615855537.790370s

35 step training time: 0.325875s

on_train_batch_end: 1615855538.114353s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.8968 - accuracy: 0.0772
on_train_batch_begin: 1615855538.114659s

36 step training time: 0.324289s

on_train_batch_end: 1615855538.439032s

37888/50000 [=====================>........] - ETA: 3s - loss: 5.8752 - accuracy: 0.0768
on_train_batch_begin: 1615855538.439336s

37 step training time: 0.324677s

on_train_batch_end: 1615855538.763759s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.8545 - accuracy: 0.0765
on_train_batch_begin: 1615855538.764069s

38 step training time: 0.324734s

on_train_batch_end: 1615855539.087252s

39936/50000 [======================>.......] - ETA: 3s - loss: 5.8341 - accuracy: 0.0762
on_train_batch_begin: 1615855539.087560s

39 step training time: 0.323491s

on_train_batch_end: 1615855539.411771s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.8124 - accuracy: 0.0760
on_train_batch_begin: 1615855539.412071s

40 step training time: 0.324511s

on_train_batch_end: 1615855539.735643s

41984/50000 [========================>.....] - ETA: 2s - loss: 5.7845 - accuracy: 0.0758
on_train_batch_begin: 1615855539.735948s

41 step training time: 0.323878s

on_train_batch_end: 1615855540.059958s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.7600 - accuracy: 0.0755
on_train_batch_begin: 1615855540.060260s

42 step training time: 0.324311s

on_train_batch_end: 1615855540.385098s

44032/50000 [=========================>....] - ETA: 1s - loss: 5.7359 - accuracy: 0.0752
on_train_batch_begin: 1615855540.385400s

43 step training time: 0.325140s

on_train_batch_end: 1615855540.709027s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.7098 - accuracy: 0.0751
on_train_batch_begin: 1615855540.709345s

44 step training time: 0.323945s

on_train_batch_end: 1615855541.033576s

46080/50000 [==========================>...] - ETA: 1s - loss: 5.6816 - accuracy: 0.0749
on_train_batch_begin: 1615855541.033906s

45 step training time: 0.324561s

on_train_batch_end: 1615855541.358780s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.6537 - accuracy: 0.0748
on_train_batch_begin: 1615855541.359089s

46 step training time: 0.325182s

on_train_batch_end: 1615855541.681835s

48128/50000 [===========================>..] - ETA: 0s - loss: 5.6242 - accuracy: 0.0748
on_train_batch_begin: 1615855541.682144s

47 step training time: 0.323056s

on_train_batch_end: 1615855542.000012s

49152/50000 [============================>.] - ETA: 0s - loss: 5.5979 - accuracy: 0.0747
on_train_batch_begin: 1615855542.000324s

48 step training time: 0.318180s

on_train_batch_end: 1615855542.267411s

on_test_batch_begin: 1615855542.278639s

49 step training time: 0.278315s

on_epoch_end: 1615855543.058521s

Validation time: 0.779866s

Real time: 1615855543.058521s

Epoch time: 16.597886085510254s

50000/50000 [==============================] - 17s 332us/sample - loss: 5.5764 - accuracy: 0.0747 - val_loss: 7.6290 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615855543.058719s

Real time: 1615855543.0587246
Epoch 3/5

on_train_batch_begin: 1615855543.062205s

on_train_batch_end: 1615855543.384796s

 1024/50000 [..............................] - ETA: 15s - loss: 3.9074 - accuracy: 0.0769
on_train_batch_begin: 1615855543.385103s

1 step training time: 0.322898s

on_train_batch_end: 1615855543.708122s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.9373 - accuracy: 0.0756
on_train_batch_begin: 1615855543.708430s

2 step training time: 0.323327s

on_train_batch_end: 1615855544.033538s

 3072/50000 [>.............................] - ETA: 14s - loss: 3.9529 - accuracy: 0.0755
on_train_batch_begin: 1615855544.033839s

3 step training time: 0.325409s

on_train_batch_end: 1615855544.357062s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.9089 - accuracy: 0.0767
on_train_batch_begin: 1615855544.357360s

4 step training time: 0.323520s

on_train_batch_end: 1615855544.681642s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.8872 - accuracy: 0.0772
on_train_batch_begin: 1615855544.681952s

5 step training time: 0.324592s

on_train_batch_end: 1615855545.007280s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.8624 - accuracy: 0.0773
on_train_batch_begin: 1615855545.007593s

6 step training time: 0.325641s

on_train_batch_end: 1615855545.333708s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.8341 - accuracy: 0.0782
on_train_batch_begin: 1615855545.334008s

7 step training time: 0.326415s

on_train_batch_end: 1615855545.658379s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.8015 - accuracy: 0.0790
on_train_batch_begin: 1615855545.658680s

8 step training time: 0.324672s

on_train_batch_end: 1615855545.982456s

 9216/50000 [====>.........................] - ETA: 12s - loss: 3.7600 - accuracy: 0.0797
on_train_batch_begin: 1615855545.982760s

9 step training time: 0.324080s

on_train_batch_end: 1615855546.305595s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.7245 - accuracy: 0.0807
on_train_batch_begin: 1615855546.305905s

10 step training time: 0.323145s

on_train_batch_end: 1615855546.631366s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.6996 - accuracy: 0.0813
on_train_batch_begin: 1615855546.631671s

11 step training time: 0.325765s

on_train_batch_end: 1615855546.955460s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.6660 - accuracy: 0.0821
on_train_batch_begin: 1615855546.955779s

12 step training time: 0.324108s

on_train_batch_end: 1615855547.280802s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.6362 - accuracy: 0.0826
on_train_batch_begin: 1615855547.281108s

13 step training time: 0.325330s

on_train_batch_end: 1615855547.604509s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.6003 - accuracy: 0.0831
on_train_batch_begin: 1615855547.604835s

14 step training time: 0.323727s

on_train_batch_end: 1615855547.928516s

15360/50000 [========>.....................] - ETA: 10s - loss: 3.5527 - accuracy: 0.0838
on_train_batch_begin: 1615855547.928863s

15 step training time: 0.324028s

on_train_batch_end: 1615855548.253836s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.5051 - accuracy: 0.0844
on_train_batch_begin: 1615855548.254144s

16 step training time: 0.325281s

on_train_batch_end: 1615855548.577401s

17408/50000 [=========>....................] - ETA: 10s - loss: 3.4550 - accuracy: 0.0849
on_train_batch_begin: 1615855548.577715s

17 step training time: 0.323571s

on_train_batch_end: 1615855548.902792s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.4211 - accuracy: 0.0853
on_train_batch_begin: 1615855548.903135s

18 step training time: 0.325420s

on_train_batch_end: 1615855549.226395s

19456/50000 [==========>...................] - ETA: 9s - loss: 3.3790 - accuracy: 0.0858 
on_train_batch_begin: 1615855549.226739s

19 step training time: 0.323603s

on_train_batch_end: 1615855549.550835s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.3349 - accuracy: 0.0863
on_train_batch_begin: 1615855549.551144s

20 step training time: 0.324405s

on_train_batch_end: 1615855549.874550s

21504/50000 [===========>..................] - ETA: 9s - loss: 3.2944 - accuracy: 0.0868
on_train_batch_begin: 1615855549.874867s

21 step training time: 0.323723s

on_train_batch_end: 1615855550.199079s

22528/50000 [============>.................] - ETA: 8s - loss: 3.2530 - accuracy: 0.0873
on_train_batch_begin: 1615855550.199378s

22 step training time: 0.324511s

on_train_batch_end: 1615855550.522764s

23552/50000 [=============>................] - ETA: 8s - loss: 3.2130 - accuracy: 0.0878
on_train_batch_begin: 1615855550.523067s

23 step training time: 0.323689s

on_train_batch_end: 1615855550.846974s

24576/50000 [=============>................] - ETA: 8s - loss: 3.1704 - accuracy: 0.0883
on_train_batch_begin: 1615855550.847284s

24 step training time: 0.324217s

on_train_batch_end: 1615855551.171205s

25600/50000 [==============>...............] - ETA: 7s - loss: 3.1344 - accuracy: 0.0888
on_train_batch_begin: 1615855551.171509s

25 step training time: 0.324225s

on_train_batch_end: 1615855551.496592s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.0981 - accuracy: 0.0892
on_train_batch_begin: 1615855551.496910s

26 step training time: 0.325401s

on_train_batch_end: 1615855551.820800s

27648/50000 [===============>..............] - ETA: 7s - loss: 3.0650 - accuracy: 0.0896
on_train_batch_begin: 1615855551.821106s

27 step training time: 0.324196s

on_train_batch_end: 1615855552.144583s

28672/50000 [================>.............] - ETA: 6s - loss: 3.0302 - accuracy: 0.0900
on_train_batch_begin: 1615855552.144904s

28 step training time: 0.323798s

on_train_batch_end: 1615855552.467452s

29696/50000 [================>.............] - ETA: 6s - loss: 2.9976 - accuracy: 0.0904
on_train_batch_begin: 1615855552.467752s

29 step training time: 0.322848s

on_train_batch_end: 1615855552.793534s

30720/50000 [=================>............] - ETA: 6s - loss: 2.9663 - accuracy: 0.0907
on_train_batch_begin: 1615855552.793838s

30 step training time: 0.326086s

on_train_batch_end: 1615855553.118377s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.9370 - accuracy: 0.0910
on_train_batch_begin: 1615855553.118685s

31 step training time: 0.324847s

on_train_batch_end: 1615855553.443552s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.9102 - accuracy: 0.0913
on_train_batch_begin: 1615855553.443860s

32 step training time: 0.325176s

on_train_batch_end: 1615855553.767392s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.8827 - accuracy: 0.0915
on_train_batch_begin: 1615855553.767732s

33 step training time: 0.323872s

on_train_batch_end: 1615855554.091936s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.8620 - accuracy: 0.0918
on_train_batch_begin: 1615855554.092302s

34 step training time: 0.324570s

on_train_batch_end: 1615855554.415495s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.8326 - accuracy: 0.0921
on_train_batch_begin: 1615855554.415823s

35 step training time: 0.323522s

on_train_batch_end: 1615855554.739146s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.8057 - accuracy: 0.0923
on_train_batch_begin: 1615855554.739457s

36 step training time: 0.323634s

on_train_batch_end: 1615855555.063746s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.7835 - accuracy: 0.0925
on_train_batch_begin: 1615855555.064060s

37 step training time: 0.324603s

on_train_batch_end: 1615855555.388591s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.7599 - accuracy: 0.0927
on_train_batch_begin: 1615855555.388932s

38 step training time: 0.324872s

on_train_batch_end: 1615855555.714272s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.7362 - accuracy: 0.0929
on_train_batch_begin: 1615855555.714573s

39 step training time: 0.325641s

on_train_batch_end: 1615855556.038054s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.7205 - accuracy: 0.0931
on_train_batch_begin: 1615855556.038364s

40 step training time: 0.323790s

on_train_batch_end: 1615855556.362446s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.6989 - accuracy: 0.0932
on_train_batch_begin: 1615855556.362751s

41 step training time: 0.324388s

on_train_batch_end: 1615855556.687341s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.6806 - accuracy: 0.0934
on_train_batch_begin: 1615855556.687665s

42 step training time: 0.324914s

on_train_batch_end: 1615855557.011749s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.6598 - accuracy: 0.0936
on_train_batch_begin: 1615855557.012057s

43 step training time: 0.324392s

on_train_batch_end: 1615855557.336576s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.6422 - accuracy: 0.0937
on_train_batch_begin: 1615855557.336894s

44 step training time: 0.324837s

on_train_batch_end: 1615855557.660326s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.6193 - accuracy: 0.0939
on_train_batch_begin: 1615855557.660627s

45 step training time: 0.323733s

on_train_batch_end: 1615855557.985399s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.6006 - accuracy: 0.0940
on_train_batch_begin: 1615855557.985697s

46 step training time: 0.325070s

on_train_batch_end: 1615855558.309277s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.5801 - accuracy: 0.0941
on_train_batch_begin: 1615855558.309585s

47 step training time: 0.323888s

on_train_batch_end: 1615855558.634399s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5591 - accuracy: 0.0943
on_train_batch_begin: 1615855558.634696s

48 step training time: 0.325111s

on_train_batch_end: 1615855558.906909s

on_test_batch_begin: 1615855558.919696s

49 step training time: 0.285000s

on_epoch_end: 1615855559.705193s

Validation time: 0.785482s

Real time: 1615855559.705193s

Epoch time: 16.646485805511475s

50000/50000 [==============================] - 17s 333us/sample - loss: 2.5438 - accuracy: 0.0943 - val_loss: 6.9724 - val_accuracy: 0.0999

on_epoch_begin: 1615855559.705388s

Real time: 1615855559.705394
Epoch 4/5

on_train_batch_begin: 1615855559.708823s

on_train_batch_end: 1615855560.033310s

 1024/50000 [..............................] - ETA: 15s - loss: 1.6519 - accuracy: 0.1014
on_train_batch_begin: 1615855560.033619s

1 step training time: 0.324796s

on_train_batch_end: 1615855560.358469s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.7191 - accuracy: 0.1008
on_train_batch_begin: 1615855560.358772s

2 step training time: 0.325152s

on_train_batch_end: 1615855560.685413s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.7151 - accuracy: 0.1006
on_train_batch_begin: 1615855560.685708s

3 step training time: 0.326936s

on_train_batch_end: 1615855561.010133s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.7010 - accuracy: 0.1006
on_train_batch_begin: 1615855561.010438s

4 step training time: 0.324730s

on_train_batch_end: 1615855561.334434s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.7336 - accuracy: 0.1006
on_train_batch_begin: 1615855561.334741s

5 step training time: 0.324303s

on_train_batch_end: 1615855561.658849s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.7111 - accuracy: 0.1005
on_train_batch_begin: 1615855561.659160s

6 step training time: 0.324419s

on_train_batch_end: 1615855561.984308s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.6894 - accuracy: 0.1005
on_train_batch_begin: 1615855561.984619s

7 step training time: 0.325459s

on_train_batch_end: 1615855562.309804s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.6647 - accuracy: 0.1004
on_train_batch_begin: 1615855562.310107s

8 step training time: 0.325488s

on_train_batch_end: 1615855562.634717s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.6463 - accuracy: 0.1004
on_train_batch_begin: 1615855562.635015s

9 step training time: 0.324909s

on_train_batch_end: 1615855562.959540s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.6443 - accuracy: 0.1004
on_train_batch_begin: 1615855562.959851s

10 step training time: 0.324835s

on_train_batch_end: 1615855563.285433s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.6521 - accuracy: 0.1004
on_train_batch_begin: 1615855563.285741s

11 step training time: 0.325891s

on_train_batch_end: 1615855563.611979s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.6360 - accuracy: 0.1004
on_train_batch_begin: 1615855563.612298s

12 step training time: 0.326556s

on_train_batch_end: 1615855563.936548s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.6182 - accuracy: 0.1003
on_train_batch_begin: 1615855563.936890s

13 step training time: 0.324592s

on_train_batch_end: 1615855564.261876s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.6125 - accuracy: 0.1004
on_train_batch_begin: 1615855564.262207s

14 step training time: 0.325317s

on_train_batch_end: 1615855564.585808s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.6065 - accuracy: 0.1004
on_train_batch_begin: 1615855564.586132s

15 step training time: 0.323925s

on_train_batch_end: 1615855564.910002s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.5980 - accuracy: 0.1004
on_train_batch_begin: 1615855564.910316s

16 step training time: 0.324184s

on_train_batch_end: 1615855565.236925s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.5928 - accuracy: 0.1004
on_train_batch_begin: 1615855565.237259s

17 step training time: 0.326943s

on_train_batch_end: 1615855565.562295s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.5770 - accuracy: 0.1004
on_train_batch_begin: 1615855565.562610s

18 step training time: 0.325351s

on_train_batch_end: 1615855565.887152s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.5744 - accuracy: 0.1003 
on_train_batch_begin: 1615855565.887470s

19 step training time: 0.324860s

on_train_batch_end: 1615855566.210845s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.5628 - accuracy: 0.1003
on_train_batch_begin: 1615855566.211169s

20 step training time: 0.323699s

on_train_batch_end: 1615855566.535157s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.5553 - accuracy: 0.1003
on_train_batch_begin: 1615855566.535470s

21 step training time: 0.324301s

on_train_batch_end: 1615855566.860022s

22528/50000 [============>.................] - ETA: 8s - loss: 1.5439 - accuracy: 0.1003
on_train_batch_begin: 1615855566.860335s

22 step training time: 0.324865s

on_train_batch_end: 1615855567.186152s

23552/50000 [=============>................] - ETA: 8s - loss: 1.5322 - accuracy: 0.1003
on_train_batch_begin: 1615855567.186459s

23 step training time: 0.326125s

on_train_batch_end: 1615855567.510904s

24576/50000 [=============>................] - ETA: 8s - loss: 1.5214 - accuracy: 0.1003
on_train_batch_begin: 1615855567.511208s

24 step training time: 0.324748s

on_train_batch_end: 1615855567.834316s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.5060 - accuracy: 0.1003
on_train_batch_begin: 1615855567.834645s

25 step training time: 0.323437s

on_train_batch_end: 1615855568.159947s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.4956 - accuracy: 0.1003
on_train_batch_begin: 1615855568.160280s

26 step training time: 0.325635s

on_train_batch_end: 1615855568.484695s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.4908 - accuracy: 0.1003
on_train_batch_begin: 1615855568.485061s

27 step training time: 0.324781s

on_train_batch_end: 1615855568.809730s

28672/50000 [================>.............] - ETA: 6s - loss: 1.4821 - accuracy: 0.1003
on_train_batch_begin: 1615855568.810036s

28 step training time: 0.324975s

on_train_batch_end: 1615855569.134248s

29696/50000 [================>.............] - ETA: 6s - loss: 1.4750 - accuracy: 0.1003
on_train_batch_begin: 1615855569.134575s

29 step training time: 0.324539s

on_train_batch_end: 1615855569.458802s

30720/50000 [=================>............] - ETA: 6s - loss: 1.4677 - accuracy: 0.1003
on_train_batch_begin: 1615855569.459109s

30 step training time: 0.324534s

on_train_batch_end: 1615855569.783791s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.4610 - accuracy: 0.1003
on_train_batch_begin: 1615855569.784108s

31 step training time: 0.324999s

on_train_batch_end: 1615855570.110914s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.4534 - accuracy: 0.1003
on_train_batch_begin: 1615855570.111223s

32 step training time: 0.327115s

on_train_batch_end: 1615855570.435355s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.4451 - accuracy: 0.1003
on_train_batch_begin: 1615855570.435658s

33 step training time: 0.324435s

on_train_batch_end: 1615855570.760577s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.4364 - accuracy: 0.1002
on_train_batch_begin: 1615855570.760915s

34 step training time: 0.325257s

on_train_batch_end: 1615855571.084709s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.4328 - accuracy: 0.1002
on_train_batch_begin: 1615855571.085048s

35 step training time: 0.324133s

on_train_batch_end: 1615855571.408621s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.4272 - accuracy: 0.1002
on_train_batch_begin: 1615855571.408947s

36 step training time: 0.323899s

on_train_batch_end: 1615855571.732791s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.4211 - accuracy: 0.1002
on_train_batch_begin: 1615855571.733093s

37 step training time: 0.324146s

on_train_batch_end: 1615855572.058337s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.4145 - accuracy: 0.1003
on_train_batch_begin: 1615855572.058644s

38 step training time: 0.325552s

on_train_batch_end: 1615855572.384035s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.4074 - accuracy: 0.1003
on_train_batch_begin: 1615855572.384345s

39 step training time: 0.325700s

on_train_batch_end: 1615855572.707714s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.4027 - accuracy: 0.1003
on_train_batch_begin: 1615855572.708035s

40 step training time: 0.323690s

on_train_batch_end: 1615855573.032300s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.3967 - accuracy: 0.1003
on_train_batch_begin: 1615855573.032604s

41 step training time: 0.324569s

on_train_batch_end: 1615855573.357648s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.3981 - accuracy: 0.1003
on_train_batch_begin: 1615855573.357956s

42 step training time: 0.325352s

on_train_batch_end: 1615855573.683383s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.3958 - accuracy: 0.1003
on_train_batch_begin: 1615855573.683690s

43 step training time: 0.325734s

on_train_batch_end: 1615855574.009141s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.3909 - accuracy: 0.1003
on_train_batch_begin: 1615855574.009449s

44 step training time: 0.325759s

on_train_batch_end: 1615855574.334316s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.3884 - accuracy: 0.1003
on_train_batch_begin: 1615855574.334626s

45 step training time: 0.325177s

on_train_batch_end: 1615855574.657003s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.3862 - accuracy: 0.1003
on_train_batch_begin: 1615855574.657309s

46 step training time: 0.322683s

on_train_batch_end: 1615855574.984187s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.3840 - accuracy: 0.1003
on_train_batch_begin: 1615855574.984506s

47 step training time: 0.327197s

on_train_batch_end: 1615855575.309211s

49152/50000 [============================>.] - ETA: 0s - loss: 1.3790 - accuracy: 0.1003
on_train_batch_begin: 1615855575.309519s

48 step training time: 0.325013s

on_train_batch_end: 1615855575.578856s

on_test_batch_begin: 1615855575.597373s

49 step training time: 0.287854s

on_epoch_end: 1615855576.380200s

Validation time: 0.782812s

Real time: 1615855576.380200s

Epoch time: 16.67482352256775s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.3739 - accuracy: 0.1003 - val_loss: 7.1842 - val_accuracy: 0.0999

on_epoch_begin: 1615855576.380397s

Real time: 1615855576.3804016
Epoch 5/5

on_train_batch_begin: 1615855576.383902s

on_train_batch_end: 1615855576.710964s

 1024/50000 [..............................] - ETA: 15s - loss: 1.1677 - accuracy: 0.0999
on_train_batch_begin: 1615855576.711275s

1 step training time: 0.327373s

on_train_batch_end: 1615855577.035471s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.1134 - accuracy: 0.1003
on_train_batch_begin: 1615855577.035773s

2 step training time: 0.324498s

on_train_batch_end: 1615855577.362385s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.0945 - accuracy: 0.1005
on_train_batch_begin: 1615855577.362682s

3 step training time: 0.326909s

on_train_batch_end: 1615855577.685401s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.0787 - accuracy: 0.1004
on_train_batch_begin: 1615855577.685706s

4 step training time: 0.323024s

on_train_batch_end: 1615855578.011780s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.0508 - accuracy: 0.1004
on_train_batch_begin: 1615855578.012090s

5 step training time: 0.326384s

on_train_batch_end: 1615855578.337139s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.0410 - accuracy: 0.1004
on_train_batch_begin: 1615855578.337441s

6 step training time: 0.325351s

on_train_batch_end: 1615855578.661150s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.0427 - accuracy: 0.1003
on_train_batch_begin: 1615855578.661450s

7 step training time: 0.324008s

on_train_batch_end: 1615855578.986697s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.0403 - accuracy: 0.1003
on_train_batch_begin: 1615855578.987005s

8 step training time: 0.325555s

on_train_batch_end: 1615855579.310939s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.0408 - accuracy: 0.1003
on_train_batch_begin: 1615855579.311249s

9 step training time: 0.324244s

on_train_batch_end: 1615855579.636037s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.0310 - accuracy: 0.1003
on_train_batch_begin: 1615855579.636343s

10 step training time: 0.325094s

on_train_batch_end: 1615855579.959975s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.0237 - accuracy: 0.1003
on_train_batch_begin: 1615855579.960285s

11 step training time: 0.323942s

on_train_batch_end: 1615855580.283729s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.0138 - accuracy: 0.1002
on_train_batch_begin: 1615855580.284031s

12 step training time: 0.323746s

on_train_batch_end: 1615855580.609510s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.0034 - accuracy: 0.1002
on_train_batch_begin: 1615855580.609816s

13 step training time: 0.325785s

on_train_batch_end: 1615855580.934350s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.0079 - accuracy: 0.1002
on_train_batch_begin: 1615855580.934653s

14 step training time: 0.324837s

on_train_batch_end: 1615855581.259030s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.0030 - accuracy: 0.1002
on_train_batch_begin: 1615855581.259336s

15 step training time: 0.324683s

on_train_batch_end: 1615855581.583958s

16384/50000 [========>.....................] - ETA: 10s - loss: 0.9983 - accuracy: 0.1002
on_train_batch_begin: 1615855581.584259s

16 step training time: 0.324923s

on_train_batch_end: 1615855581.906626s

17408/50000 [=========>....................] - ETA: 10s - loss: 0.9976 - accuracy: 0.1003
on_train_batch_begin: 1615855581.906928s

17 step training time: 0.322670s

on_train_batch_end: 1615855582.229672s

18432/50000 [==========>...................] - ETA: 10s - loss: 0.9926 - accuracy: 0.1002
on_train_batch_begin: 1615855582.229984s

18 step training time: 0.323056s

on_train_batch_end: 1615855582.554316s

19456/50000 [==========>...................] - ETA: 9s - loss: 0.9871 - accuracy: 0.1002 
on_train_batch_begin: 1615855582.554614s

19 step training time: 0.324630s

on_train_batch_end: 1615855582.878327s

20480/50000 [===========>..................] - ETA: 9s - loss: 0.9790 - accuracy: 0.1002
on_train_batch_begin: 1615855582.878623s

20 step training time: 0.324009s

on_train_batch_end: 1615855583.203062s

21504/50000 [===========>..................] - ETA: 9s - loss: 0.9717 - accuracy: 0.1003
on_train_batch_begin: 1615855583.203396s

21 step training time: 0.324773s

on_train_batch_end: 1615855583.526222s

22528/50000 [============>.................] - ETA: 8s - loss: 0.9718 - accuracy: 0.1003
on_train_batch_begin: 1615855583.526543s

22 step training time: 0.323147s

on_train_batch_end: 1615855583.851398s

23552/50000 [=============>................] - ETA: 8s - loss: 0.9718 - accuracy: 0.1003
on_train_batch_begin: 1615855583.851721s

23 step training time: 0.325179s

on_train_batch_end: 1615855584.175587s

24576/50000 [=============>................] - ETA: 8s - loss: 0.9690 - accuracy: 0.1003
on_train_batch_begin: 1615855584.175912s

24 step training time: 0.324191s

on_train_batch_end: 1615855584.499806s

25600/50000 [==============>...............] - ETA: 7s - loss: 0.9678 - accuracy: 0.1003
on_train_batch_begin: 1615855584.500135s

25 step training time: 0.324223s

on_train_batch_end: 1615855584.823786s

26624/50000 [==============>...............] - ETA: 7s - loss: 0.9670 - accuracy: 0.1003
on_train_batch_begin: 1615855584.824105s

26 step training time: 0.323970s

on_train_batch_end: 1615855585.148841s

27648/50000 [===============>..............] - ETA: 7s - loss: 0.9645 - accuracy: 0.1002
on_train_batch_begin: 1615855585.149184s

27 step training time: 0.325078s

on_train_batch_end: 1615855585.472752s

28672/50000 [================>.............] - ETA: 6s - loss: 0.9612 - accuracy: 0.1003
on_train_batch_begin: 1615855585.473085s

28 step training time: 0.323901s

on_train_batch_end: 1615855585.798458s

29696/50000 [================>.............] - ETA: 6s - loss: 0.9549 - accuracy: 0.1003
on_train_batch_begin: 1615855585.798790s

29 step training time: 0.325705s

on_train_batch_end: 1615855586.122127s

30720/50000 [=================>............] - ETA: 6s - loss: 0.9511 - accuracy: 0.1003
on_train_batch_begin: 1615855586.122455s

30 step training time: 0.323665s

on_train_batch_end: 1615855586.444715s

31744/50000 [==================>...........] - ETA: 5s - loss: 0.9529 - accuracy: 0.1003
on_train_batch_begin: 1615855586.445061s

31 step training time: 0.322606s

on_train_batch_end: 1615855586.768937s

32768/50000 [==================>...........] - ETA: 5s - loss: 0.9522 - accuracy: 0.1003
on_train_batch_begin: 1615855586.769259s

32 step training time: 0.324198s

on_train_batch_end: 1615855587.093683s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.9544 - accuracy: 0.1003
on_train_batch_begin: 1615855587.094006s

33 step training time: 0.324747s

on_train_batch_end: 1615855587.418369s

34816/50000 [===================>..........] - ETA: 4s - loss: 0.9554 - accuracy: 0.1002
on_train_batch_begin: 1615855587.418686s

34 step training time: 0.324680s

on_train_batch_end: 1615855587.742276s

35840/50000 [====================>.........] - ETA: 4s - loss: 0.9538 - accuracy: 0.1002
on_train_batch_begin: 1615855587.742599s

35 step training time: 0.323913s

on_train_batch_end: 1615855588.068110s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.9497 - accuracy: 0.1003
on_train_batch_begin: 1615855588.068434s

36 step training time: 0.325835s

on_train_batch_end: 1615855588.391793s

37888/50000 [=====================>........] - ETA: 3s - loss: 0.9458 - accuracy: 0.1003
on_train_batch_begin: 1615855588.392112s

37 step training time: 0.323678s

on_train_batch_end: 1615855588.715809s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.9444 - accuracy: 0.1003
on_train_batch_begin: 1615855588.716124s

38 step training time: 0.324012s

on_train_batch_end: 1615855589.040402s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.9427 - accuracy: 0.1003
on_train_batch_begin: 1615855589.040706s

39 step training time: 0.324582s

on_train_batch_end: 1615855589.365101s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.9397 - accuracy: 0.1003
on_train_batch_begin: 1615855589.365413s

40 step training time: 0.324708s

on_train_batch_end: 1615855589.690025s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.9388 - accuracy: 0.1003
on_train_batch_begin: 1615855589.690330s

41 step training time: 0.324916s

on_train_batch_end: 1615855590.013498s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.9346 - accuracy: 0.1003
on_train_batch_begin: 1615855590.013804s

42 step training time: 0.323475s

on_train_batch_end: 1615855590.338538s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.9346 - accuracy: 0.1003
on_train_batch_begin: 1615855590.338847s

43 step training time: 0.325042s

on_train_batch_end: 1615855590.662344s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.9333 - accuracy: 0.1003
on_train_batch_begin: 1615855590.662651s

44 step training time: 0.323804s

on_train_batch_end: 1615855590.986659s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.9335 - accuracy: 0.1003
on_train_batch_begin: 1615855590.986971s

45 step training time: 0.324320s

on_train_batch_end: 1615855591.312028s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.9301 - accuracy: 0.1003
on_train_batch_begin: 1615855591.312340s

46 step training time: 0.325370s

on_train_batch_end: 1615855591.635711s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9271 - accuracy: 0.1003
on_train_batch_begin: 1615855591.636015s

47 step training time: 0.323674s

on_train_batch_end: 1615855591.958576s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9255 - accuracy: 0.1003
on_train_batch_begin: 1615855591.958881s

48 step training time: 0.322866s

on_train_batch_end: 1615855592.228718s

on_test_batch_begin: 1615855592.240260s

49 step training time: 0.281379s

on_epoch_end: 1615855593.028272s

Validation time: 0.787996s

Real time: 1615855593.028272s

Epoch time: 16.647886276245117s

50000/50000 [==============================] - 17s 333us/sample - loss: 0.9239 - accuracy: 0.1003 - val_loss: 6.8686 - val_accuracy: 0.0999
Tempo do fit: 114.25885128974915