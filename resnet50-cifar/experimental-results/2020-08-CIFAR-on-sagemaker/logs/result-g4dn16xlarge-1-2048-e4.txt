wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 6:49
   204800/170498071 [..............................] - ETA: 1:11
  1351680/170498071 [..............................] - ETA: 17s 
  4235264/170498071 [..............................] - ETA: 7s 
  7872512/170498071 [>.............................] - ETA: 4s
 11132928/170498071 [>.............................] - ETA: 4s
 14786560/170498071 [=>............................] - ETA: 3s
 18456576/170498071 [==>...........................] - ETA: 3s
 21929984/170498071 [==>...........................] - ETA: 3s
 25255936/170498071 [===>..........................] - ETA: 2s
 28876800/170498071 [====>.........................] - ETA: 2s
 32546816/170498071 [====>.........................] - ETA: 2s
 35987456/170498071 [=====>........................] - ETA: 2s
 39247872/170498071 [=====>........................] - ETA: 2s
 42844160/170498071 [======>.......................] - ETA: 2s
 46489600/170498071 [=======>......................] - ETA: 2s
 50044928/170498071 [=======>......................] - ETA: 2s
 53288960/170498071 [========>.....................] - ETA: 1s
 56811520/170498071 [========>.....................] - ETA: 1s
 60465152/170498071 [=========>....................] - ETA: 1s
 64102400/170498071 [==========>...................] - ETA: 1s
 67346432/170498071 [==========>...................] - ETA: 1s
 70893568/170498071 [===========>..................] - ETA: 1s
 74407936/170498071 [============>.................] - ETA: 1s
 78077952/170498071 [============>.................] - ETA: 1s
 81403904/170498071 [=============>................] - ETA: 1s
 84844544/170498071 [=============>................] - ETA: 1s
 88408064/170498071 [==============>...............] - ETA: 1s
 91987968/170498071 [===============>..............] - ETA: 1s
 95444992/170498071 [===============>..............] - ETA: 1s
 98721792/170498071 [================>.............] - ETA: 1s
102260736/170498071 [================>.............] - ETA: 1s
105832448/170498071 [=================>............] - ETA: 1s
109436928/170498071 [==================>...........] - ETA: 0s
112697344/170498071 [==================>...........] - ETA: 0s
116154368/170498071 [===================>..........] - ETA: 0s
119709696/170498071 [====================>.........] - ETA: 0s
123265024/170498071 [====================>.........] - ETA: 0s
126689280/170498071 [=====================>........] - ETA: 0s
130048000/170498071 [=====================>........] - ETA: 0s
133570560/170498071 [======================>.......] - ETA: 0s
137125888/170498071 [=======================>......] - ETA: 0s
140697600/170498071 [=======================>......] - ETA: 0s
144007168/170498071 [========================>.....] - ETA: 0s
147513344/170498071 [========================>.....] - ETA: 0s
151101440/170498071 [=========================>....] - ETA: 0s
154664960/170498071 [==========================>...] - ETA: 0s
157999104/170498071 [==========================>...] - ETA: 0s
161374208/170498071 [===========================>..] - ETA: 0s
164962304/170498071 [============================>.] - ETA: 0s
168484864/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
  991232/94765736 [..............................] - ETA: 4s
 6594560/94765736 [=>............................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 0s
24649728/94765736 [======>.......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
35250176/94765736 [==========>...................] - ETA: 0s
37937152/94765736 [===========>..................] - ETA: 0s
43139072/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
54018048/94765736 [================>.............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
61939712/94765736 [==================>...........] - ETA: 0s
65994752/94765736 [===================>..........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
80838656/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
90742784/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.956775188446045
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615689937.756107s

Real time: 1615689937.7561235
Epoch 1/5

on_train_batch_begin: 1615689938.518044s

on_train_batch_end: 1615689960.147634s

 2048/50000 [>.............................] - ETA: 8:44 - loss: 17.9248 - accuracy: 2.4438e-04
on_train_batch_begin: 1615689960.148350s

1 step training time: 21.630306s

on_train_batch_end: 1615689960.792111s

 4096/50000 [=>............................] - ETA: 4:18 - loss: 15.1068 - accuracy: 3.1769e-04
on_train_batch_begin: 1615689960.792510s

2 step training time: 0.644159s

on_train_batch_end: 1615689961.438792s

 6144/50000 [==>...........................] - ETA: 2:49 - loss: 13.1830 - accuracy: 6.8625e-04
on_train_batch_begin: 1615689961.439170s

3 step training time: 0.646661s

on_train_batch_end: 1615689962.077631s

 8192/50000 [===>..........................] - ETA: 2:04 - loss: 11.9906 - accuracy: 0.0016    
on_train_batch_begin: 1615689962.078018s

4 step training time: 0.638848s

on_train_batch_end: 1615689962.723180s

10240/50000 [=====>........................] - ETA: 1:36 - loss: 11.2103 - accuracy: 0.0032
on_train_batch_begin: 1615689962.723546s

5 step training time: 0.645528s

on_train_batch_end: 1615689963.371917s

12288/50000 [======>.......................] - ETA: 1:18 - loss: 10.6395 - accuracy: 0.0065
on_train_batch_begin: 1615689963.372276s

6 step training time: 0.648730s

on_train_batch_end: 1615689964.021255s

14336/50000 [=======>......................] - ETA: 1:05 - loss: 10.2087 - accuracy: 0.0097
on_train_batch_begin: 1615689964.021562s

7 step training time: 0.649287s

on_train_batch_end: 1615689964.668783s

16384/50000 [========>.....................] - ETA: 55s - loss: 9.8510 - accuracy: 0.0133  
on_train_batch_begin: 1615689964.669114s

8 step training time: 0.647552s

on_train_batch_end: 1615689965.311738s

18432/50000 [==========>...................] - ETA: 47s - loss: 9.5577 - accuracy: 0.0175
on_train_batch_begin: 1615689965.312047s

9 step training time: 0.642933s

on_train_batch_end: 1615689965.956534s

20480/50000 [===========>..................] - ETA: 40s - loss: 9.3201 - accuracy: 0.0209
on_train_batch_begin: 1615689965.956915s

10 step training time: 0.644868s

on_train_batch_end: 1615689966.599340s

22528/50000 [============>.................] - ETA: 35s - loss: 9.1182 - accuracy: 0.0247
on_train_batch_begin: 1615689966.599719s

11 step training time: 0.642804s

on_train_batch_end: 1615689967.246398s

24576/50000 [=============>................] - ETA: 30s - loss: 8.9512 - accuracy: 0.0286
on_train_batch_begin: 1615689967.246767s

12 step training time: 0.647048s

on_train_batch_end: 1615689967.890585s

26624/50000 [==============>...............] - ETA: 26s - loss: 8.7955 - accuracy: 0.0316
on_train_batch_begin: 1615689967.890963s

13 step training time: 0.644196s

on_train_batch_end: 1615689968.534764s

28672/50000 [================>.............] - ETA: 22s - loss: 8.6532 - accuracy: 0.0337
on_train_batch_begin: 1615689968.535121s

14 step training time: 0.644158s

on_train_batch_end: 1615689969.182368s

30720/50000 [=================>............] - ETA: 19s - loss: 8.5293 - accuracy: 0.0353
on_train_batch_begin: 1615689969.182746s

15 step training time: 0.647625s

on_train_batch_end: 1615689969.827092s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.4142 - accuracy: 0.0367
on_train_batch_begin: 1615689969.827464s

16 step training time: 0.644718s

on_train_batch_end: 1615689970.472386s

34816/50000 [===================>..........] - ETA: 14s - loss: 8.3100 - accuracy: 0.0383
on_train_batch_begin: 1615689970.472749s

17 step training time: 0.645285s

on_train_batch_end: 1615689971.123485s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.2112 - accuracy: 0.0398
on_train_batch_begin: 1615689971.123854s

18 step training time: 0.651105s

on_train_batch_end: 1615689971.762899s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.1275 - accuracy: 0.0416 
on_train_batch_begin: 1615689971.763265s

19 step training time: 0.639411s

on_train_batch_end: 1615689972.407884s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.0457 - accuracy: 0.0429
on_train_batch_begin: 1615689972.408266s

20 step training time: 0.645001s

on_train_batch_end: 1615689973.051390s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.9752 - accuracy: 0.0445
on_train_batch_begin: 1615689973.051770s

21 step training time: 0.643504s

on_train_batch_end: 1615689973.703215s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.9025 - accuracy: 0.0458
on_train_batch_begin: 1615689973.703590s

22 step training time: 0.651820s

on_train_batch_end: 1615689974.350271s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.8312 - accuracy: 0.0472
on_train_batch_begin: 1615689974.350625s

23 step training time: 0.647034s

on_train_batch_end: 1615689974.992395s

49152/50000 [============================>.] - ETA: 0s - loss: 7.7656 - accuracy: 0.0484
on_train_batch_begin: 1615689974.992773s

24 step training time: 0.642148s

on_train_batch_end: 1615689980.761993s

on_test_batch_begin: 1615689980.949503s

25 step training time: 5.956730s

on_epoch_end: 1615689986.337324s

Validation time: 5.387807s

Real time: 1615689986.337324s

Epoch time: 48.58121943473816s

50000/50000 [==============================] - 49s 972us/sample - loss: 7.7400 - accuracy: 0.0486 - val_loss: 23980.1124 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615689986.337548s

Real time: 1615689986.3375542
Epoch 2/5

on_train_batch_begin: 1615689986.340915s

on_train_batch_end: 1615689986.955161s

 2048/50000 [>.............................] - ETA: 14s - loss: 6.0555 - accuracy: 0.0825
on_train_batch_begin: 1615689986.955441s

1 step training time: 0.614526s

on_train_batch_end: 1615689987.609116s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.0433 - accuracy: 0.0828
on_train_batch_begin: 1615689987.609407s

2 step training time: 0.653966s

on_train_batch_end: 1615689988.250863s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.9975 - accuracy: 0.0830
on_train_batch_begin: 1615689988.251239s

3 step training time: 0.641831s

on_train_batch_end: 1615689988.901581s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.9504 - accuracy: 0.0823
on_train_batch_begin: 1615689988.901944s

4 step training time: 0.650706s

on_train_batch_end: 1615689989.545820s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.9380 - accuracy: 0.0817
on_train_batch_begin: 1615689989.546185s

5 step training time: 0.644240s

on_train_batch_end: 1615689990.188295s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.9108 - accuracy: 0.0814
on_train_batch_begin: 1615689990.188667s

6 step training time: 0.642483s

on_train_batch_end: 1615689990.808215s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.8802 - accuracy: 0.0812
on_train_batch_begin: 1615689990.808582s

7 step training time: 0.619915s

on_train_batch_end: 1615689991.458590s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.8455 - accuracy: 0.0805
on_train_batch_begin: 1615689991.458958s

8 step training time: 0.650377s

on_train_batch_end: 1615689992.101990s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.8171 - accuracy: 0.0794 
on_train_batch_begin: 1615689992.102359s

9 step training time: 0.643400s

on_train_batch_end: 1615689992.750637s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.7836 - accuracy: 0.0789
on_train_batch_begin: 1615689992.751009s

10 step training time: 0.648650s

on_train_batch_end: 1615689993.392018s

22528/50000 [============>.................] - ETA: 8s - loss: 5.7580 - accuracy: 0.0775
on_train_batch_begin: 1615689993.392386s

11 step training time: 0.641377s

on_train_batch_end: 1615689994.037345s

24576/50000 [=============>................] - ETA: 7s - loss: 5.7286 - accuracy: 0.0766
on_train_batch_begin: 1615689994.037710s

12 step training time: 0.645324s

on_train_batch_end: 1615689994.681424s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.7035 - accuracy: 0.0755
on_train_batch_begin: 1615689994.681793s

13 step training time: 0.644083s

on_train_batch_end: 1615689995.329834s

28672/50000 [================>.............] - ETA: 6s - loss: 5.6721 - accuracy: 0.0745
on_train_batch_begin: 1615689995.330199s

14 step training time: 0.648406s

on_train_batch_end: 1615689995.974734s

30720/50000 [=================>............] - ETA: 6s - loss: 5.6405 - accuracy: 0.0738
on_train_batch_begin: 1615689995.975101s

15 step training time: 0.644902s

on_train_batch_end: 1615689996.622458s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.6055 - accuracy: 0.0730
on_train_batch_begin: 1615689996.622827s

16 step training time: 0.647726s

on_train_batch_end: 1615689997.270579s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.5686 - accuracy: 0.0724
on_train_batch_begin: 1615689997.270946s

17 step training time: 0.648119s

on_train_batch_end: 1615689997.915530s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.5336 - accuracy: 0.0718
on_train_batch_begin: 1615689997.915901s

18 step training time: 0.644955s

on_train_batch_end: 1615689998.557464s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.5028 - accuracy: 0.0714
on_train_batch_begin: 1615689998.557829s

19 step training time: 0.641928s

on_train_batch_end: 1615689999.200958s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.4724 - accuracy: 0.0710
on_train_batch_begin: 1615689999.201381s

20 step training time: 0.643552s

on_train_batch_end: 1615689999.847629s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.4417 - accuracy: 0.0707
on_train_batch_begin: 1615689999.848004s

21 step training time: 0.646623s

on_train_batch_end: 1615690000.493833s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.4113 - accuracy: 0.0704
on_train_batch_begin: 1615690000.494209s

22 step training time: 0.646204s

on_train_batch_end: 1615690001.145796s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.3800 - accuracy: 0.0700
on_train_batch_begin: 1615690001.146168s

23 step training time: 0.651959s

on_train_batch_end: 1615690001.790484s

49152/50000 [============================>.] - ETA: 0s - loss: 5.3566 - accuracy: 0.0697
on_train_batch_begin: 1615690001.790850s

24 step training time: 0.644683s

on_train_batch_end: 1615690002.068118s

on_test_batch_begin: 1615690002.190429s

25 step training time: 0.399579s

on_epoch_end: 1615690003.104674s

Validation time: 0.914224s

Real time: 1615690003.104674s

Epoch time: 16.7671377658844s

50000/50000 [==============================] - 17s 335us/sample - loss: 5.3427 - accuracy: 0.0697 - val_loss: 8.6954 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615690003.104882s

Real time: 1615690003.104888
Epoch 3/5

on_train_batch_begin: 1615690003.108271s

on_train_batch_end: 1615690003.751978s

 2048/50000 [>.............................] - ETA: 15s - loss: 4.5125 - accuracy: 0.0667
on_train_batch_begin: 1615690003.752279s

1 step training time: 0.644008s

on_train_batch_end: 1615690004.408222s

 4096/50000 [=>............................] - ETA: 14s - loss: 4.3958 - accuracy: 0.0689
on_train_batch_begin: 1615690004.408517s

2 step training time: 0.656238s

on_train_batch_end: 1615690005.053871s

 6144/50000 [==>...........................] - ETA: 13s - loss: 4.3729 - accuracy: 0.0693
on_train_batch_begin: 1615690005.054251s

3 step training time: 0.645734s

on_train_batch_end: 1615690005.703176s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.3915 - accuracy: 0.0695
on_train_batch_begin: 1615690005.703545s

4 step training time: 0.649294s

on_train_batch_end: 1615690006.351835s

10240/50000 [=====>........................] - ETA: 12s - loss: 4.3902 - accuracy: 0.0701
on_train_batch_begin: 1615690006.352202s

5 step training time: 0.648657s

on_train_batch_end: 1615690006.998470s

12288/50000 [======>.......................] - ETA: 11s - loss: 4.3929 - accuracy: 0.0706
on_train_batch_begin: 1615690006.998835s

6 step training time: 0.646633s

on_train_batch_end: 1615690007.641491s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.3857 - accuracy: 0.0720
on_train_batch_begin: 1615690007.641853s

7 step training time: 0.643019s

on_train_batch_end: 1615690008.285690s

16384/50000 [========>.....................] - ETA: 10s - loss: 4.3530 - accuracy: 0.0734
on_train_batch_begin: 1615690008.286058s

8 step training time: 0.644205s

on_train_batch_end: 1615690008.934270s

18432/50000 [==========>...................] - ETA: 9s - loss: 4.3382 - accuracy: 0.0749 
on_train_batch_begin: 1615690008.934642s

9 step training time: 0.648584s

on_train_batch_end: 1615690009.581831s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.2941 - accuracy: 0.0760
on_train_batch_begin: 1615690009.582196s

10 step training time: 0.647553s

on_train_batch_end: 1615690010.230836s

22528/50000 [============>.................] - ETA: 8s - loss: 4.2622 - accuracy: 0.0771
on_train_batch_begin: 1615690010.231200s

11 step training time: 0.649005s

on_train_batch_end: 1615690010.878082s

24576/50000 [=============>................] - ETA: 8s - loss: 4.2240 - accuracy: 0.0779
on_train_batch_begin: 1615690010.878443s

12 step training time: 0.647242s

on_train_batch_end: 1615690011.526839s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.2004 - accuracy: 0.0785
on_train_batch_begin: 1615690011.527204s

13 step training time: 0.648762s

on_train_batch_end: 1615690012.175929s

28672/50000 [================>.............] - ETA: 6s - loss: 4.1836 - accuracy: 0.0793
on_train_batch_begin: 1615690012.176293s

14 step training time: 0.649089s

on_train_batch_end: 1615690012.825407s

30720/50000 [=================>............] - ETA: 6s - loss: 4.1520 - accuracy: 0.0801
on_train_batch_begin: 1615690012.825770s

15 step training time: 0.649477s

on_train_batch_end: 1615690013.474053s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.1191 - accuracy: 0.0810
on_train_batch_begin: 1615690013.474421s

16 step training time: 0.648650s

on_train_batch_end: 1615690014.119688s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.0912 - accuracy: 0.0817
on_train_batch_begin: 1615690014.120050s

17 step training time: 0.645630s

on_train_batch_end: 1615690014.770899s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.0597 - accuracy: 0.0823
on_train_batch_begin: 1615690014.771260s

18 step training time: 0.651210s

on_train_batch_end: 1615690015.414781s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.0271 - accuracy: 0.0830
on_train_batch_begin: 1615690015.415151s

19 step training time: 0.643890s

on_train_batch_end: 1615690016.068340s

40960/50000 [=======================>......] - ETA: 2s - loss: 3.9978 - accuracy: 0.0837
on_train_batch_begin: 1615690016.068705s

20 step training time: 0.653554s

on_train_batch_end: 1615690016.712326s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.9705 - accuracy: 0.0842
on_train_batch_begin: 1615690016.712706s

21 step training time: 0.644001s

on_train_batch_end: 1615690017.367201s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.9485 - accuracy: 0.0848
on_train_batch_begin: 1615690017.367573s

22 step training time: 0.654867s

on_train_batch_end: 1615690018.013483s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.9244 - accuracy: 0.0854
on_train_batch_begin: 1615690018.013852s

23 step training time: 0.646279s

on_train_batch_end: 1615690018.662236s

49152/50000 [============================>.] - ETA: 0s - loss: 3.9011 - accuracy: 0.0859
on_train_batch_begin: 1615690018.662601s

24 step training time: 0.648749s

on_train_batch_end: 1615690018.938095s

on_test_batch_begin: 1615690019.068111s

25 step training time: 0.405510s

on_epoch_end: 1615690019.980307s

Validation time: 0.912173s

Real time: 1615690019.980307s

Epoch time: 16.875441789627075s

50000/50000 [==============================] - 17s 338us/sample - loss: 3.8934 - accuracy: 0.0859 - val_loss: 9.3416 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615690019.980536s

Real time: 1615690019.9805424
Epoch 4/5

on_train_batch_begin: 1615690019.984100s

on_train_batch_end: 1615690020.629598s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.1466 - accuracy: 0.0978
on_train_batch_begin: 1615690020.629966s

1 step training time: 0.645866s

on_train_batch_end: 1615690021.284258s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.1717 - accuracy: 0.0975
on_train_batch_begin: 1615690021.284627s

2 step training time: 0.654661s

on_train_batch_end: 1615690021.930660s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.1568 - accuracy: 0.0975
on_train_batch_begin: 1615690021.931031s

3 step training time: 0.646404s

on_train_batch_end: 1615690022.582676s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.1716 - accuracy: 0.0977
on_train_batch_begin: 1615690022.583043s

4 step training time: 0.652012s

on_train_batch_end: 1615690023.229647s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.1821 - accuracy: 0.0978
on_train_batch_begin: 1615690023.230016s

5 step training time: 0.646972s

on_train_batch_end: 1615690023.879827s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.1876 - accuracy: 0.0981
on_train_batch_begin: 1615690023.880203s

6 step training time: 0.650187s

on_train_batch_end: 1615690024.528003s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.1777 - accuracy: 0.0984
on_train_batch_begin: 1615690024.528373s

7 step training time: 0.648170s

on_train_batch_end: 1615690025.176515s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.1725 - accuracy: 0.0984
on_train_batch_begin: 1615690025.176900s

8 step training time: 0.648527s

on_train_batch_end: 1615690025.828739s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.1594 - accuracy: 0.0985
on_train_batch_begin: 1615690025.829129s

9 step training time: 0.652230s

on_train_batch_end: 1615690026.477520s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.1317 - accuracy: 0.0986 
on_train_batch_begin: 1615690026.477892s

10 step training time: 0.648762s

on_train_batch_end: 1615690027.126636s

22528/50000 [============>.................] - ETA: 8s - loss: 3.1155 - accuracy: 0.0985
on_train_batch_begin: 1615690027.127008s

11 step training time: 0.649117s

on_train_batch_end: 1615690027.777472s

24576/50000 [=============>................] - ETA: 8s - loss: 3.1025 - accuracy: 0.0986
on_train_batch_begin: 1615690027.777837s

12 step training time: 0.650829s

on_train_batch_end: 1615690028.428162s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.0897 - accuracy: 0.0986
on_train_batch_begin: 1615690028.428537s

13 step training time: 0.650700s

on_train_batch_end: 1615690029.074864s

28672/50000 [================>.............] - ETA: 6s - loss: 3.0771 - accuracy: 0.0986
on_train_batch_begin: 1615690029.075230s

14 step training time: 0.646692s

on_train_batch_end: 1615690029.724702s

30720/50000 [=================>............] - ETA: 6s - loss: 3.0650 - accuracy: 0.0986
on_train_batch_begin: 1615690029.725069s

15 step training time: 0.649839s

on_train_batch_end: 1615690030.375993s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.0531 - accuracy: 0.0985
on_train_batch_begin: 1615690030.376362s

16 step training time: 0.651294s

on_train_batch_end: 1615690031.026544s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.0325 - accuracy: 0.0986
on_train_batch_begin: 1615690031.026923s

17 step training time: 0.650561s

on_train_batch_end: 1615690031.678020s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.0166 - accuracy: 0.0987
on_train_batch_begin: 1615690031.678387s

18 step training time: 0.651464s

on_train_batch_end: 1615690032.326538s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.9968 - accuracy: 0.0988
on_train_batch_begin: 1615690032.326912s

19 step training time: 0.648525s

on_train_batch_end: 1615690032.978437s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.9883 - accuracy: 0.0988
on_train_batch_begin: 1615690032.978804s

20 step training time: 0.651892s

on_train_batch_end: 1615690033.625436s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.9743 - accuracy: 0.0988
on_train_batch_begin: 1615690033.625802s

21 step training time: 0.646998s

on_train_batch_end: 1615690034.278762s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.9640 - accuracy: 0.0988
on_train_batch_begin: 1615690034.279131s

22 step training time: 0.653329s

on_train_batch_end: 1615690034.929594s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.9547 - accuracy: 0.0988
on_train_batch_begin: 1615690034.929960s

23 step training time: 0.650829s

on_train_batch_end: 1615690035.577518s

49152/50000 [============================>.] - ETA: 0s - loss: 2.9442 - accuracy: 0.0988
on_train_batch_begin: 1615690035.577884s

24 step training time: 0.647924s

on_train_batch_end: 1615690035.850604s

on_test_batch_begin: 1615690035.983361s

25 step training time: 0.405477s

on_epoch_end: 1615690036.904569s

Validation time: 0.921187s

Real time: 1615690036.904569s

Epoch time: 16.92404794692993s

50000/50000 [==============================] - 17s 338us/sample - loss: 2.9379 - accuracy: 0.0988 - val_loss: 7.7706 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615690036.904791s

Real time: 1615690036.904797
Epoch 5/5

on_train_batch_begin: 1615690036.908368s

on_train_batch_end: 1615690037.563298s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.6994 - accuracy: 0.1005
on_train_batch_begin: 1615690037.563646s

1 step training time: 0.655277s

on_train_batch_end: 1615690038.218088s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.6502 - accuracy: 0.1000
on_train_batch_begin: 1615690038.218386s

2 step training time: 0.654741s

on_train_batch_end: 1615690038.866713s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.5703 - accuracy: 0.1003
on_train_batch_begin: 1615690038.867007s

3 step training time: 0.648620s

on_train_batch_end: 1615690039.518675s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.5440 - accuracy: 0.1002
on_train_batch_begin: 1615690039.518981s

4 step training time: 0.651975s

on_train_batch_end: 1615690040.168205s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.5273 - accuracy: 0.1003
on_train_batch_begin: 1615690040.168503s

5 step training time: 0.649522s

on_train_batch_end: 1615690040.818408s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.5108 - accuracy: 0.1002
on_train_batch_begin: 1615690040.818703s

6 step training time: 0.650200s

on_train_batch_end: 1615690041.467333s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.4874 - accuracy: 0.1001
on_train_batch_begin: 1615690041.467627s

7 step training time: 0.648924s

on_train_batch_end: 1615690042.119322s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.4548 - accuracy: 0.1001
on_train_batch_begin: 1615690042.119619s

8 step training time: 0.651991s

on_train_batch_end: 1615690042.765601s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.4388 - accuracy: 0.1001
on_train_batch_begin: 1615690042.765900s

9 step training time: 0.646281s

on_train_batch_end: 1615690043.418801s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.4203 - accuracy: 0.1000 
on_train_batch_begin: 1615690043.419100s

10 step training time: 0.653200s

on_train_batch_end: 1615690044.069671s

22528/50000 [============>.................] - ETA: 8s - loss: 2.3970 - accuracy: 0.1000
on_train_batch_begin: 1615690044.069964s

11 step training time: 0.650864s

on_train_batch_end: 1615690044.727539s

24576/50000 [=============>................] - ETA: 8s - loss: 2.3827 - accuracy: 0.1001
on_train_batch_begin: 1615690044.727836s

12 step training time: 0.657872s

on_train_batch_end: 1615690045.378258s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.3747 - accuracy: 0.1000
on_train_batch_begin: 1615690045.378556s

13 step training time: 0.650720s

on_train_batch_end: 1615690046.030303s

28672/50000 [================>.............] - ETA: 6s - loss: 2.3470 - accuracy: 0.1000
on_train_batch_begin: 1615690046.030603s

14 step training time: 0.652048s

on_train_batch_end: 1615690046.680931s

30720/50000 [=================>............] - ETA: 6s - loss: 2.3380 - accuracy: 0.1000
on_train_batch_begin: 1615690046.681252s

15 step training time: 0.650649s

on_train_batch_end: 1615690047.330823s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.3157 - accuracy: 0.1000
on_train_batch_begin: 1615690047.331120s

16 step training time: 0.649868s

on_train_batch_end: 1615690047.980249s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.3014 - accuracy: 0.1000
on_train_batch_begin: 1615690047.980547s

17 step training time: 0.649427s

on_train_batch_end: 1615690048.639020s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.2803 - accuracy: 0.1000
on_train_batch_begin: 1615690048.639323s

18 step training time: 0.658776s

on_train_batch_end: 1615690049.288406s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.2702 - accuracy: 0.1000
on_train_batch_begin: 1615690049.288711s

19 step training time: 0.649388s

on_train_batch_end: 1615690049.940862s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.2609 - accuracy: 0.1000
on_train_batch_begin: 1615690049.941204s

20 step training time: 0.652494s

on_train_batch_end: 1615690050.590559s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.2433 - accuracy: 0.1000
on_train_batch_begin: 1615690050.590854s

21 step training time: 0.649650s

on_train_batch_end: 1615690051.237614s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.2351 - accuracy: 0.1001
on_train_batch_begin: 1615690051.237911s

22 step training time: 0.647057s

on_train_batch_end: 1615690051.892445s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.2236 - accuracy: 0.1001
on_train_batch_begin: 1615690051.892747s

23 step training time: 0.654836s

on_train_batch_end: 1615690052.537388s

49152/50000 [============================>.] - ETA: 0s - loss: 2.2170 - accuracy: 0.1001
on_train_batch_begin: 1615690052.537682s

24 step training time: 0.644935s

on_train_batch_end: 1615690052.815476s

on_test_batch_begin: 1615690052.943586s

25 step training time: 0.405904s

on_epoch_end: 1615690053.852902s

Validation time: 0.909301s

Real time: 1615690053.852902s

Epoch time: 16.948121070861816s

50000/50000 [==============================] - 17s 339us/sample - loss: 2.2106 - accuracy: 0.1001 - val_loss: 7.3787 - val_accuracy: 0.1001
Tempo do fit: 119.76717400550842