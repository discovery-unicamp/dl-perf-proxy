wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:53
   221184/170498071 [..............................] - ETA: 1:11
  1122304/170498071 [..............................] - ETA: 21s 
  3465216/170498071 [..............................] - ETA: 9s 
  6471680/170498071 [>.............................] - ETA: 6s
  9814016/170498071 [>.............................] - ETA: 4s
 13148160/170498071 [=>............................] - ETA: 4s
 16416768/170498071 [=>............................] - ETA: 3s
 19767296/170498071 [==>...........................] - ETA: 3s
 23044096/170498071 [===>..........................] - ETA: 3s
 26222592/170498071 [===>..........................] - ETA: 2s
 29417472/170498071 [====>.........................] - ETA: 2s
 32645120/170498071 [====>.........................] - ETA: 2s
 35971072/170498071 [=====>........................] - ETA: 2s
 39116800/170498071 [=====>........................] - ETA: 2s
 42459136/170498071 [======>.......................] - ETA: 2s
 45752320/170498071 [=======>......................] - ETA: 2s
 49045504/170498071 [=======>......................] - ETA: 2s
 52314112/170498071 [========>.....................] - ETA: 2s
 55631872/170498071 [========>.....................] - ETA: 2s
 58957824/170498071 [=========>....................] - ETA: 1s
 62193664/170498071 [=========>....................] - ETA: 1s
 65347584/170498071 [==========>...................] - ETA: 1s
 68788224/170498071 [===========>..................] - ETA: 1s
 72105984/170498071 [===========>..................] - ETA: 1s
 75423744/170498071 [============>.................] - ETA: 1s
 78159872/170498071 [============>.................] - ETA: 1s
 82026496/170498071 [=============>................] - ETA: 1s
 85319680/170498071 [==============>...............] - ETA: 1s
 88629248/170498071 [==============>...............] - ETA: 1s
 91889664/170498071 [===============>..............] - ETA: 1s
 95199232/170498071 [===============>..............] - ETA: 1s
 98459648/170498071 [================>.............] - ETA: 1s
101638144/170498071 [================>.............] - ETA: 1s
104980480/170498071 [=================>............] - ETA: 1s
108355584/170498071 [==================>...........] - ETA: 1s
111599616/170498071 [==================>...........] - ETA: 0s
114925568/170498071 [===================>..........] - ETA: 0s
118202368/170498071 [===================>..........] - ETA: 0s
121495552/170498071 [====================>.........] - ETA: 0s
124674048/170498071 [====================>.........] - ETA: 0s
128008192/170498071 [=====================>........] - ETA: 0s
131178496/170498071 [======================>.......] - ETA: 0s
134438912/170498071 [======================>.......] - ETA: 0s
137764864/170498071 [=======================>......] - ETA: 0s
141058048/170498071 [=======================>......] - ETA: 0s
144400384/170498071 [========================>.....] - ETA: 0s
147709952/170498071 [========================>.....] - ETA: 0s
151035904/170498071 [=========================>....] - ETA: 0s
154353664/170498071 [==========================>...] - ETA: 0s
157540352/170498071 [==========================>...] - ETA: 0s
160833536/170498071 [===========================>..] - ETA: 0s
164044800/170498071 [===========================>..] - ETA: 0s
167305216/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 5971968/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
10567680/94765736 [==>...........................] - ETA: 2s
12140544/94765736 [==>...........................] - ETA: 2s
18841600/94765736 [====>.........................] - ETA: 2s
24199168/94765736 [======>.......................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
33652736/94765736 [=========>....................] - ETA: 1s
38019072/94765736 [===========>..................] - ETA: 1s
44810240/94765736 [=============>................] - ETA: 0s
48726016/94765736 [==============>...............] - ETA: 0s
55476224/94765736 [================>.............] - ETA: 0s
57016320/94765736 [=================>............] - ETA: 0s
62062592/94765736 [==================>...........] - ETA: 0s
68313088/94765736 [====================>.........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
80814080/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
87195648/94765736 [==========================>...] - ETA: 0s
90734592/94765736 [===========================>..] - ETA: 0s
93102080/94765736 [============================>.] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 15.547237873077393
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1597964074.589998s

Real time: 1597964074.5900242
Epoch 1/5

on_train_batch_begin: 1597964075.522309s

on_train_batch_end: 1597964092.710044s

 2048/50000 [>.............................] - ETA: 7:04 - loss: 18.0013 - accuracy: 2.4462e-04
on_train_batch_begin: 1597964092.710829s

1 step training time: 17.188520s

on_train_batch_end: 1597964092.933434s

 4096/50000 [=>............................] - ETA: 3:25 - loss: 15.2409 - accuracy: 4.0781e-04
on_train_batch_begin: 1597964092.933917s

2 step training time: 0.223088s

on_train_batch_end: 1597964093.157779s

 6144/50000 [==>...........................] - ETA: 2:12 - loss: 13.2164 - accuracy: 4.7263e-04
on_train_batch_begin: 1597964093.158258s

3 step training time: 0.224341s

on_train_batch_end: 1597964093.378114s

 8192/50000 [===>..........................] - ETA: 1:35 - loss: 11.9985 - accuracy: 0.0017    
on_train_batch_begin: 1597964093.378595s

4 step training time: 0.220336s

on_train_batch_end: 1597964093.601460s

10240/50000 [=====>........................] - ETA: 1:13 - loss: 11.1866 - accuracy: 0.0040
on_train_batch_begin: 1597964093.601920s

5 step training time: 0.223325s

on_train_batch_end: 1597964093.825599s

12288/50000 [======>.......................] - ETA: 59s - loss: 10.6288 - accuracy: 0.0076 
on_train_batch_begin: 1597964093.826047s

6 step training time: 0.224127s

on_train_batch_end: 1597964094.049898s

14336/50000 [=======>......................] - ETA: 48s - loss: 10.2165 - accuracy: 0.0124
on_train_batch_begin: 1597964094.050339s

7 step training time: 0.224292s

on_train_batch_end: 1597964094.270773s

16384/50000 [========>.....................] - ETA: 40s - loss: 9.8890 - accuracy: 0.0166 
on_train_batch_begin: 1597964094.271235s

8 step training time: 0.220896s

on_train_batch_end: 1597964094.494487s

18432/50000 [==========>...................] - ETA: 34s - loss: 9.6253 - accuracy: 0.0208
on_train_batch_begin: 1597964094.494945s

9 step training time: 0.223711s

on_train_batch_end: 1597964094.719122s

20480/50000 [===========>..................] - ETA: 29s - loss: 9.3953 - accuracy: 0.0259
on_train_batch_begin: 1597964094.719579s

10 step training time: 0.224634s

on_train_batch_end: 1597964094.941374s

22528/50000 [============>.................] - ETA: 24s - loss: 9.1958 - accuracy: 0.0299
on_train_batch_begin: 1597964094.941833s

11 step training time: 0.222254s

on_train_batch_end: 1597964095.163439s

24576/50000 [=============>................] - ETA: 21s - loss: 9.0302 - accuracy: 0.0338
on_train_batch_begin: 1597964095.163893s

12 step training time: 0.222061s

on_train_batch_end: 1597964095.384607s

26624/50000 [==============>...............] - ETA: 18s - loss: 8.8709 - accuracy: 0.0376
on_train_batch_begin: 1597964095.385063s

13 step training time: 0.221170s

on_train_batch_end: 1597964095.605924s

28672/50000 [================>.............] - ETA: 15s - loss: 8.7220 - accuracy: 0.0408
on_train_batch_begin: 1597964095.606382s

14 step training time: 0.221318s

on_train_batch_end: 1597964095.825402s

30720/50000 [=================>............] - ETA: 13s - loss: 8.5907 - accuracy: 0.0431
on_train_batch_begin: 1597964095.825859s

15 step training time: 0.219477s

on_train_batch_end: 1597964096.046798s

32768/50000 [==================>...........] - ETA: 11s - loss: 8.4673 - accuracy: 0.0455
on_train_batch_begin: 1597964096.047283s

16 step training time: 0.221424s

on_train_batch_end: 1597964096.267180s

34816/50000 [===================>..........] - ETA: 9s - loss: 8.3567 - accuracy: 0.0470 
on_train_batch_begin: 1597964096.267655s

17 step training time: 0.220372s

on_train_batch_end: 1597964096.487899s

36864/50000 [=====================>........] - ETA: 7s - loss: 8.2488 - accuracy: 0.0489
on_train_batch_begin: 1597964096.488387s

18 step training time: 0.220732s

on_train_batch_end: 1597964096.712572s

38912/50000 [======================>.......] - ETA: 6s - loss: 8.1616 - accuracy: 0.0503
on_train_batch_begin: 1597964096.713032s

19 step training time: 0.224645s

on_train_batch_end: 1597964096.932897s

40960/50000 [=======================>......] - ETA: 4s - loss: 8.0736 - accuracy: 0.0518
on_train_batch_begin: 1597964096.933362s

20 step training time: 0.220329s

on_train_batch_end: 1597964097.157486s

43008/50000 [========================>.....] - ETA: 3s - loss: 7.9894 - accuracy: 0.0527
on_train_batch_begin: 1597964097.158005s

21 step training time: 0.224643s

on_train_batch_end: 1597964097.378828s

45056/50000 [==========================>...] - ETA: 2s - loss: 7.9046 - accuracy: 0.0542
on_train_batch_begin: 1597964097.379274s

22 step training time: 0.221269s

on_train_batch_end: 1597964097.600353s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.8278 - accuracy: 0.0555
on_train_batch_begin: 1597964097.600796s

23 step training time: 0.221522s

on_train_batch_end: 1597964097.814706s

49152/50000 [============================>.] - ETA: 0s - loss: 7.7553 - accuracy: 0.0563
on_train_batch_begin: 1597964097.815145s

24 step training time: 0.214349s

on_train_batch_end: 1597964099.674101s

on_test_batch_begin: 1597964099.887308s

25 step training time: 2.072163s

on_epoch_end: 1597964103.458379s

Validation time: 3.571046s

Real time: 1597964103.458379s

Epoch time: 28.868383646011353s

50000/50000 [==============================] - 29s 577us/sample - loss: 7.7306 - accuracy: 0.0564 - val_loss: 5308.7637 - val_accuracy: 0.0000e+00

on_epoch_begin: 1597964103.458670s

Real time: 1597964103.4586794
Epoch 2/5

on_train_batch_begin: 1597964103.462930s

on_train_batch_end: 1597964103.684029s

 2048/50000 [>.............................] - ETA: 5s - loss: 5.9391 - accuracy: 0.0828
on_train_batch_begin: 1597964103.684521s

1 step training time: 0.221591s

on_train_batch_end: 1597964103.903886s

 4096/50000 [=>............................] - ETA: 4s - loss: 5.9171 - accuracy: 0.0864
on_train_batch_begin: 1597964103.904355s

2 step training time: 0.219834s

on_train_batch_end: 1597964104.127593s

 6144/50000 [==>...........................] - ETA: 4s - loss: 5.8876 - accuracy: 0.0886
on_train_batch_begin: 1597964104.128056s

3 step training time: 0.223701s

on_train_batch_end: 1597964104.347384s

 8192/50000 [===>..........................] - ETA: 4s - loss: 5.8732 - accuracy: 0.0903
on_train_batch_begin: 1597964104.347855s

4 step training time: 0.219799s

on_train_batch_end: 1597964104.567975s

10240/50000 [=====>........................] - ETA: 4s - loss: 5.8563 - accuracy: 0.0891
on_train_batch_begin: 1597964104.568459s

5 step training time: 0.220603s

on_train_batch_end: 1597964104.792982s

12288/50000 [======>.......................] - ETA: 4s - loss: 5.8272 - accuracy: 0.0899
on_train_batch_begin: 1597964104.793435s

6 step training time: 0.224976s

on_train_batch_end: 1597964105.017774s

14336/50000 [=======>......................] - ETA: 3s - loss: 5.8079 - accuracy: 0.0900
on_train_batch_begin: 1597964105.018226s

7 step training time: 0.224792s

on_train_batch_end: 1597964105.238523s

16384/50000 [========>.....................] - ETA: 3s - loss: 5.7722 - accuracy: 0.0902
on_train_batch_begin: 1597964105.238973s

8 step training time: 0.220746s

on_train_batch_end: 1597964105.458145s

18432/50000 [==========>...................] - ETA: 3s - loss: 5.7593 - accuracy: 0.0901
on_train_batch_begin: 1597964105.458591s

9 step training time: 0.219619s

on_train_batch_end: 1597964105.678001s

20480/50000 [===========>..................] - ETA: 3s - loss: 5.7268 - accuracy: 0.0904
on_train_batch_begin: 1597964105.678445s

10 step training time: 0.219854s

on_train_batch_end: 1597964105.898604s

22528/50000 [============>.................] - ETA: 2s - loss: 5.7049 - accuracy: 0.0902
on_train_batch_begin: 1597964105.899069s

11 step training time: 0.220623s

on_train_batch_end: 1597964106.119600s

24576/50000 [=============>................] - ETA: 2s - loss: 5.6828 - accuracy: 0.0901
on_train_batch_begin: 1597964106.120065s

12 step training time: 0.220997s

on_train_batch_end: 1597964106.338191s

26624/50000 [==============>...............] - ETA: 2s - loss: 5.6618 - accuracy: 0.0897
on_train_batch_begin: 1597964106.338645s

13 step training time: 0.218580s

on_train_batch_end: 1597964106.561439s

28672/50000 [================>.............] - ETA: 2s - loss: 5.6334 - accuracy: 0.0895
on_train_batch_begin: 1597964106.561895s

14 step training time: 0.223250s

on_train_batch_end: 1597964106.779067s

30720/50000 [=================>............] - ETA: 2s - loss: 5.6022 - accuracy: 0.0894
on_train_batch_begin: 1597964106.779528s

15 step training time: 0.217632s

on_train_batch_end: 1597964107.002517s

32768/50000 [==================>...........] - ETA: 1s - loss: 5.5717 - accuracy: 0.0893
on_train_batch_begin: 1597964107.002967s

16 step training time: 0.223439s

on_train_batch_end: 1597964107.227263s

34816/50000 [===================>..........] - ETA: 1s - loss: 5.5399 - accuracy: 0.0892
on_train_batch_begin: 1597964107.227719s

17 step training time: 0.224752s

on_train_batch_end: 1597964107.448115s

36864/50000 [=====================>........] - ETA: 1s - loss: 5.5173 - accuracy: 0.0884
on_train_batch_begin: 1597964107.448587s

18 step training time: 0.220868s

on_train_batch_end: 1597964107.669375s

38912/50000 [======================>.......] - ETA: 1s - loss: 5.4986 - accuracy: 0.0883
on_train_batch_begin: 1597964107.669820s

19 step training time: 0.221233s

on_train_batch_end: 1597964107.890016s

40960/50000 [=======================>......] - ETA: 0s - loss: 5.4666 - accuracy: 0.0881
on_train_batch_begin: 1597964107.890464s

20 step training time: 0.220644s

on_train_batch_end: 1597964108.110062s

43008/50000 [========================>.....] - ETA: 0s - loss: 5.4441 - accuracy: 0.0879
on_train_batch_begin: 1597964108.110501s

21 step training time: 0.220037s

on_train_batch_end: 1597964108.331967s

45056/50000 [==========================>...] - ETA: 0s - loss: 5.4211 - accuracy: 0.0877
on_train_batch_begin: 1597964108.332445s

22 step training time: 0.221944s

on_train_batch_end: 1597964108.553455s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.4015 - accuracy: 0.0877
on_train_batch_begin: 1597964108.553910s

23 step training time: 0.221465s

on_train_batch_end: 1597964108.767638s

49152/50000 [============================>.] - ETA: 0s - loss: 5.3837 - accuracy: 0.0873
on_train_batch_begin: 1597964108.768116s

24 step training time: 0.214206s

on_train_batch_end: 1597964108.879949s

on_test_batch_begin: 1597964108.912570s

25 step training time: 0.144454s

on_epoch_end: 1597964109.350204s

Validation time: 0.437618s

Real time: 1597964109.350204s

Epoch time: 5.891552209854126s

50000/50000 [==============================] - 6s 118us/sample - loss: 5.3780 - accuracy: 0.0873 - val_loss: 145.1557 - val_accuracy: 0.0000e+00

on_epoch_begin: 1597964109.350483s

Real time: 1597964109.350493
Epoch 3/5

on_train_batch_begin: 1597964109.354803s

on_train_batch_end: 1597964109.575695s

 2048/50000 [>.............................] - ETA: 5s - loss: 4.8651 - accuracy: 0.0825
on_train_batch_begin: 1597964109.576139s

1 step training time: 0.221336s

on_train_batch_end: 1597964109.795047s

 4096/50000 [=>............................] - ETA: 4s - loss: 4.8027 - accuracy: 0.0825
on_train_batch_begin: 1597964109.795499s

2 step training time: 0.219360s

on_train_batch_end: 1597964110.018278s

 6144/50000 [==>...........................] - ETA: 4s - loss: 4.7700 - accuracy: 0.0834
on_train_batch_begin: 1597964110.018725s

3 step training time: 0.223226s

on_train_batch_end: 1597964110.237475s

 8192/50000 [===>..........................] - ETA: 4s - loss: 4.7670 - accuracy: 0.0831
on_train_batch_begin: 1597964110.237929s

4 step training time: 0.219204s

on_train_batch_end: 1597964110.458023s

10240/50000 [=====>........................] - ETA: 4s - loss: 4.7546 - accuracy: 0.0840
on_train_batch_begin: 1597964110.458472s

5 step training time: 0.220543s

on_train_batch_end: 1597964110.684619s

12288/50000 [======>.......................] - ETA: 4s - loss: 4.7347 - accuracy: 0.0848
on_train_batch_begin: 1597964110.685060s

6 step training time: 0.226588s

on_train_batch_end: 1597964110.904530s

14336/50000 [=======>......................] - ETA: 3s - loss: 4.7162 - accuracy: 0.0848
on_train_batch_begin: 1597964110.904969s

7 step training time: 0.219909s

on_train_batch_end: 1597964111.122539s

16384/50000 [========>.....................] - ETA: 3s - loss: 4.7118 - accuracy: 0.0850
on_train_batch_begin: 1597964111.122984s

8 step training time: 0.218015s

on_train_batch_end: 1597964111.342924s

18432/50000 [==========>...................] - ETA: 3s - loss: 4.7032 - accuracy: 0.0846
on_train_batch_begin: 1597964111.343366s

9 step training time: 0.220382s

on_train_batch_end: 1597964111.568466s

20480/50000 [===========>..................] - ETA: 3s - loss: 4.6887 - accuracy: 0.0844
on_train_batch_begin: 1597964111.568933s

10 step training time: 0.225566s

on_train_batch_end: 1597964111.789291s

22528/50000 [============>.................] - ETA: 2s - loss: 4.6871 - accuracy: 0.0840
on_train_batch_begin: 1597964111.789741s

11 step training time: 0.220809s

on_train_batch_end: 1597964112.008939s

24576/50000 [=============>................] - ETA: 2s - loss: 4.6811 - accuracy: 0.0842
on_train_batch_begin: 1597964112.009387s

12 step training time: 0.219646s

on_train_batch_end: 1597964112.227957s

26624/50000 [==============>...............] - ETA: 2s - loss: 4.6789 - accuracy: 0.0840
on_train_batch_begin: 1597964112.228428s

13 step training time: 0.219041s

on_train_batch_end: 1597964112.451708s

28672/50000 [================>.............] - ETA: 2s - loss: 4.6848 - accuracy: 0.0834
on_train_batch_begin: 1597964112.452157s

14 step training time: 0.223729s

on_train_batch_end: 1597964112.672456s

30720/50000 [=================>............] - ETA: 2s - loss: 4.6725 - accuracy: 0.0831
on_train_batch_begin: 1597964112.672901s

15 step training time: 0.220744s

on_train_batch_end: 1597964112.895486s

32768/50000 [==================>...........] - ETA: 1s - loss: 4.6669 - accuracy: 0.0826
on_train_batch_begin: 1597964112.895954s

16 step training time: 0.223053s

on_train_batch_end: 1597964113.115959s

34816/50000 [===================>..........] - ETA: 1s - loss: 4.6579 - accuracy: 0.0823
on_train_batch_begin: 1597964113.116438s

17 step training time: 0.220483s

on_train_batch_end: 1597964113.336080s

36864/50000 [=====================>........] - ETA: 1s - loss: 4.6440 - accuracy: 0.0820
on_train_batch_begin: 1597964113.336551s

18 step training time: 0.220114s

on_train_batch_end: 1597964113.556658s

38912/50000 [======================>.......] - ETA: 1s - loss: 4.6390 - accuracy: 0.0816
on_train_batch_begin: 1597964113.557103s

19 step training time: 0.220551s

on_train_batch_end: 1597964113.776701s

40960/50000 [=======================>......] - ETA: 0s - loss: 4.6262 - accuracy: 0.0812
on_train_batch_begin: 1597964113.777141s

20 step training time: 0.220039s

on_train_batch_end: 1597964113.997586s

43008/50000 [========================>.....] - ETA: 0s - loss: 4.6198 - accuracy: 0.0808
on_train_batch_begin: 1597964113.998040s

21 step training time: 0.220898s

on_train_batch_end: 1597964114.218538s

45056/50000 [==========================>...] - ETA: 0s - loss: 4.6145 - accuracy: 0.0804
on_train_batch_begin: 1597964114.219010s

22 step training time: 0.220971s

on_train_batch_end: 1597964114.439084s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.6083 - accuracy: 0.0800
on_train_batch_begin: 1597964114.439551s

23 step training time: 0.220541s

on_train_batch_end: 1597964114.656923s

49152/50000 [============================>.] - ETA: 0s - loss: 4.6007 - accuracy: 0.0796
on_train_batch_begin: 1597964114.657384s

24 step training time: 0.217833s

on_train_batch_end: 1597964114.762333s

on_test_batch_begin: 1597964114.794433s

25 step training time: 0.137049s

on_epoch_end: 1597964115.223147s

Validation time: 0.428697s

Real time: 1597964115.223147s

Epoch time: 5.872681140899658s

50000/50000 [==============================] - 6s 117us/sample - loss: 4.5951 - accuracy: 0.0796 - val_loss: 7.2571 - val_accuracy: 0.1001

on_epoch_begin: 1597964115.223415s

Real time: 1597964115.223424
Epoch 4/5

on_train_batch_begin: 1597964115.227758s

on_train_batch_end: 1597964115.445712s

 2048/50000 [>.............................] - ETA: 5s - loss: 4.1704 - accuracy: 0.0706
on_train_batch_begin: 1597964115.446176s

1 step training time: 0.218418s

on_train_batch_end: 1597964115.663716s

 4096/50000 [=>............................] - ETA: 4s - loss: 4.2504 - accuracy: 0.0685
on_train_batch_begin: 1597964115.664159s

2 step training time: 0.217983s

on_train_batch_end: 1597964115.881962s

 6144/50000 [==>...........................] - ETA: 4s - loss: 4.2057 - accuracy: 0.0684
on_train_batch_begin: 1597964115.882422s

3 step training time: 0.218264s

on_train_batch_end: 1597964116.099797s

 8192/50000 [===>..........................] - ETA: 4s - loss: 4.1864 - accuracy: 0.0679
on_train_batch_begin: 1597964116.100252s

4 step training time: 0.217830s

on_train_batch_end: 1597964116.317486s

10240/50000 [=====>........................] - ETA: 4s - loss: 4.1553 - accuracy: 0.0676
on_train_batch_begin: 1597964116.317927s

5 step training time: 0.217675s

on_train_batch_end: 1597964116.538291s

12288/50000 [======>.......................] - ETA: 4s - loss: 4.1657 - accuracy: 0.0671
on_train_batch_begin: 1597964116.538728s

6 step training time: 0.220801s

on_train_batch_end: 1597964116.757452s

14336/50000 [=======>......................] - ETA: 3s - loss: 4.1400 - accuracy: 0.0667
on_train_batch_begin: 1597964116.757923s

7 step training time: 0.219195s

on_train_batch_end: 1597964116.974684s

16384/50000 [========>.....................] - ETA: 3s - loss: 4.1082 - accuracy: 0.0668
on_train_batch_begin: 1597964116.975134s

8 step training time: 0.217211s

on_train_batch_end: 1597964117.191816s

18432/50000 [==========>...................] - ETA: 3s - loss: 4.0895 - accuracy: 0.0669
on_train_batch_begin: 1597964117.192262s

9 step training time: 0.217128s

on_train_batch_end: 1597964117.411280s

20480/50000 [===========>..................] - ETA: 3s - loss: 4.0535 - accuracy: 0.0675
on_train_batch_begin: 1597964117.411720s

10 step training time: 0.219458s

on_train_batch_end: 1597964117.629765s

22528/50000 [============>.................] - ETA: 2s - loss: 4.0340 - accuracy: 0.0677
on_train_batch_begin: 1597964117.630209s

11 step training time: 0.218489s

on_train_batch_end: 1597964117.849028s

24576/50000 [=============>................] - ETA: 2s - loss: 3.9912 - accuracy: 0.0683
on_train_batch_begin: 1597964117.849467s

12 step training time: 0.219258s

on_train_batch_end: 1597964118.069329s

26624/50000 [==============>...............] - ETA: 2s - loss: 3.9797 - accuracy: 0.0686
on_train_batch_begin: 1597964118.069764s

13 step training time: 0.220297s

on_train_batch_end: 1597964118.287797s

28672/50000 [================>.............] - ETA: 2s - loss: 3.9634 - accuracy: 0.0690
on_train_batch_begin: 1597964118.288262s

14 step training time: 0.218498s

on_train_batch_end: 1597964118.503878s

30720/50000 [=================>............] - ETA: 2s - loss: 3.9407 - accuracy: 0.0695
on_train_batch_begin: 1597964118.504370s

15 step training time: 0.216108s

on_train_batch_end: 1597964118.725757s

32768/50000 [==================>...........] - ETA: 1s - loss: 3.9247 - accuracy: 0.0697
on_train_batch_begin: 1597964118.726207s

16 step training time: 0.221837s

on_train_batch_end: 1597964118.947387s

34816/50000 [===================>..........] - ETA: 1s - loss: 3.8920 - accuracy: 0.0702
on_train_batch_begin: 1597964118.947839s

17 step training time: 0.221632s

on_train_batch_end: 1597964119.171743s

36864/50000 [=====================>........] - ETA: 1s - loss: 3.8649 - accuracy: 0.0706
on_train_batch_begin: 1597964119.172208s

18 step training time: 0.224369s

on_train_batch_end: 1597964119.391541s

38912/50000 [======================>.......] - ETA: 1s - loss: 3.8405 - accuracy: 0.0710
on_train_batch_begin: 1597964119.391981s

19 step training time: 0.219773s

on_train_batch_end: 1597964119.612633s

40960/50000 [=======================>......] - ETA: 0s - loss: 3.8132 - accuracy: 0.0714
on_train_batch_begin: 1597964119.613074s

20 step training time: 0.221093s

on_train_batch_end: 1597964119.833144s

43008/50000 [========================>.....] - ETA: 0s - loss: 3.7827 - accuracy: 0.0719
on_train_batch_begin: 1597964119.833594s

21 step training time: 0.220520s

on_train_batch_end: 1597964120.053314s

45056/50000 [==========================>...] - ETA: 0s - loss: 3.7497 - accuracy: 0.0724
on_train_batch_begin: 1597964120.053789s

22 step training time: 0.220195s

on_train_batch_end: 1597964120.273494s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.7150 - accuracy: 0.0730
on_train_batch_begin: 1597964120.273942s

23 step training time: 0.220152s

on_train_batch_end: 1597964120.488167s

49152/50000 [============================>.] - ETA: 0s - loss: 3.6785 - accuracy: 0.0735
on_train_batch_begin: 1597964120.488657s

24 step training time: 0.214715s

on_train_batch_end: 1597964120.599640s

on_test_batch_begin: 1597964120.631547s

25 step training time: 0.142890s

on_epoch_end: 1597964121.066385s

Validation time: 0.434821s

Real time: 1597964121.066385s

Epoch time: 5.842987298965454s

50000/50000 [==============================] - 6s 117us/sample - loss: 3.6617 - accuracy: 0.0736 - val_loss: 7.2606 - val_accuracy: 0.1001

on_epoch_begin: 1597964121.066650s

Real time: 1597964121.0666597
Epoch 5/5

on_train_batch_begin: 1597964121.070917s

on_train_batch_end: 1597964121.290862s

 2048/50000 [>.............................] - ETA: 5s - loss: 2.5906 - accuracy: 0.0916
on_train_batch_begin: 1597964121.291305s

1 step training time: 0.220388s

on_train_batch_end: 1597964121.509451s

 4096/50000 [=>............................] - ETA: 4s - loss: 2.4804 - accuracy: 0.0926
on_train_batch_begin: 1597964121.509893s

2 step training time: 0.218588s

on_train_batch_end: 1597964121.727870s

 6144/50000 [==>...........................] - ETA: 4s - loss: 2.4728 - accuracy: 0.0934
on_train_batch_begin: 1597964121.728361s

3 step training time: 0.218468s

on_train_batch_end: 1597964121.945914s

 8192/50000 [===>..........................] - ETA: 4s - loss: 2.4025 - accuracy: 0.0941
on_train_batch_begin: 1597964121.946360s

4 step training time: 0.217998s

on_train_batch_end: 1597964122.162594s

10240/50000 [=====>........................] - ETA: 4s - loss: 2.3488 - accuracy: 0.0950
on_train_batch_begin: 1597964122.163042s

5 step training time: 0.216682s

on_train_batch_end: 1597964122.381844s

12288/50000 [======>.......................] - ETA: 4s - loss: 2.3163 - accuracy: 0.0955
on_train_batch_begin: 1597964122.382285s

6 step training time: 0.219244s

on_train_batch_end: 1597964122.602159s

14336/50000 [=======>......................] - ETA: 3s - loss: 2.2844 - accuracy: 0.0960
on_train_batch_begin: 1597964122.602597s

7 step training time: 0.220312s

on_train_batch_end: 1597964122.822044s

16384/50000 [========>.....................] - ETA: 3s - loss: 2.2523 - accuracy: 0.0963
on_train_batch_begin: 1597964122.822521s

8 step training time: 0.219923s

on_train_batch_end: 1597964123.046096s

18432/50000 [==========>...................] - ETA: 3s - loss: 2.2401 - accuracy: 0.0966
on_train_batch_begin: 1597964123.046556s

9 step training time: 0.224035s

on_train_batch_end: 1597964123.266106s

20480/50000 [===========>..................] - ETA: 3s - loss: 2.2036 - accuracy: 0.0970
on_train_batch_begin: 1597964123.266554s

10 step training time: 0.219998s

on_train_batch_end: 1597964123.487932s

22528/50000 [============>.................] - ETA: 2s - loss: 2.1738 - accuracy: 0.0972
on_train_batch_begin: 1597964123.488394s

11 step training time: 0.221840s

on_train_batch_end: 1597964123.711630s

24576/50000 [=============>................] - ETA: 2s - loss: 2.1538 - accuracy: 0.0974
on_train_batch_begin: 1597964123.712074s

12 step training time: 0.223680s

on_train_batch_end: 1597964123.934673s

26624/50000 [==============>...............] - ETA: 2s - loss: 2.1252 - accuracy: 0.0976
on_train_batch_begin: 1597964123.935109s

13 step training time: 0.223036s

on_train_batch_end: 1597964124.155173s

28672/50000 [================>.............] - ETA: 2s - loss: 2.1051 - accuracy: 0.0978
on_train_batch_begin: 1597964124.155639s

14 step training time: 0.220530s

on_train_batch_end: 1597964124.371275s

30720/50000 [=================>............] - ETA: 2s - loss: 2.0768 - accuracy: 0.0979
on_train_batch_begin: 1597964124.371718s

15 step training time: 0.216079s

on_train_batch_end: 1597964124.593709s

32768/50000 [==================>...........] - ETA: 1s - loss: 2.0429 - accuracy: 0.0981
on_train_batch_begin: 1597964124.594151s

16 step training time: 0.222433s

on_train_batch_end: 1597964124.812815s

34816/50000 [===================>..........] - ETA: 1s - loss: 2.0170 - accuracy: 0.0982
on_train_batch_begin: 1597964124.813272s

17 step training time: 0.219121s

on_train_batch_end: 1597964125.037277s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.9980 - accuracy: 0.0983
on_train_batch_begin: 1597964125.037725s

18 step training time: 0.224453s

on_train_batch_end: 1597964125.261130s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.9689 - accuracy: 0.0984
on_train_batch_begin: 1597964125.261575s

19 step training time: 0.223851s

on_train_batch_end: 1597964125.479593s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.9402 - accuracy: 0.0985
on_train_batch_begin: 1597964125.480029s

20 step training time: 0.218454s

on_train_batch_end: 1597964125.701543s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.9213 - accuracy: 0.0985
on_train_batch_begin: 1597964125.701997s

21 step training time: 0.221968s

on_train_batch_end: 1597964125.922930s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.9020 - accuracy: 0.0986
on_train_batch_begin: 1597964125.923378s

22 step training time: 0.221380s

on_train_batch_end: 1597964126.143965s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8815 - accuracy: 0.0987
on_train_batch_begin: 1597964126.144455s

23 step training time: 0.221077s

on_train_batch_end: 1597964126.358102s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8646 - accuracy: 0.0987
on_train_batch_begin: 1597964126.358545s

24 step training time: 0.214090s

on_train_batch_end: 1597964126.464769s

on_test_batch_begin: 1597964126.496099s

25 step training time: 0.137553s

on_epoch_end: 1597964126.924767s

Validation time: 0.428652s

Real time: 1597964126.924767s

Epoch time: 5.858133316040039s

50000/50000 [==============================] - 6s 117us/sample - loss: 1.8580 - accuracy: 0.0987 - val_loss: 7.1337 - val_accuracy: 0.1001
Tempo do fit: 56.63760781288147