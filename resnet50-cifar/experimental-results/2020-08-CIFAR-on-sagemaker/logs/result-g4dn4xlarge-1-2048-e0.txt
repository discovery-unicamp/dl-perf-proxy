wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:37
   122880/170498071 [..............................] - ETA: 1:40
   655360/170498071 [..............................] - ETA: 31s 
  2236416/170498071 [..............................] - ETA: 13s
  5316608/170498071 [..............................] - ETA: 6s 
  8413184/170498071 [>.............................] - ETA: 5s
 11575296/170498071 [=>............................] - ETA: 4s
 14770176/170498071 [=>............................] - ETA: 3s
 17932288/170498071 [==>...........................] - ETA: 3s
 21118976/170498071 [==>...........................] - ETA: 3s
 24207360/170498071 [===>..........................] - ETA: 3s
 27369472/170498071 [===>..........................] - ETA: 2s
 30547968/170498071 [====>.........................] - ETA: 2s
 33710080/170498071 [====>.........................] - ETA: 2s
 36855808/170498071 [=====>........................] - ETA: 2s
 40017920/170498071 [======>.......................] - ETA: 2s
 43212800/170498071 [======>.......................] - ETA: 2s
 46374912/170498071 [=======>......................] - ETA: 2s
 49537024/170498071 [=======>......................] - ETA: 2s
 52715520/170498071 [========>.....................] - ETA: 2s
 55861248/170498071 [========>.....................] - ETA: 2s
 59023360/170498071 [=========>....................] - ETA: 2s
 62201856/170498071 [=========>....................] - ETA: 1s
 65363968/170498071 [==========>...................] - ETA: 1s
 68517888/170498071 [===========>..................] - ETA: 1s
 71680000/170498071 [===========>..................] - ETA: 1s
 74842112/170498071 [============>.................] - ETA: 1s
 78012416/170498071 [============>.................] - ETA: 1s
 81207296/170498071 [=============>................] - ETA: 1s
 84402176/170498071 [=============>................] - ETA: 1s
 87564288/170498071 [==============>...............] - ETA: 1s
 90710016/170498071 [==============>...............] - ETA: 1s
 93839360/170498071 [===============>..............] - ETA: 1s
 97001472/170498071 [================>.............] - ETA: 1s
100130816/170498071 [================>.............] - ETA: 1s
103325696/170498071 [=================>............] - ETA: 1s
106438656/170498071 [=================>............] - ETA: 1s
109699072/170498071 [==================>...........] - ETA: 1s
112861184/170498071 [==================>...........] - ETA: 0s
116006912/170498071 [===================>..........] - ETA: 0s
119185408/170498071 [===================>..........] - ETA: 0s
121249792/170498071 [====================>.........] - ETA: 0s
125468672/170498071 [=====================>........] - ETA: 0s
128638976/170498071 [=====================>........] - ETA: 0s
131801088/170498071 [======================>.......] - ETA: 0s
134971392/170498071 [======================>.......] - ETA: 0s
138141696/170498071 [=======================>......] - ETA: 0s
141320192/170498071 [=======================>......] - ETA: 0s
144465920/170498071 [========================>.....] - ETA: 0s
147644416/170498071 [========================>.....] - ETA: 0s
150806528/170498071 [=========================>....] - ETA: 0s
153952256/170498071 [==========================>...] - ETA: 0s
157081600/170498071 [==========================>...] - ETA: 0s
160276480/170498071 [===========================>..] - ETA: 0s
163454976/170498071 [===========================>..] - ETA: 0s
166633472/170498071 [============================>.] - ETA: 0s
169828352/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 1114112/94765736 [..............................] - ETA: 5s
 7290880/94765736 [=>............................] - ETA: 1s
 8200192/94765736 [=>............................] - ETA: 2s
10567680/94765736 [==>...........................] - ETA: 1s
14286848/94765736 [===>..........................] - ETA: 1s
17661952/94765736 [====>.........................] - ETA: 1s
20021248/94765736 [=====>........................] - ETA: 1s
27017216/94765736 [=======>......................] - ETA: 1s
31055872/94765736 [========>.....................] - ETA: 1s
38125568/94765736 [===========>..................] - ETA: 1s
43597824/94765736 [============>.................] - ETA: 0s
45957120/94765736 [=============>................] - ETA: 1s
48324608/94765736 [==============>...............] - ETA: 1s
50683904/94765736 [===============>..............] - ETA: 1s
53051392/94765736 [===============>..............] - ETA: 1s
56598528/94765736 [================>.............] - ETA: 0s
59015168/94765736 [=================>............] - ETA: 0s
62439424/94765736 [==================>...........] - ETA: 0s
64143360/94765736 [===================>..........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
70008832/94765736 [=====================>........] - ETA: 0s
73072640/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
80936960/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
89554944/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.713608026504517
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598499846.631227s

Real time: 1598499846.631244
Epoch 1/5

on_train_batch_begin: 1598499847.376232s

on_train_batch_end: 1598499867.441151s

 2048/50000 [>.............................] - ETA: 8:07 - loss: 17.9152 - accuracy: 9.7275e-05
on_train_batch_begin: 1598499867.441796s

1 step training time: 20.065564s

on_train_batch_end: 1598499868.135335s

 4096/50000 [=>............................] - ETA: 4:00 - loss: 14.8341 - accuracy: 1.9300e-04
on_train_batch_begin: 1598499868.135668s

2 step training time: 0.693872s

on_train_batch_end: 1598499868.823874s

 6144/50000 [==>...........................] - ETA: 2:38 - loss: 12.7893 - accuracy: 4.6039e-04
on_train_batch_begin: 1598499868.824179s

3 step training time: 0.688512s

on_train_batch_end: 1598499869.516117s

 8192/50000 [===>..........................] - ETA: 1:56 - loss: 11.6853 - accuracy: 0.0012    
on_train_batch_begin: 1598499869.516413s

4 step training time: 0.692234s

on_train_batch_end: 1598499870.205917s

10240/50000 [=====>........................] - ETA: 1:31 - loss: 10.9815 - accuracy: 0.0025
on_train_batch_begin: 1598499870.206209s

5 step training time: 0.689796s

on_train_batch_end: 1598499870.898529s

12288/50000 [======>.......................] - ETA: 1:14 - loss: 10.4786 - accuracy: 0.0051
on_train_batch_begin: 1598499870.898831s

6 step training time: 0.692622s

on_train_batch_end: 1598499871.588046s

14336/50000 [=======>......................] - ETA: 1:02 - loss: 10.0993 - accuracy: 0.0094
on_train_batch_begin: 1598499871.588344s

7 step training time: 0.689512s

on_train_batch_end: 1598499872.284382s

16384/50000 [========>.....................] - ETA: 52s - loss: 9.8035 - accuracy: 0.0130  
on_train_batch_begin: 1598499872.284686s

8 step training time: 0.696342s

on_train_batch_end: 1598499872.981977s

18432/50000 [==========>...................] - ETA: 45s - loss: 9.5489 - accuracy: 0.0181
on_train_batch_begin: 1598499872.982305s

9 step training time: 0.697619s

on_train_batch_end: 1598499873.675972s

20480/50000 [===========>..................] - ETA: 38s - loss: 9.3396 - accuracy: 0.0217
on_train_batch_begin: 1598499873.676282s

10 step training time: 0.693977s

on_train_batch_end: 1598499874.370439s

22528/50000 [============>.................] - ETA: 33s - loss: 9.1737 - accuracy: 0.0254
on_train_batch_begin: 1598499874.370754s

11 step training time: 0.694472s

on_train_batch_end: 1598499875.062024s

24576/50000 [=============>................] - ETA: 29s - loss: 9.0224 - accuracy: 0.0278
on_train_batch_begin: 1598499875.062339s

12 step training time: 0.691585s

on_train_batch_end: 1598499875.754481s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.8847 - accuracy: 0.0305
on_train_batch_begin: 1598499875.754784s

13 step training time: 0.692445s

on_train_batch_end: 1598499876.447177s

28672/50000 [================>.............] - ETA: 22s - loss: 8.7672 - accuracy: 0.0333
on_train_batch_begin: 1598499876.447482s

14 step training time: 0.692698s

on_train_batch_end: 1598499877.144394s

30720/50000 [=================>............] - ETA: 19s - loss: 8.6604 - accuracy: 0.0356
on_train_batch_begin: 1598499877.144696s

15 step training time: 0.697214s

on_train_batch_end: 1598499877.841674s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.5659 - accuracy: 0.0378
on_train_batch_begin: 1598499877.841974s

16 step training time: 0.697279s

on_train_batch_end: 1598499878.513029s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.4764 - accuracy: 0.0397
on_train_batch_begin: 1598499878.513334s

17 step training time: 0.671360s

on_train_batch_end: 1598499879.215830s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.4005 - accuracy: 0.0413
on_train_batch_begin: 1598499879.216133s

18 step training time: 0.702799s

on_train_batch_end: 1598499879.907927s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.3301 - accuracy: 0.0429 
on_train_batch_begin: 1598499879.908233s

19 step training time: 0.692100s

on_train_batch_end: 1598499880.610672s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.2613 - accuracy: 0.0439
on_train_batch_begin: 1598499880.610975s

20 step training time: 0.702742s

on_train_batch_end: 1598499881.309721s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.2007 - accuracy: 0.0449
on_train_batch_begin: 1598499881.310036s

21 step training time: 0.699060s

on_train_batch_end: 1598499882.010233s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.1464 - accuracy: 0.0460
on_train_batch_begin: 1598499882.010539s

22 step training time: 0.700504s

on_train_batch_end: 1598499882.712869s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.0926 - accuracy: 0.0472
on_train_batch_begin: 1598499882.713179s

23 step training time: 0.702640s

on_train_batch_end: 1598499883.411478s

49152/50000 [============================>.] - ETA: 0s - loss: 8.0432 - accuracy: 0.0483
on_train_batch_begin: 1598499883.411791s

24 step training time: 0.698612s

on_train_batch_end: 1598499889.794037s

on_test_batch_begin: 1598499889.981750s

25 step training time: 6.569959s

on_epoch_end: 1598499895.376597s

Validation time: 5.394830s

Real time: 1598499895.376597s

Epoch time: 48.74537229537964s

50000/50000 [==============================] - 49s 975us/sample - loss: 8.0245 - accuracy: 0.0485 - val_loss: 4148.1823 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598499895.376809s

Real time: 1598499895.3768146
Epoch 2/5

on_train_batch_begin: 1598499895.380355s

on_train_batch_end: 1598499896.097660s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.9134 - accuracy: 0.0787
on_train_batch_begin: 1598499896.097953s

1 step training time: 0.717598s

on_train_batch_end: 1598499896.811799s

 4096/50000 [=>............................] - ETA: 16s - loss: 6.9387 - accuracy: 0.0828
on_train_batch_begin: 1598499896.812096s

2 step training time: 0.714143s

on_train_batch_end: 1598499897.522295s

 6144/50000 [==>...........................] - ETA: 15s - loss: 6.9257 - accuracy: 0.0844
on_train_batch_begin: 1598499897.522589s

3 step training time: 0.710494s

on_train_batch_end: 1598499898.237901s

 8192/50000 [===>..........................] - ETA: 14s - loss: 6.8941 - accuracy: 0.0836
on_train_batch_begin: 1598499898.238202s

4 step training time: 0.715613s

on_train_batch_end: 1598499898.947772s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.8731 - accuracy: 0.0833
on_train_batch_begin: 1598499898.948078s

5 step training time: 0.709877s

on_train_batch_end: 1598499899.658091s

12288/50000 [======>.......................] - ETA: 13s - loss: 6.8604 - accuracy: 0.0843
on_train_batch_begin: 1598499899.658391s

6 step training time: 0.710312s

on_train_batch_end: 1598499900.367510s

14336/50000 [=======>......................] - ETA: 12s - loss: 6.8403 - accuracy: 0.0833
on_train_batch_begin: 1598499900.367808s

7 step training time: 0.709417s

on_train_batch_end: 1598499901.084379s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.8198 - accuracy: 0.0828
on_train_batch_begin: 1598499901.084680s

8 step training time: 0.716872s

on_train_batch_end: 1598499901.797905s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.8047 - accuracy: 0.0824
on_train_batch_begin: 1598499901.798218s

9 step training time: 0.713538s

on_train_batch_end: 1598499902.511873s

20480/50000 [===========>..................] - ETA: 10s - loss: 6.7806 - accuracy: 0.0813
on_train_batch_begin: 1598499902.512211s

10 step training time: 0.713993s

on_train_batch_end: 1598499903.228510s

22528/50000 [============>.................] - ETA: 9s - loss: 6.7541 - accuracy: 0.0803 
on_train_batch_begin: 1598499903.228826s

11 step training time: 0.716615s

on_train_batch_end: 1598499903.944792s

24576/50000 [=============>................] - ETA: 8s - loss: 6.7376 - accuracy: 0.0796
on_train_batch_begin: 1598499903.945091s

12 step training time: 0.716265s

on_train_batch_end: 1598499904.631349s

26624/50000 [==============>...............] - ETA: 8s - loss: 6.7123 - accuracy: 0.0786
on_train_batch_begin: 1598499904.631649s

13 step training time: 0.686558s

on_train_batch_end: 1598499905.353518s

28672/50000 [================>.............] - ETA: 7s - loss: 6.6817 - accuracy: 0.0780
on_train_batch_begin: 1598499905.353850s

14 step training time: 0.722201s

on_train_batch_end: 1598499906.068176s

30720/50000 [=================>............] - ETA: 6s - loss: 6.6636 - accuracy: 0.0774
on_train_batch_begin: 1598499906.068477s

15 step training time: 0.714628s

on_train_batch_end: 1598499906.786658s

32768/50000 [==================>...........] - ETA: 6s - loss: 6.6387 - accuracy: 0.0768
on_train_batch_begin: 1598499906.786976s

16 step training time: 0.718498s

on_train_batch_end: 1598499907.507551s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.6176 - accuracy: 0.0762
on_train_batch_begin: 1598499907.507863s

17 step training time: 0.720887s

on_train_batch_end: 1598499908.228326s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.6034 - accuracy: 0.0757
on_train_batch_begin: 1598499908.228631s

18 step training time: 0.720768s

on_train_batch_end: 1598499908.945957s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.5841 - accuracy: 0.0756
on_train_batch_begin: 1598499908.946264s

19 step training time: 0.717633s

on_train_batch_end: 1598499909.671562s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.5665 - accuracy: 0.0752
on_train_batch_begin: 1598499909.671880s

20 step training time: 0.725616s

on_train_batch_end: 1598499910.389300s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.5462 - accuracy: 0.0750
on_train_batch_begin: 1598499910.389648s

21 step training time: 0.717768s

on_train_batch_end: 1598499911.114002s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.5330 - accuracy: 0.0743
on_train_batch_begin: 1598499911.114304s

22 step training time: 0.724655s

on_train_batch_end: 1598499911.830579s

47104/50000 [===========================>..] - ETA: 1s - loss: 6.5140 - accuracy: 0.0738
on_train_batch_begin: 1598499911.830884s

23 step training time: 0.716580s

on_train_batch_end: 1598499912.550589s

49152/50000 [============================>.] - ETA: 0s - loss: 6.4902 - accuracy: 0.0735
on_train_batch_begin: 1598499912.550897s

24 step training time: 0.720014s

on_train_batch_end: 1598499912.853340s

on_test_batch_begin: 1598499912.891681s

25 step training time: 0.340784s

on_epoch_end: 1598499913.784955s

Validation time: 0.893257s

Real time: 1598499913.784955s

Epoch time: 18.40816044807434s

50000/50000 [==============================] - 18s 368us/sample - loss: 6.4802 - accuracy: 0.0734 - val_loss: 365.0921 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598499913.785155s

Real time: 1598499913.7851608
Epoch 3/5

on_train_batch_begin: 1598499913.788572s

on_train_batch_end: 1598499914.500085s

 2048/50000 [>.............................] - ETA: 16s - loss: 5.9484 - accuracy: 0.0562
on_train_batch_begin: 1598499914.500397s

1 step training time: 0.711825s

on_train_batch_end: 1598499915.228499s

 4096/50000 [=>............................] - ETA: 16s - loss: 5.9647 - accuracy: 0.0589
on_train_batch_begin: 1598499915.228801s

2 step training time: 0.728404s

on_train_batch_end: 1598499915.947607s

 6144/50000 [==>...........................] - ETA: 15s - loss: 5.9294 - accuracy: 0.0571
on_train_batch_begin: 1598499915.947911s

3 step training time: 0.719110s

on_train_batch_end: 1598499916.671299s

 8192/50000 [===>..........................] - ETA: 14s - loss: 5.9131 - accuracy: 0.0567
on_train_batch_begin: 1598499916.671601s

4 step training time: 0.723690s

on_train_batch_end: 1598499917.394010s

10240/50000 [=====>........................] - ETA: 14s - loss: 5.9079 - accuracy: 0.0555
on_train_batch_begin: 1598499917.394323s

5 step training time: 0.722721s

on_train_batch_end: 1598499918.124956s

12288/50000 [======>.......................] - ETA: 13s - loss: 5.8887 - accuracy: 0.0555
on_train_batch_begin: 1598499918.125257s

6 step training time: 0.730934s

on_train_batch_end: 1598499918.855417s

14336/50000 [=======>......................] - ETA: 12s - loss: 5.8690 - accuracy: 0.0563
on_train_batch_begin: 1598499918.855717s

7 step training time: 0.730460s

on_train_batch_end: 1598499919.584523s

16384/50000 [========>.....................] - ETA: 11s - loss: 5.8614 - accuracy: 0.0563
on_train_batch_begin: 1598499919.584832s

8 step training time: 0.729116s

on_train_batch_end: 1598499920.313409s

18432/50000 [==========>...................] - ETA: 11s - loss: 5.8493 - accuracy: 0.0563
on_train_batch_begin: 1598499920.313751s

9 step training time: 0.728919s

on_train_batch_end: 1598499921.042829s

20480/50000 [===========>..................] - ETA: 10s - loss: 5.8339 - accuracy: 0.0566
on_train_batch_begin: 1598499921.043135s

10 step training time: 0.729384s

on_train_batch_end: 1598499921.772733s

22528/50000 [============>.................] - ETA: 9s - loss: 5.8255 - accuracy: 0.0567 
on_train_batch_begin: 1598499921.773043s

11 step training time: 0.729908s

on_train_batch_end: 1598499922.503346s

24576/50000 [=============>................] - ETA: 9s - loss: 5.8018 - accuracy: 0.0567
on_train_batch_begin: 1598499922.503654s

12 step training time: 0.730611s

on_train_batch_end: 1598499923.235581s

26624/50000 [==============>...............] - ETA: 8s - loss: 5.7826 - accuracy: 0.0565
on_train_batch_begin: 1598499923.235913s

13 step training time: 0.732259s

on_train_batch_end: 1598499923.965396s

28672/50000 [================>.............] - ETA: 7s - loss: 5.7639 - accuracy: 0.0562
on_train_batch_begin: 1598499923.965738s

14 step training time: 0.729825s

on_train_batch_end: 1598499924.696673s

30720/50000 [=================>............] - ETA: 6s - loss: 5.7398 - accuracy: 0.0559
on_train_batch_begin: 1598499924.696985s

15 step training time: 0.731248s

on_train_batch_end: 1598499925.428145s

32768/50000 [==================>...........] - ETA: 6s - loss: 5.7192 - accuracy: 0.0555
on_train_batch_begin: 1598499925.428459s

16 step training time: 0.731474s

on_train_batch_end: 1598499926.159571s

34816/50000 [===================>..........] - ETA: 5s - loss: 5.6947 - accuracy: 0.0553
on_train_batch_begin: 1598499926.159872s

17 step training time: 0.731412s

on_train_batch_end: 1598499926.888320s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.6714 - accuracy: 0.0552
on_train_batch_begin: 1598499926.888626s

18 step training time: 0.728754s

on_train_batch_end: 1598499927.620307s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.6478 - accuracy: 0.0551
on_train_batch_begin: 1598499927.620609s

19 step training time: 0.731983s

on_train_batch_end: 1598499928.350343s

40960/50000 [=======================>......] - ETA: 3s - loss: 5.6204 - accuracy: 0.0551
on_train_batch_begin: 1598499928.350647s

20 step training time: 0.730038s

on_train_batch_end: 1598499929.080525s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.5927 - accuracy: 0.0552
on_train_batch_begin: 1598499929.080828s

21 step training time: 0.730181s

on_train_batch_end: 1598499929.809684s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.5572 - accuracy: 0.0554
on_train_batch_begin: 1598499929.809994s

22 step training time: 0.729166s

on_train_batch_end: 1598499930.544592s

47104/50000 [===========================>..] - ETA: 1s - loss: 5.5239 - accuracy: 0.0556
on_train_batch_begin: 1598499930.544895s

23 step training time: 0.734901s

on_train_batch_end: 1598499931.271873s

49152/50000 [============================>.] - ETA: 0s - loss: 5.4936 - accuracy: 0.0560
on_train_batch_begin: 1598499931.272184s

24 step training time: 0.727289s

on_train_batch_end: 1598499931.584038s

on_test_batch_begin: 1598499931.622487s

25 step training time: 0.350303s

on_epoch_end: 1598499932.531697s

Validation time: 0.909193s

Real time: 1598499932.531697s

Epoch time: 18.746553659439087s

50000/50000 [==============================] - 19s 375us/sample - loss: 5.4785 - accuracy: 0.0561 - val_loss: 8.1226 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598499932.531895s

Real time: 1598499932.5319002
Epoch 4/5

on_train_batch_begin: 1598499932.535306s

on_train_batch_end: 1598499933.257083s

 2048/50000 [>.............................] - ETA: 16s - loss: 4.3834 - accuracy: 0.0685
on_train_batch_begin: 1598499933.257385s

1 step training time: 0.722079s

on_train_batch_end: 1598499933.993679s

 4096/50000 [=>............................] - ETA: 16s - loss: 4.3641 - accuracy: 0.0689
on_train_batch_begin: 1598499933.993977s

2 step training time: 0.736592s

on_train_batch_end: 1598499934.733151s

 6144/50000 [==>...........................] - ETA: 15s - loss: 4.3926 - accuracy: 0.0682
on_train_batch_begin: 1598499934.733447s

3 step training time: 0.739470s

on_train_batch_end: 1598499935.469519s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.3446 - accuracy: 0.0687
on_train_batch_begin: 1598499935.469855s

4 step training time: 0.736408s

on_train_batch_end: 1598499936.208818s

10240/50000 [=====>........................] - ETA: 14s - loss: 4.2949 - accuracy: 0.0690
on_train_batch_begin: 1598499936.209117s

5 step training time: 0.739262s

on_train_batch_end: 1598499936.951610s

12288/50000 [======>.......................] - ETA: 13s - loss: 4.2509 - accuracy: 0.0699
on_train_batch_begin: 1598499936.951917s

6 step training time: 0.742800s

on_train_batch_end: 1598499937.689814s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.2119 - accuracy: 0.0709
on_train_batch_begin: 1598499937.690112s

7 step training time: 0.738194s

on_train_batch_end: 1598499938.434882s

16384/50000 [========>.....................] - ETA: 12s - loss: 4.1540 - accuracy: 0.0721
on_train_batch_begin: 1598499938.435185s

8 step training time: 0.745073s

on_train_batch_end: 1598499939.179450s

18432/50000 [==========>...................] - ETA: 11s - loss: 4.1004 - accuracy: 0.0733
on_train_batch_begin: 1598499939.179748s

9 step training time: 0.744563s

on_train_batch_end: 1598499939.923335s

20480/50000 [===========>..................] - ETA: 10s - loss: 4.0483 - accuracy: 0.0744
on_train_batch_begin: 1598499939.923637s

10 step training time: 0.743889s

on_train_batch_end: 1598499940.667657s

22528/50000 [============>.................] - ETA: 9s - loss: 4.0041 - accuracy: 0.0755 
on_train_batch_begin: 1598499940.667958s

11 step training time: 0.744321s

on_train_batch_end: 1598499941.411530s

24576/50000 [=============>................] - ETA: 9s - loss: 3.9718 - accuracy: 0.0764
on_train_batch_begin: 1598499941.411843s

12 step training time: 0.743885s

on_train_batch_end: 1598499942.156892s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.9212 - accuracy: 0.0774
on_train_batch_begin: 1598499942.157190s

13 step training time: 0.745348s

on_train_batch_end: 1598499942.902025s

28672/50000 [================>.............] - ETA: 7s - loss: 3.8770 - accuracy: 0.0784
on_train_batch_begin: 1598499942.902337s

14 step training time: 0.745147s

on_train_batch_end: 1598499943.644890s

30720/50000 [=================>............] - ETA: 6s - loss: 3.8333 - accuracy: 0.0794
on_train_batch_begin: 1598499943.645201s

15 step training time: 0.742864s

on_train_batch_end: 1598499944.390745s

32768/50000 [==================>...........] - ETA: 6s - loss: 3.7792 - accuracy: 0.0804
on_train_batch_begin: 1598499944.391057s

16 step training time: 0.745855s

on_train_batch_end: 1598499945.139761s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.7166 - accuracy: 0.0812
on_train_batch_begin: 1598499945.140067s

17 step training time: 0.749010s

on_train_batch_end: 1598499945.884349s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.6541 - accuracy: 0.0822
on_train_batch_begin: 1598499945.884658s

18 step training time: 0.744591s

on_train_batch_end: 1598499946.632302s

38912/50000 [======================>.......] - ETA: 4s - loss: 3.5934 - accuracy: 0.0831
on_train_batch_begin: 1598499946.632606s

19 step training time: 0.747948s

on_train_batch_end: 1598499947.379429s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.5351 - accuracy: 0.0839
on_train_batch_begin: 1598499947.379725s

20 step training time: 0.747119s

on_train_batch_end: 1598499948.132843s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.4778 - accuracy: 0.0846
on_train_batch_begin: 1598499948.133149s

21 step training time: 0.753424s

on_train_batch_end: 1598499948.885185s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.4228 - accuracy: 0.0853
on_train_batch_begin: 1598499948.885488s

22 step training time: 0.752339s

on_train_batch_end: 1598499949.637241s

47104/50000 [===========================>..] - ETA: 1s - loss: 3.3684 - accuracy: 0.0859
on_train_batch_begin: 1598499949.637539s

23 step training time: 0.752051s

on_train_batch_end: 1598499950.386413s

49152/50000 [============================>.] - ETA: 0s - loss: 3.3158 - accuracy: 0.0865
on_train_batch_begin: 1598499950.386716s

24 step training time: 0.749177s

on_train_batch_end: 1598499950.701947s

on_test_batch_begin: 1598499950.739472s

25 step training time: 0.352757s

on_epoch_end: 1598499951.642353s

Validation time: 0.902869s

Real time: 1598499951.642353s

Epoch time: 19.110471725463867s

50000/50000 [==============================] - 19s 382us/sample - loss: 3.2983 - accuracy: 0.0866 - val_loss: 7.4779 - val_accuracy: 7.6888e-04

on_epoch_begin: 1598499951.642549s

Real time: 1598499951.642554
Epoch 5/5

on_train_batch_begin: 1598499951.645945s

on_train_batch_end: 1598499952.391222s

 2048/50000 [>.............................] - ETA: 17s - loss: 1.8498 - accuracy: 0.1002
on_train_batch_begin: 1598499952.391524s

1 step training time: 0.745579s

on_train_batch_end: 1598499953.147844s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.9471 - accuracy: 0.1000
on_train_batch_begin: 1598499953.148156s

2 step training time: 0.756632s

on_train_batch_end: 1598499953.897598s

 6144/50000 [==>...........................] - ETA: 16s - loss: 1.9427 - accuracy: 0.0999
on_train_batch_begin: 1598499953.897927s

3 step training time: 0.749771s

on_train_batch_end: 1598499954.652739s

 8192/50000 [===>..........................] - ETA: 15s - loss: 1.9457 - accuracy: 0.0999
on_train_batch_begin: 1598499954.653042s

4 step training time: 0.755116s

on_train_batch_end: 1598499955.406994s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.9152 - accuracy: 0.1000
on_train_batch_begin: 1598499955.407295s

5 step training time: 0.754253s

on_train_batch_end: 1598499956.166770s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.8981 - accuracy: 0.1000
on_train_batch_begin: 1598499956.167072s

6 step training time: 0.759777s

on_train_batch_end: 1598499956.915734s

14336/50000 [=======>......................] - ETA: 13s - loss: 1.8625 - accuracy: 0.1000
on_train_batch_begin: 1598499956.916041s

7 step training time: 0.748969s

on_train_batch_end: 1598499957.666289s

16384/50000 [========>.....................] - ETA: 12s - loss: 1.8271 - accuracy: 0.1000
on_train_batch_begin: 1598499957.666600s

8 step training time: 0.750560s

on_train_batch_end: 1598499958.422809s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.8081 - accuracy: 0.1000
on_train_batch_begin: 1598499958.423110s

9 step training time: 0.756509s

on_train_batch_end: 1598499959.176876s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.8099 - accuracy: 0.1000
on_train_batch_begin: 1598499959.177181s

10 step training time: 0.754071s

on_train_batch_end: 1598499959.934536s

22528/50000 [============>.................] - ETA: 10s - loss: 1.8018 - accuracy: 0.1000
on_train_batch_begin: 1598499959.934841s

11 step training time: 0.757660s

on_train_batch_end: 1598499960.686841s

24576/50000 [=============>................] - ETA: 9s - loss: 1.7849 - accuracy: 0.1000 
on_train_batch_begin: 1598499960.687153s

12 step training time: 0.752312s

on_train_batch_end: 1598499961.443640s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.7644 - accuracy: 0.1000
on_train_batch_begin: 1598499961.443942s

13 step training time: 0.756789s

on_train_batch_end: 1598499962.204368s

28672/50000 [================>.............] - ETA: 7s - loss: 1.7516 - accuracy: 0.1000
on_train_batch_begin: 1598499962.204677s

14 step training time: 0.760735s

on_train_batch_end: 1598499962.963566s

30720/50000 [=================>............] - ETA: 7s - loss: 1.7363 - accuracy: 0.1000
on_train_batch_begin: 1598499962.963868s

15 step training time: 0.759191s

on_train_batch_end: 1598499963.730778s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.7201 - accuracy: 0.1000
on_train_batch_begin: 1598499963.731079s

16 step training time: 0.767211s

on_train_batch_end: 1598499964.496335s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.7124 - accuracy: 0.1000
on_train_batch_begin: 1598499964.496631s

17 step training time: 0.765553s

on_train_batch_end: 1598499965.254706s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.7003 - accuracy: 0.1000
on_train_batch_begin: 1598499965.255002s

18 step training time: 0.758371s

on_train_batch_end: 1598499966.018809s

38912/50000 [======================>.......] - ETA: 4s - loss: 1.6894 - accuracy: 0.1000
on_train_batch_begin: 1598499966.019105s

19 step training time: 0.764103s

on_train_batch_end: 1598499966.787627s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.6776 - accuracy: 0.1001
on_train_batch_begin: 1598499966.787921s

20 step training time: 0.768816s

on_train_batch_end: 1598499967.556760s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.6706 - accuracy: 0.1001
on_train_batch_begin: 1598499967.557065s

21 step training time: 0.769144s

on_train_batch_end: 1598499968.327991s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.6562 - accuracy: 0.1001
on_train_batch_begin: 1598499968.328300s

22 step training time: 0.771235s

on_train_batch_end: 1598499969.100646s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.6464 - accuracy: 0.1001
on_train_batch_begin: 1598499969.100952s

23 step training time: 0.772652s

on_train_batch_end: 1598499969.864092s

49152/50000 [============================>.] - ETA: 0s - loss: 1.6364 - accuracy: 0.1001
on_train_batch_begin: 1598499969.864394s

24 step training time: 0.763442s

on_train_batch_end: 1598499970.184783s

on_test_batch_begin: 1598499970.222871s

25 step training time: 0.358477s

on_epoch_end: 1598499971.150239s

Validation time: 0.927352s

Real time: 1598499971.150239s

Epoch time: 19.50770354270935s

50000/50000 [==============================] - 20s 390us/sample - loss: 1.6330 - accuracy: 0.1001 - val_loss: 7.2220 - val_accuracy: 0.0998
Tempo do fit: 127.93101811408997