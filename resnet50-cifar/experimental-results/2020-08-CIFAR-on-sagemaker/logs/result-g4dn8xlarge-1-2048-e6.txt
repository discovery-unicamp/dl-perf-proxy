wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:12
    90112/170498071 [..............................] - ETA: 2:21
   303104/170498071 [..............................] - ETA: 1:10
   532480/170498071 [..............................] - ETA: 56s 
   761856/170498071 [..............................] - ETA: 50s
  1040384/170498071 [..............................] - ETA: 45s
  1335296/170498071 [..............................] - ETA: 41s
  1662976/170498071 [..............................] - ETA: 38s
  2023424/170498071 [..............................] - ETA: 36s
  2465792/170498071 [..............................] - ETA: 33s
  2924544/170498071 [..............................] - ETA: 30s
  3465216/170498071 [..............................] - ETA: 28s
  4038656/170498071 [..............................] - ETA: 26s
  4726784/170498071 [..............................] - ETA: 24s
  5431296/170498071 [..............................] - ETA: 22s
  6234112/170498071 [>.............................] - ETA: 20s
  7151616/170498071 [>.............................] - ETA: 19s
  8167424/170498071 [>.............................] - ETA: 17s
  9297920/170498071 [>.............................] - ETA: 16s
 10493952/170498071 [>.............................] - ETA: 15s
 11837440/170498071 [=>............................] - ETA: 14s
 13262848/170498071 [=>............................] - ETA: 13s
 14802944/170498071 [=>............................] - ETA: 12s
 16392192/170498071 [=>............................] - ETA: 11s
 17932288/170498071 [==>...........................] - ETA: 10s
 19554304/170498071 [==>...........................] - ETA: 10s
 21094400/170498071 [==>...........................] - ETA: 9s 
 22683648/170498071 [==>...........................] - ETA: 9s
 24190976/170498071 [===>..........................] - ETA: 8s
 25731072/170498071 [===>..........................] - ETA: 8s
 27303936/170498071 [===>..........................] - ETA: 8s
 28860416/170498071 [====>.........................] - ETA: 7s
 30416896/170498071 [====>.........................] - ETA: 7s
 31924224/170498071 [====>.........................] - ETA: 7s
 33816576/170498071 [====>.........................] - ETA: 7s
 36102144/170498071 [=====>........................] - ETA: 6s
 38608896/170498071 [=====>........................] - ETA: 6s
 41312256/170498071 [======>.......................] - ETA: 5s
 44244992/170498071 [======>.......................] - ETA: 5s
 47423488/170498071 [=======>......................] - ETA: 5s
 50708480/170498071 [=======>......................] - ETA: 4s
 53895168/170498071 [========>.....................] - ETA: 4s
 56991744/170498071 [=========>....................] - ETA: 4s
 59531264/170498071 [=========>....................] - ETA: 4s
 61808640/170498071 [=========>....................] - ETA: 3s
 64004096/170498071 [==========>...................] - ETA: 3s
 66035712/170498071 [==========>...................] - ETA: 3s
 68050944/170498071 [==========>...................] - ETA: 3s
 70131712/170498071 [===========>..................] - ETA: 3s
 72474624/170498071 [===========>..................] - ETA: 3s
 74637312/170498071 [============>.................] - ETA: 3s
 76734464/170498071 [============>.................] - ETA: 3s
 78733312/170498071 [============>.................] - ETA: 3s
 81010688/170498071 [=============>................] - ETA: 2s
 84058112/170498071 [=============>................] - ETA: 2s
 87334912/170498071 [==============>...............] - ETA: 2s
 89792512/170498071 [==============>...............] - ETA: 2s
 91938816/170498071 [===============>..............] - ETA: 2s
 93888512/170498071 [===============>..............] - ETA: 2s
 95920128/170498071 [===============>..............] - ETA: 2s
 97918976/170498071 [================>.............] - ETA: 2s
 99966976/170498071 [================>.............] - ETA: 2s
101834752/170498071 [================>.............] - ETA: 2s
103784448/170498071 [=================>............] - ETA: 2s
105668608/170498071 [=================>............] - ETA: 2s
107683840/170498071 [=================>............] - ETA: 1s
109568000/170498071 [==================>...........] - ETA: 1s
111403008/170498071 [==================>...........] - ETA: 1s
113287168/170498071 [==================>...........] - ETA: 1s
115236864/170498071 [===================>..........] - ETA: 1s
118169600/170498071 [===================>..........] - ETA: 1s
121217024/170498071 [====================>.........] - ETA: 1s
124329984/170498071 [====================>.........] - ETA: 1s
127426560/170498071 [=====================>........] - ETA: 1s
130539520/170498071 [=====================>........] - ETA: 1s
133652480/170498071 [======================>.......] - ETA: 1s
135733248/170498071 [======================>.......] - ETA: 0s
137617408/170498071 [=======================>......] - ETA: 0s
139567104/170498071 [=======================>......] - ETA: 0s
141336576/170498071 [=======================>......] - ETA: 0s
143155200/170498071 [========================>.....] - ETA: 0s
145039360/170498071 [========================>.....] - ETA: 0s
146989056/170498071 [========================>.....] - ETA: 0s
148938752/170498071 [=========================>....] - ETA: 0s
150822912/170498071 [=========================>....] - ETA: 0s
152723456/170498071 [=========================>....] - ETA: 0s
154607616/170498071 [==========================>...] - ETA: 0s
156557312/170498071 [==========================>...] - ETA: 0s
158441472/170498071 [==========================>...] - ETA: 0s
160391168/170498071 [===========================>..] - ETA: 0s
162291712/170498071 [===========================>..] - ETA: 0s
164175872/170498071 [===========================>..] - ETA: 0s
166060032/170498071 [============================>.] - ETA: 0s
168009728/170498071 [============================>.] - ETA: 0s
169943040/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 5s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 3629056/94765736 [>.............................] - ETA: 1s
 6791168/94765736 [=>............................] - ETA: 1s
10207232/94765736 [==>...........................] - ETA: 1s
13787136/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
21831680/94765736 [=====>........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
36405248/94765736 [==========>...................] - ETA: 0s
39526400/94765736 [===========>..................] - ETA: 0s
43950080/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
51888128/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
61366272/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
72253440/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
83189760/94765736 [=========================>....] - ETA: 0s
86769664/94765736 [==========================>...] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 17.07635498046875
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615857485.726084s

Real time: 1615857485.7261028
Epoch 1/5

on_train_batch_begin: 1615857486.501424s

on_train_batch_end: 1615857507.137961s

 2048/50000 [>.............................] - ETA: 8:21 - loss: 17.8888 - accuracy: 2.0313e-04
on_train_batch_begin: 1615857507.138553s

1 step training time: 20.637129s

on_train_batch_end: 1615857507.789644s

 4096/50000 [=>............................] - ETA: 4:07 - loss: 14.6946 - accuracy: 1.7297e-04
on_train_batch_begin: 1615857507.789963s

2 step training time: 0.651410s

on_train_batch_end: 1615857508.453268s

 6144/50000 [==>...........................] - ETA: 2:42 - loss: 12.8813 - accuracy: 3.4070e-04
on_train_batch_begin: 1615857508.453574s

3 step training time: 0.663612s

on_train_batch_end: 1615857509.104724s

 8192/50000 [===>..........................] - ETA: 1:59 - loss: 11.7339 - accuracy: 7.6079e-04
on_train_batch_begin: 1615857509.105041s

4 step training time: 0.651467s

on_train_batch_end: 1615857509.757070s

10240/50000 [=====>........................] - ETA: 1:33 - loss: 10.9828 - accuracy: 0.0016    
on_train_batch_begin: 1615857509.757393s

5 step training time: 0.652352s

on_train_batch_end: 1615857510.405685s

12288/50000 [======>.......................] - ETA: 1:15 - loss: 10.4209 - accuracy: 0.0038
on_train_batch_begin: 1615857510.405981s

6 step training time: 0.648588s

on_train_batch_end: 1615857511.055621s

14336/50000 [=======>......................] - ETA: 1:03 - loss: 9.9986 - accuracy: 0.0067 
on_train_batch_begin: 1615857511.055931s

7 step training time: 0.649951s

on_train_batch_end: 1615857511.707314s

16384/50000 [========>.....................] - ETA: 53s - loss: 9.6631 - accuracy: 0.0109 
on_train_batch_begin: 1615857511.707616s

8 step training time: 0.651685s

on_train_batch_end: 1615857512.366499s

18432/50000 [==========>...................] - ETA: 45s - loss: 9.3761 - accuracy: 0.0151
on_train_batch_begin: 1615857512.366798s

9 step training time: 0.659182s

on_train_batch_end: 1615857513.017511s

20480/50000 [===========>..................] - ETA: 39s - loss: 9.1392 - accuracy: 0.0183
on_train_batch_begin: 1615857513.017812s

10 step training time: 0.651013s

on_train_batch_end: 1615857513.671116s

22528/50000 [============>.................] - ETA: 34s - loss: 8.9410 - accuracy: 0.0205
on_train_batch_begin: 1615857513.671436s

11 step training time: 0.653624s

on_train_batch_end: 1615857514.322036s

24576/50000 [=============>................] - ETA: 29s - loss: 8.7628 - accuracy: 0.0235
on_train_batch_begin: 1615857514.322345s

12 step training time: 0.650909s

on_train_batch_end: 1615857514.975103s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.6111 - accuracy: 0.0266
on_train_batch_begin: 1615857514.975404s

13 step training time: 0.653059s

on_train_batch_end: 1615857515.634951s

28672/50000 [================>.............] - ETA: 22s - loss: 8.4686 - accuracy: 0.0293
on_train_batch_begin: 1615857515.635257s

14 step training time: 0.659853s

on_train_batch_end: 1615857516.286594s

30720/50000 [=================>............] - ETA: 19s - loss: 8.3468 - accuracy: 0.0320
on_train_batch_begin: 1615857516.286901s

15 step training time: 0.651645s

on_train_batch_end: 1615857516.939425s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.2309 - accuracy: 0.0342
on_train_batch_begin: 1615857516.939719s

16 step training time: 0.652818s

on_train_batch_end: 1615857517.601088s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.1171 - accuracy: 0.0365
on_train_batch_begin: 1615857517.601392s

17 step training time: 0.661673s

on_train_batch_end: 1615857518.252571s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.0134 - accuracy: 0.0387
on_train_batch_begin: 1615857518.252869s

18 step training time: 0.651477s

on_train_batch_end: 1615857518.902246s

38912/50000 [======================>.......] - ETA: 9s - loss: 7.9107 - accuracy: 0.0405 
on_train_batch_begin: 1615857518.902544s

19 step training time: 0.649675s

on_train_batch_end: 1615857519.552779s

40960/50000 [=======================>......] - ETA: 7s - loss: 7.8180 - accuracy: 0.0421
on_train_batch_begin: 1615857519.553079s

20 step training time: 0.650534s

on_train_batch_end: 1615857520.205192s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.7254 - accuracy: 0.0436
on_train_batch_begin: 1615857520.205492s

21 step training time: 0.652413s

on_train_batch_end: 1615857520.862242s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.6391 - accuracy: 0.0450
on_train_batch_begin: 1615857520.862538s

22 step training time: 0.657047s

on_train_batch_end: 1615857521.519713s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.5589 - accuracy: 0.0464
on_train_batch_begin: 1615857521.520010s

23 step training time: 0.657471s

on_train_batch_end: 1615857522.169286s

49152/50000 [============================>.] - ETA: 0s - loss: 7.4884 - accuracy: 0.0476
on_train_batch_begin: 1615857522.169587s

24 step training time: 0.649578s

on_train_batch_end: 1615857528.062181s

on_test_batch_begin: 1615857528.252277s

25 step training time: 6.082690s

on_epoch_end: 1615857533.445707s

Validation time: 5.193414s

Real time: 1615857533.445707s

Epoch time: 47.71962213516235s

50000/50000 [==============================] - 48s 954us/sample - loss: 7.4569 - accuracy: 0.0478 - val_loss: 24906.0195 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615857533.445912s

Real time: 1615857533.4459174
Epoch 2/5

on_train_batch_begin: 1615857533.449324s

on_train_batch_end: 1615857534.099385s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.5527 - accuracy: 0.0776
on_train_batch_begin: 1615857534.099694s

1 step training time: 0.650370s

on_train_batch_end: 1615857534.762238s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.5116 - accuracy: 0.0798
on_train_batch_begin: 1615857534.762535s

2 step training time: 0.662841s

on_train_batch_end: 1615857535.412179s

 6144/50000 [==>...........................] - ETA: 14s - loss: 5.4702 - accuracy: 0.0791
on_train_batch_begin: 1615857535.412477s

3 step training time: 0.649941s

on_train_batch_end: 1615857536.072146s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.4597 - accuracy: 0.0780
on_train_batch_begin: 1615857536.072442s

4 step training time: 0.659965s

on_train_batch_end: 1615857536.726652s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.4407 - accuracy: 0.0773
on_train_batch_begin: 1615857536.726947s

5 step training time: 0.654505s

on_train_batch_end: 1615857537.383858s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.3989 - accuracy: 0.0769
on_train_batch_begin: 1615857537.384167s

6 step training time: 0.657220s

on_train_batch_end: 1615857538.045037s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.3698 - accuracy: 0.0764
on_train_batch_begin: 1615857538.045331s

7 step training time: 0.661164s

on_train_batch_end: 1615857538.702163s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.3429 - accuracy: 0.0755
on_train_batch_begin: 1615857538.702466s

8 step training time: 0.657135s

on_train_batch_end: 1615857539.359068s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.3084 - accuracy: 0.0754
on_train_batch_begin: 1615857539.359366s

9 step training time: 0.656900s

on_train_batch_end: 1615857540.014606s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.2787 - accuracy: 0.0749 
on_train_batch_begin: 1615857540.014906s

10 step training time: 0.655540s

on_train_batch_end: 1615857540.667749s

22528/50000 [============>.................] - ETA: 8s - loss: 5.2398 - accuracy: 0.0749
on_train_batch_begin: 1615857540.668046s

11 step training time: 0.653140s

on_train_batch_end: 1615857541.324081s

24576/50000 [=============>................] - ETA: 8s - loss: 5.2034 - accuracy: 0.0752
on_train_batch_begin: 1615857541.324406s

12 step training time: 0.656360s

on_train_batch_end: 1615857541.984967s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.1750 - accuracy: 0.0754
on_train_batch_begin: 1615857541.985277s

13 step training time: 0.660872s

on_train_batch_end: 1615857542.641145s

28672/50000 [================>.............] - ETA: 6s - loss: 5.1479 - accuracy: 0.0755
on_train_batch_begin: 1615857542.641445s

14 step training time: 0.656168s

on_train_batch_end: 1615857543.300459s

30720/50000 [=================>............] - ETA: 6s - loss: 5.1175 - accuracy: 0.0754
on_train_batch_begin: 1615857543.300750s

15 step training time: 0.659305s

on_train_batch_end: 1615857543.954552s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.0913 - accuracy: 0.0755
on_train_batch_begin: 1615857543.954855s

16 step training time: 0.654104s

on_train_batch_end: 1615857544.600361s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.0640 - accuracy: 0.0757
on_train_batch_begin: 1615857544.600660s

17 step training time: 0.645806s

on_train_batch_end: 1615857545.261567s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.0412 - accuracy: 0.0756
on_train_batch_begin: 1615857545.261869s

18 step training time: 0.661209s

on_train_batch_end: 1615857545.918446s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.0184 - accuracy: 0.0753
on_train_batch_begin: 1615857545.918754s

19 step training time: 0.656884s

on_train_batch_end: 1615857546.574666s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.9818 - accuracy: 0.0755
on_train_batch_begin: 1615857546.574961s

20 step training time: 0.656208s

on_train_batch_end: 1615857547.233799s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.9547 - accuracy: 0.0755
on_train_batch_begin: 1615857547.234089s

21 step training time: 0.659127s

on_train_batch_end: 1615857547.890500s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.9300 - accuracy: 0.0755
on_train_batch_begin: 1615857547.890795s

22 step training time: 0.656707s

on_train_batch_end: 1615857548.548798s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.9096 - accuracy: 0.0757
on_train_batch_begin: 1615857548.549091s

23 step training time: 0.658296s

on_train_batch_end: 1615857549.205172s

49152/50000 [============================>.] - ETA: 0s - loss: 4.8891 - accuracy: 0.0759
on_train_batch_begin: 1615857549.205466s

24 step training time: 0.656375s

on_train_batch_end: 1615857549.482716s

on_test_batch_begin: 1615857549.546404s

25 step training time: 0.340938s

on_epoch_end: 1615857550.379116s

Validation time: 0.832697s

Real time: 1615857550.379116s

Epoch time: 16.93321466445923s

50000/50000 [==============================] - 17s 339us/sample - loss: 4.8781 - accuracy: 0.0759 - val_loss: 36.6110 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615857550.379308s

Real time: 1615857550.379314
Epoch 3/5

on_train_batch_begin: 1615857550.382667s

on_train_batch_end: 1615857551.033810s

 2048/50000 [>.............................] - ETA: 15s - loss: 4.0152 - accuracy: 0.0792
on_train_batch_begin: 1615857551.034105s

1 step training time: 0.651438s

on_train_batch_end: 1615857551.696060s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.9622 - accuracy: 0.0817
on_train_batch_begin: 1615857551.696373s

2 step training time: 0.662268s

on_train_batch_end: 1615857552.352069s

 6144/50000 [==>...........................] - ETA: 14s - loss: 3.9685 - accuracy: 0.0814
on_train_batch_begin: 1615857552.352396s

3 step training time: 0.656023s

on_train_batch_end: 1615857553.014601s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.9613 - accuracy: 0.0825
on_train_batch_begin: 1615857553.014897s

4 step training time: 0.662502s

on_train_batch_end: 1615857553.669669s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.9312 - accuracy: 0.0834
on_train_batch_begin: 1615857553.669965s

5 step training time: 0.655068s

on_train_batch_end: 1615857554.324919s

12288/50000 [======>.......................] - ETA: 12s - loss: 3.8903 - accuracy: 0.0843
on_train_batch_begin: 1615857554.325217s

6 step training time: 0.655252s

on_train_batch_end: 1615857554.989249s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.8713 - accuracy: 0.0845
on_train_batch_begin: 1615857554.989548s

7 step training time: 0.664331s

on_train_batch_end: 1615857555.640041s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.8616 - accuracy: 0.0846
on_train_batch_begin: 1615857555.640366s

8 step training time: 0.650818s

on_train_batch_end: 1615857556.303329s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.8588 - accuracy: 0.0851
on_train_batch_begin: 1615857556.303633s

9 step training time: 0.663267s

on_train_batch_end: 1615857556.959959s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.8627 - accuracy: 0.0857 
on_train_batch_begin: 1615857556.960277s

10 step training time: 0.656644s

on_train_batch_end: 1615857557.623664s

22528/50000 [============>.................] - ETA: 8s - loss: 3.8529 - accuracy: 0.0863
on_train_batch_begin: 1615857557.623969s

11 step training time: 0.663692s

on_train_batch_end: 1615857558.280918s

24576/50000 [=============>................] - ETA: 8s - loss: 3.8271 - accuracy: 0.0870
on_train_batch_begin: 1615857558.281224s

12 step training time: 0.657255s

on_train_batch_end: 1615857558.944578s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.8019 - accuracy: 0.0877
on_train_batch_begin: 1615857558.944881s

13 step training time: 0.663657s

on_train_batch_end: 1615857559.604437s

28672/50000 [================>.............] - ETA: 6s - loss: 3.7613 - accuracy: 0.0884
on_train_batch_begin: 1615857559.604746s

14 step training time: 0.659865s

on_train_batch_end: 1615857560.269082s

30720/50000 [=================>............] - ETA: 6s - loss: 3.7366 - accuracy: 0.0889
on_train_batch_begin: 1615857560.269380s

15 step training time: 0.664635s

on_train_batch_end: 1615857560.926549s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.7066 - accuracy: 0.0893
on_train_batch_begin: 1615857560.926848s

16 step training time: 0.657467s

on_train_batch_end: 1615857561.589737s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.6679 - accuracy: 0.0897
on_train_batch_begin: 1615857561.590039s

17 step training time: 0.663191s

on_train_batch_end: 1615857562.244717s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.6306 - accuracy: 0.0902
on_train_batch_begin: 1615857562.245016s

18 step training time: 0.654977s

on_train_batch_end: 1615857562.911055s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.5944 - accuracy: 0.0905
on_train_batch_begin: 1615857562.911362s

19 step training time: 0.666346s

on_train_batch_end: 1615857563.566322s

40960/50000 [=======================>......] - ETA: 2s - loss: 3.5576 - accuracy: 0.0909
on_train_batch_begin: 1615857563.566619s

20 step training time: 0.655258s

on_train_batch_end: 1615857564.231771s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.5150 - accuracy: 0.0912
on_train_batch_begin: 1615857564.232072s

21 step training time: 0.665452s

on_train_batch_end: 1615857564.886478s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.4716 - accuracy: 0.0915
on_train_batch_begin: 1615857564.886783s

22 step training time: 0.654711s

on_train_batch_end: 1615857565.552182s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.4218 - accuracy: 0.0918
on_train_batch_begin: 1615857565.552485s

23 step training time: 0.665702s

on_train_batch_end: 1615857566.205414s

49152/50000 [============================>.] - ETA: 0s - loss: 3.3799 - accuracy: 0.0921
on_train_batch_begin: 1615857566.205709s

24 step training time: 0.653224s

on_train_batch_end: 1615857566.490026s

on_test_batch_begin: 1615857566.552905s

25 step training time: 0.347196s

on_epoch_end: 1615857567.389668s

Validation time: 0.836750s

Real time: 1615857567.389668s

Epoch time: 17.0103702545166s

50000/50000 [==============================] - 17s 340us/sample - loss: 3.3631 - accuracy: 0.0922 - val_loss: 8.4605 - val_accuracy: 0.0051

on_epoch_begin: 1615857567.389851s

Real time: 1615857567.3898559
Epoch 4/5

on_train_batch_begin: 1615857567.393206s

on_train_batch_end: 1615857568.050395s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.3064 - accuracy: 0.0991
on_train_batch_begin: 1615857568.050697s

1 step training time: 0.657491s

on_train_batch_end: 1615857568.717899s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.2791 - accuracy: 0.0992
on_train_batch_begin: 1615857568.718195s

2 step training time: 0.667498s

on_train_batch_end: 1615857569.372838s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.2335 - accuracy: 0.0994
on_train_batch_begin: 1615857569.373141s

3 step training time: 0.654946s

on_train_batch_end: 1615857570.038931s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.2058 - accuracy: 0.0996
on_train_batch_begin: 1615857570.039236s

4 step training time: 0.666095s

on_train_batch_end: 1615857570.698257s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.1584 - accuracy: 0.0996
on_train_batch_begin: 1615857570.698565s

5 step training time: 0.659329s

on_train_batch_end: 1615857571.361515s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.1399 - accuracy: 0.0997
on_train_batch_begin: 1615857571.361815s

6 step training time: 0.663250s

on_train_batch_end: 1615857572.022727s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.1166 - accuracy: 0.0997
on_train_batch_begin: 1615857572.023025s

7 step training time: 0.661210s

on_train_batch_end: 1615857572.685085s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.0903 - accuracy: 0.0997
on_train_batch_begin: 1615857572.685376s

8 step training time: 0.662351s

on_train_batch_end: 1615857573.349875s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.0687 - accuracy: 0.0998
on_train_batch_begin: 1615857573.350171s

9 step training time: 0.664795s

on_train_batch_end: 1615857574.009794s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.0540 - accuracy: 0.0998 
on_train_batch_begin: 1615857574.010089s

10 step training time: 0.659918s

on_train_batch_end: 1615857574.672651s

22528/50000 [============>.................] - ETA: 8s - loss: 2.0301 - accuracy: 0.0998
on_train_batch_begin: 1615857574.672950s

11 step training time: 0.662861s

on_train_batch_end: 1615857575.336309s

24576/50000 [=============>................] - ETA: 8s - loss: 2.0184 - accuracy: 0.0998
on_train_batch_begin: 1615857575.336605s

12 step training time: 0.663655s

on_train_batch_end: 1615857575.999028s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.9969 - accuracy: 0.0998
on_train_batch_begin: 1615857575.999326s

13 step training time: 0.662721s

on_train_batch_end: 1615857576.658659s

28672/50000 [================>.............] - ETA: 6s - loss: 1.9769 - accuracy: 0.0999
on_train_batch_begin: 1615857576.658960s

14 step training time: 0.659634s

on_train_batch_end: 1615857577.322525s

30720/50000 [=================>............] - ETA: 6s - loss: 1.9693 - accuracy: 0.0999
on_train_batch_begin: 1615857577.322826s

15 step training time: 0.663865s

on_train_batch_end: 1615857577.984824s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.9521 - accuracy: 0.0999
on_train_batch_begin: 1615857577.985121s

16 step training time: 0.662296s

on_train_batch_end: 1615857578.648424s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.9381 - accuracy: 0.0999
on_train_batch_begin: 1615857578.648723s

17 step training time: 0.663601s

on_train_batch_end: 1615857579.311900s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.9239 - accuracy: 0.0999
on_train_batch_begin: 1615857579.312218s

18 step training time: 0.663495s

on_train_batch_end: 1615857579.979912s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.9069 - accuracy: 0.0999
on_train_batch_begin: 1615857579.980227s

19 step training time: 0.668009s

on_train_batch_end: 1615857580.640620s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.8947 - accuracy: 0.0999
on_train_batch_begin: 1615857580.640916s

20 step training time: 0.660689s

on_train_batch_end: 1615857581.304915s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.8853 - accuracy: 0.0999
on_train_batch_begin: 1615857581.305211s

21 step training time: 0.664295s

on_train_batch_end: 1615857581.967643s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8674 - accuracy: 0.0999
on_train_batch_begin: 1615857581.967938s

22 step training time: 0.662727s

on_train_batch_end: 1615857582.634393s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8591 - accuracy: 0.1000
on_train_batch_begin: 1615857582.634697s

23 step training time: 0.666759s

on_train_batch_end: 1615857583.288989s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8458 - accuracy: 0.1000
on_train_batch_begin: 1615857583.289286s

24 step training time: 0.654589s

on_train_batch_end: 1615857583.573498s

on_test_batch_begin: 1615857583.636604s

25 step training time: 0.347318s

on_epoch_end: 1615857584.489094s

Validation time: 0.852475s

Real time: 1615857584.489094s

Epoch time: 17.099255084991455s

50000/50000 [==============================] - 17s 342us/sample - loss: 1.8394 - accuracy: 0.1000 - val_loss: 7.5563 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615857584.489287s

Real time: 1615857584.4892921
Epoch 5/5

on_train_batch_begin: 1615857584.492679s

on_train_batch_end: 1615857585.152059s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.4477 - accuracy: 0.1001
on_train_batch_begin: 1615857585.152379s

1 step training time: 0.659700s

on_train_batch_end: 1615857585.819635s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.3684 - accuracy: 0.1001
on_train_batch_begin: 1615857585.819926s

2 step training time: 0.667547s

on_train_batch_end: 1615857586.475730s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.3472 - accuracy: 0.1001
on_train_batch_begin: 1615857586.476026s

3 step training time: 0.656101s

on_train_batch_end: 1615857587.141078s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.3370 - accuracy: 0.1001
on_train_batch_begin: 1615857587.141376s

4 step training time: 0.665350s

on_train_batch_end: 1615857587.807801s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.3467 - accuracy: 0.1001
on_train_batch_begin: 1615857587.808097s

5 step training time: 0.666721s

on_train_batch_end: 1615857588.476143s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.3387 - accuracy: 0.1001
on_train_batch_begin: 1615857588.476445s

6 step training time: 0.668348s

on_train_batch_end: 1615857589.136032s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.3201 - accuracy: 0.1001
on_train_batch_begin: 1615857589.136349s

7 step training time: 0.659904s

on_train_batch_end: 1615857589.799167s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.3188 - accuracy: 0.1001
on_train_batch_begin: 1615857589.799466s

8 step training time: 0.663117s

on_train_batch_end: 1615857590.464902s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.3029 - accuracy: 0.1002
on_train_batch_begin: 1615857590.465194s

9 step training time: 0.665728s

on_train_batch_end: 1615857591.133849s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.2961 - accuracy: 0.1002 
on_train_batch_begin: 1615857591.134142s

10 step training time: 0.668948s

on_train_batch_end: 1615857591.800684s

22528/50000 [============>.................] - ETA: 8s - loss: 1.2874 - accuracy: 0.1002
on_train_batch_begin: 1615857591.800978s

11 step training time: 0.666836s

on_train_batch_end: 1615857592.471915s

24576/50000 [=============>................] - ETA: 8s - loss: 1.2789 - accuracy: 0.1002
on_train_batch_begin: 1615857592.472230s

12 step training time: 0.671252s

on_train_batch_end: 1615857593.125771s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.2676 - accuracy: 0.1002
on_train_batch_begin: 1615857593.126062s

13 step training time: 0.653833s

on_train_batch_end: 1615857593.796528s

28672/50000 [================>.............] - ETA: 6s - loss: 1.2709 - accuracy: 0.1002
on_train_batch_begin: 1615857593.796825s

14 step training time: 0.670763s

on_train_batch_end: 1615857594.458716s

30720/50000 [=================>............] - ETA: 6s - loss: 1.2621 - accuracy: 0.1002
on_train_batch_begin: 1615857594.459008s

15 step training time: 0.662183s

on_train_batch_end: 1615857595.125744s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.2563 - accuracy: 0.1002
on_train_batch_begin: 1615857595.126045s

16 step training time: 0.667036s

on_train_batch_end: 1615857595.793008s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.2514 - accuracy: 0.1002
on_train_batch_begin: 1615857595.793303s

17 step training time: 0.667258s

on_train_batch_end: 1615857596.458870s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.2506 - accuracy: 0.1002
on_train_batch_begin: 1615857596.459167s

18 step training time: 0.665864s

on_train_batch_end: 1615857597.127590s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.2491 - accuracy: 0.1002
on_train_batch_begin: 1615857597.127884s

19 step training time: 0.668717s

on_train_batch_end: 1615857597.788984s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.2436 - accuracy: 0.1002
on_train_batch_begin: 1615857597.789273s

20 step training time: 0.661388s

on_train_batch_end: 1615857598.457751s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.2375 - accuracy: 0.1002
on_train_batch_begin: 1615857598.458045s

21 step training time: 0.668772s

on_train_batch_end: 1615857599.122693s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.2313 - accuracy: 0.1002
on_train_batch_begin: 1615857599.122988s

22 step training time: 0.664943s

on_train_batch_end: 1615857599.788163s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.2284 - accuracy: 0.1002
on_train_batch_begin: 1615857599.788460s

23 step training time: 0.665472s

on_train_batch_end: 1615857600.448190s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2249 - accuracy: 0.1002
on_train_batch_begin: 1615857600.448486s

24 step training time: 0.660026s

on_train_batch_end: 1615857600.732058s

on_test_batch_begin: 1615857600.794631s

25 step training time: 0.346145s

on_epoch_end: 1615857601.632550s

Validation time: 0.837905s

Real time: 1615857601.632550s

Epoch time: 17.143275499343872s

50000/50000 [==============================] - 17s 343us/sample - loss: 1.2234 - accuracy: 0.1002 - val_loss: 7.1835 - val_accuracy: 0.0998
Tempo do fit: 119.46787643432617