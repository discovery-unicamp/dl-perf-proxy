wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:08
   122880/170498071 [..............................] - ETA: 1:42
   532480/170498071 [..............................] - ETA: 39s 
  1867776/170498071 [..............................] - ETA: 15s
  4939776/170498071 [..............................] - ETA: 7s 
  8060928/170498071 [>.............................] - ETA: 5s
 11214848/170498071 [>.............................] - ETA: 4s
 14360576/170498071 [=>............................] - ETA: 4s
 17457152/170498071 [==>...........................] - ETA: 3s
 20602880/170498071 [==>...........................] - ETA: 3s
 23502848/170498071 [===>..........................] - ETA: 3s
 26648576/170498071 [===>..........................] - ETA: 3s
 29720576/170498071 [====>.........................] - ETA: 2s
 32735232/170498071 [====>.........................] - ETA: 2s
 35823616/170498071 [=====>........................] - ETA: 2s
 38690816/170498071 [=====>........................] - ETA: 2s
 41672704/170498071 [======>.......................] - ETA: 2s
 44523520/170498071 [======>.......................] - ETA: 2s
 47390720/170498071 [=======>......................] - ETA: 2s
 50274304/170498071 [=======>......................] - ETA: 2s
 53141504/170498071 [========>.....................] - ETA: 2s
 55975936/170498071 [========>.....................] - ETA: 2s
 58859520/170498071 [=========>....................] - ETA: 2s
 61644800/170498071 [=========>....................] - ETA: 2s
 64446464/170498071 [==========>...................] - ETA: 2s
 67297280/170498071 [==========>...................] - ETA: 1s
 70164480/170498071 [===========>..................] - ETA: 1s
 73048064/170498071 [===========>..................] - ETA: 1s
 75931648/170498071 [============>.................] - ETA: 1s
 78815232/170498071 [============>.................] - ETA: 1s
 81747968/170498071 [=============>................] - ETA: 1s
 84639744/170498071 [=============>................] - ETA: 1s
 87547904/170498071 [==============>...............] - ETA: 1s
 90464256/170498071 [==============>...............] - ETA: 1s
 93356032/170498071 [===============>..............] - ETA: 1s
 96256000/170498071 [===============>..............] - ETA: 1s
 99131392/170498071 [================>.............] - ETA: 1s
101982208/170498071 [================>.............] - ETA: 1s
104849408/170498071 [=================>............] - ETA: 1s
107749376/170498071 [=================>............] - ETA: 1s
110657536/170498071 [==================>...........] - ETA: 1s
113491968/170498071 [==================>...........] - ETA: 1s
116400128/170498071 [===================>..........] - ETA: 0s
119185408/170498071 [===================>..........] - ETA: 0s
122036224/170498071 [====================>.........] - ETA: 0s
124952576/170498071 [====================>.........] - ETA: 0s
127885312/170498071 [=====================>........] - ETA: 0s
130752512/170498071 [======================>.......] - ETA: 0s
133668864/170498071 [======================>.......] - ETA: 0s
136503296/170498071 [=======================>......] - ETA: 0s
139337728/170498071 [=======================>......] - ETA: 0s
142278656/170498071 [========================>.....] - ETA: 0s
145301504/170498071 [========================>.....] - ETA: 0s
148406272/170498071 [=========================>....] - ETA: 0s
151248896/170498071 [=========================>....] - ETA: 0s
154378240/170498071 [==========================>...] - ETA: 0s
157188096/170498071 [==========================>...] - ETA: 0s
160030720/170498071 [===========================>..] - ETA: 0s
162930688/170498071 [===========================>..] - ETA: 0s
165781504/170498071 [============================>.] - ETA: 0s
168681472/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 2s
 6094848/94765736 [>.............................] - ETA: 0s
10706944/94765736 [==>...........................] - ETA: 0s
13312000/94765736 [===>..........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
25198592/94765736 [======>.......................] - ETA: 0s
29507584/94765736 [========>.....................] - ETA: 0s
36052992/94765736 [==========>...................] - ETA: 0s
38510592/94765736 [===========>..................] - ETA: 0s
44810240/94765736 [=============>................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
50642944/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
60997632/94765736 [==================>...........] - ETA: 0s
67158016/94765736 [====================>.........] - ETA: 0s
72712192/94765736 [======================>.......] - ETA: 0s
76324864/94765736 [=======================>......] - ETA: 0s
81346560/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
89677824/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 27.16326093673706
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1599081402.226507s

Real time: 1599081402.22653
Epoch 1/5

on_train_batch_begin: 1599081403.275860s

on_train_batch_end: 1599081533.696383s

 1024/50000 [..............................] - ETA: 1:44:47 - loss: 16.6713 - accuracy: 2.8229e-04
on_train_batch_begin: 1599081533.697121s

1 step training time: 130.421261s

on_train_batch_end: 1599081533.947572s

 2048/50000 [>.............................] - ETA: 51:24 - loss: 14.5873 - accuracy: 1.7929e-04  
on_train_batch_begin: 1599081533.947992s

2 step training time: 0.250871s

on_train_batch_end: 1599081534.176160s

 3072/50000 [>.............................] - ETA: 33:35 - loss: 12.8057 - accuracy: 3.3824e-04
on_train_batch_begin: 1599081534.176557s

3 step training time: 0.228566s

on_train_batch_end: 1599081534.422301s

 4096/50000 [=>............................] - ETA: 24:41 - loss: 11.7111 - accuracy: 9.0218e-04
on_train_batch_begin: 1599081534.422694s

4 step training time: 0.246137s

on_train_batch_end: 1599081534.651788s

 5120/50000 [==>...........................] - ETA: 19:20 - loss: 10.9630 - accuracy: 0.0021    
on_train_batch_begin: 1599081534.652177s

5 step training time: 0.229483s

on_train_batch_end: 1599081534.856152s

 6144/50000 [==>...........................] - ETA: 15:46 - loss: 10.4591 - accuracy: 0.0038
on_train_batch_begin: 1599081534.856539s

6 step training time: 0.204362s

on_train_batch_end: 1599081535.104195s

 7168/50000 [===>..........................] - ETA: 13:14 - loss: 10.0638 - accuracy: 0.0063
on_train_batch_begin: 1599081535.104577s

7 step training time: 0.248038s

on_train_batch_end: 1599081535.338845s

 8192/50000 [===>..........................] - ETA: 11:19 - loss: 9.7494 - accuracy: 0.0096 
on_train_batch_begin: 1599081535.339225s

8 step training time: 0.234648s

on_train_batch_end: 1599081535.586114s

 9216/50000 [====>.........................] - ETA: 9:50 - loss: 9.4938 - accuracy: 0.0126 
on_train_batch_begin: 1599081535.586499s

9 step training time: 0.247274s

on_train_batch_end: 1599081535.813492s

10240/50000 [=====>........................] - ETA: 8:38 - loss: 9.2596 - accuracy: 0.0166
on_train_batch_begin: 1599081535.813879s

10 step training time: 0.227379s

on_train_batch_end: 1599081536.059604s

11264/50000 [=====>........................] - ETA: 7:40 - loss: 9.0718 - accuracy: 0.0198
on_train_batch_begin: 1599081536.060008s

11 step training time: 0.246130s

on_train_batch_end: 1599081536.288432s

12288/50000 [======>.......................] - ETA: 6:51 - loss: 8.9097 - accuracy: 0.0227
on_train_batch_begin: 1599081536.288822s

12 step training time: 0.228814s

on_train_batch_end: 1599081536.534416s

13312/50000 [======>.......................] - ETA: 6:10 - loss: 8.7646 - accuracy: 0.0264
on_train_batch_begin: 1599081536.534832s

13 step training time: 0.246010s

on_train_batch_end: 1599081536.782764s

14336/50000 [=======>......................] - ETA: 5:34 - loss: 8.6326 - accuracy: 0.0289
on_train_batch_begin: 1599081536.783178s

14 step training time: 0.248346s

on_train_batch_end: 1599081537.030486s

15360/50000 [========>.....................] - ETA: 5:04 - loss: 8.5102 - accuracy: 0.0317
on_train_batch_begin: 1599081537.030911s

15 step training time: 0.247733s

on_train_batch_end: 1599081537.284608s

16384/50000 [========>.....................] - ETA: 4:37 - loss: 8.4008 - accuracy: 0.0342
on_train_batch_begin: 1599081537.284993s

16 step training time: 0.254082s

on_train_batch_end: 1599081537.534978s

17408/50000 [=========>....................] - ETA: 4:13 - loss: 8.2939 - accuracy: 0.0370
on_train_batch_begin: 1599081537.535372s

17 step training time: 0.250379s

on_train_batch_end: 1599081537.783016s

18432/50000 [==========>...................] - ETA: 3:52 - loss: 8.1818 - accuracy: 0.0388
on_train_batch_begin: 1599081537.783403s

18 step training time: 0.248031s

on_train_batch_end: 1599081538.032521s

19456/50000 [==========>...................] - ETA: 3:33 - loss: 8.0830 - accuracy: 0.0403
on_train_batch_begin: 1599081538.032908s

19 step training time: 0.249506s

on_train_batch_end: 1599081538.286591s

20480/50000 [===========>..................] - ETA: 3:16 - loss: 7.9800 - accuracy: 0.0419
on_train_batch_begin: 1599081538.287011s

20 step training time: 0.254102s

on_train_batch_end: 1599081538.537318s

21504/50000 [===========>..................] - ETA: 3:00 - loss: 7.8851 - accuracy: 0.0432
on_train_batch_begin: 1599081538.537711s

21 step training time: 0.250700s

on_train_batch_end: 1599081538.785551s

22528/50000 [============>.................] - ETA: 2:46 - loss: 7.8011 - accuracy: 0.0443
on_train_batch_begin: 1599081538.785946s

22 step training time: 0.248235s

on_train_batch_end: 1599081539.034373s

23552/50000 [=============>................] - ETA: 2:33 - loss: 7.7231 - accuracy: 0.0451
on_train_batch_begin: 1599081539.034766s

23 step training time: 0.248820s

on_train_batch_end: 1599081539.271847s

24576/50000 [=============>................] - ETA: 2:21 - loss: 7.6484 - accuracy: 0.0457
on_train_batch_begin: 1599081539.272264s

24 step training time: 0.237497s

on_train_batch_end: 1599081539.517607s

25600/50000 [==============>...............] - ETA: 2:10 - loss: 7.5585 - accuracy: 0.0463
on_train_batch_begin: 1599081539.517990s

25 step training time: 0.245726s

on_train_batch_end: 1599081539.748112s

26624/50000 [==============>...............] - ETA: 2:00 - loss: 7.4819 - accuracy: 0.0470
on_train_batch_begin: 1599081539.748501s

26 step training time: 0.230511s

on_train_batch_end: 1599081539.993822s

27648/50000 [===============>..............] - ETA: 1:51 - loss: 7.4009 - accuracy: 0.0479
on_train_batch_begin: 1599081539.994213s

27 step training time: 0.245712s

on_train_batch_end: 1599081540.248823s

28672/50000 [================>.............] - ETA: 1:42 - loss: 7.3325 - accuracy: 0.0485
on_train_batch_begin: 1599081540.249211s

28 step training time: 0.254997s

on_train_batch_end: 1599081540.499961s

29696/50000 [================>.............] - ETA: 1:34 - loss: 7.2654 - accuracy: 0.0493
on_train_batch_begin: 1599081540.500351s

29 step training time: 0.251141s

on_train_batch_end: 1599081540.747217s

30720/50000 [=================>............] - ETA: 1:26 - loss: 7.2035 - accuracy: 0.0500
on_train_batch_begin: 1599081540.747608s

30 step training time: 0.247256s

on_train_batch_end: 1599081540.993720s

31744/50000 [==================>...........] - ETA: 1:19 - loss: 7.1401 - accuracy: 0.0505
on_train_batch_begin: 1599081540.994115s

31 step training time: 0.246507s

on_train_batch_end: 1599081541.228839s

32768/50000 [==================>...........] - ETA: 1:13 - loss: 7.0722 - accuracy: 0.0512
on_train_batch_begin: 1599081541.229219s

32 step training time: 0.235104s

on_train_batch_end: 1599081541.478444s

33792/50000 [===================>..........] - ETA: 1:06 - loss: 7.0068 - accuracy: 0.0520
on_train_batch_begin: 1599081541.478852s

33 step training time: 0.249633s

on_train_batch_end: 1599081541.705585s

34816/50000 [===================>..........] - ETA: 1:00 - loss: 6.9427 - accuracy: 0.0527
on_train_batch_begin: 1599081541.705966s

34 step training time: 0.227114s

on_train_batch_end: 1599081541.952562s

35840/50000 [====================>.........] - ETA: 55s - loss: 6.8788 - accuracy: 0.0534 
on_train_batch_begin: 1599081541.952945s

35 step training time: 0.246979s

on_train_batch_end: 1599081542.182214s

36864/50000 [=====================>........] - ETA: 49s - loss: 6.8178 - accuracy: 0.0539
on_train_batch_begin: 1599081542.182605s

36 step training time: 0.229660s

on_train_batch_end: 1599081542.428905s

37888/50000 [=====================>........] - ETA: 44s - loss: 6.7567 - accuracy: 0.0546
on_train_batch_begin: 1599081542.429284s

37 step training time: 0.246678s

on_train_batch_end: 1599081542.676144s

38912/50000 [======================>.......] - ETA: 40s - loss: 6.6959 - accuracy: 0.0551
on_train_batch_begin: 1599081542.676524s

38 step training time: 0.247240s

on_train_batch_end: 1599081542.925401s

39936/50000 [======================>.......] - ETA: 35s - loss: 6.6432 - accuracy: 0.0556
on_train_batch_begin: 1599081542.925787s

39 step training time: 0.249264s

on_train_batch_end: 1599081543.179796s

40960/50000 [=======================>......] - ETA: 31s - loss: 6.5888 - accuracy: 0.0561
on_train_batch_begin: 1599081543.180170s

40 step training time: 0.254383s

on_train_batch_end: 1599081543.430761s

41984/50000 [========================>.....] - ETA: 26s - loss: 6.5306 - accuracy: 0.0567
on_train_batch_begin: 1599081543.431161s

41 step training time: 0.250990s

on_train_batch_end: 1599081543.677554s

43008/50000 [========================>.....] - ETA: 22s - loss: 6.4766 - accuracy: 0.0571
on_train_batch_begin: 1599081543.677931s

42 step training time: 0.246770s

on_train_batch_end: 1599081543.927562s

44032/50000 [=========================>....] - ETA: 19s - loss: 6.4202 - accuracy: 0.0576
on_train_batch_begin: 1599081543.927936s

43 step training time: 0.250006s

on_train_batch_end: 1599081544.181322s

45056/50000 [==========================>...] - ETA: 15s - loss: 6.3667 - accuracy: 0.0581
on_train_batch_begin: 1599081544.181694s

44 step training time: 0.253758s

on_train_batch_end: 1599081544.432595s

46080/50000 [==========================>...] - ETA: 12s - loss: 6.3174 - accuracy: 0.0586
on_train_batch_begin: 1599081544.432970s

45 step training time: 0.251276s

on_train_batch_end: 1599081544.679654s

47104/50000 [===========================>..] - ETA: 8s - loss: 6.2655 - accuracy: 0.0592 
on_train_batch_begin: 1599081544.680036s

46 step training time: 0.247066s

on_train_batch_end: 1599081544.928784s

48128/50000 [===========================>..] - ETA: 5s - loss: 6.2127 - accuracy: 0.0598
on_train_batch_begin: 1599081544.929167s

47 step training time: 0.249131s

on_train_batch_end: 1599081545.183526s

49152/50000 [============================>.] - ETA: 2s - loss: 6.1591 - accuracy: 0.0604
on_train_batch_begin: 1599081545.183910s

48 step training time: 0.254743s

on_train_batch_end: 1599081552.432350s

on_test_batch_begin: 1599081552.807500s

49 step training time: 7.623590s

on_epoch_end: 1599081567.578607s

Validation time: 14.771088s

Real time: 1599081567.578607s

Epoch time: 165.35210347175598s

50000/50000 [==============================] - 165s 3ms/sample - loss: 6.1148 - accuracy: 0.0608 - val_loss: 8.2386 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599081567.578910s

Real time: 1599081567.5789196
Epoch 2/5

on_train_batch_begin: 1599081567.586729s

on_train_batch_end: 1599081567.835243s

 1024/50000 [..............................] - ETA: 12s - loss: 3.3744 - accuracy: 0.0894
on_train_batch_begin: 1599081567.835630s

1 step training time: 0.248901s

on_train_batch_end: 1599081568.065277s

 2048/50000 [>.............................] - ETA: 11s - loss: 3.3306 - accuracy: 0.0889
on_train_batch_begin: 1599081568.065648s

2 step training time: 0.230017s

on_train_batch_end: 1599081568.313839s

 3072/50000 [>.............................] - ETA: 11s - loss: 3.3726 - accuracy: 0.0904
on_train_batch_begin: 1599081568.314209s

3 step training time: 0.248561s

on_train_batch_end: 1599081568.542525s

 4096/50000 [=>............................] - ETA: 10s - loss: 3.3269 - accuracy: 0.0919
on_train_batch_begin: 1599081568.542929s

4 step training time: 0.228720s

on_train_batch_end: 1599081568.789539s

 5120/50000 [==>...........................] - ETA: 10s - loss: 3.2961 - accuracy: 0.0930
on_train_batch_begin: 1599081568.789914s

5 step training time: 0.246985s

on_train_batch_end: 1599081569.019191s

 6144/50000 [==>...........................] - ETA: 10s - loss: 3.2627 - accuracy: 0.0939
on_train_batch_begin: 1599081569.019568s

6 step training time: 0.229654s

on_train_batch_end: 1599081569.267942s

 7168/50000 [===>..........................] - ETA: 10s - loss: 3.2448 - accuracy: 0.0945
on_train_batch_begin: 1599081569.268343s

7 step training time: 0.248775s

on_train_batch_end: 1599081569.496842s

 8192/50000 [===>..........................] - ETA: 9s - loss: 3.2180 - accuracy: 0.0948 
on_train_batch_begin: 1599081569.497227s

8 step training time: 0.228884s

on_train_batch_end: 1599081569.745077s

 9216/50000 [====>.........................] - ETA: 9s - loss: 3.2017 - accuracy: 0.0952
on_train_batch_begin: 1599081569.745462s

9 step training time: 0.248235s

on_train_batch_end: 1599081569.996181s

10240/50000 [=====>........................] - ETA: 9s - loss: 3.1653 - accuracy: 0.0954
on_train_batch_begin: 1599081569.996571s

10 step training time: 0.251109s

on_train_batch_end: 1599081570.244647s

11264/50000 [=====>........................] - ETA: 9s - loss: 3.1405 - accuracy: 0.0958
on_train_batch_begin: 1599081570.245035s

11 step training time: 0.248464s

on_train_batch_end: 1599081570.493442s

12288/50000 [======>.......................] - ETA: 8s - loss: 3.1278 - accuracy: 0.0960
on_train_batch_begin: 1599081570.493834s

12 step training time: 0.248799s

on_train_batch_end: 1599081570.744597s

13312/50000 [======>.......................] - ETA: 8s - loss: 3.1028 - accuracy: 0.0961
on_train_batch_begin: 1599081570.744992s

13 step training time: 0.251158s

on_train_batch_end: 1599081570.993523s

14336/50000 [=======>......................] - ETA: 8s - loss: 3.0844 - accuracy: 0.0963
on_train_batch_begin: 1599081570.993960s

14 step training time: 0.248968s

on_train_batch_end: 1599081571.241582s

15360/50000 [========>.....................] - ETA: 8s - loss: 3.0538 - accuracy: 0.0966
on_train_batch_begin: 1599081571.241967s

15 step training time: 0.248007s

on_train_batch_end: 1599081571.490292s

16384/50000 [========>.....................] - ETA: 8s - loss: 3.0332 - accuracy: 0.0968
on_train_batch_begin: 1599081571.490670s

16 step training time: 0.248703s

on_train_batch_end: 1599081571.741634s

17408/50000 [=========>....................] - ETA: 7s - loss: 3.0319 - accuracy: 0.0970
on_train_batch_begin: 1599081571.742011s

17 step training time: 0.251341s

on_train_batch_end: 1599081571.989576s

18432/50000 [==========>...................] - ETA: 7s - loss: 3.0100 - accuracy: 0.0971
on_train_batch_begin: 1599081571.989951s

18 step training time: 0.247941s

on_train_batch_end: 1599081572.239659s

19456/50000 [==========>...................] - ETA: 7s - loss: 2.9964 - accuracy: 0.0972
on_train_batch_begin: 1599081572.240034s

19 step training time: 0.250082s

on_train_batch_end: 1599081572.487358s

20480/50000 [===========>..................] - ETA: 7s - loss: 2.9773 - accuracy: 0.0973
on_train_batch_begin: 1599081572.487739s

20 step training time: 0.247705s

on_train_batch_end: 1599081572.737564s

21504/50000 [===========>..................] - ETA: 6s - loss: 2.9520 - accuracy: 0.0974
on_train_batch_begin: 1599081572.737941s

21 step training time: 0.250202s

on_train_batch_end: 1599081572.989007s

22528/50000 [============>.................] - ETA: 6s - loss: 2.9374 - accuracy: 0.0975
on_train_batch_begin: 1599081572.989381s

22 step training time: 0.251440s

on_train_batch_end: 1599081573.237264s

23552/50000 [=============>................] - ETA: 6s - loss: 2.9179 - accuracy: 0.0976
on_train_batch_begin: 1599081573.237639s

23 step training time: 0.248257s

on_train_batch_end: 1599081573.484879s

24576/50000 [=============>................] - ETA: 6s - loss: 2.8954 - accuracy: 0.0978
on_train_batch_begin: 1599081573.485252s

24 step training time: 0.247613s

on_train_batch_end: 1599081573.735254s

25600/50000 [==============>...............] - ETA: 5s - loss: 2.8837 - accuracy: 0.0980
on_train_batch_begin: 1599081573.735629s

25 step training time: 0.250377s

on_train_batch_end: 1599081573.986587s

26624/50000 [==============>...............] - ETA: 5s - loss: 2.8719 - accuracy: 0.0981
on_train_batch_begin: 1599081573.986992s

26 step training time: 0.251363s

on_train_batch_end: 1599081574.237024s

27648/50000 [===============>..............] - ETA: 5s - loss: 2.8642 - accuracy: 0.0982
on_train_batch_begin: 1599081574.237403s

27 step training time: 0.250412s

on_train_batch_end: 1599081574.485753s

28672/50000 [================>.............] - ETA: 5s - loss: 2.8485 - accuracy: 0.0983
on_train_batch_begin: 1599081574.486132s

28 step training time: 0.248729s

on_train_batch_end: 1599081574.738173s

29696/50000 [================>.............] - ETA: 4s - loss: 2.8371 - accuracy: 0.0984
on_train_batch_begin: 1599081574.738552s

29 step training time: 0.252420s

on_train_batch_end: 1599081574.988553s

30720/50000 [=================>............] - ETA: 4s - loss: 2.8214 - accuracy: 0.0985
on_train_batch_begin: 1599081574.988930s

30 step training time: 0.250378s

on_train_batch_end: 1599081575.238678s

31744/50000 [==================>...........] - ETA: 4s - loss: 2.8071 - accuracy: 0.0986
on_train_batch_begin: 1599081575.239084s

31 step training time: 0.250154s

on_train_batch_end: 1599081575.487332s

32768/50000 [==================>...........] - ETA: 4s - loss: 2.7997 - accuracy: 0.0986
on_train_batch_begin: 1599081575.487709s

32 step training time: 0.248625s

on_train_batch_end: 1599081575.738825s

33792/50000 [===================>..........] - ETA: 3s - loss: 2.7899 - accuracy: 0.0987
on_train_batch_begin: 1599081575.739200s

33 step training time: 0.251491s

on_train_batch_end: 1599081575.989005s

34816/50000 [===================>..........] - ETA: 3s - loss: 2.7775 - accuracy: 0.0988
on_train_batch_begin: 1599081575.989379s

34 step training time: 0.250179s

on_train_batch_end: 1599081576.237873s

35840/50000 [====================>.........] - ETA: 3s - loss: 2.7700 - accuracy: 0.0988
on_train_batch_begin: 1599081576.238247s

35 step training time: 0.248868s

on_train_batch_end: 1599081576.488012s

36864/50000 [=====================>........] - ETA: 3s - loss: 2.7624 - accuracy: 0.0989
on_train_batch_begin: 1599081576.488389s

36 step training time: 0.250143s

on_train_batch_end: 1599081576.738137s

37888/50000 [=====================>........] - ETA: 2s - loss: 2.7515 - accuracy: 0.0989
on_train_batch_begin: 1599081576.738513s

37 step training time: 0.250124s

on_train_batch_end: 1599081576.988913s

38912/50000 [======================>.......] - ETA: 2s - loss: 2.7445 - accuracy: 0.0990
on_train_batch_begin: 1599081576.989294s

38 step training time: 0.250780s

on_train_batch_end: 1599081577.239164s

39936/50000 [======================>.......] - ETA: 2s - loss: 2.7308 - accuracy: 0.0990
on_train_batch_begin: 1599081577.239541s

39 step training time: 0.250248s

on_train_batch_end: 1599081577.488079s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.7193 - accuracy: 0.0991
on_train_batch_begin: 1599081577.488456s

40 step training time: 0.248915s

on_train_batch_end: 1599081577.740041s

41984/50000 [========================>.....] - ETA: 1s - loss: 2.7051 - accuracy: 0.0991
on_train_batch_begin: 1599081577.740419s

41 step training time: 0.251962s

on_train_batch_end: 1599081577.990300s

43008/50000 [========================>.....] - ETA: 1s - loss: 2.6964 - accuracy: 0.0991
on_train_batch_begin: 1599081577.990682s

42 step training time: 0.250263s

on_train_batch_end: 1599081578.237382s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.6829 - accuracy: 0.0992
on_train_batch_begin: 1599081578.237781s

43 step training time: 0.247098s

on_train_batch_end: 1599081578.485639s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.6709 - accuracy: 0.0992
on_train_batch_begin: 1599081578.486023s

44 step training time: 0.248243s

on_train_batch_end: 1599081578.737538s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.6589 - accuracy: 0.0993
on_train_batch_begin: 1599081578.737923s

45 step training time: 0.251900s

on_train_batch_end: 1599081578.987176s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.6467 - accuracy: 0.0993
on_train_batch_begin: 1599081578.987561s

46 step training time: 0.249637s

on_train_batch_end: 1599081579.235483s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.6376 - accuracy: 0.0994
on_train_batch_begin: 1599081579.235870s

47 step training time: 0.248310s

on_train_batch_end: 1599081579.484999s

49152/50000 [============================>.] - ETA: 0s - loss: 2.6291 - accuracy: 0.0994
on_train_batch_begin: 1599081579.485384s

48 step training time: 0.249514s

on_train_batch_end: 1599081579.719945s

on_test_batch_begin: 1599081579.760479s

49 step training time: 0.275094s

on_epoch_end: 1599081580.259520s

Validation time: 0.499022s

Real time: 1599081580.259520s

Epoch time: 12.680621147155762s

50000/50000 [==============================] - 13s 254us/sample - loss: 2.6218 - accuracy: 0.0995 - val_loss: 7.9513 - val_accuracy: 0.0999

on_epoch_begin: 1599081580.259769s

Real time: 1599081580.2597787
Epoch 3/5

on_train_batch_begin: 1599081580.267686s

on_train_batch_end: 1599081580.518532s

 1024/50000 [..............................] - ETA: 12s - loss: 2.0191 - accuracy: 0.1022
on_train_batch_begin: 1599081580.518940s

1 step training time: 0.251254s

on_train_batch_end: 1599081580.746907s

 2048/50000 [>.............................] - ETA: 11s - loss: 1.9381 - accuracy: 0.1018
on_train_batch_begin: 1599081580.747288s

2 step training time: 0.228348s

on_train_batch_end: 1599081580.995239s

 3072/50000 [>.............................] - ETA: 11s - loss: 1.9439 - accuracy: 0.1020
on_train_batch_begin: 1599081580.995617s

3 step training time: 0.248329s

on_train_batch_end: 1599081581.224822s

 4096/50000 [=>............................] - ETA: 10s - loss: 1.9839 - accuracy: 0.1017
on_train_batch_begin: 1599081581.225197s

4 step training time: 0.229581s

on_train_batch_end: 1599081581.473007s

 5120/50000 [==>...........................] - ETA: 10s - loss: 2.0263 - accuracy: 0.1015
on_train_batch_begin: 1599081581.473383s

5 step training time: 0.248186s

on_train_batch_end: 1599081581.728241s

 6144/50000 [==>...........................] - ETA: 10s - loss: 2.0287 - accuracy: 0.1014
on_train_batch_begin: 1599081581.728615s

6 step training time: 0.255231s

on_train_batch_end: 1599081581.979026s

 7168/50000 [===>..........................] - ETA: 10s - loss: 2.0167 - accuracy: 0.1014
on_train_batch_begin: 1599081581.979402s

7 step training time: 0.250787s

on_train_batch_end: 1599081582.225629s

 8192/50000 [===>..........................] - ETA: 10s - loss: 2.0135 - accuracy: 0.1015
on_train_batch_begin: 1599081582.226005s

8 step training time: 0.246603s

on_train_batch_end: 1599081582.475249s

 9216/50000 [====>.........................] - ETA: 9s - loss: 2.0214 - accuracy: 0.1017 
on_train_batch_begin: 1599081582.475642s

9 step training time: 0.249637s

on_train_batch_end: 1599081582.727663s

10240/50000 [=====>........................] - ETA: 9s - loss: 2.0116 - accuracy: 0.1017
on_train_batch_begin: 1599081582.728038s

10 step training time: 0.252396s

on_train_batch_end: 1599081582.978236s

11264/50000 [=====>........................] - ETA: 9s - loss: 2.0110 - accuracy: 0.1018
on_train_batch_begin: 1599081582.978616s

11 step training time: 0.250578s

on_train_batch_end: 1599081583.225433s

12288/50000 [======>.......................] - ETA: 9s - loss: 2.0046 - accuracy: 0.1018
on_train_batch_begin: 1599081583.225807s

12 step training time: 0.247190s

on_train_batch_end: 1599081583.476220s

13312/50000 [======>.......................] - ETA: 8s - loss: 2.0040 - accuracy: 0.1018
on_train_batch_begin: 1599081583.476599s

13 step training time: 0.250792s

on_train_batch_end: 1599081583.727757s

14336/50000 [=======>......................] - ETA: 8s - loss: 2.0224 - accuracy: 0.1018
on_train_batch_begin: 1599081583.728134s

14 step training time: 0.251535s

on_train_batch_end: 1599081583.978603s

15360/50000 [========>.....................] - ETA: 8s - loss: 2.0155 - accuracy: 0.1018
on_train_batch_begin: 1599081583.979012s

15 step training time: 0.250879s

on_train_batch_end: 1599081584.226414s

16384/50000 [========>.....................] - ETA: 8s - loss: 2.0041 - accuracy: 0.1019
on_train_batch_begin: 1599081584.226816s

16 step training time: 0.247804s

on_train_batch_end: 1599081584.476567s

17408/50000 [=========>....................] - ETA: 7s - loss: 1.9915 - accuracy: 0.1019
on_train_batch_begin: 1599081584.476944s

17 step training time: 0.250129s

on_train_batch_end: 1599081584.728699s

18432/50000 [==========>...................] - ETA: 7s - loss: 1.9780 - accuracy: 0.1020
on_train_batch_begin: 1599081584.729075s

18 step training time: 0.252131s

on_train_batch_end: 1599081584.978966s

19456/50000 [==========>...................] - ETA: 7s - loss: 1.9759 - accuracy: 0.1019
on_train_batch_begin: 1599081584.979350s

19 step training time: 0.250274s

on_train_batch_end: 1599081585.227515s

20480/50000 [===========>..................] - ETA: 7s - loss: 1.9836 - accuracy: 0.1019
on_train_batch_begin: 1599081585.227895s

20 step training time: 0.248545s

on_train_batch_end: 1599081585.478992s

21504/50000 [===========>..................] - ETA: 6s - loss: 1.9855 - accuracy: 0.1019
on_train_batch_begin: 1599081585.479375s

21 step training time: 0.251480s

on_train_batch_end: 1599081585.729336s

22528/50000 [============>.................] - ETA: 6s - loss: 1.9856 - accuracy: 0.1019
on_train_batch_begin: 1599081585.729712s

22 step training time: 0.250337s

on_train_batch_end: 1599081585.980235s

23552/50000 [=============>................] - ETA: 6s - loss: 1.9824 - accuracy: 0.1019
on_train_batch_begin: 1599081585.980615s

23 step training time: 0.250903s

on_train_batch_end: 1599081586.227776s

24576/50000 [=============>................] - ETA: 6s - loss: 1.9783 - accuracy: 0.1019
on_train_batch_begin: 1599081586.228152s

24 step training time: 0.247537s

on_train_batch_end: 1599081586.477878s

25600/50000 [==============>...............] - ETA: 5s - loss: 1.9739 - accuracy: 0.1019
on_train_batch_begin: 1599081586.478256s

25 step training time: 0.250105s

on_train_batch_end: 1599081586.728308s

26624/50000 [==============>...............] - ETA: 5s - loss: 1.9763 - accuracy: 0.1019
on_train_batch_begin: 1599081586.728686s

26 step training time: 0.250429s

on_train_batch_end: 1599081586.977743s

27648/50000 [===============>..............] - ETA: 5s - loss: 1.9711 - accuracy: 0.1019
on_train_batch_begin: 1599081586.978123s

27 step training time: 0.249437s

on_train_batch_end: 1599081587.227647s

28672/50000 [================>.............] - ETA: 5s - loss: 1.9678 - accuracy: 0.1019
on_train_batch_begin: 1599081587.228031s

28 step training time: 0.249908s

on_train_batch_end: 1599081587.478054s

29696/50000 [================>.............] - ETA: 4s - loss: 1.9617 - accuracy: 0.1019
on_train_batch_begin: 1599081587.478430s

29 step training time: 0.250399s

on_train_batch_end: 1599081587.728862s

30720/50000 [=================>............] - ETA: 4s - loss: 1.9611 - accuracy: 0.1019
on_train_batch_begin: 1599081587.729266s

30 step training time: 0.250836s

on_train_batch_end: 1599081587.979289s

31744/50000 [==================>...........] - ETA: 4s - loss: 1.9615 - accuracy: 0.1019
on_train_batch_begin: 1599081587.979668s

31 step training time: 0.250402s

on_train_batch_end: 1599081588.227007s

32768/50000 [==================>...........] - ETA: 4s - loss: 1.9589 - accuracy: 0.1019
on_train_batch_begin: 1599081588.227386s

32 step training time: 0.247718s

on_train_batch_end: 1599081588.476911s

33792/50000 [===================>..........] - ETA: 3s - loss: 1.9563 - accuracy: 0.1019
on_train_batch_begin: 1599081588.477290s

33 step training time: 0.249904s

on_train_batch_end: 1599081588.729487s

34816/50000 [===================>..........] - ETA: 3s - loss: 1.9494 - accuracy: 0.1019
on_train_batch_begin: 1599081588.729862s

34 step training time: 0.252573s

on_train_batch_end: 1599081588.980549s

35840/50000 [====================>.........] - ETA: 3s - loss: 1.9472 - accuracy: 0.1019
on_train_batch_begin: 1599081588.980927s

35 step training time: 0.251065s

on_train_batch_end: 1599081589.230119s

36864/50000 [=====================>........] - ETA: 3s - loss: 1.9417 - accuracy: 0.1018
on_train_batch_begin: 1599081589.230496s

36 step training time: 0.249568s

on_train_batch_end: 1599081589.480539s

37888/50000 [=====================>........] - ETA: 2s - loss: 1.9343 - accuracy: 0.1018
on_train_batch_begin: 1599081589.480915s

37 step training time: 0.250420s

on_train_batch_end: 1599081589.732540s

38912/50000 [======================>.......] - ETA: 2s - loss: 1.9305 - accuracy: 0.1018
on_train_batch_begin: 1599081589.732919s

38 step training time: 0.252004s

on_train_batch_end: 1599081589.982869s

39936/50000 [======================>.......] - ETA: 2s - loss: 1.9258 - accuracy: 0.1018
on_train_batch_begin: 1599081589.983249s

39 step training time: 0.250330s

on_train_batch_end: 1599081590.230851s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.9229 - accuracy: 0.1018
on_train_batch_begin: 1599081590.231230s

40 step training time: 0.247981s

on_train_batch_end: 1599081590.479472s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.9205 - accuracy: 0.1018
on_train_batch_begin: 1599081590.479851s

41 step training time: 0.248622s

on_train_batch_end: 1599081590.729243s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.9116 - accuracy: 0.1018
on_train_batch_begin: 1599081590.729622s

42 step training time: 0.249771s

on_train_batch_end: 1599081590.979061s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.9086 - accuracy: 0.1018
on_train_batch_begin: 1599081590.979440s

43 step training time: 0.249818s

on_train_batch_end: 1599081591.228333s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.9012 - accuracy: 0.1018
on_train_batch_begin: 1599081591.228859s

44 step training time: 0.249419s

on_train_batch_end: 1599081591.479535s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.8954 - accuracy: 0.1018
on_train_batch_begin: 1599081591.479916s

45 step training time: 0.251057s

on_train_batch_end: 1599081591.729491s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8902 - accuracy: 0.1018
on_train_batch_begin: 1599081591.729868s

46 step training time: 0.249952s

on_train_batch_end: 1599081591.979431s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.8869 - accuracy: 0.1018
on_train_batch_begin: 1599081591.979810s

47 step training time: 0.249942s

on_train_batch_end: 1599081592.205771s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8821 - accuracy: 0.1018
on_train_batch_begin: 1599081592.206167s

48 step training time: 0.226357s

on_train_batch_end: 1599081592.438641s

on_test_batch_begin: 1599081592.475113s

49 step training time: 0.268946s

on_epoch_end: 1599081592.975885s

Validation time: 0.500757s

Real time: 1599081592.975885s

Epoch time: 12.716126918792725s

50000/50000 [==============================] - 13s 254us/sample - loss: 1.8765 - accuracy: 0.1018 - val_loss: 6.3334 - val_accuracy: 0.0999

on_epoch_begin: 1599081592.976140s

Real time: 1599081592.9761503
Epoch 4/5

on_train_batch_begin: 1599081592.984023s

on_train_batch_end: 1599081593.233351s

 1024/50000 [..............................] - ETA: 12s - loss: 1.3877 - accuracy: 0.1024
on_train_batch_begin: 1599081593.233738s

1 step training time: 0.249715s

on_train_batch_end: 1599081593.462748s

 2048/50000 [>.............................] - ETA: 11s - loss: 1.4040 - accuracy: 0.1025
on_train_batch_begin: 1599081593.463162s

2 step training time: 0.229424s

on_train_batch_end: 1599081593.712251s

 3072/50000 [>.............................] - ETA: 11s - loss: 1.4076 - accuracy: 0.1023
on_train_batch_begin: 1599081593.712628s

3 step training time: 0.249466s

on_train_batch_end: 1599081593.959759s

 4096/50000 [=>............................] - ETA: 11s - loss: 1.4571 - accuracy: 0.1021
on_train_batch_begin: 1599081593.960149s

4 step training time: 0.247520s

on_train_batch_end: 1599081594.210383s

 5120/50000 [==>...........................] - ETA: 10s - loss: 1.4582 - accuracy: 0.1021
on_train_batch_begin: 1599081594.210768s

5 step training time: 0.250619s

on_train_batch_end: 1599081594.437275s

 6144/50000 [==>...........................] - ETA: 10s - loss: 1.4459 - accuracy: 0.1022
on_train_batch_begin: 1599081594.437660s

6 step training time: 0.226892s

on_train_batch_end: 1599081594.686320s

 7168/50000 [===>..........................] - ETA: 10s - loss: 1.4573 - accuracy: 0.1022
on_train_batch_begin: 1599081594.686704s

7 step training time: 0.249044s

on_train_batch_end: 1599081594.912916s

 8192/50000 [===>..........................] - ETA: 9s - loss: 1.4533 - accuracy: 0.1023 
on_train_batch_begin: 1599081594.913304s

8 step training time: 0.226599s

on_train_batch_end: 1599081595.160426s

 9216/50000 [====>.........................] - ETA: 9s - loss: 1.4562 - accuracy: 0.1022
on_train_batch_begin: 1599081595.160816s

9 step training time: 0.247512s

on_train_batch_end: 1599081595.391497s

10240/50000 [=====>........................] - ETA: 9s - loss: 1.4668 - accuracy: 0.1022
on_train_batch_begin: 1599081595.391884s

10 step training time: 0.231068s

on_train_batch_end: 1599081595.639483s

11264/50000 [=====>........................] - ETA: 9s - loss: 1.4728 - accuracy: 0.1023
on_train_batch_begin: 1599081595.639869s

11 step training time: 0.247985s

on_train_batch_end: 1599081595.866698s

12288/50000 [======>.......................] - ETA: 8s - loss: 1.4706 - accuracy: 0.1023
on_train_batch_begin: 1599081595.867136s

12 step training time: 0.227268s

on_train_batch_end: 1599081596.114280s

13312/50000 [======>.......................] - ETA: 8s - loss: 1.4653 - accuracy: 0.1022
on_train_batch_begin: 1599081596.114666s

13 step training time: 0.247529s

on_train_batch_end: 1599081596.366973s

14336/50000 [=======>......................] - ETA: 8s - loss: 1.4644 - accuracy: 0.1021
on_train_batch_begin: 1599081596.367365s

14 step training time: 0.252699s

on_train_batch_end: 1599081596.616716s

15360/50000 [========>.....................] - ETA: 8s - loss: 1.4497 - accuracy: 0.1022
on_train_batch_begin: 1599081596.617108s

15 step training time: 0.249743s

on_train_batch_end: 1599081596.866415s

16384/50000 [========>.....................] - ETA: 7s - loss: 1.4392 - accuracy: 0.1022
on_train_batch_begin: 1599081596.866829s

16 step training time: 0.249721s

on_train_batch_end: 1599081597.118013s

17408/50000 [=========>....................] - ETA: 7s - loss: 1.4261 - accuracy: 0.1021
on_train_batch_begin: 1599081597.118405s

17 step training time: 0.251576s

on_train_batch_end: 1599081597.368152s

18432/50000 [==========>...................] - ETA: 7s - loss: 1.4243 - accuracy: 0.1021
on_train_batch_begin: 1599081597.368541s

18 step training time: 0.250137s

on_train_batch_end: 1599081597.617180s

19456/50000 [==========>...................] - ETA: 7s - loss: 1.4197 - accuracy: 0.1021
on_train_batch_begin: 1599081597.617571s

19 step training time: 0.249029s

on_train_batch_end: 1599081597.866398s

20480/50000 [===========>..................] - ETA: 7s - loss: 1.4130 - accuracy: 0.1021
on_train_batch_begin: 1599081597.866776s

20 step training time: 0.249206s

on_train_batch_end: 1599081598.118156s

21504/50000 [===========>..................] - ETA: 6s - loss: 1.3986 - accuracy: 0.1021
on_train_batch_begin: 1599081598.118535s

21 step training time: 0.251759s

on_train_batch_end: 1599081598.369860s

22528/50000 [============>.................] - ETA: 6s - loss: 1.3883 - accuracy: 0.1022
on_train_batch_begin: 1599081598.370238s

22 step training time: 0.251703s

on_train_batch_end: 1599081598.619774s

23552/50000 [=============>................] - ETA: 6s - loss: 1.3856 - accuracy: 0.1022
on_train_batch_begin: 1599081598.620154s

23 step training time: 0.249916s

on_train_batch_end: 1599081598.868420s

24576/50000 [=============>................] - ETA: 6s - loss: 1.3750 - accuracy: 0.1022
on_train_batch_begin: 1599081598.868798s

24 step training time: 0.248644s

on_train_batch_end: 1599081599.121348s

25600/50000 [==============>...............] - ETA: 5s - loss: 1.3675 - accuracy: 0.1022
on_train_batch_begin: 1599081599.121727s

25 step training time: 0.252929s

on_train_batch_end: 1599081599.369803s

26624/50000 [==============>...............] - ETA: 5s - loss: 1.3630 - accuracy: 0.1022
on_train_batch_begin: 1599081599.370180s

26 step training time: 0.248453s

on_train_batch_end: 1599081599.620562s

27648/50000 [===============>..............] - ETA: 5s - loss: 1.3611 - accuracy: 0.1022
on_train_batch_begin: 1599081599.620940s

27 step training time: 0.250761s

on_train_batch_end: 1599081599.868011s

28672/50000 [================>.............] - ETA: 5s - loss: 1.3586 - accuracy: 0.1022
on_train_batch_begin: 1599081599.868390s

28 step training time: 0.247449s

on_train_batch_end: 1599081600.120162s

29696/50000 [================>.............] - ETA: 4s - loss: 1.3557 - accuracy: 0.1022
on_train_batch_begin: 1599081600.120541s

29 step training time: 0.252151s

on_train_batch_end: 1599081600.369761s

30720/50000 [=================>............] - ETA: 4s - loss: 1.3505 - accuracy: 0.1022
on_train_batch_begin: 1599081600.370138s

30 step training time: 0.249597s

on_train_batch_end: 1599081600.619627s

31744/50000 [==================>...........] - ETA: 4s - loss: 1.3474 - accuracy: 0.1022
on_train_batch_begin: 1599081600.620008s

31 step training time: 0.249869s

on_train_batch_end: 1599081600.869890s

32768/50000 [==================>...........] - ETA: 4s - loss: 1.3446 - accuracy: 0.1022
on_train_batch_begin: 1599081600.870266s

32 step training time: 0.250258s

on_train_batch_end: 1599081601.120813s

33792/50000 [===================>..........] - ETA: 3s - loss: 1.3412 - accuracy: 0.1022
on_train_batch_begin: 1599081601.121194s

33 step training time: 0.250928s

on_train_batch_end: 1599081601.369326s

34816/50000 [===================>..........] - ETA: 3s - loss: 1.3369 - accuracy: 0.1023
on_train_batch_begin: 1599081601.369704s

34 step training time: 0.248510s

on_train_batch_end: 1599081601.619120s

35840/50000 [====================>.........] - ETA: 3s - loss: 1.3307 - accuracy: 0.1023
on_train_batch_begin: 1599081601.619500s

35 step training time: 0.249796s

on_train_batch_end: 1599081601.867674s

36864/50000 [=====================>........] - ETA: 3s - loss: 1.3280 - accuracy: 0.1023
on_train_batch_begin: 1599081601.868055s

36 step training time: 0.248555s

on_train_batch_end: 1599081602.119501s

37888/50000 [=====================>........] - ETA: 2s - loss: 1.3279 - accuracy: 0.1023
on_train_batch_begin: 1599081602.119878s

37 step training time: 0.251822s

on_train_batch_end: 1599081602.366853s

38912/50000 [======================>.......] - ETA: 2s - loss: 1.3238 - accuracy: 0.1023
on_train_batch_begin: 1599081602.367231s

38 step training time: 0.247353s

on_train_batch_end: 1599081602.617200s

39936/50000 [======================>.......] - ETA: 2s - loss: 1.3215 - accuracy: 0.1023
on_train_batch_begin: 1599081602.617578s

39 step training time: 0.250347s

on_train_batch_end: 1599081602.866775s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.3149 - accuracy: 0.1023
on_train_batch_begin: 1599081602.867182s

40 step training time: 0.249604s

on_train_batch_end: 1599081603.119266s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.3081 - accuracy: 0.1023
on_train_batch_begin: 1599081603.119637s

41 step training time: 0.252455s

on_train_batch_end: 1599081603.366827s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.3081 - accuracy: 0.1023
on_train_batch_begin: 1599081603.367203s

42 step training time: 0.247565s

on_train_batch_end: 1599081603.617567s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.3077 - accuracy: 0.1023
on_train_batch_begin: 1599081603.617939s

43 step training time: 0.250736s

on_train_batch_end: 1599081603.866222s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.3072 - accuracy: 0.1023
on_train_batch_begin: 1599081603.866601s

44 step training time: 0.248662s

on_train_batch_end: 1599081604.116651s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.3036 - accuracy: 0.1023
on_train_batch_begin: 1599081604.117030s

45 step training time: 0.250429s

on_train_batch_end: 1599081604.365643s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.3027 - accuracy: 0.1023
on_train_batch_begin: 1599081604.366022s

46 step training time: 0.248992s

on_train_batch_end: 1599081604.614911s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.2996 - accuracy: 0.1023
on_train_batch_begin: 1599081604.615292s

47 step training time: 0.249270s

on_train_batch_end: 1599081604.864702s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2975 - accuracy: 0.1023
on_train_batch_begin: 1599081604.865081s

48 step training time: 0.249789s

on_train_batch_end: 1599081605.099431s

on_test_batch_begin: 1599081605.134987s

49 step training time: 0.269906s

on_epoch_end: 1599081605.635364s

Validation time: 0.500362s

Real time: 1599081605.635364s

Epoch time: 12.65923547744751s

50000/50000 [==============================] - 13s 253us/sample - loss: 1.2919 - accuracy: 0.1024 - val_loss: 9.3511 - val_accuracy: 0.0999

on_epoch_begin: 1599081605.635620s

Real time: 1599081605.6356294
Epoch 5/5

on_train_batch_begin: 1599081605.643599s

on_train_batch_end: 1599081605.894272s

 1024/50000 [..............................] - ETA: 12s - loss: 0.8431 - accuracy: 0.1028
on_train_batch_begin: 1599081605.894657s

1 step training time: 0.251058s

on_train_batch_end: 1599081606.121166s

 2048/50000 [>.............................] - ETA: 11s - loss: 0.9325 - accuracy: 0.1027
on_train_batch_begin: 1599081606.121542s

2 step training time: 0.226885s

on_train_batch_end: 1599081606.370944s

 3072/50000 [>.............................] - ETA: 11s - loss: 0.9288 - accuracy: 0.1027
on_train_batch_begin: 1599081606.371320s

3 step training time: 0.249778s

on_train_batch_end: 1599081606.600359s

 4096/50000 [=>............................] - ETA: 10s - loss: 0.9322 - accuracy: 0.1025
on_train_batch_begin: 1599081606.600735s

4 step training time: 0.229415s

on_train_batch_end: 1599081606.850762s

 5120/50000 [==>...........................] - ETA: 10s - loss: 0.9328 - accuracy: 0.1026
on_train_batch_begin: 1599081606.851168s

5 step training time: 0.250433s

on_train_batch_end: 1599081607.101570s

 6144/50000 [==>...........................] - ETA: 10s - loss: 0.9433 - accuracy: 0.1026
on_train_batch_begin: 1599081607.101952s

6 step training time: 0.250784s

on_train_batch_end: 1599081607.353134s

 7168/50000 [===>..........................] - ETA: 10s - loss: 0.9432 - accuracy: 0.1027
on_train_batch_begin: 1599081607.353513s

7 step training time: 0.251561s

on_train_batch_end: 1599081607.601343s

 8192/50000 [===>..........................] - ETA: 10s - loss: 0.9499 - accuracy: 0.1027
on_train_batch_begin: 1599081607.601720s

8 step training time: 0.248207s

on_train_batch_end: 1599081607.851984s

 9216/50000 [====>.........................] - ETA: 9s - loss: 0.9579 - accuracy: 0.1026 
on_train_batch_begin: 1599081607.852363s

9 step training time: 0.250643s

on_train_batch_end: 1599081608.102296s

10240/50000 [=====>........................] - ETA: 9s - loss: 0.9627 - accuracy: 0.1026
on_train_batch_begin: 1599081608.102672s

10 step training time: 0.250308s

on_train_batch_end: 1599081608.353413s

11264/50000 [=====>........................] - ETA: 9s - loss: 0.9544 - accuracy: 0.1027
on_train_batch_begin: 1599081608.353802s

11 step training time: 0.251131s

on_train_batch_end: 1599081608.602164s

12288/50000 [======>.......................] - ETA: 9s - loss: 0.9540 - accuracy: 0.1027
on_train_batch_begin: 1599081608.602540s

12 step training time: 0.248737s

on_train_batch_end: 1599081608.852593s

13312/50000 [======>.......................] - ETA: 8s - loss: 0.9458 - accuracy: 0.1027
on_train_batch_begin: 1599081608.852970s

13 step training time: 0.250430s

on_train_batch_end: 1599081609.100809s

14336/50000 [=======>......................] - ETA: 8s - loss: 0.9498 - accuracy: 0.1027
on_train_batch_begin: 1599081609.101187s

14 step training time: 0.248217s

on_train_batch_end: 1599081609.351147s

15360/50000 [========>.....................] - ETA: 8s - loss: 0.9460 - accuracy: 0.1027
on_train_batch_begin: 1599081609.351526s

15 step training time: 0.250339s

on_train_batch_end: 1599081609.596694s

16384/50000 [========>.....................] - ETA: 8s - loss: 0.9436 - accuracy: 0.1026
on_train_batch_begin: 1599081609.597072s

16 step training time: 0.245546s

on_train_batch_end: 1599081609.847394s

17408/50000 [=========>....................] - ETA: 7s - loss: 0.9458 - accuracy: 0.1026
on_train_batch_begin: 1599081609.847774s

17 step training time: 0.250703s

on_train_batch_end: 1599081610.096818s

18432/50000 [==========>...................] - ETA: 7s - loss: 0.9472 - accuracy: 0.1026
on_train_batch_begin: 1599081610.097198s

18 step training time: 0.249424s

on_train_batch_end: 1599081610.348298s

19456/50000 [==========>...................] - ETA: 7s - loss: 0.9482 - accuracy: 0.1026
on_train_batch_begin: 1599081610.348677s

19 step training time: 0.251479s

on_train_batch_end: 1599081610.593039s

20480/50000 [===========>..................] - ETA: 7s - loss: 0.9439 - accuracy: 0.1026
on_train_batch_begin: 1599081610.593419s

20 step training time: 0.244742s

on_train_batch_end: 1599081610.843796s

21504/50000 [===========>..................] - ETA: 6s - loss: 0.9436 - accuracy: 0.1025
on_train_batch_begin: 1599081610.844171s

21 step training time: 0.250752s

on_train_batch_end: 1599081611.093809s

22528/50000 [============>.................] - ETA: 6s - loss: 0.9447 - accuracy: 0.1026
on_train_batch_begin: 1599081611.094190s

22 step training time: 0.250019s

on_train_batch_end: 1599081611.345568s

23552/50000 [=============>................] - ETA: 6s - loss: 0.9434 - accuracy: 0.1027
on_train_batch_begin: 1599081611.345943s

23 step training time: 0.251753s

on_train_batch_end: 1599081611.596658s

24576/50000 [=============>................] - ETA: 6s - loss: 0.9443 - accuracy: 0.1027
on_train_batch_begin: 1599081611.597035s

24 step training time: 0.251092s

on_train_batch_end: 1599081611.846655s

25600/50000 [==============>...............] - ETA: 5s - loss: 0.9388 - accuracy: 0.1027
on_train_batch_begin: 1599081611.847060s

25 step training time: 0.250025s

on_train_batch_end: 1599081612.096309s

26624/50000 [==============>...............] - ETA: 5s - loss: 0.9398 - accuracy: 0.1027
on_train_batch_begin: 1599081612.096684s

26 step training time: 0.249624s

on_train_batch_end: 1599081612.346731s

27648/50000 [===============>..............] - ETA: 5s - loss: 0.9376 - accuracy: 0.1027
on_train_batch_begin: 1599081612.347131s

27 step training time: 0.250447s

on_train_batch_end: 1599081612.596404s

28672/50000 [================>.............] - ETA: 5s - loss: 0.9362 - accuracy: 0.1027
on_train_batch_begin: 1599081612.596777s

28 step training time: 0.249645s

on_train_batch_end: 1599081612.845386s

29696/50000 [================>.............] - ETA: 4s - loss: 0.9354 - accuracy: 0.1027
on_train_batch_begin: 1599081612.845794s

29 step training time: 0.249017s

on_train_batch_end: 1599081613.098335s

30720/50000 [=================>............] - ETA: 4s - loss: 0.9383 - accuracy: 0.1027
on_train_batch_begin: 1599081613.098708s

30 step training time: 0.252915s

on_train_batch_end: 1599081613.350151s

31744/50000 [==================>...........] - ETA: 4s - loss: 0.9394 - accuracy: 0.1027
on_train_batch_begin: 1599081613.350528s

31 step training time: 0.251820s

on_train_batch_end: 1599081613.599165s

32768/50000 [==================>...........] - ETA: 4s - loss: 0.9410 - accuracy: 0.1027
on_train_batch_begin: 1599081613.599544s

32 step training time: 0.249016s

on_train_batch_end: 1599081613.851082s

33792/50000 [===================>..........] - ETA: 3s - loss: 0.9418 - accuracy: 0.1027
on_train_batch_begin: 1599081613.851456s

33 step training time: 0.251913s

on_train_batch_end: 1599081614.103692s

34816/50000 [===================>..........] - ETA: 3s - loss: 0.9405 - accuracy: 0.1027
on_train_batch_begin: 1599081614.104075s

34 step training time: 0.252618s

on_train_batch_end: 1599081614.356284s

35840/50000 [====================>.........] - ETA: 3s - loss: 0.9455 - accuracy: 0.1027
on_train_batch_begin: 1599081614.356655s

35 step training time: 0.252580s

on_train_batch_end: 1599081614.605452s

36864/50000 [=====================>........] - ETA: 3s - loss: 0.9454 - accuracy: 0.1028
on_train_batch_begin: 1599081614.605831s

36 step training time: 0.249176s

on_train_batch_end: 1599081614.855903s

37888/50000 [=====================>........] - ETA: 2s - loss: 0.9454 - accuracy: 0.1027
on_train_batch_begin: 1599081614.856280s

37 step training time: 0.250449s

on_train_batch_end: 1599081615.107612s

38912/50000 [======================>.......] - ETA: 2s - loss: 0.9459 - accuracy: 0.1028
on_train_batch_begin: 1599081615.107987s

38 step training time: 0.251707s

on_train_batch_end: 1599081615.359279s

39936/50000 [======================>.......] - ETA: 2s - loss: 0.9461 - accuracy: 0.1027
on_train_batch_begin: 1599081615.359655s

39 step training time: 0.251668s

on_train_batch_end: 1599081615.609470s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.9420 - accuracy: 0.1027
on_train_batch_begin: 1599081615.609843s

40 step training time: 0.250188s

on_train_batch_end: 1599081615.859950s

41984/50000 [========================>.....] - ETA: 1s - loss: 0.9442 - accuracy: 0.1027
on_train_batch_begin: 1599081615.860326s

41 step training time: 0.250483s

on_train_batch_end: 1599081616.111648s

43008/50000 [========================>.....] - ETA: 1s - loss: 0.9420 - accuracy: 0.1028
on_train_batch_begin: 1599081616.112025s

42 step training time: 0.251698s

on_train_batch_end: 1599081616.362495s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.9407 - accuracy: 0.1027
on_train_batch_begin: 1599081616.362901s

43 step training time: 0.250876s

on_train_batch_end: 1599081616.611441s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.9401 - accuracy: 0.1027
on_train_batch_begin: 1599081616.611817s

44 step training time: 0.248916s

on_train_batch_end: 1599081616.862460s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.9391 - accuracy: 0.1028
on_train_batch_begin: 1599081616.862857s

45 step training time: 0.251039s

on_train_batch_end: 1599081617.113789s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.9388 - accuracy: 0.1028
on_train_batch_begin: 1599081617.114161s

46 step training time: 0.251304s

on_train_batch_end: 1599081617.363948s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9380 - accuracy: 0.1028
on_train_batch_begin: 1599081617.364323s

47 step training time: 0.250162s

on_train_batch_end: 1599081617.613295s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9352 - accuracy: 0.1028
on_train_batch_begin: 1599081617.613686s

48 step training time: 0.249363s

on_train_batch_end: 1599081617.848726s

on_test_batch_begin: 1599081617.890004s

49 step training time: 0.276318s

on_epoch_end: 1599081618.391199s

Validation time: 0.501177s

Real time: 1599081618.391199s

Epoch time: 12.755589962005615s

50000/50000 [==============================] - 13s 255us/sample - loss: 0.9345 - accuracy: 0.1028 - val_loss: 7.5928 - val_accuracy: 0.0999
Tempo do fit: 219.98134803771973