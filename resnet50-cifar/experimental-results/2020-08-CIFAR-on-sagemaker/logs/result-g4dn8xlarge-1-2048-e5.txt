wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:26
   221184/170498071 [..............................] - ETA: 1:09
  1368064/170498071 [..............................] - ETA: 17s 
  3383296/170498071 [..............................] - ETA: 9s 
  6938624/170498071 [>.............................] - ETA: 5s
 10461184/170498071 [>.............................] - ETA: 4s
 14000128/170498071 [=>............................] - ETA: 3s
 17457152/170498071 [==>...........................] - ETA: 3s
 20766720/170498071 [==>...........................] - ETA: 3s
 24272896/170498071 [===>..........................] - ETA: 3s
 27746304/170498071 [===>..........................] - ETA: 2s
 31236096/170498071 [====>.........................] - ETA: 2s
 34627584/170498071 [=====>........................] - ETA: 2s
 37871616/170498071 [=====>........................] - ETA: 2s
 41295872/170498071 [======>.......................] - ETA: 2s
 44769280/170498071 [======>.......................] - ETA: 2s
 48275456/170498071 [=======>......................] - ETA: 2s
 51781632/170498071 [========>.....................] - ETA: 2s
 54976512/170498071 [========>.....................] - ETA: 2s
 58220544/170498071 [=========>....................] - ETA: 1s
 61579264/170498071 [=========>....................] - ETA: 1s
 65052672/170498071 [==========>...................] - ETA: 1s
 68526080/170498071 [===========>..................] - ETA: 1s
 72015872/170498071 [===========>..................] - ETA: 1s
 75292672/170498071 [============>.................] - ETA: 1s
 78553088/170498071 [============>.................] - ETA: 1s
 81952768/170498071 [=============>................] - ETA: 1s
 85434368/170498071 [==============>...............] - ETA: 1s
 88915968/170498071 [==============>...............] - ETA: 1s
 92364800/170498071 [===============>..............] - ETA: 1s
 95657984/170498071 [===============>..............] - ETA: 1s
 98902016/170498071 [================>.............] - ETA: 1s
102342656/170498071 [=================>............] - ETA: 1s
105816064/170498071 [=================>............] - ETA: 1s
109322240/170498071 [==================>...........] - ETA: 0s
112762880/170498071 [==================>...........] - ETA: 0s
116023296/170498071 [===================>..........] - ETA: 0s
119332864/170498071 [===================>..........] - ETA: 0s
122675200/170498071 [====================>.........] - ETA: 0s
126181376/170498071 [=====================>........] - ETA: 0s
129703936/170498071 [=====================>........] - ETA: 0s
133103616/170498071 [======================>.......] - ETA: 0s
136388608/170498071 [======================>.......] - ETA: 0s
139714560/170498071 [=======================>......] - ETA: 0s
143106048/170498071 [========================>.....] - ETA: 0s
146563072/170498071 [========================>.....] - ETA: 0s
150069248/170498071 [=========================>....] - ETA: 0s
153493504/170498071 [==========================>...] - ETA: 0s
156704768/170498071 [==========================>...] - ETA: 0s
160030720/170498071 [===========================>..] - ETA: 0s
163389440/170498071 [===========================>..] - ETA: 0s
166846464/170498071 [============================>.] - ETA: 0s
170377216/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 2s
 2465792/94765736 [..............................] - ETA: 1s
 9904128/94765736 [==>...........................] - ETA: 0s
16211968/94765736 [====>.........................] - ETA: 0s
21397504/94765736 [=====>........................] - ETA: 0s
26460160/94765736 [=======>......................] - ETA: 0s
31465472/94765736 [========>.....................] - ETA: 0s
36732928/94765736 [==========>...................] - ETA: 0s
41902080/94765736 [============>.................] - ETA: 0s
46981120/94765736 [=============>................] - ETA: 0s
51994624/94765736 [===============>..............] - ETA: 0s
56893440/94765736 [=================>............] - ETA: 0s
62062592/94765736 [==================>...........] - ETA: 0s
67100672/94765736 [====================>.........] - ETA: 0s
72155136/94765736 [=====================>........] - ETA: 0s
77029376/94765736 [=======================>......] - ETA: 0s
82051072/94765736 [========================>.....] - ETA: 0s
87261184/94765736 [==========================>...] - ETA: 0s
91652096/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.356750249862671
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615758473.700336s

Real time: 1615758473.7003524
Epoch 1/5

on_train_batch_begin: 1615758474.574788s

on_train_batch_end: 1615758494.454618s

 2048/50000 [>.............................] - ETA: 8:05 - loss: 18.0798 - accuracy: 1.4377e-04
on_train_batch_begin: 1615758494.455220s

1 step training time: 19.880433s

on_train_batch_end: 1615758495.100130s

 4096/50000 [=>............................] - ETA: 3:59 - loss: 14.0381 - accuracy: 2.9135e-04
on_train_batch_begin: 1615758495.100446s

2 step training time: 0.645225s

on_train_batch_end: 1615758495.745766s

 6144/50000 [==>...........................] - ETA: 2:37 - loss: 12.1932 - accuracy: 6.0678e-04
on_train_batch_begin: 1615758495.746092s

3 step training time: 0.645647s

on_train_batch_end: 1615758496.392421s

 8192/50000 [===>..........................] - ETA: 1:55 - loss: 11.1963 - accuracy: 0.0021    
on_train_batch_begin: 1615758496.392732s

4 step training time: 0.646639s

on_train_batch_end: 1615758497.041538s

10240/50000 [=====>........................] - ETA: 1:30 - loss: 10.5885 - accuracy: 0.0054
on_train_batch_begin: 1615758497.041846s

5 step training time: 0.649114s

on_train_batch_end: 1615758497.690504s

12288/50000 [======>.......................] - ETA: 1:13 - loss: 10.1581 - accuracy: 0.0089
on_train_batch_begin: 1615758497.690815s

6 step training time: 0.648969s

on_train_batch_end: 1615758498.337588s

14336/50000 [=======>......................] - ETA: 1:01 - loss: 9.8234 - accuracy: 0.0135 
on_train_batch_begin: 1615758498.337893s

7 step training time: 0.647078s

on_train_batch_end: 1615758498.988036s

16384/50000 [========>.....................] - ETA: 51s - loss: 9.5846 - accuracy: 0.0171 
on_train_batch_begin: 1615758498.988340s

8 step training time: 0.650447s

on_train_batch_end: 1615758499.630791s

18432/50000 [==========>...................] - ETA: 44s - loss: 9.3807 - accuracy: 0.0207
on_train_batch_begin: 1615758499.631094s

9 step training time: 0.642754s

on_train_batch_end: 1615758500.279498s

20480/50000 [===========>..................] - ETA: 38s - loss: 9.2044 - accuracy: 0.0236
on_train_batch_begin: 1615758500.279808s

10 step training time: 0.648714s

on_train_batch_end: 1615758500.921601s

22528/50000 [============>.................] - ETA: 33s - loss: 9.0555 - accuracy: 0.0272
on_train_batch_begin: 1615758500.921900s

11 step training time: 0.642092s

on_train_batch_end: 1615758501.567727s

24576/50000 [=============>................] - ETA: 28s - loss: 8.9385 - accuracy: 0.0295
on_train_batch_begin: 1615758501.568035s

12 step training time: 0.646135s

on_train_batch_end: 1615758502.217304s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.8269 - accuracy: 0.0306
on_train_batch_begin: 1615758502.217602s

13 step training time: 0.649567s

on_train_batch_end: 1615758502.864121s

28672/50000 [================>.............] - ETA: 21s - loss: 8.7295 - accuracy: 0.0318
on_train_batch_begin: 1615758502.864424s

14 step training time: 0.646822s

on_train_batch_end: 1615758503.512747s

30720/50000 [=================>............] - ETA: 18s - loss: 8.6428 - accuracy: 0.0335
on_train_batch_begin: 1615758503.513074s

15 step training time: 0.648650s

on_train_batch_end: 1615758504.161918s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.5567 - accuracy: 0.0351
on_train_batch_begin: 1615758504.162217s

16 step training time: 0.649143s

on_train_batch_end: 1615758504.802425s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.4780 - accuracy: 0.0366
on_train_batch_begin: 1615758504.802724s

17 step training time: 0.640507s

on_train_batch_end: 1615758505.449126s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.4072 - accuracy: 0.0388
on_train_batch_begin: 1615758505.449427s

18 step training time: 0.646703s

on_train_batch_end: 1615758506.093353s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.3409 - accuracy: 0.0405 
on_train_batch_begin: 1615758506.093650s

19 step training time: 0.644223s

on_train_batch_end: 1615758506.739248s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.2789 - accuracy: 0.0417
on_train_batch_begin: 1615758506.739549s

20 step training time: 0.645899s

on_train_batch_end: 1615758507.387082s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.2223 - accuracy: 0.0429
on_train_batch_begin: 1615758507.387380s

21 step training time: 0.647831s

on_train_batch_end: 1615758508.030371s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.1687 - accuracy: 0.0443
on_train_batch_begin: 1615758508.030667s

22 step training time: 0.643287s

on_train_batch_end: 1615758508.673625s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.1286 - accuracy: 0.0451
on_train_batch_begin: 1615758508.673930s

23 step training time: 0.643263s

on_train_batch_end: 1615758509.311836s

49152/50000 [============================>.] - ETA: 0s - loss: 8.0783 - accuracy: 0.0462
on_train_batch_begin: 1615758509.312139s

24 step training time: 0.638209s

on_train_batch_end: 1615758515.006582s

on_test_batch_begin: 1615758515.193842s

25 step training time: 5.881703s

on_epoch_end: 1615758520.278711s

Validation time: 5.084854s

Real time: 1615758520.278711s

Epoch time: 46.57837653160095s

50000/50000 [==============================] - 47s 932us/sample - loss: 8.0597 - accuracy: 0.0465 - val_loss: 1541.2000 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615758520.278911s

Real time: 1615758520.2789166
Epoch 2/5

on_train_batch_begin: 1615758520.282319s

on_train_batch_end: 1615758520.920917s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.8574 - accuracy: 0.0749
on_train_batch_begin: 1615758520.921245s

1 step training time: 0.638927s

on_train_batch_end: 1615758521.570560s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.8311 - accuracy: 0.0769
on_train_batch_begin: 1615758521.570857s

2 step training time: 0.649612s

on_train_batch_end: 1615758522.215431s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.8391 - accuracy: 0.0762
on_train_batch_begin: 1615758522.215723s

3 step training time: 0.644866s

on_train_batch_end: 1615758522.860573s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.8233 - accuracy: 0.0751
on_train_batch_begin: 1615758522.860871s

4 step training time: 0.645148s

on_train_batch_end: 1615758523.502803s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.8109 - accuracy: 0.0759
on_train_batch_begin: 1615758523.503095s

5 step training time: 0.642225s

on_train_batch_end: 1615758524.146789s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.7839 - accuracy: 0.0761
on_train_batch_begin: 1615758524.147086s

6 step training time: 0.643991s

on_train_batch_end: 1615758524.796277s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.7735 - accuracy: 0.0762
on_train_batch_begin: 1615758524.796573s

7 step training time: 0.649486s

on_train_batch_end: 1615758525.443887s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.7673 - accuracy: 0.0766
on_train_batch_begin: 1615758525.444183s

8 step training time: 0.647610s

on_train_batch_end: 1615758526.089331s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.7419 - accuracy: 0.0769 
on_train_batch_begin: 1615758526.089625s

9 step training time: 0.645442s

on_train_batch_end: 1615758526.734179s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.7181 - accuracy: 0.0774
on_train_batch_begin: 1615758526.734474s

10 step training time: 0.644850s

on_train_batch_end: 1615758527.379006s

22528/50000 [============>.................] - ETA: 8s - loss: 6.7030 - accuracy: 0.0777
on_train_batch_begin: 1615758527.379313s

11 step training time: 0.644839s

on_train_batch_end: 1615758528.025128s

24576/50000 [=============>................] - ETA: 8s - loss: 6.6764 - accuracy: 0.0779
on_train_batch_begin: 1615758528.025429s

12 step training time: 0.646116s

on_train_batch_end: 1615758528.672174s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.6656 - accuracy: 0.0780
on_train_batch_begin: 1615758528.672471s

13 step training time: 0.647042s

on_train_batch_end: 1615758529.322371s

28672/50000 [================>.............] - ETA: 6s - loss: 6.6502 - accuracy: 0.0781
on_train_batch_begin: 1615758529.322672s

14 step training time: 0.650201s

on_train_batch_end: 1615758529.967363s

30720/50000 [=================>............] - ETA: 6s - loss: 6.6325 - accuracy: 0.0788
on_train_batch_begin: 1615758529.967666s

15 step training time: 0.644994s

on_train_batch_end: 1615758530.620172s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.6098 - accuracy: 0.0790
on_train_batch_begin: 1615758530.620474s

16 step training time: 0.652808s

on_train_batch_end: 1615758531.268985s

34816/50000 [===================>..........] - ETA: 4s - loss: 6.5822 - accuracy: 0.0795
on_train_batch_begin: 1615758531.269330s

17 step training time: 0.648856s

on_train_batch_end: 1615758531.915483s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.5651 - accuracy: 0.0797
on_train_batch_begin: 1615758531.915788s

18 step training time: 0.646458s

on_train_batch_end: 1615758532.565770s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.5438 - accuracy: 0.0796
on_train_batch_begin: 1615758532.566069s

19 step training time: 0.650281s

on_train_batch_end: 1615758533.213850s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.5235 - accuracy: 0.0801
on_train_batch_begin: 1615758533.214150s

20 step training time: 0.648081s

on_train_batch_end: 1615758533.859036s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.5018 - accuracy: 0.0799
on_train_batch_begin: 1615758533.859330s

21 step training time: 0.645180s

on_train_batch_end: 1615758534.510435s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.4783 - accuracy: 0.0798
on_train_batch_begin: 1615758534.510734s

22 step training time: 0.651404s

on_train_batch_end: 1615758535.156661s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.4549 - accuracy: 0.0796
on_train_batch_begin: 1615758535.156961s

23 step training time: 0.646228s

on_train_batch_end: 1615758535.801412s

49152/50000 [============================>.] - ETA: 0s - loss: 6.4375 - accuracy: 0.0793
on_train_batch_begin: 1615758535.801711s

24 step training time: 0.644750s

on_train_batch_end: 1615758536.079346s

on_test_batch_begin: 1615758536.142540s

25 step training time: 0.340829s

on_epoch_end: 1615758536.963941s

Validation time: 0.821385s

Real time: 1615758536.963941s

Epoch time: 16.685040950775146s

50000/50000 [==============================] - 17s 334us/sample - loss: 6.4300 - accuracy: 0.0793 - val_loss: 16887.0765 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615758536.964130s

Real time: 1615758536.9641352
Epoch 3/5

on_train_batch_begin: 1615758536.967525s

on_train_batch_end: 1615758537.612751s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.7383 - accuracy: 0.0741
on_train_batch_begin: 1615758537.613086s

1 step training time: 0.645561s

on_train_batch_end: 1615758538.266628s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.7403 - accuracy: 0.0753
on_train_batch_begin: 1615758538.266926s

2 step training time: 0.653840s

on_train_batch_end: 1615758538.913734s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.7453 - accuracy: 0.0754
on_train_batch_begin: 1615758538.914031s

3 step training time: 0.647105s

on_train_batch_end: 1615758539.564536s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.7412 - accuracy: 0.0746
on_train_batch_begin: 1615758539.564833s

4 step training time: 0.650802s

on_train_batch_end: 1615758540.211532s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.7137 - accuracy: 0.0729
on_train_batch_begin: 1615758540.211827s

5 step training time: 0.646995s

on_train_batch_end: 1615758540.861663s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.7074 - accuracy: 0.0706
on_train_batch_begin: 1615758540.861959s

6 step training time: 0.650132s

on_train_batch_end: 1615758541.509669s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.6862 - accuracy: 0.0684
on_train_batch_begin: 1615758541.509973s

7 step training time: 0.648014s

on_train_batch_end: 1615758542.159275s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.6585 - accuracy: 0.0667
on_train_batch_begin: 1615758542.159582s

8 step training time: 0.649608s

on_train_batch_end: 1615758542.807050s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.6457 - accuracy: 0.0646
on_train_batch_begin: 1615758542.807354s

9 step training time: 0.647772s

on_train_batch_end: 1615758543.457230s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.6251 - accuracy: 0.0630 
on_train_batch_begin: 1615758543.457535s

10 step training time: 0.650181s

on_train_batch_end: 1615758544.103613s

22528/50000 [============>.................] - ETA: 8s - loss: 5.6063 - accuracy: 0.0616
on_train_batch_begin: 1615758544.103929s

11 step training time: 0.646394s

on_train_batch_end: 1615758544.752129s

24576/50000 [=============>................] - ETA: 8s - loss: 5.5821 - accuracy: 0.0604
on_train_batch_begin: 1615758544.752442s

12 step training time: 0.648513s

on_train_batch_end: 1615758545.401556s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.5556 - accuracy: 0.0593
on_train_batch_begin: 1615758545.401862s

13 step training time: 0.649420s

on_train_batch_end: 1615758546.049469s

28672/50000 [================>.............] - ETA: 6s - loss: 5.5133 - accuracy: 0.0589
on_train_batch_begin: 1615758546.049783s

14 step training time: 0.647920s

on_train_batch_end: 1615758546.699310s

30720/50000 [=================>............] - ETA: 6s - loss: 5.4744 - accuracy: 0.0584
on_train_batch_begin: 1615758546.699613s

15 step training time: 0.649830s

on_train_batch_end: 1615758547.347735s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.4349 - accuracy: 0.0580
on_train_batch_begin: 1615758547.348035s

16 step training time: 0.648423s

on_train_batch_end: 1615758547.995209s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.3976 - accuracy: 0.0579
on_train_batch_begin: 1615758547.995505s

17 step training time: 0.647470s

on_train_batch_end: 1615758548.645449s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.3488 - accuracy: 0.0581
on_train_batch_begin: 1615758548.645750s

18 step training time: 0.650244s

on_train_batch_end: 1615758549.293880s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.2990 - accuracy: 0.0582
on_train_batch_begin: 1615758549.294180s

19 step training time: 0.648430s

on_train_batch_end: 1615758549.943868s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.2501 - accuracy: 0.0584
on_train_batch_begin: 1615758549.944166s

20 step training time: 0.649987s

on_train_batch_end: 1615758550.592010s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.2002 - accuracy: 0.0587
on_train_batch_begin: 1615758550.592303s

21 step training time: 0.648137s

on_train_batch_end: 1615758551.240354s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.1514 - accuracy: 0.0590
on_train_batch_begin: 1615758551.240653s

22 step training time: 0.648350s

on_train_batch_end: 1615758551.889973s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.0994 - accuracy: 0.0594
on_train_batch_begin: 1615758551.890288s

23 step training time: 0.649635s

on_train_batch_end: 1615758552.537029s

49152/50000 [============================>.] - ETA: 0s - loss: 5.0445 - accuracy: 0.0600
on_train_batch_begin: 1615758552.537353s

24 step training time: 0.647065s

on_train_batch_end: 1615758552.812060s

on_test_batch_begin: 1615758552.874805s

25 step training time: 0.337452s

on_epoch_end: 1615758553.707280s

Validation time: 0.832460s

Real time: 1615758553.707280s

Epoch time: 16.743159294128418s

50000/50000 [==============================] - 17s 335us/sample - loss: 5.0277 - accuracy: 0.0601 - val_loss: 39.7742 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615758553.707468s

Real time: 1615758553.7074738
Epoch 4/5

on_train_batch_begin: 1615758553.710850s

on_train_batch_end: 1615758554.357847s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.6310 - accuracy: 0.0744
on_train_batch_begin: 1615758554.358144s

1 step training time: 0.647293s

on_train_batch_end: 1615758555.010830s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.6387 - accuracy: 0.0748
on_train_batch_begin: 1615758555.011124s

2 step training time: 0.652981s

on_train_batch_end: 1615758555.659186s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.7002 - accuracy: 0.0748
on_train_batch_begin: 1615758555.659478s

3 step training time: 0.648354s

on_train_batch_end: 1615758556.308747s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.6859 - accuracy: 0.0753
on_train_batch_begin: 1615758556.309038s

4 step training time: 0.649560s

on_train_batch_end: 1615758556.957807s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.6123 - accuracy: 0.0765
on_train_batch_begin: 1615758556.958102s

5 step training time: 0.649063s

on_train_batch_end: 1615758557.605874s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.5408 - accuracy: 0.0772
on_train_batch_begin: 1615758557.606172s

6 step training time: 0.648070s

on_train_batch_end: 1615758558.254763s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.5022 - accuracy: 0.0779
on_train_batch_begin: 1615758558.255060s

7 step training time: 0.648888s

on_train_batch_end: 1615758558.903574s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.4552 - accuracy: 0.0789
on_train_batch_begin: 1615758558.903871s

8 step training time: 0.648810s

on_train_batch_end: 1615758559.553027s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.4011 - accuracy: 0.0799
on_train_batch_begin: 1615758559.553339s

9 step training time: 0.649468s

on_train_batch_end: 1615758560.201139s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.3697 - accuracy: 0.0806 
on_train_batch_begin: 1615758560.201435s

10 step training time: 0.648096s

on_train_batch_end: 1615758560.850386s

22528/50000 [============>.................] - ETA: 8s - loss: 3.3227 - accuracy: 0.0814
on_train_batch_begin: 1615758560.850680s

11 step training time: 0.649245s

on_train_batch_end: 1615758561.497285s

24576/50000 [=============>................] - ETA: 8s - loss: 3.2753 - accuracy: 0.0822
on_train_batch_begin: 1615758561.497584s

12 step training time: 0.646904s

on_train_batch_end: 1615758562.147111s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.2465 - accuracy: 0.0828
on_train_batch_begin: 1615758562.147403s

13 step training time: 0.649820s

on_train_batch_end: 1615758562.795825s

28672/50000 [================>.............] - ETA: 6s - loss: 3.2065 - accuracy: 0.0834
on_train_batch_begin: 1615758562.796126s

14 step training time: 0.648722s

on_train_batch_end: 1615758563.444527s

30720/50000 [=================>............] - ETA: 6s - loss: 3.1637 - accuracy: 0.0840
on_train_batch_begin: 1615758563.444826s

15 step training time: 0.648700s

on_train_batch_end: 1615758564.095223s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.1190 - accuracy: 0.0845
on_train_batch_begin: 1615758564.095519s

16 step training time: 0.650693s

on_train_batch_end: 1615758564.743016s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.0729 - accuracy: 0.0852
on_train_batch_begin: 1615758564.743310s

17 step training time: 0.647791s

on_train_batch_end: 1615758565.393283s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.0352 - accuracy: 0.0859
on_train_batch_begin: 1615758565.393577s

18 step training time: 0.650267s

on_train_batch_end: 1615758566.042290s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.0090 - accuracy: 0.0865
on_train_batch_begin: 1615758566.042588s

19 step training time: 0.649011s

on_train_batch_end: 1615758566.691430s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.9700 - accuracy: 0.0871
on_train_batch_begin: 1615758566.691728s

20 step training time: 0.649140s

on_train_batch_end: 1615758567.341628s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.9377 - accuracy: 0.0876
on_train_batch_begin: 1615758567.341928s

21 step training time: 0.650199s

on_train_batch_end: 1615758567.990523s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.9104 - accuracy: 0.0881
on_train_batch_begin: 1615758567.990819s

22 step training time: 0.648892s

on_train_batch_end: 1615758568.637134s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.8833 - accuracy: 0.0886
on_train_batch_begin: 1615758568.637424s

23 step training time: 0.646605s

on_train_batch_end: 1615758569.289839s

49152/50000 [============================>.] - ETA: 0s - loss: 2.8537 - accuracy: 0.0890
on_train_batch_begin: 1615758569.290146s

24 step training time: 0.652721s

on_train_batch_end: 1615758569.565523s

on_test_batch_begin: 1615758569.629169s

25 step training time: 0.339024s

on_epoch_end: 1615758570.460753s

Validation time: 0.831570s

Real time: 1615758570.460753s

Epoch time: 16.753295183181763s

50000/50000 [==============================] - 17s 335us/sample - loss: 2.8389 - accuracy: 0.0891 - val_loss: 7.6291 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615758570.460942s

Real time: 1615758570.460947
Epoch 5/5

on_train_batch_begin: 1615758570.464305s

on_train_batch_end: 1615758571.110431s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.9671 - accuracy: 0.1000
on_train_batch_begin: 1615758571.110725s

1 step training time: 0.646420s

on_train_batch_end: 1615758571.767880s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.9691 - accuracy: 0.1000
on_train_batch_begin: 1615758571.768180s

2 step training time: 0.657455s

on_train_batch_end: 1615758572.417419s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.9531 - accuracy: 0.0998
on_train_batch_begin: 1615758572.417709s

3 step training time: 0.649529s

on_train_batch_end: 1615758573.065483s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.9403 - accuracy: 0.0998
on_train_batch_begin: 1615758573.065775s

4 step training time: 0.648066s

on_train_batch_end: 1615758573.718644s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.9141 - accuracy: 0.0999
on_train_batch_begin: 1615758573.718945s

5 step training time: 0.653170s

on_train_batch_end: 1615758574.368694s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.8757 - accuracy: 0.1000
on_train_batch_begin: 1615758574.368993s

6 step training time: 0.650048s

on_train_batch_end: 1615758575.017069s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.8624 - accuracy: 0.1001
on_train_batch_begin: 1615758575.017379s

7 step training time: 0.648386s

on_train_batch_end: 1615758575.669309s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.8447 - accuracy: 0.1000
on_train_batch_begin: 1615758575.669614s

8 step training time: 0.652235s

on_train_batch_end: 1615758576.320191s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.8354 - accuracy: 0.1000
on_train_batch_begin: 1615758576.320489s

9 step training time: 0.650875s

on_train_batch_end: 1615758576.971460s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.8095 - accuracy: 0.1001 
on_train_batch_begin: 1615758576.971760s

10 step training time: 0.651271s

on_train_batch_end: 1615758577.621704s

22528/50000 [============>.................] - ETA: 8s - loss: 1.8051 - accuracy: 0.1001
on_train_batch_begin: 1615758577.622004s

11 step training time: 0.650245s

on_train_batch_end: 1615758578.273485s

24576/50000 [=============>................] - ETA: 8s - loss: 1.7872 - accuracy: 0.1001
on_train_batch_begin: 1615758578.273783s

12 step training time: 0.651779s

on_train_batch_end: 1615758578.920666s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.7691 - accuracy: 0.1001
on_train_batch_begin: 1615758578.920967s

13 step training time: 0.647184s

on_train_batch_end: 1615758579.569245s

28672/50000 [================>.............] - ETA: 6s - loss: 1.7642 - accuracy: 0.1001
on_train_batch_begin: 1615758579.569544s

14 step training time: 0.648577s

on_train_batch_end: 1615758580.221785s

30720/50000 [=================>............] - ETA: 6s - loss: 1.7553 - accuracy: 0.1000
on_train_batch_begin: 1615758580.222084s

15 step training time: 0.652540s

on_train_batch_end: 1615758580.873622s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.7415 - accuracy: 0.1001
on_train_batch_begin: 1615758580.873921s

16 step training time: 0.651837s

on_train_batch_end: 1615758581.522940s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.7317 - accuracy: 0.1001
on_train_batch_begin: 1615758581.523257s

17 step training time: 0.649336s

on_train_batch_end: 1615758582.173826s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.7216 - accuracy: 0.1001
on_train_batch_begin: 1615758582.174122s

18 step training time: 0.650865s

on_train_batch_end: 1615758582.822464s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.7072 - accuracy: 0.1001
on_train_batch_begin: 1615758582.822765s

19 step training time: 0.648642s

on_train_batch_end: 1615758583.477725s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.7026 - accuracy: 0.1001
on_train_batch_begin: 1615758583.478022s

20 step training time: 0.655257s

on_train_batch_end: 1615758584.126546s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.6900 - accuracy: 0.1001
on_train_batch_begin: 1615758584.126845s

21 step training time: 0.648824s

on_train_batch_end: 1615758584.776032s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.6833 - accuracy: 0.1001
on_train_batch_begin: 1615758584.776337s

22 step training time: 0.649492s

on_train_batch_end: 1615758585.424873s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.6714 - accuracy: 0.1001
on_train_batch_begin: 1615758585.425203s

23 step training time: 0.648866s

on_train_batch_end: 1615758586.073187s

49152/50000 [============================>.] - ETA: 0s - loss: 1.6629 - accuracy: 0.1001
on_train_batch_begin: 1615758586.073480s

24 step training time: 0.648277s

on_train_batch_end: 1615758586.350549s

on_test_batch_begin: 1615758586.413651s

25 step training time: 0.340171s

on_epoch_end: 1615758587.231595s

Validation time: 0.817929s

Real time: 1615758587.231595s

Epoch time: 16.77066445350647s

50000/50000 [==============================] - 17s 335us/sample - loss: 1.6591 - accuracy: 0.1001 - val_loss: 7.1036 - val_accuracy: 0.0998
Tempo do fit: 117.0512068271637