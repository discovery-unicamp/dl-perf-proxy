wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:49
   106496/170498071 [..............................] - ETA: 1:59
   499712/170498071 [..............................] - ETA: 42s 
   925696/170498071 [..............................] - ETA: 32s
  1466368/170498071 [..............................] - ETA: 26s
  2056192/170498071 [..............................] - ETA: 22s
  2711552/170498071 [..............................] - ETA: 20s
  3399680/170498071 [..............................] - ETA: 18s
  4169728/170498071 [..............................] - ETA: 17s
  5054464/170498071 [..............................] - ETA: 15s
  5955584/170498071 [>.............................] - ETA: 14s
  6987776/170498071 [>.............................] - ETA: 13s
  8069120/170498071 [>.............................] - ETA: 12s
  9297920/170498071 [>.............................] - ETA: 11s
 10592256/170498071 [>.............................] - ETA: 11s
 12001280/170498071 [=>............................] - ETA: 10s
 13574144/170498071 [=>............................] - ETA: 9s 
 15409152/170498071 [=>............................] - ETA: 8s
 17227776/170498071 [==>...........................] - ETA: 8s
 19046400/170498071 [==>...........................] - ETA: 7s
 21061632/170498071 [==>...........................] - ETA: 7s
 23126016/170498071 [===>..........................] - ETA: 6s
 25108480/170498071 [===>..........................] - ETA: 6s
 27058176/170498071 [===>..........................] - ETA: 6s
 29433856/170498071 [====>.........................] - ETA: 5s
 31612928/170498071 [====>.........................] - ETA: 5s
 34086912/170498071 [====>.........................] - ETA: 5s
 36036608/170498071 [=====>........................] - ETA: 5s
 38248448/170498071 [=====>........................] - ETA: 5s
 40148992/170498071 [======>.......................] - ETA: 4s
 42819584/170498071 [======>.......................] - ETA: 4s
 45096960/170498071 [======>.......................] - ETA: 4s
 47357952/170498071 [=======>......................] - ETA: 4s
 49389568/170498071 [=======>......................] - ETA: 4s
 51666944/170498071 [========>.....................] - ETA: 4s
 54075392/170498071 [========>.....................] - ETA: 3s
 56221696/170498071 [========>.....................] - ETA: 3s
 58499072/170498071 [=========>....................] - ETA: 3s
 60841984/170498071 [=========>....................] - ETA: 3s
 63119360/170498071 [==========>...................] - ETA: 3s
 65347584/170498071 [==========>...................] - ETA: 3s
 67641344/170498071 [==========>...................] - ETA: 3s
 69869568/170498071 [===========>..................] - ETA: 3s
 72097792/170498071 [===========>..................] - ETA: 3s
 74375168/170498071 [============>.................] - ETA: 2s
 76587008/170498071 [============>.................] - ETA: 2s
 78848000/170498071 [============>.................] - ETA: 2s
 81141760/170498071 [=============>................] - ETA: 2s
 83468288/170498071 [=============>................] - ETA: 2s
 85762048/170498071 [==============>...............] - ETA: 2s
 88039424/170498071 [==============>...............] - ETA: 2s
 90251264/170498071 [==============>...............] - ETA: 2s
 92463104/170498071 [===============>..............] - ETA: 2s
 94740480/170498071 [===============>..............] - ETA: 2s
 97017856/170498071 [================>.............] - ETA: 2s
 99229696/170498071 [================>.............] - ETA: 2s
101572608/170498071 [================>.............] - ETA: 1s
103784448/170498071 [=================>............] - ETA: 1s
106192896/170498071 [=================>............] - ETA: 1s
108404736/170498071 [==================>...........] - ETA: 1s
110813184/170498071 [==================>...........] - ETA: 1s
112844800/170498071 [==================>...........] - ETA: 1s
115367936/170498071 [===================>..........] - ETA: 1s
117317632/170498071 [===================>..........] - ETA: 1s
120168448/170498071 [====================>.........] - ETA: 1s
122789888/170498071 [====================>.........] - ETA: 1s
125657088/170498071 [=====================>........] - ETA: 1s
128442368/170498071 [=====================>........] - ETA: 1s
130719744/170498071 [======================>.......] - ETA: 1s
132866048/170498071 [======================>.......] - ETA: 0s
135143424/170498071 [======================>.......] - ETA: 0s
137289728/170498071 [=======================>......] - ETA: 0s
139419648/170498071 [=======================>......] - ETA: 0s
141598720/170498071 [=======================>......] - ETA: 0s
143761408/170498071 [========================>.....] - ETA: 0s
145760256/170498071 [========================>.....] - ETA: 0s
147841024/170498071 [=========================>....] - ETA: 0s
150839296/170498071 [=========================>....] - ETA: 0s
153821184/170498071 [==========================>...] - ETA: 0s
156672000/170498071 [==========================>...] - ETA: 0s
159539200/170498071 [===========================>..] - ETA: 0s
162439168/170498071 [===========================>..] - ETA: 0s
165486592/170498071 [============================>.] - ETA: 0s
168337408/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 4s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 3416064/94765736 [>.............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 2s
14172160/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
28114944/94765736 [=======>......................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
34004992/94765736 [=========>....................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
45236224/94765736 [=============>................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 1s
49823744/94765736 [==============>...............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
70746112/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
86368256/94765736 [==========================>...] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 16.40881085395813
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615862094.825757s

Real time: 1615862094.825773
Epoch 1/5

on_train_batch_begin: 1615862095.600767s

on_train_batch_end: 1615862113.363761s

 1024/50000 [..............................] - ETA: 14:46 - loss: 17.6320 - accuracy: 1.9360e-04
on_train_batch_begin: 1615862113.364415s

1 step training time: 17.763649s

on_train_batch_end: 1615862113.694951s

 2048/50000 [>.............................] - ETA: 7:21 - loss: 14.5555 - accuracy: 2.9325e-04 
on_train_batch_begin: 1615862113.695277s

2 step training time: 0.330861s

on_train_batch_end: 1615862114.010726s

 3072/50000 [>.............................] - ETA: 4:53 - loss: 12.5527 - accuracy: 5.7030e-04
on_train_batch_begin: 1615862114.011041s

3 step training time: 0.315764s

on_train_batch_end: 1615862114.329811s

 4096/50000 [=>............................] - ETA: 3:38 - loss: 11.4859 - accuracy: 0.0014    
on_train_batch_begin: 1615862114.330114s

4 step training time: 0.319073s

on_train_batch_end: 1615862114.642085s

 5120/50000 [==>...........................] - ETA: 2:53 - loss: 10.8260 - accuracy: 0.0040
on_train_batch_begin: 1615862114.642384s

5 step training time: 0.312270s

on_train_batch_end: 1615862114.962354s

 6144/50000 [==>...........................] - ETA: 2:23 - loss: 10.3578 - accuracy: 0.0081
on_train_batch_begin: 1615862114.962654s

6 step training time: 0.320269s

on_train_batch_end: 1615862115.275584s

 7168/50000 [===>..........................] - ETA: 2:02 - loss: 10.0273 - accuracy: 0.0130
on_train_batch_begin: 1615862115.275884s

7 step training time: 0.313230s

on_train_batch_end: 1615862115.593041s

 8192/50000 [===>..........................] - ETA: 1:45 - loss: 9.7780 - accuracy: 0.0167 
on_train_batch_begin: 1615862115.593344s

8 step training time: 0.317460s

on_train_batch_end: 1615862115.906555s

 9216/50000 [====>.........................] - ETA: 1:33 - loss: 9.5871 - accuracy: 0.0184
on_train_batch_begin: 1615862115.906853s

9 step training time: 0.313509s

on_train_batch_end: 1615862116.223504s

10240/50000 [=====>........................] - ETA: 1:23 - loss: 9.4268 - accuracy: 0.0216
on_train_batch_begin: 1615862116.223829s

10 step training time: 0.316977s

on_train_batch_end: 1615862116.534458s

11264/50000 [=====>........................] - ETA: 1:14 - loss: 9.2929 - accuracy: 0.0259
on_train_batch_begin: 1615862116.534760s

11 step training time: 0.310930s

on_train_batch_end: 1615862116.850600s

12288/50000 [======>.......................] - ETA: 1:07 - loss: 9.1652 - accuracy: 0.0299
on_train_batch_begin: 1615862116.850900s

12 step training time: 0.316141s

on_train_batch_end: 1615862117.163654s

13312/50000 [======>.......................] - ETA: 1:01 - loss: 9.0716 - accuracy: 0.0335
on_train_batch_begin: 1615862117.163965s

13 step training time: 0.313065s

on_train_batch_end: 1615862117.481920s

14336/50000 [=======>......................] - ETA: 56s - loss: 8.9888 - accuracy: 0.0376 
on_train_batch_begin: 1615862117.482226s

14 step training time: 0.318260s

on_train_batch_end: 1615862117.793938s

15360/50000 [========>.....................] - ETA: 51s - loss: 8.8972 - accuracy: 0.0409
on_train_batch_begin: 1615862117.794237s

15 step training time: 0.312011s

on_train_batch_end: 1615862118.109936s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.8178 - accuracy: 0.0438
on_train_batch_begin: 1615862118.110240s

16 step training time: 0.316004s

on_train_batch_end: 1615862118.421989s

17408/50000 [=========>....................] - ETA: 44s - loss: 8.7552 - accuracy: 0.0464
on_train_batch_begin: 1615862118.422306s

17 step training time: 0.312066s

on_train_batch_end: 1615862118.740010s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.6979 - accuracy: 0.0499
on_train_batch_begin: 1615862118.740319s

18 step training time: 0.318013s

on_train_batch_end: 1615862119.053386s

19456/50000 [==========>...................] - ETA: 38s - loss: 8.6380 - accuracy: 0.0516
on_train_batch_begin: 1615862119.053666s

19 step training time: 0.313347s

on_train_batch_end: 1615862119.369127s

20480/50000 [===========>..................] - ETA: 35s - loss: 8.5838 - accuracy: 0.0534
on_train_batch_begin: 1615862119.369408s

20 step training time: 0.315742s

on_train_batch_end: 1615862119.680685s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.5360 - accuracy: 0.0550
on_train_batch_begin: 1615862119.680982s

21 step training time: 0.311574s

on_train_batch_end: 1615862119.999136s

22528/50000 [============>.................] - ETA: 30s - loss: 8.4872 - accuracy: 0.0564
on_train_batch_begin: 1615862119.999434s

22 step training time: 0.318452s

on_train_batch_end: 1615862120.311535s

23552/50000 [=============>................] - ETA: 28s - loss: 8.4478 - accuracy: 0.0574
on_train_batch_begin: 1615862120.311852s

23 step training time: 0.312417s

on_train_batch_end: 1615862120.630633s

24576/50000 [=============>................] - ETA: 26s - loss: 8.4066 - accuracy: 0.0585
on_train_batch_begin: 1615862120.631009s

24 step training time: 0.319157s

on_train_batch_end: 1615862120.952732s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.3742 - accuracy: 0.0599
on_train_batch_begin: 1615862120.953107s

25 step training time: 0.322098s

on_train_batch_end: 1615862121.267575s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.3458 - accuracy: 0.0608
on_train_batch_begin: 1615862121.267950s

26 step training time: 0.314843s

on_train_batch_end: 1615862121.586719s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.3128 - accuracy: 0.0614
on_train_batch_begin: 1615862121.587094s

27 step training time: 0.319144s

on_train_batch_end: 1615862121.907786s

28672/50000 [================>.............] - ETA: 20s - loss: 8.2850 - accuracy: 0.0619
on_train_batch_begin: 1615862121.908159s

28 step training time: 0.321065s

on_train_batch_end: 1615862122.223155s

29696/50000 [================>.............] - ETA: 18s - loss: 8.2521 - accuracy: 0.0624
on_train_batch_begin: 1615862122.223522s

29 step training time: 0.315363s

on_train_batch_end: 1615862122.543540s

30720/50000 [=================>............] - ETA: 17s - loss: 8.2316 - accuracy: 0.0627
on_train_batch_begin: 1615862122.543940s

30 step training time: 0.320417s

on_train_batch_end: 1615862122.864120s

31744/50000 [==================>...........] - ETA: 16s - loss: 8.2094 - accuracy: 0.0631
on_train_batch_begin: 1615862122.864500s

31 step training time: 0.320560s

on_train_batch_end: 1615862123.179480s

32768/50000 [==================>...........] - ETA: 14s - loss: 8.1935 - accuracy: 0.0632
on_train_batch_begin: 1615862123.179868s

32 step training time: 0.315368s

on_train_batch_end: 1615862123.497223s

33792/50000 [===================>..........] - ETA: 13s - loss: 8.1719 - accuracy: 0.0639
on_train_batch_begin: 1615862123.497583s

33 step training time: 0.317715s

on_train_batch_end: 1615862123.819928s

34816/50000 [===================>..........] - ETA: 12s - loss: 8.1485 - accuracy: 0.0645
on_train_batch_begin: 1615862123.820290s

34 step training time: 0.322707s

on_train_batch_end: 1615862124.140441s

35840/50000 [====================>.........] - ETA: 11s - loss: 8.1296 - accuracy: 0.0654
on_train_batch_begin: 1615862124.140810s

35 step training time: 0.320520s

on_train_batch_end: 1615862124.455438s

36864/50000 [=====================>........] - ETA: 10s - loss: 8.1134 - accuracy: 0.0657
on_train_batch_begin: 1615862124.455828s

36 step training time: 0.315018s

on_train_batch_end: 1615862124.774861s

37888/50000 [=====================>........] - ETA: 9s - loss: 8.0951 - accuracy: 0.0667 
on_train_batch_begin: 1615862124.775233s

37 step training time: 0.319404s

on_train_batch_end: 1615862125.097249s

38912/50000 [======================>.......] - ETA: 8s - loss: 8.0757 - accuracy: 0.0675
on_train_batch_begin: 1615862125.097620s

38 step training time: 0.322387s

on_train_batch_end: 1615862125.421882s

39936/50000 [======================>.......] - ETA: 7s - loss: 8.0583 - accuracy: 0.0679
on_train_batch_begin: 1615862125.422245s

39 step training time: 0.324625s

on_train_batch_end: 1615862125.745995s

40960/50000 [=======================>......] - ETA: 6s - loss: 8.0403 - accuracy: 0.0683
on_train_batch_begin: 1615862125.746361s

40 step training time: 0.324116s

on_train_batch_end: 1615862126.063222s

41984/50000 [========================>.....] - ETA: 5s - loss: 8.0240 - accuracy: 0.0687
on_train_batch_begin: 1615862126.063613s

41 step training time: 0.317252s

on_train_batch_end: 1615862126.381706s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.0107 - accuracy: 0.0691
on_train_batch_begin: 1615862126.382091s

42 step training time: 0.318478s

on_train_batch_end: 1615862126.704493s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.9961 - accuracy: 0.0699
on_train_batch_begin: 1615862126.704856s

43 step training time: 0.322766s

on_train_batch_end: 1615862127.027888s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.9803 - accuracy: 0.0705
on_train_batch_begin: 1615862127.028259s

44 step training time: 0.323402s

on_train_batch_end: 1615862127.349120s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.9647 - accuracy: 0.0710
on_train_batch_begin: 1615862127.349466s

45 step training time: 0.321208s

on_train_batch_end: 1615862127.666651s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.9500 - accuracy: 0.0713
on_train_batch_begin: 1615862127.667018s

46 step training time: 0.317551s

on_train_batch_end: 1615862127.975183s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.9362 - accuracy: 0.0714
on_train_batch_begin: 1615862127.975538s

47 step training time: 0.308520s

on_train_batch_end: 1615862128.303536s

49152/50000 [============================>.] - ETA: 0s - loss: 7.9242 - accuracy: 0.0715
on_train_batch_begin: 1615862128.303930s

48 step training time: 0.328392s

on_train_batch_end: 1615862133.927310s

on_test_batch_begin: 1615862134.120505s

49 step training time: 5.816575s

on_epoch_end: 1615862138.858200s

Validation time: 4.737677s

Real time: 1615862138.858200s

Epoch time: 44.03244972229004s

50000/50000 [==============================] - 44s 881us/sample - loss: 7.9158 - accuracy: 0.0714 - val_loss: 7627.2737 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615862138.858440s

Real time: 1615862138.8584464
Epoch 2/5

on_train_batch_begin: 1615862138.862054s

on_train_batch_end: 1615862139.183494s

 1024/50000 [..............................] - ETA: 15s - loss: 7.3308 - accuracy: 0.0780
on_train_batch_begin: 1615862139.183911s

1 step training time: 0.321857s

on_train_batch_end: 1615862139.504013s

 2048/50000 [>.............................] - ETA: 15s - loss: 7.2951 - accuracy: 0.0785
on_train_batch_begin: 1615862139.504390s

2 step training time: 0.320479s

on_train_batch_end: 1615862139.826408s

 3072/50000 [>.............................] - ETA: 14s - loss: 7.3197 - accuracy: 0.0779
on_train_batch_begin: 1615862139.826769s

3 step training time: 0.322379s

on_train_batch_end: 1615862140.150250s

 4096/50000 [=>............................] - ETA: 14s - loss: 7.3133 - accuracy: 0.0779
on_train_batch_begin: 1615862140.150615s

4 step training time: 0.323846s

on_train_batch_end: 1615862140.475221s

 5120/50000 [==>...........................] - ETA: 14s - loss: 7.3145 - accuracy: 0.0776
on_train_batch_begin: 1615862140.475605s

5 step training time: 0.324990s

on_train_batch_end: 1615862140.800243s

 6144/50000 [==>...........................] - ETA: 13s - loss: 7.3088 - accuracy: 0.0780
on_train_batch_begin: 1615862140.800606s

6 step training time: 0.325001s

on_train_batch_end: 1615862141.125205s

 7168/50000 [===>..........................] - ETA: 13s - loss: 7.3110 - accuracy: 0.0769
on_train_batch_begin: 1615862141.125569s

7 step training time: 0.324964s

on_train_batch_end: 1615862141.450640s

 8192/50000 [===>..........................] - ETA: 13s - loss: 7.3086 - accuracy: 0.0743
on_train_batch_begin: 1615862141.450998s

8 step training time: 0.325428s

on_train_batch_end: 1615862141.775236s

 9216/50000 [====>.........................] - ETA: 12s - loss: 7.3194 - accuracy: 0.0752
on_train_batch_begin: 1615862141.775623s

9 step training time: 0.324625s

on_train_batch_end: 1615862142.099342s

10240/50000 [=====>........................] - ETA: 12s - loss: 7.3073 - accuracy: 0.0764
on_train_batch_begin: 1615862142.099725s

10 step training time: 0.324103s

on_train_batch_end: 1615862142.425166s

11264/50000 [=====>........................] - ETA: 12s - loss: 7.3059 - accuracy: 0.0769
on_train_batch_begin: 1615862142.425520s

11 step training time: 0.325794s

on_train_batch_end: 1615862142.749445s

12288/50000 [======>.......................] - ETA: 11s - loss: 7.3014 - accuracy: 0.0759
on_train_batch_begin: 1615862142.749807s

12 step training time: 0.324287s

on_train_batch_end: 1615862143.074178s

13312/50000 [======>.......................] - ETA: 11s - loss: 7.2882 - accuracy: 0.0750
on_train_batch_begin: 1615862143.074548s

13 step training time: 0.324742s

on_train_batch_end: 1615862143.396898s

14336/50000 [=======>......................] - ETA: 11s - loss: 7.2823 - accuracy: 0.0740
on_train_batch_begin: 1615862143.397236s

14 step training time: 0.322688s

on_train_batch_end: 1615862143.723365s

15360/50000 [========>.....................] - ETA: 10s - loss: 7.2830 - accuracy: 0.0721
on_train_batch_begin: 1615862143.723758s

15 step training time: 0.326522s

on_train_batch_end: 1615862144.048727s

16384/50000 [========>.....................] - ETA: 10s - loss: 7.2799 - accuracy: 0.0729
on_train_batch_begin: 1615862144.049088s

16 step training time: 0.325330s

on_train_batch_end: 1615862144.374109s

17408/50000 [=========>....................] - ETA: 10s - loss: 7.2757 - accuracy: 0.0716
on_train_batch_begin: 1615862144.374477s

17 step training time: 0.325389s

on_train_batch_end: 1615862144.698020s

18432/50000 [==========>...................] - ETA: 10s - loss: 7.2726 - accuracy: 0.0714
on_train_batch_begin: 1615862144.698388s

18 step training time: 0.323910s

on_train_batch_end: 1615862145.022702s

19456/50000 [==========>...................] - ETA: 9s - loss: 7.2740 - accuracy: 0.0698 
on_train_batch_begin: 1615862145.023084s

19 step training time: 0.324696s

on_train_batch_end: 1615862145.348113s

20480/50000 [===========>..................] - ETA: 9s - loss: 7.2713 - accuracy: 0.0706
on_train_batch_begin: 1615862145.348488s

20 step training time: 0.325405s

on_train_batch_end: 1615862145.672341s

21504/50000 [===========>..................] - ETA: 9s - loss: 7.2768 - accuracy: 0.0711
on_train_batch_begin: 1615862145.672728s

21 step training time: 0.324239s

on_train_batch_end: 1615862145.996538s

22528/50000 [============>.................] - ETA: 8s - loss: 7.2677 - accuracy: 0.0723
on_train_batch_begin: 1615862145.996921s

22 step training time: 0.324194s

on_train_batch_end: 1615862146.321965s

23552/50000 [=============>................] - ETA: 8s - loss: 7.2619 - accuracy: 0.0729
on_train_batch_begin: 1615862146.322314s

23 step training time: 0.325392s

on_train_batch_end: 1615862146.645814s

24576/50000 [=============>................] - ETA: 8s - loss: 7.2541 - accuracy: 0.0730
on_train_batch_begin: 1615862146.646178s

24 step training time: 0.323864s

on_train_batch_end: 1615862146.971846s

25600/50000 [==============>...............] - ETA: 7s - loss: 7.2455 - accuracy: 0.0735
on_train_batch_begin: 1615862146.972214s

25 step training time: 0.326036s

on_train_batch_end: 1615862147.296934s

26624/50000 [==============>...............] - ETA: 7s - loss: 7.2368 - accuracy: 0.0744
on_train_batch_begin: 1615862147.297232s

26 step training time: 0.325018s

on_train_batch_end: 1615862147.620840s

27648/50000 [===============>..............] - ETA: 7s - loss: 7.2296 - accuracy: 0.0748
on_train_batch_begin: 1615862147.621133s

27 step training time: 0.323901s

on_train_batch_end: 1615862147.945006s

28672/50000 [================>.............] - ETA: 6s - loss: 7.2282 - accuracy: 0.0749
on_train_batch_begin: 1615862147.945312s

28 step training time: 0.324179s

on_train_batch_end: 1615862148.265146s

29696/50000 [================>.............] - ETA: 6s - loss: 7.2234 - accuracy: 0.0753
on_train_batch_begin: 1615862148.265448s

29 step training time: 0.320136s

on_train_batch_end: 1615862148.573055s

30720/50000 [=================>............] - ETA: 6s - loss: 7.2171 - accuracy: 0.0751
on_train_batch_begin: 1615862148.573352s

30 step training time: 0.307904s

on_train_batch_end: 1615862148.894152s

31744/50000 [==================>...........] - ETA: 5s - loss: 7.2101 - accuracy: 0.0753
on_train_batch_begin: 1615862148.894448s

31 step training time: 0.321096s

on_train_batch_end: 1615862149.215831s

32768/50000 [==================>...........] - ETA: 5s - loss: 7.2044 - accuracy: 0.0753
on_train_batch_begin: 1615862149.216182s

32 step training time: 0.321734s

on_train_batch_end: 1615862149.539217s

33792/50000 [===================>..........] - ETA: 5s - loss: 7.1938 - accuracy: 0.0751
on_train_batch_begin: 1615862149.539610s

33 step training time: 0.323427s

on_train_batch_end: 1615862149.862815s

34816/50000 [===================>..........] - ETA: 4s - loss: 7.1846 - accuracy: 0.0746
on_train_batch_begin: 1615862149.863178s

34 step training time: 0.323568s

on_train_batch_end: 1615862150.187585s

35840/50000 [====================>.........] - ETA: 4s - loss: 7.1749 - accuracy: 0.0741
on_train_batch_begin: 1615862150.187939s

35 step training time: 0.324761s

on_train_batch_end: 1615862150.510134s

36864/50000 [=====================>........] - ETA: 4s - loss: 7.1629 - accuracy: 0.0738
on_train_batch_begin: 1615862150.510499s

36 step training time: 0.322560s

on_train_batch_end: 1615862150.835355s

37888/50000 [=====================>........] - ETA: 3s - loss: 7.1536 - accuracy: 0.0734
on_train_batch_begin: 1615862150.835753s

37 step training time: 0.325253s

on_train_batch_end: 1615862151.160233s

38912/50000 [======================>.......] - ETA: 3s - loss: 7.1437 - accuracy: 0.0729
on_train_batch_begin: 1615862151.160604s

38 step training time: 0.324851s

on_train_batch_end: 1615862151.484455s

39936/50000 [======================>.......] - ETA: 3s - loss: 7.1362 - accuracy: 0.0724
on_train_batch_begin: 1615862151.484852s

39 step training time: 0.324248s

on_train_batch_end: 1615862151.809428s

40960/50000 [=======================>......] - ETA: 2s - loss: 7.1304 - accuracy: 0.0720
on_train_batch_begin: 1615862151.809809s

40 step training time: 0.324958s

on_train_batch_end: 1615862152.134656s

41984/50000 [========================>.....] - ETA: 2s - loss: 7.1195 - accuracy: 0.0719
on_train_batch_begin: 1615862152.135025s

41 step training time: 0.325216s

on_train_batch_end: 1615862152.458996s

43008/50000 [========================>.....] - ETA: 2s - loss: 7.1124 - accuracy: 0.0714
on_train_batch_begin: 1615862152.459382s

42 step training time: 0.324357s

on_train_batch_end: 1615862152.784772s

44032/50000 [=========================>....] - ETA: 1s - loss: 7.1050 - accuracy: 0.0707
on_train_batch_begin: 1615862152.785141s

43 step training time: 0.325759s

on_train_batch_end: 1615862153.108918s

45056/50000 [==========================>...] - ETA: 1s - loss: 7.0965 - accuracy: 0.0701
on_train_batch_begin: 1615862153.109282s

44 step training time: 0.324141s

on_train_batch_end: 1615862153.433846s

46080/50000 [==========================>...] - ETA: 1s - loss: 7.0885 - accuracy: 0.0694
on_train_batch_begin: 1615862153.434219s

45 step training time: 0.324937s

on_train_batch_end: 1615862153.758862s

47104/50000 [===========================>..] - ETA: 0s - loss: 7.0791 - accuracy: 0.0687
on_train_batch_begin: 1615862153.759237s

46 step training time: 0.325017s

on_train_batch_end: 1615862154.082778s

48128/50000 [===========================>..] - ETA: 0s - loss: 7.0682 - accuracy: 0.0680
on_train_batch_begin: 1615862154.083155s

47 step training time: 0.323918s

on_train_batch_end: 1615862154.406971s

49152/50000 [============================>.] - ETA: 0s - loss: 7.0542 - accuracy: 0.0674
on_train_batch_begin: 1615862154.407341s

48 step training time: 0.324185s

on_train_batch_end: 1615862154.677810s

on_test_batch_begin: 1615862154.692006s

49 step training time: 0.284665s

on_epoch_end: 1615862155.514934s

Validation time: 0.822913s

Real time: 1615862155.514934s

Epoch time: 16.656508207321167s

50000/50000 [==============================] - 17s 333us/sample - loss: 7.0420 - accuracy: 0.0670 - val_loss: 7.6290 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615862155.515159s

Real time: 1615862155.515165
Epoch 3/5

on_train_batch_begin: 1615862155.518687s

on_train_batch_end: 1615862155.844455s

 1024/50000 [..............................] - ETA: 15s - loss: 6.3994 - accuracy: 0.0379
on_train_batch_begin: 1615862155.844837s

1 step training time: 0.326150s

on_train_batch_end: 1615862156.170904s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.3636 - accuracy: 0.0371
on_train_batch_begin: 1615862156.171284s

2 step training time: 0.326447s

on_train_batch_end: 1615862156.495613s

 3072/50000 [>.............................] - ETA: 14s - loss: 6.3522 - accuracy: 0.0374
on_train_batch_begin: 1615862156.495975s

3 step training time: 0.324692s

on_train_batch_end: 1615862156.819601s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.3068 - accuracy: 0.0376
on_train_batch_begin: 1615862156.819900s

4 step training time: 0.323924s

on_train_batch_end: 1615862157.144854s

 5120/50000 [==>...........................] - ETA: 14s - loss: 6.2712 - accuracy: 0.0390
on_train_batch_begin: 1615862157.145149s

5 step training time: 0.325249s

on_train_batch_end: 1615862157.467806s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.2456 - accuracy: 0.0397
on_train_batch_begin: 1615862157.468054s

6 step training time: 0.322905s

on_train_batch_end: 1615862157.790338s

 7168/50000 [===>..........................] - ETA: 13s - loss: 6.1969 - accuracy: 0.0404
on_train_batch_begin: 1615862157.790624s

7 step training time: 0.322570s

on_train_batch_end: 1615862158.114639s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.1511 - accuracy: 0.0422
on_train_batch_begin: 1615862158.114889s

8 step training time: 0.324265s

on_train_batch_end: 1615862158.438948s

 9216/50000 [====>.........................] - ETA: 12s - loss: 6.1208 - accuracy: 0.0440
on_train_batch_begin: 1615862158.439236s

9 step training time: 0.324347s

on_train_batch_end: 1615862158.764342s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.1053 - accuracy: 0.0453
on_train_batch_begin: 1615862158.764600s

10 step training time: 0.325364s

on_train_batch_end: 1615862159.089240s

11264/50000 [=====>........................] - ETA: 12s - loss: 6.0559 - accuracy: 0.0467
on_train_batch_begin: 1615862159.089527s

11 step training time: 0.324927s

on_train_batch_end: 1615862159.413981s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.0107 - accuracy: 0.0480
on_train_batch_begin: 1615862159.414271s

12 step training time: 0.324743s

on_train_batch_end: 1615862159.738173s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.9571 - accuracy: 0.0493
on_train_batch_begin: 1615862159.738451s

13 step training time: 0.324181s

on_train_batch_end: 1615862160.062400s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.9108 - accuracy: 0.0504
on_train_batch_begin: 1615862160.062647s

14 step training time: 0.324195s

on_train_batch_end: 1615862160.389001s

15360/50000 [========>.....................] - ETA: 10s - loss: 5.8818 - accuracy: 0.0513
on_train_batch_begin: 1615862160.389313s

15 step training time: 0.326667s

on_train_batch_end: 1615862160.714610s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.8416 - accuracy: 0.0523
on_train_batch_begin: 1615862160.714905s

16 step training time: 0.325591s

on_train_batch_end: 1615862161.038913s

17408/50000 [=========>....................] - ETA: 10s - loss: 5.7970 - accuracy: 0.0534
on_train_batch_begin: 1615862161.039211s

17 step training time: 0.324306s

on_train_batch_end: 1615862161.363935s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.7490 - accuracy: 0.0550
on_train_batch_begin: 1615862161.364223s

18 step training time: 0.325012s

on_train_batch_end: 1615862161.689557s

19456/50000 [==========>...................] - ETA: 9s - loss: 5.7116 - accuracy: 0.0561 
on_train_batch_begin: 1615862161.689831s

19 step training time: 0.325608s

on_train_batch_end: 1615862162.014122s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.6674 - accuracy: 0.0573
on_train_batch_begin: 1615862162.014417s

20 step training time: 0.324586s

on_train_batch_end: 1615862162.338964s

21504/50000 [===========>..................] - ETA: 9s - loss: 5.6330 - accuracy: 0.0582
on_train_batch_begin: 1615862162.339252s

21 step training time: 0.324836s

on_train_batch_end: 1615862162.663022s

22528/50000 [============>.................] - ETA: 8s - loss: 5.5959 - accuracy: 0.0590
on_train_batch_begin: 1615862162.663309s

22 step training time: 0.324057s

on_train_batch_end: 1615862162.990170s

23552/50000 [=============>................] - ETA: 8s - loss: 5.5525 - accuracy: 0.0600
on_train_batch_begin: 1615862162.990454s

23 step training time: 0.327145s

on_train_batch_end: 1615862163.315609s

24576/50000 [=============>................] - ETA: 8s - loss: 5.5095 - accuracy: 0.0612
on_train_batch_begin: 1615862163.315915s

24 step training time: 0.325461s

on_train_batch_end: 1615862163.641432s

25600/50000 [==============>...............] - ETA: 7s - loss: 5.4765 - accuracy: 0.0620
on_train_batch_begin: 1615862163.641723s

25 step training time: 0.325808s

on_train_batch_end: 1615862163.967683s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.4378 - accuracy: 0.0628
on_train_batch_begin: 1615862163.967992s

26 step training time: 0.326269s

on_train_batch_end: 1615862164.297696s

27648/50000 [===============>..............] - ETA: 7s - loss: 5.3968 - accuracy: 0.0636
on_train_batch_begin: 1615862164.297972s

27 step training time: 0.329981s

on_train_batch_end: 1615862164.627146s

28672/50000 [================>.............] - ETA: 6s - loss: 5.3602 - accuracy: 0.0643
on_train_batch_begin: 1615862164.627436s

28 step training time: 0.329463s

on_train_batch_end: 1615862164.952708s

29696/50000 [================>.............] - ETA: 6s - loss: 5.3219 - accuracy: 0.0651
on_train_batch_begin: 1615862164.952995s

29 step training time: 0.325559s

on_train_batch_end: 1615862165.278120s

30720/50000 [=================>............] - ETA: 6s - loss: 5.2895 - accuracy: 0.0659
on_train_batch_begin: 1615862165.278406s

30 step training time: 0.325411s

on_train_batch_end: 1615862165.598457s

31744/50000 [==================>...........] - ETA: 5s - loss: 5.2541 - accuracy: 0.0665
on_train_batch_begin: 1615862165.598757s

31 step training time: 0.320351s

on_train_batch_end: 1615862165.930954s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.2208 - accuracy: 0.0672
on_train_batch_begin: 1615862165.931641s

32 step training time: 0.332885s

on_train_batch_end: 1615862166.258679s

33792/50000 [===================>..........] - ETA: 5s - loss: 5.1841 - accuracy: 0.0679
on_train_batch_begin: 1615862166.259022s

33 step training time: 0.327381s

on_train_batch_end: 1615862166.583597s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.1513 - accuracy: 0.0684
on_train_batch_begin: 1615862166.583899s

34 step training time: 0.324877s

on_train_batch_end: 1615862166.909806s

35840/50000 [====================>.........] - ETA: 4s - loss: 5.1202 - accuracy: 0.0690
on_train_batch_begin: 1615862166.910093s

35 step training time: 0.326194s

on_train_batch_end: 1615862167.223770s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.0874 - accuracy: 0.0697
on_train_batch_begin: 1615862167.224060s

36 step training time: 0.313967s

on_train_batch_end: 1615862167.555327s

37888/50000 [=====================>........] - ETA: 3s - loss: 5.0560 - accuracy: 0.0702
on_train_batch_begin: 1615862167.555628s

37 step training time: 0.331568s

on_train_batch_end: 1615862167.882023s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.0216 - accuracy: 0.0709
on_train_batch_begin: 1615862167.882307s

38 step training time: 0.326680s

on_train_batch_end: 1615862168.207263s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.9959 - accuracy: 0.0714
on_train_batch_begin: 1615862168.207572s

39 step training time: 0.325265s

on_train_batch_end: 1615862168.534760s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.9636 - accuracy: 0.0719
on_train_batch_begin: 1615862168.535041s

40 step training time: 0.327469s

on_train_batch_end: 1615862168.860040s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.9305 - accuracy: 0.0725
on_train_batch_begin: 1615862168.860336s

41 step training time: 0.325295s

on_train_batch_end: 1615862169.185706s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.9003 - accuracy: 0.0731
on_train_batch_begin: 1615862169.186000s

42 step training time: 0.325664s

on_train_batch_end: 1615862169.510480s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.8736 - accuracy: 0.0737
on_train_batch_begin: 1615862169.510763s

43 step training time: 0.324763s

on_train_batch_end: 1615862169.839282s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.8422 - accuracy: 0.0742
on_train_batch_begin: 1615862169.839568s

44 step training time: 0.328805s

on_train_batch_end: 1615862170.166525s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.8045 - accuracy: 0.0748
on_train_batch_begin: 1615862170.166790s

45 step training time: 0.327221s

on_train_batch_end: 1615862170.496427s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.7698 - accuracy: 0.0754
on_train_batch_begin: 1615862170.496739s

46 step training time: 0.329949s

on_train_batch_end: 1615862170.822925s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.7358 - accuracy: 0.0759
on_train_batch_begin: 1615862170.823210s

47 step training time: 0.326472s

on_train_batch_end: 1615862171.149477s

49152/50000 [============================>.] - ETA: 0s - loss: 4.7047 - accuracy: 0.0764
on_train_batch_begin: 1615862171.149777s

48 step training time: 0.326567s

on_train_batch_end: 1615862171.420865s

on_test_batch_begin: 1615862171.435384s

49 step training time: 0.285607s

on_epoch_end: 1615862172.229855s

Validation time: 0.794459s

Real time: 1615862172.229855s

Epoch time: 16.714707136154175s

50000/50000 [==============================] - 17s 334us/sample - loss: 4.6753 - accuracy: 0.0767 - val_loss: 7.6229 - val_accuracy: 0.0999

on_epoch_begin: 1615862172.230040s

Real time: 1615862172.2300458
Epoch 4/5

on_train_batch_begin: 1615862172.233271s

on_train_batch_end: 1615862172.557396s

 1024/50000 [..............................] - ETA: 15s - loss: 3.1150 - accuracy: 0.0989
on_train_batch_begin: 1615862172.557706s

1 step training time: 0.324435s

on_train_batch_end: 1615862172.888468s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.0592 - accuracy: 0.0992
on_train_batch_begin: 1615862172.888766s

2 step training time: 0.331060s

on_train_batch_end: 1615862173.219336s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.9984 - accuracy: 0.0998
on_train_batch_begin: 1615862173.219644s

3 step training time: 0.330878s

on_train_batch_end: 1615862173.547573s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.9436 - accuracy: 0.0995
on_train_batch_begin: 1615862173.547872s

4 step training time: 0.328228s

on_train_batch_end: 1615862173.871407s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.9655 - accuracy: 0.0997
on_train_batch_begin: 1615862173.871680s

5 step training time: 0.323808s

on_train_batch_end: 1615862174.198193s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.9486 - accuracy: 0.0996
on_train_batch_begin: 1615862174.198459s

6 step training time: 0.326778s

on_train_batch_end: 1615862174.526128s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.9121 - accuracy: 0.0995
on_train_batch_begin: 1615862174.526427s

7 step training time: 0.327968s

on_train_batch_end: 1615862174.851959s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.8783 - accuracy: 0.0996
on_train_batch_begin: 1615862174.852250s

8 step training time: 0.325823s

on_train_batch_end: 1615862175.178531s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.8335 - accuracy: 0.0997
on_train_batch_begin: 1615862175.178823s

9 step training time: 0.326573s

on_train_batch_end: 1615862175.507380s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.8097 - accuracy: 0.0998
on_train_batch_begin: 1615862175.507712s

10 step training time: 0.328889s

on_train_batch_end: 1615862175.838006s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.7887 - accuracy: 0.0998
on_train_batch_begin: 1615862175.838259s

11 step training time: 0.330548s

on_train_batch_end: 1615862176.166934s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.7718 - accuracy: 0.0998
on_train_batch_begin: 1615862176.167233s

12 step training time: 0.328974s

on_train_batch_end: 1615862176.493841s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.7619 - accuracy: 0.0998
on_train_batch_begin: 1615862176.494135s

13 step training time: 0.326902s

on_train_batch_end: 1615862176.820778s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.7519 - accuracy: 0.0998
on_train_batch_begin: 1615862176.821060s

14 step training time: 0.326925s

on_train_batch_end: 1615862177.147446s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.7323 - accuracy: 0.0998
on_train_batch_begin: 1615862177.147760s

15 step training time: 0.326699s

on_train_batch_end: 1615862177.476189s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.7124 - accuracy: 0.0999
on_train_batch_begin: 1615862177.476503s

16 step training time: 0.328743s

on_train_batch_end: 1615862177.805110s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.7051 - accuracy: 0.1000
on_train_batch_begin: 1615862177.805404s

17 step training time: 0.328901s

on_train_batch_end: 1615862178.133950s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.6893 - accuracy: 0.1001
on_train_batch_begin: 1615862178.134230s

18 step training time: 0.328825s

on_train_batch_end: 1615862178.463565s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.6811 - accuracy: 0.1001 
on_train_batch_begin: 1615862178.463851s

19 step training time: 0.329621s

on_train_batch_end: 1615862178.791917s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.6892 - accuracy: 0.1001
on_train_batch_begin: 1615862178.792201s

20 step training time: 0.328350s

on_train_batch_end: 1615862179.119668s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.6941 - accuracy: 0.1000
on_train_batch_begin: 1615862179.119954s

21 step training time: 0.327753s

on_train_batch_end: 1615862179.446349s

22528/50000 [============>.................] - ETA: 8s - loss: 2.6951 - accuracy: 0.1000
on_train_batch_begin: 1615862179.446682s

22 step training time: 0.326729s

on_train_batch_end: 1615862179.776034s

23552/50000 [=============>................] - ETA: 8s - loss: 2.7098 - accuracy: 0.0999
on_train_batch_begin: 1615862179.776325s

23 step training time: 0.329642s

on_train_batch_end: 1615862180.107526s

24576/50000 [=============>................] - ETA: 8s - loss: 2.7120 - accuracy: 0.0999
on_train_batch_begin: 1615862180.107824s

24 step training time: 0.331499s

on_train_batch_end: 1615862180.437898s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.7087 - accuracy: 0.0999
on_train_batch_begin: 1615862180.438159s

25 step training time: 0.330335s

on_train_batch_end: 1615862180.764852s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.7055 - accuracy: 0.0999
on_train_batch_begin: 1615862180.765141s

26 step training time: 0.326982s

on_train_batch_end: 1615862181.092233s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.7049 - accuracy: 0.1000
on_train_batch_begin: 1615862181.092521s

27 step training time: 0.327380s

on_train_batch_end: 1615862181.422590s

28672/50000 [================>.............] - ETA: 6s - loss: 2.6991 - accuracy: 0.0999
on_train_batch_begin: 1615862181.422885s

28 step training time: 0.330365s

on_train_batch_end: 1615862181.754841s

29696/50000 [================>.............] - ETA: 6s - loss: 2.6986 - accuracy: 0.0999
on_train_batch_begin: 1615862181.755126s

29 step training time: 0.332241s

on_train_batch_end: 1615862182.084908s

30720/50000 [=================>............] - ETA: 6s - loss: 2.6888 - accuracy: 0.0999
on_train_batch_begin: 1615862182.085212s

30 step training time: 0.330086s

on_train_batch_end: 1615862182.411927s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.6829 - accuracy: 0.0999
on_train_batch_begin: 1615862182.412215s

31 step training time: 0.327003s

on_train_batch_end: 1615862182.741305s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.6746 - accuracy: 0.1000
on_train_batch_begin: 1615862182.741593s

32 step training time: 0.329378s

on_train_batch_end: 1615862183.075491s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.6620 - accuracy: 0.1000
on_train_batch_begin: 1615862183.075813s

33 step training time: 0.334220s

on_train_batch_end: 1615862183.404953s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.6504 - accuracy: 0.1000
on_train_batch_begin: 1615862183.405235s

34 step training time: 0.329422s

on_train_batch_end: 1615862183.733578s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.6399 - accuracy: 0.1000
on_train_batch_begin: 1615862183.733864s

35 step training time: 0.328629s

on_train_batch_end: 1615862184.067684s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.6302 - accuracy: 0.1000
on_train_batch_begin: 1615862184.067973s

36 step training time: 0.334109s

on_train_batch_end: 1615862184.398933s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.6247 - accuracy: 0.1000
on_train_batch_begin: 1615862184.399223s

37 step training time: 0.331250s

on_train_batch_end: 1615862184.728970s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.6223 - accuracy: 0.1000
on_train_batch_begin: 1615862184.729257s

38 step training time: 0.330034s

on_train_batch_end: 1615862185.059210s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.6182 - accuracy: 0.1000
on_train_batch_begin: 1615862185.059504s

39 step training time: 0.330246s

on_train_batch_end: 1615862185.393285s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.6196 - accuracy: 0.1000
on_train_batch_begin: 1615862185.393579s

40 step training time: 0.334076s

on_train_batch_end: 1615862185.712998s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.6133 - accuracy: 0.1000
on_train_batch_begin: 1615862185.713284s

41 step training time: 0.319705s

on_train_batch_end: 1615862186.047206s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.6115 - accuracy: 0.1000
on_train_batch_begin: 1615862186.047507s

42 step training time: 0.334223s

on_train_batch_end: 1615862186.378498s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.6059 - accuracy: 0.1000
on_train_batch_begin: 1615862186.378787s

43 step training time: 0.331280s

on_train_batch_end: 1615862186.711099s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.6054 - accuracy: 0.1000
on_train_batch_begin: 1615862186.711391s

44 step training time: 0.332604s

on_train_batch_end: 1615862187.041964s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.6026 - accuracy: 0.1000
on_train_batch_begin: 1615862187.042264s

45 step training time: 0.330873s

on_train_batch_end: 1615862187.371073s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.5973 - accuracy: 0.1000
on_train_batch_begin: 1615862187.371371s

46 step training time: 0.329107s

on_train_batch_end: 1615862187.700205s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.5935 - accuracy: 0.1000
on_train_batch_begin: 1615862187.700493s

47 step training time: 0.329122s

on_train_batch_end: 1615862188.032697s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5931 - accuracy: 0.1000
on_train_batch_begin: 1615862188.032991s

48 step training time: 0.332498s

on_train_batch_end: 1615862188.321722s

on_test_batch_begin: 1615862188.337062s

49 step training time: 0.304071s

on_epoch_end: 1615862189.136470s

Validation time: 0.799393s

Real time: 1615862189.136470s

Epoch time: 16.90644073486328s

50000/50000 [==============================] - 17s 338us/sample - loss: 2.5957 - accuracy: 0.1000 - val_loss: 7.2036 - val_accuracy: 0.0999

on_epoch_begin: 1615862189.136654s

Real time: 1615862189.136659
Epoch 5/5

on_train_batch_begin: 1615862189.139976s

on_train_batch_end: 1615862189.469694s

 1024/50000 [..............................] - ETA: 15s - loss: 2.3692 - accuracy: 0.1005
on_train_batch_begin: 1615862189.469986s

1 step training time: 0.330010s

on_train_batch_end: 1615862189.803117s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.4941 - accuracy: 0.1003
on_train_batch_begin: 1615862189.803497s

2 step training time: 0.333511s

on_train_batch_end: 1615862190.137505s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.4888 - accuracy: 0.1001
on_train_batch_begin: 1615862190.137867s

3 step training time: 0.334370s

on_train_batch_end: 1615862190.470009s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.5286 - accuracy: 0.0998
on_train_batch_begin: 1615862190.470305s

4 step training time: 0.332438s

on_train_batch_end: 1615862190.800442s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.5128 - accuracy: 0.0998
on_train_batch_begin: 1615862190.800729s

5 step training time: 0.330424s

on_train_batch_end: 1615862191.127280s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.4995 - accuracy: 0.0997
on_train_batch_begin: 1615862191.127592s

6 step training time: 0.326863s

on_train_batch_end: 1615862191.461868s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.5116 - accuracy: 0.0997
on_train_batch_begin: 1615862191.462160s

7 step training time: 0.334568s

on_train_batch_end: 1615862191.792177s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.4836 - accuracy: 0.0998
on_train_batch_begin: 1615862191.792470s

8 step training time: 0.330310s

on_train_batch_end: 1615862192.119225s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.4666 - accuracy: 0.0998
on_train_batch_begin: 1615862192.119529s

9 step training time: 0.327060s

on_train_batch_end: 1615862192.447940s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.4661 - accuracy: 0.0999
on_train_batch_begin: 1615862192.448244s

10 step training time: 0.328714s

on_train_batch_end: 1615862192.779026s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.4531 - accuracy: 0.0999
on_train_batch_begin: 1615862192.779328s

11 step training time: 0.331084s

on_train_batch_end: 1615862193.109053s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.4336 - accuracy: 0.1000
on_train_batch_begin: 1615862193.109340s

12 step training time: 0.330012s

on_train_batch_end: 1615862193.437042s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.4198 - accuracy: 0.1001
on_train_batch_begin: 1615862193.437338s

13 step training time: 0.327997s

on_train_batch_end: 1615862193.764446s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.4216 - accuracy: 0.1000
on_train_batch_begin: 1615862193.764735s

14 step training time: 0.327397s

on_train_batch_end: 1615862194.092933s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.4029 - accuracy: 0.1001
on_train_batch_begin: 1615862194.093229s

15 step training time: 0.328494s

on_train_batch_end: 1615862194.423620s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.4004 - accuracy: 0.1000
on_train_batch_begin: 1615862194.423914s

16 step training time: 0.330685s

on_train_batch_end: 1615862194.750781s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.3856 - accuracy: 0.1000
on_train_batch_begin: 1615862194.751072s

17 step training time: 0.327157s

on_train_batch_end: 1615862195.077902s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.3725 - accuracy: 0.1001
on_train_batch_begin: 1615862195.078191s

18 step training time: 0.327119s

on_train_batch_end: 1615862195.404721s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.3587 - accuracy: 0.1001 
on_train_batch_begin: 1615862195.405006s

19 step training time: 0.326816s

on_train_batch_end: 1615862195.730264s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.3487 - accuracy: 0.1000
on_train_batch_begin: 1615862195.730555s

20 step training time: 0.325549s

on_train_batch_end: 1615862196.057204s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.3480 - accuracy: 0.1001
on_train_batch_begin: 1615862196.057500s

21 step training time: 0.326945s

on_train_batch_end: 1615862196.386214s

22528/50000 [============>.................] - ETA: 8s - loss: 2.3312 - accuracy: 0.1001
on_train_batch_begin: 1615862196.386536s

22 step training time: 0.329036s

on_train_batch_end: 1615862196.716797s

23552/50000 [=============>................] - ETA: 8s - loss: 2.3236 - accuracy: 0.1001
on_train_batch_begin: 1615862196.717092s

23 step training time: 0.330556s

on_train_batch_end: 1615862197.044170s

24576/50000 [=============>................] - ETA: 8s - loss: 2.3022 - accuracy: 0.1001
on_train_batch_begin: 1615862197.044447s

24 step training time: 0.327355s

on_train_batch_end: 1615862197.369111s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.2921 - accuracy: 0.1001
on_train_batch_begin: 1615862197.369402s

25 step training time: 0.324955s

on_train_batch_end: 1615862197.694588s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.2824 - accuracy: 0.1001
on_train_batch_begin: 1615862197.694838s

26 step training time: 0.325436s

on_train_batch_end: 1615862198.020737s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.2746 - accuracy: 0.1001
on_train_batch_begin: 1615862198.021034s

27 step training time: 0.326195s

on_train_batch_end: 1615862198.345925s

28672/50000 [================>.............] - ETA: 6s - loss: 2.2598 - accuracy: 0.1001
on_train_batch_begin: 1615862198.346215s

28 step training time: 0.325181s

on_train_batch_end: 1615862198.671121s

29696/50000 [================>.............] - ETA: 6s - loss: 2.2524 - accuracy: 0.1001
on_train_batch_begin: 1615862198.671409s

29 step training time: 0.325194s

on_train_batch_end: 1615862198.998034s

30720/50000 [=================>............] - ETA: 6s - loss: 2.2416 - accuracy: 0.1001
on_train_batch_begin: 1615862198.998325s

30 step training time: 0.326916s

on_train_batch_end: 1615862199.323716s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.2267 - accuracy: 0.1001
on_train_batch_begin: 1615862199.324008s

31 step training time: 0.325683s

on_train_batch_end: 1615862199.648256s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.2154 - accuracy: 0.1001
on_train_batch_begin: 1615862199.648546s

32 step training time: 0.324538s

on_train_batch_end: 1615862199.972994s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.2024 - accuracy: 0.1001
on_train_batch_begin: 1615862199.973289s

33 step training time: 0.324743s

on_train_batch_end: 1615862200.300089s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.1902 - accuracy: 0.1001
on_train_batch_begin: 1615862200.300377s

34 step training time: 0.327088s

on_train_batch_end: 1615862200.629323s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.1840 - accuracy: 0.1001
on_train_batch_begin: 1615862200.629616s

35 step training time: 0.329239s

on_train_batch_end: 1615862200.955511s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.1789 - accuracy: 0.1001
on_train_batch_begin: 1615862200.955807s

36 step training time: 0.326191s

on_train_batch_end: 1615862201.281438s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.1704 - accuracy: 0.1001
on_train_batch_begin: 1615862201.281732s

37 step training time: 0.325925s

on_train_batch_end: 1615862201.606745s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.1641 - accuracy: 0.1002
on_train_batch_begin: 1615862201.607033s

38 step training time: 0.325301s

on_train_batch_end: 1615862201.932209s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.1580 - accuracy: 0.1002
on_train_batch_begin: 1615862201.932501s

39 step training time: 0.325468s

on_train_batch_end: 1615862202.256780s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.1520 - accuracy: 0.1001
on_train_batch_begin: 1615862202.257072s

40 step training time: 0.324571s

on_train_batch_end: 1615862202.581417s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.1461 - accuracy: 0.1001
on_train_batch_begin: 1615862202.581705s

41 step training time: 0.324633s

on_train_batch_end: 1615862202.906399s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.1409 - accuracy: 0.1002
on_train_batch_begin: 1615862202.906711s

42 step training time: 0.325006s

on_train_batch_end: 1615862203.229558s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.1368 - accuracy: 0.1002
on_train_batch_begin: 1615862203.229853s

43 step training time: 0.323141s

on_train_batch_end: 1615862203.555246s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.1264 - accuracy: 0.1002
on_train_batch_begin: 1615862203.555534s

44 step training time: 0.325681s

on_train_batch_end: 1615862203.880435s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.1210 - accuracy: 0.1002
on_train_batch_begin: 1615862203.880727s

45 step training time: 0.325194s

on_train_batch_end: 1615862204.206052s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.1142 - accuracy: 0.1002
on_train_batch_begin: 1615862204.206341s

46 step training time: 0.325613s

on_train_batch_end: 1615862204.527412s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.1083 - accuracy: 0.1002
on_train_batch_begin: 1615862204.527735s

47 step training time: 0.321394s

on_train_batch_end: 1615862204.849681s

49152/50000 [============================>.] - ETA: 0s - loss: 2.1021 - accuracy: 0.1001
on_train_batch_begin: 1615862204.849951s

48 step training time: 0.322217s

on_train_batch_end: 1615862205.120509s

on_test_batch_begin: 1615862205.137190s

49 step training time: 0.287238s

on_epoch_end: 1615862205.932283s

Validation time: 0.795082s

Real time: 1615862205.932283s

Epoch time: 16.795640230178833s

50000/50000 [==============================] - 17s 336us/sample - loss: 2.0962 - accuracy: 0.1002 - val_loss: 6.8576 - val_accuracy: 0.1000
Tempo do fit: 114.55592918395996