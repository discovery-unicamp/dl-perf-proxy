wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:55
   172032/170498071 [..............................] - ETA: 1:12
   663552/170498071 [..............................] - ETA: 31s 
  2203648/170498071 [..............................] - ETA: 13s
  5185536/170498071 [..............................] - ETA: 7s 
  8216576/170498071 [>.............................] - ETA: 5s
 11173888/170498071 [>.............................] - ETA: 4s
 14131200/170498071 [=>............................] - ETA: 4s
 17096704/170498071 [==>...........................] - ETA: 3s
 20062208/170498071 [==>...........................] - ETA: 3s
 23044096/170498071 [===>..........................] - ETA: 3s
 25698304/170498071 [===>..........................] - ETA: 3s
 28876800/170498071 [====>.........................] - ETA: 3s
 31891456/170498071 [====>.........................] - ETA: 2s
 34873344/170498071 [=====>........................] - ETA: 2s
 37838848/170498071 [=====>........................] - ETA: 2s
 41033728/170498071 [======>.......................] - ETA: 2s
 44277760/170498071 [======>.......................] - ETA: 2s
 47521792/170498071 [=======>......................] - ETA: 2s
 50733056/170498071 [=======>......................] - ETA: 2s
 53985280/170498071 [========>.....................] - ETA: 2s
 57188352/170498071 [=========>....................] - ETA: 2s
 60448768/170498071 [=========>....................] - ETA: 2s
 63709184/170498071 [==========>...................] - ETA: 1s
 66953216/170498071 [==========>...................] - ETA: 1s
 70164480/170498071 [===========>..................] - ETA: 1s
 73392128/170498071 [===========>..................] - ETA: 1s
 76701696/170498071 [============>.................] - ETA: 1s
 79896576/170498071 [=============>................] - ETA: 1s
 83156992/170498071 [=============>................] - ETA: 1s
 86401024/170498071 [==============>...............] - ETA: 1s
 89694208/170498071 [==============>...............] - ETA: 1s
 92987392/170498071 [===============>..............] - ETA: 1s
 96239616/170498071 [===============>..............] - ETA: 1s
 99491840/170498071 [================>.............] - ETA: 1s
102735872/170498071 [=================>............] - ETA: 1s
105947136/170498071 [=================>............] - ETA: 1s
109240320/170498071 [==================>...........] - ETA: 1s
112500736/170498071 [==================>...........] - ETA: 0s
115744768/170498071 [===================>..........] - ETA: 0s
119021568/170498071 [===================>..........] - ETA: 0s
122273792/170498071 [====================>.........] - ETA: 0s
125509632/170498071 [=====================>........] - ETA: 0s
128786432/170498071 [=====================>........] - ETA: 0s
132096000/170498071 [======================>.......] - ETA: 0s
135397376/170498071 [======================>.......] - ETA: 0s
138625024/170498071 [=======================>......] - ETA: 0s
141877248/170498071 [=======================>......] - ETA: 0s
145039360/170498071 [========================>.....] - ETA: 0s
148250624/170498071 [=========================>....] - ETA: 0s
151511040/170498071 [=========================>....] - ETA: 0s
154804224/170498071 [==========================>...] - ETA: 0s
157999104/170498071 [==========================>...] - ETA: 0s
161259520/170498071 [===========================>..] - ETA: 0s
164585472/170498071 [===========================>..] - ETA: 0s
167878656/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 2s
 5849088/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
18014208/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 1s
23568384/94765736 [======>.......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 1s
37117952/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 0s
49455104/94765736 [==============>...............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
65945600/94765736 [===================>..........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
74743808/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
82157568/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
93888512/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.79878830909729
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598475018.366342s

Real time: 1598475018.3663623
Epoch 1/5

on_train_batch_begin: 1598475019.114675s

on_train_batch_end: 1598475036.252404s

 1024/50000 [..............................] - ETA: 14:15 - loss: 17.9517 - accuracy: 3.0327e-04
on_train_batch_begin: 1598475036.253044s

1 step training time: 17.138369s

on_train_batch_end: 1598475036.588729s

 2048/50000 [>.............................] - ETA: 7:06 - loss: 15.4410 - accuracy: 2.4986e-04 
on_train_batch_begin: 1598475036.589050s

2 step training time: 0.336006s

on_train_batch_end: 1598475036.921163s

 3072/50000 [>.............................] - ETA: 4:43 - loss: 13.2914 - accuracy: 3.8656e-04
on_train_batch_begin: 1598475036.921495s

3 step training time: 0.332445s

on_train_batch_end: 1598475037.256621s

 4096/50000 [=>............................] - ETA: 3:31 - loss: 12.0598 - accuracy: 8.6832e-04
on_train_batch_begin: 1598475037.256931s

4 step training time: 0.335436s

on_train_batch_end: 1598475037.594253s

 5120/50000 [==>...........................] - ETA: 2:48 - loss: 11.3039 - accuracy: 0.0026    
on_train_batch_begin: 1598475037.594562s

5 step training time: 0.337631s

on_train_batch_end: 1598475037.929413s

 6144/50000 [==>...........................] - ETA: 2:19 - loss: 10.7912 - accuracy: 0.0035
on_train_batch_begin: 1598475037.929750s

6 step training time: 0.335188s

on_train_batch_end: 1598475038.266678s

 7168/50000 [===>..........................] - ETA: 1:58 - loss: 10.4124 - accuracy: 0.0046
on_train_batch_begin: 1598475038.266981s

7 step training time: 0.337231s

on_train_batch_end: 1598475038.606927s

 8192/50000 [===>..........................] - ETA: 1:43 - loss: 10.1197 - accuracy: 0.0070
on_train_batch_begin: 1598475038.607239s

8 step training time: 0.340259s

on_train_batch_end: 1598475038.943377s

 9216/50000 [====>.........................] - ETA: 1:31 - loss: 9.8708 - accuracy: 0.0096 
on_train_batch_begin: 1598475038.943695s

9 step training time: 0.336455s

on_train_batch_end: 1598475039.279591s

10240/50000 [=====>........................] - ETA: 1:21 - loss: 9.6630 - accuracy: 0.0129
on_train_batch_begin: 1598475039.279898s

10 step training time: 0.336203s

on_train_batch_end: 1598475039.622378s

11264/50000 [=====>........................] - ETA: 1:13 - loss: 9.4912 - accuracy: 0.0145
on_train_batch_begin: 1598475039.622721s

11 step training time: 0.342824s

on_train_batch_end: 1598475039.945541s

12288/50000 [======>.......................] - ETA: 1:06 - loss: 9.3547 - accuracy: 0.0170
on_train_batch_begin: 1598475039.945862s

12 step training time: 0.323140s

on_train_batch_end: 1598475040.281488s

13312/50000 [======>.......................] - ETA: 1:00 - loss: 9.2331 - accuracy: 0.0189
on_train_batch_begin: 1598475040.281824s

13 step training time: 0.335963s

on_train_batch_end: 1598475040.621831s

14336/50000 [=======>......................] - ETA: 55s - loss: 9.1255 - accuracy: 0.0215 
on_train_batch_begin: 1598475040.622138s

14 step training time: 0.340314s

on_train_batch_end: 1598475040.951734s

15360/50000 [========>.....................] - ETA: 50s - loss: 9.0236 - accuracy: 0.0235
on_train_batch_begin: 1598475040.952049s

15 step training time: 0.329911s

on_train_batch_end: 1598475041.281835s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.9322 - accuracy: 0.0251
on_train_batch_begin: 1598475041.282141s

16 step training time: 0.330093s

on_train_batch_end: 1598475041.622275s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.8449 - accuracy: 0.0275
on_train_batch_begin: 1598475041.622582s

17 step training time: 0.340441s

on_train_batch_end: 1598475041.959533s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.7742 - accuracy: 0.0304
on_train_batch_begin: 1598475041.959847s

18 step training time: 0.337265s

on_train_batch_end: 1598475042.293489s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.6942 - accuracy: 0.0324
on_train_batch_begin: 1598475042.293824s

19 step training time: 0.333977s

on_train_batch_end: 1598475042.629333s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.6325 - accuracy: 0.0345
on_train_batch_begin: 1598475042.629659s

20 step training time: 0.335835s

on_train_batch_end: 1598475042.967361s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.5649 - accuracy: 0.0363
on_train_batch_begin: 1598475042.967665s

21 step training time: 0.338006s

on_train_batch_end: 1598475043.304939s

22528/50000 [============>.................] - ETA: 30s - loss: 8.5082 - accuracy: 0.0383
on_train_batch_begin: 1598475043.305239s

22 step training time: 0.337575s

on_train_batch_end: 1598475043.634985s

23552/50000 [=============>................] - ETA: 28s - loss: 8.4547 - accuracy: 0.0401
on_train_batch_begin: 1598475043.635284s

23 step training time: 0.330045s

on_train_batch_end: 1598475043.973211s

24576/50000 [=============>................] - ETA: 26s - loss: 8.4000 - accuracy: 0.0414
on_train_batch_begin: 1598475043.973517s

24 step training time: 0.338233s

on_train_batch_end: 1598475044.311213s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.3418 - accuracy: 0.0424
on_train_batch_begin: 1598475044.311522s

25 step training time: 0.338004s

on_train_batch_end: 1598475044.647637s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.2934 - accuracy: 0.0432
on_train_batch_begin: 1598475044.647945s

26 step training time: 0.336423s

on_train_batch_end: 1598475044.984727s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.2452 - accuracy: 0.0439
on_train_batch_begin: 1598475044.985043s

27 step training time: 0.337098s

on_train_batch_end: 1598475045.323025s

28672/50000 [================>.............] - ETA: 20s - loss: 8.2002 - accuracy: 0.0444
on_train_batch_begin: 1598475045.323338s

28 step training time: 0.338295s

on_train_batch_end: 1598475045.659221s

29696/50000 [================>.............] - ETA: 18s - loss: 8.1529 - accuracy: 0.0448
on_train_batch_begin: 1598475045.659531s

29 step training time: 0.336193s

on_train_batch_end: 1598475045.994566s

30720/50000 [=================>............] - ETA: 17s - loss: 8.1045 - accuracy: 0.0451
on_train_batch_begin: 1598475045.994872s

30 step training time: 0.335340s

on_train_batch_end: 1598475046.334149s

31744/50000 [==================>...........] - ETA: 16s - loss: 8.0538 - accuracy: 0.0451
on_train_batch_begin: 1598475046.334452s

31 step training time: 0.339581s

on_train_batch_end: 1598475046.669508s

32768/50000 [==================>...........] - ETA: 14s - loss: 8.0034 - accuracy: 0.0456
on_train_batch_begin: 1598475046.669826s

32 step training time: 0.335374s

on_train_batch_end: 1598475047.008621s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.9537 - accuracy: 0.0463
on_train_batch_begin: 1598475047.008933s

33 step training time: 0.339107s

on_train_batch_end: 1598475047.344760s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.9119 - accuracy: 0.0468
on_train_batch_begin: 1598475047.345057s

34 step training time: 0.336124s

on_train_batch_end: 1598475047.686871s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.8688 - accuracy: 0.0466
on_train_batch_begin: 1598475047.687168s

35 step training time: 0.342111s

on_train_batch_end: 1598475048.028657s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.8225 - accuracy: 0.0468
on_train_batch_begin: 1598475048.028981s

36 step training time: 0.341814s

on_train_batch_end: 1598475048.369806s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.7766 - accuracy: 0.0474 
on_train_batch_begin: 1598475048.370113s

37 step training time: 0.341131s

on_train_batch_end: 1598475048.706083s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.7366 - accuracy: 0.0478
on_train_batch_begin: 1598475048.706384s

38 step training time: 0.336271s

on_train_batch_end: 1598475049.043001s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.6900 - accuracy: 0.0482
on_train_batch_begin: 1598475049.043314s

39 step training time: 0.336930s

on_train_batch_end: 1598475049.379564s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.6491 - accuracy: 0.0485
on_train_batch_begin: 1598475049.379870s

40 step training time: 0.336556s

on_train_batch_end: 1598475049.717181s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.6049 - accuracy: 0.0490
on_train_batch_begin: 1598475049.717498s

41 step training time: 0.337628s

on_train_batch_end: 1598475050.060681s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.5641 - accuracy: 0.0493
on_train_batch_begin: 1598475050.060981s

42 step training time: 0.343483s

on_train_batch_end: 1598475050.399765s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.5200 - accuracy: 0.0495
on_train_batch_begin: 1598475050.400072s

43 step training time: 0.339091s

on_train_batch_end: 1598475050.735241s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.4769 - accuracy: 0.0498
on_train_batch_begin: 1598475050.735543s

44 step training time: 0.335472s

on_train_batch_end: 1598475051.078405s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.4344 - accuracy: 0.0500
on_train_batch_begin: 1598475051.078709s

45 step training time: 0.343166s

on_train_batch_end: 1598475051.419706s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.3876 - accuracy: 0.0502
on_train_batch_begin: 1598475051.420017s

46 step training time: 0.341308s

on_train_batch_end: 1598475051.755837s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.3430 - accuracy: 0.0505
on_train_batch_begin: 1598475051.756159s

47 step training time: 0.336142s

on_train_batch_end: 1598475052.097940s

49152/50000 [============================>.] - ETA: 0s - loss: 7.2985 - accuracy: 0.0508
on_train_batch_begin: 1598475052.098245s

48 step training time: 0.342085s

on_train_batch_end: 1598475058.357055s

on_test_batch_begin: 1598475058.542666s

49 step training time: 6.444421s

on_epoch_end: 1598475063.286918s

Validation time: 4.744236s

Real time: 1598475063.286918s

Epoch time: 44.92057156562805s

50000/50000 [==============================] - 45s 898us/sample - loss: 7.2629 - accuracy: 0.0510 - val_loss: 10.0520 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598475063.287117s

Real time: 1598475063.2871244
Epoch 2/5

on_train_batch_begin: 1598475063.290441s

on_train_batch_end: 1598475063.640105s

 1024/50000 [..............................] - ETA: 16s - loss: 5.0296 - accuracy: 0.0674
on_train_batch_begin: 1598475063.640418s

1 step training time: 0.349977s

on_train_batch_end: 1598475063.979830s

 2048/50000 [>.............................] - ETA: 16s - loss: 4.9327 - accuracy: 0.0671
on_train_batch_begin: 1598475063.980138s

2 step training time: 0.339719s

on_train_batch_end: 1598475064.320854s

 3072/50000 [>.............................] - ETA: 15s - loss: 4.9168 - accuracy: 0.0694
on_train_batch_begin: 1598475064.321167s

3 step training time: 0.341029s

on_train_batch_end: 1598475064.666575s

 4096/50000 [=>............................] - ETA: 15s - loss: 4.8988 - accuracy: 0.0690
on_train_batch_begin: 1598475064.666877s

4 step training time: 0.345710s

on_train_batch_end: 1598475065.014783s

 5120/50000 [==>...........................] - ETA: 15s - loss: 4.8634 - accuracy: 0.0698
on_train_batch_begin: 1598475065.015078s

5 step training time: 0.348201s

on_train_batch_end: 1598475065.356109s

 6144/50000 [==>...........................] - ETA: 14s - loss: 4.8368 - accuracy: 0.0702
on_train_batch_begin: 1598475065.356409s

6 step training time: 0.341331s

on_train_batch_end: 1598475065.703894s

 7168/50000 [===>..........................] - ETA: 14s - loss: 4.8078 - accuracy: 0.0709
on_train_batch_begin: 1598475065.704218s

7 step training time: 0.347809s

on_train_batch_end: 1598475066.050545s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.7684 - accuracy: 0.0722
on_train_batch_begin: 1598475066.050847s

8 step training time: 0.346628s

on_train_batch_end: 1598475066.395266s

 9216/50000 [====>.........................] - ETA: 13s - loss: 4.7534 - accuracy: 0.0727
on_train_batch_begin: 1598475066.395565s

9 step training time: 0.344718s

on_train_batch_end: 1598475066.739273s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.7303 - accuracy: 0.0733
on_train_batch_begin: 1598475066.739589s

10 step training time: 0.344025s

on_train_batch_end: 1598475067.085108s

11264/50000 [=====>........................] - ETA: 13s - loss: 4.7094 - accuracy: 0.0739
on_train_batch_begin: 1598475067.085415s

11 step training time: 0.345826s

on_train_batch_end: 1598475067.429061s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.6843 - accuracy: 0.0740
on_train_batch_begin: 1598475067.429362s

12 step training time: 0.343946s

on_train_batch_end: 1598475067.774307s

13312/50000 [======>.......................] - ETA: 12s - loss: 4.6569 - accuracy: 0.0741
on_train_batch_begin: 1598475067.774613s

13 step training time: 0.345251s

on_train_batch_end: 1598475068.121882s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.6206 - accuracy: 0.0745
on_train_batch_begin: 1598475068.122200s

14 step training time: 0.347587s

on_train_batch_end: 1598475068.467133s

15360/50000 [========>.....................] - ETA: 11s - loss: 4.5909 - accuracy: 0.0746
on_train_batch_begin: 1598475068.467440s

15 step training time: 0.345240s

on_train_batch_end: 1598475068.818856s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.5537 - accuracy: 0.0750
on_train_batch_begin: 1598475068.819159s

16 step training time: 0.351719s

on_train_batch_end: 1598475069.158926s

17408/50000 [=========>....................] - ETA: 10s - loss: 4.5215 - accuracy: 0.0754
on_train_batch_begin: 1598475069.159246s

17 step training time: 0.340087s

on_train_batch_end: 1598475069.508843s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.5012 - accuracy: 0.0755
on_train_batch_begin: 1598475069.509146s

18 step training time: 0.349900s

on_train_batch_end: 1598475069.859766s

19456/50000 [==========>...................] - ETA: 10s - loss: 4.4759 - accuracy: 0.0756
on_train_batch_begin: 1598475069.860070s

19 step training time: 0.350924s

on_train_batch_end: 1598475070.203724s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.4586 - accuracy: 0.0756 
on_train_batch_begin: 1598475070.204038s

20 step training time: 0.343968s

on_train_batch_end: 1598475070.554101s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.4296 - accuracy: 0.0757
on_train_batch_begin: 1598475070.554404s

21 step training time: 0.350366s

on_train_batch_end: 1598475070.899846s

22528/50000 [============>.................] - ETA: 9s - loss: 4.3987 - accuracy: 0.0759
on_train_batch_begin: 1598475070.900146s

22 step training time: 0.345742s

on_train_batch_end: 1598475071.247087s

23552/50000 [=============>................] - ETA: 8s - loss: 4.3659 - accuracy: 0.0763
on_train_batch_begin: 1598475071.247392s

23 step training time: 0.347246s

on_train_batch_end: 1598475071.595824s

24576/50000 [=============>................] - ETA: 8s - loss: 4.3339 - accuracy: 0.0766
on_train_batch_begin: 1598475071.596123s

24 step training time: 0.348731s

on_train_batch_end: 1598475071.942568s

25600/50000 [==============>...............] - ETA: 8s - loss: 4.2974 - accuracy: 0.0769
on_train_batch_begin: 1598475071.942899s

25 step training time: 0.346776s

on_train_batch_end: 1598475072.291352s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.2639 - accuracy: 0.0771
on_train_batch_begin: 1598475072.291658s

26 step training time: 0.348759s

on_train_batch_end: 1598475072.638969s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.2291 - accuracy: 0.0773
on_train_batch_begin: 1598475072.639266s

27 step training time: 0.347607s

on_train_batch_end: 1598475072.990383s

28672/50000 [================>.............] - ETA: 7s - loss: 4.1960 - accuracy: 0.0777
on_train_batch_begin: 1598475072.990700s

28 step training time: 0.351434s

on_train_batch_end: 1598475073.337816s

29696/50000 [================>.............] - ETA: 6s - loss: 4.1626 - accuracy: 0.0780
on_train_batch_begin: 1598475073.338143s

29 step training time: 0.347443s

on_train_batch_end: 1598475073.687917s

30720/50000 [=================>............] - ETA: 6s - loss: 4.1379 - accuracy: 0.0782
on_train_batch_begin: 1598475073.688219s

30 step training time: 0.350076s

on_train_batch_end: 1598475074.039386s

31744/50000 [==================>...........] - ETA: 6s - loss: 4.1015 - accuracy: 0.0786
on_train_batch_begin: 1598475074.039685s

31 step training time: 0.351466s

on_train_batch_end: 1598475074.390115s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.0661 - accuracy: 0.0789
on_train_batch_begin: 1598475074.390418s

32 step training time: 0.350732s

on_train_batch_end: 1598475074.737746s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.0271 - accuracy: 0.0794
on_train_batch_begin: 1598475074.738052s

33 step training time: 0.347634s

on_train_batch_end: 1598475075.084626s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.9916 - accuracy: 0.0799
on_train_batch_begin: 1598475075.084995s

34 step training time: 0.346943s

on_train_batch_end: 1598475075.439609s

35840/50000 [====================>.........] - ETA: 4s - loss: 3.9635 - accuracy: 0.0804
on_train_batch_begin: 1598475075.439908s

35 step training time: 0.354913s

on_train_batch_end: 1598475075.791904s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.9355 - accuracy: 0.0808
on_train_batch_begin: 1598475075.792211s

36 step training time: 0.352303s

on_train_batch_end: 1598475076.139194s

37888/50000 [=====================>........] - ETA: 4s - loss: 3.9066 - accuracy: 0.0813
on_train_batch_begin: 1598475076.139491s

37 step training time: 0.347280s

on_train_batch_end: 1598475076.490427s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.8720 - accuracy: 0.0817
on_train_batch_begin: 1598475076.490734s

38 step training time: 0.351243s

on_train_batch_end: 1598475076.841662s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.8416 - accuracy: 0.0822
on_train_batch_begin: 1598475076.841977s

39 step training time: 0.351243s

on_train_batch_end: 1598475077.191777s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.8107 - accuracy: 0.0826
on_train_batch_begin: 1598475077.192082s

40 step training time: 0.350105s

on_train_batch_end: 1598475077.543768s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.7805 - accuracy: 0.0830
on_train_batch_begin: 1598475077.544088s

41 step training time: 0.352006s

on_train_batch_end: 1598475077.892371s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.7522 - accuracy: 0.0833
on_train_batch_begin: 1598475077.892669s

42 step training time: 0.348581s

on_train_batch_end: 1598475078.243941s

44032/50000 [=========================>....] - ETA: 2s - loss: 3.7270 - accuracy: 0.0837
on_train_batch_begin: 1598475078.244261s

43 step training time: 0.351592s

on_train_batch_end: 1598475078.593864s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.6963 - accuracy: 0.0840
on_train_batch_begin: 1598475078.594186s

44 step training time: 0.349924s

on_train_batch_end: 1598475078.947994s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.6704 - accuracy: 0.0844
on_train_batch_begin: 1598475078.948415s

45 step training time: 0.354229s

on_train_batch_end: 1598475079.300228s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.6422 - accuracy: 0.0847
on_train_batch_begin: 1598475079.300535s

46 step training time: 0.352121s

on_train_batch_end: 1598475079.652033s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.6179 - accuracy: 0.0850
on_train_batch_begin: 1598475079.652335s

47 step training time: 0.351799s

on_train_batch_end: 1598475080.003703s

49152/50000 [============================>.] - ETA: 0s - loss: 3.5909 - accuracy: 0.0853
on_train_batch_begin: 1598475080.004019s

48 step training time: 0.351684s

on_train_batch_end: 1598475080.295131s

on_test_batch_begin: 1598475080.305675s

49 step training time: 0.301656s

on_epoch_end: 1598475081.133322s

Validation time: 0.827631s

Real time: 1598475081.133322s

Epoch time: 17.846214294433594s

50000/50000 [==============================] - 18s 357us/sample - loss: 3.5700 - accuracy: 0.0855 - val_loss: 6.8387 - val_accuracy: 0.1000

on_epoch_begin: 1598475081.133521s

Real time: 1598475081.1335285
Epoch 3/5

on_train_batch_begin: 1598475081.136910s

on_train_batch_end: 1598475081.483956s

 1024/50000 [..............................] - ETA: 16s - loss: 2.2419 - accuracy: 0.0996
on_train_batch_begin: 1598475081.484264s

1 step training time: 0.347354s

on_train_batch_end: 1598475081.830283s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.2783 - accuracy: 0.1001
on_train_batch_begin: 1598475081.830590s

2 step training time: 0.346326s

on_train_batch_end: 1598475082.187599s

 3072/50000 [>.............................] - ETA: 16s - loss: 2.2505 - accuracy: 0.1001
on_train_batch_begin: 1598475082.187903s

3 step training time: 0.357312s

on_train_batch_end: 1598475082.542183s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.2453 - accuracy: 0.1000
on_train_batch_begin: 1598475082.542495s

4 step training time: 0.354593s

on_train_batch_end: 1598475082.890635s

 5120/50000 [==>...........................] - ETA: 15s - loss: 2.2215 - accuracy: 0.1001
on_train_batch_begin: 1598475082.890935s

5 step training time: 0.348439s

on_train_batch_end: 1598475083.241703s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.1763 - accuracy: 0.1001
on_train_batch_begin: 1598475083.242012s

6 step training time: 0.351078s

on_train_batch_end: 1598475083.597024s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.1664 - accuracy: 0.1001
on_train_batch_begin: 1598475083.597322s

7 step training time: 0.355310s

on_train_batch_end: 1598475083.941068s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.1433 - accuracy: 0.1001
on_train_batch_begin: 1598475083.941377s

8 step training time: 0.344055s

on_train_batch_end: 1598475084.294482s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.1379 - accuracy: 0.1002
on_train_batch_begin: 1598475084.294781s

9 step training time: 0.353404s

on_train_batch_end: 1598475084.646197s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.1481 - accuracy: 0.1001
on_train_batch_begin: 1598475084.646495s

10 step training time: 0.351714s

on_train_batch_end: 1598475084.996129s

11264/50000 [=====>........................] - ETA: 13s - loss: 2.1531 - accuracy: 0.1002
on_train_batch_begin: 1598475084.996428s

11 step training time: 0.349933s

on_train_batch_end: 1598475085.350419s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.1631 - accuracy: 0.1002
on_train_batch_begin: 1598475085.350729s

12 step training time: 0.354300s

on_train_batch_end: 1598475085.702264s

13312/50000 [======>.......................] - ETA: 12s - loss: 2.1723 - accuracy: 0.1002
on_train_batch_begin: 1598475085.702583s

13 step training time: 0.351854s

on_train_batch_end: 1598475086.053052s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.1716 - accuracy: 0.1002
on_train_batch_begin: 1598475086.053366s

14 step training time: 0.350783s

on_train_batch_end: 1598475086.405480s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.1660 - accuracy: 0.1002
on_train_batch_begin: 1598475086.405811s

15 step training time: 0.352445s

on_train_batch_end: 1598475086.758575s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.1656 - accuracy: 0.1001
on_train_batch_begin: 1598475086.758878s

16 step training time: 0.353067s

on_train_batch_end: 1598475087.108366s

17408/50000 [=========>....................] - ETA: 11s - loss: 2.1649 - accuracy: 0.1001
on_train_batch_begin: 1598475087.108668s

17 step training time: 0.349791s

on_train_batch_end: 1598475087.462286s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.1550 - accuracy: 0.1001
on_train_batch_begin: 1598475087.462590s

18 step training time: 0.353922s

on_train_batch_end: 1598475087.820099s

19456/50000 [==========>...................] - ETA: 10s - loss: 2.1383 - accuracy: 0.1001
on_train_batch_begin: 1598475087.820395s

19 step training time: 0.357805s

on_train_batch_end: 1598475088.173696s

20480/50000 [===========>..................] - ETA: 10s - loss: 2.1317 - accuracy: 0.1001
on_train_batch_begin: 1598475088.174016s

20 step training time: 0.353621s

on_train_batch_end: 1598475088.527279s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.1304 - accuracy: 0.1001 
on_train_batch_begin: 1598475088.527578s

21 step training time: 0.353562s

on_train_batch_end: 1598475088.880624s

22528/50000 [============>.................] - ETA: 9s - loss: 2.1337 - accuracy: 0.1001
on_train_batch_begin: 1598475088.880929s

22 step training time: 0.353351s

on_train_batch_end: 1598475089.238082s

23552/50000 [=============>................] - ETA: 9s - loss: 2.1291 - accuracy: 0.1002
on_train_batch_begin: 1598475089.238387s

23 step training time: 0.357458s

on_train_batch_end: 1598475089.590355s

24576/50000 [=============>................] - ETA: 8s - loss: 2.1249 - accuracy: 0.1001
on_train_batch_begin: 1598475089.590661s

24 step training time: 0.352274s

on_train_batch_end: 1598475089.943633s

25600/50000 [==============>...............] - ETA: 8s - loss: 2.1212 - accuracy: 0.1001
on_train_batch_begin: 1598475089.943942s

25 step training time: 0.353281s

on_train_batch_end: 1598475090.297960s

26624/50000 [==============>...............] - ETA: 8s - loss: 2.1183 - accuracy: 0.1001
on_train_batch_begin: 1598475090.298263s

26 step training time: 0.354320s

on_train_batch_end: 1598475090.648670s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.1158 - accuracy: 0.1001
on_train_batch_begin: 1598475090.648976s

27 step training time: 0.350713s

on_train_batch_end: 1598475091.004449s

28672/50000 [================>.............] - ETA: 7s - loss: 2.1089 - accuracy: 0.1001
on_train_batch_begin: 1598475091.004765s

28 step training time: 0.355789s

on_train_batch_end: 1598475091.359051s

29696/50000 [================>.............] - ETA: 6s - loss: 2.1061 - accuracy: 0.1001
on_train_batch_begin: 1598475091.359355s

29 step training time: 0.354591s

on_train_batch_end: 1598475091.715042s

30720/50000 [=================>............] - ETA: 6s - loss: 2.1028 - accuracy: 0.1002
on_train_batch_begin: 1598475091.715341s

30 step training time: 0.355986s

on_train_batch_end: 1598475092.071775s

31744/50000 [==================>...........] - ETA: 6s - loss: 2.0976 - accuracy: 0.1002
on_train_batch_begin: 1598475092.072071s

31 step training time: 0.356730s

on_train_batch_end: 1598475092.427259s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.0873 - accuracy: 0.1002
on_train_batch_begin: 1598475092.427556s

32 step training time: 0.355485s

on_train_batch_end: 1598475092.781214s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.0803 - accuracy: 0.1002
on_train_batch_begin: 1598475092.781517s

33 step training time: 0.353961s

on_train_batch_end: 1598475093.136343s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.0730 - accuracy: 0.1002
on_train_batch_begin: 1598475093.136655s

34 step training time: 0.355137s

on_train_batch_end: 1598475093.489419s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.0661 - accuracy: 0.1002
on_train_batch_begin: 1598475093.489755s

35 step training time: 0.353100s

on_train_batch_end: 1598475093.842458s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.0598 - accuracy: 0.1002
on_train_batch_begin: 1598475093.842771s

36 step training time: 0.353017s

on_train_batch_end: 1598475094.194853s

37888/50000 [=====================>........] - ETA: 4s - loss: 2.0554 - accuracy: 0.1002
on_train_batch_begin: 1598475094.195148s

37 step training time: 0.352377s

on_train_batch_end: 1598475094.551308s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.0489 - accuracy: 0.1002
on_train_batch_begin: 1598475094.551624s

38 step training time: 0.356476s

on_train_batch_end: 1598475094.907289s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.0443 - accuracy: 0.1002
on_train_batch_begin: 1598475094.907594s

39 step training time: 0.355970s

on_train_batch_end: 1598475095.258747s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.0373 - accuracy: 0.1002
on_train_batch_begin: 1598475095.259042s

40 step training time: 0.351448s

on_train_batch_end: 1598475095.614856s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.0315 - accuracy: 0.1002
on_train_batch_begin: 1598475095.615163s

41 step training time: 0.356122s

on_train_batch_end: 1598475095.966291s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.0254 - accuracy: 0.1002
on_train_batch_begin: 1598475095.966643s

42 step training time: 0.351480s

on_train_batch_end: 1598475096.321176s

44032/50000 [=========================>....] - ETA: 2s - loss: 2.0209 - accuracy: 0.1002
on_train_batch_begin: 1598475096.321493s

43 step training time: 0.354850s

on_train_batch_end: 1598475096.678591s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.0163 - accuracy: 0.1002
on_train_batch_begin: 1598475096.678901s

44 step training time: 0.357408s

on_train_batch_end: 1598475097.033183s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.0107 - accuracy: 0.1002
on_train_batch_begin: 1598475097.033493s

45 step training time: 0.354592s

on_train_batch_end: 1598475097.387705s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.0071 - accuracy: 0.1002
on_train_batch_begin: 1598475097.388017s

46 step training time: 0.354525s

on_train_batch_end: 1598475097.745432s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.0034 - accuracy: 0.1002
on_train_batch_begin: 1598475097.745778s

47 step training time: 0.357761s

on_train_batch_end: 1598475098.101165s

49152/50000 [============================>.] - ETA: 0s - loss: 1.9974 - accuracy: 0.1002
on_train_batch_begin: 1598475098.101468s

48 step training time: 0.355690s

on_train_batch_end: 1598475098.401803s

on_test_batch_begin: 1598475098.411684s

49 step training time: 0.310217s

on_epoch_end: 1598475099.244704s

Validation time: 0.833006s

Real time: 1598475099.244704s

Epoch time: 18.111191034317017s

50000/50000 [==============================] - 18s 362us/sample - loss: 1.9955 - accuracy: 0.1002 - val_loss: 7.1926 - val_accuracy: 0.0999

on_epoch_begin: 1598475099.244891s

Real time: 1598475099.2448964
Epoch 4/5

on_train_batch_begin: 1598475099.248370s

on_train_batch_end: 1598475099.600263s

 1024/50000 [..............................] - ETA: 17s - loss: 1.8253 - accuracy: 0.1003
on_train_batch_begin: 1598475099.600585s

1 step training time: 0.352215s

on_train_batch_end: 1598475099.953678s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.7525 - accuracy: 0.1002
on_train_batch_begin: 1598475099.953992s

2 step training time: 0.353407s

on_train_batch_end: 1598475100.317660s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.7643 - accuracy: 0.1003
on_train_batch_begin: 1598475100.317976s

3 step training time: 0.363983s

on_train_batch_end: 1598475100.673280s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.8094 - accuracy: 0.1003
on_train_batch_begin: 1598475100.673663s

4 step training time: 0.355687s

on_train_batch_end: 1598475101.025827s

 5120/50000 [==>...........................] - ETA: 15s - loss: 1.8417 - accuracy: 0.1002
on_train_batch_begin: 1598475101.026135s

5 step training time: 0.352473s

on_train_batch_end: 1598475101.385830s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.8379 - accuracy: 0.1002
on_train_batch_begin: 1598475101.386127s

6 step training time: 0.359992s

on_train_batch_end: 1598475101.747991s

 7168/50000 [===>..........................] - ETA: 14s - loss: 1.8533 - accuracy: 0.1002
on_train_batch_begin: 1598475101.748290s

7 step training time: 0.362163s

on_train_batch_end: 1598475102.105949s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.8592 - accuracy: 0.1002
on_train_batch_begin: 1598475102.106250s

8 step training time: 0.357960s

on_train_batch_end: 1598475102.465681s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.8517 - accuracy: 0.1002
on_train_batch_begin: 1598475102.465978s

9 step training time: 0.359728s

on_train_batch_end: 1598475102.824201s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.8633 - accuracy: 0.1002
on_train_batch_begin: 1598475102.824499s

10 step training time: 0.358520s

on_train_batch_end: 1598475103.182420s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.8787 - accuracy: 0.1002
on_train_batch_begin: 1598475103.182728s

11 step training time: 0.358229s

on_train_batch_end: 1598475103.544064s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.8762 - accuracy: 0.1002
on_train_batch_begin: 1598475103.544372s

12 step training time: 0.361644s

on_train_batch_end: 1598475103.899796s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.8819 - accuracy: 0.1002
on_train_batch_begin: 1598475103.900095s

13 step training time: 0.355724s

on_train_batch_end: 1598475104.258232s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.8908 - accuracy: 0.1001
on_train_batch_begin: 1598475104.258546s

14 step training time: 0.358451s

on_train_batch_end: 1598475104.616062s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.8946 - accuracy: 0.1002
on_train_batch_begin: 1598475104.616369s

15 step training time: 0.357823s

on_train_batch_end: 1598475104.977054s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.9026 - accuracy: 0.1002
on_train_batch_begin: 1598475104.977359s

16 step training time: 0.360990s

on_train_batch_end: 1598475105.336338s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.8941 - accuracy: 0.1002
on_train_batch_begin: 1598475105.336638s

17 step training time: 0.359279s

on_train_batch_end: 1598475105.698674s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.8825 - accuracy: 0.1001
on_train_batch_begin: 1598475105.698975s

18 step training time: 0.362337s

on_train_batch_end: 1598475106.055450s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.8721 - accuracy: 0.1002
on_train_batch_begin: 1598475106.055781s

19 step training time: 0.356807s

on_train_batch_end: 1598475106.417209s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.8684 - accuracy: 0.1002
on_train_batch_begin: 1598475106.417518s

20 step training time: 0.361737s

on_train_batch_end: 1598475106.777687s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.8582 - accuracy: 0.1002 
on_train_batch_begin: 1598475106.777995s

21 step training time: 0.360476s

on_train_batch_end: 1598475107.137832s

22528/50000 [============>.................] - ETA: 9s - loss: 1.8529 - accuracy: 0.1002
on_train_batch_begin: 1598475107.138141s

22 step training time: 0.360147s

on_train_batch_end: 1598475107.499032s

23552/50000 [=============>................] - ETA: 9s - loss: 1.8494 - accuracy: 0.1002
on_train_batch_begin: 1598475107.499338s

23 step training time: 0.361197s

on_train_batch_end: 1598475107.858719s

24576/50000 [=============>................] - ETA: 8s - loss: 1.8410 - accuracy: 0.1003
on_train_batch_begin: 1598475107.859022s

24 step training time: 0.359684s

on_train_batch_end: 1598475108.218063s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.8399 - accuracy: 0.1003
on_train_batch_begin: 1598475108.218358s

25 step training time: 0.359336s

on_train_batch_end: 1598475108.574623s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.8310 - accuracy: 0.1003
on_train_batch_begin: 1598475108.574921s

26 step training time: 0.356563s

on_train_batch_end: 1598475108.935570s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.8206 - accuracy: 0.1003
on_train_batch_begin: 1598475108.935907s

27 step training time: 0.360985s

on_train_batch_end: 1598475109.297397s

28672/50000 [================>.............] - ETA: 7s - loss: 1.8146 - accuracy: 0.1003
on_train_batch_begin: 1598475109.297734s

28 step training time: 0.361827s

on_train_batch_end: 1598475109.660573s

29696/50000 [================>.............] - ETA: 7s - loss: 1.8075 - accuracy: 0.1003
on_train_batch_begin: 1598475109.660880s

29 step training time: 0.363146s

on_train_batch_end: 1598475110.024394s

30720/50000 [=================>............] - ETA: 6s - loss: 1.8037 - accuracy: 0.1003
on_train_batch_begin: 1598475110.024694s

30 step training time: 0.363814s

on_train_batch_end: 1598475110.381508s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.7974 - accuracy: 0.1003
on_train_batch_begin: 1598475110.381835s

31 step training time: 0.357141s

on_train_batch_end: 1598475110.738485s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.7948 - accuracy: 0.1003
on_train_batch_begin: 1598475110.738786s

32 step training time: 0.356951s

on_train_batch_end: 1598475111.098983s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.7901 - accuracy: 0.1003
on_train_batch_begin: 1598475111.099293s

33 step training time: 0.360507s

on_train_batch_end: 1598475111.464250s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.7882 - accuracy: 0.1002
on_train_batch_begin: 1598475111.464559s

34 step training time: 0.365266s

on_train_batch_end: 1598475111.824704s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.7760 - accuracy: 0.1003
on_train_batch_begin: 1598475111.825016s

35 step training time: 0.360457s

on_train_batch_end: 1598475112.187867s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.7721 - accuracy: 0.1003
on_train_batch_begin: 1598475112.188168s

36 step training time: 0.363152s

on_train_batch_end: 1598475112.550125s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.7677 - accuracy: 0.1003
on_train_batch_begin: 1598475112.550431s

37 step training time: 0.362263s

on_train_batch_end: 1598475112.915106s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.7584 - accuracy: 0.1002
on_train_batch_begin: 1598475112.915425s

38 step training time: 0.364995s

on_train_batch_end: 1598475113.278407s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.7501 - accuracy: 0.1002
on_train_batch_begin: 1598475113.278720s

39 step training time: 0.363294s

on_train_batch_end: 1598475113.640758s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.7442 - accuracy: 0.1002
on_train_batch_begin: 1598475113.641071s

40 step training time: 0.362351s

on_train_batch_end: 1598475114.005847s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.7394 - accuracy: 0.1003
on_train_batch_begin: 1598475114.006169s

41 step training time: 0.365098s

on_train_batch_end: 1598475114.366441s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.7310 - accuracy: 0.1003
on_train_batch_begin: 1598475114.366758s

42 step training time: 0.360589s

on_train_batch_end: 1598475114.727367s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.7248 - accuracy: 0.1003
on_train_batch_begin: 1598475114.727685s

43 step training time: 0.360927s

on_train_batch_end: 1598475115.088722s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.7206 - accuracy: 0.1003
on_train_batch_begin: 1598475115.089018s

44 step training time: 0.361333s

on_train_batch_end: 1598475115.449636s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.7144 - accuracy: 0.1003
on_train_batch_begin: 1598475115.449941s

45 step training time: 0.360923s

on_train_batch_end: 1598475115.811085s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.7049 - accuracy: 0.1003
on_train_batch_begin: 1598475115.811383s

46 step training time: 0.361442s

on_train_batch_end: 1598475116.169437s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.6988 - accuracy: 0.1003
on_train_batch_begin: 1598475116.169782s

47 step training time: 0.358400s

on_train_batch_end: 1598475116.530644s

49152/50000 [============================>.] - ETA: 0s - loss: 1.6919 - accuracy: 0.1003
on_train_batch_begin: 1598475116.530964s

48 step training time: 0.361182s

on_train_batch_end: 1598475116.832097s

on_test_batch_begin: 1598475116.841909s

49 step training time: 0.310945s

on_epoch_end: 1598475117.687289s

Validation time: 0.845368s

Real time: 1598475117.687289s

Epoch time: 18.4424090385437s

50000/50000 [==============================] - 18s 369us/sample - loss: 1.6893 - accuracy: 0.1002 - val_loss: 7.2674 - val_accuracy: 0.0999

on_epoch_begin: 1598475117.687473s

Real time: 1598475117.6874778
Epoch 5/5

on_train_batch_begin: 1598475117.690804s

on_train_batch_end: 1598475118.051673s

 1024/50000 [..............................] - ETA: 17s - loss: 1.2885 - accuracy: 0.1001
on_train_batch_begin: 1598475118.051987s

1 step training time: 0.361183s

on_train_batch_end: 1598475118.409415s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.3342 - accuracy: 0.1000
on_train_batch_begin: 1598475118.409743s

2 step training time: 0.357756s

on_train_batch_end: 1598475118.776189s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.3346 - accuracy: 0.1001
on_train_batch_begin: 1598475118.776493s

3 step training time: 0.366750s

on_train_batch_end: 1598475119.136988s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.3030 - accuracy: 0.1002
on_train_batch_begin: 1598475119.137285s

4 step training time: 0.360791s

on_train_batch_end: 1598475119.496858s

 5120/50000 [==>...........................] - ETA: 15s - loss: 1.2754 - accuracy: 0.1002
on_train_batch_begin: 1598475119.497160s

5 step training time: 0.359875s

on_train_batch_end: 1598475119.863400s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.2716 - accuracy: 0.1002
on_train_batch_begin: 1598475119.863710s

6 step training time: 0.366549s

on_train_batch_end: 1598475120.227496s

 7168/50000 [===>..........................] - ETA: 15s - loss: 1.2605 - accuracy: 0.1002
on_train_batch_begin: 1598475120.227798s

7 step training time: 0.364088s

on_train_batch_end: 1598475120.591593s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.2347 - accuracy: 0.1002
on_train_batch_begin: 1598475120.591892s

8 step training time: 0.364094s

on_train_batch_end: 1598475120.954801s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.2360 - accuracy: 0.1002
on_train_batch_begin: 1598475120.955102s

9 step training time: 0.363210s

on_train_batch_end: 1598475121.318048s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.2134 - accuracy: 0.1002
on_train_batch_begin: 1598475121.318364s

10 step training time: 0.363262s

on_train_batch_end: 1598475121.679470s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.2121 - accuracy: 0.1002
on_train_batch_begin: 1598475121.679792s

11 step training time: 0.361428s

on_train_batch_end: 1598475122.042069s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.2022 - accuracy: 0.1002
on_train_batch_begin: 1598475122.042370s

12 step training time: 0.362579s

on_train_batch_end: 1598475122.406891s

13312/50000 [======>.......................] - ETA: 13s - loss: 1.1892 - accuracy: 0.1002
on_train_batch_begin: 1598475122.407202s

13 step training time: 0.364832s

on_train_batch_end: 1598475122.767853s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.1845 - accuracy: 0.1002
on_train_batch_begin: 1598475122.768155s

14 step training time: 0.360953s

on_train_batch_end: 1598475123.132127s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.1817 - accuracy: 0.1002
on_train_batch_begin: 1598475123.132427s

15 step training time: 0.364271s

on_train_batch_end: 1598475123.496953s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.1766 - accuracy: 0.1003
on_train_batch_begin: 1598475123.497251s

16 step training time: 0.364824s

on_train_batch_end: 1598475123.860342s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.1709 - accuracy: 0.1003
on_train_batch_begin: 1598475123.860698s

17 step training time: 0.363448s

on_train_batch_end: 1598475124.225222s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.1630 - accuracy: 0.1003
on_train_batch_begin: 1598475124.225528s

18 step training time: 0.364830s

on_train_batch_end: 1598475124.591820s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.1573 - accuracy: 0.1003
on_train_batch_begin: 1598475124.592129s

19 step training time: 0.366601s

on_train_batch_end: 1598475124.954234s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.1509 - accuracy: 0.1003
on_train_batch_begin: 1598475124.954540s

20 step training time: 0.362411s

on_train_batch_end: 1598475125.320973s

21504/50000 [===========>..................] - ETA: 10s - loss: 1.1473 - accuracy: 0.1003
on_train_batch_begin: 1598475125.321277s

21 step training time: 0.366737s

on_train_batch_end: 1598475125.686254s

22528/50000 [============>.................] - ETA: 9s - loss: 1.1468 - accuracy: 0.1003 
on_train_batch_begin: 1598475125.686563s

22 step training time: 0.365286s

on_train_batch_end: 1598475126.046893s

23552/50000 [=============>................] - ETA: 9s - loss: 1.1456 - accuracy: 0.1002
on_train_batch_begin: 1598475126.047201s

23 step training time: 0.360638s

on_train_batch_end: 1598475126.415457s

24576/50000 [=============>................] - ETA: 9s - loss: 1.1421 - accuracy: 0.1002
on_train_batch_begin: 1598475126.415771s

24 step training time: 0.368570s

on_train_batch_end: 1598475126.780879s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.1462 - accuracy: 0.1002
on_train_batch_begin: 1598475126.781188s

25 step training time: 0.365417s

on_train_batch_end: 1598475127.141951s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.1435 - accuracy: 0.1002
on_train_batch_begin: 1598475127.142257s

26 step training time: 0.361069s

on_train_batch_end: 1598475127.507600s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.1387 - accuracy: 0.1002
on_train_batch_begin: 1598475127.507920s

27 step training time: 0.365663s

on_train_batch_end: 1598475127.875731s

28672/50000 [================>.............] - ETA: 7s - loss: 1.1391 - accuracy: 0.1002
on_train_batch_begin: 1598475127.876033s

28 step training time: 0.368113s

on_train_batch_end: 1598475128.238720s

29696/50000 [================>.............] - ETA: 7s - loss: 1.1371 - accuracy: 0.1002
on_train_batch_begin: 1598475128.239028s

29 step training time: 0.362995s

on_train_batch_end: 1598475128.598124s

30720/50000 [=================>............] - ETA: 6s - loss: 1.1386 - accuracy: 0.1002
on_train_batch_begin: 1598475128.598421s

30 step training time: 0.359394s

on_train_batch_end: 1598475128.966043s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.1311 - accuracy: 0.1002
on_train_batch_begin: 1598475128.966345s

31 step training time: 0.367924s

on_train_batch_end: 1598475129.331600s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.1301 - accuracy: 0.1002
on_train_batch_begin: 1598475129.331899s

32 step training time: 0.365554s

on_train_batch_end: 1598475129.696593s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.1251 - accuracy: 0.1002
on_train_batch_begin: 1598475129.696904s

33 step training time: 0.365005s

on_train_batch_end: 1598475130.060985s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.1214 - accuracy: 0.1002
on_train_batch_begin: 1598475130.061293s

34 step training time: 0.364389s

on_train_batch_end: 1598475130.427018s

35840/50000 [====================>.........] - ETA: 5s - loss: 1.1170 - accuracy: 0.1002
on_train_batch_begin: 1598475130.427336s

35 step training time: 0.366043s

on_train_batch_end: 1598475130.793860s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.1130 - accuracy: 0.1002
on_train_batch_begin: 1598475130.794171s

36 step training time: 0.366835s

on_train_batch_end: 1598475131.159865s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.1091 - accuracy: 0.1002
on_train_batch_begin: 1598475131.160182s

37 step training time: 0.366011s

on_train_batch_end: 1598475131.524554s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.1034 - accuracy: 0.1002
on_train_batch_begin: 1598475131.524864s

38 step training time: 0.364682s

on_train_batch_end: 1598475131.890610s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.1007 - accuracy: 0.1002
on_train_batch_begin: 1598475131.890917s

39 step training time: 0.366052s

on_train_batch_end: 1598475132.256847s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.0978 - accuracy: 0.1002
on_train_batch_begin: 1598475132.257151s

40 step training time: 0.366234s

on_train_batch_end: 1598475132.623738s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.0962 - accuracy: 0.1002
on_train_batch_begin: 1598475132.624060s

41 step training time: 0.366909s

on_train_batch_end: 1598475132.986960s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.0938 - accuracy: 0.1002
on_train_batch_begin: 1598475132.987264s

42 step training time: 0.363204s

on_train_batch_end: 1598475133.350839s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.0901 - accuracy: 0.1002
on_train_batch_begin: 1598475133.351139s

43 step training time: 0.363876s

on_train_batch_end: 1598475133.717352s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.0862 - accuracy: 0.1002
on_train_batch_begin: 1598475133.717674s

44 step training time: 0.366534s

on_train_batch_end: 1598475134.084327s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.0858 - accuracy: 0.1002
on_train_batch_begin: 1598475134.084649s

45 step training time: 0.366975s

on_train_batch_end: 1598475134.452467s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.0814 - accuracy: 0.1002
on_train_batch_begin: 1598475134.452774s

46 step training time: 0.368125s

on_train_batch_end: 1598475134.815675s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.0846 - accuracy: 0.1002
on_train_batch_begin: 1598475134.815980s

47 step training time: 0.363205s

on_train_batch_end: 1598475135.179387s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0822 - accuracy: 0.1002
on_train_batch_begin: 1598475135.179691s

48 step training time: 0.363712s

on_train_batch_end: 1598475135.480757s

on_test_batch_begin: 1598475135.492176s

49 step training time: 0.312485s

on_epoch_end: 1598475136.356867s

Validation time: 0.864677s

Real time: 1598475136.356867s

Epoch time: 18.669406414031982s

50000/50000 [==============================] - 19s 373us/sample - loss: 1.0790 - accuracy: 0.1002 - val_loss: 7.1517 - val_accuracy: 0.0999
Tempo do fit: 121.34806680679321