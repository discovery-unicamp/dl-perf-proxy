wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:29
   155648/170498071 [..............................] - ETA: 1:18
   663552/170498071 [..............................] - ETA: 31s 
  2236416/170498071 [..............................] - ETA: 12s
  5251072/170498071 [..............................] - ETA: 7s 
  8101888/170498071 [>.............................] - ETA: 5s
 11280384/170498071 [>.............................] - ETA: 4s
 14409728/170498071 [=>............................] - ETA: 4s
 17489920/170498071 [==>...........................] - ETA: 3s
 20389888/170498071 [==>...........................] - ETA: 3s
 23650304/170498071 [===>..........................] - ETA: 3s
 26648576/170498071 [===>..........................] - ETA: 3s
 29630464/170498071 [====>.........................] - ETA: 2s
 32677888/170498071 [====>.........................] - ETA: 2s
 35758080/170498071 [=====>........................] - ETA: 2s
 38936576/170498071 [=====>........................] - ETA: 2s
 41803776/170498071 [======>.......................] - ETA: 2s
 44802048/170498071 [======>.......................] - ETA: 2s
 47915008/170498071 [=======>......................] - ETA: 2s
 50880512/170498071 [=======>......................] - ETA: 2s
 53846016/170498071 [========>.....................] - ETA: 2s
 56893440/170498071 [=========>....................] - ETA: 2s
 59990016/170498071 [=========>....................] - ETA: 2s
 63021056/170498071 [==========>...................] - ETA: 2s
 65953792/170498071 [==========>...................] - ETA: 1s
 69263360/170498071 [===========>..................] - ETA: 1s
 72589312/170498071 [===========>..................] - ETA: 1s
 75833344/170498071 [============>.................] - ETA: 1s
 79159296/170498071 [============>.................] - ETA: 1s
 82567168/170498071 [=============>................] - ETA: 1s
 85942272/170498071 [==============>...............] - ETA: 1s
 89284608/170498071 [==============>...............] - ETA: 1s
 92495872/170498071 [===============>..............] - ETA: 1s
 95821824/170498071 [===============>..............] - ETA: 1s
 99131392/170498071 [================>.............] - ETA: 1s
102391808/170498071 [=================>............] - ETA: 1s
105701376/170498071 [=================>............] - ETA: 1s
108994560/170498071 [==================>...........] - ETA: 1s
112369664/170498071 [==================>...........] - ETA: 0s
115703808/170498071 [===================>..........] - ETA: 0s
119070720/170498071 [===================>..........] - ETA: 0s
122413056/170498071 [====================>.........] - ETA: 0s
125689856/170498071 [=====================>........] - ETA: 0s
128999424/170498071 [=====================>........] - ETA: 0s
132325376/170498071 [======================>.......] - ETA: 0s
135618560/170498071 [======================>.......] - ETA: 0s
138993664/170498071 [=======================>......] - ETA: 0s
142336000/170498071 [========================>.....] - ETA: 0s
145727488/170498071 [========================>.....] - ETA: 0s
149037056/170498071 [=========================>....] - ETA: 0s
152363008/170498071 [=========================>....] - ETA: 0s
155639808/170498071 [==========================>...] - ETA: 0s
158801920/170498071 [==========================>...] - ETA: 0s
162095104/170498071 [===========================>..] - ETA: 0s
165404672/170498071 [============================>.] - ETA: 0s
168763392/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 3s
 4276224/94765736 [>.............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 1s
15261696/94765736 [===>..........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 1s
21692416/94765736 [=====>........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 0s
46047232/94765736 [=============>................] - ETA: 0s
52043776/94765736 [===============>..............] - ETA: 0s
57573376/94765736 [=================>............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
68911104/94765736 [====================>.........] - ETA: 0s
73654272/94765736 [======================>.......] - ETA: 0s
82370560/94765736 [=========================>....] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 20.089777946472168
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615761866.089674s

Real time: 1615761866.0896888
Epoch 1/5

on_train_batch_begin: 1615761866.909089s

on_train_batch_end: 1615761914.966474s

 1024/50000 [..............................] - ETA: 38:57 - loss: 17.4848 - accuracy: 4.0817e-04
on_train_batch_begin: 1615761914.967070s

1 step training time: 48.057981s

on_train_batch_end: 1615761915.104545s

 2048/50000 [>.............................] - ETA: 19:07 - loss: 14.7026 - accuracy: 7.1335e-04
on_train_batch_begin: 1615761915.104856s

2 step training time: 0.137786s

on_train_batch_end: 1615761915.235206s

 3072/50000 [>.............................] - ETA: 12:30 - loss: 12.7900 - accuracy: 8.0999e-04
on_train_batch_begin: 1615761915.235518s

3 step training time: 0.130661s

on_train_batch_end: 1615761915.367779s

 4096/50000 [=>............................] - ETA: 9:12 - loss: 11.6781 - accuracy: 0.0017     
on_train_batch_begin: 1615761915.368069s

4 step training time: 0.132552s

on_train_batch_end: 1615761915.497673s

 5120/50000 [==>...........................] - ETA: 7:13 - loss: 10.9777 - accuracy: 0.0040
on_train_batch_begin: 1615761915.497987s

5 step training time: 0.129918s

on_train_batch_end: 1615761915.630382s

 6144/50000 [==>...........................] - ETA: 5:53 - loss: 10.4966 - accuracy: 0.0071
on_train_batch_begin: 1615761915.630687s

6 step training time: 0.132700s

on_train_batch_end: 1615761915.761137s

 7168/50000 [===>..........................] - ETA: 4:56 - loss: 10.1358 - accuracy: 0.0099
on_train_batch_begin: 1615761915.761426s

7 step training time: 0.130739s

on_train_batch_end: 1615761915.893155s

 8192/50000 [===>..........................] - ETA: 4:14 - loss: 9.8764 - accuracy: 0.0128 
on_train_batch_begin: 1615761915.893448s

8 step training time: 0.132022s

on_train_batch_end: 1615761916.025263s

 9216/50000 [====>.........................] - ETA: 3:40 - loss: 9.6487 - accuracy: 0.0156
on_train_batch_begin: 1615761916.025572s

9 step training time: 0.132124s

on_train_batch_end: 1615761916.157186s

10240/50000 [=====>........................] - ETA: 3:14 - loss: 9.4636 - accuracy: 0.0183
on_train_batch_begin: 1615761916.157480s

10 step training time: 0.131908s

on_train_batch_end: 1615761916.288082s

11264/50000 [=====>........................] - ETA: 2:52 - loss: 9.2993 - accuracy: 0.0210
on_train_batch_begin: 1615761916.288373s

11 step training time: 0.130894s

on_train_batch_end: 1615761916.419152s

12288/50000 [======>.......................] - ETA: 2:34 - loss: 9.1638 - accuracy: 0.0234
on_train_batch_begin: 1615761916.419446s

12 step training time: 0.131072s

on_train_batch_end: 1615761916.553498s

13312/50000 [======>.......................] - ETA: 2:19 - loss: 9.0435 - accuracy: 0.0258
on_train_batch_begin: 1615761916.553786s

13 step training time: 0.134340s

on_train_batch_end: 1615761916.686726s

14336/50000 [=======>......................] - ETA: 2:05 - loss: 8.9336 - accuracy: 0.0284
on_train_batch_begin: 1615761916.687006s

14 step training time: 0.133220s

on_train_batch_end: 1615761916.817594s

15360/50000 [========>.....................] - ETA: 1:54 - loss: 8.8361 - accuracy: 0.0311
on_train_batch_begin: 1615761916.817885s

15 step training time: 0.130879s

on_train_batch_end: 1615761916.950006s

16384/50000 [========>.....................] - ETA: 1:44 - loss: 8.7421 - accuracy: 0.0339
on_train_batch_begin: 1615761916.950297s

16 step training time: 0.132411s

on_train_batch_end: 1615761917.081058s

17408/50000 [=========>....................] - ETA: 1:35 - loss: 8.6523 - accuracy: 0.0368
on_train_batch_begin: 1615761917.081346s

17 step training time: 0.131049s

on_train_batch_end: 1615761917.214351s

18432/50000 [==========>...................] - ETA: 1:27 - loss: 8.5727 - accuracy: 0.0393
on_train_batch_begin: 1615761917.214648s

18 step training time: 0.133302s

on_train_batch_end: 1615761917.345144s

19456/50000 [==========>...................] - ETA: 1:20 - loss: 8.5005 - accuracy: 0.0416
on_train_batch_begin: 1615761917.345457s

19 step training time: 0.130809s

on_train_batch_end: 1615761917.476779s

20480/50000 [===========>..................] - ETA: 1:14 - loss: 8.4290 - accuracy: 0.0439
on_train_batch_begin: 1615761917.477067s

20 step training time: 0.131610s

on_train_batch_end: 1615761917.610420s

21504/50000 [===========>..................] - ETA: 1:08 - loss: 8.3576 - accuracy: 0.0458
on_train_batch_begin: 1615761917.610726s

21 step training time: 0.133659s

on_train_batch_end: 1615761917.741695s

22528/50000 [============>.................] - ETA: 1:02 - loss: 8.2963 - accuracy: 0.0476
on_train_batch_begin: 1615761917.742034s

22 step training time: 0.131308s

on_train_batch_end: 1615761917.874452s

23552/50000 [=============>................] - ETA: 58s - loss: 8.2366 - accuracy: 0.0492 
on_train_batch_begin: 1615761917.874786s

23 step training time: 0.132752s

on_train_batch_end: 1615761918.005275s

24576/50000 [=============>................] - ETA: 53s - loss: 8.1838 - accuracy: 0.0505
on_train_batch_begin: 1615761918.005578s

24 step training time: 0.130792s

on_train_batch_end: 1615761918.138176s

25600/50000 [==============>...............] - ETA: 49s - loss: 8.1344 - accuracy: 0.0518
on_train_batch_begin: 1615761918.138487s

25 step training time: 0.132909s

on_train_batch_end: 1615761918.270070s

26624/50000 [==============>...............] - ETA: 45s - loss: 8.0880 - accuracy: 0.0525
on_train_batch_begin: 1615761918.270358s

26 step training time: 0.131871s

on_train_batch_end: 1615761918.401469s

27648/50000 [===============>..............] - ETA: 42s - loss: 8.0419 - accuracy: 0.0534
on_train_batch_begin: 1615761918.401754s

27 step training time: 0.131396s

on_train_batch_end: 1615761918.532382s

28672/50000 [================>.............] - ETA: 39s - loss: 8.0006 - accuracy: 0.0549
on_train_batch_begin: 1615761918.532671s

28 step training time: 0.130917s

on_train_batch_end: 1615761918.664933s

29696/50000 [================>.............] - ETA: 35s - loss: 7.9613 - accuracy: 0.0562
on_train_batch_begin: 1615761918.665227s

29 step training time: 0.132556s

on_train_batch_end: 1615761918.796893s

30720/50000 [=================>............] - ETA: 33s - loss: 7.9210 - accuracy: 0.0573
on_train_batch_begin: 1615761918.797191s

30 step training time: 0.131964s

on_train_batch_end: 1615761918.929245s

31744/50000 [==================>...........] - ETA: 30s - loss: 7.8808 - accuracy: 0.0580
on_train_batch_begin: 1615761918.929533s

31 step training time: 0.132343s

on_train_batch_end: 1615761919.062919s

32768/50000 [==================>...........] - ETA: 27s - loss: 7.8404 - accuracy: 0.0589
on_train_batch_begin: 1615761919.063203s

32 step training time: 0.133670s

on_train_batch_end: 1615761919.196599s

33792/50000 [===================>..........] - ETA: 25s - loss: 7.8077 - accuracy: 0.0591
on_train_batch_begin: 1615761919.196880s

33 step training time: 0.133677s

on_train_batch_end: 1615761919.327478s

34816/50000 [===================>..........] - ETA: 23s - loss: 7.7674 - accuracy: 0.0594
on_train_batch_begin: 1615761919.327764s

34 step training time: 0.130883s

on_train_batch_end: 1615761919.459210s

35840/50000 [====================>.........] - ETA: 21s - loss: 7.7305 - accuracy: 0.0593
on_train_batch_begin: 1615761919.459521s

35 step training time: 0.131758s

on_train_batch_end: 1615761919.590628s

36864/50000 [=====================>........] - ETA: 19s - loss: 7.6904 - accuracy: 0.0592
on_train_batch_begin: 1615761919.590913s

36 step training time: 0.131391s

on_train_batch_end: 1615761919.722648s

37888/50000 [=====================>........] - ETA: 17s - loss: 7.6479 - accuracy: 0.0593
on_train_batch_begin: 1615761919.722932s

37 step training time: 0.132019s

on_train_batch_end: 1615761919.854255s

38912/50000 [======================>.......] - ETA: 15s - loss: 7.6112 - accuracy: 0.0592
on_train_batch_begin: 1615761919.854545s

38 step training time: 0.131613s

on_train_batch_end: 1615761919.985439s

39936/50000 [======================>.......] - ETA: 13s - loss: 7.5752 - accuracy: 0.0594
on_train_batch_begin: 1615761919.985720s

39 step training time: 0.131176s

on_train_batch_end: 1615761920.117345s

40960/50000 [=======================>......] - ETA: 11s - loss: 7.5460 - accuracy: 0.0595
on_train_batch_begin: 1615761920.117633s

40 step training time: 0.131913s

on_train_batch_end: 1615761920.249168s

41984/50000 [========================>.....] - ETA: 10s - loss: 7.5114 - accuracy: 0.0596
on_train_batch_begin: 1615761920.249458s

41 step training time: 0.131825s

on_train_batch_end: 1615761920.382831s

43008/50000 [========================>.....] - ETA: 8s - loss: 7.4741 - accuracy: 0.0598 
on_train_batch_begin: 1615761920.383119s

42 step training time: 0.133661s

on_train_batch_end: 1615761920.516255s

44032/50000 [=========================>....] - ETA: 7s - loss: 7.4391 - accuracy: 0.0598
on_train_batch_begin: 1615761920.516550s

43 step training time: 0.133431s

on_train_batch_end: 1615761920.647336s

45056/50000 [==========================>...] - ETA: 5s - loss: 7.4096 - accuracy: 0.0598
on_train_batch_begin: 1615761920.647636s

44 step training time: 0.131086s

on_train_batch_end: 1615761920.779225s

46080/50000 [==========================>...] - ETA: 4s - loss: 7.3775 - accuracy: 0.0597
on_train_batch_begin: 1615761920.779513s

45 step training time: 0.131877s

on_train_batch_end: 1615761920.910252s

47104/50000 [===========================>..] - ETA: 3s - loss: 7.3457 - accuracy: 0.0595
on_train_batch_begin: 1615761920.910540s

46 step training time: 0.131027s

on_train_batch_end: 1615761921.042319s

48128/50000 [===========================>..] - ETA: 2s - loss: 7.3132 - accuracy: 0.0593
on_train_batch_begin: 1615761921.042605s

47 step training time: 0.132065s

on_train_batch_end: 1615761921.173180s

49152/50000 [============================>.] - ETA: 0s - loss: 7.2814 - accuracy: 0.0592
on_train_batch_begin: 1615761921.173463s

48 step training time: 0.130859s

on_train_batch_end: 1615761923.762896s

on_test_batch_begin: 1615761923.999308s

49 step training time: 2.825845s

on_epoch_end: 1615761929.890626s

Validation time: 5.891304s

Real time: 1615761929.890626s

Epoch time: 63.80095624923706s

50000/50000 [==============================] - 64s 1ms/sample - loss: 7.2555 - accuracy: 0.0591 - val_loss: 10.1836 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615761929.890829s

Real time: 1615761929.8908336
Epoch 2/5

on_train_batch_begin: 1615761929.895110s

on_train_batch_end: 1615761930.029669s

 1024/50000 [..............................] - ETA: 6s - loss: 5.7662 - accuracy: 0.0625
on_train_batch_begin: 1615761930.029978s

1 step training time: 0.134868s

on_train_batch_end: 1615761930.160901s

 2048/50000 [>.............................] - ETA: 6s - loss: 5.6535 - accuracy: 0.0632
on_train_batch_begin: 1615761930.161179s

2 step training time: 0.131201s

on_train_batch_end: 1615761930.294619s

 3072/50000 [>.............................] - ETA: 6s - loss: 5.5765 - accuracy: 0.0656
on_train_batch_begin: 1615761930.294906s

3 step training time: 0.133728s

on_train_batch_end: 1615761930.425725s

 4096/50000 [=>............................] - ETA: 5s - loss: 5.5747 - accuracy: 0.0668
on_train_batch_begin: 1615761930.426032s

4 step training time: 0.131126s

on_train_batch_end: 1615761930.557775s

 5120/50000 [==>...........................] - ETA: 5s - loss: 5.5883 - accuracy: 0.0667
on_train_batch_begin: 1615761930.558098s

5 step training time: 0.132066s

on_train_batch_end: 1615761930.689351s

 6144/50000 [==>...........................] - ETA: 5s - loss: 5.5467 - accuracy: 0.0669
on_train_batch_begin: 1615761930.689638s

6 step training time: 0.131540s

on_train_batch_end: 1615761930.821516s

 7168/50000 [===>..........................] - ETA: 5s - loss: 5.5139 - accuracy: 0.0673
on_train_batch_begin: 1615761930.821805s

7 step training time: 0.132168s

on_train_batch_end: 1615761930.953276s

 8192/50000 [===>..........................] - ETA: 5s - loss: 5.4887 - accuracy: 0.0673
on_train_batch_begin: 1615761930.953567s

8 step training time: 0.131761s

on_train_batch_end: 1615761931.084936s

 9216/50000 [====>.........................] - ETA: 5s - loss: 5.4628 - accuracy: 0.0677
on_train_batch_begin: 1615761931.085230s

9 step training time: 0.131663s

on_train_batch_end: 1615761931.216025s

10240/50000 [=====>........................] - ETA: 5s - loss: 5.4550 - accuracy: 0.0682
on_train_batch_begin: 1615761931.216334s

10 step training time: 0.131104s

on_train_batch_end: 1615761931.348304s

11264/50000 [=====>........................] - ETA: 5s - loss: 5.4493 - accuracy: 0.0688
on_train_batch_begin: 1615761931.348608s

11 step training time: 0.132273s

on_train_batch_end: 1615761931.480122s

12288/50000 [======>.......................] - ETA: 4s - loss: 5.4360 - accuracy: 0.0693
on_train_batch_begin: 1615761931.480412s

12 step training time: 0.131805s

on_train_batch_end: 1615761931.612418s

13312/50000 [======>.......................] - ETA: 4s - loss: 5.4261 - accuracy: 0.0693
on_train_batch_begin: 1615761931.612705s

13 step training time: 0.132293s

on_train_batch_end: 1615761931.745287s

14336/50000 [=======>......................] - ETA: 4s - loss: 5.4272 - accuracy: 0.0690
on_train_batch_begin: 1615761931.745610s

14 step training time: 0.132905s

on_train_batch_end: 1615761931.876591s

15360/50000 [========>.....................] - ETA: 4s - loss: 5.4332 - accuracy: 0.0689
on_train_batch_begin: 1615761931.876879s

15 step training time: 0.131269s

on_train_batch_end: 1615761932.008032s

16384/50000 [========>.....................] - ETA: 4s - loss: 5.4232 - accuracy: 0.0691
on_train_batch_begin: 1615761932.008318s

16 step training time: 0.131438s

on_train_batch_end: 1615761932.139532s

17408/50000 [=========>....................] - ETA: 4s - loss: 5.4124 - accuracy: 0.0692
on_train_batch_begin: 1615761932.139821s

17 step training time: 0.131503s

on_train_batch_end: 1615761932.274036s

18432/50000 [==========>...................] - ETA: 4s - loss: 5.4006 - accuracy: 0.0690
on_train_batch_begin: 1615761932.274359s

18 step training time: 0.134538s

on_train_batch_end: 1615761932.407147s

19456/50000 [==========>...................] - ETA: 3s - loss: 5.3843 - accuracy: 0.0692
on_train_batch_begin: 1615761932.407459s

19 step training time: 0.133101s

on_train_batch_end: 1615761932.538428s

20480/50000 [===========>..................] - ETA: 3s - loss: 5.3646 - accuracy: 0.0694
on_train_batch_begin: 1615761932.538719s

20 step training time: 0.131260s

on_train_batch_end: 1615761932.670518s

21504/50000 [===========>..................] - ETA: 3s - loss: 5.3491 - accuracy: 0.0695
on_train_batch_begin: 1615761932.670803s

21 step training time: 0.132083s

on_train_batch_end: 1615761932.803524s

22528/50000 [============>.................] - ETA: 3s - loss: 5.3456 - accuracy: 0.0692
on_train_batch_begin: 1615761932.803949s

22 step training time: 0.133146s

on_train_batch_end: 1615761932.935492s

23552/50000 [=============>................] - ETA: 3s - loss: 5.3382 - accuracy: 0.0689
on_train_batch_begin: 1615761932.935806s

23 step training time: 0.131856s

on_train_batch_end: 1615761933.068015s

24576/50000 [=============>................] - ETA: 3s - loss: 5.3328 - accuracy: 0.0687
on_train_batch_begin: 1615761933.068428s

24 step training time: 0.132623s

on_train_batch_end: 1615761933.200414s

25600/50000 [==============>...............] - ETA: 3s - loss: 5.3212 - accuracy: 0.0685
on_train_batch_begin: 1615761933.200702s

25 step training time: 0.132274s

on_train_batch_end: 1615761933.334217s

26624/50000 [==============>...............] - ETA: 3s - loss: 5.3089 - accuracy: 0.0684
on_train_batch_begin: 1615761933.334511s

26 step training time: 0.133809s

on_train_batch_end: 1615761933.465354s

27648/50000 [===============>..............] - ETA: 2s - loss: 5.2999 - accuracy: 0.0681
on_train_batch_begin: 1615761933.465675s

27 step training time: 0.131164s

on_train_batch_end: 1615761933.601066s

28672/50000 [================>.............] - ETA: 2s - loss: 5.2860 - accuracy: 0.0680
on_train_batch_begin: 1615761933.601367s

28 step training time: 0.135692s

on_train_batch_end: 1615761933.734626s

29696/50000 [================>.............] - ETA: 2s - loss: 5.2716 - accuracy: 0.0679
on_train_batch_begin: 1615761933.734921s

29 step training time: 0.133554s

on_train_batch_end: 1615761933.868204s

30720/50000 [=================>............] - ETA: 2s - loss: 5.2585 - accuracy: 0.0677
on_train_batch_begin: 1615761933.868492s

30 step training time: 0.133572s

on_train_batch_end: 1615761934.000416s

31744/50000 [==================>...........] - ETA: 2s - loss: 5.2462 - accuracy: 0.0676
on_train_batch_begin: 1615761934.000706s

31 step training time: 0.132213s

on_train_batch_end: 1615761934.134177s

32768/50000 [==================>...........] - ETA: 2s - loss: 5.2346 - accuracy: 0.0675
on_train_batch_begin: 1615761934.134468s

32 step training time: 0.133762s

on_train_batch_end: 1615761934.266175s

33792/50000 [===================>..........] - ETA: 2s - loss: 5.2247 - accuracy: 0.0674
on_train_batch_begin: 1615761934.266487s

33 step training time: 0.132019s

on_train_batch_end: 1615761934.398631s

34816/50000 [===================>..........] - ETA: 1s - loss: 5.2148 - accuracy: 0.0673
on_train_batch_begin: 1615761934.398919s

34 step training time: 0.132432s

on_train_batch_end: 1615761934.530469s

35840/50000 [====================>.........] - ETA: 1s - loss: 5.2109 - accuracy: 0.0671
on_train_batch_begin: 1615761934.530757s

35 step training time: 0.131838s

on_train_batch_end: 1615761934.662249s

36864/50000 [=====================>........] - ETA: 1s - loss: 5.1978 - accuracy: 0.0671
on_train_batch_begin: 1615761934.662550s

36 step training time: 0.131793s

on_train_batch_end: 1615761934.793193s

37888/50000 [=====================>........] - ETA: 1s - loss: 5.1819 - accuracy: 0.0671
on_train_batch_begin: 1615761934.793483s

37 step training time: 0.130932s

on_train_batch_end: 1615761934.925578s

38912/50000 [======================>.......] - ETA: 1s - loss: 5.1709 - accuracy: 0.0672
on_train_batch_begin: 1615761934.925859s

38 step training time: 0.132376s

on_train_batch_end: 1615761935.058125s

39936/50000 [======================>.......] - ETA: 1s - loss: 5.1634 - accuracy: 0.0673
on_train_batch_begin: 1615761935.058423s

39 step training time: 0.132564s

on_train_batch_end: 1615761935.189995s

40960/50000 [=======================>......] - ETA: 1s - loss: 5.1533 - accuracy: 0.0673
on_train_batch_begin: 1615761935.190283s

40 step training time: 0.131860s

on_train_batch_end: 1615761935.321217s

41984/50000 [========================>.....] - ETA: 1s - loss: 5.1332 - accuracy: 0.0674
on_train_batch_begin: 1615761935.321507s

41 step training time: 0.131223s

on_train_batch_end: 1615761935.452943s

43008/50000 [========================>.....] - ETA: 0s - loss: 5.1169 - accuracy: 0.0676
on_train_batch_begin: 1615761935.453243s

42 step training time: 0.131736s

on_train_batch_end: 1615761935.584702s

44032/50000 [=========================>....] - ETA: 0s - loss: 5.1033 - accuracy: 0.0676
on_train_batch_begin: 1615761935.584996s

43 step training time: 0.131754s

on_train_batch_end: 1615761935.717142s

45056/50000 [==========================>...] - ETA: 0s - loss: 5.0901 - accuracy: 0.0676
on_train_batch_begin: 1615761935.717434s

44 step training time: 0.132438s

on_train_batch_end: 1615761935.848500s

46080/50000 [==========================>...] - ETA: 0s - loss: 5.0767 - accuracy: 0.0677
on_train_batch_begin: 1615761935.848816s

45 step training time: 0.131382s

on_train_batch_end: 1615761935.981405s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.0679 - accuracy: 0.0678
on_train_batch_begin: 1615761935.981690s

46 step training time: 0.132874s

on_train_batch_end: 1615761936.114164s

48128/50000 [===========================>..] - ETA: 0s - loss: 5.0602 - accuracy: 0.0678
on_train_batch_begin: 1615761936.114456s

47 step training time: 0.132766s

on_train_batch_end: 1615761936.245635s

49152/50000 [============================>.] - ETA: 0s - loss: 5.0474 - accuracy: 0.0678
on_train_batch_begin: 1615761936.245932s

48 step training time: 0.131475s

on_train_batch_end: 1615761936.365474s

on_test_batch_begin: 1615761936.386249s

49 step training time: 0.140317s

on_epoch_end: 1615761936.689150s

Validation time: 0.302889s

Real time: 1615761936.689150s

Epoch time: 6.798332214355469s

50000/50000 [==============================] - 7s 136us/sample - loss: 5.0370 - accuracy: 0.0679 - val_loss: 7.0596 - val_accuracy: 0.0998

on_epoch_begin: 1615761936.689334s

Real time: 1615761936.6893392
Epoch 3/5

on_train_batch_begin: 1615761936.693598s

on_train_batch_end: 1615761936.824462s

 1024/50000 [..............................] - ETA: 6s - loss: 4.5269 - accuracy: 0.0690
on_train_batch_begin: 1615761936.824745s

1 step training time: 0.131147s

on_train_batch_end: 1615761936.957187s

 2048/50000 [>.............................] - ETA: 6s - loss: 4.4238 - accuracy: 0.0690
on_train_batch_begin: 1615761936.957473s

2 step training time: 0.132728s

on_train_batch_end: 1615761937.088625s

 3072/50000 [>.............................] - ETA: 6s - loss: 4.4291 - accuracy: 0.0694
on_train_batch_begin: 1615761937.088916s

3 step training time: 0.131444s

on_train_batch_end: 1615761937.221203s

 4096/50000 [=>............................] - ETA: 5s - loss: 4.3768 - accuracy: 0.0703
on_train_batch_begin: 1615761937.221488s

4 step training time: 0.132571s

on_train_batch_end: 1615761937.353173s

 5120/50000 [==>...........................] - ETA: 5s - loss: 4.3536 - accuracy: 0.0706
on_train_batch_begin: 1615761937.353469s

5 step training time: 0.131982s

on_train_batch_end: 1615761937.485871s

 6144/50000 [==>...........................] - ETA: 5s - loss: 4.3556 - accuracy: 0.0708
on_train_batch_begin: 1615761937.486179s

6 step training time: 0.132710s

on_train_batch_end: 1615761937.617543s

 7168/50000 [===>..........................] - ETA: 5s - loss: 4.3178 - accuracy: 0.0715
on_train_batch_begin: 1615761937.617828s

7 step training time: 0.131648s

on_train_batch_end: 1615761937.749516s

 8192/50000 [===>..........................] - ETA: 5s - loss: 4.2963 - accuracy: 0.0720
on_train_batch_begin: 1615761937.749802s

8 step training time: 0.131974s

on_train_batch_end: 1615761937.881643s

 9216/50000 [====>.........................] - ETA: 5s - loss: 4.2848 - accuracy: 0.0723
on_train_batch_begin: 1615761937.881932s

9 step training time: 0.132130s

on_train_batch_end: 1615761938.015501s

10240/50000 [=====>........................] - ETA: 5s - loss: 4.2678 - accuracy: 0.0730
on_train_batch_begin: 1615761938.015788s

10 step training time: 0.133856s

on_train_batch_end: 1615761938.146400s

11264/50000 [=====>........................] - ETA: 5s - loss: 4.2575 - accuracy: 0.0732
on_train_batch_begin: 1615761938.146686s

11 step training time: 0.130899s

on_train_batch_end: 1615761938.278574s

12288/50000 [======>.......................] - ETA: 4s - loss: 4.2371 - accuracy: 0.0736
on_train_batch_begin: 1615761938.278862s

12 step training time: 0.132176s

on_train_batch_end: 1615761938.409333s

13312/50000 [======>.......................] - ETA: 4s - loss: 4.2270 - accuracy: 0.0739
on_train_batch_begin: 1615761938.409615s

13 step training time: 0.130753s

on_train_batch_end: 1615761938.543118s

14336/50000 [=======>......................] - ETA: 4s - loss: 4.2242 - accuracy: 0.0740
on_train_batch_begin: 1615761938.543407s

14 step training time: 0.133792s

on_train_batch_end: 1615761938.674505s

15360/50000 [========>.....................] - ETA: 4s - loss: 4.2067 - accuracy: 0.0745
on_train_batch_begin: 1615761938.674791s

15 step training time: 0.131384s

on_train_batch_end: 1615761938.809591s

16384/50000 [========>.....................] - ETA: 4s - loss: 4.2082 - accuracy: 0.0746
on_train_batch_begin: 1615761938.809875s

16 step training time: 0.135084s

on_train_batch_end: 1615761938.940506s

17408/50000 [=========>....................] - ETA: 4s - loss: 4.1916 - accuracy: 0.0749
on_train_batch_begin: 1615761938.940793s

17 step training time: 0.130918s

on_train_batch_end: 1615761939.074262s

18432/50000 [==========>...................] - ETA: 4s - loss: 4.1802 - accuracy: 0.0752
on_train_batch_begin: 1615761939.074555s

18 step training time: 0.133763s

on_train_batch_end: 1615761939.206336s

19456/50000 [==========>...................] - ETA: 3s - loss: 4.1567 - accuracy: 0.0756
on_train_batch_begin: 1615761939.206625s

19 step training time: 0.132070s

on_train_batch_end: 1615761939.338331s

20480/50000 [===========>..................] - ETA: 3s - loss: 4.1401 - accuracy: 0.0759
on_train_batch_begin: 1615761939.338618s

20 step training time: 0.131993s

on_train_batch_end: 1615761939.470277s

21504/50000 [===========>..................] - ETA: 3s - loss: 4.1238 - accuracy: 0.0763
on_train_batch_begin: 1615761939.470562s

21 step training time: 0.131944s

on_train_batch_end: 1615761939.603647s

22528/50000 [============>.................] - ETA: 3s - loss: 4.1076 - accuracy: 0.0765
on_train_batch_begin: 1615761939.603935s

22 step training time: 0.133373s

on_train_batch_end: 1615761939.737063s

23552/50000 [=============>................] - ETA: 3s - loss: 4.0935 - accuracy: 0.0768
on_train_batch_begin: 1615761939.737361s

23 step training time: 0.133426s

on_train_batch_end: 1615761939.871368s

24576/50000 [=============>................] - ETA: 3s - loss: 4.0751 - accuracy: 0.0770
on_train_batch_begin: 1615761939.871655s

24 step training time: 0.134295s

on_train_batch_end: 1615761940.005403s

25600/50000 [==============>...............] - ETA: 3s - loss: 4.0614 - accuracy: 0.0773
on_train_batch_begin: 1615761940.005691s

25 step training time: 0.134035s

on_train_batch_end: 1615761940.136463s

26624/50000 [==============>...............] - ETA: 3s - loss: 4.0469 - accuracy: 0.0776
on_train_batch_begin: 1615761940.136747s

26 step training time: 0.131056s

on_train_batch_end: 1615761940.269449s

27648/50000 [===============>..............] - ETA: 2s - loss: 4.0209 - accuracy: 0.0781
on_train_batch_begin: 1615761940.269732s

27 step training time: 0.132985s

on_train_batch_end: 1615761940.401047s

28672/50000 [================>.............] - ETA: 2s - loss: 4.0028 - accuracy: 0.0783
on_train_batch_begin: 1615761940.401335s

28 step training time: 0.131603s

on_train_batch_end: 1615761940.534410s

29696/50000 [================>.............] - ETA: 2s - loss: 3.9816 - accuracy: 0.0788
on_train_batch_begin: 1615761940.534696s

29 step training time: 0.133361s

on_train_batch_end: 1615761940.666912s

30720/50000 [=================>............] - ETA: 2s - loss: 3.9632 - accuracy: 0.0791
on_train_batch_begin: 1615761940.667205s

30 step training time: 0.132509s

on_train_batch_end: 1615761940.799426s

31744/50000 [==================>...........] - ETA: 2s - loss: 3.9365 - accuracy: 0.0796
on_train_batch_begin: 1615761940.799716s

31 step training time: 0.132510s

on_train_batch_end: 1615761940.931321s

32768/50000 [==================>...........] - ETA: 2s - loss: 3.9120 - accuracy: 0.0800
on_train_batch_begin: 1615761940.931612s

32 step training time: 0.131897s

on_train_batch_end: 1615761941.062661s

33792/50000 [===================>..........] - ETA: 2s - loss: 3.8845 - accuracy: 0.0804
on_train_batch_begin: 1615761941.062948s

33 step training time: 0.131335s

on_train_batch_end: 1615761941.194333s

34816/50000 [===================>..........] - ETA: 1s - loss: 3.8619 - accuracy: 0.0808
on_train_batch_begin: 1615761941.194629s

34 step training time: 0.131682s

on_train_batch_end: 1615761941.326933s

35840/50000 [====================>.........] - ETA: 1s - loss: 3.8343 - accuracy: 0.0812
on_train_batch_begin: 1615761941.327220s

35 step training time: 0.132590s

on_train_batch_end: 1615761941.458261s

36864/50000 [=====================>........] - ETA: 1s - loss: 3.8106 - accuracy: 0.0815
on_train_batch_begin: 1615761941.458549s

36 step training time: 0.131330s

on_train_batch_end: 1615761941.591921s

37888/50000 [=====================>........] - ETA: 1s - loss: 3.7847 - accuracy: 0.0819
on_train_batch_begin: 1615761941.592209s

37 step training time: 0.133659s

on_train_batch_end: 1615761941.724541s

38912/50000 [======================>.......] - ETA: 1s - loss: 3.7556 - accuracy: 0.0823
on_train_batch_begin: 1615761941.724827s

38 step training time: 0.132618s

on_train_batch_end: 1615761941.856478s

39936/50000 [======================>.......] - ETA: 1s - loss: 3.7291 - accuracy: 0.0827
on_train_batch_begin: 1615761941.856760s

39 step training time: 0.131933s

on_train_batch_end: 1615761941.989049s

40960/50000 [=======================>......] - ETA: 1s - loss: 3.7007 - accuracy: 0.0831
on_train_batch_begin: 1615761941.989338s

40 step training time: 0.132579s

on_train_batch_end: 1615761942.122411s

41984/50000 [========================>.....] - ETA: 1s - loss: 3.6720 - accuracy: 0.0836
on_train_batch_begin: 1615761942.122709s

41 step training time: 0.133370s

on_train_batch_end: 1615761942.256180s

43008/50000 [========================>.....] - ETA: 0s - loss: 3.6448 - accuracy: 0.0839
on_train_batch_begin: 1615761942.256482s

42 step training time: 0.133773s

on_train_batch_end: 1615761942.387799s

44032/50000 [=========================>....] - ETA: 0s - loss: 3.6170 - accuracy: 0.0843
on_train_batch_begin: 1615761942.388096s

43 step training time: 0.131614s

on_train_batch_end: 1615761942.521294s

45056/50000 [==========================>...] - ETA: 0s - loss: 3.5961 - accuracy: 0.0847
on_train_batch_begin: 1615761942.521581s

44 step training time: 0.133485s

on_train_batch_end: 1615761942.653459s

46080/50000 [==========================>...] - ETA: 0s - loss: 3.5753 - accuracy: 0.0850
on_train_batch_begin: 1615761942.653775s

45 step training time: 0.132195s

on_train_batch_end: 1615761942.787966s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.5508 - accuracy: 0.0853
on_train_batch_begin: 1615761942.788258s

46 step training time: 0.134482s

on_train_batch_end: 1615761942.919567s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.5303 - accuracy: 0.0856
on_train_batch_begin: 1615761942.919855s

47 step training time: 0.131598s

on_train_batch_end: 1615761943.052892s

49152/50000 [============================>.] - ETA: 0s - loss: 3.5075 - accuracy: 0.0859
on_train_batch_begin: 1615761943.053180s

48 step training time: 0.133325s

on_train_batch_end: 1615761943.172950s

on_test_batch_begin: 1615761943.193663s

49 step training time: 0.140482s

on_epoch_end: 1615761943.502801s

Validation time: 0.309126s

Real time: 1615761943.502801s

Epoch time: 6.8134777545928955s

50000/50000 [==============================] - 7s 136us/sample - loss: 3.4864 - accuracy: 0.0861 - val_loss: 7.2357 - val_accuracy: 0.1001

on_epoch_begin: 1615761943.502982s

Real time: 1615761943.5029883
Epoch 4/5

on_train_batch_begin: 1615761943.507380s

on_train_batch_end: 1615761943.640294s

 1024/50000 [..............................] - ETA: 6s - loss: 2.1726 - accuracy: 0.1012
on_train_batch_begin: 1615761943.640579s

1 step training time: 0.133199s

on_train_batch_end: 1615761943.773391s

 2048/50000 [>.............................] - ETA: 6s - loss: 2.3252 - accuracy: 0.1010
on_train_batch_begin: 1615761943.773690s

2 step training time: 0.133111s

on_train_batch_end: 1615761943.908316s

 3072/50000 [>.............................] - ETA: 6s - loss: 2.3217 - accuracy: 0.1009
on_train_batch_begin: 1615761943.908598s

3 step training time: 0.134908s

on_train_batch_end: 1615761944.042284s

 4096/50000 [=>............................] - ETA: 6s - loss: 2.3536 - accuracy: 0.1005
on_train_batch_begin: 1615761944.042573s

4 step training time: 0.133975s

on_train_batch_end: 1615761944.174160s

 5120/50000 [==>...........................] - ETA: 5s - loss: 2.3501 - accuracy: 0.1011
on_train_batch_begin: 1615761944.174448s

5 step training time: 0.131875s

on_train_batch_end: 1615761944.308110s

 6144/50000 [==>...........................] - ETA: 5s - loss: 2.4066 - accuracy: 0.1006
on_train_batch_begin: 1615761944.308395s

6 step training time: 0.133947s

on_train_batch_end: 1615761944.441352s

 7168/50000 [===>..........................] - ETA: 5s - loss: 2.3817 - accuracy: 0.1008
on_train_batch_begin: 1615761944.441638s

7 step training time: 0.133243s

on_train_batch_end: 1615761944.574523s

 8192/50000 [===>..........................] - ETA: 5s - loss: 2.3640 - accuracy: 0.1010
on_train_batch_begin: 1615761944.574814s

8 step training time: 0.133176s

on_train_batch_end: 1615761944.709280s

 9216/50000 [====>.........................] - ETA: 5s - loss: 2.3359 - accuracy: 0.1009
on_train_batch_begin: 1615761944.709565s

9 step training time: 0.134751s

on_train_batch_end: 1615761944.841313s

10240/50000 [=====>........................] - ETA: 5s - loss: 2.3230 - accuracy: 0.1007
on_train_batch_begin: 1615761944.841597s

10 step training time: 0.132032s

on_train_batch_end: 1615761944.977179s

11264/50000 [=====>........................] - ETA: 5s - loss: 2.3039 - accuracy: 0.1008
on_train_batch_begin: 1615761944.977466s

11 step training time: 0.135869s

on_train_batch_end: 1615761945.109284s

12288/50000 [======>.......................] - ETA: 4s - loss: 2.2901 - accuracy: 0.1007
on_train_batch_begin: 1615761945.109569s

12 step training time: 0.132103s

on_train_batch_end: 1615761945.242263s

13312/50000 [======>.......................] - ETA: 4s - loss: 2.2882 - accuracy: 0.1007
on_train_batch_begin: 1615761945.242552s

13 step training time: 0.132983s

on_train_batch_end: 1615761945.373412s

14336/50000 [=======>......................] - ETA: 4s - loss: 2.2693 - accuracy: 0.1008
on_train_batch_begin: 1615761945.373706s

14 step training time: 0.131154s

on_train_batch_end: 1615761945.506539s

15360/50000 [========>.....................] - ETA: 4s - loss: 2.2703 - accuracy: 0.1008
on_train_batch_begin: 1615761945.506825s

15 step training time: 0.133119s

on_train_batch_end: 1615761945.639398s

16384/50000 [========>.....................] - ETA: 4s - loss: 2.2719 - accuracy: 0.1008
on_train_batch_begin: 1615761945.639688s

16 step training time: 0.132863s

on_train_batch_end: 1615761945.772392s

17408/50000 [=========>....................] - ETA: 4s - loss: 2.2753 - accuracy: 0.1007
on_train_batch_begin: 1615761945.772682s

17 step training time: 0.132995s

on_train_batch_end: 1615761945.906406s

18432/50000 [==========>...................] - ETA: 4s - loss: 2.2706 - accuracy: 0.1007
on_train_batch_begin: 1615761945.906693s

18 step training time: 0.134011s

on_train_batch_end: 1615761946.038543s

19456/50000 [==========>...................] - ETA: 3s - loss: 2.2631 - accuracy: 0.1007
on_train_batch_begin: 1615761946.038836s

19 step training time: 0.132143s

on_train_batch_end: 1615761946.173172s

20480/50000 [===========>..................] - ETA: 3s - loss: 2.2639 - accuracy: 0.1007
on_train_batch_begin: 1615761946.173471s

20 step training time: 0.134635s

on_train_batch_end: 1615761946.306206s

21504/50000 [===========>..................] - ETA: 3s - loss: 2.2640 - accuracy: 0.1007
on_train_batch_begin: 1615761946.306508s

21 step training time: 0.133037s

on_train_batch_end: 1615761946.438680s

22528/50000 [============>.................] - ETA: 3s - loss: 2.2664 - accuracy: 0.1006
on_train_batch_begin: 1615761946.438968s

22 step training time: 0.132460s

on_train_batch_end: 1615761946.570529s

23552/50000 [=============>................] - ETA: 3s - loss: 2.2646 - accuracy: 0.1006
on_train_batch_begin: 1615761946.570835s

23 step training time: 0.131867s

on_train_batch_end: 1615761946.702690s

24576/50000 [=============>................] - ETA: 3s - loss: 2.2592 - accuracy: 0.1006
on_train_batch_begin: 1615761946.702979s

24 step training time: 0.132144s

on_train_batch_end: 1615761946.835101s

25600/50000 [==============>...............] - ETA: 3s - loss: 2.2549 - accuracy: 0.1006
on_train_batch_begin: 1615761946.835427s

25 step training time: 0.132448s

on_train_batch_end: 1615761946.967434s

26624/50000 [==============>...............] - ETA: 3s - loss: 2.2540 - accuracy: 0.1006
on_train_batch_begin: 1615761946.967722s

26 step training time: 0.132295s

on_train_batch_end: 1615761947.100127s

27648/50000 [===============>..............] - ETA: 2s - loss: 2.2445 - accuracy: 0.1006
on_train_batch_begin: 1615761947.100416s

27 step training time: 0.132695s

on_train_batch_end: 1615761947.234233s

28672/50000 [================>.............] - ETA: 2s - loss: 2.2433 - accuracy: 0.1006
on_train_batch_begin: 1615761947.234526s

28 step training time: 0.134109s

on_train_batch_end: 1615761947.368340s

29696/50000 [================>.............] - ETA: 2s - loss: 2.2418 - accuracy: 0.1006
on_train_batch_begin: 1615761947.368630s

29 step training time: 0.134104s

on_train_batch_end: 1615761947.500322s

30720/50000 [=================>............] - ETA: 2s - loss: 2.2377 - accuracy: 0.1005
on_train_batch_begin: 1615761947.500610s

30 step training time: 0.131980s

on_train_batch_end: 1615761947.634445s

31744/50000 [==================>...........] - ETA: 2s - loss: 2.2364 - accuracy: 0.1006
on_train_batch_begin: 1615761947.634740s

31 step training time: 0.134130s

on_train_batch_end: 1615761947.769233s

32768/50000 [==================>...........] - ETA: 2s - loss: 2.2351 - accuracy: 0.1006
on_train_batch_begin: 1615761947.769521s

32 step training time: 0.134780s

on_train_batch_end: 1615761947.901515s

33792/50000 [===================>..........] - ETA: 2s - loss: 2.2351 - accuracy: 0.1006
on_train_batch_begin: 1615761947.901806s

33 step training time: 0.132285s

on_train_batch_end: 1615761948.040208s

34816/50000 [===================>..........] - ETA: 1s - loss: 2.2314 - accuracy: 0.1006
on_train_batch_begin: 1615761948.040500s

34 step training time: 0.138694s

on_train_batch_end: 1615761948.173165s

35840/50000 [====================>.........] - ETA: 1s - loss: 2.2317 - accuracy: 0.1005
on_train_batch_begin: 1615761948.173478s

35 step training time: 0.132978s

on_train_batch_end: 1615761948.306180s

36864/50000 [=====================>........] - ETA: 1s - loss: 2.2226 - accuracy: 0.1006
on_train_batch_begin: 1615761948.306469s

36 step training time: 0.132991s

on_train_batch_end: 1615761948.439335s

37888/50000 [=====================>........] - ETA: 1s - loss: 2.2204 - accuracy: 0.1006
on_train_batch_begin: 1615761948.439621s

37 step training time: 0.133152s

on_train_batch_end: 1615761948.574080s

38912/50000 [======================>.......] - ETA: 1s - loss: 2.2150 - accuracy: 0.1006
on_train_batch_begin: 1615761948.574374s

38 step training time: 0.134753s

on_train_batch_end: 1615761948.707581s

39936/50000 [======================>.......] - ETA: 1s - loss: 2.2070 - accuracy: 0.1006
on_train_batch_begin: 1615761948.707865s

39 step training time: 0.133491s

on_train_batch_end: 1615761948.838075s

40960/50000 [=======================>......] - ETA: 1s - loss: 2.1963 - accuracy: 0.1007
on_train_batch_begin: 1615761948.838366s

40 step training time: 0.130501s

on_train_batch_end: 1615761948.973569s

41984/50000 [========================>.....] - ETA: 1s - loss: 2.1910 - accuracy: 0.1006
on_train_batch_begin: 1615761948.973855s

41 step training time: 0.135489s

on_train_batch_end: 1615761949.106009s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.1857 - accuracy: 0.1006
on_train_batch_begin: 1615761949.106294s

42 step training time: 0.132439s

on_train_batch_end: 1615761949.238508s

44032/50000 [=========================>....] - ETA: 0s - loss: 2.1801 - accuracy: 0.1006
on_train_batch_begin: 1615761949.238793s

43 step training time: 0.132499s

on_train_batch_end: 1615761949.371065s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.1680 - accuracy: 0.1007
on_train_batch_begin: 1615761949.371351s

44 step training time: 0.132557s

on_train_batch_end: 1615761949.503417s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.1606 - accuracy: 0.1006
on_train_batch_begin: 1615761949.503705s

45 step training time: 0.132354s

on_train_batch_end: 1615761949.636096s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.1543 - accuracy: 0.1007
on_train_batch_begin: 1615761949.636397s

46 step training time: 0.132692s

on_train_batch_end: 1615761949.770066s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.1490 - accuracy: 0.1007
on_train_batch_begin: 1615761949.770354s

47 step training time: 0.133957s

on_train_batch_end: 1615761949.903989s

49152/50000 [============================>.] - ETA: 0s - loss: 2.1395 - accuracy: 0.1007
on_train_batch_begin: 1615761949.904309s

48 step training time: 0.133955s

on_train_batch_end: 1615761950.024335s

on_test_batch_begin: 1615761950.042441s

49 step training time: 0.138133s

on_epoch_end: 1615761950.351975s

Validation time: 0.309522s

Real time: 1615761950.351975s

Epoch time: 6.849002838134766s

50000/50000 [==============================] - 7s 137us/sample - loss: 2.1327 - accuracy: 0.1007 - val_loss: 6.9222 - val_accuracy: 0.0999

on_epoch_begin: 1615761950.352155s

Real time: 1615761950.3521597
Epoch 5/5

on_train_batch_begin: 1615761950.356511s

on_train_batch_end: 1615761950.492285s

 1024/50000 [..............................] - ETA: 6s - loss: 1.8448 - accuracy: 0.1008
on_train_batch_begin: 1615761950.492551s

1 step training time: 0.136040s

on_train_batch_end: 1615761950.623848s

 2048/50000 [>.............................] - ETA: 6s - loss: 1.6531 - accuracy: 0.1007
on_train_batch_begin: 1615761950.624161s

2 step training time: 0.131611s

on_train_batch_end: 1615761950.759280s

 3072/50000 [>.............................] - ETA: 6s - loss: 1.6949 - accuracy: 0.1006
on_train_batch_begin: 1615761950.759562s

3 step training time: 0.135400s

on_train_batch_end: 1615761950.892008s

 4096/50000 [=>............................] - ETA: 6s - loss: 1.6429 - accuracy: 0.1008
on_train_batch_begin: 1615761950.892316s

4 step training time: 0.132755s

on_train_batch_end: 1615761951.024269s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.5981 - accuracy: 0.1007
on_train_batch_begin: 1615761951.024558s

5 step training time: 0.132242s

on_train_batch_end: 1615761951.158039s

 6144/50000 [==>...........................] - ETA: 5s - loss: 1.5722 - accuracy: 0.1008
on_train_batch_begin: 1615761951.158325s

6 step training time: 0.133767s

on_train_batch_end: 1615761951.290212s

 7168/50000 [===>..........................] - ETA: 5s - loss: 1.5503 - accuracy: 0.1008
on_train_batch_begin: 1615761951.290493s

7 step training time: 0.132168s

on_train_batch_end: 1615761951.425696s

 8192/50000 [===>..........................] - ETA: 5s - loss: 1.5300 - accuracy: 0.1010
on_train_batch_begin: 1615761951.426007s

8 step training time: 0.135514s

on_train_batch_end: 1615761951.556695s

 9216/50000 [====>.........................] - ETA: 5s - loss: 1.5177 - accuracy: 0.1011
on_train_batch_begin: 1615761951.556979s

9 step training time: 0.130972s

on_train_batch_end: 1615761951.692048s

10240/50000 [=====>........................] - ETA: 5s - loss: 1.5063 - accuracy: 0.1011
on_train_batch_begin: 1615761951.692338s

10 step training time: 0.135359s

on_train_batch_end: 1615761951.825937s

11264/50000 [=====>........................] - ETA: 5s - loss: 1.4792 - accuracy: 0.1011
on_train_batch_begin: 1615761951.826241s

11 step training time: 0.133903s

on_train_batch_end: 1615761951.959439s

12288/50000 [======>.......................] - ETA: 4s - loss: 1.4581 - accuracy: 0.1011
on_train_batch_begin: 1615761951.959759s

12 step training time: 0.133518s

on_train_batch_end: 1615761952.093650s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.4571 - accuracy: 0.1011
on_train_batch_begin: 1615761952.093938s

13 step training time: 0.134179s

on_train_batch_end: 1615761952.224856s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.4471 - accuracy: 0.1010
on_train_batch_begin: 1615761952.225151s

14 step training time: 0.131213s

on_train_batch_end: 1615761952.359628s

15360/50000 [========>.....................] - ETA: 4s - loss: 1.4408 - accuracy: 0.1011
on_train_batch_begin: 1615761952.359919s

15 step training time: 0.134768s

on_train_batch_end: 1615761952.492233s

16384/50000 [========>.....................] - ETA: 4s - loss: 1.4377 - accuracy: 0.1011
on_train_batch_begin: 1615761952.492519s

16 step training time: 0.132601s

on_train_batch_end: 1615761952.625800s

17408/50000 [=========>....................] - ETA: 4s - loss: 1.4427 - accuracy: 0.1011
on_train_batch_begin: 1615761952.626138s

17 step training time: 0.133619s

on_train_batch_end: 1615761952.758169s

18432/50000 [==========>...................] - ETA: 4s - loss: 1.4595 - accuracy: 0.1011
on_train_batch_begin: 1615761952.758458s

18 step training time: 0.132319s

on_train_batch_end: 1615761952.891012s

19456/50000 [==========>...................] - ETA: 3s - loss: 1.4640 - accuracy: 0.1011
on_train_batch_begin: 1615761952.891300s

19 step training time: 0.132843s

on_train_batch_end: 1615761953.025365s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.4606 - accuracy: 0.1011
on_train_batch_begin: 1615761953.025648s

20 step training time: 0.134348s

on_train_batch_end: 1615761953.157251s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.4645 - accuracy: 0.1010
on_train_batch_begin: 1615761953.157536s

21 step training time: 0.131888s

on_train_batch_end: 1615761953.292614s

22528/50000 [============>.................] - ETA: 3s - loss: 1.4617 - accuracy: 0.1011
on_train_batch_begin: 1615761953.292900s

22 step training time: 0.135364s

on_train_batch_end: 1615761953.425932s

23552/50000 [=============>................] - ETA: 3s - loss: 1.4593 - accuracy: 0.1011
on_train_batch_begin: 1615761953.426242s

23 step training time: 0.133342s

on_train_batch_end: 1615761953.558217s

24576/50000 [=============>................] - ETA: 3s - loss: 1.4574 - accuracy: 0.1011
on_train_batch_begin: 1615761953.558503s

24 step training time: 0.132261s

on_train_batch_end: 1615761953.690528s

25600/50000 [==============>...............] - ETA: 3s - loss: 1.4520 - accuracy: 0.1011
on_train_batch_begin: 1615761953.690815s

25 step training time: 0.132312s

on_train_batch_end: 1615761953.823608s

26624/50000 [==============>...............] - ETA: 3s - loss: 1.4500 - accuracy: 0.1011
on_train_batch_begin: 1615761953.823894s

26 step training time: 0.133079s

on_train_batch_end: 1615761953.957172s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.4503 - accuracy: 0.1011
on_train_batch_begin: 1615761953.957458s

27 step training time: 0.133564s

on_train_batch_end: 1615761954.090034s

28672/50000 [================>.............] - ETA: 2s - loss: 1.4421 - accuracy: 0.1011
on_train_batch_begin: 1615761954.090321s

28 step training time: 0.132864s

on_train_batch_end: 1615761954.224480s

29696/50000 [================>.............] - ETA: 2s - loss: 1.4408 - accuracy: 0.1011
on_train_batch_begin: 1615761954.224767s

29 step training time: 0.134445s

on_train_batch_end: 1615761954.358080s

30720/50000 [=================>............] - ETA: 2s - loss: 1.4417 - accuracy: 0.1011
on_train_batch_begin: 1615761954.358365s

30 step training time: 0.133598s

on_train_batch_end: 1615761954.491870s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.4442 - accuracy: 0.1011
on_train_batch_begin: 1615761954.492166s

31 step training time: 0.133801s

on_train_batch_end: 1615761954.624196s

32768/50000 [==================>...........] - ETA: 2s - loss: 1.4382 - accuracy: 0.1011
on_train_batch_begin: 1615761954.624487s

32 step training time: 0.132322s

on_train_batch_end: 1615761954.757308s

33792/50000 [===================>..........] - ETA: 2s - loss: 1.4328 - accuracy: 0.1011
on_train_batch_begin: 1615761954.757593s

33 step training time: 0.133105s

on_train_batch_end: 1615761954.890675s

34816/50000 [===================>..........] - ETA: 1s - loss: 1.4308 - accuracy: 0.1011
on_train_batch_begin: 1615761954.890960s

34 step training time: 0.133367s

on_train_batch_end: 1615761955.023317s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.4305 - accuracy: 0.1011
on_train_batch_begin: 1615761955.023600s

35 step training time: 0.132640s

on_train_batch_end: 1615761955.158136s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.4267 - accuracy: 0.1011
on_train_batch_begin: 1615761955.158419s

36 step training time: 0.134819s

on_train_batch_end: 1615761955.290876s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.4159 - accuracy: 0.1011
on_train_batch_begin: 1615761955.291164s

37 step training time: 0.132745s

on_train_batch_end: 1615761955.424301s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.4112 - accuracy: 0.1012
on_train_batch_begin: 1615761955.424587s

38 step training time: 0.133423s

on_train_batch_end: 1615761955.556610s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.4100 - accuracy: 0.1012
on_train_batch_begin: 1615761955.556892s

39 step training time: 0.132305s

on_train_batch_end: 1615761955.688698s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.4045 - accuracy: 0.1012
on_train_batch_begin: 1615761955.688984s

40 step training time: 0.132092s

on_train_batch_end: 1615761955.822634s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.4013 - accuracy: 0.1012
on_train_batch_begin: 1615761955.822948s

41 step training time: 0.133964s

on_train_batch_end: 1615761955.955271s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.3956 - accuracy: 0.1012
on_train_batch_begin: 1615761955.955558s

42 step training time: 0.132611s

on_train_batch_end: 1615761956.090334s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.3893 - accuracy: 0.1012
on_train_batch_begin: 1615761956.090619s

43 step training time: 0.135060s

on_train_batch_end: 1615761956.223248s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.3831 - accuracy: 0.1012
on_train_batch_begin: 1615761956.223532s

44 step training time: 0.132914s

on_train_batch_end: 1615761956.357102s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.3807 - accuracy: 0.1012
on_train_batch_begin: 1615761956.357390s

45 step training time: 0.133858s

on_train_batch_end: 1615761956.489089s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.3734 - accuracy: 0.1012
on_train_batch_begin: 1615761956.489372s

46 step training time: 0.131982s

on_train_batch_end: 1615761956.622269s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.3652 - accuracy: 0.1012
on_train_batch_begin: 1615761956.622554s

47 step training time: 0.133181s

on_train_batch_end: 1615761956.754178s

49152/50000 [============================>.] - ETA: 0s - loss: 1.3602 - accuracy: 0.1012
on_train_batch_begin: 1615761956.754468s

48 step training time: 0.131914s

on_train_batch_end: 1615761956.876323s

on_test_batch_begin: 1615761956.897069s

49 step training time: 0.142601s

on_epoch_end: 1615761957.209174s

Validation time: 0.312093s

Real time: 1615761957.209174s

Epoch time: 6.857031345367432s

50000/50000 [==============================] - 7s 137us/sample - loss: 1.3583 - accuracy: 0.1012 - val_loss: 6.7593 - val_accuracy: 0.0999
Tempo do fit: 94.49788212776184