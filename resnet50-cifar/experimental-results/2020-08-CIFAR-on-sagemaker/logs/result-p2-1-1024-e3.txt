wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:21
   221184/170498071 [..............................] - ETA: 1:08
  1499136/170498071 [..............................] - ETA: 15s 
  4489216/170498071 [..............................] - ETA: 6s 
  8069120/170498071 [>.............................] - ETA: 4s
 11476992/170498071 [=>............................] - ETA: 4s
 15056896/170498071 [=>............................] - ETA: 3s
 18391040/170498071 [==>...........................] - ETA: 3s
 22159360/170498071 [==>...........................] - ETA: 3s
 25436160/170498071 [===>..........................] - ETA: 2s
 29024256/170498071 [====>.........................] - ETA: 2s
 32587776/170498071 [====>.........................] - ETA: 2s
 36151296/170498071 [=====>........................] - ETA: 2s
 39362560/170498071 [=====>........................] - ETA: 2s
 42696704/170498071 [======>.......................] - ETA: 2s
 46260224/170498071 [=======>......................] - ETA: 2s
 49848320/170498071 [=======>......................] - ETA: 2s
 53370880/170498071 [========>.....................] - ETA: 1s
 56614912/170498071 [========>.....................] - ETA: 1s
 60030976/170498071 [=========>....................] - ETA: 1s
 63602688/170498071 [==========>...................] - ETA: 1s
 67149824/170498071 [==========>...................] - ETA: 1s
 70606848/170498071 [===========>..................] - ETA: 1s
 73867264/170498071 [===========>..................] - ETA: 1s
 77234176/170498071 [============>.................] - ETA: 1s
 80936960/170498071 [=============>................] - ETA: 1s
 84500480/170498071 [=============>................] - ETA: 1s
 87842816/170498071 [==============>...............] - ETA: 1s
 91144192/170498071 [===============>..............] - ETA: 1s
 94642176/170498071 [===============>..............] - ETA: 1s
 98181120/170498071 [================>.............] - ETA: 1s
101670912/170498071 [================>.............] - ETA: 1s
105054208/170498071 [=================>............] - ETA: 1s
108273664/170498071 [==================>...........] - ETA: 0s
111730688/170498071 [==================>...........] - ETA: 0s
115286016/170498071 [===================>..........] - ETA: 0s
118784000/170498071 [===================>..........] - ETA: 0s
122265600/170498071 [====================>.........] - ETA: 0s
125526016/170498071 [=====================>........] - ETA: 0s
128966656/170498071 [=====================>........] - ETA: 0s
132530176/170498071 [======================>.......] - ETA: 0s
136003584/170498071 [======================>.......] - ETA: 0s
139452416/170498071 [=======================>......] - ETA: 0s
142696448/170498071 [========================>.....] - ETA: 0s
146145280/170498071 [========================>.....] - ETA: 0s
149676032/170498071 [=========================>....] - ETA: 0s
153182208/170498071 [=========================>....] - ETA: 0s
156688384/170498071 [==========================>...] - ETA: 0s
159948800/170498071 [===========================>..] - ETA: 0s
163422208/170498071 [===========================>..] - ETA: 0s
166920192/170498071 [============================>.] - ETA: 0s
170426368/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 5s
 5201920/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 0s
16056320/94765736 [====>.........................] - ETA: 0s
22437888/94765736 [======>.......................] - ETA: 0s
29138944/94765736 [========>.....................] - ETA: 0s
35831808/94765736 [==========>...................] - ETA: 0s
40402944/94765736 [===========>..................] - ETA: 0s
46514176/94765736 [=============>................] - ETA: 0s
50094080/94765736 [==============>...............] - ETA: 0s
56360960/94765736 [================>.............] - ETA: 0s
61620224/94765736 [==================>...........] - ETA: 0s
66617344/94765736 [====================>.........] - ETA: 0s
71548928/94765736 [=====================>........] - ETA: 0s
76611584/94765736 [=======================>......] - ETA: 0s
81641472/94765736 [========================>.....] - ETA: 0s
86622208/94765736 [==========================>...] - ETA: 0s
91643904/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 16.118818759918213
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1607713118.014482s

Real time: 1607713118.0145063
Epoch 1/5

on_train_batch_begin: 1607713118.889941s

on_train_batch_end: 1607713143.321931s

 1024/50000 [..............................] - ETA: 20:10 - loss: 17.9938 - accuracy: 4.8447e-04
on_train_batch_begin: 1607713143.322752s

1 step training time: 24.432812s

on_train_batch_end: 1607713144.108793s

 2048/50000 [>.............................] - ETA: 10:10 - loss: 15.6936 - accuracy: 5.3930e-04
on_train_batch_begin: 1607713144.109257s

2 step training time: 0.786505s

on_train_batch_end: 1607713144.954445s

 3072/50000 [>.............................] - ETA: 6:51 - loss: 13.5059 - accuracy: 6.2180e-04 
on_train_batch_begin: 1607713144.954874s

3 step training time: 0.845617s

on_train_batch_end: 1607713145.697283s

 4096/50000 [=>............................] - ETA: 5:10 - loss: 12.2393 - accuracy: 8.3971e-04
on_train_batch_begin: 1607713145.697751s

4 step training time: 0.742877s

on_train_batch_end: 1607713146.464858s

 5120/50000 [==>...........................] - ETA: 4:09 - loss: 11.4378 - accuracy: 0.0022    
on_train_batch_begin: 1607713146.465271s

5 step training time: 0.767519s

on_train_batch_end: 1607713147.275410s

 6144/50000 [==>...........................] - ETA: 3:28 - loss: 10.8793 - accuracy: 0.0060
on_train_batch_begin: 1607713147.275837s

6 step training time: 0.810566s

on_train_batch_end: 1607713148.087567s

 7168/50000 [===>..........................] - ETA: 2:59 - loss: 10.4398 - accuracy: 0.0101
on_train_batch_begin: 1607713148.087993s

7 step training time: 0.812156s

on_train_batch_end: 1607713148.844474s

 8192/50000 [===>..........................] - ETA: 2:37 - loss: 10.1175 - accuracy: 0.0162
on_train_batch_begin: 1607713148.844896s

8 step training time: 0.756904s

on_train_batch_end: 1607713149.608613s

 9216/50000 [====>.........................] - ETA: 2:19 - loss: 9.8435 - accuracy: 0.0215 
on_train_batch_begin: 1607713149.609029s

9 step training time: 0.764132s

on_train_batch_end: 1607713150.380385s

10240/50000 [=====>........................] - ETA: 2:05 - loss: 9.6233 - accuracy: 0.0261
on_train_batch_begin: 1607713150.380798s

10 step training time: 0.771770s

on_train_batch_end: 1607713151.216263s

11264/50000 [=====>........................] - ETA: 1:54 - loss: 9.4429 - accuracy: 0.0303
on_train_batch_begin: 1607713151.216678s

11 step training time: 0.835880s

on_train_batch_end: 1607713151.958132s

12288/50000 [======>.......................] - ETA: 1:44 - loss: 9.3022 - accuracy: 0.0331
on_train_batch_begin: 1607713151.958609s

12 step training time: 0.741931s

on_train_batch_end: 1607713152.727185s

13312/50000 [======>.......................] - ETA: 1:35 - loss: 9.1694 - accuracy: 0.0351
on_train_batch_begin: 1607713152.727617s

13 step training time: 0.769008s

on_train_batch_end: 1607713153.493504s

14336/50000 [=======>......................] - ETA: 1:28 - loss: 9.0578 - accuracy: 0.0382
on_train_batch_begin: 1607713153.494165s

14 step training time: 0.766548s

on_train_batch_end: 1607713154.290535s

15360/50000 [========>.....................] - ETA: 1:21 - loss: 8.9580 - accuracy: 0.0402
on_train_batch_begin: 1607713154.290959s

15 step training time: 0.796794s

on_train_batch_end: 1607713155.059877s

16384/50000 [========>.....................] - ETA: 1:16 - loss: 8.8699 - accuracy: 0.0427
on_train_batch_begin: 1607713155.060288s

16 step training time: 0.769329s

on_train_batch_end: 1607713155.813713s

17408/50000 [=========>....................] - ETA: 1:10 - loss: 8.7823 - accuracy: 0.0445
on_train_batch_begin: 1607713155.814165s

17 step training time: 0.753876s

on_train_batch_end: 1607713156.590326s

18432/50000 [==========>...................] - ETA: 1:06 - loss: 8.7165 - accuracy: 0.0461
on_train_batch_begin: 1607713156.590800s

18 step training time: 0.776635s

on_train_batch_end: 1607713157.409785s

19456/50000 [==========>...................] - ETA: 1:01 - loss: 8.6502 - accuracy: 0.0477
on_train_batch_begin: 1607713157.410253s

19 step training time: 0.819453s

on_train_batch_end: 1607713158.158138s

20480/50000 [===========>..................] - ETA: 57s - loss: 8.5802 - accuracy: 0.0496 
on_train_batch_begin: 1607713158.158610s

20 step training time: 0.748358s

on_train_batch_end: 1607713158.950272s

21504/50000 [===========>..................] - ETA: 54s - loss: 8.5232 - accuracy: 0.0513
on_train_batch_begin: 1607713158.950774s

21 step training time: 0.792163s

on_train_batch_end: 1607713159.716641s

22528/50000 [============>.................] - ETA: 50s - loss: 8.4669 - accuracy: 0.0523
on_train_batch_begin: 1607713159.717087s

22 step training time: 0.766313s

on_train_batch_end: 1607713160.576402s

23552/50000 [=============>................] - ETA: 47s - loss: 8.4152 - accuracy: 0.0538
on_train_batch_begin: 1607713160.576827s

23 step training time: 0.859740s

on_train_batch_end: 1607713161.372951s

24576/50000 [=============>................] - ETA: 44s - loss: 8.3639 - accuracy: 0.0556
on_train_batch_begin: 1607713161.373426s

24 step training time: 0.796599s

on_train_batch_end: 1607713162.132679s

25600/50000 [==============>...............] - ETA: 42s - loss: 8.3194 - accuracy: 0.0573
on_train_batch_begin: 1607713162.133130s

25 step training time: 0.759704s

on_train_batch_end: 1607713162.906976s

26624/50000 [==============>...............] - ETA: 39s - loss: 8.2709 - accuracy: 0.0585
on_train_batch_begin: 1607713162.907430s

26 step training time: 0.774300s

on_train_batch_end: 1607713163.726663s

27648/50000 [===============>..............] - ETA: 36s - loss: 8.2269 - accuracy: 0.0594
on_train_batch_begin: 1607713163.727091s

27 step training time: 0.819661s

on_train_batch_end: 1607713164.474478s

28672/50000 [================>.............] - ETA: 34s - loss: 8.1897 - accuracy: 0.0603
on_train_batch_begin: 1607713164.474885s

28 step training time: 0.747794s

on_train_batch_end: 1607713165.268821s

29696/50000 [================>.............] - ETA: 32s - loss: 8.1488 - accuracy: 0.0608
on_train_batch_begin: 1607713165.269250s

29 step training time: 0.794364s

on_train_batch_end: 1607713166.021799s

30720/50000 [=================>............] - ETA: 30s - loss: 8.1096 - accuracy: 0.0615
on_train_batch_begin: 1607713166.022221s

30 step training time: 0.752971s

on_train_batch_end: 1607713166.858806s

31744/50000 [==================>...........] - ETA: 28s - loss: 8.0696 - accuracy: 0.0621
on_train_batch_begin: 1607713166.859221s

31 step training time: 0.837000s

on_train_batch_end: 1607713167.607894s

32768/50000 [==================>...........] - ETA: 26s - loss: 8.0327 - accuracy: 0.0625
on_train_batch_begin: 1607713167.608460s

32 step training time: 0.749239s

on_train_batch_end: 1607713168.378471s

33792/50000 [===================>..........] - ETA: 24s - loss: 7.9951 - accuracy: 0.0630
on_train_batch_begin: 1607713168.378898s

33 step training time: 0.770438s

on_train_batch_end: 1607713169.193193s

34816/50000 [===================>..........] - ETA: 22s - loss: 7.9541 - accuracy: 0.0638
on_train_batch_begin: 1607713169.193621s

34 step training time: 0.814724s

on_train_batch_end: 1607713169.980940s

35840/50000 [====================>.........] - ETA: 20s - loss: 7.9170 - accuracy: 0.0641
on_train_batch_begin: 1607713169.981368s

35 step training time: 0.787746s

on_train_batch_end: 1607713170.734648s

36864/50000 [=====================>........] - ETA: 18s - loss: 7.8787 - accuracy: 0.0646
on_train_batch_begin: 1607713170.735057s

36 step training time: 0.753690s

on_train_batch_end: 1607713171.497616s

37888/50000 [=====================>........] - ETA: 17s - loss: 7.8462 - accuracy: 0.0650
on_train_batch_begin: 1607713171.498036s

37 step training time: 0.762979s

on_train_batch_end: 1607713172.251516s

38912/50000 [======================>.......] - ETA: 15s - loss: 7.8105 - accuracy: 0.0653
on_train_batch_begin: 1607713172.251940s

38 step training time: 0.753903s

on_train_batch_end: 1607713173.080575s

39936/50000 [======================>.......] - ETA: 13s - loss: 7.7727 - accuracy: 0.0659
on_train_batch_begin: 1607713173.080991s

39 step training time: 0.829052s

on_train_batch_end: 1607713173.836421s

40960/50000 [=======================>......] - ETA: 12s - loss: 7.7384 - accuracy: 0.0663
on_train_batch_begin: 1607713173.836839s

40 step training time: 0.755848s

on_train_batch_end: 1607713174.604068s

41984/50000 [========================>.....] - ETA: 10s - loss: 7.7035 - accuracy: 0.0667
on_train_batch_begin: 1607713174.604512s

41 step training time: 0.767673s

on_train_batch_end: 1607713175.357539s

43008/50000 [========================>.....] - ETA: 9s - loss: 7.6749 - accuracy: 0.0667 
on_train_batch_begin: 1607713175.357972s

42 step training time: 0.753460s

on_train_batch_end: 1607713176.156362s

44032/50000 [=========================>....] - ETA: 7s - loss: 7.6459 - accuracy: 0.0671
on_train_batch_begin: 1607713176.156773s

43 step training time: 0.798801s

on_train_batch_end: 1607713176.929055s

45056/50000 [==========================>...] - ETA: 6s - loss: 7.6174 - accuracy: 0.0675
on_train_batch_begin: 1607713176.929465s

44 step training time: 0.772692s

on_train_batch_end: 1607713177.694756s

46080/50000 [==========================>...] - ETA: 5s - loss: 7.5852 - accuracy: 0.0682
on_train_batch_begin: 1607713177.695182s

45 step training time: 0.765718s

on_train_batch_end: 1607713178.481756s

47104/50000 [===========================>..] - ETA: 3s - loss: 7.5558 - accuracy: 0.0690
on_train_batch_begin: 1607713178.482178s

46 step training time: 0.786996s

on_train_batch_end: 1607713179.296253s

48128/50000 [===========================>..] - ETA: 2s - loss: 7.5288 - accuracy: 0.0695
on_train_batch_begin: 1607713179.296717s

47 step training time: 0.814539s

on_train_batch_end: 1607713180.046454s

49152/50000 [============================>.] - ETA: 1s - loss: 7.5005 - accuracy: 0.0702
on_train_batch_begin: 1607713180.046893s

48 step training time: 0.750176s

on_train_batch_end: 1607713187.899134s

on_test_batch_begin: 1607713188.127890s

49 step training time: 8.080997s

on_epoch_end: 1607713194.371077s

Validation time: 6.243158s

Real time: 1607713194.371077s

Epoch time: 76.35659527778625s

50000/50000 [==============================] - 76s 2ms/sample - loss: 7.4794 - accuracy: 0.0705 - val_loss: 293956.4684 - val_accuracy: 0.0000e+00

on_epoch_begin: 1607713194.371373s

Real time: 1607713194.3713837
Epoch 2/5

on_train_batch_begin: 1607713194.375895s

on_train_batch_end: 1607713195.186208s

 1024/50000 [..............................] - ETA: 38s - loss: 5.9887 - accuracy: 0.0954
on_train_batch_begin: 1607713195.186688s

1 step training time: 0.810793s

on_train_batch_end: 1607713195.973803s

 2048/50000 [>.............................] - ETA: 37s - loss: 6.0680 - accuracy: 0.0946
on_train_batch_begin: 1607713195.974218s

2 step training time: 0.787530s

on_train_batch_end: 1607713196.734971s

 3072/50000 [>.............................] - ETA: 36s - loss: 6.0517 - accuracy: 0.0921
on_train_batch_begin: 1607713196.735385s

3 step training time: 0.761167s

on_train_batch_end: 1607713197.528497s

 4096/50000 [=>............................] - ETA: 35s - loss: 6.0107 - accuracy: 0.0916
on_train_batch_begin: 1607713197.528941s

4 step training time: 0.793556s

on_train_batch_end: 1607713198.348251s

 5120/50000 [==>...........................] - ETA: 34s - loss: 5.9676 - accuracy: 0.0918
on_train_batch_begin: 1607713198.348676s

5 step training time: 0.819735s

on_train_batch_end: 1607713199.106550s

 6144/50000 [==>...........................] - ETA: 33s - loss: 5.9734 - accuracy: 0.0906
on_train_batch_begin: 1607713199.106957s

6 step training time: 0.758281s

on_train_batch_end: 1607713199.912278s

 7168/50000 [===>..........................] - ETA: 33s - loss: 5.9372 - accuracy: 0.0894
on_train_batch_begin: 1607713199.912691s

7 step training time: 0.805735s

on_train_batch_end: 1607713200.680144s

 8192/50000 [===>..........................] - ETA: 32s - loss: 5.9243 - accuracy: 0.0879
on_train_batch_begin: 1607713200.680561s

8 step training time: 0.767870s

on_train_batch_end: 1607713201.563560s

 9216/50000 [====>.........................] - ETA: 31s - loss: 5.9088 - accuracy: 0.0860
on_train_batch_begin: 1607713201.563985s

9 step training time: 0.883424s

on_train_batch_end: 1607713202.327605s

10240/50000 [=====>........................] - ETA: 30s - loss: 5.8837 - accuracy: 0.0852
on_train_batch_begin: 1607713202.328264s

10 step training time: 0.764278s

on_train_batch_end: 1607713203.091950s

11264/50000 [=====>........................] - ETA: 29s - loss: 5.8639 - accuracy: 0.0840
on_train_batch_begin: 1607713203.092357s

11 step training time: 0.764094s

on_train_batch_end: 1607713203.908757s

12288/50000 [======>.......................] - ETA: 29s - loss: 5.8462 - accuracy: 0.0827
on_train_batch_begin: 1607713203.909187s

12 step training time: 0.816830s

on_train_batch_end: 1607713204.730432s

13312/50000 [======>.......................] - ETA: 28s - loss: 5.8339 - accuracy: 0.0817
on_train_batch_begin: 1607713204.730879s

13 step training time: 0.821692s

on_train_batch_end: 1607713205.499073s

14336/50000 [=======>......................] - ETA: 27s - loss: 5.8260 - accuracy: 0.0810
on_train_batch_begin: 1607713205.499534s

14 step training time: 0.768655s

on_train_batch_end: 1607713206.279427s

15360/50000 [========>.....................] - ETA: 26s - loss: 5.8098 - accuracy: 0.0804
on_train_batch_begin: 1607713206.279848s

15 step training time: 0.780314s

on_train_batch_end: 1607713207.044371s

16384/50000 [========>.....................] - ETA: 26s - loss: 5.7995 - accuracy: 0.0799
on_train_batch_begin: 1607713207.044850s

16 step training time: 0.765002s

on_train_batch_end: 1607713207.888963s

17408/50000 [=========>....................] - ETA: 25s - loss: 5.7868 - accuracy: 0.0796
on_train_batch_begin: 1607713207.889409s

17 step training time: 0.844558s

on_train_batch_end: 1607713208.645125s

18432/50000 [==========>...................] - ETA: 24s - loss: 5.7682 - accuracy: 0.0796
on_train_batch_begin: 1607713208.645547s

18 step training time: 0.756138s

on_train_batch_end: 1607713209.411557s

19456/50000 [==========>...................] - ETA: 23s - loss: 5.7596 - accuracy: 0.0797
on_train_batch_begin: 1607713209.412006s

19 step training time: 0.766459s

on_train_batch_end: 1607713210.208812s

20480/50000 [===========>..................] - ETA: 22s - loss: 5.7500 - accuracy: 0.0799
on_train_batch_begin: 1607713210.209252s

20 step training time: 0.797246s

on_train_batch_end: 1607713211.012335s

21504/50000 [===========>..................] - ETA: 22s - loss: 5.7441 - accuracy: 0.0798
on_train_batch_begin: 1607713211.012777s

21 step training time: 0.803525s

on_train_batch_end: 1607713211.773040s

22528/50000 [============>.................] - ETA: 21s - loss: 5.7314 - accuracy: 0.0800
on_train_batch_begin: 1607713211.773503s

22 step training time: 0.760726s

on_train_batch_end: 1607713212.535638s

23552/50000 [=============>................] - ETA: 20s - loss: 5.7248 - accuracy: 0.0795
on_train_batch_begin: 1607713212.536045s

23 step training time: 0.762542s

on_train_batch_end: 1607713213.300381s

24576/50000 [=============>................] - ETA: 19s - loss: 5.7156 - accuracy: 0.0795
on_train_batch_begin: 1607713213.300821s

24 step training time: 0.764776s

on_train_batch_end: 1607713214.155705s

25600/50000 [==============>...............] - ETA: 18s - loss: 5.7071 - accuracy: 0.0794
on_train_batch_begin: 1607713214.156124s

25 step training time: 0.855303s

on_train_batch_end: 1607713214.883318s

26624/50000 [==============>...............] - ETA: 18s - loss: 5.7000 - accuracy: 0.0795
on_train_batch_begin: 1607713214.883794s

26 step training time: 0.727670s

on_train_batch_end: 1607713215.604294s

27648/50000 [===============>..............] - ETA: 17s - loss: 5.6851 - accuracy: 0.0798
on_train_batch_begin: 1607713215.604722s

27 step training time: 0.720929s

on_train_batch_end: 1607713216.327676s

28672/50000 [================>.............] - ETA: 16s - loss: 5.6819 - accuracy: 0.0795
on_train_batch_begin: 1607713216.328087s

28 step training time: 0.723364s

on_train_batch_end: 1607713217.059855s

29696/50000 [================>.............] - ETA: 15s - loss: 5.6759 - accuracy: 0.0795
on_train_batch_begin: 1607713217.060256s

29 step training time: 0.732169s

on_train_batch_end: 1607713217.792873s

30720/50000 [=================>............] - ETA: 14s - loss: 5.6682 - accuracy: 0.0794
on_train_batch_begin: 1607713217.793303s

30 step training time: 0.733048s

on_train_batch_end: 1607713218.513858s

31744/50000 [==================>...........] - ETA: 13s - loss: 5.6596 - accuracy: 0.0794
on_train_batch_begin: 1607713218.514362s

31 step training time: 0.721058s

on_train_batch_end: 1607713219.243102s

32768/50000 [==================>...........] - ETA: 13s - loss: 5.6514 - accuracy: 0.0793
on_train_batch_begin: 1607713219.243555s

32 step training time: 0.729193s

on_train_batch_end: 1607713219.974710s

33792/50000 [===================>..........] - ETA: 12s - loss: 5.6416 - accuracy: 0.0792
on_train_batch_begin: 1607713219.975321s

33 step training time: 0.731766s

on_train_batch_end: 1607713220.701606s

34816/50000 [===================>..........] - ETA: 11s - loss: 5.6320 - accuracy: 0.0793
on_train_batch_begin: 1607713220.702138s

34 step training time: 0.726817s

on_train_batch_end: 1607713221.427310s

35840/50000 [====================>.........] - ETA: 10s - loss: 5.6204 - accuracy: 0.0792
on_train_batch_begin: 1607713221.427736s

35 step training time: 0.725598s

on_train_batch_end: 1607713222.156169s

36864/50000 [=====================>........] - ETA: 9s - loss: 5.6091 - accuracy: 0.0793 
on_train_batch_begin: 1607713222.156575s

36 step training time: 0.728839s

on_train_batch_end: 1607713222.910684s

37888/50000 [=====================>........] - ETA: 9s - loss: 5.6025 - accuracy: 0.0793
on_train_batch_begin: 1607713222.911102s

37 step training time: 0.754527s

on_train_batch_end: 1607713223.628953s

38912/50000 [======================>.......] - ETA: 8s - loss: 5.5963 - accuracy: 0.0790
on_train_batch_begin: 1607713223.629384s

38 step training time: 0.718283s

on_train_batch_end: 1607713224.357783s

39936/50000 [======================>.......] - ETA: 7s - loss: 5.5937 - accuracy: 0.0788
on_train_batch_begin: 1607713224.358191s

39 step training time: 0.728807s

on_train_batch_end: 1607713225.081897s

40960/50000 [=======================>......] - ETA: 6s - loss: 5.5951 - accuracy: 0.0786
on_train_batch_begin: 1607713225.082376s

40 step training time: 0.724185s

on_train_batch_end: 1607713225.824783s

41984/50000 [========================>.....] - ETA: 6s - loss: 5.5910 - accuracy: 0.0784
on_train_batch_begin: 1607713225.825189s

41 step training time: 0.742814s

on_train_batch_end: 1607713226.549021s

43008/50000 [========================>.....] - ETA: 5s - loss: 5.5893 - accuracy: 0.0783
on_train_batch_begin: 1607713226.549441s

42 step training time: 0.724252s

on_train_batch_end: 1607713227.276432s

44032/50000 [=========================>....] - ETA: 4s - loss: 5.5822 - accuracy: 0.0782
on_train_batch_begin: 1607713227.276836s

43 step training time: 0.727395s

on_train_batch_end: 1607713228.026950s

45056/50000 [==========================>...] - ETA: 3s - loss: 5.5760 - accuracy: 0.0781
on_train_batch_begin: 1607713228.027385s

44 step training time: 0.750549s

on_train_batch_end: 1607713228.756310s

46080/50000 [==========================>...] - ETA: 2s - loss: 5.5741 - accuracy: 0.0777
on_train_batch_begin: 1607713228.756727s

45 step training time: 0.729342s

on_train_batch_end: 1607713229.483918s

47104/50000 [===========================>..] - ETA: 2s - loss: 5.5657 - accuracy: 0.0774
on_train_batch_begin: 1607713229.484330s

46 step training time: 0.727602s

on_train_batch_end: 1607713230.210265s

48128/50000 [===========================>..] - ETA: 1s - loss: 5.5635 - accuracy: 0.0771
on_train_batch_begin: 1607713230.210761s

47 step training time: 0.726431s

on_train_batch_end: 1607713230.941523s

49152/50000 [============================>.] - ETA: 0s - loss: 5.5574 - accuracy: 0.0769
on_train_batch_begin: 1607713230.941965s

48 step training time: 0.731204s

on_train_batch_end: 1607713231.557872s

on_test_batch_begin: 1607713231.572273s

49 step training time: 0.630307s

on_epoch_end: 1607713233.458427s

Validation time: 1.886129s

Real time: 1607713233.458427s

Epoch time: 39.08706521987915s

50000/50000 [==============================] - 39s 782us/sample - loss: 5.5535 - accuracy: 0.0767 - val_loss: 7.3756 - val_accuracy: 0.0999

on_epoch_begin: 1607713233.458691s

Real time: 1607713233.4587011
Epoch 3/5

on_train_batch_begin: 1607713233.463057s

on_train_batch_end: 1607713234.189191s

 1024/50000 [..............................] - ETA: 34s - loss: 5.1153 - accuracy: 0.0689
on_train_batch_begin: 1607713234.189731s

1 step training time: 0.726674s

on_train_batch_end: 1607713234.927555s

 2048/50000 [>.............................] - ETA: 34s - loss: 5.1584 - accuracy: 0.0657
on_train_batch_begin: 1607713234.927979s

2 step training time: 0.738248s

on_train_batch_end: 1607713235.668725s

 3072/50000 [>.............................] - ETA: 33s - loss: 5.1372 - accuracy: 0.0680
on_train_batch_begin: 1607713235.669134s

3 step training time: 0.741156s

on_train_batch_end: 1607713236.393259s

 4096/50000 [=>............................] - ETA: 32s - loss: 5.1747 - accuracy: 0.0675
on_train_batch_begin: 1607713236.393711s

4 step training time: 0.724577s

on_train_batch_end: 1607713237.124119s

 5120/50000 [==>...........................] - ETA: 32s - loss: 5.2142 - accuracy: 0.0690
on_train_batch_begin: 1607713237.124548s

5 step training time: 0.730837s

on_train_batch_end: 1607713237.862990s

 6144/50000 [==>...........................] - ETA: 31s - loss: 5.1959 - accuracy: 0.0689
on_train_batch_begin: 1607713237.863434s

6 step training time: 0.738886s

on_train_batch_end: 1607713238.591701s

 7168/50000 [===>..........................] - ETA: 30s - loss: 5.1942 - accuracy: 0.0699
on_train_batch_begin: 1607713238.592118s

7 step training time: 0.728684s

on_train_batch_end: 1607713239.320341s

 8192/50000 [===>..........................] - ETA: 29s - loss: 5.1805 - accuracy: 0.0704
on_train_batch_begin: 1607713239.320794s

8 step training time: 0.728676s

on_train_batch_end: 1607713240.055690s

 9216/50000 [====>.........................] - ETA: 29s - loss: 5.1799 - accuracy: 0.0702
on_train_batch_begin: 1607713240.056096s

9 step training time: 0.735302s

on_train_batch_end: 1607713240.796265s

10240/50000 [=====>........................] - ETA: 28s - loss: 5.1939 - accuracy: 0.0702
on_train_batch_begin: 1607713240.796672s

10 step training time: 0.740575s

on_train_batch_end: 1607713241.525038s

11264/50000 [=====>........................] - ETA: 27s - loss: 5.1818 - accuracy: 0.0703
on_train_batch_begin: 1607713241.525455s

11 step training time: 0.728783s

on_train_batch_end: 1607713242.254215s

12288/50000 [======>.......................] - ETA: 26s - loss: 5.1814 - accuracy: 0.0698
on_train_batch_begin: 1607713242.254671s

12 step training time: 0.729216s

on_train_batch_end: 1607713242.981558s

13312/50000 [======>.......................] - ETA: 26s - loss: 5.1916 - accuracy: 0.0698
on_train_batch_begin: 1607713242.981976s

13 step training time: 0.727305s

on_train_batch_end: 1607713243.714264s

14336/50000 [=======>......................] - ETA: 25s - loss: 5.2041 - accuracy: 0.0693
on_train_batch_begin: 1607713243.714703s

14 step training time: 0.732727s

on_train_batch_end: 1607713244.459535s

15360/50000 [========>.....................] - ETA: 24s - loss: 5.2008 - accuracy: 0.0690
on_train_batch_begin: 1607713244.459948s

15 step training time: 0.745246s

on_train_batch_end: 1607713245.188348s

16384/50000 [========>.....................] - ETA: 24s - loss: 5.1939 - accuracy: 0.0689
on_train_batch_begin: 1607713245.188776s

16 step training time: 0.728827s

on_train_batch_end: 1607713245.917737s

17408/50000 [=========>....................] - ETA: 23s - loss: 5.1857 - accuracy: 0.0688
on_train_batch_begin: 1607713245.918162s

17 step training time: 0.729387s

on_train_batch_end: 1607713246.649590s

18432/50000 [==========>...................] - ETA: 22s - loss: 5.1777 - accuracy: 0.0688
on_train_batch_begin: 1607713246.650006s

18 step training time: 0.731844s

on_train_batch_end: 1607713247.374364s

19456/50000 [==========>...................] - ETA: 21s - loss: 5.1673 - accuracy: 0.0689
on_train_batch_begin: 1607713247.374774s

19 step training time: 0.724768s

on_train_batch_end: 1607713248.103823s

20480/50000 [===========>..................] - ETA: 21s - loss: 5.1580 - accuracy: 0.0688
on_train_batch_begin: 1607713248.104266s

20 step training time: 0.729493s

on_train_batch_end: 1607713248.834792s

21504/50000 [===========>..................] - ETA: 20s - loss: 5.1516 - accuracy: 0.0687
on_train_batch_begin: 1607713248.835472s

21 step training time: 0.731206s

on_train_batch_end: 1607713249.588038s

22528/50000 [============>.................] - ETA: 19s - loss: 5.1464 - accuracy: 0.0685
on_train_batch_begin: 1607713249.588463s

22 step training time: 0.752991s

on_train_batch_end: 1607713250.312552s

23552/50000 [=============>................] - ETA: 18s - loss: 5.1358 - accuracy: 0.0684
on_train_batch_begin: 1607713250.312960s

23 step training time: 0.724497s

on_train_batch_end: 1607713251.041120s

24576/50000 [=============>................] - ETA: 18s - loss: 5.1264 - accuracy: 0.0683
on_train_batch_begin: 1607713251.041524s

24 step training time: 0.728564s

on_train_batch_end: 1607713251.772822s

25600/50000 [==============>...............] - ETA: 17s - loss: 5.1078 - accuracy: 0.0686
on_train_batch_begin: 1607713251.773247s

25 step training time: 0.731723s

on_train_batch_end: 1607713252.520776s

26624/50000 [==============>...............] - ETA: 16s - loss: 5.1004 - accuracy: 0.0686
on_train_batch_begin: 1607713252.521245s

26 step training time: 0.747998s

on_train_batch_end: 1607713253.247203s

27648/50000 [===============>..............] - ETA: 15s - loss: 5.0860 - accuracy: 0.0686
on_train_batch_begin: 1607713253.247624s

27 step training time: 0.726379s

on_train_batch_end: 1607713253.978204s

28672/50000 [================>.............] - ETA: 15s - loss: 5.0721 - accuracy: 0.0688
on_train_batch_begin: 1607713253.978673s

28 step training time: 0.731049s

on_train_batch_end: 1607713254.717035s

29696/50000 [================>.............] - ETA: 14s - loss: 5.0534 - accuracy: 0.0691
on_train_batch_begin: 1607713254.717458s

29 step training time: 0.738784s

on_train_batch_end: 1607713255.452638s

30720/50000 [=================>............] - ETA: 13s - loss: 5.0452 - accuracy: 0.0693
on_train_batch_begin: 1607713255.453049s

30 step training time: 0.735592s

on_train_batch_end: 1607713256.181376s

31744/50000 [==================>...........] - ETA: 13s - loss: 5.0338 - accuracy: 0.0696
on_train_batch_begin: 1607713256.181820s

31 step training time: 0.728771s

on_train_batch_end: 1607713256.906587s

32768/50000 [==================>...........] - ETA: 12s - loss: 5.0266 - accuracy: 0.0698
on_train_batch_begin: 1607713256.907007s

32 step training time: 0.725187s

on_train_batch_end: 1607713257.634936s

33792/50000 [===================>..........] - ETA: 11s - loss: 5.0174 - accuracy: 0.0698
on_train_batch_begin: 1607713257.635345s

33 step training time: 0.728338s

on_train_batch_end: 1607713258.398673s

34816/50000 [===================>..........] - ETA: 10s - loss: 5.0001 - accuracy: 0.0701
on_train_batch_begin: 1607713258.399084s

34 step training time: 0.763739s

on_train_batch_end: 1607713259.119716s

35840/50000 [====================>.........] - ETA: 10s - loss: 4.9853 - accuracy: 0.0703
on_train_batch_begin: 1607713259.120158s

35 step training time: 0.721074s

on_train_batch_end: 1607713259.857097s

36864/50000 [=====================>........] - ETA: 9s - loss: 4.9679 - accuracy: 0.0705 
on_train_batch_begin: 1607713259.857528s

36 step training time: 0.737370s

on_train_batch_end: 1607713260.583728s

37888/50000 [=====================>........] - ETA: 8s - loss: 4.9528 - accuracy: 0.0709
on_train_batch_begin: 1607713260.584183s

37 step training time: 0.726655s

on_train_batch_end: 1607713261.340334s

38912/50000 [======================>.......] - ETA: 7s - loss: 4.9352 - accuracy: 0.0711
on_train_batch_begin: 1607713261.340767s

38 step training time: 0.756584s

on_train_batch_end: 1607713262.066390s

39936/50000 [======================>.......] - ETA: 7s - loss: 4.9172 - accuracy: 0.0714
on_train_batch_begin: 1607713262.066829s

39 step training time: 0.726062s

on_train_batch_end: 1607713262.795002s

40960/50000 [=======================>......] - ETA: 6s - loss: 4.8965 - accuracy: 0.0717
on_train_batch_begin: 1607713262.795427s

40 step training time: 0.728598s

on_train_batch_end: 1607713263.548883s

41984/50000 [========================>.....] - ETA: 5s - loss: 4.8807 - accuracy: 0.0719
on_train_batch_begin: 1607713263.549301s

41 step training time: 0.753874s

on_train_batch_end: 1607713264.282821s

43008/50000 [========================>.....] - ETA: 5s - loss: 4.8586 - accuracy: 0.0722
on_train_batch_begin: 1607713264.283267s

42 step training time: 0.733966s

on_train_batch_end: 1607713265.010133s

44032/50000 [=========================>....] - ETA: 4s - loss: 4.8346 - accuracy: 0.0726
on_train_batch_begin: 1607713265.010585s

43 step training time: 0.727318s

on_train_batch_end: 1607713265.737688s

45056/50000 [==========================>...] - ETA: 3s - loss: 4.8077 - accuracy: 0.0730
on_train_batch_begin: 1607713265.738101s

44 step training time: 0.727516s

on_train_batch_end: 1607713266.470985s

46080/50000 [==========================>...] - ETA: 2s - loss: 4.7826 - accuracy: 0.0734
on_train_batch_begin: 1607713266.471397s

45 step training time: 0.733296s

on_train_batch_end: 1607713267.205926s

47104/50000 [===========================>..] - ETA: 2s - loss: 4.7574 - accuracy: 0.0738
on_train_batch_begin: 1607713267.206389s

46 step training time: 0.734992s

on_train_batch_end: 1607713267.931355s

48128/50000 [===========================>..] - ETA: 1s - loss: 4.7309 - accuracy: 0.0742
on_train_batch_begin: 1607713267.931773s

47 step training time: 0.725384s

on_train_batch_end: 1607713268.673511s

49152/50000 [============================>.] - ETA: 0s - loss: 4.7036 - accuracy: 0.0746
on_train_batch_begin: 1607713268.673958s

48 step training time: 0.742185s

on_train_batch_end: 1607713269.285553s

on_test_batch_begin: 1607713269.299138s

49 step training time: 0.625180s

on_epoch_end: 1607713271.177141s

Validation time: 1.877983s

Real time: 1607713271.177141s

Epoch time: 37.71846389770508s

50000/50000 [==============================] - 38s 754us/sample - loss: 4.6861 - accuracy: 0.0748 - val_loss: 7.2855 - val_accuracy: 0.0999

on_epoch_begin: 1607713271.177417s

Real time: 1607713271.1774266
Epoch 4/5

on_train_batch_begin: 1607713271.182036s

on_train_batch_end: 1607713271.909101s

 1024/50000 [..............................] - ETA: 35s - loss: 3.0846 - accuracy: 0.0985
on_train_batch_begin: 1607713271.909534s

1 step training time: 0.727498s

on_train_batch_end: 1607713272.647825s

 2048/50000 [>.............................] - ETA: 34s - loss: 3.0540 - accuracy: 0.0978
on_train_batch_begin: 1607713272.648267s

2 step training time: 0.738733s

on_train_batch_end: 1607713273.377842s

 3072/50000 [>.............................] - ETA: 33s - loss: 3.0517 - accuracy: 0.0973
on_train_batch_begin: 1607713273.378270s

3 step training time: 0.730003s

on_train_batch_end: 1607713274.115794s

 4096/50000 [=>............................] - ETA: 32s - loss: 2.9748 - accuracy: 0.0980
on_train_batch_begin: 1607713274.116340s

4 step training time: 0.738070s

on_train_batch_end: 1607713274.848087s

 5120/50000 [==>...........................] - ETA: 32s - loss: 2.9974 - accuracy: 0.0978
on_train_batch_begin: 1607713274.848542s

5 step training time: 0.732202s

on_train_batch_end: 1607713275.579497s

 6144/50000 [==>...........................] - ETA: 31s - loss: 2.9374 - accuracy: 0.0981
on_train_batch_begin: 1607713275.579920s

6 step training time: 0.731378s

on_train_batch_end: 1607713276.338710s

 7168/50000 [===>..........................] - ETA: 30s - loss: 2.8892 - accuracy: 0.0982
on_train_batch_begin: 1607713276.339139s

7 step training time: 0.759219s

on_train_batch_end: 1607713277.066369s

 8192/50000 [===>..........................] - ETA: 30s - loss: 2.8574 - accuracy: 0.0983
on_train_batch_begin: 1607713277.066782s

8 step training time: 0.727643s

on_train_batch_end: 1607713277.799029s

 9216/50000 [====>.........................] - ETA: 29s - loss: 2.8565 - accuracy: 0.0984
on_train_batch_begin: 1607713277.799451s

9 step training time: 0.732668s

on_train_batch_end: 1607713278.531313s

10240/50000 [=====>........................] - ETA: 28s - loss: 2.8516 - accuracy: 0.0985
on_train_batch_begin: 1607713278.531739s

10 step training time: 0.732288s

on_train_batch_end: 1607713279.277809s

11264/50000 [=====>........................] - ETA: 27s - loss: 2.8329 - accuracy: 0.0987
on_train_batch_begin: 1607713279.278263s

11 step training time: 0.746525s

on_train_batch_end: 1607713280.005110s

12288/50000 [======>.......................] - ETA: 27s - loss: 2.8048 - accuracy: 0.0987
on_train_batch_begin: 1607713280.005575s

12 step training time: 0.727312s

on_train_batch_end: 1607713280.733448s

13312/50000 [======>.......................] - ETA: 26s - loss: 2.7904 - accuracy: 0.0988
on_train_batch_begin: 1607713280.733863s

13 step training time: 0.728288s

on_train_batch_end: 1607713281.479716s

14336/50000 [=======>......................] - ETA: 25s - loss: 2.7704 - accuracy: 0.0988
on_train_batch_begin: 1607713281.480208s

14 step training time: 0.746345s

on_train_batch_end: 1607713282.213281s

15360/50000 [========>.....................] - ETA: 24s - loss: 2.7474 - accuracy: 0.0988
on_train_batch_begin: 1607713282.213695s

15 step training time: 0.733487s

on_train_batch_end: 1607713282.947564s

16384/50000 [========>.....................] - ETA: 24s - loss: 2.7350 - accuracy: 0.0989
on_train_batch_begin: 1607713282.947990s

16 step training time: 0.734295s

on_train_batch_end: 1607713283.676412s

17408/50000 [=========>....................] - ETA: 23s - loss: 2.7306 - accuracy: 0.0989
on_train_batch_begin: 1607713283.676841s

17 step training time: 0.728850s

on_train_batch_end: 1607713284.406573s

18432/50000 [==========>...................] - ETA: 22s - loss: 2.7192 - accuracy: 0.0990
on_train_batch_begin: 1607713284.407025s

18 step training time: 0.730184s

on_train_batch_end: 1607713285.165058s

19456/50000 [==========>...................] - ETA: 21s - loss: 2.6921 - accuracy: 0.0990
on_train_batch_begin: 1607713285.165513s

19 step training time: 0.758489s

on_train_batch_end: 1607713285.890184s

20480/50000 [===========>..................] - ETA: 21s - loss: 2.6747 - accuracy: 0.0991
on_train_batch_begin: 1607713285.890654s

20 step training time: 0.725140s

on_train_batch_end: 1607713286.621503s

21504/50000 [===========>..................] - ETA: 20s - loss: 2.6526 - accuracy: 0.0991
on_train_batch_begin: 1607713286.621961s

21 step training time: 0.731307s

on_train_batch_end: 1607713287.354379s

22528/50000 [============>.................] - ETA: 19s - loss: 2.6285 - accuracy: 0.0992
on_train_batch_begin: 1607713287.354940s

22 step training time: 0.732979s

on_train_batch_end: 1607713288.097950s

23552/50000 [=============>................] - ETA: 19s - loss: 2.6136 - accuracy: 0.0992
on_train_batch_begin: 1607713288.098425s

23 step training time: 0.743485s

on_train_batch_end: 1607713288.825063s

24576/50000 [=============>................] - ETA: 18s - loss: 2.5988 - accuracy: 0.0992
on_train_batch_begin: 1607713288.825511s

24 step training time: 0.727086s

on_train_batch_end: 1607713289.546220s

25600/50000 [==============>...............] - ETA: 17s - loss: 2.5771 - accuracy: 0.0993
on_train_batch_begin: 1607713289.546665s

25 step training time: 0.721154s

on_train_batch_end: 1607713290.298064s

26624/50000 [==============>...............] - ETA: 16s - loss: 2.5597 - accuracy: 0.0993
on_train_batch_begin: 1607713290.298540s

26 step training time: 0.751875s

on_train_batch_end: 1607713291.037143s

27648/50000 [===============>..............] - ETA: 16s - loss: 2.5413 - accuracy: 0.0994
on_train_batch_begin: 1607713291.037556s

27 step training time: 0.739016s

on_train_batch_end: 1607713291.762709s

28672/50000 [================>.............] - ETA: 15s - loss: 2.5212 - accuracy: 0.0994
on_train_batch_begin: 1607713291.763119s

28 step training time: 0.725563s

on_train_batch_end: 1607713292.495367s

29696/50000 [================>.............] - ETA: 14s - loss: 2.5086 - accuracy: 0.0994
on_train_batch_begin: 1607713292.495806s

29 step training time: 0.732687s

on_train_batch_end: 1607713293.221287s

30720/50000 [=================>............] - ETA: 13s - loss: 2.4938 - accuracy: 0.0994
on_train_batch_begin: 1607713293.221691s

30 step training time: 0.725885s

on_train_batch_end: 1607713293.953298s

31744/50000 [==================>...........] - ETA: 13s - loss: 2.4729 - accuracy: 0.0995
on_train_batch_begin: 1607713293.953786s

31 step training time: 0.732095s

on_train_batch_end: 1607713294.676912s

32768/50000 [==================>...........] - ETA: 12s - loss: 2.4573 - accuracy: 0.0995
on_train_batch_begin: 1607713294.677319s

32 step training time: 0.723533s

on_train_batch_end: 1607713295.427155s

33792/50000 [===================>..........] - ETA: 11s - loss: 2.4409 - accuracy: 0.0995
on_train_batch_begin: 1607713295.427571s

33 step training time: 0.750252s

on_train_batch_end: 1607713296.150432s

34816/50000 [===================>..........] - ETA: 10s - loss: 2.4261 - accuracy: 0.0995
on_train_batch_begin: 1607713296.150854s

34 step training time: 0.723283s

on_train_batch_end: 1607713296.896099s

35840/50000 [====================>.........] - ETA: 10s - loss: 2.4136 - accuracy: 0.0995
on_train_batch_begin: 1607713296.896506s

35 step training time: 0.745653s

on_train_batch_end: 1607713297.623490s

36864/50000 [=====================>........] - ETA: 9s - loss: 2.3972 - accuracy: 0.0995 
on_train_batch_begin: 1607713297.623922s

36 step training time: 0.727416s

on_train_batch_end: 1607713298.347521s

37888/50000 [=====================>........] - ETA: 8s - loss: 2.3812 - accuracy: 0.0996
on_train_batch_begin: 1607713298.347945s

37 step training time: 0.724022s

on_train_batch_end: 1607713299.071923s

38912/50000 [======================>.......] - ETA: 7s - loss: 2.3678 - accuracy: 0.0996
on_train_batch_begin: 1607713299.072369s

38 step training time: 0.724425s

on_train_batch_end: 1607713299.808331s

39936/50000 [======================>.......] - ETA: 7s - loss: 2.3522 - accuracy: 0.0996
on_train_batch_begin: 1607713299.808755s

39 step training time: 0.736386s

on_train_batch_end: 1607713300.545597s

40960/50000 [=======================>......] - ETA: 6s - loss: 2.3377 - accuracy: 0.0996
on_train_batch_begin: 1607713300.546021s

40 step training time: 0.737265s

on_train_batch_end: 1607713301.280746s

41984/50000 [========================>.....] - ETA: 5s - loss: 2.3242 - accuracy: 0.0996
on_train_batch_begin: 1607713301.281176s

41 step training time: 0.735155s

on_train_batch_end: 1607713302.015855s

43008/50000 [========================>.....] - ETA: 5s - loss: 2.3129 - accuracy: 0.0997
on_train_batch_begin: 1607713302.016297s

42 step training time: 0.735121s

on_train_batch_end: 1607713302.750477s

44032/50000 [=========================>....] - ETA: 4s - loss: 2.2984 - accuracy: 0.0997
on_train_batch_begin: 1607713302.750883s

43 step training time: 0.734586s

on_train_batch_end: 1607713303.475355s

45056/50000 [==========================>...] - ETA: 3s - loss: 2.2846 - accuracy: 0.0997
on_train_batch_begin: 1607713303.475780s

44 step training time: 0.724897s

on_train_batch_end: 1607713304.217342s

46080/50000 [==========================>...] - ETA: 2s - loss: 2.2709 - accuracy: 0.0997
on_train_batch_begin: 1607713304.217834s

45 step training time: 0.742054s

on_train_batch_end: 1607713304.951300s

47104/50000 [===========================>..] - ETA: 2s - loss: 2.2560 - accuracy: 0.0997
on_train_batch_begin: 1607713304.951735s

46 step training time: 0.733901s

on_train_batch_end: 1607713305.692408s

48128/50000 [===========================>..] - ETA: 1s - loss: 2.2441 - accuracy: 0.0997
on_train_batch_begin: 1607713305.692833s

47 step training time: 0.741097s

on_train_batch_end: 1607713306.419401s

49152/50000 [============================>.] - ETA: 0s - loss: 2.2324 - accuracy: 0.0997
on_train_batch_begin: 1607713306.419851s

48 step training time: 0.727019s

on_train_batch_end: 1607713307.046644s

on_test_batch_begin: 1607713307.059985s

49 step training time: 0.640133s

on_epoch_end: 1607713308.938717s

Validation time: 1.878717s

Real time: 1607713308.938717s

Epoch time: 37.761314392089844s

50000/50000 [==============================] - 38s 755us/sample - loss: 2.2252 - accuracy: 0.0997 - val_loss: 7.1100 - val_accuracy: 0.0999

on_epoch_begin: 1607713308.939023s

Real time: 1607713308.9390333
Epoch 5/5

on_train_batch_begin: 1607713308.943552s

on_train_batch_end: 1607713309.668970s

 1024/50000 [..............................] - ETA: 34s - loss: 1.4286 - accuracy: 0.1007
on_train_batch_begin: 1607713309.669376s

1 step training time: 0.725823s

on_train_batch_end: 1607713310.402881s

 2048/50000 [>.............................] - ETA: 34s - loss: 1.4792 - accuracy: 0.1006
on_train_batch_begin: 1607713310.403306s

2 step training time: 0.733930s

on_train_batch_end: 1607713311.131002s

 3072/50000 [>.............................] - ETA: 33s - loss: 1.4770 - accuracy: 0.1005
on_train_batch_begin: 1607713311.131421s

3 step training time: 0.728115s

on_train_batch_end: 1607713311.882074s

 4096/50000 [=>............................] - ETA: 32s - loss: 1.4976 - accuracy: 0.1004
on_train_batch_begin: 1607713311.882577s

4 step training time: 0.751156s

on_train_batch_end: 1607713312.606945s

 5120/50000 [==>...........................] - ETA: 32s - loss: 1.4896 - accuracy: 0.1004
on_train_batch_begin: 1607713312.607356s

5 step training time: 0.724779s

on_train_batch_end: 1607713313.337346s

 6144/50000 [==>...........................] - ETA: 31s - loss: 1.4817 - accuracy: 0.1004
on_train_batch_begin: 1607713313.337747s

6 step training time: 0.730391s

on_train_batch_end: 1607713314.062116s

 7168/50000 [===>..........................] - ETA: 30s - loss: 1.4552 - accuracy: 0.1003
on_train_batch_begin: 1607713314.062587s

7 step training time: 0.724840s

on_train_batch_end: 1607713314.805182s

 8192/50000 [===>..........................] - ETA: 29s - loss: 1.4603 - accuracy: 0.1003
on_train_batch_begin: 1607713314.805641s

8 step training time: 0.743054s

on_train_batch_end: 1607713315.529745s

 9216/50000 [====>.........................] - ETA: 29s - loss: 1.4618 - accuracy: 0.1003
on_train_batch_begin: 1607713315.530192s

9 step training time: 0.724550s

on_train_batch_end: 1607713316.259293s

10240/50000 [=====>........................] - ETA: 28s - loss: 1.4407 - accuracy: 0.1003
on_train_batch_begin: 1607713316.259740s

10 step training time: 0.729548s

on_train_batch_end: 1607713316.997654s

11264/50000 [=====>........................] - ETA: 27s - loss: 1.4511 - accuracy: 0.1004
on_train_batch_begin: 1607713316.998071s

11 step training time: 0.738331s

on_train_batch_end: 1607713317.732832s

12288/50000 [======>.......................] - ETA: 26s - loss: 1.4399 - accuracy: 0.1003
on_train_batch_begin: 1607713317.733243s

12 step training time: 0.735173s

on_train_batch_end: 1607713318.467892s

13312/50000 [======>.......................] - ETA: 26s - loss: 1.4478 - accuracy: 0.1003
on_train_batch_begin: 1607713318.468317s

13 step training time: 0.735074s

on_train_batch_end: 1607713319.200061s

14336/50000 [=======>......................] - ETA: 25s - loss: 1.4480 - accuracy: 0.1003
on_train_batch_begin: 1607713319.200496s

14 step training time: 0.732179s

on_train_batch_end: 1607713319.933497s

15360/50000 [========>.....................] - ETA: 24s - loss: 1.4437 - accuracy: 0.1003
on_train_batch_begin: 1607713319.933906s

15 step training time: 0.733409s

on_train_batch_end: 1607713320.691591s

16384/50000 [========>.....................] - ETA: 24s - loss: 1.4383 - accuracy: 0.1003
on_train_batch_begin: 1607713320.692041s

16 step training time: 0.758135s

on_train_batch_end: 1607713321.418775s

17408/50000 [=========>....................] - ETA: 23s - loss: 1.4282 - accuracy: 0.1003
on_train_batch_begin: 1607713321.419189s

17 step training time: 0.727148s

on_train_batch_end: 1607713322.154808s

18432/50000 [==========>...................] - ETA: 22s - loss: 1.4313 - accuracy: 0.1003
on_train_batch_begin: 1607713322.155277s

18 step training time: 0.736088s

on_train_batch_end: 1607713322.878988s

19456/50000 [==========>...................] - ETA: 21s - loss: 1.4313 - accuracy: 0.1003
on_train_batch_begin: 1607713322.879420s

19 step training time: 0.724143s

on_train_batch_end: 1607713323.627473s

20480/50000 [===========>..................] - ETA: 21s - loss: 1.4229 - accuracy: 0.1003
on_train_batch_begin: 1607713323.627890s

20 step training time: 0.748470s

on_train_batch_end: 1607713324.353849s

21504/50000 [===========>..................] - ETA: 20s - loss: 1.4183 - accuracy: 0.1003
on_train_batch_begin: 1607713324.354270s

21 step training time: 0.726381s

on_train_batch_end: 1607713325.083583s

22528/50000 [============>.................] - ETA: 19s - loss: 1.4142 - accuracy: 0.1003
on_train_batch_begin: 1607713325.084009s

22 step training time: 0.729739s

on_train_batch_end: 1607713325.826210s

23552/50000 [=============>................] - ETA: 18s - loss: 1.4173 - accuracy: 0.1003
on_train_batch_begin: 1607713325.826700s

23 step training time: 0.742691s

on_train_batch_end: 1607713326.564909s

24576/50000 [=============>................] - ETA: 18s - loss: 1.4149 - accuracy: 0.1003
on_train_batch_begin: 1607713326.565322s

24 step training time: 0.738622s

on_train_batch_end: 1607713327.294608s

25600/50000 [==============>...............] - ETA: 17s - loss: 1.4147 - accuracy: 0.1003
on_train_batch_begin: 1607713327.295038s

25 step training time: 0.729717s

on_train_batch_end: 1607713328.021627s

26624/50000 [==============>...............] - ETA: 16s - loss: 1.4125 - accuracy: 0.1003
on_train_batch_begin: 1607713328.022109s

26 step training time: 0.727071s

on_train_batch_end: 1607713328.759538s

27648/50000 [===============>..............] - ETA: 16s - loss: 1.4072 - accuracy: 0.1003
on_train_batch_begin: 1607713328.759952s

27 step training time: 0.737843s

on_train_batch_end: 1607713329.497096s

28672/50000 [================>.............] - ETA: 15s - loss: 1.4003 - accuracy: 0.1003
on_train_batch_begin: 1607713329.497524s

28 step training time: 0.737571s

on_train_batch_end: 1607713330.221075s

29696/50000 [================>.............] - ETA: 14s - loss: 1.3965 - accuracy: 0.1003
on_train_batch_begin: 1607713330.221538s

29 step training time: 0.724015s

on_train_batch_end: 1607713330.959084s

30720/50000 [=================>............] - ETA: 13s - loss: 1.3905 - accuracy: 0.1003
on_train_batch_begin: 1607713330.959531s

30 step training time: 0.737993s

on_train_batch_end: 1607713331.687966s

31744/50000 [==================>...........] - ETA: 13s - loss: 1.3877 - accuracy: 0.1003
on_train_batch_begin: 1607713331.688399s

31 step training time: 0.728868s

on_train_batch_end: 1607713332.432622s

32768/50000 [==================>...........] - ETA: 12s - loss: 1.3857 - accuracy: 0.1003
on_train_batch_begin: 1607713332.433026s

32 step training time: 0.744627s

on_train_batch_end: 1607713333.155680s

33792/50000 [===================>..........] - ETA: 11s - loss: 1.3757 - accuracy: 0.1003
on_train_batch_begin: 1607713333.156101s

33 step training time: 0.723074s

on_train_batch_end: 1607713333.885033s

34816/50000 [===================>..........] - ETA: 10s - loss: 1.3717 - accuracy: 0.1003
on_train_batch_begin: 1607713333.885439s

34 step training time: 0.729339s

on_train_batch_end: 1607713334.614739s

35840/50000 [====================>.........] - ETA: 10s - loss: 1.3669 - accuracy: 0.1003
on_train_batch_begin: 1607713334.615207s

35 step training time: 0.729768s

on_train_batch_end: 1607713335.346902s

36864/50000 [=====================>........] - ETA: 9s - loss: 1.3638 - accuracy: 0.1003 
on_train_batch_begin: 1607713335.347306s

36 step training time: 0.732099s

on_train_batch_end: 1607713336.088110s

37888/50000 [=====================>........] - ETA: 8s - loss: 1.3613 - accuracy: 0.1003
on_train_batch_begin: 1607713336.088547s

37 step training time: 0.741241s

on_train_batch_end: 1607713336.819287s

38912/50000 [======================>.......] - ETA: 7s - loss: 1.3593 - accuracy: 0.1003
on_train_batch_begin: 1607713336.819700s

38 step training time: 0.731154s

on_train_batch_end: 1607713337.549966s

39936/50000 [======================>.......] - ETA: 7s - loss: 1.3558 - accuracy: 0.1003
on_train_batch_begin: 1607713337.550497s

39 step training time: 0.730797s

on_train_batch_end: 1607713338.288352s

40960/50000 [=======================>......] - ETA: 6s - loss: 1.3547 - accuracy: 0.1003
on_train_batch_begin: 1607713338.288771s

40 step training time: 0.738274s

on_train_batch_end: 1607713339.020992s

41984/50000 [========================>.....] - ETA: 5s - loss: 1.3547 - accuracy: 0.1003
on_train_batch_begin: 1607713339.021407s

41 step training time: 0.732636s

on_train_batch_end: 1607713339.751300s

43008/50000 [========================>.....] - ETA: 5s - loss: 1.3521 - accuracy: 0.1003
on_train_batch_begin: 1607713339.751730s

42 step training time: 0.730323s

on_train_batch_end: 1607713340.482680s

44032/50000 [=========================>....] - ETA: 4s - loss: 1.3500 - accuracy: 0.1003
on_train_batch_begin: 1607713340.483101s

43 step training time: 0.731371s

on_train_batch_end: 1607713341.227914s

45056/50000 [==========================>...] - ETA: 3s - loss: 1.3477 - accuracy: 0.1003
on_train_batch_begin: 1607713341.228328s

44 step training time: 0.745227s

on_train_batch_end: 1607713341.953967s

46080/50000 [==========================>...] - ETA: 2s - loss: 1.3456 - accuracy: 0.1003
on_train_batch_begin: 1607713341.954455s

45 step training time: 0.726127s

on_train_batch_end: 1607713342.680965s

47104/50000 [===========================>..] - ETA: 2s - loss: 1.3417 - accuracy: 0.1003
on_train_batch_begin: 1607713342.681376s

46 step training time: 0.726921s

on_train_batch_end: 1607713343.409985s

48128/50000 [===========================>..] - ETA: 1s - loss: 1.3399 - accuracy: 0.1003
on_train_batch_begin: 1607713343.410467s

47 step training time: 0.729092s

on_train_batch_end: 1607713344.148636s

49152/50000 [============================>.] - ETA: 0s - loss: 1.3374 - accuracy: 0.1003
on_train_batch_begin: 1607713344.149062s

48 step training time: 0.738595s

on_train_batch_end: 1607713344.769917s

on_test_batch_begin: 1607713344.783419s

49 step training time: 0.634356s

on_epoch_end: 1607713346.675236s

Validation time: 1.891796s

Real time: 1607713346.675236s

Epoch time: 37.736228227615356s

50000/50000 [==============================] - 38s 755us/sample - loss: 1.3353 - accuracy: 0.1003 - val_loss: 7.0588 - val_accuracy: 0.0999
Tempo do fit: 232.6567506790161