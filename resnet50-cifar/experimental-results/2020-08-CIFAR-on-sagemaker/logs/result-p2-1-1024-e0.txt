wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:50
   221184/170498071 [..............................] - ETA: 1:12
  1032192/170498071 [..............................] - ETA: 23s 
  3760128/170498071 [..............................] - ETA: 8s 
  7069696/170498071 [>.............................] - ETA: 5s
 10346496/170498071 [>.............................] - ETA: 4s
 13631488/170498071 [=>............................] - ETA: 3s
 16941056/170498071 [=>............................] - ETA: 3s
 20217856/170498071 [==>...........................] - ETA: 3s
 23511040/170498071 [===>..........................] - ETA: 3s
 26828800/170498071 [===>..........................] - ETA: 2s
 29990912/170498071 [====>.........................] - ETA: 2s
 33136640/170498071 [====>.........................] - ETA: 2s
 36315136/170498071 [=====>........................] - ETA: 2s
 39510016/170498071 [=====>........................] - ETA: 2s
 42819584/170498071 [======>.......................] - ETA: 2s
 46055424/170498071 [=======>......................] - ETA: 2s
 49258496/170498071 [=======>......................] - ETA: 2s
 52518912/170498071 [========>.....................] - ETA: 2s
 55640064/170498071 [========>.....................] - ETA: 2s
 59088896/170498071 [=========>....................] - ETA: 1s
 62373888/170498071 [=========>....................] - ETA: 1s
 65724416/170498071 [==========>...................] - ETA: 1s
 68993024/170498071 [===========>..................] - ETA: 1s
 72278016/170498071 [===========>..................] - ETA: 1s
 75423744/170498071 [============>.................] - ETA: 1s
 78618624/170498071 [============>.................] - ETA: 1s
 81829888/170498071 [=============>................] - ETA: 1s
 85073920/170498071 [=============>................] - ETA: 1s
 88301568/170498071 [==============>...............] - ETA: 1s
 91496448/170498071 [===============>..............] - ETA: 1s
 94756864/170498071 [===============>..............] - ETA: 1s
 98000896/170498071 [================>.............] - ETA: 1s
101261312/170498071 [================>.............] - ETA: 1s
104480768/170498071 [=================>............] - ETA: 1s
107741184/170498071 [=================>............] - ETA: 1s
111009792/170498071 [==================>...........] - ETA: 0s
114253824/170498071 [===================>..........] - ETA: 0s
117481472/170498071 [===================>..........] - ETA: 0s
120741888/170498071 [====================>.........] - ETA: 0s
124018688/170498071 [====================>.........] - ETA: 0s
127213568/170498071 [=====================>........] - ETA: 0s
130465792/170498071 [=====================>........] - ETA: 0s
133611520/170498071 [======================>.......] - ETA: 0s
136912896/170498071 [=======================>......] - ETA: 0s
140214272/170498071 [=======================>......] - ETA: 0s
143482880/170498071 [========================>.....] - ETA: 0s
146694144/170498071 [========================>.....] - ETA: 0s
149938176/170498071 [=========================>....] - ETA: 0s
153182208/170498071 [=========================>....] - ETA: 0s
156467200/170498071 [==========================>...] - ETA: 0s
159711232/170498071 [===========================>..] - ETA: 0s
162988032/170498071 [===========================>..] - ETA: 0s
166256640/170498071 [============================>.] - ETA: 0s
169476096/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 4s
 3989504/94765736 [>.............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 1s
16015360/94765736 [====>.........................] - ETA: 0s
18792448/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 1s
24780800/94765736 [======>.......................] - ETA: 0s
28950528/94765736 [========>.....................] - ETA: 0s
33579008/94765736 [=========>....................] - ETA: 0s
38658048/94765736 [===========>..................] - ETA: 0s
39763968/94765736 [===========>..................] - ETA: 0s
45187072/94765736 [=============>................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
48324608/94765736 [==============>...............] - ETA: 0s
53960704/94765736 [================>.............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
61808640/94765736 [==================>...........] - ETA: 0s
67158016/94765736 [====================>.........] - ETA: 0s
71925760/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
81297408/94765736 [========================>.....] - ETA: 0s
87736320/94765736 [==========================>...] - ETA: 0s
87777280/94765736 [==========================>...] - ETA: 0s
92618752/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 15.439917087554932
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598428394.151535s

Real time: 1598428394.1515703
Epoch 1/5

on_train_batch_begin: 1598428394.993649s

on_train_batch_end: 1598428417.944854s

 1024/50000 [..............................] - ETA: 18:58 - loss: 17.6144 - accuracy: 3.1948e-04
on_train_batch_begin: 1598428417.945611s

1 step training time: 22.951962s

on_train_batch_end: 1598428418.665357s

 2048/50000 [>.............................] - ETA: 9:33 - loss: 15.1332 - accuracy: 2.8563e-04 
on_train_batch_begin: 1598428418.665771s

2 step training time: 0.720160s

on_train_batch_end: 1598428419.381023s

 3072/50000 [>.............................] - ETA: 6:25 - loss: 13.0606 - accuracy: 4.7429e-04
on_train_batch_begin: 1598428419.381418s

3 step training time: 0.715647s

on_train_batch_end: 1598428420.093360s

 4096/50000 [=>............................] - ETA: 4:50 - loss: 11.8859 - accuracy: 0.0014    
on_train_batch_begin: 1598428420.093751s

4 step training time: 0.712333s

on_train_batch_end: 1598428420.806161s

 5120/50000 [==>...........................] - ETA: 3:53 - loss: 11.1265 - accuracy: 0.0023
on_train_batch_begin: 1598428420.806551s

5 step training time: 0.712799s

on_train_batch_end: 1598428421.520158s

 6144/50000 [==>...........................] - ETA: 3:15 - loss: 10.5574 - accuracy: 0.0049
on_train_batch_begin: 1598428421.520577s

6 step training time: 0.714027s

on_train_batch_end: 1598428422.246034s

 7168/50000 [===>..........................] - ETA: 2:47 - loss: 10.1688 - accuracy: 0.0079
on_train_batch_begin: 1598428422.246450s

7 step training time: 0.725872s

on_train_batch_end: 1598428422.963686s

 8192/50000 [===>..........................] - ETA: 2:27 - loss: 9.8581 - accuracy: 0.0108 
on_train_batch_begin: 1598428422.964065s

8 step training time: 0.717615s

on_train_batch_end: 1598428423.679583s

 9216/50000 [====>.........................] - ETA: 2:10 - loss: 9.6095 - accuracy: 0.0137
on_train_batch_begin: 1598428423.679976s

9 step training time: 0.715911s

on_train_batch_end: 1598428424.389459s

10240/50000 [=====>........................] - ETA: 1:57 - loss: 9.4024 - accuracy: 0.0160
on_train_batch_begin: 1598428424.389848s

10 step training time: 0.709872s

on_train_batch_end: 1598428425.101188s

11264/50000 [=====>........................] - ETA: 1:46 - loss: 9.2169 - accuracy: 0.0181
on_train_batch_begin: 1598428425.101568s

11 step training time: 0.711720s

on_train_batch_end: 1598428425.810184s

12288/50000 [======>.......................] - ETA: 1:37 - loss: 9.0518 - accuracy: 0.0212
on_train_batch_begin: 1598428425.810584s

12 step training time: 0.709016s

on_train_batch_end: 1598428426.520461s

13312/50000 [======>.......................] - ETA: 1:29 - loss: 8.9052 - accuracy: 0.0227
on_train_batch_begin: 1598428426.520843s

13 step training time: 0.710259s

on_train_batch_end: 1598428427.243763s

14336/50000 [=======>......................] - ETA: 1:22 - loss: 8.7763 - accuracy: 0.0253
on_train_batch_begin: 1598428427.244156s

14 step training time: 0.723313s

on_train_batch_end: 1598428427.965772s

15360/50000 [========>.....................] - ETA: 1:16 - loss: 8.6604 - accuracy: 0.0281
on_train_batch_begin: 1598428427.966159s

15 step training time: 0.722003s

on_train_batch_end: 1598428428.688965s

16384/50000 [========>.....................] - ETA: 1:10 - loss: 8.5576 - accuracy: 0.0298
on_train_batch_begin: 1598428428.689362s

16 step training time: 0.723204s

on_train_batch_end: 1598428429.407602s

17408/50000 [=========>....................] - ETA: 1:06 - loss: 8.4717 - accuracy: 0.0308
on_train_batch_begin: 1598428429.407995s

17 step training time: 0.718632s

on_train_batch_end: 1598428430.119581s

18432/50000 [==========>...................] - ETA: 1:01 - loss: 8.3883 - accuracy: 0.0314
on_train_batch_begin: 1598428430.119968s

18 step training time: 0.711973s

on_train_batch_end: 1598428430.827525s

19456/50000 [==========>...................] - ETA: 57s - loss: 8.3089 - accuracy: 0.0324 
on_train_batch_begin: 1598428430.827914s

19 step training time: 0.707947s

on_train_batch_end: 1598428431.535270s

20480/50000 [===========>..................] - ETA: 53s - loss: 8.2252 - accuracy: 0.0331
on_train_batch_begin: 1598428431.535682s

20 step training time: 0.707767s

on_train_batch_end: 1598428432.253614s

21504/50000 [===========>..................] - ETA: 50s - loss: 8.1371 - accuracy: 0.0337
on_train_batch_begin: 1598428432.254011s

21 step training time: 0.718330s

on_train_batch_end: 1598428432.973577s

22528/50000 [============>.................] - ETA: 47s - loss: 8.0630 - accuracy: 0.0344
on_train_batch_begin: 1598428432.973952s

22 step training time: 0.719940s

on_train_batch_end: 1598428433.690537s

23552/50000 [=============>................] - ETA: 44s - loss: 7.9845 - accuracy: 0.0352
on_train_batch_begin: 1598428433.690993s

23 step training time: 0.717041s

on_train_batch_end: 1598428434.411340s

24576/50000 [=============>................] - ETA: 41s - loss: 7.9204 - accuracy: 0.0364
on_train_batch_begin: 1598428434.411741s

24 step training time: 0.720748s

on_train_batch_end: 1598428435.125390s

25600/50000 [==============>...............] - ETA: 39s - loss: 7.8612 - accuracy: 0.0370
on_train_batch_begin: 1598428435.125782s

25 step training time: 0.714041s

on_train_batch_end: 1598428435.841177s

26624/50000 [==============>...............] - ETA: 36s - loss: 7.7937 - accuracy: 0.0379
on_train_batch_begin: 1598428435.841561s

26 step training time: 0.715780s

on_train_batch_end: 1598428436.552399s

27648/50000 [===============>..............] - ETA: 34s - loss: 7.7353 - accuracy: 0.0386
on_train_batch_begin: 1598428436.552807s

27 step training time: 0.711246s

on_train_batch_end: 1598428437.268893s

28672/50000 [================>.............] - ETA: 32s - loss: 7.6768 - accuracy: 0.0392
on_train_batch_begin: 1598428437.269295s

28 step training time: 0.716488s

on_train_batch_end: 1598428437.985596s

29696/50000 [================>.............] - ETA: 29s - loss: 7.6121 - accuracy: 0.0395
on_train_batch_begin: 1598428437.986008s

29 step training time: 0.716712s

on_train_batch_end: 1598428438.710556s

30720/50000 [=================>............] - ETA: 27s - loss: 7.5556 - accuracy: 0.0401
on_train_batch_begin: 1598428438.710993s

30 step training time: 0.724985s

on_train_batch_end: 1598428439.434231s

31744/50000 [==================>...........] - ETA: 26s - loss: 7.4949 - accuracy: 0.0405
on_train_batch_begin: 1598428439.434614s

31 step training time: 0.723621s

on_train_batch_end: 1598428440.154111s

32768/50000 [==================>...........] - ETA: 24s - loss: 7.4393 - accuracy: 0.0408
on_train_batch_begin: 1598428440.154490s

32 step training time: 0.719876s

on_train_batch_end: 1598428440.869469s

33792/50000 [===================>..........] - ETA: 22s - loss: 7.3874 - accuracy: 0.0410
on_train_batch_begin: 1598428440.869861s

33 step training time: 0.715372s

on_train_batch_end: 1598428441.591896s

34816/50000 [===================>..........] - ETA: 20s - loss: 7.3261 - accuracy: 0.0416
on_train_batch_begin: 1598428441.592294s

34 step training time: 0.722433s

on_train_batch_end: 1598428442.319286s

35840/50000 [====================>.........] - ETA: 19s - loss: 7.2704 - accuracy: 0.0422
on_train_batch_begin: 1598428442.319663s

35 step training time: 0.727368s

on_train_batch_end: 1598428443.038612s

36864/50000 [=====================>........] - ETA: 17s - loss: 7.2155 - accuracy: 0.0428
on_train_batch_begin: 1598428443.039027s

36 step training time: 0.719364s

on_train_batch_end: 1598428443.760433s

37888/50000 [=====================>........] - ETA: 15s - loss: 7.1630 - accuracy: 0.0433
on_train_batch_begin: 1598428443.760827s

37 step training time: 0.721800s

on_train_batch_end: 1598428444.479342s

38912/50000 [======================>.......] - ETA: 14s - loss: 7.1109 - accuracy: 0.0439
on_train_batch_begin: 1598428444.479738s

38 step training time: 0.718910s

on_train_batch_end: 1598428445.203825s

39936/50000 [======================>.......] - ETA: 12s - loss: 7.0597 - accuracy: 0.0443
on_train_batch_begin: 1598428445.204203s

39 step training time: 0.724465s

on_train_batch_end: 1598428445.923282s

40960/50000 [=======================>......] - ETA: 11s - loss: 7.0091 - accuracy: 0.0448
on_train_batch_begin: 1598428445.923674s

40 step training time: 0.719471s

on_train_batch_end: 1598428446.643958s

41984/50000 [========================>.....] - ETA: 10s - loss: 6.9595 - accuracy: 0.0453
on_train_batch_begin: 1598428446.644334s

41 step training time: 0.720660s

on_train_batch_end: 1598428447.363205s

43008/50000 [========================>.....] - ETA: 8s - loss: 6.9102 - accuracy: 0.0458 
on_train_batch_begin: 1598428447.363590s

42 step training time: 0.719256s

on_train_batch_end: 1598428448.073739s

44032/50000 [=========================>....] - ETA: 7s - loss: 6.8580 - accuracy: 0.0465
on_train_batch_begin: 1598428448.074118s

43 step training time: 0.710528s

on_train_batch_end: 1598428448.787350s

45056/50000 [==========================>...] - ETA: 5s - loss: 6.8132 - accuracy: 0.0469
on_train_batch_begin: 1598428448.787756s

44 step training time: 0.713638s

on_train_batch_end: 1598428449.499626s

46080/50000 [==========================>...] - ETA: 4s - loss: 6.7671 - accuracy: 0.0475
on_train_batch_begin: 1598428449.500013s

45 step training time: 0.712257s

on_train_batch_end: 1598428450.217715s

47104/50000 [===========================>..] - ETA: 3s - loss: 6.7217 - accuracy: 0.0480
on_train_batch_begin: 1598428450.218092s

46 step training time: 0.718080s

on_train_batch_end: 1598428450.944275s

48128/50000 [===========================>..] - ETA: 2s - loss: 6.6752 - accuracy: 0.0486
on_train_batch_begin: 1598428450.944654s

47 step training time: 0.726561s

on_train_batch_end: 1598428451.672917s

49152/50000 [============================>.] - ETA: 0s - loss: 6.6267 - accuracy: 0.0491
on_train_batch_begin: 1598428451.673326s

48 step training time: 0.728672s

on_train_batch_end: 1598428459.440983s

on_test_batch_begin: 1598428459.664031s

49 step training time: 7.990706s

on_epoch_end: 1598428465.795230s

Validation time: 6.131177s

Real time: 1598428465.795230s

Epoch time: 71.64368200302124s

50000/50000 [==============================] - 72s 1ms/sample - loss: 6.5931 - accuracy: 0.0495 - val_loss: 4734.4927 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598428465.795530s

Real time: 1598428465.7955425
Epoch 2/5

on_train_batch_begin: 1598428465.800080s

on_train_batch_end: 1598428466.530721s

 1024/50000 [..............................] - ETA: 35s - loss: 4.5664 - accuracy: 0.0735
on_train_batch_begin: 1598428466.531153s

1 step training time: 0.731073s

on_train_batch_end: 1598428467.250197s

 2048/50000 [>.............................] - ETA: 34s - loss: 4.5154 - accuracy: 0.0731
on_train_batch_begin: 1598428467.250575s

2 step training time: 0.719422s

on_train_batch_end: 1598428467.966510s

 3072/50000 [>.............................] - ETA: 33s - loss: 4.3971 - accuracy: 0.0759
on_train_batch_begin: 1598428467.966944s

3 step training time: 0.716369s

on_train_batch_end: 1598428468.686294s

 4096/50000 [=>............................] - ETA: 32s - loss: 4.3469 - accuracy: 0.0774
on_train_batch_begin: 1598428468.686693s

4 step training time: 0.719749s

on_train_batch_end: 1598428469.408446s

 5120/50000 [==>...........................] - ETA: 31s - loss: 4.3239 - accuracy: 0.0789
on_train_batch_begin: 1598428469.408882s

5 step training time: 0.722189s

on_train_batch_end: 1598428470.143415s

 6144/50000 [==>...........................] - ETA: 31s - loss: 4.2771 - accuracy: 0.0799
on_train_batch_begin: 1598428470.143790s

6 step training time: 0.734908s

on_train_batch_end: 1598428470.864617s

 7168/50000 [===>..........................] - ETA: 30s - loss: 4.2266 - accuracy: 0.0809
on_train_batch_begin: 1598428470.865004s

7 step training time: 0.721214s

on_train_batch_end: 1598428471.587670s

 8192/50000 [===>..........................] - ETA: 29s - loss: 4.2021 - accuracy: 0.0811
on_train_batch_begin: 1598428471.588072s

8 step training time: 0.723068s

on_train_batch_end: 1598428472.316362s

 9216/50000 [====>.........................] - ETA: 28s - loss: 4.1846 - accuracy: 0.0816
on_train_batch_begin: 1598428472.316748s

9 step training time: 0.728676s

on_train_batch_end: 1598428473.043138s

10240/50000 [=====>........................] - ETA: 28s - loss: 4.1613 - accuracy: 0.0825
on_train_batch_begin: 1598428473.043523s

10 step training time: 0.726775s

on_train_batch_end: 1598428473.765265s

11264/50000 [=====>........................] - ETA: 27s - loss: 4.1418 - accuracy: 0.0832
on_train_batch_begin: 1598428473.765677s

11 step training time: 0.722154s

on_train_batch_end: 1598428474.492936s

12288/50000 [======>.......................] - ETA: 26s - loss: 4.1293 - accuracy: 0.0836
on_train_batch_begin: 1598428474.493344s

12 step training time: 0.727667s

on_train_batch_end: 1598428475.212003s

13312/50000 [======>.......................] - ETA: 25s - loss: 4.1103 - accuracy: 0.0839
on_train_batch_begin: 1598428475.212392s

13 step training time: 0.719048s

on_train_batch_end: 1598428475.932071s

14336/50000 [=======>......................] - ETA: 25s - loss: 4.0872 - accuracy: 0.0840
on_train_batch_begin: 1598428475.932469s

14 step training time: 0.720077s

on_train_batch_end: 1598428476.657501s

15360/50000 [========>.....................] - ETA: 24s - loss: 4.0480 - accuracy: 0.0846
on_train_batch_begin: 1598428476.657885s

15 step training time: 0.725416s

on_train_batch_end: 1598428477.378106s

16384/50000 [========>.....................] - ETA: 23s - loss: 3.9989 - accuracy: 0.0852
on_train_batch_begin: 1598428477.378475s

16 step training time: 0.720591s

on_train_batch_end: 1598428478.099586s

17408/50000 [=========>....................] - ETA: 23s - loss: 3.9572 - accuracy: 0.0858
on_train_batch_begin: 1598428478.099989s

17 step training time: 0.721514s

on_train_batch_end: 1598428478.816349s

18432/50000 [==========>...................] - ETA: 22s - loss: 3.9131 - accuracy: 0.0861
on_train_batch_begin: 1598428478.816736s

18 step training time: 0.716747s

on_train_batch_end: 1598428479.547218s

19456/50000 [==========>...................] - ETA: 21s - loss: 3.8875 - accuracy: 0.0863
on_train_batch_begin: 1598428479.547595s

19 step training time: 0.730859s

on_train_batch_end: 1598428480.278559s

20480/50000 [===========>..................] - ETA: 20s - loss: 3.8612 - accuracy: 0.0866
on_train_batch_begin: 1598428480.278992s

20 step training time: 0.731397s

on_train_batch_end: 1598428481.005696s

21504/50000 [===========>..................] - ETA: 20s - loss: 3.8265 - accuracy: 0.0870
on_train_batch_begin: 1598428481.006076s

21 step training time: 0.727083s

on_train_batch_end: 1598428481.732259s

22528/50000 [============>.................] - ETA: 19s - loss: 3.7912 - accuracy: 0.0873
on_train_batch_begin: 1598428481.732664s

22 step training time: 0.726588s

on_train_batch_end: 1598428482.457588s

23552/50000 [=============>................] - ETA: 18s - loss: 3.7599 - accuracy: 0.0877
on_train_batch_begin: 1598428482.458007s

23 step training time: 0.725343s

on_train_batch_end: 1598428483.184970s

24576/50000 [=============>................] - ETA: 17s - loss: 3.7262 - accuracy: 0.0881
on_train_batch_begin: 1598428483.185343s

24 step training time: 0.727336s

on_train_batch_end: 1598428483.909720s

25600/50000 [==============>...............] - ETA: 17s - loss: 3.6932 - accuracy: 0.0884
on_train_batch_begin: 1598428483.910123s

25 step training time: 0.724779s

on_train_batch_end: 1598428484.627681s

26624/50000 [==============>...............] - ETA: 16s - loss: 3.6580 - accuracy: 0.0888
on_train_batch_begin: 1598428484.628085s

26 step training time: 0.717962s

on_train_batch_end: 1598428485.357032s

27648/50000 [===============>..............] - ETA: 15s - loss: 3.6258 - accuracy: 0.0892
on_train_batch_begin: 1598428485.357416s

27 step training time: 0.729331s

on_train_batch_end: 1598428486.080703s

28672/50000 [================>.............] - ETA: 15s - loss: 3.5943 - accuracy: 0.0895
on_train_batch_begin: 1598428486.081086s

28 step training time: 0.723669s

on_train_batch_end: 1598428486.808856s

29696/50000 [================>.............] - ETA: 14s - loss: 3.5695 - accuracy: 0.0897
on_train_batch_begin: 1598428486.809245s

29 step training time: 0.728159s

on_train_batch_end: 1598428487.539299s

30720/50000 [=================>............] - ETA: 13s - loss: 3.5420 - accuracy: 0.0900
on_train_batch_begin: 1598428487.539686s

30 step training time: 0.730441s

on_train_batch_end: 1598428488.272408s

31744/50000 [==================>...........] - ETA: 12s - loss: 3.5124 - accuracy: 0.0903
on_train_batch_begin: 1598428488.272795s

31 step training time: 0.733109s

on_train_batch_end: 1598428489.003112s

32768/50000 [==================>...........] - ETA: 12s - loss: 3.4816 - accuracy: 0.0905
on_train_batch_begin: 1598428489.003517s

32 step training time: 0.730721s

on_train_batch_end: 1598428489.736737s

33792/50000 [===================>..........] - ETA: 11s - loss: 3.4562 - accuracy: 0.0907
on_train_batch_begin: 1598428489.737127s

33 step training time: 0.733610s

on_train_batch_end: 1598428490.462918s

34816/50000 [===================>..........] - ETA: 10s - loss: 3.4274 - accuracy: 0.0910
on_train_batch_begin: 1598428490.463305s

34 step training time: 0.726179s

on_train_batch_end: 1598428491.199760s

35840/50000 [====================>.........] - ETA: 10s - loss: 3.4046 - accuracy: 0.0912
on_train_batch_begin: 1598428491.200150s

35 step training time: 0.736845s

on_train_batch_end: 1598428491.943170s

36864/50000 [=====================>........] - ETA: 9s - loss: 3.3830 - accuracy: 0.0914 
on_train_batch_begin: 1598428491.943544s

36 step training time: 0.743394s

on_train_batch_end: 1598428492.667099s

37888/50000 [=====================>........] - ETA: 8s - loss: 3.3550 - accuracy: 0.0916
on_train_batch_begin: 1598428492.667526s

37 step training time: 0.723982s

on_train_batch_end: 1598428493.400263s

38912/50000 [======================>.......] - ETA: 7s - loss: 3.3327 - accuracy: 0.0918
on_train_batch_begin: 1598428493.400648s

38 step training time: 0.733122s

on_train_batch_end: 1598428494.142478s

39936/50000 [======================>.......] - ETA: 7s - loss: 3.3099 - accuracy: 0.0920
on_train_batch_begin: 1598428494.143051s

39 step training time: 0.742403s

on_train_batch_end: 1598428494.877953s

40960/50000 [=======================>......] - ETA: 6s - loss: 3.2821 - accuracy: 0.0922
on_train_batch_begin: 1598428494.878329s

40 step training time: 0.735278s

on_train_batch_end: 1598428495.616792s

41984/50000 [========================>.....] - ETA: 5s - loss: 3.2594 - accuracy: 0.0924
on_train_batch_begin: 1598428495.617169s

41 step training time: 0.738840s

on_train_batch_end: 1598428496.353722s

43008/50000 [========================>.....] - ETA: 4s - loss: 3.2411 - accuracy: 0.0926
on_train_batch_begin: 1598428496.354107s

42 step training time: 0.736938s

on_train_batch_end: 1598428497.086755s

44032/50000 [=========================>....] - ETA: 4s - loss: 3.2159 - accuracy: 0.0928
on_train_batch_begin: 1598428497.087169s

43 step training time: 0.733062s

on_train_batch_end: 1598428497.821245s

45056/50000 [==========================>...] - ETA: 3s - loss: 3.1936 - accuracy: 0.0929
on_train_batch_begin: 1598428497.821652s

44 step training time: 0.734483s

on_train_batch_end: 1598428498.554795s

46080/50000 [==========================>...] - ETA: 2s - loss: 3.1751 - accuracy: 0.0931
on_train_batch_begin: 1598428498.555216s

45 step training time: 0.733564s

on_train_batch_end: 1598428499.283344s

47104/50000 [===========================>..] - ETA: 2s - loss: 3.1520 - accuracy: 0.0932
on_train_batch_begin: 1598428499.283735s

46 step training time: 0.728518s

on_train_batch_end: 1598428500.023978s

48128/50000 [===========================>..] - ETA: 1s - loss: 3.1331 - accuracy: 0.0934
on_train_batch_begin: 1598428500.024359s

47 step training time: 0.740625s

on_train_batch_end: 1598428500.761563s

49152/50000 [============================>.] - ETA: 0s - loss: 3.1132 - accuracy: 0.0935
on_train_batch_begin: 1598428500.761977s

48 step training time: 0.737617s

on_train_batch_end: 1598428501.392553s

on_test_batch_begin: 1598428501.406602s

49 step training time: 0.644626s

on_epoch_end: 1598428503.306247s

Validation time: 1.899621s

Real time: 1598428503.306247s

Epoch time: 37.51072716712952s

50000/50000 [==============================] - 38s 750us/sample - loss: 3.0964 - accuracy: 0.0936 - val_loss: 7.7100 - val_accuracy: 0.1000

on_epoch_begin: 1598428503.306495s

Real time: 1598428503.3065042
Epoch 3/5

on_train_batch_begin: 1598428503.310803s

on_train_batch_end: 1598428504.067559s

 1024/50000 [..............................] - ETA: 36s - loss: 2.0311 - accuracy: 0.1008
on_train_batch_begin: 1598428504.067934s

1 step training time: 0.757131s

on_train_batch_end: 1598428504.816789s

 2048/50000 [>.............................] - ETA: 35s - loss: 2.0583 - accuracy: 0.1005
on_train_batch_begin: 1598428504.817168s

2 step training time: 0.749233s

on_train_batch_end: 1598428505.564895s

 3072/50000 [>.............................] - ETA: 34s - loss: 2.0301 - accuracy: 0.1001
on_train_batch_begin: 1598428505.565300s

3 step training time: 0.748133s

on_train_batch_end: 1598428506.305668s

 4096/50000 [=>............................] - ETA: 33s - loss: 2.0225 - accuracy: 0.1001
on_train_batch_begin: 1598428506.306103s

4 step training time: 0.740803s

on_train_batch_end: 1598428507.061151s

 5120/50000 [==>...........................] - ETA: 32s - loss: 2.0333 - accuracy: 0.1002
on_train_batch_begin: 1598428507.061534s

5 step training time: 0.755431s

on_train_batch_end: 1598428507.822528s

 6144/50000 [==>...........................] - ETA: 32s - loss: 2.0133 - accuracy: 0.1002
on_train_batch_begin: 1598428507.822929s

6 step training time: 0.761395s

on_train_batch_end: 1598428508.574188s

 7168/50000 [===>..........................] - ETA: 31s - loss: 2.0328 - accuracy: 0.1002
on_train_batch_begin: 1598428508.574580s

7 step training time: 0.751651s

on_train_batch_end: 1598428509.326013s

 8192/50000 [===>..........................] - ETA: 30s - loss: 2.0176 - accuracy: 0.1002
on_train_batch_begin: 1598428509.326387s

8 step training time: 0.751807s

on_train_batch_end: 1598428510.081701s

 9216/50000 [====>.........................] - ETA: 29s - loss: 2.0233 - accuracy: 0.1002
on_train_batch_begin: 1598428510.082090s

9 step training time: 0.755703s

on_train_batch_end: 1598428510.838755s

10240/50000 [=====>........................] - ETA: 29s - loss: 2.0048 - accuracy: 0.1002
on_train_batch_begin: 1598428510.839176s

10 step training time: 0.757086s

on_train_batch_end: 1598428511.596941s

11264/50000 [=====>........................] - ETA: 28s - loss: 1.9920 - accuracy: 0.1002
on_train_batch_begin: 1598428511.597322s

11 step training time: 0.758147s

on_train_batch_end: 1598428512.348687s

12288/50000 [======>.......................] - ETA: 27s - loss: 1.9834 - accuracy: 0.1003
on_train_batch_begin: 1598428512.349071s

12 step training time: 0.751749s

on_train_batch_end: 1598428513.102573s

13312/50000 [======>.......................] - ETA: 26s - loss: 1.9801 - accuracy: 0.1002
on_train_batch_begin: 1598428513.102983s

13 step training time: 0.753912s

on_train_batch_end: 1598428513.850598s

14336/50000 [=======>......................] - ETA: 26s - loss: 1.9600 - accuracy: 0.1002
on_train_batch_begin: 1598428513.851007s

14 step training time: 0.748024s

on_train_batch_end: 1598428514.597825s

15360/50000 [========>.....................] - ETA: 25s - loss: 1.9570 - accuracy: 0.1003
on_train_batch_begin: 1598428514.598220s

15 step training time: 0.747212s

on_train_batch_end: 1598428515.350838s

16384/50000 [========>.....................] - ETA: 24s - loss: 1.9498 - accuracy: 0.1003
on_train_batch_begin: 1598428515.351270s

16 step training time: 0.753051s

on_train_batch_end: 1598428516.100112s

17408/50000 [=========>....................] - ETA: 23s - loss: 1.9540 - accuracy: 0.1002
on_train_batch_begin: 1598428516.100546s

17 step training time: 0.749276s

on_train_batch_end: 1598428516.850508s

18432/50000 [==========>...................] - ETA: 23s - loss: 1.9453 - accuracy: 0.1002
on_train_batch_begin: 1598428516.850943s

18 step training time: 0.750397s

on_train_batch_end: 1598428517.616807s

19456/50000 [==========>...................] - ETA: 22s - loss: 1.9505 - accuracy: 0.1002
on_train_batch_begin: 1598428517.617239s

19 step training time: 0.766296s

on_train_batch_end: 1598428518.370903s

20480/50000 [===========>..................] - ETA: 21s - loss: 1.9562 - accuracy: 0.1002
on_train_batch_begin: 1598428518.371288s

20 step training time: 0.754049s

on_train_batch_end: 1598428519.128450s

21504/50000 [===========>..................] - ETA: 20s - loss: 1.9484 - accuracy: 0.1002
on_train_batch_begin: 1598428519.128836s

21 step training time: 0.757548s

on_train_batch_end: 1598428519.887441s

22528/50000 [============>.................] - ETA: 20s - loss: 1.9421 - accuracy: 0.1002
on_train_batch_begin: 1598428519.887829s

22 step training time: 0.758993s

on_train_batch_end: 1598428520.639431s

23552/50000 [=============>................] - ETA: 19s - loss: 1.9385 - accuracy: 0.1002
on_train_batch_begin: 1598428520.639847s

23 step training time: 0.752018s

on_train_batch_end: 1598428521.387961s

24576/50000 [=============>................] - ETA: 18s - loss: 1.9388 - accuracy: 0.1002
on_train_batch_begin: 1598428521.388353s

24 step training time: 0.748506s

on_train_batch_end: 1598428522.135595s

25600/50000 [==============>...............] - ETA: 17s - loss: 1.9427 - accuracy: 0.1002
on_train_batch_begin: 1598428522.135972s

25 step training time: 0.747619s

on_train_batch_end: 1598428522.883981s

26624/50000 [==============>...............] - ETA: 17s - loss: 1.9364 - accuracy: 0.1002
on_train_batch_begin: 1598428522.884377s

26 step training time: 0.748405s

on_train_batch_end: 1598428523.638325s

27648/50000 [===============>..............] - ETA: 16s - loss: 1.9387 - accuracy: 0.1002
on_train_batch_begin: 1598428523.638712s

27 step training time: 0.754335s

on_train_batch_end: 1598428524.393679s

28672/50000 [================>.............] - ETA: 15s - loss: 1.9363 - accuracy: 0.1002
on_train_batch_begin: 1598428524.394099s

28 step training time: 0.755387s

on_train_batch_end: 1598428525.155666s

29696/50000 [================>.............] - ETA: 14s - loss: 1.9357 - accuracy: 0.1002
on_train_batch_begin: 1598428525.156045s

29 step training time: 0.761946s

on_train_batch_end: 1598428525.908199s

30720/50000 [=================>............] - ETA: 14s - loss: 1.9308 - accuracy: 0.1002
on_train_batch_begin: 1598428525.908584s

30 step training time: 0.752539s

on_train_batch_end: 1598428526.664703s

31744/50000 [==================>...........] - ETA: 13s - loss: 1.9305 - accuracy: 0.1002
on_train_batch_begin: 1598428526.665081s

31 step training time: 0.756497s

on_train_batch_end: 1598428527.419693s

32768/50000 [==================>...........] - ETA: 12s - loss: 1.9299 - accuracy: 0.1002
on_train_batch_begin: 1598428527.420106s

32 step training time: 0.755025s

on_train_batch_end: 1598428528.179639s

33792/50000 [===================>..........] - ETA: 11s - loss: 1.9268 - accuracy: 0.1002
on_train_batch_begin: 1598428528.180026s

33 step training time: 0.759920s

on_train_batch_end: 1598428528.931988s

34816/50000 [===================>..........] - ETA: 11s - loss: 1.9217 - accuracy: 0.1002
on_train_batch_begin: 1598428528.932370s

34 step training time: 0.752344s

on_train_batch_end: 1598428529.683246s

35840/50000 [====================>.........] - ETA: 10s - loss: 1.9218 - accuracy: 0.1002
on_train_batch_begin: 1598428529.683650s

35 step training time: 0.751280s

on_train_batch_end: 1598428530.429505s

36864/50000 [=====================>........] - ETA: 9s - loss: 1.9181 - accuracy: 0.1002 
on_train_batch_begin: 1598428530.429889s

36 step training time: 0.746239s

on_train_batch_end: 1598428531.187049s

37888/50000 [=====================>........] - ETA: 8s - loss: 1.9122 - accuracy: 0.1002
on_train_batch_begin: 1598428531.187438s

37 step training time: 0.757550s

on_train_batch_end: 1598428531.943488s

38912/50000 [======================>.......] - ETA: 8s - loss: 1.9096 - accuracy: 0.1002
on_train_batch_begin: 1598428531.943871s

38 step training time: 0.756433s

on_train_batch_end: 1598428532.709423s

39936/50000 [======================>.......] - ETA: 7s - loss: 1.9044 - accuracy: 0.1002
on_train_batch_begin: 1598428532.709815s

39 step training time: 0.765944s

on_train_batch_end: 1598428533.472972s

40960/50000 [=======================>......] - ETA: 6s - loss: 1.8968 - accuracy: 0.1002
on_train_batch_begin: 1598428533.473348s

40 step training time: 0.763533s

on_train_batch_end: 1598428534.219695s

41984/50000 [========================>.....] - ETA: 5s - loss: 1.8909 - accuracy: 0.1002
on_train_batch_begin: 1598428534.220087s

41 step training time: 0.746739s

on_train_batch_end: 1598428534.969413s

43008/50000 [========================>.....] - ETA: 5s - loss: 1.8823 - accuracy: 0.1002
on_train_batch_begin: 1598428534.969795s

42 step training time: 0.749708s

on_train_batch_end: 1598428535.717841s

44032/50000 [=========================>....] - ETA: 4s - loss: 1.8701 - accuracy: 0.1002
on_train_batch_begin: 1598428535.718234s

43 step training time: 0.748440s

on_train_batch_end: 1598428536.470835s

45056/50000 [==========================>...] - ETA: 3s - loss: 1.8610 - accuracy: 0.1002
on_train_batch_begin: 1598428536.471248s

44 step training time: 0.753014s

on_train_batch_end: 1598428537.220323s

46080/50000 [==========================>...] - ETA: 2s - loss: 1.8552 - accuracy: 0.1002
on_train_batch_begin: 1598428537.220705s

45 step training time: 0.749457s

on_train_batch_end: 1598428537.974117s

47104/50000 [===========================>..] - ETA: 2s - loss: 1.8494 - accuracy: 0.1002
on_train_batch_begin: 1598428537.974495s

46 step training time: 0.753790s

on_train_batch_end: 1598428538.723090s

48128/50000 [===========================>..] - ETA: 1s - loss: 1.8427 - accuracy: 0.1002
on_train_batch_begin: 1598428538.723487s

47 step training time: 0.748992s

on_train_batch_end: 1598428539.469395s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8383 - accuracy: 0.1002
on_train_batch_begin: 1598428539.469770s

48 step training time: 0.746284s

on_train_batch_end: 1598428540.095989s

on_test_batch_begin: 1598428540.108876s

49 step training time: 0.639105s

on_epoch_end: 1598428541.992295s

Validation time: 1.883399s

Real time: 1598428541.992295s

Epoch time: 38.685813188552856s

50000/50000 [==============================] - 39s 774us/sample - loss: 1.8314 - accuracy: 0.1002 - val_loss: 6.0929 - val_accuracy: 0.0999

on_epoch_begin: 1598428541.992542s

Real time: 1598428541.9925508
Epoch 4/5

on_train_batch_begin: 1598428541.996886s

on_train_batch_end: 1598428542.728947s

 1024/50000 [..............................] - ETA: 35s - loss: 1.2547 - accuracy: 0.1002
on_train_batch_begin: 1598428542.729345s

1 step training time: 0.732459s

on_train_batch_end: 1598428543.460968s

 2048/50000 [>.............................] - ETA: 34s - loss: 1.2865 - accuracy: 0.1008
on_train_batch_begin: 1598428543.461360s

2 step training time: 0.732015s

on_train_batch_end: 1598428544.195513s

 3072/50000 [>.............................] - ETA: 33s - loss: 1.2759 - accuracy: 0.1005
on_train_batch_begin: 1598428544.195898s

3 step training time: 0.734538s

on_train_batch_end: 1598428544.925069s

 4096/50000 [=>............................] - ETA: 32s - loss: 1.3068 - accuracy: 0.1005
on_train_batch_begin: 1598428544.925461s

4 step training time: 0.729563s

on_train_batch_end: 1598428545.659541s

 5120/50000 [==>...........................] - ETA: 32s - loss: 1.2933 - accuracy: 0.1004
on_train_batch_begin: 1598428545.659928s

5 step training time: 0.734467s

on_train_batch_end: 1598428546.400803s

 6144/50000 [==>...........................] - ETA: 31s - loss: 1.2783 - accuracy: 0.1003
on_train_batch_begin: 1598428546.401180s

6 step training time: 0.741252s

on_train_batch_end: 1598428547.142359s

 7168/50000 [===>..........................] - ETA: 30s - loss: 1.2896 - accuracy: 0.1003
on_train_batch_begin: 1598428547.142779s

7 step training time: 0.741598s

on_train_batch_end: 1598428547.866894s

 8192/50000 [===>..........................] - ETA: 29s - loss: 1.2774 - accuracy: 0.1003
on_train_batch_begin: 1598428547.867284s

8 step training time: 0.724506s

on_train_batch_end: 1598428548.605318s

 9216/50000 [====>.........................] - ETA: 29s - loss: 1.2743 - accuracy: 0.1003
on_train_batch_begin: 1598428548.605694s

9 step training time: 0.738410s

on_train_batch_end: 1598428549.336993s

10240/50000 [=====>........................] - ETA: 28s - loss: 1.2734 - accuracy: 0.1003
on_train_batch_begin: 1598428549.337368s

10 step training time: 0.731673s

on_train_batch_end: 1598428550.069129s

11264/50000 [=====>........................] - ETA: 27s - loss: 1.2689 - accuracy: 0.1004
on_train_batch_begin: 1598428550.069537s

11 step training time: 0.732170s

on_train_batch_end: 1598428550.801399s

12288/50000 [======>.......................] - ETA: 27s - loss: 1.2620 - accuracy: 0.1004
on_train_batch_begin: 1598428550.801787s

12 step training time: 0.732249s

on_train_batch_end: 1598428551.536962s

13312/50000 [======>.......................] - ETA: 26s - loss: 1.2610 - accuracy: 0.1003
on_train_batch_begin: 1598428551.537364s

13 step training time: 0.735577s

on_train_batch_end: 1598428552.272869s

14336/50000 [=======>......................] - ETA: 25s - loss: 1.2516 - accuracy: 0.1004
on_train_batch_begin: 1598428552.273275s

14 step training time: 0.735911s

on_train_batch_end: 1598428552.997981s

15360/50000 [========>.....................] - ETA: 24s - loss: 1.2450 - accuracy: 0.1003
on_train_batch_begin: 1598428552.998362s

15 step training time: 0.725086s

on_train_batch_end: 1598428553.735837s

16384/50000 [========>.....................] - ETA: 24s - loss: 1.2410 - accuracy: 0.1003
on_train_batch_begin: 1598428553.736223s

16 step training time: 0.737862s

on_train_batch_end: 1598428554.465601s

17408/50000 [=========>....................] - ETA: 23s - loss: 1.2449 - accuracy: 0.1003
on_train_batch_begin: 1598428554.466003s

17 step training time: 0.729780s

on_train_batch_end: 1598428555.190739s

18432/50000 [==========>...................] - ETA: 22s - loss: 1.2370 - accuracy: 0.1003
on_train_batch_begin: 1598428555.191149s

18 step training time: 0.725146s

on_train_batch_end: 1598428555.925464s

19456/50000 [==========>...................] - ETA: 21s - loss: 1.2307 - accuracy: 0.1003
on_train_batch_begin: 1598428555.925847s

19 step training time: 0.734698s

on_train_batch_end: 1598428556.659442s

20480/50000 [===========>..................] - ETA: 21s - loss: 1.2296 - accuracy: 0.1003
on_train_batch_begin: 1598428556.659833s

20 step training time: 0.733987s

on_train_batch_end: 1598428557.385464s

21504/50000 [===========>..................] - ETA: 20s - loss: 1.2239 - accuracy: 0.1003
on_train_batch_begin: 1598428557.385849s

21 step training time: 0.726016s

on_train_batch_end: 1598428558.110878s

22528/50000 [============>.................] - ETA: 19s - loss: 1.2226 - accuracy: 0.1003
on_train_batch_begin: 1598428558.111268s

22 step training time: 0.725419s

on_train_batch_end: 1598428558.845979s

23552/50000 [=============>................] - ETA: 18s - loss: 1.2228 - accuracy: 0.1003
on_train_batch_begin: 1598428558.846353s

23 step training time: 0.735085s

on_train_batch_end: 1598428559.574191s

24576/50000 [=============>................] - ETA: 18s - loss: 1.2190 - accuracy: 0.1003
on_train_batch_begin: 1598428559.574571s

24 step training time: 0.728218s

on_train_batch_end: 1598428560.305803s

25600/50000 [==============>...............] - ETA: 17s - loss: 1.2132 - accuracy: 0.1003
on_train_batch_begin: 1598428560.306190s

25 step training time: 0.731619s

on_train_batch_end: 1598428561.036492s

26624/50000 [==============>...............] - ETA: 16s - loss: 1.2088 - accuracy: 0.1003
on_train_batch_begin: 1598428561.036879s

26 step training time: 0.730690s

on_train_batch_end: 1598428561.768208s

27648/50000 [===============>..............] - ETA: 15s - loss: 1.2015 - accuracy: 0.1003
on_train_batch_begin: 1598428561.768588s

27 step training time: 0.731709s

on_train_batch_end: 1598428562.497484s

28672/50000 [================>.............] - ETA: 15s - loss: 1.1971 - accuracy: 0.1003
on_train_batch_begin: 1598428562.497859s

28 step training time: 0.729271s

on_train_batch_end: 1598428563.231145s

29696/50000 [================>.............] - ETA: 14s - loss: 1.1913 - accuracy: 0.1003
on_train_batch_begin: 1598428563.231543s

29 step training time: 0.733684s

on_train_batch_end: 1598428563.963571s

30720/50000 [=================>............] - ETA: 13s - loss: 1.1953 - accuracy: 0.1003
on_train_batch_begin: 1598428563.963953s

30 step training time: 0.732410s

on_train_batch_end: 1598428564.692050s

31744/50000 [==================>...........] - ETA: 13s - loss: 1.1898 - accuracy: 0.1003
on_train_batch_begin: 1598428564.692442s

31 step training time: 0.728489s

on_train_batch_end: 1598428565.421398s

32768/50000 [==================>...........] - ETA: 12s - loss: 1.1913 - accuracy: 0.1003
on_train_batch_begin: 1598428565.421778s

32 step training time: 0.729336s

on_train_batch_end: 1598428566.143652s

33792/50000 [===================>..........] - ETA: 11s - loss: 1.1905 - accuracy: 0.1003
on_train_batch_begin: 1598428566.144043s

33 step training time: 0.722265s

on_train_batch_end: 1598428566.872586s

34816/50000 [===================>..........] - ETA: 10s - loss: 1.1894 - accuracy: 0.1003
on_train_batch_begin: 1598428566.872966s

34 step training time: 0.728923s

on_train_batch_end: 1598428567.611374s

35840/50000 [====================>.........] - ETA: 10s - loss: 1.1842 - accuracy: 0.1003
on_train_batch_begin: 1598428567.611765s

35 step training time: 0.738799s

on_train_batch_end: 1598428568.342643s

36864/50000 [=====================>........] - ETA: 9s - loss: 1.1813 - accuracy: 0.1003 
on_train_batch_begin: 1598428568.343053s

36 step training time: 0.731288s

on_train_batch_end: 1598428569.075018s

37888/50000 [=====================>........] - ETA: 8s - loss: 1.1791 - accuracy: 0.1003
on_train_batch_begin: 1598428569.075405s

37 step training time: 0.732352s

on_train_batch_end: 1598428569.796874s

38912/50000 [======================>.......] - ETA: 7s - loss: 1.1743 - accuracy: 0.1003
on_train_batch_begin: 1598428569.797248s

38 step training time: 0.721843s

on_train_batch_end: 1598428570.528818s

39936/50000 [======================>.......] - ETA: 7s - loss: 1.1726 - accuracy: 0.1003
on_train_batch_begin: 1598428570.529202s

39 step training time: 0.731954s

on_train_batch_end: 1598428571.258034s

40960/50000 [=======================>......] - ETA: 6s - loss: 1.1703 - accuracy: 0.1004
on_train_batch_begin: 1598428571.258411s

40 step training time: 0.729209s

on_train_batch_end: 1598428571.985913s

41984/50000 [========================>.....] - ETA: 5s - loss: 1.1673 - accuracy: 0.1003
on_train_batch_begin: 1598428571.986286s

41 step training time: 0.727875s

on_train_batch_end: 1598428572.728367s

43008/50000 [========================>.....] - ETA: 4s - loss: 1.1631 - accuracy: 0.1003
on_train_batch_begin: 1598428572.728764s

42 step training time: 0.742478s

on_train_batch_end: 1598428573.463072s

44032/50000 [=========================>....] - ETA: 4s - loss: 1.1595 - accuracy: 0.1003
on_train_batch_begin: 1598428573.463459s

43 step training time: 0.734695s

on_train_batch_end: 1598428574.193815s

45056/50000 [==========================>...] - ETA: 3s - loss: 1.1591 - accuracy: 0.1003
on_train_batch_begin: 1598428574.194237s

44 step training time: 0.730778s

on_train_batch_end: 1598428574.925306s

46080/50000 [==========================>...] - ETA: 2s - loss: 1.1578 - accuracy: 0.1004
on_train_batch_begin: 1598428574.925863s

45 step training time: 0.731626s

on_train_batch_end: 1598428575.657044s

47104/50000 [===========================>..] - ETA: 2s - loss: 1.1578 - accuracy: 0.1004
on_train_batch_begin: 1598428575.657430s

46 step training time: 0.731567s

on_train_batch_end: 1598428576.388963s

48128/50000 [===========================>..] - ETA: 1s - loss: 1.1583 - accuracy: 0.1003
on_train_batch_begin: 1598428576.389379s

47 step training time: 0.731949s

on_train_batch_end: 1598428577.122672s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1549 - accuracy: 0.1004
on_train_batch_begin: 1598428577.123162s

48 step training time: 0.733783s

on_train_batch_end: 1598428577.746464s

on_test_batch_begin: 1598428577.761975s

49 step training time: 0.638813s

on_epoch_end: 1598428579.629455s

Validation time: 1.867459s

Real time: 1598428579.629455s

Epoch time: 37.63692545890808s

50000/50000 [==============================] - 38s 753us/sample - loss: 1.1532 - accuracy: 0.1004 - val_loss: 7.0768 - val_accuracy: 0.1000

on_epoch_begin: 1598428579.629701s

Real time: 1598428579.6297112
Epoch 5/5

on_train_batch_begin: 1598428579.633940s

on_train_batch_end: 1598428580.375436s

 1024/50000 [..............................] - ETA: 35s - loss: 0.7960 - accuracy: 0.1002
on_train_batch_begin: 1598428580.375818s

1 step training time: 0.741878s

on_train_batch_end: 1598428581.111006s

 2048/50000 [>.............................] - ETA: 34s - loss: 0.8373 - accuracy: 0.1004
on_train_batch_begin: 1598428581.111523s

2 step training time: 0.735706s

on_train_batch_end: 1598428581.846962s

 3072/50000 [>.............................] - ETA: 33s - loss: 0.8158 - accuracy: 0.1004
on_train_batch_begin: 1598428581.847389s

3 step training time: 0.735866s

on_train_batch_end: 1598428582.592296s

 4096/50000 [=>............................] - ETA: 33s - loss: 0.8328 - accuracy: 0.1004
on_train_batch_begin: 1598428582.592707s

4 step training time: 0.745318s

on_train_batch_end: 1598428583.324228s

 5120/50000 [==>...........................] - ETA: 32s - loss: 0.8260 - accuracy: 0.1003
on_train_batch_begin: 1598428583.324598s

5 step training time: 0.731891s

on_train_batch_end: 1598428584.060073s

 6144/50000 [==>...........................] - ETA: 31s - loss: 0.8016 - accuracy: 0.1003
on_train_batch_begin: 1598428584.060473s

6 step training time: 0.735875s

on_train_batch_end: 1598428584.805858s

 7168/50000 [===>..........................] - ETA: 30s - loss: 0.8090 - accuracy: 0.1003
on_train_batch_begin: 1598428584.806231s

7 step training time: 0.745758s

on_train_batch_end: 1598428585.536710s

 8192/50000 [===>..........................] - ETA: 30s - loss: 0.8036 - accuracy: 0.1003
on_train_batch_begin: 1598428585.537087s

8 step training time: 0.730855s

on_train_batch_end: 1598428586.282771s

 9216/50000 [====>.........................] - ETA: 29s - loss: 0.8047 - accuracy: 0.1003
on_train_batch_begin: 1598428586.283191s

9 step training time: 0.746104s

on_train_batch_end: 1598428587.020405s

10240/50000 [=====>........................] - ETA: 28s - loss: 0.8087 - accuracy: 0.1003
on_train_batch_begin: 1598428587.020797s

10 step training time: 0.737606s

on_train_batch_end: 1598428587.760641s

11264/50000 [=====>........................] - ETA: 27s - loss: 0.8029 - accuracy: 0.1003
on_train_batch_begin: 1598428587.761049s

11 step training time: 0.740252s

on_train_batch_end: 1598428588.497261s

12288/50000 [======>.......................] - ETA: 27s - loss: 0.8193 - accuracy: 0.1003
on_train_batch_begin: 1598428588.497637s

12 step training time: 0.736588s

on_train_batch_end: 1598428589.235198s

13312/50000 [======>.......................] - ETA: 26s - loss: 0.8200 - accuracy: 0.1003
on_train_batch_begin: 1598428589.235592s

13 step training time: 0.737955s

on_train_batch_end: 1598428589.975554s

14336/50000 [=======>......................] - ETA: 25s - loss: 0.8127 - accuracy: 0.1003
on_train_batch_begin: 1598428589.975938s

14 step training time: 0.740346s

on_train_batch_end: 1598428590.721792s

15360/50000 [========>.....................] - ETA: 25s - loss: 0.8082 - accuracy: 0.1003
on_train_batch_begin: 1598428590.722191s

15 step training time: 0.746253s

on_train_batch_end: 1598428591.459074s

16384/50000 [========>.....................] - ETA: 24s - loss: 0.7974 - accuracy: 0.1003
on_train_batch_begin: 1598428591.459491s

16 step training time: 0.737300s

on_train_batch_end: 1598428592.203778s

17408/50000 [=========>....................] - ETA: 23s - loss: 0.7961 - accuracy: 0.1003
on_train_batch_begin: 1598428592.204169s

17 step training time: 0.744677s

on_train_batch_end: 1598428592.945416s

18432/50000 [==========>...................] - ETA: 22s - loss: 0.8007 - accuracy: 0.1003
on_train_batch_begin: 1598428592.945800s

18 step training time: 0.741631s

on_train_batch_end: 1598428593.693593s

19456/50000 [==========>...................] - ETA: 22s - loss: 0.7970 - accuracy: 0.1003
on_train_batch_begin: 1598428593.693979s

19 step training time: 0.748179s

on_train_batch_end: 1598428594.441091s

20480/50000 [===========>..................] - ETA: 21s - loss: 0.8002 - accuracy: 0.1003
on_train_batch_begin: 1598428594.441484s

20 step training time: 0.747506s

on_train_batch_end: 1598428595.188632s

21504/50000 [===========>..................] - ETA: 20s - loss: 0.7956 - accuracy: 0.1003
on_train_batch_begin: 1598428595.189126s

21 step training time: 0.747642s

on_train_batch_end: 1598428595.944920s

22528/50000 [============>.................] - ETA: 19s - loss: 0.7969 - accuracy: 0.1003
on_train_batch_begin: 1598428595.945304s

22 step training time: 0.756178s

on_train_batch_end: 1598428596.692842s

23552/50000 [=============>................] - ETA: 19s - loss: 0.7966 - accuracy: 0.1003
on_train_batch_begin: 1598428596.693222s

23 step training time: 0.747917s

on_train_batch_end: 1598428597.439729s

24576/50000 [=============>................] - ETA: 18s - loss: 0.7945 - accuracy: 0.1003
on_train_batch_begin: 1598428597.440119s

24 step training time: 0.746898s

on_train_batch_end: 1598428598.181541s

25600/50000 [==============>...............] - ETA: 17s - loss: 0.7920 - accuracy: 0.1004
on_train_batch_begin: 1598428598.181928s

25 step training time: 0.741808s

on_train_batch_end: 1598428598.929952s

26624/50000 [==============>...............] - ETA: 16s - loss: 0.7932 - accuracy: 0.1004
on_train_batch_begin: 1598428598.930343s

26 step training time: 0.748415s

on_train_batch_end: 1598428599.670044s

27648/50000 [===============>..............] - ETA: 16s - loss: 0.7943 - accuracy: 0.1004
on_train_batch_begin: 1598428599.670439s

27 step training time: 0.740097s

on_train_batch_end: 1598428600.422076s

28672/50000 [================>.............] - ETA: 15s - loss: 0.7932 - accuracy: 0.1003
on_train_batch_begin: 1598428600.422475s

28 step training time: 0.752036s

on_train_batch_end: 1598428601.169883s

29696/50000 [================>.............] - ETA: 14s - loss: 0.7925 - accuracy: 0.1003
on_train_batch_begin: 1598428601.170289s

29 step training time: 0.747814s

on_train_batch_end: 1598428601.915885s

30720/50000 [=================>............] - ETA: 13s - loss: 0.7896 - accuracy: 0.1004
on_train_batch_begin: 1598428601.916284s

30 step training time: 0.745996s

on_train_batch_end: 1598428602.667820s

31744/50000 [==================>...........] - ETA: 13s - loss: 0.7881 - accuracy: 0.1003
on_train_batch_begin: 1598428602.668219s

31 step training time: 0.751935s

on_train_batch_end: 1598428603.427795s

32768/50000 [==================>...........] - ETA: 12s - loss: 0.7912 - accuracy: 0.1003
on_train_batch_begin: 1598428603.428186s

32 step training time: 0.759967s

on_train_batch_end: 1598428604.182792s

33792/50000 [===================>..........] - ETA: 11s - loss: 0.7913 - accuracy: 0.1003
on_train_batch_begin: 1598428604.183213s

33 step training time: 0.755026s

on_train_batch_end: 1598428604.933669s

34816/50000 [===================>..........] - ETA: 11s - loss: 0.7902 - accuracy: 0.1003
on_train_batch_begin: 1598428604.934054s

34 step training time: 0.750842s

on_train_batch_end: 1598428605.693462s

35840/50000 [====================>.........] - ETA: 10s - loss: 0.7884 - accuracy: 0.1003
on_train_batch_begin: 1598428605.693845s

35 step training time: 0.759791s

on_train_batch_end: 1598428606.445120s

36864/50000 [=====================>........] - ETA: 9s - loss: 0.7887 - accuracy: 0.1003 
on_train_batch_begin: 1598428606.445503s

36 step training time: 0.751657s

on_train_batch_end: 1598428607.205294s

37888/50000 [=====================>........] - ETA: 8s - loss: 0.7884 - accuracy: 0.1003
on_train_batch_begin: 1598428607.205697s

37 step training time: 0.760195s

on_train_batch_end: 1598428607.958792s

38912/50000 [======================>.......] - ETA: 8s - loss: 0.7900 - accuracy: 0.1003
on_train_batch_begin: 1598428607.959217s

38 step training time: 0.753520s

on_train_batch_end: 1598428608.708093s

39936/50000 [======================>.......] - ETA: 7s - loss: 0.7903 - accuracy: 0.1003
on_train_batch_begin: 1598428608.708502s

39 step training time: 0.749285s

on_train_batch_end: 1598428609.460785s

40960/50000 [=======================>......] - ETA: 6s - loss: 0.7893 - accuracy: 0.1003
on_train_batch_begin: 1598428609.461160s

40 step training time: 0.752658s

on_train_batch_end: 1598428610.213572s

41984/50000 [========================>.....] - ETA: 5s - loss: 0.7903 - accuracy: 0.1003
on_train_batch_begin: 1598428610.214134s

41 step training time: 0.752974s

on_train_batch_end: 1598428610.986049s

43008/50000 [========================>.....] - ETA: 5s - loss: 0.7874 - accuracy: 0.1003
on_train_batch_begin: 1598428610.986443s

42 step training time: 0.772310s

on_train_batch_end: 1598428611.729627s

44032/50000 [=========================>....] - ETA: 4s - loss: 0.7860 - accuracy: 0.1003
on_train_batch_begin: 1598428611.730006s

43 step training time: 0.743563s

on_train_batch_end: 1598428612.488771s

45056/50000 [==========================>...] - ETA: 3s - loss: 0.7867 - accuracy: 0.1003
on_train_batch_begin: 1598428612.489154s

44 step training time: 0.759147s

on_train_batch_end: 1598428613.237177s

46080/50000 [==========================>...] - ETA: 2s - loss: 0.7884 - accuracy: 0.1003
on_train_batch_begin: 1598428613.237566s

45 step training time: 0.748412s

on_train_batch_end: 1598428613.995604s

47104/50000 [===========================>..] - ETA: 2s - loss: 0.7880 - accuracy: 0.1003
on_train_batch_begin: 1598428613.996008s

46 step training time: 0.758442s

on_train_batch_end: 1598428614.754682s

48128/50000 [===========================>..] - ETA: 1s - loss: 0.7885 - accuracy: 0.1003
on_train_batch_begin: 1598428614.755116s

47 step training time: 0.759108s

on_train_batch_end: 1598428615.516897s

49152/50000 [============================>.] - ETA: 0s - loss: 0.7891 - accuracy: 0.1003
on_train_batch_begin: 1598428615.517278s

48 step training time: 0.762162s

on_train_batch_end: 1598428616.147743s

on_test_batch_begin: 1598428616.161484s

49 step training time: 0.644206s

on_epoch_end: 1598428618.081059s

Validation time: 1.919551s

Real time: 1598428618.081059s

Epoch time: 38.45137023925781s

50000/50000 [==============================] - 38s 769us/sample - loss: 0.7871 - accuracy: 0.1003 - val_loss: 6.6833 - val_accuracy: 0.1000
Tempo do fit: 227.72317481040955