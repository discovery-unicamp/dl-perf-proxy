wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:51
   155648/170498071 [..............................] - ETA: 1:20
   827392/170498071 [..............................] - ETA: 28s 
  3399680/170498071 [..............................] - ETA: 9s 
  6758400/170498071 [>.............................] - ETA: 5s
 10174464/170498071 [>.............................] - ETA: 4s
 13623296/170498071 [=>............................] - ETA: 3s
 17113088/170498071 [==>...........................] - ETA: 3s
 20422656/170498071 [==>...........................] - ETA: 3s
 23699456/170498071 [===>..........................] - ETA: 3s
 27074560/170498071 [===>..........................] - ETA: 2s
 30384128/170498071 [====>.........................] - ETA: 2s
 33546240/170498071 [====>.........................] - ETA: 2s
 36298752/170498071 [=====>........................] - ETA: 2s
 39321600/170498071 [=====>........................] - ETA: 2s
 42098688/170498071 [======>.......................] - ETA: 2s
 45391872/170498071 [======>.......................] - ETA: 2s
 48750592/170498071 [=======>......................] - ETA: 2s
 51699712/170498071 [========>.....................] - ETA: 2s
 55123968/170498071 [========>.....................] - ETA: 2s
 58302464/170498071 [=========>....................] - ETA: 2s
 61235200/170498071 [=========>....................] - ETA: 1s
 64389120/170498071 [==========>...................] - ETA: 1s
 67690496/170498071 [==========>...................] - ETA: 1s
 71081984/170498071 [===========>..................] - ETA: 1s
 74481664/170498071 [============>.................] - ETA: 1s
 77914112/170498071 [============>.................] - ETA: 1s
 81158144/170498071 [=============>................] - ETA: 1s
 84353024/170498071 [=============>................] - ETA: 1s
 87834624/170498071 [==============>...............] - ETA: 1s
 91275264/170498071 [===============>..............] - ETA: 1s
 94658560/170498071 [===============>..............] - ETA: 1s
 98058240/170498071 [================>.............] - ETA: 1s
101400576/170498071 [================>.............] - ETA: 1s
104701952/170498071 [=================>............] - ETA: 1s
107880448/170498071 [=================>............] - ETA: 1s
111271936/170498071 [==================>...........] - ETA: 0s
114679808/170498071 [===================>..........] - ETA: 0s
118185984/170498071 [===================>..........] - ETA: 0s
121659392/170498071 [====================>.........] - ETA: 0s
125067264/170498071 [=====================>........] - ETA: 0s
128245760/170498071 [=====================>........] - ETA: 0s
131653632/170498071 [======================>.......] - ETA: 0s
135110656/170498071 [======================>.......] - ETA: 0s
138543104/170498071 [=======================>......] - ETA: 0s
141869056/170498071 [=======================>......] - ETA: 0s
145367040/170498071 [========================>.....] - ETA: 0s
148553728/170498071 [=========================>....] - ETA: 0s
151838720/170498071 [=========================>....] - ETA: 0s
155328512/170498071 [==========================>...] - ETA: 0s
158769152/170498071 [==========================>...] - ETA: 0s
162111488/170498071 [===========================>..] - ETA: 0s
165371904/170498071 [============================>.] - ETA: 0s
168796160/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 6676480/94765736 [=>............................] - ETA: 0s
12238848/94765736 [==>...........................] - ETA: 0s
19644416/94765736 [=====>........................] - ETA: 0s
25894912/94765736 [=======>......................] - ETA: 0s
30924800/94765736 [========>.....................] - ETA: 0s
35905536/94765736 [==========>...................] - ETA: 0s
40960000/94765736 [===========>..................] - ETA: 0s
45948928/94765736 [=============>................] - ETA: 0s
50929664/94765736 [===============>..............] - ETA: 0s
55967744/94765736 [================>.............] - ETA: 0s
60956672/94765736 [==================>...........] - ETA: 0s
66019328/94765736 [===================>..........] - ETA: 0s
71024640/94765736 [=====================>........] - ETA: 0s
76005376/94765736 [=======================>......] - ETA: 0s
81035264/94765736 [========================>.....] - ETA: 0s
85909504/94765736 [==========================>...] - ETA: 0s
90996736/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 28.987066984176636
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1599839287.263164s

Real time: 1599839287.2631855
Epoch 1/5

on_train_batch_begin: 1599839288.291016s

on_train_batch_end: 1599839416.480501s

 1024/50000 [..............................] - ETA: 1:43:00 - loss: 16.7531 - accuracy: 1.0681e-04
on_train_batch_begin: 1599839416.481267s

1 step training time: 128.190251s

on_train_batch_end: 1599839416.546125s

 2048/50000 [>.............................] - ETA: 50:27 - loss: 14.9711 - accuracy: 2.5558e-04  
on_train_batch_begin: 1599839416.546523s

2 step training time: 0.065256s

on_train_batch_end: 1599839416.608831s

 3072/50000 [>.............................] - ETA: 32:55 - loss: 13.2398 - accuracy: 2.9500e-04
on_train_batch_begin: 1599839416.609244s

3 step training time: 0.062721s

on_train_batch_end: 1599839416.671098s

 4096/50000 [=>............................] - ETA: 24:10 - loss: 12.1179 - accuracy: 8.1062e-04
on_train_batch_begin: 1599839416.671476s

4 step training time: 0.062232s

on_train_batch_end: 1599839416.733860s

 5120/50000 [==>...........................] - ETA: 18:54 - loss: 11.3239 - accuracy: 0.0019    
on_train_batch_begin: 1599839416.734240s

5 step training time: 0.062763s

on_train_batch_end: 1599839416.798525s

 6144/50000 [==>...........................] - ETA: 15:24 - loss: 10.7367 - accuracy: 0.0040
on_train_batch_begin: 1599839416.798910s

6 step training time: 0.064670s

on_train_batch_end: 1599839416.861254s

 7168/50000 [===>..........................] - ETA: 12:54 - loss: 10.2722 - accuracy: 0.0070
on_train_batch_begin: 1599839416.861633s

7 step training time: 0.062722s

on_train_batch_end: 1599839416.922838s

 8192/50000 [===>..........................] - ETA: 11:01 - loss: 9.9144 - accuracy: 0.0107 
on_train_batch_begin: 1599839416.923229s

8 step training time: 0.061597s

on_train_batch_end: 1599839416.985987s

 9216/50000 [====>.........................] - ETA: 9:34 - loss: 9.6038 - accuracy: 0.0130 
on_train_batch_begin: 1599839416.986368s

9 step training time: 0.063138s

on_train_batch_end: 1599839417.046716s

10240/50000 [=====>........................] - ETA: 8:23 - loss: 9.3453 - accuracy: 0.0161
on_train_batch_begin: 1599839417.047096s

10 step training time: 0.060728s

on_train_batch_end: 1599839417.106969s

11264/50000 [=====>........................] - ETA: 7:26 - loss: 9.1177 - accuracy: 0.0194
on_train_batch_begin: 1599839417.107351s

11 step training time: 0.060256s

on_train_batch_end: 1599839417.168353s

12288/50000 [======>.......................] - ETA: 6:38 - loss: 8.9182 - accuracy: 0.0227
on_train_batch_begin: 1599839417.168732s

12 step training time: 0.061381s

on_train_batch_end: 1599839417.228753s

13312/50000 [======>.......................] - ETA: 5:58 - loss: 8.7538 - accuracy: 0.0255
on_train_batch_begin: 1599839417.229172s

13 step training time: 0.060440s

on_train_batch_end: 1599839417.290507s

14336/50000 [=======>......................] - ETA: 5:23 - loss: 8.5972 - accuracy: 0.0285
on_train_batch_begin: 1599839417.290907s

14 step training time: 0.061735s

on_train_batch_end: 1599839417.353600s

15360/50000 [========>.....................] - ETA: 4:53 - loss: 8.4478 - accuracy: 0.0307
on_train_batch_begin: 1599839417.354016s

15 step training time: 0.063109s

on_train_batch_end: 1599839417.419191s

16384/50000 [========>.....................] - ETA: 4:27 - loss: 8.3189 - accuracy: 0.0322
on_train_batch_begin: 1599839417.419574s

16 step training time: 0.065559s

on_train_batch_end: 1599839417.483556s

17408/50000 [=========>....................] - ETA: 4:03 - loss: 8.1952 - accuracy: 0.0336
on_train_batch_begin: 1599839417.483969s

17 step training time: 0.064394s

on_train_batch_end: 1599839417.547932s

18432/50000 [==========>...................] - ETA: 3:43 - loss: 8.0834 - accuracy: 0.0351
on_train_batch_begin: 1599839417.548343s

18 step training time: 0.064374s

on_train_batch_end: 1599839417.611166s

19456/50000 [==========>...................] - ETA: 3:24 - loss: 7.9810 - accuracy: 0.0365
on_train_batch_begin: 1599839417.611547s

19 step training time: 0.063204s

on_train_batch_end: 1599839417.670660s

20480/50000 [===========>..................] - ETA: 3:07 - loss: 7.8828 - accuracy: 0.0379
on_train_batch_begin: 1599839417.671044s

20 step training time: 0.059497s

on_train_batch_end: 1599839417.733030s

21504/50000 [===========>..................] - ETA: 2:52 - loss: 7.7891 - accuracy: 0.0388
on_train_batch_begin: 1599839417.733413s

21 step training time: 0.062369s

on_train_batch_end: 1599839417.793977s

22528/50000 [============>.................] - ETA: 2:39 - loss: 7.7015 - accuracy: 0.0398
on_train_batch_begin: 1599839417.794364s

22 step training time: 0.060951s

on_train_batch_end: 1599839417.855855s

23552/50000 [=============>................] - ETA: 2:26 - loss: 7.6270 - accuracy: 0.0406
on_train_batch_begin: 1599839417.856264s

23 step training time: 0.061901s

on_train_batch_end: 1599839417.919767s

24576/50000 [=============>................] - ETA: 2:15 - loss: 7.5409 - accuracy: 0.0416
on_train_batch_begin: 1599839417.920144s

24 step training time: 0.063880s

on_train_batch_end: 1599839417.984099s

25600/50000 [==============>...............] - ETA: 2:04 - loss: 7.4630 - accuracy: 0.0426
on_train_batch_begin: 1599839417.984486s

25 step training time: 0.064342s

on_train_batch_end: 1599839418.048499s

26624/50000 [==============>...............] - ETA: 1:54 - loss: 7.3880 - accuracy: 0.0436
on_train_batch_begin: 1599839418.048910s

26 step training time: 0.064425s

on_train_batch_end: 1599839418.113099s

27648/50000 [===============>..............] - ETA: 1:45 - loss: 7.3121 - accuracy: 0.0445
on_train_batch_begin: 1599839418.113515s

27 step training time: 0.064605s

on_train_batch_end: 1599839418.177619s

28672/50000 [================>.............] - ETA: 1:37 - loss: 7.2392 - accuracy: 0.0454
on_train_batch_begin: 1599839418.178029s

28 step training time: 0.064514s

on_train_batch_end: 1599839418.242101s

29696/50000 [================>.............] - ETA: 1:29 - loss: 7.1676 - accuracy: 0.0462
on_train_batch_begin: 1599839418.242482s

29 step training time: 0.064453s

on_train_batch_end: 1599839418.305905s

30720/50000 [=================>............] - ETA: 1:22 - loss: 7.0969 - accuracy: 0.0471
on_train_batch_begin: 1599839418.306287s

30 step training time: 0.063806s

on_train_batch_end: 1599839418.366014s

31744/50000 [==================>...........] - ETA: 1:15 - loss: 7.0274 - accuracy: 0.0477
on_train_batch_begin: 1599839418.366400s

31 step training time: 0.060113s

on_train_batch_end: 1599839418.428427s

32768/50000 [==================>...........] - ETA: 1:08 - loss: 6.9581 - accuracy: 0.0484
on_train_batch_begin: 1599839418.428809s

32 step training time: 0.062409s

on_train_batch_end: 1599839418.489447s

33792/50000 [===================>..........] - ETA: 1:02 - loss: 6.8915 - accuracy: 0.0491
on_train_batch_begin: 1599839418.489828s

33 step training time: 0.061019s

on_train_batch_end: 1599839418.554548s

34816/50000 [===================>..........] - ETA: 57s - loss: 6.8244 - accuracy: 0.0497 
on_train_batch_begin: 1599839418.554928s

34 step training time: 0.065100s

on_train_batch_end: 1599839418.618879s

35840/50000 [====================>.........] - ETA: 51s - loss: 6.7576 - accuracy: 0.0505
on_train_batch_begin: 1599839418.619266s

35 step training time: 0.064337s

on_train_batch_end: 1599839418.680523s

36864/50000 [=====================>........] - ETA: 46s - loss: 6.6924 - accuracy: 0.0512
on_train_batch_begin: 1599839418.680942s

36 step training time: 0.061677s

on_train_batch_end: 1599839418.743205s

37888/50000 [=====================>........] - ETA: 42s - loss: 6.6282 - accuracy: 0.0520
on_train_batch_begin: 1599839418.743583s

37 step training time: 0.062641s

on_train_batch_end: 1599839418.807858s

38912/50000 [======================>.......] - ETA: 37s - loss: 6.5635 - accuracy: 0.0527
on_train_batch_begin: 1599839418.808235s

38 step training time: 0.064651s

on_train_batch_end: 1599839418.867715s

39936/50000 [======================>.......] - ETA: 33s - loss: 6.5000 - accuracy: 0.0535
on_train_batch_begin: 1599839418.868090s

39 step training time: 0.059855s

on_train_batch_end: 1599839418.933170s

40960/50000 [=======================>......] - ETA: 29s - loss: 6.4340 - accuracy: 0.0543
on_train_batch_begin: 1599839418.933551s

40 step training time: 0.065461s

on_train_batch_end: 1599839418.994127s

41984/50000 [========================>.....] - ETA: 25s - loss: 6.3715 - accuracy: 0.0551
on_train_batch_begin: 1599839418.994503s

41 step training time: 0.060953s

on_train_batch_end: 1599839419.054565s

43008/50000 [========================>.....] - ETA: 21s - loss: 6.3106 - accuracy: 0.0559
on_train_batch_begin: 1599839419.054949s

42 step training time: 0.060445s

on_train_batch_end: 1599839419.120431s

44032/50000 [=========================>....] - ETA: 17s - loss: 6.2484 - accuracy: 0.0566
on_train_batch_begin: 1599839419.120816s

43 step training time: 0.065868s

on_train_batch_end: 1599839419.182642s

45056/50000 [==========================>...] - ETA: 14s - loss: 6.1906 - accuracy: 0.0574
on_train_batch_begin: 1599839419.183021s

44 step training time: 0.062205s

on_train_batch_end: 1599839419.245127s

46080/50000 [==========================>...] - ETA: 11s - loss: 6.1323 - accuracy: 0.0582
on_train_batch_begin: 1599839419.245505s

45 step training time: 0.062484s

on_train_batch_end: 1599839419.310883s

47104/50000 [===========================>..] - ETA: 8s - loss: 6.0724 - accuracy: 0.0589 
on_train_batch_begin: 1599839419.311288s

46 step training time: 0.065783s

on_train_batch_end: 1599839419.375286s

48128/50000 [===========================>..] - ETA: 5s - loss: 6.0142 - accuracy: 0.0596
on_train_batch_begin: 1599839419.375664s

47 step training time: 0.064375s

on_train_batch_end: 1599839419.434535s

49152/50000 [============================>.] - ETA: 2s - loss: 5.9550 - accuracy: 0.0604
on_train_batch_begin: 1599839419.434949s

48 step training time: 0.059286s

on_train_batch_end: 1599839420.394493s

on_test_batch_begin: 1599839420.785327s

49 step training time: 1.350378s

on_epoch_end: 1599839432.723652s

Validation time: 11.938302s

Real time: 1599839432.723652s

Epoch time: 145.46049737930298s

50000/50000 [==============================] - 145s 3ms/sample - loss: 5.9059 - accuracy: 0.0610 - val_loss: 12.9012 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599839432.723939s

Real time: 1599839432.723948
Epoch 2/5

on_train_batch_begin: 1599839432.732066s

on_train_batch_end: 1599839432.797424s

 1024/50000 [..............................] - ETA: 3s - loss: 3.1447 - accuracy: 0.0973
on_train_batch_begin: 1599839432.797837s

1 step training time: 0.065771s

on_train_batch_end: 1599839432.863521s

 2048/50000 [>.............................] - ETA: 3s - loss: 3.1222 - accuracy: 0.0983
on_train_batch_begin: 1599839432.863915s

2 step training time: 0.066078s

on_train_batch_end: 1599839432.929611s

 3072/50000 [>.............................] - ETA: 3s - loss: 3.0298 - accuracy: 0.0989
on_train_batch_begin: 1599839432.930004s

3 step training time: 0.066089s

on_train_batch_end: 1599839432.989908s

 4096/50000 [=>............................] - ETA: 2s - loss: 3.0416 - accuracy: 0.0986
on_train_batch_begin: 1599839432.990303s

4 step training time: 0.060299s

on_train_batch_end: 1599839433.054400s

 5120/50000 [==>...........................] - ETA: 2s - loss: 2.9983 - accuracy: 0.0987
on_train_batch_begin: 1599839433.054773s

5 step training time: 0.064470s

on_train_batch_end: 1599839433.113457s

 6144/50000 [==>...........................] - ETA: 2s - loss: 2.9514 - accuracy: 0.0988
on_train_batch_begin: 1599839433.113835s

6 step training time: 0.059062s

on_train_batch_end: 1599839433.176185s

 7168/50000 [===>..........................] - ETA: 2s - loss: 2.9311 - accuracy: 0.0986
on_train_batch_begin: 1599839433.176569s

7 step training time: 0.062734s

on_train_batch_end: 1599839433.242083s

 8192/50000 [===>..........................] - ETA: 2s - loss: 2.9159 - accuracy: 0.0986
on_train_batch_begin: 1599839433.242464s

8 step training time: 0.065895s

on_train_batch_end: 1599839433.307622s

 9216/50000 [====>.........................] - ETA: 2s - loss: 2.8977 - accuracy: 0.0986
on_train_batch_begin: 1599839433.308007s

9 step training time: 0.065543s

on_train_batch_end: 1599839433.371343s

10240/50000 [=====>........................] - ETA: 2s - loss: 2.8934 - accuracy: 0.0987
on_train_batch_begin: 1599839433.371745s

10 step training time: 0.063738s

on_train_batch_end: 1599839433.432394s

11264/50000 [=====>........................] - ETA: 2s - loss: 2.8797 - accuracy: 0.0988
on_train_batch_begin: 1599839433.432794s

11 step training time: 0.061049s

on_train_batch_end: 1599839433.498458s

12288/50000 [======>.......................] - ETA: 2s - loss: 2.8478 - accuracy: 0.0990
on_train_batch_begin: 1599839433.498895s

12 step training time: 0.066101s

on_train_batch_end: 1599839433.564516s

13312/50000 [======>.......................] - ETA: 2s - loss: 2.8179 - accuracy: 0.0992
on_train_batch_begin: 1599839433.564970s

13 step training time: 0.066074s

on_train_batch_end: 1599839433.627661s

14336/50000 [=======>......................] - ETA: 2s - loss: 2.7974 - accuracy: 0.0992
on_train_batch_begin: 1599839433.628108s

14 step training time: 0.063138s

on_train_batch_end: 1599839433.692619s

15360/50000 [========>.....................] - ETA: 2s - loss: 2.7830 - accuracy: 0.0993
on_train_batch_begin: 1599839433.693079s

15 step training time: 0.064972s

on_train_batch_end: 1599839433.754684s

16384/50000 [========>.....................] - ETA: 2s - loss: 2.7670 - accuracy: 0.0995
on_train_batch_begin: 1599839433.755102s

16 step training time: 0.062022s

on_train_batch_end: 1599839433.817061s

17408/50000 [=========>....................] - ETA: 2s - loss: 2.7492 - accuracy: 0.0994
on_train_batch_begin: 1599839433.817510s

17 step training time: 0.062408s

on_train_batch_end: 1599839433.882723s

18432/50000 [==========>...................] - ETA: 1s - loss: 2.7413 - accuracy: 0.0994
on_train_batch_begin: 1599839433.883192s

18 step training time: 0.065682s

on_train_batch_end: 1599839433.948293s

19456/50000 [==========>...................] - ETA: 1s - loss: 2.7330 - accuracy: 0.0995
on_train_batch_begin: 1599839433.948712s

19 step training time: 0.065520s

on_train_batch_end: 1599839434.012646s

20480/50000 [===========>..................] - ETA: 1s - loss: 2.7138 - accuracy: 0.0996
on_train_batch_begin: 1599839434.013093s

20 step training time: 0.064382s

on_train_batch_end: 1599839434.076892s

21504/50000 [===========>..................] - ETA: 1s - loss: 2.7036 - accuracy: 0.0996
on_train_batch_begin: 1599839434.077306s

21 step training time: 0.064212s

on_train_batch_end: 1599839434.138076s

22528/50000 [============>.................] - ETA: 1s - loss: 2.6891 - accuracy: 0.0997
on_train_batch_begin: 1599839434.138494s

22 step training time: 0.061189s

on_train_batch_end: 1599839434.199047s

23552/50000 [=============>................] - ETA: 1s - loss: 2.6730 - accuracy: 0.0997
on_train_batch_begin: 1599839434.199456s

23 step training time: 0.060961s

on_train_batch_end: 1599839434.263157s

24576/50000 [=============>................] - ETA: 1s - loss: 2.6574 - accuracy: 0.0998
on_train_batch_begin: 1599839434.263578s

24 step training time: 0.064122s

on_train_batch_end: 1599839434.326579s

25600/50000 [==============>...............] - ETA: 1s - loss: 2.6492 - accuracy: 0.0998
on_train_batch_begin: 1599839434.327005s

25 step training time: 0.063427s

on_train_batch_end: 1599839434.386457s

26624/50000 [==============>...............] - ETA: 1s - loss: 2.6374 - accuracy: 0.0999
on_train_batch_begin: 1599839434.386870s

26 step training time: 0.059865s

on_train_batch_end: 1599839434.447418s

27648/50000 [===============>..............] - ETA: 1s - loss: 2.6246 - accuracy: 0.0999
on_train_batch_begin: 1599839434.447832s

27 step training time: 0.060962s

on_train_batch_end: 1599839434.512589s

28672/50000 [================>.............] - ETA: 1s - loss: 2.6154 - accuracy: 0.1000
on_train_batch_begin: 1599839434.513041s

28 step training time: 0.065209s

on_train_batch_end: 1599839434.575803s

29696/50000 [================>.............] - ETA: 1s - loss: 2.5996 - accuracy: 0.1000
on_train_batch_begin: 1599839434.576202s

29 step training time: 0.063162s

on_train_batch_end: 1599839434.640978s

30720/50000 [=================>............] - ETA: 1s - loss: 2.5825 - accuracy: 0.1001
on_train_batch_begin: 1599839434.641403s

30 step training time: 0.065201s

on_train_batch_end: 1599839434.703040s

31744/50000 [==================>...........] - ETA: 1s - loss: 2.5680 - accuracy: 0.1002
on_train_batch_begin: 1599839434.703452s

31 step training time: 0.062049s

on_train_batch_end: 1599839434.764027s

32768/50000 [==================>...........] - ETA: 1s - loss: 2.5533 - accuracy: 0.1002
on_train_batch_begin: 1599839434.764439s

32 step training time: 0.060986s

on_train_batch_end: 1599839434.824053s

33792/50000 [===================>..........] - ETA: 1s - loss: 2.5412 - accuracy: 0.1002
on_train_batch_begin: 1599839434.824461s

33 step training time: 0.060023s

on_train_batch_end: 1599839434.889416s

34816/50000 [===================>..........] - ETA: 0s - loss: 2.5267 - accuracy: 0.1003
on_train_batch_begin: 1599839434.889848s

34 step training time: 0.065386s

on_train_batch_end: 1599839434.954256s

35840/50000 [====================>.........] - ETA: 0s - loss: 2.5132 - accuracy: 0.1003
on_train_batch_begin: 1599839434.954657s

35 step training time: 0.064810s

on_train_batch_end: 1599839435.018018s

36864/50000 [=====================>........] - ETA: 0s - loss: 2.5022 - accuracy: 0.1003
on_train_batch_begin: 1599839435.018466s

36 step training time: 0.063809s

on_train_batch_end: 1599839435.081636s

37888/50000 [=====================>........] - ETA: 0s - loss: 2.4913 - accuracy: 0.1004
on_train_batch_begin: 1599839435.082072s

37 step training time: 0.063606s

on_train_batch_end: 1599839435.143941s

38912/50000 [======================>.......] - ETA: 0s - loss: 2.4808 - accuracy: 0.1004
on_train_batch_begin: 1599839435.144390s

38 step training time: 0.062318s

on_train_batch_end: 1599839435.207067s

39936/50000 [======================>.......] - ETA: 0s - loss: 2.4729 - accuracy: 0.1004
on_train_batch_begin: 1599839435.207510s

39 step training time: 0.063120s

on_train_batch_end: 1599839435.270199s

40960/50000 [=======================>......] - ETA: 0s - loss: 2.4647 - accuracy: 0.1005
on_train_batch_begin: 1599839435.270641s

40 step training time: 0.063132s

on_train_batch_end: 1599839435.332119s

41984/50000 [========================>.....] - ETA: 0s - loss: 2.4520 - accuracy: 0.1005
on_train_batch_begin: 1599839435.332555s

41 step training time: 0.061913s

on_train_batch_end: 1599839435.399944s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.4405 - accuracy: 0.1006
on_train_batch_begin: 1599839435.400392s

42 step training time: 0.067837s

on_train_batch_end: 1599839435.463492s

44032/50000 [=========================>....] - ETA: 0s - loss: 2.4259 - accuracy: 0.1006
on_train_batch_begin: 1599839435.463933s

43 step training time: 0.063541s

on_train_batch_end: 1599839435.529934s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.4135 - accuracy: 0.1006
on_train_batch_begin: 1599839435.530385s

44 step training time: 0.066452s

on_train_batch_end: 1599839435.594397s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.4031 - accuracy: 0.1006
on_train_batch_begin: 1599839435.594840s

45 step training time: 0.064455s

on_train_batch_end: 1599839435.657573s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.3939 - accuracy: 0.1006
on_train_batch_begin: 1599839435.658044s

46 step training time: 0.063204s

on_train_batch_end: 1599839435.721088s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.3836 - accuracy: 0.1006
on_train_batch_begin: 1599839435.721538s

47 step training time: 0.063494s

on_train_batch_end: 1599839435.785696s

49152/50000 [============================>.] - ETA: 0s - loss: 2.3736 - accuracy: 0.1006
on_train_batch_begin: 1599839435.786134s

48 step training time: 0.064596s

on_train_batch_end: 1599839435.847959s

on_test_batch_begin: 1599839435.887062s

49 step training time: 0.100928s

on_epoch_end: 1599839436.159454s

Validation time: 0.272376s

Real time: 1599839436.159454s

Epoch time: 3.4355320930480957s

50000/50000 [==============================] - 3s 69us/sample - loss: 2.3656 - accuracy: 0.1006 - val_loss: 7.2446 - val_accuracy: 0.0999

on_epoch_begin: 1599839436.159723s

Real time: 1599839436.1597311
Epoch 3/5

on_train_batch_begin: 1599839436.167818s

on_train_batch_end: 1599839436.235617s

 1024/50000 [..............................] - ETA: 3s - loss: 1.7905 - accuracy: 0.1020
on_train_batch_begin: 1599839436.236069s

1 step training time: 0.068252s

on_train_batch_end: 1599839436.302930s

 2048/50000 [>.............................] - ETA: 3s - loss: 1.8482 - accuracy: 0.1016
on_train_batch_begin: 1599839436.303385s

2 step training time: 0.067316s

on_train_batch_end: 1599839436.369254s

 3072/50000 [>.............................] - ETA: 3s - loss: 1.7839 - accuracy: 0.1016
on_train_batch_begin: 1599839436.369702s

3 step training time: 0.066316s

on_train_batch_end: 1599839436.434553s

 4096/50000 [=>............................] - ETA: 3s - loss: 1.7552 - accuracy: 0.1015
on_train_batch_begin: 1599839436.434995s

4 step training time: 0.065293s

on_train_batch_end: 1599839436.497663s

 5120/50000 [==>...........................] - ETA: 2s - loss: 1.7526 - accuracy: 0.1017
on_train_batch_begin: 1599839436.498100s

5 step training time: 0.063105s

on_train_batch_end: 1599839436.559141s

 6144/50000 [==>...........................] - ETA: 2s - loss: 1.7313 - accuracy: 0.1017
on_train_batch_begin: 1599839436.559593s

6 step training time: 0.061493s

on_train_batch_end: 1599839436.622899s

 7168/50000 [===>..........................] - ETA: 2s - loss: 1.7226 - accuracy: 0.1018
on_train_batch_begin: 1599839436.623343s

7 step training time: 0.063750s

on_train_batch_end: 1599839436.688512s

 8192/50000 [===>..........................] - ETA: 2s - loss: 1.6995 - accuracy: 0.1019
on_train_batch_begin: 1599839436.688986s

8 step training time: 0.065643s

on_train_batch_end: 1599839436.750366s

 9216/50000 [====>.........................] - ETA: 2s - loss: 1.7067 - accuracy: 0.1018
on_train_batch_begin: 1599839436.750808s

9 step training time: 0.061822s

on_train_batch_end: 1599839436.815716s

10240/50000 [=====>........................] - ETA: 2s - loss: 1.7043 - accuracy: 0.1018
on_train_batch_begin: 1599839436.816181s

10 step training time: 0.065373s

on_train_batch_end: 1599839436.878826s

11264/50000 [=====>........................] - ETA: 2s - loss: 1.7055 - accuracy: 0.1017
on_train_batch_begin: 1599839436.879282s

11 step training time: 0.063101s

on_train_batch_end: 1599839436.946028s

12288/50000 [======>.......................] - ETA: 2s - loss: 1.7205 - accuracy: 0.1017
on_train_batch_begin: 1599839436.946472s

12 step training time: 0.067190s

on_train_batch_end: 1599839437.008100s

13312/50000 [======>.......................] - ETA: 2s - loss: 1.7211 - accuracy: 0.1018
on_train_batch_begin: 1599839437.008554s

13 step training time: 0.062082s

on_train_batch_end: 1599839437.070309s

14336/50000 [=======>......................] - ETA: 2s - loss: 1.7212 - accuracy: 0.1018
on_train_batch_begin: 1599839437.070765s

14 step training time: 0.062212s

on_train_batch_end: 1599839437.134334s

15360/50000 [========>.....................] - ETA: 2s - loss: 1.7311 - accuracy: 0.1018
on_train_batch_begin: 1599839437.134781s

15 step training time: 0.064016s

on_train_batch_end: 1599839437.199156s

16384/50000 [========>.....................] - ETA: 2s - loss: 1.7283 - accuracy: 0.1018
on_train_batch_begin: 1599839437.199595s

16 step training time: 0.064814s

on_train_batch_end: 1599839437.266365s

17408/50000 [=========>....................] - ETA: 2s - loss: 1.7225 - accuracy: 0.1020
on_train_batch_begin: 1599839437.266848s

17 step training time: 0.067253s

on_train_batch_end: 1599839437.329230s

18432/50000 [==========>...................] - ETA: 2s - loss: 1.7344 - accuracy: 0.1020
on_train_batch_begin: 1599839437.329666s

18 step training time: 0.062818s

on_train_batch_end: 1599839437.393147s

19456/50000 [==========>...................] - ETA: 1s - loss: 1.7342 - accuracy: 0.1020
on_train_batch_begin: 1599839437.393610s

19 step training time: 0.063944s

on_train_batch_end: 1599839437.457237s

20480/50000 [===========>..................] - ETA: 1s - loss: 1.7352 - accuracy: 0.1020
on_train_batch_begin: 1599839437.457682s

20 step training time: 0.064072s

on_train_batch_end: 1599839437.521138s

21504/50000 [===========>..................] - ETA: 1s - loss: 1.7284 - accuracy: 0.1020
on_train_batch_begin: 1599839437.521598s

21 step training time: 0.063915s

on_train_batch_end: 1599839437.587814s

22528/50000 [============>.................] - ETA: 1s - loss: 1.7195 - accuracy: 0.1020
on_train_batch_begin: 1599839437.588256s

22 step training time: 0.066658s

on_train_batch_end: 1599839437.653765s

23552/50000 [=============>................] - ETA: 1s - loss: 1.7169 - accuracy: 0.1020
on_train_batch_begin: 1599839437.654211s

23 step training time: 0.065955s

on_train_batch_end: 1599839437.720417s

24576/50000 [=============>................] - ETA: 1s - loss: 1.7104 - accuracy: 0.1020
on_train_batch_begin: 1599839437.720895s

24 step training time: 0.066684s

on_train_batch_end: 1599839437.787640s

25600/50000 [==============>...............] - ETA: 1s - loss: 1.7032 - accuracy: 0.1020
on_train_batch_begin: 1599839437.788082s

25 step training time: 0.067188s

on_train_batch_end: 1599839437.850538s

26624/50000 [==============>...............] - ETA: 1s - loss: 1.7008 - accuracy: 0.1020
on_train_batch_begin: 1599839437.850979s

26 step training time: 0.062896s

on_train_batch_end: 1599839437.913305s

27648/50000 [===============>..............] - ETA: 1s - loss: 1.6936 - accuracy: 0.1020
on_train_batch_begin: 1599839437.913777s

27 step training time: 0.062798s

on_train_batch_end: 1599839437.975848s

28672/50000 [================>.............] - ETA: 1s - loss: 1.6869 - accuracy: 0.1020
on_train_batch_begin: 1599839437.976284s

28 step training time: 0.062508s

on_train_batch_end: 1599839438.039330s

29696/50000 [================>.............] - ETA: 1s - loss: 1.6872 - accuracy: 0.1020
on_train_batch_begin: 1599839438.039787s

29 step training time: 0.063503s

on_train_batch_end: 1599839438.102916s

30720/50000 [=================>............] - ETA: 1s - loss: 1.6792 - accuracy: 0.1020
on_train_batch_begin: 1599839438.103355s

30 step training time: 0.063568s

on_train_batch_end: 1599839438.166293s

31744/50000 [==================>...........] - ETA: 1s - loss: 1.6792 - accuracy: 0.1020
on_train_batch_begin: 1599839438.166745s

31 step training time: 0.063390s

on_train_batch_end: 1599839438.232908s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.6752 - accuracy: 0.1020
on_train_batch_begin: 1599839438.233363s

32 step training time: 0.066618s

on_train_batch_end: 1599839438.299204s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.6722 - accuracy: 0.1019
on_train_batch_begin: 1599839438.299643s

33 step training time: 0.066280s

on_train_batch_end: 1599839438.362730s

34816/50000 [===================>..........] - ETA: 0s - loss: 1.6629 - accuracy: 0.1020
on_train_batch_begin: 1599839438.363183s

34 step training time: 0.063540s

on_train_batch_end: 1599839438.427523s

35840/50000 [====================>.........] - ETA: 0s - loss: 1.6544 - accuracy: 0.1020
on_train_batch_begin: 1599839438.427985s

35 step training time: 0.064802s

on_train_batch_end: 1599839438.491832s

36864/50000 [=====================>........] - ETA: 0s - loss: 1.6499 - accuracy: 0.1020
on_train_batch_begin: 1599839438.492285s

36 step training time: 0.064300s

on_train_batch_end: 1599839438.555667s

37888/50000 [=====================>........] - ETA: 0s - loss: 1.6477 - accuracy: 0.1020
on_train_batch_begin: 1599839438.556106s

37 step training time: 0.063821s

on_train_batch_end: 1599839438.621251s

38912/50000 [======================>.......] - ETA: 0s - loss: 1.6408 - accuracy: 0.1020
on_train_batch_begin: 1599839438.621693s

38 step training time: 0.065587s

on_train_batch_end: 1599839438.686079s

39936/50000 [======================>.......] - ETA: 0s - loss: 1.6361 - accuracy: 0.1020
on_train_batch_begin: 1599839438.686518s

39 step training time: 0.064826s

on_train_batch_end: 1599839438.752001s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.6331 - accuracy: 0.1019
on_train_batch_begin: 1599839438.752440s

40 step training time: 0.065921s

on_train_batch_end: 1599839438.815459s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.6294 - accuracy: 0.1019
on_train_batch_begin: 1599839438.815901s

41 step training time: 0.063462s

on_train_batch_end: 1599839438.882459s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.6237 - accuracy: 0.1019
on_train_batch_begin: 1599839438.882932s

42 step training time: 0.067031s

on_train_batch_end: 1599839438.944010s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.6211 - accuracy: 0.1019
on_train_batch_begin: 1599839438.944447s

43 step training time: 0.061515s

on_train_batch_end: 1599839439.008034s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.6196 - accuracy: 0.1019
on_train_batch_begin: 1599839439.008473s

44 step training time: 0.064026s

on_train_batch_end: 1599839439.072269s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.6200 - accuracy: 0.1019
on_train_batch_begin: 1599839439.072713s

45 step training time: 0.064240s

on_train_batch_end: 1599839439.138706s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.6183 - accuracy: 0.1019
on_train_batch_begin: 1599839439.139148s

46 step training time: 0.066435s

on_train_batch_end: 1599839439.202273s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.6147 - accuracy: 0.1019
on_train_batch_begin: 1599839439.202712s

47 step training time: 0.063564s

on_train_batch_end: 1599839439.264770s

49152/50000 [============================>.] - ETA: 0s - loss: 1.6111 - accuracy: 0.1020
on_train_batch_begin: 1599839439.265234s

48 step training time: 0.062522s

on_train_batch_end: 1599839439.329407s

on_test_batch_begin: 1599839439.371442s

49 step training time: 0.106208s

on_epoch_end: 1599839439.618466s

Validation time: 0.247010s

Real time: 1599839439.618466s

Epoch time: 3.4587604999542236s

50000/50000 [==============================] - 3s 69us/sample - loss: 1.6133 - accuracy: 0.1019 - val_loss: 6.8377 - val_accuracy: 0.0999

on_epoch_begin: 1599839439.618724s

Real time: 1599839439.6187325
Epoch 4/5

on_train_batch_begin: 1599839439.627052s

on_train_batch_end: 1599839439.690115s

 1024/50000 [..............................] - ETA: 3s - loss: 1.4868 - accuracy: 0.1020
on_train_batch_begin: 1599839439.690555s

1 step training time: 0.063504s

on_train_batch_end: 1599839439.754809s

 2048/50000 [>.............................] - ETA: 3s - loss: 1.4980 - accuracy: 0.1017
on_train_batch_begin: 1599839439.755245s

2 step training time: 0.064690s

on_train_batch_end: 1599839439.819617s

 3072/50000 [>.............................] - ETA: 3s - loss: 1.4337 - accuracy: 0.1015
on_train_batch_begin: 1599839439.820058s

3 step training time: 0.064813s

on_train_batch_end: 1599839439.881544s

 4096/50000 [=>............................] - ETA: 2s - loss: 1.4381 - accuracy: 0.1018
on_train_batch_begin: 1599839439.881946s

4 step training time: 0.061889s

on_train_batch_end: 1599839439.946534s

 5120/50000 [==>...........................] - ETA: 2s - loss: 1.4427 - accuracy: 0.1018
on_train_batch_begin: 1599839439.946911s

5 step training time: 0.064965s

on_train_batch_end: 1599839440.010875s

 6144/50000 [==>...........................] - ETA: 2s - loss: 1.4442 - accuracy: 0.1019
on_train_batch_begin: 1599839440.011275s

6 step training time: 0.064363s

on_train_batch_end: 1599839440.071919s

 7168/50000 [===>..........................] - ETA: 2s - loss: 1.4353 - accuracy: 0.1019
on_train_batch_begin: 1599839440.072338s

7 step training time: 0.061064s

on_train_batch_end: 1599839440.137928s

 8192/50000 [===>..........................] - ETA: 2s - loss: 1.4281 - accuracy: 0.1020
on_train_batch_begin: 1599839440.138350s

8 step training time: 0.066011s

on_train_batch_end: 1599839440.201213s

 9216/50000 [====>.........................] - ETA: 2s - loss: 1.4228 - accuracy: 0.1020
on_train_batch_begin: 1599839440.201589s

9 step training time: 0.063239s

on_train_batch_end: 1599839440.261663s

10240/50000 [=====>........................] - ETA: 2s - loss: 1.4077 - accuracy: 0.1020
on_train_batch_begin: 1599839440.262041s

10 step training time: 0.060452s

on_train_batch_end: 1599839440.325405s

11264/50000 [=====>........................] - ETA: 2s - loss: 1.3928 - accuracy: 0.1022
on_train_batch_begin: 1599839440.325805s

11 step training time: 0.063764s

on_train_batch_end: 1599839440.388986s

12288/50000 [======>.......................] - ETA: 2s - loss: 1.3895 - accuracy: 0.1022
on_train_batch_begin: 1599839440.389337s

12 step training time: 0.063532s

on_train_batch_end: 1599839440.450995s

13312/50000 [======>.......................] - ETA: 2s - loss: 1.3800 - accuracy: 0.1022
on_train_batch_begin: 1599839440.451467s

13 step training time: 0.062130s

on_train_batch_end: 1599839440.514031s

14336/50000 [=======>......................] - ETA: 2s - loss: 1.3811 - accuracy: 0.1022
on_train_batch_begin: 1599839440.514568s

14 step training time: 0.063101s

on_train_batch_end: 1599839440.577579s

15360/50000 [========>.....................] - ETA: 2s - loss: 1.3750 - accuracy: 0.1022
on_train_batch_begin: 1599839440.578064s

15 step training time: 0.063496s

on_train_batch_end: 1599839440.643250s

16384/50000 [========>.....................] - ETA: 2s - loss: 1.3665 - accuracy: 0.1022
on_train_batch_begin: 1599839440.643737s

16 step training time: 0.065673s

on_train_batch_end: 1599839440.706748s

17408/50000 [=========>....................] - ETA: 2s - loss: 1.3622 - accuracy: 0.1023
on_train_batch_begin: 1599839440.707204s

17 step training time: 0.063467s

on_train_batch_end: 1599839440.773490s

18432/50000 [==========>...................] - ETA: 1s - loss: 1.3506 - accuracy: 0.1022
on_train_batch_begin: 1599839440.773962s

18 step training time: 0.066759s

on_train_batch_end: 1599839440.838523s

19456/50000 [==========>...................] - ETA: 1s - loss: 1.3463 - accuracy: 0.1022
on_train_batch_begin: 1599839440.838994s

19 step training time: 0.065032s

on_train_batch_end: 1599839440.902193s

20480/50000 [===========>..................] - ETA: 1s - loss: 1.3461 - accuracy: 0.1022
on_train_batch_begin: 1599839440.902671s

20 step training time: 0.063677s

on_train_batch_end: 1599839440.965628s

21504/50000 [===========>..................] - ETA: 1s - loss: 1.3430 - accuracy: 0.1023
on_train_batch_begin: 1599839440.966099s

21 step training time: 0.063428s

on_train_batch_end: 1599839441.033786s

22528/50000 [============>.................] - ETA: 1s - loss: 1.3441 - accuracy: 0.1023
on_train_batch_begin: 1599839441.034257s

22 step training time: 0.068158s

on_train_batch_end: 1599839441.098265s

23552/50000 [=============>................] - ETA: 1s - loss: 1.3352 - accuracy: 0.1023
on_train_batch_begin: 1599839441.098712s

23 step training time: 0.064456s

on_train_batch_end: 1599839441.164699s

24576/50000 [=============>................] - ETA: 1s - loss: 1.3317 - accuracy: 0.1023
on_train_batch_begin: 1599839441.165163s

24 step training time: 0.066451s

on_train_batch_end: 1599839441.228252s

25600/50000 [==============>...............] - ETA: 1s - loss: 1.3294 - accuracy: 0.1023
on_train_batch_begin: 1599839441.228701s

25 step training time: 0.063538s

on_train_batch_end: 1599839441.292627s

26624/50000 [==============>...............] - ETA: 1s - loss: 1.3257 - accuracy: 0.1023
on_train_batch_begin: 1599839441.293162s

26 step training time: 0.064461s

on_train_batch_end: 1599839441.356290s

27648/50000 [===============>..............] - ETA: 1s - loss: 1.3233 - accuracy: 0.1023
on_train_batch_begin: 1599839441.356779s

27 step training time: 0.063617s

on_train_batch_end: 1599839441.424512s

28672/50000 [================>.............] - ETA: 1s - loss: 1.3223 - accuracy: 0.1023
on_train_batch_begin: 1599839441.425041s

28 step training time: 0.068262s

on_train_batch_end: 1599839441.487931s

29696/50000 [================>.............] - ETA: 1s - loss: 1.3202 - accuracy: 0.1023
on_train_batch_begin: 1599839441.488390s

29 step training time: 0.063349s

on_train_batch_end: 1599839441.553404s

30720/50000 [=================>............] - ETA: 1s - loss: 1.3133 - accuracy: 0.1023
on_train_batch_begin: 1599839441.553843s

30 step training time: 0.065452s

on_train_batch_end: 1599839441.615762s

31744/50000 [==================>...........] - ETA: 1s - loss: 1.3149 - accuracy: 0.1023
on_train_batch_begin: 1599839441.616205s

31 step training time: 0.062362s

on_train_batch_end: 1599839441.678604s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.3121 - accuracy: 0.1023
on_train_batch_begin: 1599839441.679042s

32 step training time: 0.062838s

on_train_batch_end: 1599839441.742849s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.3085 - accuracy: 0.1023
on_train_batch_begin: 1599839441.743327s

33 step training time: 0.064285s

on_train_batch_end: 1599839441.808433s

34816/50000 [===================>..........] - ETA: 0s - loss: 1.3057 - accuracy: 0.1023
on_train_batch_begin: 1599839441.808900s

34 step training time: 0.065573s

on_train_batch_end: 1599839441.872750s

35840/50000 [====================>.........] - ETA: 0s - loss: 1.3051 - accuracy: 0.1023
on_train_batch_begin: 1599839441.873270s

35 step training time: 0.064370s

on_train_batch_end: 1599839441.939353s

36864/50000 [=====================>........] - ETA: 0s - loss: 1.3048 - accuracy: 0.1023
on_train_batch_begin: 1599839441.939759s

36 step training time: 0.066489s

on_train_batch_end: 1599839442.000775s

37888/50000 [=====================>........] - ETA: 0s - loss: 1.2983 - accuracy: 0.1023
on_train_batch_begin: 1599839442.001177s

37 step training time: 0.061418s

on_train_batch_end: 1599839442.063730s

38912/50000 [======================>.......] - ETA: 0s - loss: 1.2965 - accuracy: 0.1023
on_train_batch_begin: 1599839442.064108s

38 step training time: 0.062931s

on_train_batch_end: 1599839442.124684s

39936/50000 [======================>.......] - ETA: 0s - loss: 1.2911 - accuracy: 0.1023
on_train_batch_begin: 1599839442.125140s

39 step training time: 0.061032s

on_train_batch_end: 1599839442.189048s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.2838 - accuracy: 0.1023
on_train_batch_begin: 1599839442.189427s

40 step training time: 0.064287s

on_train_batch_end: 1599839442.252261s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.2825 - accuracy: 0.1023
on_train_batch_begin: 1599839442.252633s

41 step training time: 0.063206s

on_train_batch_end: 1599839442.320250s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.2827 - accuracy: 0.1023
on_train_batch_begin: 1599839442.320602s

42 step training time: 0.067969s

on_train_batch_end: 1599839442.381636s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.2813 - accuracy: 0.1023
on_train_batch_begin: 1599839442.381989s

43 step training time: 0.061386s

on_train_batch_end: 1599839442.446241s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.2762 - accuracy: 0.1023
on_train_batch_begin: 1599839442.446614s

44 step training time: 0.064625s

on_train_batch_end: 1599839442.506743s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.2744 - accuracy: 0.1023
on_train_batch_begin: 1599839442.507132s

45 step training time: 0.060519s

on_train_batch_end: 1599839442.567854s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.2736 - accuracy: 0.1023
on_train_batch_begin: 1599839442.568236s

46 step training time: 0.061104s

on_train_batch_end: 1599839442.631648s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.2691 - accuracy: 0.1023
on_train_batch_begin: 1599839442.632058s

47 step training time: 0.063822s

on_train_batch_end: 1599839442.692896s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2690 - accuracy: 0.1024
on_train_batch_begin: 1599839442.693269s

48 step training time: 0.061211s

on_train_batch_end: 1599839442.755262s

on_test_batch_begin: 1599839442.800284s

49 step training time: 0.107015s

on_epoch_end: 1599839443.054639s

Validation time: 0.254324s

Real time: 1599839443.054639s

Epoch time: 3.4359323978424072s

50000/50000 [==============================] - 3s 69us/sample - loss: 1.2646 - accuracy: 0.1024 - val_loss: 7.2021 - val_accuracy: 0.0999

on_epoch_begin: 1599839443.054909s

Real time: 1599839443.0549169
Epoch 5/5

on_train_batch_begin: 1599839443.062889s

on_train_batch_end: 1599839443.126205s

 1024/50000 [..............................] - ETA: 3s - loss: 1.0905 - accuracy: 0.1028
on_train_batch_begin: 1599839443.126619s

1 step training time: 0.063730s

on_train_batch_end: 1599839443.189851s

 2048/50000 [>.............................] - ETA: 3s - loss: 1.0718 - accuracy: 0.1025
on_train_batch_begin: 1599839443.190258s

2 step training time: 0.063638s

on_train_batch_end: 1599839443.251307s

 3072/50000 [>.............................] - ETA: 3s - loss: 1.0316 - accuracy: 0.1026
on_train_batch_begin: 1599839443.251709s

3 step training time: 0.061452s

on_train_batch_end: 1599839443.314529s

 4096/50000 [=>............................] - ETA: 2s - loss: 1.0405 - accuracy: 0.1027
on_train_batch_begin: 1599839443.314929s

4 step training time: 0.063220s

on_train_batch_end: 1599839443.374523s

 5120/50000 [==>...........................] - ETA: 2s - loss: 1.0151 - accuracy: 0.1025
on_train_batch_begin: 1599839443.374891s

5 step training time: 0.059962s

on_train_batch_end: 1599839443.434845s

 6144/50000 [==>...........................] - ETA: 2s - loss: 1.0004 - accuracy: 0.1027
on_train_batch_begin: 1599839443.435230s

6 step training time: 0.060339s

on_train_batch_end: 1599839443.495481s

 7168/50000 [===>..........................] - ETA: 2s - loss: 0.9891 - accuracy: 0.1029
on_train_batch_begin: 1599839443.495863s

7 step training time: 0.060633s

on_train_batch_end: 1599839443.555904s

 8192/50000 [===>..........................] - ETA: 2s - loss: 0.9895 - accuracy: 0.1029
on_train_batch_begin: 1599839443.556286s

8 step training time: 0.060423s

on_train_batch_end: 1599839443.619580s

 9216/50000 [====>.........................] - ETA: 2s - loss: 0.9883 - accuracy: 0.1029
on_train_batch_begin: 1599839443.619952s

9 step training time: 0.063666s

on_train_batch_end: 1599839443.680654s

10240/50000 [=====>........................] - ETA: 2s - loss: 0.9990 - accuracy: 0.1028
on_train_batch_begin: 1599839443.681050s

10 step training time: 0.061098s

on_train_batch_end: 1599839443.743024s

11264/50000 [=====>........................] - ETA: 2s - loss: 0.9846 - accuracy: 0.1029
on_train_batch_begin: 1599839443.743469s

11 step training time: 0.062418s

on_train_batch_end: 1599839443.808219s

12288/50000 [======>.......................] - ETA: 2s - loss: 0.9859 - accuracy: 0.1029
on_train_batch_begin: 1599839443.808616s

12 step training time: 0.065148s

on_train_batch_end: 1599839443.869006s

13312/50000 [======>.......................] - ETA: 2s - loss: 0.9867 - accuracy: 0.1029
on_train_batch_begin: 1599839443.869431s

13 step training time: 0.060815s

on_train_batch_end: 1599839443.936288s

14336/50000 [=======>......................] - ETA: 2s - loss: 0.9840 - accuracy: 0.1029
on_train_batch_begin: 1599839443.936689s

14 step training time: 0.067257s

on_train_batch_end: 1599839443.996214s

15360/50000 [========>.....................] - ETA: 2s - loss: 0.9833 - accuracy: 0.1030
on_train_batch_begin: 1599839443.996594s

15 step training time: 0.059906s

on_train_batch_end: 1599839444.057000s

16384/50000 [========>.....................] - ETA: 2s - loss: 0.9761 - accuracy: 0.1029
on_train_batch_begin: 1599839444.057416s

16 step training time: 0.060821s

on_train_batch_end: 1599839444.119617s

17408/50000 [=========>....................] - ETA: 1s - loss: 0.9772 - accuracy: 0.1029
on_train_batch_begin: 1599839444.120002s

17 step training time: 0.062586s

on_train_batch_end: 1599839444.183139s

18432/50000 [==========>...................] - ETA: 1s - loss: 0.9762 - accuracy: 0.1029
on_train_batch_begin: 1599839444.183554s

18 step training time: 0.063552s

on_train_batch_end: 1599839444.244446s

19456/50000 [==========>...................] - ETA: 1s - loss: 0.9769 - accuracy: 0.1028
on_train_batch_begin: 1599839444.244824s

19 step training time: 0.061270s

on_train_batch_end: 1599839444.305605s

20480/50000 [===========>..................] - ETA: 1s - loss: 0.9830 - accuracy: 0.1028
on_train_batch_begin: 1599839444.305969s

20 step training time: 0.061145s

on_train_batch_end: 1599839444.368756s

21504/50000 [===========>..................] - ETA: 1s - loss: 0.9842 - accuracy: 0.1028
on_train_batch_begin: 1599839444.369205s

21 step training time: 0.063236s

on_train_batch_end: 1599839444.430622s

22528/50000 [============>.................] - ETA: 1s - loss: 0.9849 - accuracy: 0.1027
on_train_batch_begin: 1599839444.431031s

22 step training time: 0.061826s

on_train_batch_end: 1599839444.492614s

23552/50000 [=============>................] - ETA: 1s - loss: 0.9852 - accuracy: 0.1027
on_train_batch_begin: 1599839444.493026s

23 step training time: 0.061995s

on_train_batch_end: 1599839444.555560s

24576/50000 [=============>................] - ETA: 1s - loss: 0.9824 - accuracy: 0.1027
on_train_batch_begin: 1599839444.555937s

24 step training time: 0.062911s

on_train_batch_end: 1599839444.617487s

25600/50000 [==============>...............] - ETA: 1s - loss: 0.9815 - accuracy: 0.1027
on_train_batch_begin: 1599839444.617831s

25 step training time: 0.061894s

on_train_batch_end: 1599839444.681223s

26624/50000 [==============>...............] - ETA: 1s - loss: 0.9872 - accuracy: 0.1027
on_train_batch_begin: 1599839444.681637s

26 step training time: 0.063805s

on_train_batch_end: 1599839444.745285s

27648/50000 [===============>..............] - ETA: 1s - loss: 0.9878 - accuracy: 0.1027
on_train_batch_begin: 1599839444.745715s

27 step training time: 0.064078s

on_train_batch_end: 1599839444.811027s

28672/50000 [================>.............] - ETA: 1s - loss: 0.9860 - accuracy: 0.1027
on_train_batch_begin: 1599839444.811428s

28 step training time: 0.065714s

on_train_batch_end: 1599839444.873566s

29696/50000 [================>.............] - ETA: 1s - loss: 0.9853 - accuracy: 0.1027
on_train_batch_begin: 1599839444.873974s

29 step training time: 0.062546s

on_train_batch_end: 1599839444.939410s

30720/50000 [=================>............] - ETA: 1s - loss: 0.9876 - accuracy: 0.1027
on_train_batch_begin: 1599839444.939790s

30 step training time: 0.065816s

on_train_batch_end: 1599839445.003844s

31744/50000 [==================>...........] - ETA: 1s - loss: 0.9826 - accuracy: 0.1027
on_train_batch_begin: 1599839445.004267s

31 step training time: 0.064476s

on_train_batch_end: 1599839445.067046s

32768/50000 [==================>...........] - ETA: 1s - loss: 0.9855 - accuracy: 0.1028
on_train_batch_begin: 1599839445.067425s

32 step training time: 0.063159s

on_train_batch_end: 1599839445.129414s

33792/50000 [===================>..........] - ETA: 0s - loss: 0.9840 - accuracy: 0.1028
on_train_batch_begin: 1599839445.129811s

33 step training time: 0.062386s

on_train_batch_end: 1599839445.194307s

34816/50000 [===================>..........] - ETA: 0s - loss: 0.9809 - accuracy: 0.1028
on_train_batch_begin: 1599839445.194733s

34 step training time: 0.064922s

on_train_batch_end: 1599839445.257989s

35840/50000 [====================>.........] - ETA: 0s - loss: 0.9778 - accuracy: 0.1028
on_train_batch_begin: 1599839445.258393s

35 step training time: 0.063660s

on_train_batch_end: 1599839445.321655s

36864/50000 [=====================>........] - ETA: 0s - loss: 0.9801 - accuracy: 0.1028
on_train_batch_begin: 1599839445.322053s

36 step training time: 0.063661s

on_train_batch_end: 1599839445.387021s

37888/50000 [=====================>........] - ETA: 0s - loss: 0.9804 - accuracy: 0.1028
on_train_batch_begin: 1599839445.387437s

37 step training time: 0.065384s

on_train_batch_end: 1599839445.451764s

38912/50000 [======================>.......] - ETA: 0s - loss: 0.9799 - accuracy: 0.1028
on_train_batch_begin: 1599839445.452152s

38 step training time: 0.064715s

on_train_batch_end: 1599839445.515959s

39936/50000 [======================>.......] - ETA: 0s - loss: 0.9778 - accuracy: 0.1028
on_train_batch_begin: 1599839445.516372s

39 step training time: 0.064220s

on_train_batch_end: 1599839445.577115s

40960/50000 [=======================>......] - ETA: 0s - loss: 0.9782 - accuracy: 0.1028
on_train_batch_begin: 1599839445.577515s

40 step training time: 0.061142s

on_train_batch_end: 1599839445.640283s

41984/50000 [========================>.....] - ETA: 0s - loss: 0.9759 - accuracy: 0.1028
on_train_batch_begin: 1599839445.640696s

41 step training time: 0.063181s

on_train_batch_end: 1599839445.702001s

43008/50000 [========================>.....] - ETA: 0s - loss: 0.9768 - accuracy: 0.1028
on_train_batch_begin: 1599839445.702383s

42 step training time: 0.061688s

on_train_batch_end: 1599839445.764467s

44032/50000 [=========================>....] - ETA: 0s - loss: 0.9751 - accuracy: 0.1028
on_train_batch_begin: 1599839445.764920s

43 step training time: 0.062537s

on_train_batch_end: 1599839445.826220s

45056/50000 [==========================>...] - ETA: 0s - loss: 0.9761 - accuracy: 0.1028
on_train_batch_begin: 1599839445.826658s

44 step training time: 0.061738s

on_train_batch_end: 1599839445.889387s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.9731 - accuracy: 0.1028
on_train_batch_begin: 1599839445.889806s

45 step training time: 0.063148s

on_train_batch_end: 1599839445.951127s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.9709 - accuracy: 0.1029
on_train_batch_begin: 1599839445.951550s

46 step training time: 0.061745s

on_train_batch_end: 1599839446.013576s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9725 - accuracy: 0.1029
on_train_batch_begin: 1599839446.014013s

47 step training time: 0.062462s

on_train_batch_end: 1599839446.081892s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9717 - accuracy: 0.1029
on_train_batch_begin: 1599839446.082369s

48 step training time: 0.068357s

on_train_batch_end: 1599839446.146246s

on_test_batch_begin: 1599839446.182482s

49 step training time: 0.100113s

on_epoch_end: 1599839446.456762s

Validation time: 0.274263s

Real time: 1599839446.456762s

Epoch time: 3.4018709659576416s

50000/50000 [==============================] - 3s 68us/sample - loss: 0.9703 - accuracy: 0.1029 - val_loss: 6.8904 - val_accuracy: 0.0999
Tempo do fit: 163.1542887687683