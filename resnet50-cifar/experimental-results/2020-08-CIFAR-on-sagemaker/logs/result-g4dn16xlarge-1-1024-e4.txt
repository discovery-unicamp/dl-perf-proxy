wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:24
   204800/170498071 [..............................] - ETA: 1:14
  1368064/170498071 [..............................] - ETA: 17s 
  4227072/170498071 [..............................] - ETA: 7s 
  7757824/170498071 [>.............................] - ETA: 5s
 11083776/170498071 [>.............................] - ETA: 4s
 14278656/170498071 [=>............................] - ETA: 3s
 17752064/170498071 [==>...........................] - ETA: 3s
 20848640/170498071 [==>...........................] - ETA: 3s
 23764992/170498071 [===>..........................] - ETA: 3s
 26648576/170498071 [===>..........................] - ETA: 2s
 29532160/170498071 [====>.........................] - ETA: 2s
 31588352/170498071 [====>.........................] - ETA: 2s
 35250176/170498071 [=====>........................] - ETA: 2s
 38150144/170498071 [=====>........................] - ETA: 2s
 41033728/170498071 [======>.......................] - ETA: 2s
 43917312/170498071 [======>.......................] - ETA: 2s
 46800896/170498071 [=======>......................] - ETA: 2s
 49668096/170498071 [=======>......................] - ETA: 2s
 52551680/170498071 [========>.....................] - ETA: 2s
 55443456/170498071 [========>.....................] - ETA: 2s
 58449920/170498071 [=========>....................] - ETA: 2s
 61677568/170498071 [=========>....................] - ETA: 2s
 64757760/170498071 [==========>...................] - ETA: 1s
 67690496/170498071 [==========>...................] - ETA: 1s
 70590464/170498071 [===========>..................] - ETA: 1s
 73752576/170498071 [===========>..................] - ETA: 1s
 76668928/170498071 [============>.................] - ETA: 1s
 79732736/170498071 [=============>................] - ETA: 1s
 82632704/170498071 [=============>................] - ETA: 1s
 85712896/170498071 [==============>...............] - ETA: 1s
 88539136/170498071 [==============>...............] - ETA: 1s
 91693056/170498071 [===============>..............] - ETA: 1s
 94576640/170498071 [===============>..............] - ETA: 1s
 97787904/170498071 [================>.............] - ETA: 1s
101081088/170498071 [================>.............] - ETA: 1s
104112128/170498071 [=================>............] - ETA: 1s
106848256/170498071 [=================>............] - ETA: 1s
109944832/170498071 [==================>...........] - ETA: 1s
113008640/170498071 [==================>...........] - ETA: 1s
115908608/170498071 [===================>..........] - ETA: 0s
118939648/170498071 [===================>..........] - ETA: 0s
121905152/170498071 [====================>.........] - ETA: 0s
124805120/170498071 [====================>.........] - ETA: 0s
127803392/170498071 [=====================>........] - ETA: 0s
130785280/170498071 [======================>.......] - ETA: 0s
134012928/170498071 [======================>.......] - ETA: 0s
137125888/170498071 [=======================>......] - ETA: 0s
139862016/170498071 [=======================>......] - ETA: 0s
142860288/170498071 [========================>.....] - ETA: 0s
145547264/170498071 [========================>.....] - ETA: 0s
148267008/170498071 [=========================>....] - ETA: 0s
151199744/170498071 [=========================>....] - ETA: 0s
154591232/170498071 [==========================>...] - ETA: 0s
157802496/170498071 [==========================>...] - ETA: 0s
161013760/170498071 [===========================>..] - ETA: 0s
164208640/170498071 [===========================>..] - ETA: 0s
167256064/170498071 [============================>.] - ETA: 0s
170254336/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 3563520/94765736 [>.............................] - ETA: 1s
13787136/94765736 [===>..........................] - ETA: 0s
19873792/94765736 [=====>........................] - ETA: 0s
23863296/94765736 [======>.......................] - ETA: 0s
30294016/94765736 [========>.....................] - ETA: 0s
35119104/94765736 [==========>...................] - ETA: 0s
40624128/94765736 [===========>..................] - ETA: 0s
45309952/94765736 [=============>................] - ETA: 0s
50552832/94765736 [===============>..............] - ETA: 0s
54067200/94765736 [================>.............] - ETA: 0s
60719104/94765736 [==================>...........] - ETA: 0s
64012288/94765736 [===================>..........] - ETA: 0s
71106560/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
90161152/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.838570356369019
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615690334.187798s

Real time: 1615690334.1878157
Epoch 1/5

on_train_batch_begin: 1615690334.941466s

on_train_batch_end: 1615690353.372515s

 1024/50000 [..............................] - ETA: 15:17 - loss: 17.9321 - accuracy: 4.5586e-04
on_train_batch_begin: 1615690353.373158s

1 step training time: 18.431692s

on_train_batch_end: 1615690353.696420s

 2048/50000 [>.............................] - ETA: 7:36 - loss: 15.8448 - accuracy: 4.2963e-04 
on_train_batch_begin: 1615690353.696747s

2 step training time: 0.323588s

on_train_batch_end: 1615690354.018403s

 3072/50000 [>.............................] - ETA: 5:02 - loss: 13.6783 - accuracy: 5.8778e-04
on_train_batch_begin: 1615690354.018696s

3 step training time: 0.321949s

on_train_batch_end: 1615690354.339611s

 4096/50000 [=>............................] - ETA: 3:45 - loss: 12.3574 - accuracy: 8.7285e-04
on_train_batch_begin: 1615690354.339883s

4 step training time: 0.321187s

on_train_batch_end: 1615690354.656971s

 5120/50000 [==>...........................] - ETA: 2:59 - loss: 11.5098 - accuracy: 0.0014    
on_train_batch_begin: 1615690354.657240s

5 step training time: 0.317357s

on_train_batch_end: 1615690354.977371s

 6144/50000 [==>...........................] - ETA: 2:28 - loss: 10.9303 - accuracy: 0.0029
on_train_batch_begin: 1615690354.977640s

6 step training time: 0.320400s

on_train_batch_end: 1615690355.297917s

 7168/50000 [===>..........................] - ETA: 2:06 - loss: 10.4909 - accuracy: 0.0060
on_train_batch_begin: 1615690355.298215s

7 step training time: 0.320575s

on_train_batch_end: 1615690355.620511s

 8192/50000 [===>..........................] - ETA: 1:49 - loss: 10.1438 - accuracy: 0.0080
on_train_batch_begin: 1615690355.620804s

8 step training time: 0.322589s

on_train_batch_end: 1615690355.943046s

 9216/50000 [====>.........................] - ETA: 1:36 - loss: 9.8684 - accuracy: 0.0107 
on_train_batch_begin: 1615690355.943356s

9 step training time: 0.322552s

on_train_batch_end: 1615690356.265468s

10240/50000 [=====>........................] - ETA: 1:25 - loss: 9.6360 - accuracy: 0.0136
on_train_batch_begin: 1615690356.265735s

10 step training time: 0.322379s

on_train_batch_end: 1615690356.585741s

11264/50000 [=====>........................] - ETA: 1:17 - loss: 9.4461 - accuracy: 0.0171
on_train_batch_begin: 1615690356.586012s

11 step training time: 0.320277s

on_train_batch_end: 1615690356.903960s

12288/50000 [======>.......................] - ETA: 1:09 - loss: 9.2736 - accuracy: 0.0200
on_train_batch_begin: 1615690356.904251s

12 step training time: 0.318239s

on_train_batch_end: 1615690357.226941s

13312/50000 [======>.......................] - ETA: 1:03 - loss: 9.1311 - accuracy: 0.0232
on_train_batch_begin: 1615690357.227267s

13 step training time: 0.323015s

on_train_batch_end: 1615690357.549473s

14336/50000 [=======>......................] - ETA: 58s - loss: 8.9979 - accuracy: 0.0255 
on_train_batch_begin: 1615690357.549862s

14 step training time: 0.322596s

on_train_batch_end: 1615690357.873078s

15360/50000 [========>.....................] - ETA: 53s - loss: 8.8832 - accuracy: 0.0275
on_train_batch_begin: 1615690357.873428s

15 step training time: 0.323565s

on_train_batch_end: 1615690358.196517s

16384/50000 [========>.....................] - ETA: 49s - loss: 8.7658 - accuracy: 0.0296
on_train_batch_begin: 1615690358.196813s

16 step training time: 0.323385s

on_train_batch_end: 1615690358.518613s

17408/50000 [=========>....................] - ETA: 45s - loss: 8.6618 - accuracy: 0.0315
on_train_batch_begin: 1615690358.518910s

17 step training time: 0.322096s

on_train_batch_end: 1615690358.835559s

18432/50000 [==========>...................] - ETA: 42s - loss: 8.5571 - accuracy: 0.0339
on_train_batch_begin: 1615690358.835855s

18 step training time: 0.316945s

on_train_batch_end: 1615690359.155042s

19456/50000 [==========>...................] - ETA: 39s - loss: 8.4592 - accuracy: 0.0355
on_train_batch_begin: 1615690359.155343s

19 step training time: 0.319488s

on_train_batch_end: 1615690359.477295s

20480/50000 [===========>..................] - ETA: 36s - loss: 8.3745 - accuracy: 0.0372
on_train_batch_begin: 1615690359.477580s

20 step training time: 0.322237s

on_train_batch_end: 1615690359.800987s

21504/50000 [===========>..................] - ETA: 33s - loss: 8.2901 - accuracy: 0.0385
on_train_batch_begin: 1615690359.801281s

21 step training time: 0.323702s

on_train_batch_end: 1615690360.125764s

22528/50000 [============>.................] - ETA: 31s - loss: 8.2085 - accuracy: 0.0400
on_train_batch_begin: 1615690360.126061s

22 step training time: 0.324780s

on_train_batch_end: 1615690360.449536s

23552/50000 [=============>................] - ETA: 29s - loss: 8.1509 - accuracy: 0.0397
on_train_batch_begin: 1615690360.449835s

23 step training time: 0.323774s

on_train_batch_end: 1615690360.772810s

24576/50000 [=============>................] - ETA: 27s - loss: 8.0828 - accuracy: 0.0408
on_train_batch_begin: 1615690360.773105s

24 step training time: 0.323270s

on_train_batch_end: 1615690361.093636s

25600/50000 [==============>...............] - ETA: 25s - loss: 8.0138 - accuracy: 0.0424
on_train_batch_begin: 1615690361.093932s

25 step training time: 0.320827s

on_train_batch_end: 1615690361.413690s

26624/50000 [==============>...............] - ETA: 23s - loss: 7.9529 - accuracy: 0.0436
on_train_batch_begin: 1615690361.413990s

26 step training time: 0.320058s

on_train_batch_end: 1615690361.734479s

27648/50000 [===============>..............] - ETA: 22s - loss: 7.8936 - accuracy: 0.0450
on_train_batch_begin: 1615690361.734776s

27 step training time: 0.320786s

on_train_batch_end: 1615690362.057979s

28672/50000 [================>.............] - ETA: 20s - loss: 7.8400 - accuracy: 0.0462
on_train_batch_begin: 1615690362.058360s

28 step training time: 0.323584s

on_train_batch_end: 1615690362.380794s

29696/50000 [================>.............] - ETA: 19s - loss: 7.7843 - accuracy: 0.0472
on_train_batch_begin: 1615690362.381120s

29 step training time: 0.322760s

on_train_batch_end: 1615690362.704756s

30720/50000 [=================>............] - ETA: 17s - loss: 7.7291 - accuracy: 0.0483
on_train_batch_begin: 1615690362.705103s

30 step training time: 0.323983s

on_train_batch_end: 1615690363.028728s

31744/50000 [==================>...........] - ETA: 16s - loss: 7.6766 - accuracy: 0.0493
on_train_batch_begin: 1615690363.029122s

31 step training time: 0.324019s

on_train_batch_end: 1615690363.353560s

32768/50000 [==================>...........] - ETA: 15s - loss: 7.6233 - accuracy: 0.0506
on_train_batch_begin: 1615690363.353926s

32 step training time: 0.324804s

on_train_batch_end: 1615690363.678106s

33792/50000 [===================>..........] - ETA: 14s - loss: 7.5802 - accuracy: 0.0514
on_train_batch_begin: 1615690363.678481s

33 step training time: 0.324555s

on_train_batch_end: 1615690364.001070s

34816/50000 [===================>..........] - ETA: 13s - loss: 7.5347 - accuracy: 0.0523
on_train_batch_begin: 1615690364.001412s

34 step training time: 0.322931s

on_train_batch_end: 1615690364.324333s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.4894 - accuracy: 0.0532
on_train_batch_begin: 1615690364.324713s

35 step training time: 0.323301s

on_train_batch_end: 1615690364.650121s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.4462 - accuracy: 0.0540
on_train_batch_begin: 1615690364.650493s

36 step training time: 0.325780s

on_train_batch_end: 1615690364.981746s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.4037 - accuracy: 0.0546 
on_train_batch_begin: 1615690364.982136s

37 step training time: 0.331643s

on_train_batch_end: 1615690365.307962s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.3627 - accuracy: 0.0552
on_train_batch_begin: 1615690365.308306s

38 step training time: 0.326170s

on_train_batch_end: 1615690365.631479s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.3194 - accuracy: 0.0556
on_train_batch_begin: 1615690365.631865s

39 step training time: 0.323558s

on_train_batch_end: 1615690365.956633s

40960/50000 [=======================>......] - ETA: 7s - loss: 7.2746 - accuracy: 0.0563
on_train_batch_begin: 1615690365.957015s

40 step training time: 0.325151s

on_train_batch_end: 1615690366.280723s

41984/50000 [========================>.....] - ETA: 6s - loss: 7.2353 - accuracy: 0.0566
on_train_batch_begin: 1615690366.281096s

41 step training time: 0.324081s

on_train_batch_end: 1615690366.602537s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.1964 - accuracy: 0.0570
on_train_batch_begin: 1615690366.602906s

42 step training time: 0.321810s

on_train_batch_end: 1615690366.919735s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.1613 - accuracy: 0.0572
on_train_batch_begin: 1615690366.920108s

43 step training time: 0.317203s

on_train_batch_end: 1615690367.240736s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.1229 - accuracy: 0.0576
on_train_batch_begin: 1615690367.241081s

44 step training time: 0.320973s

on_train_batch_end: 1615690367.565835s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.0877 - accuracy: 0.0581
on_train_batch_begin: 1615690367.566181s

45 step training time: 0.325100s

on_train_batch_end: 1615690367.888412s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.0538 - accuracy: 0.0582
on_train_batch_begin: 1615690367.888768s

46 step training time: 0.322587s

on_train_batch_end: 1615690368.212632s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.0171 - accuracy: 0.0589
on_train_batch_begin: 1615690368.212969s

47 step training time: 0.324201s

on_train_batch_end: 1615690368.530737s

49152/50000 [============================>.] - ETA: 0s - loss: 6.9811 - accuracy: 0.0594
on_train_batch_begin: 1615690368.531082s

48 step training time: 0.318113s

on_train_batch_end: 1615690374.286882s

on_test_batch_begin: 1615690374.478043s

49 step training time: 5.946960s

on_epoch_end: 1615690379.234158s

Validation time: 4.756095s

Real time: 1615690379.234158s

Epoch time: 45.046361446380615s

50000/50000 [==============================] - 45s 901us/sample - loss: 6.9499 - accuracy: 0.0599 - val_loss: 1242.9013 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615690379.234370s

Real time: 1615690379.2343752
Epoch 2/5

on_train_batch_begin: 1615690379.237777s

on_train_batch_end: 1615690379.561830s

 1024/50000 [..............................] - ETA: 15s - loss: 5.3503 - accuracy: 0.0871
on_train_batch_begin: 1615690379.562179s

1 step training time: 0.324401s

on_train_batch_end: 1615690379.884645s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.3931 - accuracy: 0.0834
on_train_batch_begin: 1615690379.884976s

2 step training time: 0.322798s

on_train_batch_end: 1615690380.207103s

 3072/50000 [>.............................] - ETA: 14s - loss: 5.3279 - accuracy: 0.0837
on_train_batch_begin: 1615690380.207503s

3 step training time: 0.322527s

on_train_batch_end: 1615690380.531304s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.2870 - accuracy: 0.0831
on_train_batch_begin: 1615690380.531639s

4 step training time: 0.324136s

on_train_batch_end: 1615690380.854808s

 5120/50000 [==>...........................] - ETA: 14s - loss: 5.2689 - accuracy: 0.0833
on_train_batch_begin: 1615690380.855097s

5 step training time: 0.323458s

on_train_batch_end: 1615690381.178630s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.2407 - accuracy: 0.0832
on_train_batch_begin: 1615690381.178997s

6 step training time: 0.323900s

on_train_batch_end: 1615690381.503441s

 7168/50000 [===>..........................] - ETA: 13s - loss: 5.2148 - accuracy: 0.0832
on_train_batch_begin: 1615690381.503811s

7 step training time: 0.324814s

on_train_batch_end: 1615690381.827963s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.2027 - accuracy: 0.0836
on_train_batch_begin: 1615690381.828341s

8 step training time: 0.324530s

on_train_batch_end: 1615690382.151891s

 9216/50000 [====>.........................] - ETA: 12s - loss: 5.1832 - accuracy: 0.0840
on_train_batch_begin: 1615690382.152270s

9 step training time: 0.323930s

on_train_batch_end: 1615690382.477905s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.1528 - accuracy: 0.0838
on_train_batch_begin: 1615690382.478285s

10 step training time: 0.326015s

on_train_batch_end: 1615690382.803593s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.1269 - accuracy: 0.0835
on_train_batch_begin: 1615690382.803958s

11 step training time: 0.325673s

on_train_batch_end: 1615690383.127042s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.1094 - accuracy: 0.0834
on_train_batch_begin: 1615690383.127444s

12 step training time: 0.323486s

on_train_batch_end: 1615690383.452544s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.0973 - accuracy: 0.0835
on_train_batch_begin: 1615690383.452896s

13 step training time: 0.325452s

on_train_batch_end: 1615690383.778522s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.0761 - accuracy: 0.0831
on_train_batch_begin: 1615690383.778887s

14 step training time: 0.325991s

on_train_batch_end: 1615690384.104178s

15360/50000 [========>.....................] - ETA: 10s - loss: 5.0629 - accuracy: 0.0827
on_train_batch_begin: 1615690384.104546s

15 step training time: 0.325659s

on_train_batch_end: 1615690384.427749s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.0563 - accuracy: 0.0821
on_train_batch_begin: 1615690384.428110s

16 step training time: 0.323564s

on_train_batch_end: 1615690384.752113s

17408/50000 [=========>....................] - ETA: 10s - loss: 5.0329 - accuracy: 0.0823
on_train_batch_begin: 1615690384.752474s

17 step training time: 0.324364s

on_train_batch_end: 1615690385.063056s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.0227 - accuracy: 0.0826 
on_train_batch_begin: 1615690385.063448s

18 step training time: 0.310974s

on_train_batch_end: 1615690385.393989s

19456/50000 [==========>...................] - ETA: 9s - loss: 5.0021 - accuracy: 0.0828
on_train_batch_begin: 1615690385.394375s

19 step training time: 0.330927s

on_train_batch_end: 1615690385.719040s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.9862 - accuracy: 0.0830
on_train_batch_begin: 1615690385.719443s

20 step training time: 0.325068s

on_train_batch_end: 1615690386.040863s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.9739 - accuracy: 0.0831
on_train_batch_begin: 1615690386.041237s

21 step training time: 0.321794s

on_train_batch_end: 1615690386.362074s

22528/50000 [============>.................] - ETA: 8s - loss: 4.9610 - accuracy: 0.0828
on_train_batch_begin: 1615690386.362446s

22 step training time: 0.321209s

on_train_batch_end: 1615690386.679362s

23552/50000 [=============>................] - ETA: 8s - loss: 4.9503 - accuracy: 0.0828
on_train_batch_begin: 1615690386.679697s

23 step training time: 0.317251s

on_train_batch_end: 1615690387.007965s

24576/50000 [=============>................] - ETA: 8s - loss: 4.9411 - accuracy: 0.0825
on_train_batch_begin: 1615690387.008298s

24 step training time: 0.328601s

on_train_batch_end: 1615690387.332374s

25600/50000 [==============>...............] - ETA: 7s - loss: 4.9292 - accuracy: 0.0823
on_train_batch_begin: 1615690387.332740s

25 step training time: 0.324442s

on_train_batch_end: 1615690387.657197s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.9140 - accuracy: 0.0821
on_train_batch_begin: 1615690387.657549s

26 step training time: 0.324809s

on_train_batch_end: 1615690387.983105s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.9057 - accuracy: 0.0815
on_train_batch_begin: 1615690387.983465s

27 step training time: 0.325916s

on_train_batch_end: 1615690388.307824s

28672/50000 [================>.............] - ETA: 6s - loss: 4.8922 - accuracy: 0.0820
on_train_batch_begin: 1615690388.308169s

28 step training time: 0.324704s

on_train_batch_end: 1615690388.631676s

29696/50000 [================>.............] - ETA: 6s - loss: 4.8802 - accuracy: 0.0824
on_train_batch_begin: 1615690388.631971s

29 step training time: 0.323802s

on_train_batch_end: 1615690388.956974s

30720/50000 [=================>............] - ETA: 6s - loss: 4.8693 - accuracy: 0.0826
on_train_batch_begin: 1615690388.957325s

30 step training time: 0.325354s

on_train_batch_end: 1615690389.281704s

31744/50000 [==================>...........] - ETA: 5s - loss: 4.8612 - accuracy: 0.0830
on_train_batch_begin: 1615690389.282046s

31 step training time: 0.324721s

on_train_batch_end: 1615690389.606456s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.8520 - accuracy: 0.0834
on_train_batch_begin: 1615690389.606794s

32 step training time: 0.324748s

on_train_batch_end: 1615690389.931469s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.8433 - accuracy: 0.0838
on_train_batch_begin: 1615690389.931806s

33 step training time: 0.325011s

on_train_batch_end: 1615690390.256816s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.8397 - accuracy: 0.0840
on_train_batch_begin: 1615690390.257187s

34 step training time: 0.325381s

on_train_batch_end: 1615690390.582194s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.8352 - accuracy: 0.0843
on_train_batch_begin: 1615690390.582501s

35 step training time: 0.325315s

on_train_batch_end: 1615690390.906917s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.8233 - accuracy: 0.0846
on_train_batch_begin: 1615690390.907219s

36 step training time: 0.324718s

on_train_batch_end: 1615690391.231616s

37888/50000 [=====================>........] - ETA: 3s - loss: 4.8174 - accuracy: 0.0847
on_train_batch_begin: 1615690391.231944s

37 step training time: 0.324725s

on_train_batch_end: 1615690391.556785s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.8121 - accuracy: 0.0849
on_train_batch_begin: 1615690391.557136s

38 step training time: 0.325192s

on_train_batch_end: 1615690391.882207s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.8046 - accuracy: 0.0851
on_train_batch_begin: 1615690391.882544s

39 step training time: 0.325408s

on_train_batch_end: 1615690392.206625s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.7965 - accuracy: 0.0855
on_train_batch_begin: 1615690392.206977s

40 step training time: 0.324433s

on_train_batch_end: 1615690392.531632s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.7938 - accuracy: 0.0856
on_train_batch_begin: 1615690392.531993s

41 step training time: 0.325015s

on_train_batch_end: 1615690392.856931s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.7876 - accuracy: 0.0857
on_train_batch_begin: 1615690392.857290s

42 step training time: 0.325297s

on_train_batch_end: 1615690393.181830s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.7829 - accuracy: 0.0857
on_train_batch_begin: 1615690393.182201s

43 step training time: 0.324911s

on_train_batch_end: 1615690393.506819s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.7765 - accuracy: 0.0857
on_train_batch_begin: 1615690393.507217s

44 step training time: 0.325016s

on_train_batch_end: 1615690393.832822s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.7738 - accuracy: 0.0857
on_train_batch_begin: 1615690393.833179s

45 step training time: 0.325963s

on_train_batch_end: 1615690394.156982s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.7616 - accuracy: 0.0857
on_train_batch_begin: 1615690394.157335s

46 step training time: 0.324155s

on_train_batch_end: 1615690394.480860s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.7518 - accuracy: 0.0856
on_train_batch_begin: 1615690394.481198s

47 step training time: 0.323864s

on_train_batch_end: 1615690394.805173s

49152/50000 [============================>.] - ETA: 0s - loss: 4.7455 - accuracy: 0.0856
on_train_batch_begin: 1615690394.805497s

48 step training time: 0.324299s

on_train_batch_end: 1615690395.076971s

on_test_batch_begin: 1615690395.088737s

49 step training time: 0.283240s

on_epoch_end: 1615690395.877935s

Validation time: 0.789186s

Real time: 1615690395.877935s

Epoch time: 16.643579721450806s

50000/50000 [==============================] - 17s 333us/sample - loss: 4.7427 - accuracy: 0.0856 - val_loss: 7.5925 - val_accuracy: 0.0998

on_epoch_begin: 1615690395.878140s

Real time: 1615690395.878146
Epoch 3/5

on_train_batch_begin: 1615690395.881520s

on_train_batch_end: 1615690396.207194s

 1024/50000 [..............................] - ETA: 15s - loss: 4.1694 - accuracy: 0.0787
on_train_batch_begin: 1615690396.207528s

1 step training time: 0.326008s

on_train_batch_end: 1615690396.531842s

 2048/50000 [>.............................] - ETA: 15s - loss: 4.2437 - accuracy: 0.0773
on_train_batch_begin: 1615690396.532130s

2 step training time: 0.324602s

on_train_batch_end: 1615690396.856071s

 3072/50000 [>.............................] - ETA: 14s - loss: 4.2577 - accuracy: 0.0790
on_train_batch_begin: 1615690396.856416s

3 step training time: 0.324287s

on_train_batch_end: 1615690397.179484s

 4096/50000 [=>............................] - ETA: 14s - loss: 4.2958 - accuracy: 0.0799
on_train_batch_begin: 1615690397.179819s

4 step training time: 0.323403s

on_train_batch_end: 1615690397.504210s

 5120/50000 [==>...........................] - ETA: 14s - loss: 4.2933 - accuracy: 0.0808
on_train_batch_begin: 1615690397.504561s

5 step training time: 0.324741s

on_train_batch_end: 1615690397.828923s

 6144/50000 [==>...........................] - ETA: 13s - loss: 4.2960 - accuracy: 0.0808
on_train_batch_begin: 1615690397.829258s

6 step training time: 0.324697s

on_train_batch_end: 1615690398.155859s

 7168/50000 [===>..........................] - ETA: 13s - loss: 4.2824 - accuracy: 0.0808
on_train_batch_begin: 1615690398.156207s

7 step training time: 0.326949s

on_train_batch_end: 1615690398.480592s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.2858 - accuracy: 0.0810
on_train_batch_begin: 1615690398.480933s

8 step training time: 0.324726s

on_train_batch_end: 1615690398.805387s

 9216/50000 [====>.........................] - ETA: 12s - loss: 4.2600 - accuracy: 0.0812
on_train_batch_begin: 1615690398.805713s

9 step training time: 0.324780s

on_train_batch_end: 1615690399.130511s

10240/50000 [=====>........................] - ETA: 12s - loss: 4.2425 - accuracy: 0.0816
on_train_batch_begin: 1615690399.130856s

10 step training time: 0.325143s

on_train_batch_end: 1615690399.453398s

11264/50000 [=====>........................] - ETA: 12s - loss: 4.2366 - accuracy: 0.0814
on_train_batch_begin: 1615690399.453751s

11 step training time: 0.322895s

on_train_batch_end: 1615690399.778607s

12288/50000 [======>.......................] - ETA: 11s - loss: 4.2302 - accuracy: 0.0812
on_train_batch_begin: 1615690399.778954s

12 step training time: 0.325203s

on_train_batch_end: 1615690400.101986s

13312/50000 [======>.......................] - ETA: 11s - loss: 4.2269 - accuracy: 0.0813
on_train_batch_begin: 1615690400.102333s

13 step training time: 0.323379s

on_train_batch_end: 1615690400.427079s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.2257 - accuracy: 0.0812
on_train_batch_begin: 1615690400.427440s

14 step training time: 0.325107s

on_train_batch_end: 1615690400.752747s

15360/50000 [========>.....................] - ETA: 10s - loss: 4.2339 - accuracy: 0.0808
on_train_batch_begin: 1615690400.753073s

15 step training time: 0.325633s

on_train_batch_end: 1615690401.076969s

16384/50000 [========>.....................] - ETA: 10s - loss: 4.2216 - accuracy: 0.0806
on_train_batch_begin: 1615690401.077328s

16 step training time: 0.324255s

on_train_batch_end: 1615690401.400937s

17408/50000 [=========>....................] - ETA: 10s - loss: 4.2081 - accuracy: 0.0804
on_train_batch_begin: 1615690401.401278s

17 step training time: 0.323950s

on_train_batch_end: 1615690401.725040s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.1984 - accuracy: 0.0803
on_train_batch_begin: 1615690401.725377s

18 step training time: 0.324100s

on_train_batch_end: 1615690402.049625s

19456/50000 [==========>...................] - ETA: 9s - loss: 4.1919 - accuracy: 0.0801 
on_train_batch_begin: 1615690402.049951s

19 step training time: 0.324574s

on_train_batch_end: 1615690402.374739s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.1839 - accuracy: 0.0801
on_train_batch_begin: 1615690402.375103s

20 step training time: 0.325152s

on_train_batch_end: 1615690402.698947s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.1787 - accuracy: 0.0801
on_train_batch_begin: 1615690402.699316s

21 step training time: 0.324213s

on_train_batch_end: 1615690403.022334s

22528/50000 [============>.................] - ETA: 8s - loss: 4.1632 - accuracy: 0.0800
on_train_batch_begin: 1615690403.022680s

22 step training time: 0.323364s

on_train_batch_end: 1615690403.347514s

23552/50000 [=============>................] - ETA: 8s - loss: 4.1527 - accuracy: 0.0800
on_train_batch_begin: 1615690403.347846s

23 step training time: 0.325166s

on_train_batch_end: 1615690403.672589s

24576/50000 [=============>................] - ETA: 8s - loss: 4.1468 - accuracy: 0.0802
on_train_batch_begin: 1615690403.672930s

24 step training time: 0.325084s

on_train_batch_end: 1615690403.996575s

25600/50000 [==============>...............] - ETA: 7s - loss: 4.1467 - accuracy: 0.0799
on_train_batch_begin: 1615690403.996931s

25 step training time: 0.324001s

on_train_batch_end: 1615690404.320531s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.1483 - accuracy: 0.0798
on_train_batch_begin: 1615690404.320879s

26 step training time: 0.323948s

on_train_batch_end: 1615690404.644740s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.1441 - accuracy: 0.0799
on_train_batch_begin: 1615690404.645095s

27 step training time: 0.324216s

on_train_batch_end: 1615690404.970295s

28672/50000 [================>.............] - ETA: 6s - loss: 4.1487 - accuracy: 0.0799
on_train_batch_begin: 1615690404.970650s

28 step training time: 0.325555s

on_train_batch_end: 1615690405.293794s

29696/50000 [================>.............] - ETA: 6s - loss: 4.1471 - accuracy: 0.0799
on_train_batch_begin: 1615690405.294158s

29 step training time: 0.323508s

on_train_batch_end: 1615690405.618348s

30720/50000 [=================>............] - ETA: 6s - loss: 4.1439 - accuracy: 0.0799
on_train_batch_begin: 1615690405.618715s

30 step training time: 0.324557s

on_train_batch_end: 1615690405.957839s

31744/50000 [==================>...........] - ETA: 5s - loss: 4.1408 - accuracy: 0.0800
on_train_batch_begin: 1615690405.958185s

31 step training time: 0.339470s

on_train_batch_end: 1615690406.283823s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.1395 - accuracy: 0.0800
on_train_batch_begin: 1615690406.284173s

32 step training time: 0.325988s

on_train_batch_end: 1615690406.610369s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.1404 - accuracy: 0.0802
on_train_batch_begin: 1615690406.610707s

33 step training time: 0.326534s

on_train_batch_end: 1615690406.938559s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.1377 - accuracy: 0.0803
on_train_batch_begin: 1615690406.938884s

34 step training time: 0.328176s

on_train_batch_end: 1615690407.263232s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.1366 - accuracy: 0.0805
on_train_batch_begin: 1615690407.263581s

35 step training time: 0.324698s

on_train_batch_end: 1615690407.580507s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.1321 - accuracy: 0.0806
on_train_batch_begin: 1615690407.580879s

36 step training time: 0.317297s

on_train_batch_end: 1615690407.915823s

37888/50000 [=====================>........] - ETA: 3s - loss: 4.1286 - accuracy: 0.0806
on_train_batch_begin: 1615690407.916187s

37 step training time: 0.335308s

on_train_batch_end: 1615690408.242585s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.1221 - accuracy: 0.0807
on_train_batch_begin: 1615690408.242945s

38 step training time: 0.326758s

on_train_batch_end: 1615690408.565098s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.1199 - accuracy: 0.0808
on_train_batch_begin: 1615690408.565447s

39 step training time: 0.322502s

on_train_batch_end: 1615690408.890764s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.1187 - accuracy: 0.0808
on_train_batch_begin: 1615690408.891098s

40 step training time: 0.325651s

on_train_batch_end: 1615690409.217967s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.1131 - accuracy: 0.0809
on_train_batch_begin: 1615690409.218290s

41 step training time: 0.327192s

on_train_batch_end: 1615690409.543281s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.1099 - accuracy: 0.0809
on_train_batch_begin: 1615690409.543602s

42 step training time: 0.325312s

on_train_batch_end: 1615690409.871325s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.1060 - accuracy: 0.0809
on_train_batch_begin: 1615690409.871654s

43 step training time: 0.328052s

on_train_batch_end: 1615690410.201318s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.0975 - accuracy: 0.0810
on_train_batch_begin: 1615690410.201676s

44 step training time: 0.330022s

on_train_batch_end: 1615690410.527355s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.0951 - accuracy: 0.0809
on_train_batch_begin: 1615690410.527702s

45 step training time: 0.326026s

on_train_batch_end: 1615690410.852853s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.0886 - accuracy: 0.0810
on_train_batch_begin: 1615690410.853186s

46 step training time: 0.325484s

on_train_batch_end: 1615690411.178642s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.0828 - accuracy: 0.0809
on_train_batch_begin: 1615690411.178970s

47 step training time: 0.325784s

on_train_batch_end: 1615690411.503626s

49152/50000 [============================>.] - ETA: 0s - loss: 4.0790 - accuracy: 0.0809
on_train_batch_begin: 1615690411.503984s

48 step training time: 0.325014s

on_train_batch_end: 1615690411.776887s

on_test_batch_begin: 1615690411.790539s

49 step training time: 0.286555s

on_epoch_end: 1615690412.585599s

Validation time: 0.795049s

Real time: 1615690412.585599s

Epoch time: 16.70747399330139s

50000/50000 [==============================] - 17s 334us/sample - loss: 4.0752 - accuracy: 0.0809 - val_loss: 6.8842 - val_accuracy: 0.1000

on_epoch_begin: 1615690412.585812s

Real time: 1615690412.5858173
Epoch 4/5

on_train_batch_begin: 1615690412.589262s

on_train_batch_end: 1615690412.918301s

 1024/50000 [..............................] - ETA: 15s - loss: 3.7263 - accuracy: 0.0792
on_train_batch_begin: 1615690412.918632s

1 step training time: 0.329370s

on_train_batch_end: 1615690413.245463s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.7652 - accuracy: 0.0776
on_train_batch_begin: 1615690413.245795s

2 step training time: 0.327163s

on_train_batch_end: 1615690413.572786s

 3072/50000 [>.............................] - ETA: 15s - loss: 3.7683 - accuracy: 0.0780
on_train_batch_begin: 1615690413.573108s

3 step training time: 0.327313s

on_train_batch_end: 1615690413.899953s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.7355 - accuracy: 0.0781
on_train_batch_begin: 1615690413.900285s

4 step training time: 0.327178s

on_train_batch_end: 1615690414.224833s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.7034 - accuracy: 0.0784
on_train_batch_begin: 1615690414.225175s

5 step training time: 0.324889s

on_train_batch_end: 1615690414.550186s

 6144/50000 [==>...........................] - ETA: 14s - loss: 3.6918 - accuracy: 0.0785
on_train_batch_begin: 1615690414.550542s

6 step training time: 0.325367s

on_train_batch_end: 1615690414.877722s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.6832 - accuracy: 0.0790
on_train_batch_begin: 1615690414.878057s

7 step training time: 0.327516s

on_train_batch_end: 1615690415.206702s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.6917 - accuracy: 0.0789
on_train_batch_begin: 1615690415.207046s

8 step training time: 0.328989s

on_train_batch_end: 1615690415.535947s

 9216/50000 [====>.........................] - ETA: 13s - loss: 3.6616 - accuracy: 0.0796
on_train_batch_begin: 1615690415.536280s

9 step training time: 0.329234s

on_train_batch_end: 1615690415.864280s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.6833 - accuracy: 0.0799
on_train_batch_begin: 1615690415.864581s

10 step training time: 0.328300s

on_train_batch_end: 1615690416.190927s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.6688 - accuracy: 0.0804
on_train_batch_begin: 1615690416.191298s

11 step training time: 0.326717s

on_train_batch_end: 1615690416.516679s

12288/50000 [======>.......................] - ETA: 12s - loss: 3.6759 - accuracy: 0.0805
on_train_batch_begin: 1615690416.516987s

12 step training time: 0.325689s

on_train_batch_end: 1615690416.845564s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.6839 - accuracy: 0.0805
on_train_batch_begin: 1615690416.845908s

13 step training time: 0.328921s

on_train_batch_end: 1615690417.177313s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.6805 - accuracy: 0.0807
on_train_batch_begin: 1615690417.177660s

14 step training time: 0.331752s

on_train_batch_end: 1615690417.505321s

15360/50000 [========>.....................] - ETA: 11s - loss: 3.6740 - accuracy: 0.0811
on_train_batch_begin: 1615690417.505682s

15 step training time: 0.328022s

on_train_batch_end: 1615690417.833667s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.6663 - accuracy: 0.0812
on_train_batch_begin: 1615690417.834010s

16 step training time: 0.328328s

on_train_batch_end: 1615690418.160493s

17408/50000 [=========>....................] - ETA: 10s - loss: 3.6680 - accuracy: 0.0812
on_train_batch_begin: 1615690418.160847s

17 step training time: 0.326837s

on_train_batch_end: 1615690418.488570s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.6716 - accuracy: 0.0811
on_train_batch_begin: 1615690418.488915s

18 step training time: 0.328069s

on_train_batch_end: 1615690418.820218s

19456/50000 [==========>...................] - ETA: 9s - loss: 3.6656 - accuracy: 0.0812 
on_train_batch_begin: 1615690418.820557s

19 step training time: 0.331641s

on_train_batch_end: 1615690419.148376s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.6566 - accuracy: 0.0815
on_train_batch_begin: 1615690419.148725s

20 step training time: 0.328168s

on_train_batch_end: 1615690419.477043s

21504/50000 [===========>..................] - ETA: 9s - loss: 3.6480 - accuracy: 0.0817
on_train_batch_begin: 1615690419.477417s

21 step training time: 0.328692s

on_train_batch_end: 1615690419.803049s

22528/50000 [============>.................] - ETA: 8s - loss: 3.6525 - accuracy: 0.0819
on_train_batch_begin: 1615690419.803423s

22 step training time: 0.326006s

on_train_batch_end: 1615690420.135720s

23552/50000 [=============>................] - ETA: 8s - loss: 3.6399 - accuracy: 0.0821
on_train_batch_begin: 1615690420.136065s

23 step training time: 0.332643s

on_train_batch_end: 1615690420.464799s

24576/50000 [=============>................] - ETA: 8s - loss: 3.6333 - accuracy: 0.0822
on_train_batch_begin: 1615690420.465169s

24 step training time: 0.329104s

on_train_batch_end: 1615690420.790924s

25600/50000 [==============>...............] - ETA: 7s - loss: 3.6374 - accuracy: 0.0822
on_train_batch_begin: 1615690420.791288s

25 step training time: 0.326118s

on_train_batch_end: 1615690421.119390s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.6363 - accuracy: 0.0823
on_train_batch_begin: 1615690421.119741s

26 step training time: 0.328453s

on_train_batch_end: 1615690421.446889s

27648/50000 [===============>..............] - ETA: 7s - loss: 3.6373 - accuracy: 0.0824
on_train_batch_begin: 1615690421.447286s

27 step training time: 0.327545s

on_train_batch_end: 1615690421.777145s

28672/50000 [================>.............] - ETA: 6s - loss: 3.6256 - accuracy: 0.0827
on_train_batch_begin: 1615690421.777462s

28 step training time: 0.330176s

on_train_batch_end: 1615690422.105771s

29696/50000 [================>.............] - ETA: 6s - loss: 3.6167 - accuracy: 0.0829
on_train_batch_begin: 1615690422.106139s

29 step training time: 0.328677s

on_train_batch_end: 1615690422.436365s

30720/50000 [=================>............] - ETA: 6s - loss: 3.6141 - accuracy: 0.0830
on_train_batch_begin: 1615690422.436701s

30 step training time: 0.330562s

on_train_batch_end: 1615690422.764590s

31744/50000 [==================>...........] - ETA: 5s - loss: 3.6074 - accuracy: 0.0832
on_train_batch_begin: 1615690422.764923s

31 step training time: 0.328223s

on_train_batch_end: 1615690423.094615s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.6072 - accuracy: 0.0833
on_train_batch_begin: 1615690423.094947s

32 step training time: 0.330024s

on_train_batch_end: 1615690423.427513s

33792/50000 [===================>..........] - ETA: 5s - loss: 3.6021 - accuracy: 0.0834
on_train_batch_begin: 1615690423.427859s

33 step training time: 0.332912s

on_train_batch_end: 1615690423.756153s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.5990 - accuracy: 0.0836
on_train_batch_begin: 1615690423.756502s

34 step training time: 0.328643s

on_train_batch_end: 1615690424.083337s

35840/50000 [====================>.........] - ETA: 4s - loss: 3.5929 - accuracy: 0.0838
on_train_batch_begin: 1615690424.083706s

35 step training time: 0.327204s

on_train_batch_end: 1615690424.416085s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.5841 - accuracy: 0.0839
on_train_batch_begin: 1615690424.416459s

36 step training time: 0.332752s

on_train_batch_end: 1615690424.748772s

37888/50000 [=====================>........] - ETA: 3s - loss: 3.5784 - accuracy: 0.0841
on_train_batch_begin: 1615690424.749147s

37 step training time: 0.332689s

on_train_batch_end: 1615690425.076437s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.5744 - accuracy: 0.0842
on_train_batch_begin: 1615690425.076807s

38 step training time: 0.327659s

on_train_batch_end: 1615690425.407270s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.5714 - accuracy: 0.0843
on_train_batch_begin: 1615690425.407643s

39 step training time: 0.330837s

on_train_batch_end: 1615690425.743329s

40960/50000 [=======================>......] - ETA: 2s - loss: 3.5571 - accuracy: 0.0845
on_train_batch_begin: 1615690425.743698s

40 step training time: 0.336055s

on_train_batch_end: 1615690426.069793s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.5505 - accuracy: 0.0847
on_train_batch_begin: 1615690426.070168s

41 step training time: 0.326470s

on_train_batch_end: 1615690426.398068s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.5439 - accuracy: 0.0848
on_train_batch_begin: 1615690426.398443s

42 step training time: 0.328275s

on_train_batch_end: 1615690426.732245s

44032/50000 [=========================>....] - ETA: 1s - loss: 3.5364 - accuracy: 0.0848
on_train_batch_begin: 1615690426.732622s

43 step training time: 0.334179s

on_train_batch_end: 1615690427.050806s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.5303 - accuracy: 0.0849
on_train_batch_begin: 1615690427.051187s

44 step training time: 0.318565s

on_train_batch_end: 1615690427.384199s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.5258 - accuracy: 0.0850
on_train_batch_begin: 1615690427.384563s

45 step training time: 0.333376s

on_train_batch_end: 1615690427.716440s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.5191 - accuracy: 0.0852
on_train_batch_begin: 1615690427.716814s

46 step training time: 0.332251s

on_train_batch_end: 1615690428.043080s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.5086 - accuracy: 0.0854
on_train_batch_begin: 1615690428.043470s

47 step training time: 0.326656s

on_train_batch_end: 1615690428.376451s

49152/50000 [============================>.] - ETA: 0s - loss: 3.4965 - accuracy: 0.0856
on_train_batch_begin: 1615690428.376824s

48 step training time: 0.333354s

on_train_batch_end: 1615690428.645209s

on_test_batch_begin: 1615690428.657302s

49 step training time: 0.280478s

on_epoch_end: 1615690429.467516s

Validation time: 0.810196s

Real time: 1615690429.467516s

Epoch time: 16.881717920303345s

50000/50000 [==============================] - 17s 338us/sample - loss: 3.4888 - accuracy: 0.0857 - val_loss: 6.7681 - val_accuracy: 0.0999

on_epoch_begin: 1615690429.467715s

Real time: 1615690429.4677203
Epoch 5/5

on_train_batch_begin: 1615690429.471006s

on_train_batch_end: 1615690429.803490s

 1024/50000 [..............................] - ETA: 16s - loss: 2.7923 - accuracy: 0.0952
on_train_batch_begin: 1615690429.803721s

1 step training time: 0.332715s

on_train_batch_end: 1615690430.132278s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.9180 - accuracy: 0.0941
on_train_batch_begin: 1615690430.132548s

2 step training time: 0.328827s

on_train_batch_end: 1615690430.466800s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.8443 - accuracy: 0.0944
on_train_batch_begin: 1615690430.467081s

3 step training time: 0.334533s

on_train_batch_end: 1615690430.799965s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.8867 - accuracy: 0.0940
on_train_batch_begin: 1615690430.800247s

4 step training time: 0.333166s

on_train_batch_end: 1615690431.130208s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.8562 - accuracy: 0.0945
on_train_batch_begin: 1615690431.130507s

5 step training time: 0.330260s

on_train_batch_end: 1615690431.456843s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.8157 - accuracy: 0.0951
on_train_batch_begin: 1615690431.457145s

6 step training time: 0.326638s

on_train_batch_end: 1615690431.793573s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.8283 - accuracy: 0.0952
on_train_batch_begin: 1615690431.793863s

7 step training time: 0.336718s

on_train_batch_end: 1615690432.125184s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.8226 - accuracy: 0.0951
on_train_batch_begin: 1615690432.125475s

8 step training time: 0.331613s

on_train_batch_end: 1615690432.452811s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.8135 - accuracy: 0.0952
on_train_batch_begin: 1615690432.453105s

9 step training time: 0.327630s

on_train_batch_end: 1615690432.789064s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.8146 - accuracy: 0.0955
on_train_batch_begin: 1615690432.789359s

10 step training time: 0.336254s

on_train_batch_end: 1615690433.122237s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.7859 - accuracy: 0.0960
on_train_batch_begin: 1615690433.122535s

11 step training time: 0.333175s

on_train_batch_end: 1615690433.454468s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.7706 - accuracy: 0.0963
on_train_batch_begin: 1615690433.454767s

12 step training time: 0.332233s

on_train_batch_end: 1615690433.788967s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.7649 - accuracy: 0.0965
on_train_batch_begin: 1615690433.789265s

13 step training time: 0.334497s

on_train_batch_end: 1615690434.121702s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.7570 - accuracy: 0.0965
on_train_batch_begin: 1615690434.122003s

14 step training time: 0.332738s

on_train_batch_end: 1615690434.457047s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.7390 - accuracy: 0.0966
on_train_batch_begin: 1615690434.457360s

15 step training time: 0.335357s

on_train_batch_end: 1615690434.790155s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.7258 - accuracy: 0.0968
on_train_batch_begin: 1615690434.790453s

16 step training time: 0.333093s

on_train_batch_end: 1615690435.118984s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.7093 - accuracy: 0.0970
on_train_batch_begin: 1615690435.119302s

17 step training time: 0.328848s

on_train_batch_end: 1615690435.457279s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.6970 - accuracy: 0.0971
on_train_batch_begin: 1615690435.457570s

18 step training time: 0.338269s

on_train_batch_end: 1615690435.788200s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.6794 - accuracy: 0.0971 
on_train_batch_begin: 1615690435.788487s

19 step training time: 0.330917s

on_train_batch_end: 1615690436.121535s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.6812 - accuracy: 0.0972
on_train_batch_begin: 1615690436.121820s

20 step training time: 0.333333s

on_train_batch_end: 1615690436.457194s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.6798 - accuracy: 0.0973
on_train_batch_begin: 1615690436.457479s

21 step training time: 0.335659s

on_train_batch_end: 1615690436.788381s

22528/50000 [============>.................] - ETA: 8s - loss: 2.6680 - accuracy: 0.0974
on_train_batch_begin: 1615690436.788668s

22 step training time: 0.331189s

on_train_batch_end: 1615690437.123591s

23552/50000 [=============>................] - ETA: 8s - loss: 2.6515 - accuracy: 0.0975
on_train_batch_begin: 1615690437.123878s

23 step training time: 0.335209s

on_train_batch_end: 1615690437.455501s

24576/50000 [=============>................] - ETA: 8s - loss: 2.6458 - accuracy: 0.0975
on_train_batch_begin: 1615690437.455794s

24 step training time: 0.331917s

on_train_batch_end: 1615690437.791412s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.6316 - accuracy: 0.0976
on_train_batch_begin: 1615690437.791697s

25 step training time: 0.335902s

on_train_batch_end: 1615690438.124683s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.6215 - accuracy: 0.0977
on_train_batch_begin: 1615690438.124974s

26 step training time: 0.333278s

on_train_batch_end: 1615690438.456473s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.6060 - accuracy: 0.0977
on_train_batch_begin: 1615690438.456766s

27 step training time: 0.331792s

on_train_batch_end: 1615690438.791955s

28672/50000 [================>.............] - ETA: 6s - loss: 2.5931 - accuracy: 0.0978
on_train_batch_begin: 1615690438.792253s

28 step training time: 0.335486s

on_train_batch_end: 1615690439.122677s

29696/50000 [================>.............] - ETA: 6s - loss: 2.5776 - accuracy: 0.0979
on_train_batch_begin: 1615690439.122971s

29 step training time: 0.330718s

on_train_batch_end: 1615690439.459555s

30720/50000 [=================>............] - ETA: 6s - loss: 2.5632 - accuracy: 0.0980
on_train_batch_begin: 1615690439.459846s

30 step training time: 0.336875s

on_train_batch_end: 1615690439.790698s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.5446 - accuracy: 0.0981
on_train_batch_begin: 1615690439.790991s

31 step training time: 0.331145s

on_train_batch_end: 1615690440.121744s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.5247 - accuracy: 0.0981
on_train_batch_begin: 1615690440.122043s

32 step training time: 0.331052s

on_train_batch_end: 1615690440.455223s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.5064 - accuracy: 0.0982
on_train_batch_begin: 1615690440.455516s

33 step training time: 0.333473s

on_train_batch_end: 1615690440.786191s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.4851 - accuracy: 0.0982
on_train_batch_begin: 1615690440.786482s

34 step training time: 0.330966s

on_train_batch_end: 1615690441.114001s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.4705 - accuracy: 0.0983
on_train_batch_begin: 1615690441.114301s

35 step training time: 0.327819s

on_train_batch_end: 1615690441.450647s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.4560 - accuracy: 0.0983
on_train_batch_begin: 1615690441.450942s

36 step training time: 0.336641s

on_train_batch_end: 1615690441.781620s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.4409 - accuracy: 0.0984
on_train_batch_begin: 1615690441.782002s

37 step training time: 0.331060s

on_train_batch_end: 1615690442.110402s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.4176 - accuracy: 0.0984
on_train_batch_begin: 1615690442.110778s

38 step training time: 0.328776s

on_train_batch_end: 1615690442.447548s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.3993 - accuracy: 0.0985
on_train_batch_begin: 1615690442.447873s

39 step training time: 0.337095s

on_train_batch_end: 1615690442.779659s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.3831 - accuracy: 0.0985
on_train_batch_begin: 1615690442.779953s

40 step training time: 0.332080s

on_train_batch_end: 1615690443.110771s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.3652 - accuracy: 0.0986
on_train_batch_begin: 1615690443.111065s

41 step training time: 0.331111s

on_train_batch_end: 1615690443.445648s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.3469 - accuracy: 0.0986
on_train_batch_begin: 1615690443.445946s

42 step training time: 0.334881s

on_train_batch_end: 1615690443.774095s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.3276 - accuracy: 0.0986
on_train_batch_begin: 1615690443.774395s

43 step training time: 0.328449s

on_train_batch_end: 1615690444.108543s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.3141 - accuracy: 0.0987
on_train_batch_begin: 1615690444.108838s

44 step training time: 0.334443s

on_train_batch_end: 1615690444.441123s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.3002 - accuracy: 0.0987
on_train_batch_begin: 1615690444.441421s

45 step training time: 0.332583s

on_train_batch_end: 1615690444.768346s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.2869 - accuracy: 0.0988
on_train_batch_begin: 1615690444.768645s

46 step training time: 0.327224s

on_train_batch_end: 1615690445.099354s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.2694 - accuracy: 0.0988
on_train_batch_begin: 1615690445.099656s

47 step training time: 0.331011s

on_train_batch_end: 1615690445.434257s

49152/50000 [============================>.] - ETA: 0s - loss: 2.2553 - accuracy: 0.0988
on_train_batch_begin: 1615690445.434558s

48 step training time: 0.334903s

on_train_batch_end: 1615690445.709152s

on_test_batch_begin: 1615690445.721511s

49 step training time: 0.286953s

on_epoch_end: 1615690446.531022s

Validation time: 0.809496s

Real time: 1615690446.531022s

Epoch time: 17.063323974609375s

50000/50000 [==============================] - 17s 341us/sample - loss: 2.2440 - accuracy: 0.0988 - val_loss: 7.3177 - val_accuracy: 0.0999
Tempo do fit: 115.78194117546082