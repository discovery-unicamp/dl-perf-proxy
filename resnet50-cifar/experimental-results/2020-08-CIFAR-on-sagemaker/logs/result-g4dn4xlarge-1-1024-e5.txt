wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:13
   204800/170498071 [..............................] - ETA: 59s 
   860160/170498071 [..............................] - ETA: 26s
  3465216/170498071 [..............................] - ETA: 8s 
  7168000/170498071 [>.............................] - ETA: 5s
 10706944/170498071 [>.............................] - ETA: 4s
 14032896/170498071 [=>............................] - ETA: 3s
 17719296/170498071 [==>...........................] - ETA: 3s
 21356544/170498071 [==>...........................] - ETA: 3s
 24829952/170498071 [===>..........................] - ETA: 2s
 28123136/170498071 [===>..........................] - ETA: 2s
 31744000/170498071 [====>.........................] - ETA: 2s
 35405824/170498071 [=====>........................] - ETA: 2s
 38887424/170498071 [=====>........................] - ETA: 2s
 42213376/170498071 [======>.......................] - ETA: 2s
 45850624/170498071 [=======>......................] - ETA: 2s
 49504256/170498071 [=======>......................] - ETA: 2s
 52961280/170498071 [========>.....................] - ETA: 1s
 56254464/170498071 [========>.....................] - ETA: 1s
 59744256/170498071 [=========>....................] - ETA: 1s
 63152128/170498071 [==========>...................] - ETA: 1s
 66379776/170498071 [==========>...................] - ETA: 1s
 69607424/170498071 [===========>..................] - ETA: 1s
 72916992/170498071 [===========>..................] - ETA: 1s
 76275712/170498071 [============>.................] - ETA: 1s
 79683584/170498071 [=============>................] - ETA: 1s
 82894848/170498071 [=============>................] - ETA: 1s
 86114304/170498071 [==============>...............] - ETA: 1s
 89415680/170498071 [==============>...............] - ETA: 1s
 92643328/170498071 [===============>..............] - ETA: 1s
 96034816/170498071 [===============>..............] - ETA: 1s
 99262464/170498071 [================>.............] - ETA: 1s
102555648/170498071 [=================>............] - ETA: 1s
105979904/170498071 [=================>............] - ETA: 1s
109223936/170498071 [==================>...........] - ETA: 0s
112566272/170498071 [==================>...........] - ETA: 0s
115875840/170498071 [===================>..........] - ETA: 0s
119250944/170498071 [===================>..........] - ETA: 0s
122576896/170498071 [====================>.........] - ETA: 0s
125665280/170498071 [=====================>........] - ETA: 0s
128884736/170498071 [=====================>........] - ETA: 0s
132194304/170498071 [======================>.......] - ETA: 0s
135536640/170498071 [======================>.......] - ETA: 0s
138960896/170498071 [=======================>......] - ETA: 0s
142286848/170498071 [========================>.....] - ETA: 0s
145596416/170498071 [========================>.....] - ETA: 0s
148652032/170498071 [=========================>....] - ETA: 0s
151863296/170498071 [=========================>....] - ETA: 0s
155164672/170498071 [==========================>...] - ETA: 0s
158556160/170498071 [==========================>...] - ETA: 0s
161898496/170498071 [===========================>..] - ETA: 0s
165027840/170498071 [============================>.] - ETA: 0s
168222720/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 17s
 1114112/94765736 [..............................] - ETA: 6s 
 8126464/94765736 [=>............................] - ETA: 1s
13049856/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 0s
26984448/94765736 [=======>......................] - ETA: 1s
35938304/94765736 [==========>...................] - ETA: 0s
40681472/94765736 [===========>..................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
51314688/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
62619648/94765736 [==================>...........] - ETA: 0s
68329472/94765736 [====================>.........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
81960960/94765736 [========================>.....] - ETA: 0s
87539712/94765736 [==========================>...] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.047310590744019
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615756878.369958s

Real time: 1615756878.3699765
Epoch 1/5

on_train_batch_begin: 1615756879.134326s

on_train_batch_end: 1615756896.580386s

 1024/50000 [..............................] - ETA: 14:30 - loss: 17.9983 - accuracy: 0.0000e+00
on_train_batch_begin: 1615756896.580984s

1 step training time: 17.446658s

on_train_batch_end: 1615756896.899966s

 2048/50000 [>.............................] - ETA: 7:13 - loss: 15.0993 - accuracy: 1.9979e-04 
on_train_batch_begin: 1615756896.900299s

2 step training time: 0.319315s

on_train_batch_end: 1615756897.220497s

 3072/50000 [>.............................] - ETA: 4:47 - loss: 13.0052 - accuracy: 3.0867e-04
on_train_batch_begin: 1615756897.220836s

3 step training time: 0.320537s

on_train_batch_end: 1615756897.542165s

 4096/50000 [=>............................] - ETA: 3:34 - loss: 11.8517 - accuracy: 0.0011    
on_train_batch_begin: 1615756897.542479s

4 step training time: 0.321643s

on_train_batch_end: 1615756897.856947s

 5120/50000 [==>...........................] - ETA: 2:50 - loss: 11.1262 - accuracy: 0.0027
on_train_batch_begin: 1615756897.857249s

5 step training time: 0.314770s

on_train_batch_end: 1615756898.175658s

 6144/50000 [==>...........................] - ETA: 2:21 - loss: 10.6359 - accuracy: 0.0048
on_train_batch_begin: 1615756898.175967s

6 step training time: 0.318718s

on_train_batch_end: 1615756898.495656s

 7168/50000 [===>..........................] - ETA: 2:00 - loss: 10.2434 - accuracy: 0.0080
on_train_batch_begin: 1615756898.495962s

7 step training time: 0.319994s

on_train_batch_end: 1615756898.812275s

 8192/50000 [===>..........................] - ETA: 1:44 - loss: 9.9546 - accuracy: 0.0116 
on_train_batch_begin: 1615756898.812598s

8 step training time: 0.316636s

on_train_batch_end: 1615756899.129673s

 9216/50000 [====>.........................] - ETA: 1:31 - loss: 9.7048 - accuracy: 0.0153
on_train_batch_begin: 1615756899.129982s

9 step training time: 0.317384s

on_train_batch_end: 1615756899.448412s

10240/50000 [=====>........................] - ETA: 1:21 - loss: 9.5025 - accuracy: 0.0180
on_train_batch_begin: 1615756899.448732s

10 step training time: 0.318750s

on_train_batch_end: 1615756899.763344s

11264/50000 [=====>........................] - ETA: 1:13 - loss: 9.3334 - accuracy: 0.0206
on_train_batch_begin: 1615756899.763658s

11 step training time: 0.314926s

on_train_batch_end: 1615756900.081984s

12288/50000 [======>.......................] - ETA: 1:06 - loss: 9.1823 - accuracy: 0.0234
on_train_batch_begin: 1615756900.082291s

12 step training time: 0.318633s

on_train_batch_end: 1615756900.403730s

13312/50000 [======>.......................] - ETA: 1:00 - loss: 9.0514 - accuracy: 0.0263
on_train_batch_begin: 1615756900.404052s

13 step training time: 0.321761s

on_train_batch_end: 1615756900.722317s

14336/50000 [=======>......................] - ETA: 55s - loss: 8.9287 - accuracy: 0.0291 
on_train_batch_begin: 1615756900.722633s

14 step training time: 0.318582s

on_train_batch_end: 1615756901.038507s

15360/50000 [========>.....................] - ETA: 51s - loss: 8.8252 - accuracy: 0.0313
on_train_batch_begin: 1615756901.038816s

15 step training time: 0.316183s

on_train_batch_end: 1615756901.359178s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.7326 - accuracy: 0.0336
on_train_batch_begin: 1615756901.359482s

16 step training time: 0.320666s

on_train_batch_end: 1615756901.677901s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.6388 - accuracy: 0.0357
on_train_batch_begin: 1615756901.678212s

17 step training time: 0.318730s

on_train_batch_end: 1615756901.992806s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.5609 - accuracy: 0.0371
on_train_batch_begin: 1615756901.993110s

18 step training time: 0.314898s

on_train_batch_end: 1615756902.313320s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.4803 - accuracy: 0.0388
on_train_batch_begin: 1615756902.313649s

19 step training time: 0.320539s

on_train_batch_end: 1615756902.630002s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.4104 - accuracy: 0.0400
on_train_batch_begin: 1615756902.630306s

20 step training time: 0.316658s

on_train_batch_end: 1615756902.947787s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.3487 - accuracy: 0.0417
on_train_batch_begin: 1615756902.948095s

21 step training time: 0.317789s

on_train_batch_end: 1615756903.269170s

22528/50000 [============>.................] - ETA: 30s - loss: 8.2860 - accuracy: 0.0431
on_train_batch_begin: 1615756903.269480s

22 step training time: 0.321384s

on_train_batch_end: 1615756903.587394s

23552/50000 [=============>................] - ETA: 28s - loss: 8.2330 - accuracy: 0.0443
on_train_batch_begin: 1615756903.587709s

23 step training time: 0.318229s

on_train_batch_end: 1615756903.902025s

24576/50000 [=============>................] - ETA: 26s - loss: 8.1829 - accuracy: 0.0457
on_train_batch_begin: 1615756903.902346s

24 step training time: 0.314637s

on_train_batch_end: 1615756904.222629s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.1365 - accuracy: 0.0466
on_train_batch_begin: 1615756904.222941s

25 step training time: 0.320595s

on_train_batch_end: 1615756904.541569s

26624/50000 [==============>...............] - ETA: 22s - loss: 8.0907 - accuracy: 0.0477
on_train_batch_begin: 1615756904.541910s

26 step training time: 0.318969s

on_train_batch_end: 1615756904.858998s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.0447 - accuracy: 0.0488
on_train_batch_begin: 1615756904.859307s

27 step training time: 0.317397s

on_train_batch_end: 1615756905.179974s

28672/50000 [================>.............] - ETA: 19s - loss: 7.9990 - accuracy: 0.0501
on_train_batch_begin: 1615756905.180286s

28 step training time: 0.320978s

on_train_batch_end: 1615756905.501459s

29696/50000 [================>.............] - ETA: 18s - loss: 7.9590 - accuracy: 0.0513
on_train_batch_begin: 1615756905.501787s

29 step training time: 0.321501s

on_train_batch_end: 1615756905.817834s

30720/50000 [=================>............] - ETA: 17s - loss: 7.9200 - accuracy: 0.0522
on_train_batch_begin: 1615756905.818135s

30 step training time: 0.316349s

on_train_batch_end: 1615756906.134249s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.8780 - accuracy: 0.0534
on_train_batch_begin: 1615756906.134558s

31 step training time: 0.316423s

on_train_batch_end: 1615756906.455436s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.8418 - accuracy: 0.0539
on_train_batch_begin: 1615756906.455739s

32 step training time: 0.321181s

on_train_batch_end: 1615756906.771176s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.8050 - accuracy: 0.0547
on_train_batch_begin: 1615756906.771489s

33 step training time: 0.315750s

on_train_batch_end: 1615756907.090922s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.7747 - accuracy: 0.0553
on_train_batch_begin: 1615756907.091223s

34 step training time: 0.319734s

on_train_batch_end: 1615756907.414425s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.7439 - accuracy: 0.0558
on_train_batch_begin: 1615756907.414724s

35 step training time: 0.323501s

on_train_batch_end: 1615756907.738137s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.7109 - accuracy: 0.0566
on_train_batch_begin: 1615756907.738451s

36 step training time: 0.323727s

on_train_batch_end: 1615756908.057455s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.6809 - accuracy: 0.0572 
on_train_batch_begin: 1615756908.057779s

37 step training time: 0.319328s

on_train_batch_end: 1615756908.372879s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.6544 - accuracy: 0.0578
on_train_batch_begin: 1615756908.373196s

38 step training time: 0.315418s

on_train_batch_end: 1615756908.691727s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.6276 - accuracy: 0.0583
on_train_batch_begin: 1615756908.692033s

39 step training time: 0.318837s

on_train_batch_end: 1615756909.010220s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.5988 - accuracy: 0.0587
on_train_batch_begin: 1615756909.010529s

40 step training time: 0.318496s

on_train_batch_end: 1615756909.327010s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.5696 - accuracy: 0.0592
on_train_batch_begin: 1615756909.327328s

41 step training time: 0.316799s

on_train_batch_end: 1615756909.650079s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.5430 - accuracy: 0.0596
on_train_batch_begin: 1615756909.650394s

42 step training time: 0.323066s

on_train_batch_end: 1615756909.972060s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.5186 - accuracy: 0.0600
on_train_batch_begin: 1615756909.972366s

43 step training time: 0.321972s

on_train_batch_end: 1615756910.293363s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.4956 - accuracy: 0.0602
on_train_batch_begin: 1615756910.293700s

44 step training time: 0.321333s

on_train_batch_end: 1615756910.610070s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.4706 - accuracy: 0.0606
on_train_batch_begin: 1615756910.610377s

45 step training time: 0.316677s

on_train_batch_end: 1615756910.928668s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.4475 - accuracy: 0.0607
on_train_batch_begin: 1615756910.928973s

46 step training time: 0.318596s

on_train_batch_end: 1615756911.249856s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.4238 - accuracy: 0.0608
on_train_batch_begin: 1615756911.250164s

47 step training time: 0.321191s

on_train_batch_end: 1615756911.568280s

49152/50000 [============================>.] - ETA: 0s - loss: 7.3992 - accuracy: 0.0609
on_train_batch_begin: 1615756911.568583s

48 step training time: 0.318419s

on_train_batch_end: 1615756917.212080s

on_test_batch_begin: 1615756917.400469s

49 step training time: 5.831886s

on_epoch_end: 1615756921.976973s

Validation time: 4.576490s

Real time: 1615756921.976973s

Epoch time: 43.607014179229736s

50000/50000 [==============================] - 44s 872us/sample - loss: 7.3809 - accuracy: 0.0608 - val_loss: 13.4712 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615756921.977181s

Real time: 1615756921.9771862
Epoch 2/5

on_train_batch_begin: 1615756921.980602s

on_train_batch_end: 1615756922.302307s

 1024/50000 [..............................] - ETA: 15s - loss: 6.2604 - accuracy: 0.0547
on_train_batch_begin: 1615756922.302620s

1 step training time: 0.322018s

on_train_batch_end: 1615756922.602479s

 2048/50000 [>.............................] - ETA: 14s - loss: 6.1404 - accuracy: 0.0581
on_train_batch_begin: 1615756922.602783s

2 step training time: 0.300163s

on_train_batch_end: 1615756922.925720s

 3072/50000 [>.............................] - ETA: 14s - loss: 6.1424 - accuracy: 0.0556
on_train_batch_begin: 1615756922.926023s

3 step training time: 0.323240s

on_train_batch_end: 1615756923.247181s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.1085 - accuracy: 0.0539
on_train_batch_begin: 1615756923.247480s

4 step training time: 0.321457s

on_train_batch_end: 1615756923.564640s

 5120/50000 [==>...........................] - ETA: 13s - loss: 6.0931 - accuracy: 0.0536
on_train_batch_begin: 1615756923.564939s

5 step training time: 0.317458s

on_train_batch_end: 1615756923.884710s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.0505 - accuracy: 0.0536
on_train_batch_begin: 1615756923.885012s

6 step training time: 0.320074s

on_train_batch_end: 1615756924.204967s

 7168/50000 [===>..........................] - ETA: 13s - loss: 6.0655 - accuracy: 0.0524
on_train_batch_begin: 1615756924.205265s

7 step training time: 0.320253s

on_train_batch_end: 1615756924.523670s

 8192/50000 [===>..........................] - ETA: 12s - loss: 6.0497 - accuracy: 0.0515
on_train_batch_begin: 1615756924.523978s

8 step training time: 0.318713s

on_train_batch_end: 1615756924.843970s

 9216/50000 [====>.........................] - ETA: 12s - loss: 6.0389 - accuracy: 0.0516
on_train_batch_begin: 1615756924.844381s

9 step training time: 0.320403s

on_train_batch_end: 1615756925.165760s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.0234 - accuracy: 0.0529
on_train_batch_begin: 1615756925.166068s

10 step training time: 0.321687s

on_train_batch_end: 1615756925.486470s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.9970 - accuracy: 0.0537
on_train_batch_begin: 1615756925.486777s

11 step training time: 0.320709s

on_train_batch_end: 1615756925.803873s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.9690 - accuracy: 0.0533
on_train_batch_begin: 1615756925.804198s

12 step training time: 0.317420s

on_train_batch_end: 1615756926.123057s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.9513 - accuracy: 0.0533
on_train_batch_begin: 1615756926.123360s

13 step training time: 0.319162s

on_train_batch_end: 1615756926.444060s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.9218 - accuracy: 0.0533
on_train_batch_begin: 1615756926.444360s

14 step training time: 0.321000s

on_train_batch_end: 1615756926.766141s

15360/50000 [========>.....................] - ETA: 10s - loss: 5.9064 - accuracy: 0.0531
on_train_batch_begin: 1615756926.766477s

15 step training time: 0.322118s

on_train_batch_end: 1615756927.084718s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.8790 - accuracy: 0.0532
on_train_batch_begin: 1615756927.085019s

16 step training time: 0.318541s

on_train_batch_end: 1615756927.402430s

17408/50000 [=========>....................] - ETA: 10s - loss: 5.8493 - accuracy: 0.0532
on_train_batch_begin: 1615756927.402729s

17 step training time: 0.317710s

on_train_batch_end: 1615756927.722795s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.8249 - accuracy: 0.0534 
on_train_batch_begin: 1615756927.723077s

18 step training time: 0.320348s

on_train_batch_end: 1615756928.044238s

19456/50000 [==========>...................] - ETA: 9s - loss: 5.7892 - accuracy: 0.0535
on_train_batch_begin: 1615756928.044538s

19 step training time: 0.321460s

on_train_batch_end: 1615756928.365215s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.7504 - accuracy: 0.0539
on_train_batch_begin: 1615756928.365524s

20 step training time: 0.320986s

on_train_batch_end: 1615756928.683507s

21504/50000 [===========>..................] - ETA: 8s - loss: 5.7104 - accuracy: 0.0541
on_train_batch_begin: 1615756928.683805s

21 step training time: 0.318281s

on_train_batch_end: 1615756929.002685s

22528/50000 [============>.................] - ETA: 8s - loss: 5.6649 - accuracy: 0.0545
on_train_batch_begin: 1615756929.002990s

22 step training time: 0.319185s

on_train_batch_end: 1615756929.324763s

23552/50000 [=============>................] - ETA: 8s - loss: 5.6183 - accuracy: 0.0549
on_train_batch_begin: 1615756929.325068s

23 step training time: 0.322078s

on_train_batch_end: 1615756929.648076s

24576/50000 [=============>................] - ETA: 7s - loss: 5.5720 - accuracy: 0.0554
on_train_batch_begin: 1615756929.648429s

24 step training time: 0.323362s

on_train_batch_end: 1615756929.970837s

25600/50000 [==============>...............] - ETA: 7s - loss: 5.5238 - accuracy: 0.0560
on_train_batch_begin: 1615756929.971144s

25 step training time: 0.322715s

on_train_batch_end: 1615756930.288728s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.4797 - accuracy: 0.0566
on_train_batch_begin: 1615756930.289033s

26 step training time: 0.317889s

on_train_batch_end: 1615756930.607836s

27648/50000 [===============>..............] - ETA: 6s - loss: 5.4426 - accuracy: 0.0571
on_train_batch_begin: 1615756930.608140s

27 step training time: 0.319107s

on_train_batch_end: 1615756930.929497s

28672/50000 [================>.............] - ETA: 6s - loss: 5.4027 - accuracy: 0.0578
on_train_batch_begin: 1615756930.929832s

28 step training time: 0.321692s

on_train_batch_end: 1615756931.252427s

29696/50000 [================>.............] - ETA: 6s - loss: 5.3684 - accuracy: 0.0585
on_train_batch_begin: 1615756931.252740s

29 step training time: 0.322907s

on_train_batch_end: 1615756931.576087s

30720/50000 [=================>............] - ETA: 6s - loss: 5.3347 - accuracy: 0.0593
on_train_batch_begin: 1615756931.576393s

30 step training time: 0.323653s

on_train_batch_end: 1615756931.899975s

31744/50000 [==================>...........] - ETA: 5s - loss: 5.2958 - accuracy: 0.0604
on_train_batch_begin: 1615756931.900277s

31 step training time: 0.323884s

on_train_batch_end: 1615756932.219044s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.2532 - accuracy: 0.0614
on_train_batch_begin: 1615756932.219347s

32 step training time: 0.319070s

on_train_batch_end: 1615756932.535852s

33792/50000 [===================>..........] - ETA: 5s - loss: 5.2114 - accuracy: 0.0623
on_train_batch_begin: 1615756932.536153s

33 step training time: 0.316806s

on_train_batch_end: 1615756932.857564s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.1713 - accuracy: 0.0633
on_train_batch_begin: 1615756932.857905s

34 step training time: 0.321753s

on_train_batch_end: 1615756933.180448s

35840/50000 [====================>.........] - ETA: 4s - loss: 5.1300 - accuracy: 0.0642
on_train_batch_begin: 1615756933.180760s

35 step training time: 0.322854s

on_train_batch_end: 1615756933.503556s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.0891 - accuracy: 0.0651
on_train_batch_begin: 1615756933.503867s

36 step training time: 0.323107s

on_train_batch_end: 1615756933.826806s

37888/50000 [=====================>........] - ETA: 3s - loss: 5.0456 - accuracy: 0.0660
on_train_batch_begin: 1615756933.827127s

37 step training time: 0.323260s

on_train_batch_end: 1615756934.141672s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.0090 - accuracy: 0.0668
on_train_batch_begin: 1615756934.141977s

38 step training time: 0.314850s

on_train_batch_end: 1615756934.462075s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.9767 - accuracy: 0.0675
on_train_batch_begin: 1615756934.462380s

39 step training time: 0.320403s

on_train_batch_end: 1615756934.783717s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.9371 - accuracy: 0.0682
on_train_batch_begin: 1615756934.784036s

40 step training time: 0.321656s

on_train_batch_end: 1615756935.105721s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.8977 - accuracy: 0.0690
on_train_batch_begin: 1615756935.106021s

41 step training time: 0.321985s

on_train_batch_end: 1615756935.426290s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.8595 - accuracy: 0.0696
on_train_batch_begin: 1615756935.426594s

42 step training time: 0.320573s

on_train_batch_end: 1615756935.744385s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.8288 - accuracy: 0.0703
on_train_batch_begin: 1615756935.744692s

43 step training time: 0.318099s

on_train_batch_end: 1615756936.063895s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.7917 - accuracy: 0.0710
on_train_batch_begin: 1615756936.064201s

44 step training time: 0.319508s

on_train_batch_end: 1615756936.385819s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.7603 - accuracy: 0.0716
on_train_batch_begin: 1615756936.386120s

45 step training time: 0.321919s

on_train_batch_end: 1615756936.708285s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.7300 - accuracy: 0.0722
on_train_batch_begin: 1615756936.708587s

46 step training time: 0.322468s

on_train_batch_end: 1615756937.023897s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.6982 - accuracy: 0.0727
on_train_batch_begin: 1615756937.024199s

47 step training time: 0.315612s

on_train_batch_end: 1615756937.343033s

49152/50000 [============================>.] - ETA: 0s - loss: 4.6639 - accuracy: 0.0733
on_train_batch_begin: 1615756937.343344s

48 step training time: 0.319144s

on_train_batch_end: 1615756937.612631s

on_test_batch_begin: 1615756937.623894s

49 step training time: 0.280550s

on_epoch_end: 1615756938.412526s

Validation time: 0.788618s

Real time: 1615756938.412526s

Epoch time: 16.43535566329956s

50000/50000 [==============================] - 16s 329us/sample - loss: 4.6362 - accuracy: 0.0736 - val_loss: 7.3447 - val_accuracy: 0.0999

on_epoch_begin: 1615756938.412740s

Real time: 1615756938.4127493
Epoch 3/5

on_train_batch_begin: 1615756938.416208s

on_train_batch_end: 1615756938.739014s

 1024/50000 [..............................] - ETA: 15s - loss: 3.0197 - accuracy: 0.1000
on_train_batch_begin: 1615756938.739321s

1 step training time: 0.323113s

on_train_batch_end: 1615756939.061505s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.9292 - accuracy: 0.1004
on_train_batch_begin: 1615756939.061841s

2 step training time: 0.322520s

on_train_batch_end: 1615756939.384967s

 3072/50000 [>.............................] - ETA: 14s - loss: 2.8908 - accuracy: 0.1001
on_train_batch_begin: 1615756939.385269s

3 step training time: 0.323428s

on_train_batch_end: 1615756939.707359s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.9201 - accuracy: 0.0991
on_train_batch_begin: 1615756939.707667s

4 step training time: 0.322398s

on_train_batch_end: 1615756940.025197s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.9142 - accuracy: 0.0992
on_train_batch_begin: 1615756940.025505s

5 step training time: 0.317838s

on_train_batch_end: 1615756940.346984s

 6144/50000 [==>...........................] - ETA: 13s - loss: 2.8992 - accuracy: 0.0992
on_train_batch_begin: 1615756940.347294s

6 step training time: 0.321788s

on_train_batch_end: 1615756940.669117s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.8908 - accuracy: 0.0990
on_train_batch_begin: 1615756940.669426s

7 step training time: 0.322133s

on_train_batch_end: 1615756940.990787s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.8719 - accuracy: 0.0992
on_train_batch_begin: 1615756940.991101s

8 step training time: 0.321675s

on_train_batch_end: 1615756941.314301s

 9216/50000 [====>.........................] - ETA: 12s - loss: 2.8402 - accuracy: 0.0992
on_train_batch_begin: 1615756941.314608s

9 step training time: 0.323507s

on_train_batch_end: 1615756941.637888s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.8061 - accuracy: 0.0993
on_train_batch_begin: 1615756941.638191s

10 step training time: 0.323583s

on_train_batch_end: 1615756941.962095s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.8004 - accuracy: 0.0991
on_train_batch_begin: 1615756941.962404s

11 step training time: 0.324214s

on_train_batch_end: 1615756942.286643s

12288/50000 [======>.......................] - ETA: 11s - loss: 2.7963 - accuracy: 0.0992
on_train_batch_begin: 1615756942.286975s

12 step training time: 0.324571s

on_train_batch_end: 1615756942.609445s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.7875 - accuracy: 0.0992
on_train_batch_begin: 1615756942.609784s

13 step training time: 0.322809s

on_train_batch_end: 1615756942.931356s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.7723 - accuracy: 0.0992
on_train_batch_begin: 1615756942.931661s

14 step training time: 0.321877s

on_train_batch_end: 1615756943.249665s

15360/50000 [========>.....................] - ETA: 10s - loss: 2.7514 - accuracy: 0.0992
on_train_batch_begin: 1615756943.249982s

15 step training time: 0.318321s

on_train_batch_end: 1615756943.570841s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.7398 - accuracy: 0.0993
on_train_batch_begin: 1615756943.571148s

16 step training time: 0.321166s

on_train_batch_end: 1615756943.892783s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.7337 - accuracy: 0.0994
on_train_batch_begin: 1615756943.893131s

17 step training time: 0.321983s

on_train_batch_end: 1615756944.215415s

18432/50000 [==========>...................] - ETA: 9s - loss: 2.7154 - accuracy: 0.0994 
on_train_batch_begin: 1615756944.215724s

18 step training time: 0.322593s

on_train_batch_end: 1615756944.539072s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.6934 - accuracy: 0.0994
on_train_batch_begin: 1615756944.539378s

19 step training time: 0.323654s

on_train_batch_end: 1615756944.863453s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.6792 - accuracy: 0.0995
on_train_batch_begin: 1615756944.863768s

20 step training time: 0.324390s

on_train_batch_end: 1615756945.188169s

21504/50000 [===========>..................] - ETA: 8s - loss: 2.6656 - accuracy: 0.0995
on_train_batch_begin: 1615756945.188478s

21 step training time: 0.324710s

on_train_batch_end: 1615756945.511684s

22528/50000 [============>.................] - ETA: 8s - loss: 2.6607 - accuracy: 0.0996
on_train_batch_begin: 1615756945.512000s

22 step training time: 0.323522s

on_train_batch_end: 1615756945.836601s

23552/50000 [=============>................] - ETA: 8s - loss: 2.6624 - accuracy: 0.0996
on_train_batch_begin: 1615756945.836910s

23 step training time: 0.324910s

on_train_batch_end: 1615756946.156545s

24576/50000 [=============>................] - ETA: 8s - loss: 2.6641 - accuracy: 0.0996
on_train_batch_begin: 1615756946.156845s

24 step training time: 0.319935s

on_train_batch_end: 1615756946.475394s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.6631 - accuracy: 0.0996
on_train_batch_begin: 1615756946.475680s

25 step training time: 0.318835s

on_train_batch_end: 1615756946.796224s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.6638 - accuracy: 0.0996
on_train_batch_begin: 1615756946.796500s

26 step training time: 0.320820s

on_train_batch_end: 1615756947.117464s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.6641 - accuracy: 0.0997
on_train_batch_begin: 1615756947.117793s

27 step training time: 0.321293s

on_train_batch_end: 1615756947.440022s

28672/50000 [================>.............] - ETA: 6s - loss: 2.6641 - accuracy: 0.0996
on_train_batch_begin: 1615756947.440324s

28 step training time: 0.322531s

on_train_batch_end: 1615756947.763767s

29696/50000 [================>.............] - ETA: 6s - loss: 2.6622 - accuracy: 0.0997
on_train_batch_begin: 1615756947.764071s

29 step training time: 0.323748s

on_train_batch_end: 1615756948.087977s

30720/50000 [=================>............] - ETA: 6s - loss: 2.6610 - accuracy: 0.0997
on_train_batch_begin: 1615756948.088289s

30 step training time: 0.324217s

on_train_batch_end: 1615756948.406673s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.6646 - accuracy: 0.0997
on_train_batch_begin: 1615756948.406977s

31 step training time: 0.318688s

on_train_batch_end: 1615756948.723724s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.6534 - accuracy: 0.0997
on_train_batch_begin: 1615756948.724044s

32 step training time: 0.317068s

on_train_batch_end: 1615756949.045905s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.6426 - accuracy: 0.0997
on_train_batch_begin: 1615756949.046214s

33 step training time: 0.322170s

on_train_batch_end: 1615756949.367847s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.6438 - accuracy: 0.0997
on_train_batch_begin: 1615756949.368152s

34 step training time: 0.321938s

on_train_batch_end: 1615756949.690842s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.6340 - accuracy: 0.0998
on_train_batch_begin: 1615756949.691151s

35 step training time: 0.322999s

on_train_batch_end: 1615756950.014339s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.6247 - accuracy: 0.0998
on_train_batch_begin: 1615756950.014654s

36 step training time: 0.323503s

on_train_batch_end: 1615756950.338449s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.6199 - accuracy: 0.0997
on_train_batch_begin: 1615756950.338753s

37 step training time: 0.324100s

on_train_batch_end: 1615756950.656560s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.6075 - accuracy: 0.0998
on_train_batch_begin: 1615756950.656863s

38 step training time: 0.318110s

on_train_batch_end: 1615756950.975177s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.6001 - accuracy: 0.0998
on_train_batch_begin: 1615756950.975491s

39 step training time: 0.318628s

on_train_batch_end: 1615756951.296328s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.5917 - accuracy: 0.0998
on_train_batch_begin: 1615756951.296646s

40 step training time: 0.321155s

on_train_batch_end: 1615756951.619125s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.5857 - accuracy: 0.0998
on_train_batch_begin: 1615756951.619442s

41 step training time: 0.322795s

on_train_batch_end: 1615756951.942937s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.5837 - accuracy: 0.0998
on_train_batch_begin: 1615756951.943245s

42 step training time: 0.323804s

on_train_batch_end: 1615756952.266338s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.5753 - accuracy: 0.0998
on_train_batch_begin: 1615756952.266652s

43 step training time: 0.323406s

on_train_batch_end: 1615756952.590927s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.5691 - accuracy: 0.0998
on_train_batch_begin: 1615756952.591246s

44 step training time: 0.324594s

on_train_batch_end: 1615756952.915830s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.5629 - accuracy: 0.0998
on_train_batch_begin: 1615756952.916157s

45 step training time: 0.324911s

on_train_batch_end: 1615756953.240170s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.5585 - accuracy: 0.0998
on_train_batch_begin: 1615756953.240493s

46 step training time: 0.324336s

on_train_batch_end: 1615756953.563967s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.5543 - accuracy: 0.0998
on_train_batch_begin: 1615756953.564281s

47 step training time: 0.323788s

on_train_batch_end: 1615756953.884966s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5463 - accuracy: 0.0998
on_train_batch_begin: 1615756953.885275s

48 step training time: 0.320994s

on_train_batch_end: 1615756954.154130s

on_test_batch_begin: 1615756954.166491s

49 step training time: 0.281215s

on_epoch_end: 1615756954.941877s

Validation time: 0.775372s

Real time: 1615756954.941877s

Epoch time: 16.52914309501648s

50000/50000 [==============================] - 17s 331us/sample - loss: 2.5420 - accuracy: 0.0998 - val_loss: 6.9529 - val_accuracy: 0.0999

on_epoch_begin: 1615756954.942072s

Real time: 1615756954.942079
Epoch 4/5

on_train_batch_begin: 1615756954.945430s

on_train_batch_end: 1615756955.268439s

 1024/50000 [..............................] - ETA: 15s - loss: 2.0944 - accuracy: 0.0998
on_train_batch_begin: 1615756955.268754s

1 step training time: 0.323324s

on_train_batch_end: 1615756955.592285s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.1257 - accuracy: 0.0996
on_train_batch_begin: 1615756955.592587s

2 step training time: 0.323833s

on_train_batch_end: 1615756955.915980s

 3072/50000 [>.............................] - ETA: 14s - loss: 2.1042 - accuracy: 0.0999
on_train_batch_begin: 1615756955.916287s

3 step training time: 0.323699s

on_train_batch_end: 1615756956.238894s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.1025 - accuracy: 0.0999
on_train_batch_begin: 1615756956.239202s

4 step training time: 0.322915s

on_train_batch_end: 1615756956.558610s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.0837 - accuracy: 0.1000
on_train_batch_begin: 1615756956.558925s

5 step training time: 0.319723s

on_train_batch_end: 1615756956.876838s

 6144/50000 [==>...........................] - ETA: 13s - loss: 2.0843 - accuracy: 0.1001
on_train_batch_begin: 1615756956.877147s

6 step training time: 0.318222s

on_train_batch_end: 1615756957.198131s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.0595 - accuracy: 0.1000
on_train_batch_begin: 1615756957.198442s

7 step training time: 0.321295s

on_train_batch_end: 1615756957.521619s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.0557 - accuracy: 0.1000
on_train_batch_begin: 1615756957.521968s

8 step training time: 0.323526s

on_train_batch_end: 1615756957.844801s

 9216/50000 [====>.........................] - ETA: 12s - loss: 2.0488 - accuracy: 0.1000
on_train_batch_begin: 1615756957.845112s

9 step training time: 0.323143s

on_train_batch_end: 1615756958.169559s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.0269 - accuracy: 0.1000
on_train_batch_begin: 1615756958.169893s

10 step training time: 0.324781s

on_train_batch_end: 1615756958.493450s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.0155 - accuracy: 0.1000
on_train_batch_begin: 1615756958.493813s

11 step training time: 0.323921s

on_train_batch_end: 1615756958.817091s

12288/50000 [======>.......................] - ETA: 11s - loss: 2.0163 - accuracy: 0.1000
on_train_batch_begin: 1615756958.817400s

12 step training time: 0.323586s

on_train_batch_end: 1615756959.140349s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.0091 - accuracy: 0.1000
on_train_batch_begin: 1615756959.140669s

13 step training time: 0.323269s

on_train_batch_end: 1615756959.461826s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.9900 - accuracy: 0.1000
on_train_batch_begin: 1615756959.462132s

14 step training time: 0.321463s

on_train_batch_end: 1615756959.780584s

15360/50000 [========>.....................] - ETA: 10s - loss: 1.9912 - accuracy: 0.1000
on_train_batch_begin: 1615756959.780897s

15 step training time: 0.318766s

on_train_batch_end: 1615756960.101480s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.9878 - accuracy: 0.1000
on_train_batch_begin: 1615756960.101808s

16 step training time: 0.320910s

on_train_batch_end: 1615756960.423540s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.9783 - accuracy: 0.1000
on_train_batch_begin: 1615756960.423852s

17 step training time: 0.322044s

on_train_batch_end: 1615756960.746448s

18432/50000 [==========>...................] - ETA: 9s - loss: 1.9731 - accuracy: 0.1001 
on_train_batch_begin: 1615756960.746760s

18 step training time: 0.322908s

on_train_batch_end: 1615756961.069759s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.9602 - accuracy: 0.1001
on_train_batch_begin: 1615756961.070078s

19 step training time: 0.323318s

on_train_batch_end: 1615756961.393435s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.9542 - accuracy: 0.1000
on_train_batch_begin: 1615756961.393781s

20 step training time: 0.323703s

on_train_batch_end: 1615756961.717024s

21504/50000 [===========>..................] - ETA: 8s - loss: 1.9439 - accuracy: 0.1000
on_train_batch_begin: 1615756961.717337s

21 step training time: 0.323555s

on_train_batch_end: 1615756962.039253s

22528/50000 [============>.................] - ETA: 8s - loss: 1.9354 - accuracy: 0.1000
on_train_batch_begin: 1615756962.039560s

22 step training time: 0.322223s

on_train_batch_end: 1615756962.357000s

23552/50000 [=============>................] - ETA: 8s - loss: 1.9246 - accuracy: 0.1000
on_train_batch_begin: 1615756962.357315s

23 step training time: 0.317755s

on_train_batch_end: 1615756962.676761s

24576/50000 [=============>................] - ETA: 8s - loss: 1.9160 - accuracy: 0.1000
on_train_batch_begin: 1615756962.677070s

24 step training time: 0.319755s

on_train_batch_end: 1615756962.999501s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.8974 - accuracy: 0.1001
on_train_batch_begin: 1615756962.999805s

25 step training time: 0.322735s

on_train_batch_end: 1615756963.321098s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.8954 - accuracy: 0.1001
on_train_batch_begin: 1615756963.321406s

26 step training time: 0.321601s

on_train_batch_end: 1615756963.644512s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.8920 - accuracy: 0.1001
on_train_batch_begin: 1615756963.644819s

27 step training time: 0.323412s

on_train_batch_end: 1615756963.968329s

28672/50000 [================>.............] - ETA: 6s - loss: 1.8818 - accuracy: 0.1001
on_train_batch_begin: 1615756963.968638s

28 step training time: 0.323819s

on_train_batch_end: 1615756964.293921s

29696/50000 [================>.............] - ETA: 6s - loss: 1.8768 - accuracy: 0.1001
on_train_batch_begin: 1615756964.294227s

29 step training time: 0.325589s

on_train_batch_end: 1615756964.617018s

30720/50000 [=================>............] - ETA: 6s - loss: 1.8687 - accuracy: 0.1001
on_train_batch_begin: 1615756964.617321s

30 step training time: 0.323094s

on_train_batch_end: 1615756964.937491s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.8613 - accuracy: 0.1001
on_train_batch_begin: 1615756964.937828s

31 step training time: 0.320508s

on_train_batch_end: 1615756965.255719s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.8496 - accuracy: 0.1001
on_train_batch_begin: 1615756965.256032s

32 step training time: 0.318204s

on_train_batch_end: 1615756965.579203s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.8376 - accuracy: 0.1001
on_train_batch_begin: 1615756965.579507s

33 step training time: 0.323475s

on_train_batch_end: 1615756965.901122s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.8320 - accuracy: 0.1001
on_train_batch_begin: 1615756965.901469s

34 step training time: 0.321962s

on_train_batch_end: 1615756966.224587s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.8221 - accuracy: 0.1001
on_train_batch_begin: 1615756966.224904s

35 step training time: 0.323436s

on_train_batch_end: 1615756966.548891s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.8185 - accuracy: 0.1001
on_train_batch_begin: 1615756966.549216s

36 step training time: 0.324311s

on_train_batch_end: 1615756966.871544s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.8094 - accuracy: 0.1001
on_train_batch_begin: 1615756966.871860s

37 step training time: 0.322644s

on_train_batch_end: 1615756967.196461s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.8020 - accuracy: 0.1002
on_train_batch_begin: 1615756967.196765s

38 step training time: 0.324905s

on_train_batch_end: 1615756967.520555s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.7994 - accuracy: 0.1001
on_train_batch_begin: 1615756967.520866s

39 step training time: 0.324101s

on_train_batch_end: 1615756967.843226s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.7898 - accuracy: 0.1001
on_train_batch_begin: 1615756967.843540s

40 step training time: 0.322674s

on_train_batch_end: 1615756968.162263s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.7817 - accuracy: 0.1002
on_train_batch_begin: 1615756968.162574s

41 step training time: 0.319034s

on_train_batch_end: 1615756968.483096s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.7746 - accuracy: 0.1002
on_train_batch_begin: 1615756968.483397s

42 step training time: 0.320822s

on_train_batch_end: 1615756968.804665s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.7675 - accuracy: 0.1002
on_train_batch_begin: 1615756968.804967s

43 step training time: 0.321571s

on_train_batch_end: 1615756969.130062s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.7594 - accuracy: 0.1001
on_train_batch_begin: 1615756969.130362s

44 step training time: 0.325394s

on_train_batch_end: 1615756969.453078s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.7510 - accuracy: 0.1001
on_train_batch_begin: 1615756969.453397s

45 step training time: 0.323035s

on_train_batch_end: 1615756969.779072s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7434 - accuracy: 0.1001
on_train_batch_begin: 1615756969.779391s

46 step training time: 0.325994s

on_train_batch_end: 1615756970.102487s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7354 - accuracy: 0.1001
on_train_batch_begin: 1615756970.102792s

47 step training time: 0.323401s

on_train_batch_end: 1615756970.422594s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7284 - accuracy: 0.1001
on_train_batch_begin: 1615756970.422910s

48 step training time: 0.320118s

on_train_batch_end: 1615756970.689294s

on_test_batch_begin: 1615756970.699273s

49 step training time: 0.276363s

on_epoch_end: 1615756971.479186s

Validation time: 0.779898s

Real time: 1615756971.479186s

Epoch time: 16.537124156951904s

50000/50000 [==============================] - 17s 331us/sample - loss: 1.7231 - accuracy: 0.1001 - val_loss: 6.8412 - val_accuracy: 0.0999

on_epoch_begin: 1615756971.479387s

Real time: 1615756971.4793918
Epoch 5/5

on_train_batch_begin: 1615756971.482840s

on_train_batch_end: 1615756971.802441s

 1024/50000 [..............................] - ETA: 15s - loss: 1.3171 - accuracy: 0.0999
on_train_batch_begin: 1615756971.802748s

1 step training time: 0.319908s

on_train_batch_end: 1615756972.122522s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.2235 - accuracy: 0.1000
on_train_batch_begin: 1615756972.122831s

2 step training time: 0.320084s

on_train_batch_end: 1615756972.445807s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.2350 - accuracy: 0.1000
on_train_batch_begin: 1615756972.446104s

3 step training time: 0.323273s

on_train_batch_end: 1615756972.769912s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.2368 - accuracy: 0.1001
on_train_batch_begin: 1615756972.770225s

4 step training time: 0.324121s

on_train_batch_end: 1615756973.094026s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.2079 - accuracy: 0.1004
on_train_batch_begin: 1615756973.094338s

5 step training time: 0.324113s

on_train_batch_end: 1615756973.419225s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.1821 - accuracy: 0.1004
on_train_batch_begin: 1615756973.419542s

6 step training time: 0.325204s

on_train_batch_end: 1615756973.744339s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.1951 - accuracy: 0.1003
on_train_batch_begin: 1615756973.744651s

7 step training time: 0.325109s

on_train_batch_end: 1615756974.068408s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.1801 - accuracy: 0.1003
on_train_batch_begin: 1615756974.068719s

8 step training time: 0.324068s

on_train_batch_end: 1615756974.392667s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.1681 - accuracy: 0.1003
on_train_batch_begin: 1615756974.392972s

9 step training time: 0.324253s

on_train_batch_end: 1615756974.719154s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.1686 - accuracy: 0.1004
on_train_batch_begin: 1615756974.719465s

10 step training time: 0.326494s

on_train_batch_end: 1615756975.044520s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.1642 - accuracy: 0.1003
on_train_batch_begin: 1615756975.044841s

11 step training time: 0.325376s

on_train_batch_end: 1615756975.370679s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.1488 - accuracy: 0.1003
on_train_batch_begin: 1615756975.370996s

12 step training time: 0.326154s

on_train_batch_end: 1615756975.695071s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.1380 - accuracy: 0.1003
on_train_batch_begin: 1615756975.695380s

13 step training time: 0.324384s

on_train_batch_end: 1615756976.019011s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.1325 - accuracy: 0.1003
on_train_batch_begin: 1615756976.019318s

14 step training time: 0.323938s

on_train_batch_end: 1615756976.345733s

15360/50000 [========>.....................] - ETA: 10s - loss: 1.1370 - accuracy: 0.1002
on_train_batch_begin: 1615756976.346037s

15 step training time: 0.326719s

on_train_batch_end: 1615756976.670485s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.1313 - accuracy: 0.1002
on_train_batch_begin: 1615756976.670800s

16 step training time: 0.324763s

on_train_batch_end: 1615756976.994984s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.1232 - accuracy: 0.1003
on_train_batch_begin: 1615756976.995294s

17 step training time: 0.324493s

on_train_batch_end: 1615756977.319362s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.1211 - accuracy: 0.1002
on_train_batch_begin: 1615756977.319679s

18 step training time: 0.324386s

on_train_batch_end: 1615756977.641532s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.1199 - accuracy: 0.1002 
on_train_batch_begin: 1615756977.641890s

19 step training time: 0.322211s

on_train_batch_end: 1615756977.963172s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.1141 - accuracy: 0.1002
on_train_batch_begin: 1615756977.963479s

20 step training time: 0.321589s

on_train_batch_end: 1615756978.282982s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.1058 - accuracy: 0.1002
on_train_batch_begin: 1615756978.283299s

21 step training time: 0.319819s

on_train_batch_end: 1615756978.606110s

22528/50000 [============>.................] - ETA: 8s - loss: 1.1045 - accuracy: 0.1002
on_train_batch_begin: 1615756978.606418s

22 step training time: 0.323119s

on_train_batch_end: 1615756978.928874s

23552/50000 [=============>................] - ETA: 8s - loss: 1.1038 - accuracy: 0.1003
on_train_batch_begin: 1615756978.929177s

23 step training time: 0.322758s

on_train_batch_end: 1615756979.253125s

24576/50000 [=============>................] - ETA: 8s - loss: 1.0929 - accuracy: 0.1002
on_train_batch_begin: 1615756979.253430s

24 step training time: 0.324254s

on_train_batch_end: 1615756979.577775s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.0926 - accuracy: 0.1003
on_train_batch_begin: 1615756979.578079s

25 step training time: 0.324649s

on_train_batch_end: 1615756979.902751s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.0927 - accuracy: 0.1003
on_train_batch_begin: 1615756979.903066s

26 step training time: 0.324987s

on_train_batch_end: 1615756980.227928s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.0894 - accuracy: 0.1003
on_train_batch_begin: 1615756980.228246s

27 step training time: 0.325180s

on_train_batch_end: 1615756980.552984s

28672/50000 [================>.............] - ETA: 6s - loss: 1.0828 - accuracy: 0.1003
on_train_batch_begin: 1615756980.553294s

28 step training time: 0.325048s

on_train_batch_end: 1615756980.877411s

29696/50000 [================>.............] - ETA: 6s - loss: 1.0847 - accuracy: 0.1003
on_train_batch_begin: 1615756980.877751s

29 step training time: 0.324457s

on_train_batch_end: 1615756981.201753s

30720/50000 [=================>............] - ETA: 6s - loss: 1.0849 - accuracy: 0.1003
on_train_batch_begin: 1615756981.202064s

30 step training time: 0.324313s

on_train_batch_end: 1615756981.528148s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.0820 - accuracy: 0.1003
on_train_batch_begin: 1615756981.528460s

31 step training time: 0.326396s

on_train_batch_end: 1615756981.853339s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.0804 - accuracy: 0.1003
on_train_batch_begin: 1615756981.853670s

32 step training time: 0.325210s

on_train_batch_end: 1615756982.179456s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.0789 - accuracy: 0.1003
on_train_batch_begin: 1615756982.179783s

33 step training time: 0.326113s

on_train_batch_end: 1615756982.503390s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.0770 - accuracy: 0.1003
on_train_batch_begin: 1615756982.503703s

34 step training time: 0.323920s

on_train_batch_end: 1615756982.828316s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.0801 - accuracy: 0.1003
on_train_batch_begin: 1615756982.828621s

35 step training time: 0.324919s

on_train_batch_end: 1615756983.154478s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.0792 - accuracy: 0.1003
on_train_batch_begin: 1615756983.154787s

36 step training time: 0.326165s

on_train_batch_end: 1615756983.477739s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.0744 - accuracy: 0.1003
on_train_batch_begin: 1615756983.478050s

37 step training time: 0.323264s

on_train_batch_end: 1615756983.802825s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.0739 - accuracy: 0.1003
on_train_batch_begin: 1615756983.803131s

38 step training time: 0.325080s

on_train_batch_end: 1615756984.126698s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.0746 - accuracy: 0.1003
on_train_batch_begin: 1615756984.127026s

39 step training time: 0.323895s

on_train_batch_end: 1615756984.453285s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.0722 - accuracy: 0.1003
on_train_batch_begin: 1615756984.453596s

40 step training time: 0.326570s

on_train_batch_end: 1615756984.778453s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.0704 - accuracy: 0.1003
on_train_batch_begin: 1615756984.778764s

41 step training time: 0.325168s

on_train_batch_end: 1615756985.103452s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.0653 - accuracy: 0.1003
on_train_batch_begin: 1615756985.103755s

42 step training time: 0.324991s

on_train_batch_end: 1615756985.425994s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.0653 - accuracy: 0.1003
on_train_batch_begin: 1615756985.426309s

43 step training time: 0.322554s

on_train_batch_end: 1615756985.752478s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.0633 - accuracy: 0.1003
on_train_batch_begin: 1615756985.752782s

44 step training time: 0.326473s

on_train_batch_end: 1615756986.077777s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.0608 - accuracy: 0.1003
on_train_batch_begin: 1615756986.078080s

45 step training time: 0.325298s

on_train_batch_end: 1615756986.400928s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.0590 - accuracy: 0.1003
on_train_batch_begin: 1615756986.401239s

46 step training time: 0.323159s

on_train_batch_end: 1615756986.725502s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.0561 - accuracy: 0.1003
on_train_batch_begin: 1615756986.725834s

47 step training time: 0.324595s

on_train_batch_end: 1615756987.049519s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0540 - accuracy: 0.1003
on_train_batch_begin: 1615756987.049860s

48 step training time: 0.324026s

on_train_batch_end: 1615756987.320746s

on_test_batch_begin: 1615756987.335846s

49 step training time: 0.285986s

on_epoch_end: 1615756988.111833s

Validation time: 0.775974s

Real time: 1615756988.111833s

Epoch time: 16.632457733154297s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.0511 - accuracy: 0.1003 - val_loss: 6.8386 - val_accuracy: 0.0999
Tempo do fit: 113.17985248565674