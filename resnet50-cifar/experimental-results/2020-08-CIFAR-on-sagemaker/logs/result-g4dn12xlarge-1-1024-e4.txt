wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:40
   204800/170498071 [..............................] - ETA: 1:16
  1064960/170498071 [..............................] - ETA: 22s 
  3497984/170498071 [..............................] - ETA: 9s 
  6864896/170498071 [>.............................] - ETA: 5s
 10215424/170498071 [>.............................] - ETA: 4s
 13557760/170498071 [=>............................] - ETA: 3s
 16916480/170498071 [=>............................] - ETA: 3s
 20127744/170498071 [==>...........................] - ETA: 3s
 23388160/170498071 [===>..........................] - ETA: 3s
 26730496/170498071 [===>..........................] - ETA: 2s
 30072832/170498071 [====>.........................] - ETA: 2s
 33431552/170498071 [====>.........................] - ETA: 2s
 36806656/170498071 [=====>........................] - ETA: 2s
 40165376/170498071 [======>.......................] - ETA: 2s
 43458560/170498071 [======>.......................] - ETA: 2s
 46718976/170498071 [=======>......................] - ETA: 2s
 49897472/170498071 [=======>......................] - ETA: 2s
 53157888/170498071 [========>.....................] - ETA: 2s
 56516608/170498071 [========>.....................] - ETA: 2s
 59793408/170498071 [=========>....................] - ETA: 1s
 63168512/170498071 [==========>...................] - ETA: 1s
 66543616/170498071 [==========>...................] - ETA: 1s
 69885952/170498071 [===========>..................] - ETA: 1s
 73244672/170498071 [===========>..................] - ETA: 1s
 76537856/170498071 [============>.................] - ETA: 1s
 79831040/170498071 [=============>................] - ETA: 1s
 83042304/170498071 [=============>................] - ETA: 1s
 86417408/170498071 [==============>...............] - ETA: 1s
 89759744/170498071 [==============>...............] - ETA: 1s
 93102080/170498071 [===============>..............] - ETA: 1s
 96296960/170498071 [===============>..............] - ETA: 1s
 99082240/170498071 [================>.............] - ETA: 1s
101769216/170498071 [================>.............] - ETA: 1s
104521728/170498071 [=================>............] - ETA: 1s
107257856/170498071 [=================>............] - ETA: 1s
109993984/170498071 [==================>...........] - ETA: 1s
112812032/170498071 [==================>...........] - ETA: 0s
115564544/170498071 [===================>..........] - ETA: 0s
118284288/170498071 [===================>..........] - ETA: 0s
121020416/170498071 [====================>.........] - ETA: 0s
123756544/170498071 [====================>.........] - ETA: 0s
126558208/170498071 [=====================>........] - ETA: 0s
129343488/170498071 [=====================>........] - ETA: 0s
132079616/170498071 [======================>.......] - ETA: 0s
134815744/170498071 [======================>.......] - ETA: 0s
137576448/170498071 [=======================>......] - ETA: 0s
140288000/170498071 [=======================>......] - ETA: 0s
143024128/170498071 [========================>.....] - ETA: 0s
145776640/170498071 [========================>.....] - ETA: 0s
148545536/170498071 [=========================>....] - ETA: 0s
151224320/170498071 [=========================>....] - ETA: 0s
153952256/170498071 [==========================>...] - ETA: 0s
156737536/170498071 [==========================>...] - ETA: 0s
159440896/170498071 [===========================>..] - ETA: 0s
162209792/170498071 [===========================>..] - ETA: 0s
164995072/170498071 [============================>.] - ETA: 0s
167682048/170498071 [============================>.] - ETA: 0s
170352640/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 3s
 9388032/94765736 [=>............................] - ETA: 0s
15966208/94765736 [====>.........................] - ETA: 0s
21397504/94765736 [=====>........................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
73195520/94765736 [======================>.......] - ETA: 0s
75964416/94765736 [=======================>......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
91963392/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 16.965524911880493
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615692135.271415s

Real time: 1615692135.2714305
Epoch 1/5

on_train_batch_begin: 1615692136.061533s

on_train_batch_end: 1615692183.820743s

 1024/50000 [..............................] - ETA: 38:42 - loss: 17.1885 - accuracy: 3.0518e-04
on_train_batch_begin: 1615692183.821381s

1 step training time: 47.759848s

on_train_batch_end: 1615692183.955217s

 2048/50000 [>.............................] - ETA: 18:59 - loss: 15.6189 - accuracy: 3.9864e-04
on_train_batch_begin: 1615692183.955542s

2 step training time: 0.134161s

on_train_batch_end: 1615692184.091509s

 3072/50000 [>.............................] - ETA: 12:25 - loss: 13.9010 - accuracy: 4.2089e-04
on_train_batch_begin: 1615692184.091821s

3 step training time: 0.136278s

on_train_batch_end: 1615692184.224434s

 4096/50000 [=>............................] - ETA: 9:08 - loss: 12.6895 - accuracy: 6.6853e-04 
on_train_batch_begin: 1615692184.224800s

4 step training time: 0.132980s

on_train_batch_end: 1615692184.359947s

 5120/50000 [==>...........................] - ETA: 7:10 - loss: 11.7695 - accuracy: 0.0016    
on_train_batch_begin: 1615692184.360271s

5 step training time: 0.135470s

on_train_batch_end: 1615692184.494785s

 6144/50000 [==>...........................] - ETA: 5:51 - loss: 11.0767 - accuracy: 0.0030
on_train_batch_begin: 1615692184.495087s

6 step training time: 0.134816s

on_train_batch_end: 1615692184.627736s

 7168/50000 [===>..........................] - ETA: 4:54 - loss: 10.5687 - accuracy: 0.0041
on_train_batch_begin: 1615692184.628045s

7 step training time: 0.132958s

on_train_batch_end: 1615692184.764033s

 8192/50000 [===>..........................] - ETA: 4:12 - loss: 10.1709 - accuracy: 0.0060
on_train_batch_begin: 1615692184.764354s

8 step training time: 0.136309s

on_train_batch_end: 1615692184.899990s

 9216/50000 [====>.........................] - ETA: 3:39 - loss: 9.8430 - accuracy: 0.0081 
on_train_batch_begin: 1615692184.900296s

9 step training time: 0.135942s

on_train_batch_end: 1615692185.034067s

10240/50000 [=====>........................] - ETA: 3:13 - loss: 9.5711 - accuracy: 0.0102
on_train_batch_begin: 1615692185.034387s

10 step training time: 0.134091s

on_train_batch_end: 1615692185.171149s

11264/50000 [=====>........................] - ETA: 2:51 - loss: 9.3381 - accuracy: 0.0126
on_train_batch_begin: 1615692185.171463s

11 step training time: 0.137076s

on_train_batch_end: 1615692185.305289s

12288/50000 [======>.......................] - ETA: 2:33 - loss: 9.1319 - accuracy: 0.0146
on_train_batch_begin: 1615692185.305604s

12 step training time: 0.134141s

on_train_batch_end: 1615692185.439494s

13312/50000 [======>.......................] - ETA: 2:18 - loss: 8.9544 - accuracy: 0.0165
on_train_batch_begin: 1615692185.439802s

13 step training time: 0.134198s

on_train_batch_end: 1615692185.575505s

14336/50000 [=======>......................] - ETA: 2:05 - loss: 8.7916 - accuracy: 0.0186
on_train_batch_begin: 1615692185.575804s

14 step training time: 0.136002s

on_train_batch_end: 1615692185.711717s

15360/50000 [========>.....................] - ETA: 1:53 - loss: 8.6459 - accuracy: 0.0203
on_train_batch_begin: 1615692185.712012s

15 step training time: 0.136208s

on_train_batch_end: 1615692185.844482s

16384/50000 [========>.....................] - ETA: 1:43 - loss: 8.5107 - accuracy: 0.0218
on_train_batch_begin: 1615692185.844790s

16 step training time: 0.132779s

on_train_batch_end: 1615692185.981885s

17408/50000 [=========>....................] - ETA: 1:34 - loss: 8.3806 - accuracy: 0.0236
on_train_batch_begin: 1615692185.982182s

17 step training time: 0.137391s

on_train_batch_end: 1615692186.116006s

18432/50000 [==========>...................] - ETA: 1:27 - loss: 8.2589 - accuracy: 0.0255
on_train_batch_begin: 1615692186.116297s

18 step training time: 0.134115s

on_train_batch_end: 1615692186.249043s

19456/50000 [==========>...................] - ETA: 1:20 - loss: 8.1413 - accuracy: 0.0269
on_train_batch_begin: 1615692186.249364s

19 step training time: 0.133067s

on_train_batch_end: 1615692186.383633s

20480/50000 [===========>..................] - ETA: 1:13 - loss: 8.0329 - accuracy: 0.0283
on_train_batch_begin: 1615692186.383930s

20 step training time: 0.134566s

on_train_batch_end: 1615692186.515777s

21504/50000 [===========>..................] - ETA: 1:07 - loss: 7.9238 - accuracy: 0.0294
on_train_batch_begin: 1615692186.516071s

21 step training time: 0.132141s

on_train_batch_end: 1615692186.652708s

22528/50000 [============>.................] - ETA: 1:02 - loss: 7.8252 - accuracy: 0.0306
on_train_batch_begin: 1615692186.653000s

22 step training time: 0.136929s

on_train_batch_end: 1615692186.786273s

23552/50000 [=============>................] - ETA: 57s - loss: 7.7190 - accuracy: 0.0317 
on_train_batch_begin: 1615692186.786560s

23 step training time: 0.133560s

on_train_batch_end: 1615692186.918269s

24576/50000 [=============>................] - ETA: 53s - loss: 7.6175 - accuracy: 0.0328
on_train_batch_begin: 1615692186.918579s

24 step training time: 0.132019s

on_train_batch_end: 1615692187.054227s

25600/50000 [==============>...............] - ETA: 49s - loss: 7.5208 - accuracy: 0.0338
on_train_batch_begin: 1615692187.054538s

25 step training time: 0.135959s

on_train_batch_end: 1615692187.186238s

26624/50000 [==============>...............] - ETA: 45s - loss: 7.4256 - accuracy: 0.0349
on_train_batch_begin: 1615692187.186529s

26 step training time: 0.131991s

on_train_batch_end: 1615692187.321361s

27648/50000 [===============>..............] - ETA: 42s - loss: 7.3284 - accuracy: 0.0360
on_train_batch_begin: 1615692187.321657s

27 step training time: 0.135128s

on_train_batch_end: 1615692187.456003s

28672/50000 [================>.............] - ETA: 38s - loss: 7.2400 - accuracy: 0.0371
on_train_batch_begin: 1615692187.456297s

28 step training time: 0.134640s

on_train_batch_end: 1615692187.588521s

29696/50000 [================>.............] - ETA: 35s - loss: 7.1423 - accuracy: 0.0383
on_train_batch_begin: 1615692187.588817s

29 step training time: 0.132521s

on_train_batch_end: 1615692187.723429s

30720/50000 [=================>............] - ETA: 32s - loss: 7.0513 - accuracy: 0.0394
on_train_batch_begin: 1615692187.723729s

30 step training time: 0.134912s

on_train_batch_end: 1615692187.855658s

31744/50000 [==================>...........] - ETA: 30s - loss: 6.9565 - accuracy: 0.0407
on_train_batch_begin: 1615692187.855945s

31 step training time: 0.132216s

on_train_batch_end: 1615692187.991145s

32768/50000 [==================>...........] - ETA: 27s - loss: 6.8568 - accuracy: 0.0419
on_train_batch_begin: 1615692187.991435s

32 step training time: 0.135490s

on_train_batch_end: 1615692188.124291s

33792/50000 [===================>..........] - ETA: 25s - loss: 6.7630 - accuracy: 0.0431
on_train_batch_begin: 1615692188.124609s

33 step training time: 0.133174s

on_train_batch_end: 1615692188.257288s

34816/50000 [===================>..........] - ETA: 23s - loss: 6.6696 - accuracy: 0.0445
on_train_batch_begin: 1615692188.257586s

34 step training time: 0.132977s

on_train_batch_end: 1615692188.392779s

35840/50000 [====================>.........] - ETA: 20s - loss: 6.5854 - accuracy: 0.0458
on_train_batch_begin: 1615692188.393071s

35 step training time: 0.135485s

on_train_batch_end: 1615692188.526506s

36864/50000 [=====================>........] - ETA: 18s - loss: 6.4993 - accuracy: 0.0470
on_train_batch_begin: 1615692188.526805s

36 step training time: 0.133733s

on_train_batch_end: 1615692188.660982s

37888/50000 [=====================>........] - ETA: 17s - loss: 6.4118 - accuracy: 0.0482
on_train_batch_begin: 1615692188.661295s

37 step training time: 0.134490s

on_train_batch_end: 1615692188.794320s

38912/50000 [======================>.......] - ETA: 15s - loss: 6.3273 - accuracy: 0.0494
on_train_batch_begin: 1615692188.794630s

38 step training time: 0.133336s

on_train_batch_end: 1615692188.927909s

39936/50000 [======================>.......] - ETA: 13s - loss: 6.2462 - accuracy: 0.0507
on_train_batch_begin: 1615692188.928208s

39 step training time: 0.133578s

on_train_batch_end: 1615692189.062612s

40960/50000 [=======================>......] - ETA: 11s - loss: 6.1674 - accuracy: 0.0518
on_train_batch_begin: 1615692189.062900s

40 step training time: 0.134692s

on_train_batch_end: 1615692189.197591s

41984/50000 [========================>.....] - ETA: 10s - loss: 6.0917 - accuracy: 0.0530
on_train_batch_begin: 1615692189.197872s

41 step training time: 0.134972s

on_train_batch_end: 1615692189.331987s

43008/50000 [========================>.....] - ETA: 8s - loss: 6.0163 - accuracy: 0.0540 
on_train_batch_begin: 1615692189.332274s

42 step training time: 0.134402s

on_train_batch_end: 1615692189.471978s

44032/50000 [=========================>....] - ETA: 7s - loss: 5.9406 - accuracy: 0.0551
on_train_batch_begin: 1615692189.472260s

43 step training time: 0.139986s

on_train_batch_end: 1615692189.605374s

45056/50000 [==========================>...] - ETA: 5s - loss: 5.8725 - accuracy: 0.0561
on_train_batch_begin: 1615692189.605657s

44 step training time: 0.133397s

on_train_batch_end: 1615692189.740323s

46080/50000 [==========================>...] - ETA: 4s - loss: 5.8023 - accuracy: 0.0571
on_train_batch_begin: 1615692189.740608s

45 step training time: 0.134951s

on_train_batch_end: 1615692189.876200s

47104/50000 [===========================>..] - ETA: 3s - loss: 5.7334 - accuracy: 0.0580
on_train_batch_begin: 1615692189.876484s

46 step training time: 0.135876s

on_train_batch_end: 1615692190.008560s

48128/50000 [===========================>..] - ETA: 2s - loss: 5.6673 - accuracy: 0.0589
on_train_batch_begin: 1615692190.008844s

47 step training time: 0.132360s

on_train_batch_end: 1615692190.142606s

49152/50000 [============================>.] - ETA: 0s - loss: 5.6008 - accuracy: 0.0597
on_train_batch_begin: 1615692190.142899s

48 step training time: 0.134055s

on_train_batch_end: 1615692192.822401s

on_test_batch_begin: 1615692193.055764s

49 step training time: 2.912865s

on_epoch_end: 1615692198.959955s

Validation time: 5.904176s

Real time: 1615692198.959955s

Epoch time: 63.68854093551636s

50000/50000 [==============================] - 64s 1ms/sample - loss: 5.5487 - accuracy: 0.0603 - val_loss: 14.2643 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615692198.960141s

Real time: 1615692198.960146
Epoch 2/5

on_train_batch_begin: 1615692198.964523s

on_train_batch_end: 1615692199.106128s

 1024/50000 [..............................] - ETA: 6s - loss: 2.3536 - accuracy: 0.1007
on_train_batch_begin: 1615692199.106412s

1 step training time: 0.141889s

on_train_batch_end: 1615692199.239528s

 2048/50000 [>.............................] - ETA: 6s - loss: 2.3962 - accuracy: 0.1005
on_train_batch_begin: 1615692199.239814s

2 step training time: 0.133402s

on_train_batch_end: 1615692199.374381s

 3072/50000 [>.............................] - ETA: 6s - loss: 2.4011 - accuracy: 0.1003
on_train_batch_begin: 1615692199.374688s

3 step training time: 0.134874s

on_train_batch_end: 1615692199.510471s

 4096/50000 [=>............................] - ETA: 6s - loss: 2.4356 - accuracy: 0.1008
on_train_batch_begin: 1615692199.510775s

4 step training time: 0.136087s

on_train_batch_end: 1615692199.643160s

 5120/50000 [==>...........................] - ETA: 5s - loss: 2.4414 - accuracy: 0.1007
on_train_batch_begin: 1615692199.643501s

5 step training time: 0.132726s

on_train_batch_end: 1615692199.778343s

 6144/50000 [==>...........................] - ETA: 5s - loss: 2.4047 - accuracy: 0.1007
on_train_batch_begin: 1615692199.778643s

6 step training time: 0.135142s

on_train_batch_end: 1615692199.916217s

 7168/50000 [===>..........................] - ETA: 5s - loss: 2.4087 - accuracy: 0.1007
on_train_batch_begin: 1615692199.916523s

7 step training time: 0.137880s

on_train_batch_end: 1615692200.048816s

 8192/50000 [===>..........................] - ETA: 5s - loss: 2.4109 - accuracy: 0.1006
on_train_batch_begin: 1615692200.049117s

8 step training time: 0.132594s

on_train_batch_end: 1615692200.184094s

 9216/50000 [====>.........................] - ETA: 5s - loss: 2.4152 - accuracy: 0.1006
on_train_batch_begin: 1615692200.184402s

9 step training time: 0.135285s

on_train_batch_end: 1615692200.319991s

10240/50000 [=====>........................] - ETA: 5s - loss: 2.4256 - accuracy: 0.1005
on_train_batch_begin: 1615692200.320308s

10 step training time: 0.135906s

on_train_batch_end: 1615692200.452484s

11264/50000 [=====>........................] - ETA: 5s - loss: 2.4245 - accuracy: 0.1006
on_train_batch_begin: 1615692200.452803s

11 step training time: 0.132495s

on_train_batch_end: 1615692200.588303s

12288/50000 [======>.......................] - ETA: 4s - loss: 2.4510 - accuracy: 0.1006
on_train_batch_begin: 1615692200.588604s

12 step training time: 0.135801s

on_train_batch_end: 1615692200.721911s

13312/50000 [======>.......................] - ETA: 4s - loss: 2.4599 - accuracy: 0.1006
on_train_batch_begin: 1615692200.722215s

13 step training time: 0.133611s

on_train_batch_end: 1615692200.855794s

14336/50000 [=======>......................] - ETA: 4s - loss: 2.4608 - accuracy: 0.1006
on_train_batch_begin: 1615692200.856108s

14 step training time: 0.133893s

on_train_batch_end: 1615692200.991298s

15360/50000 [========>.....................] - ETA: 4s - loss: 2.4600 - accuracy: 0.1006
on_train_batch_begin: 1615692200.991602s

15 step training time: 0.135494s

on_train_batch_end: 1615692201.123175s

16384/50000 [========>.....................] - ETA: 4s - loss: 2.4531 - accuracy: 0.1006
on_train_batch_begin: 1615692201.123516s

16 step training time: 0.131913s

on_train_batch_end: 1615692201.260610s

17408/50000 [=========>....................] - ETA: 4s - loss: 2.4494 - accuracy: 0.1006
on_train_batch_begin: 1615692201.260917s

17 step training time: 0.137401s

on_train_batch_end: 1615692201.397007s

18432/50000 [==========>...................] - ETA: 4s - loss: 2.4450 - accuracy: 0.1007
on_train_batch_begin: 1615692201.397347s

18 step training time: 0.136430s

on_train_batch_end: 1615692201.531436s

19456/50000 [==========>...................] - ETA: 4s - loss: 2.4294 - accuracy: 0.1007
on_train_batch_begin: 1615692201.531744s

19 step training time: 0.134398s

on_train_batch_end: 1615692201.666109s

20480/50000 [===========>..................] - ETA: 3s - loss: 2.4157 - accuracy: 0.1007
on_train_batch_begin: 1615692201.666413s

20 step training time: 0.134668s

on_train_batch_end: 1615692201.799778s

21504/50000 [===========>..................] - ETA: 3s - loss: 2.4156 - accuracy: 0.1007
on_train_batch_begin: 1615692201.800085s

21 step training time: 0.133672s

on_train_batch_end: 1615692201.932735s

22528/50000 [============>.................] - ETA: 3s - loss: 2.4042 - accuracy: 0.1007
on_train_batch_begin: 1615692201.933051s

22 step training time: 0.132967s

on_train_batch_end: 1615692202.071130s

23552/50000 [=============>................] - ETA: 3s - loss: 2.3943 - accuracy: 0.1007
on_train_batch_begin: 1615692202.071440s

23 step training time: 0.138389s

on_train_batch_end: 1615692202.204100s

24576/50000 [=============>................] - ETA: 3s - loss: 2.3871 - accuracy: 0.1007
on_train_batch_begin: 1615692202.204412s

24 step training time: 0.132972s

on_train_batch_end: 1615692202.337332s

25600/50000 [==============>...............] - ETA: 3s - loss: 2.3791 - accuracy: 0.1007
on_train_batch_begin: 1615692202.337642s

25 step training time: 0.133230s

on_train_batch_end: 1615692202.474482s

26624/50000 [==============>...............] - ETA: 3s - loss: 2.3663 - accuracy: 0.1007
on_train_batch_begin: 1615692202.474832s

26 step training time: 0.137189s

on_train_batch_end: 1615692202.608314s

27648/50000 [===============>..............] - ETA: 2s - loss: 2.3577 - accuracy: 0.1007
on_train_batch_begin: 1615692202.608625s

27 step training time: 0.133793s

on_train_batch_end: 1615692202.742059s

28672/50000 [================>.............] - ETA: 2s - loss: 2.3435 - accuracy: 0.1007
on_train_batch_begin: 1615692202.742363s

28 step training time: 0.133739s

on_train_batch_end: 1615692202.878199s

29696/50000 [================>.............] - ETA: 2s - loss: 2.3275 - accuracy: 0.1007
on_train_batch_begin: 1615692202.878505s

29 step training time: 0.136142s

on_train_batch_end: 1615692203.010699s

30720/50000 [=================>............] - ETA: 2s - loss: 2.3169 - accuracy: 0.1007
on_train_batch_begin: 1615692203.011003s

30 step training time: 0.132498s

on_train_batch_end: 1615692203.145757s

31744/50000 [==================>...........] - ETA: 2s - loss: 2.3053 - accuracy: 0.1007
on_train_batch_begin: 1615692203.146079s

31 step training time: 0.135076s

on_train_batch_end: 1615692203.279257s

32768/50000 [==================>...........] - ETA: 2s - loss: 2.2968 - accuracy: 0.1007
on_train_batch_begin: 1615692203.279562s

32 step training time: 0.133483s

on_train_batch_end: 1615692203.412920s

33792/50000 [===================>..........] - ETA: 2s - loss: 2.2813 - accuracy: 0.1008
on_train_batch_begin: 1615692203.413207s

33 step training time: 0.133645s

on_train_batch_end: 1615692203.548307s

34816/50000 [===================>..........] - ETA: 2s - loss: 2.2687 - accuracy: 0.1008
on_train_batch_begin: 1615692203.548593s

34 step training time: 0.135386s

on_train_batch_end: 1615692203.680947s

35840/50000 [====================>.........] - ETA: 1s - loss: 2.2613 - accuracy: 0.1008
on_train_batch_begin: 1615692203.681228s

35 step training time: 0.132635s

on_train_batch_end: 1615692203.817582s

36864/50000 [=====================>........] - ETA: 1s - loss: 2.2515 - accuracy: 0.1007
on_train_batch_begin: 1615692203.817870s

36 step training time: 0.136642s

on_train_batch_end: 1615692203.951958s

37888/50000 [=====================>........] - ETA: 1s - loss: 2.2398 - accuracy: 0.1007
on_train_batch_begin: 1615692203.952246s

37 step training time: 0.134376s

on_train_batch_end: 1615692204.085518s

38912/50000 [======================>.......] - ETA: 1s - loss: 2.2281 - accuracy: 0.1007
on_train_batch_begin: 1615692204.085808s

38 step training time: 0.133562s

on_train_batch_end: 1615692204.221578s

39936/50000 [======================>.......] - ETA: 1s - loss: 2.2239 - accuracy: 0.1007
on_train_batch_begin: 1615692204.221863s

39 step training time: 0.136055s

on_train_batch_end: 1615692204.356755s

40960/50000 [=======================>......] - ETA: 1s - loss: 2.2169 - accuracy: 0.1007
on_train_batch_begin: 1615692204.357060s

40 step training time: 0.135197s

on_train_batch_end: 1615692204.489120s

41984/50000 [========================>.....] - ETA: 1s - loss: 2.2078 - accuracy: 0.1008
on_train_batch_begin: 1615692204.489445s

41 step training time: 0.132385s

on_train_batch_end: 1615692204.626695s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.2034 - accuracy: 0.1007
on_train_batch_begin: 1615692204.626980s

42 step training time: 0.137535s

on_train_batch_end: 1615692204.760521s

44032/50000 [=========================>....] - ETA: 0s - loss: 2.1970 - accuracy: 0.1007
on_train_batch_begin: 1615692204.760804s

43 step training time: 0.133824s

on_train_batch_end: 1615692204.896402s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.1871 - accuracy: 0.1007
on_train_batch_begin: 1615692204.896682s

44 step training time: 0.135878s

on_train_batch_end: 1615692205.032383s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.1797 - accuracy: 0.1007
on_train_batch_begin: 1615692205.032675s

45 step training time: 0.135993s

on_train_batch_end: 1615692205.165985s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.1727 - accuracy: 0.1007
on_train_batch_begin: 1615692205.166275s

46 step training time: 0.133600s

on_train_batch_end: 1615692205.299372s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.1656 - accuracy: 0.1007
on_train_batch_begin: 1615692205.299655s

47 step training time: 0.133380s

on_train_batch_end: 1615692205.434338s

49152/50000 [============================>.] - ETA: 0s - loss: 2.1517 - accuracy: 0.1008
on_train_batch_begin: 1615692205.434629s

48 step training time: 0.134974s

on_train_batch_end: 1615692205.554981s

on_test_batch_begin: 1615692205.573213s

49 step training time: 0.138584s

on_epoch_end: 1615692205.882395s

Validation time: 0.309170s

Real time: 1615692205.882395s

Epoch time: 6.92226505279541s

50000/50000 [==============================] - 7s 138us/sample - loss: 2.1479 - accuracy: 0.1008 - val_loss: 6.9298 - val_accuracy: 0.1000

on_epoch_begin: 1615692205.882574s

Real time: 1615692205.8825786
Epoch 3/5

on_train_batch_begin: 1615692205.887062s

on_train_batch_end: 1615692206.023132s

 1024/50000 [..............................] - ETA: 6s - loss: 1.8433 - accuracy: 0.1019
on_train_batch_begin: 1615692206.023424s

1 step training time: 0.136362s

on_train_batch_end: 1615692206.159284s

 2048/50000 [>.............................] - ETA: 6s - loss: 1.7686 - accuracy: 0.1017
on_train_batch_begin: 1615692206.159562s

2 step training time: 0.136137s

on_train_batch_end: 1615692206.292262s

 3072/50000 [>.............................] - ETA: 6s - loss: 1.7822 - accuracy: 0.1013
on_train_batch_begin: 1615692206.292539s

3 step training time: 0.132978s

on_train_batch_end: 1615692206.427271s

 4096/50000 [=>............................] - ETA: 6s - loss: 1.7405 - accuracy: 0.1011
on_train_batch_begin: 1615692206.427553s

4 step training time: 0.135013s

on_train_batch_end: 1615692206.560297s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.7164 - accuracy: 0.1012
on_train_batch_begin: 1615692206.560579s

5 step training time: 0.133026s

on_train_batch_end: 1615692206.695362s

 6144/50000 [==>...........................] - ETA: 5s - loss: 1.7000 - accuracy: 0.1011
on_train_batch_begin: 1615692206.695644s

6 step training time: 0.135065s

on_train_batch_end: 1615692206.828629s

 7168/50000 [===>..........................] - ETA: 5s - loss: 1.7199 - accuracy: 0.1010
on_train_batch_begin: 1615692206.828913s

7 step training time: 0.133270s

on_train_batch_end: 1615692206.962463s

 8192/50000 [===>..........................] - ETA: 5s - loss: 1.7028 - accuracy: 0.1009
on_train_batch_begin: 1615692206.962751s

8 step training time: 0.133837s

on_train_batch_end: 1615692207.098151s

 9216/50000 [====>.........................] - ETA: 5s - loss: 1.7282 - accuracy: 0.1010
on_train_batch_begin: 1615692207.098436s

9 step training time: 0.135685s

on_train_batch_end: 1615692207.232155s

10240/50000 [=====>........................] - ETA: 5s - loss: 1.7242 - accuracy: 0.1010
on_train_batch_begin: 1615692207.232439s

10 step training time: 0.134004s

on_train_batch_end: 1615692207.366553s

11264/50000 [=====>........................] - ETA: 5s - loss: 1.7164 - accuracy: 0.1010
on_train_batch_begin: 1615692207.366839s

11 step training time: 0.134399s

on_train_batch_end: 1615692207.503379s

12288/50000 [======>.......................] - ETA: 4s - loss: 1.7042 - accuracy: 0.1010
on_train_batch_begin: 1615692207.503700s

12 step training time: 0.136861s

on_train_batch_end: 1615692207.636912s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.7040 - accuracy: 0.1010
on_train_batch_begin: 1615692207.637203s

13 step training time: 0.133503s

on_train_batch_end: 1615692207.773057s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.6970 - accuracy: 0.1010
on_train_batch_begin: 1615692207.773377s

14 step training time: 0.136175s

on_train_batch_end: 1615692207.907326s

15360/50000 [========>.....................] - ETA: 4s - loss: 1.6887 - accuracy: 0.1010
on_train_batch_begin: 1615692207.907615s

15 step training time: 0.134238s

on_train_batch_end: 1615692208.041991s

16384/50000 [========>.....................] - ETA: 4s - loss: 1.6839 - accuracy: 0.1010
on_train_batch_begin: 1615692208.042280s

16 step training time: 0.134665s

on_train_batch_end: 1615692208.178950s

17408/50000 [=========>....................] - ETA: 4s - loss: 1.6697 - accuracy: 0.1010
on_train_batch_begin: 1615692208.179237s

17 step training time: 0.136956s

on_train_batch_end: 1615692208.313551s

18432/50000 [==========>...................] - ETA: 4s - loss: 1.6663 - accuracy: 0.1010
on_train_batch_begin: 1615692208.313844s

18 step training time: 0.134608s

on_train_batch_end: 1615692208.446496s

19456/50000 [==========>...................] - ETA: 4s - loss: 1.6529 - accuracy: 0.1010
on_train_batch_begin: 1615692208.446782s

19 step training time: 0.132937s

on_train_batch_end: 1615692208.583180s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.6431 - accuracy: 0.1010
on_train_batch_begin: 1615692208.583494s

20 step training time: 0.136712s

on_train_batch_end: 1615692208.718274s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.6338 - accuracy: 0.1010
on_train_batch_begin: 1615692208.718561s

21 step training time: 0.135067s

on_train_batch_end: 1615692208.851483s

22528/50000 [============>.................] - ETA: 3s - loss: 1.6317 - accuracy: 0.1010
on_train_batch_begin: 1615692208.851775s

22 step training time: 0.133214s

on_train_batch_end: 1615692208.988256s

23552/50000 [=============>................] - ETA: 3s - loss: 1.6252 - accuracy: 0.1010
on_train_batch_begin: 1615692208.988543s

23 step training time: 0.136769s

on_train_batch_end: 1615692209.121935s

24576/50000 [=============>................] - ETA: 3s - loss: 1.6189 - accuracy: 0.1010
on_train_batch_begin: 1615692209.122220s

24 step training time: 0.133677s

on_train_batch_end: 1615692209.255465s

25600/50000 [==============>...............] - ETA: 3s - loss: 1.6045 - accuracy: 0.1010
on_train_batch_begin: 1615692209.255748s

25 step training time: 0.133528s

on_train_batch_end: 1615692209.393376s

26624/50000 [==============>...............] - ETA: 3s - loss: 1.5994 - accuracy: 0.1010
on_train_batch_begin: 1615692209.393697s

26 step training time: 0.137949s

on_train_batch_end: 1615692209.527369s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.5940 - accuracy: 0.1010
on_train_batch_begin: 1615692209.527668s

27 step training time: 0.133970s

on_train_batch_end: 1615692209.661052s

28672/50000 [================>.............] - ETA: 2s - loss: 1.5865 - accuracy: 0.1010
on_train_batch_begin: 1615692209.661386s

28 step training time: 0.133718s

on_train_batch_end: 1615692209.799068s

29696/50000 [================>.............] - ETA: 2s - loss: 1.5794 - accuracy: 0.1009
on_train_batch_begin: 1615692209.799363s

29 step training time: 0.137977s

on_train_batch_end: 1615692209.932891s

30720/50000 [=================>............] - ETA: 2s - loss: 1.5768 - accuracy: 0.1009
on_train_batch_begin: 1615692209.933174s

30 step training time: 0.133811s

on_train_batch_end: 1615692210.066487s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.5725 - accuracy: 0.1009
on_train_batch_begin: 1615692210.066773s

31 step training time: 0.133598s

on_train_batch_end: 1615692210.202329s

32768/50000 [==================>...........] - ETA: 2s - loss: 1.5654 - accuracy: 0.1009
on_train_batch_begin: 1615692210.202606s

32 step training time: 0.135833s

on_train_batch_end: 1615692210.336423s

33792/50000 [===================>..........] - ETA: 2s - loss: 1.5595 - accuracy: 0.1009
on_train_batch_begin: 1615692210.336703s

33 step training time: 0.134098s

on_train_batch_end: 1615692210.471674s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.5526 - accuracy: 0.1009
on_train_batch_begin: 1615692210.471958s

34 step training time: 0.135255s

on_train_batch_end: 1615692210.608691s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.5452 - accuracy: 0.1009
on_train_batch_begin: 1615692210.608989s

35 step training time: 0.137030s

on_train_batch_end: 1615692210.742239s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.5404 - accuracy: 0.1009
on_train_batch_begin: 1615692210.742536s

36 step training time: 0.133547s

on_train_batch_end: 1615692210.877443s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.5354 - accuracy: 0.1009
on_train_batch_begin: 1615692210.877739s

37 step training time: 0.135203s

on_train_batch_end: 1615692211.013912s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.5298 - accuracy: 0.1010
on_train_batch_begin: 1615692211.014208s

38 step training time: 0.136469s

on_train_batch_end: 1615692211.147646s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.5235 - accuracy: 0.1010
on_train_batch_begin: 1615692211.147938s

39 step training time: 0.133731s

on_train_batch_end: 1615692211.288699s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.5150 - accuracy: 0.1010
on_train_batch_begin: 1615692211.288999s

40 step training time: 0.141061s

on_train_batch_end: 1615692211.424164s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.5077 - accuracy: 0.1010
on_train_batch_begin: 1615692211.424459s

41 step training time: 0.135460s

on_train_batch_end: 1615692211.557712s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.5039 - accuracy: 0.1010
on_train_batch_begin: 1615692211.558010s

42 step training time: 0.133552s

on_train_batch_end: 1615692211.691716s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.4995 - accuracy: 0.1010
on_train_batch_begin: 1615692211.692011s

43 step training time: 0.134000s

on_train_batch_end: 1615692211.828337s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.4919 - accuracy: 0.1010
on_train_batch_begin: 1615692211.828629s

44 step training time: 0.136618s

on_train_batch_end: 1615692211.962222s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.4858 - accuracy: 0.1010
on_train_batch_begin: 1615692211.962516s

45 step training time: 0.133887s

on_train_batch_end: 1615692212.094378s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.4829 - accuracy: 0.1010
on_train_batch_begin: 1615692212.094690s

46 step training time: 0.132174s

on_train_batch_end: 1615692212.227350s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.4773 - accuracy: 0.1010
on_train_batch_begin: 1615692212.227643s

47 step training time: 0.132953s

on_train_batch_end: 1615692212.363276s

49152/50000 [============================>.] - ETA: 0s - loss: 1.4779 - accuracy: 0.1010
on_train_batch_begin: 1615692212.363604s

48 step training time: 0.135961s

on_train_batch_end: 1615692212.486052s

on_test_batch_begin: 1615692212.506909s

49 step training time: 0.143305s

on_epoch_end: 1615692212.818419s

Validation time: 0.311498s

Real time: 1615692212.818419s

Epoch time: 6.9358556270599365s

50000/50000 [==============================] - 7s 139us/sample - loss: 1.4779 - accuracy: 0.1010 - val_loss: 6.9787 - val_accuracy: 0.0999

on_epoch_begin: 1615692212.818600s

Real time: 1615692212.8186064
Epoch 4/5

on_train_batch_begin: 1615692212.822949s

on_train_batch_end: 1615692212.956546s

 1024/50000 [..............................] - ETA: 6s - loss: 1.0908 - accuracy: 0.1011
on_train_batch_begin: 1615692212.956834s

1 step training time: 0.133885s

on_train_batch_end: 1615692213.090378s

 2048/50000 [>.............................] - ETA: 6s - loss: 1.0700 - accuracy: 0.1012
on_train_batch_begin: 1615692213.090667s

2 step training time: 0.133832s

on_train_batch_end: 1615692213.224087s

 3072/50000 [>.............................] - ETA: 6s - loss: 1.0628 - accuracy: 0.1010
on_train_batch_begin: 1615692213.224382s

3 step training time: 0.133715s

on_train_batch_end: 1615692213.358041s

 4096/50000 [=>............................] - ETA: 6s - loss: 1.0621 - accuracy: 0.1011
on_train_batch_begin: 1615692213.358332s

4 step training time: 0.133950s

on_train_batch_end: 1615692213.493692s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.0923 - accuracy: 0.1010
on_train_batch_begin: 1615692213.493991s

5 step training time: 0.135659s

on_train_batch_end: 1615692213.628465s

 6144/50000 [==>...........................] - ETA: 5s - loss: 1.1015 - accuracy: 0.1010
on_train_batch_begin: 1615692213.628752s

6 step training time: 0.134761s

on_train_batch_end: 1615692213.764546s

 7168/50000 [===>..........................] - ETA: 5s - loss: 1.0836 - accuracy: 0.1010
on_train_batch_begin: 1615692213.764864s

7 step training time: 0.136112s

on_train_batch_end: 1615692213.900931s

 8192/50000 [===>..........................] - ETA: 5s - loss: 1.0912 - accuracy: 0.1010
on_train_batch_begin: 1615692213.901219s

8 step training time: 0.136355s

on_train_batch_end: 1615692214.034554s

 9216/50000 [====>.........................] - ETA: 5s - loss: 1.0980 - accuracy: 0.1010
on_train_batch_begin: 1615692214.034868s

9 step training time: 0.133650s

on_train_batch_end: 1615692214.170115s

10240/50000 [=====>........................] - ETA: 5s - loss: 1.0909 - accuracy: 0.1011
on_train_batch_begin: 1615692214.170403s

10 step training time: 0.135535s

on_train_batch_end: 1615692214.305538s

11264/50000 [=====>........................] - ETA: 5s - loss: 1.0887 - accuracy: 0.1011
on_train_batch_begin: 1615692214.305829s

11 step training time: 0.135426s

on_train_batch_end: 1615692214.439067s

12288/50000 [======>.......................] - ETA: 4s - loss: 1.0992 - accuracy: 0.1011
on_train_batch_begin: 1615692214.439354s

12 step training time: 0.133525s

on_train_batch_end: 1615692214.576700s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.0975 - accuracy: 0.1011
on_train_batch_begin: 1615692214.576986s

13 step training time: 0.137632s

on_train_batch_end: 1615692214.713768s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.1068 - accuracy: 0.1012
on_train_batch_begin: 1615692214.714062s

14 step training time: 0.137076s

on_train_batch_end: 1615692214.847411s

15360/50000 [========>.....................] - ETA: 4s - loss: 1.0972 - accuracy: 0.1012
on_train_batch_begin: 1615692214.847703s

15 step training time: 0.133641s

on_train_batch_end: 1615692214.984341s

16384/50000 [========>.....................] - ETA: 4s - loss: 1.0967 - accuracy: 0.1012
on_train_batch_begin: 1615692214.984641s

16 step training time: 0.136938s

on_train_batch_end: 1615692215.120896s

17408/50000 [=========>....................] - ETA: 4s - loss: 1.0926 - accuracy: 0.1011
on_train_batch_begin: 1615692215.121184s

17 step training time: 0.136544s

on_train_batch_end: 1615692215.256173s

18432/50000 [==========>...................] - ETA: 4s - loss: 1.0931 - accuracy: 0.1011
on_train_batch_begin: 1615692215.256460s

18 step training time: 0.135276s

on_train_batch_end: 1615692215.391054s

19456/50000 [==========>...................] - ETA: 4s - loss: 1.0872 - accuracy: 0.1011
on_train_batch_begin: 1615692215.391348s

19 step training time: 0.134887s

on_train_batch_end: 1615692215.529190s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.0882 - accuracy: 0.1011
on_train_batch_begin: 1615692215.529511s

20 step training time: 0.138163s

on_train_batch_end: 1615692215.664206s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.0837 - accuracy: 0.1012
on_train_batch_begin: 1615692215.664501s

21 step training time: 0.134990s

on_train_batch_end: 1615692215.798839s

22528/50000 [============>.................] - ETA: 3s - loss: 1.0850 - accuracy: 0.1011
on_train_batch_begin: 1615692215.799132s

22 step training time: 0.134631s

on_train_batch_end: 1615692215.934581s

23552/50000 [=============>................] - ETA: 3s - loss: 1.0879 - accuracy: 0.1012
on_train_batch_begin: 1615692215.934895s

23 step training time: 0.135763s

on_train_batch_end: 1615692216.068565s

24576/50000 [=============>................] - ETA: 3s - loss: 1.0838 - accuracy: 0.1012
on_train_batch_begin: 1615692216.068856s

24 step training time: 0.133961s

on_train_batch_end: 1615692216.201619s

25600/50000 [==============>...............] - ETA: 3s - loss: 1.0838 - accuracy: 0.1012
on_train_batch_begin: 1615692216.201907s

25 step training time: 0.133051s

on_train_batch_end: 1615692216.339234s

26624/50000 [==============>...............] - ETA: 3s - loss: 1.0825 - accuracy: 0.1012
on_train_batch_begin: 1615692216.339527s

26 step training time: 0.137619s

on_train_batch_end: 1615692216.473713s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.0827 - accuracy: 0.1012
on_train_batch_begin: 1615692216.474010s

27 step training time: 0.134484s

on_train_batch_end: 1615692216.609030s

28672/50000 [================>.............] - ETA: 2s - loss: 1.0778 - accuracy: 0.1012
on_train_batch_begin: 1615692216.609344s

28 step training time: 0.135334s

on_train_batch_end: 1615692216.745476s

29696/50000 [================>.............] - ETA: 2s - loss: 1.0767 - accuracy: 0.1012
on_train_batch_begin: 1615692216.745769s

29 step training time: 0.136425s

on_train_batch_end: 1615692216.879182s

30720/50000 [=================>............] - ETA: 2s - loss: 1.0719 - accuracy: 0.1012
on_train_batch_begin: 1615692216.879462s

30 step training time: 0.133693s

on_train_batch_end: 1615692217.013351s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.0720 - accuracy: 0.1013
on_train_batch_begin: 1615692217.013679s

31 step training time: 0.134216s

on_train_batch_end: 1615692217.151346s

32768/50000 [==================>...........] - ETA: 2s - loss: 1.0704 - accuracy: 0.1013
on_train_batch_begin: 1615692217.151638s

32 step training time: 0.137959s

on_train_batch_end: 1615692217.286448s

33792/50000 [===================>..........] - ETA: 2s - loss: 1.0671 - accuracy: 0.1012
on_train_batch_begin: 1615692217.286741s

33 step training time: 0.135103s

on_train_batch_end: 1615692217.419923s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.0686 - accuracy: 0.1013
on_train_batch_begin: 1615692217.420213s

34 step training time: 0.133472s

on_train_batch_end: 1615692217.556925s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.0646 - accuracy: 0.1013
on_train_batch_begin: 1615692217.557222s

35 step training time: 0.137009s

on_train_batch_end: 1615692217.694104s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.0628 - accuracy: 0.1013
on_train_batch_begin: 1615692217.694398s

36 step training time: 0.137176s

on_train_batch_end: 1615692217.828416s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.0589 - accuracy: 0.1013
on_train_batch_begin: 1615692217.828704s

37 step training time: 0.134306s

on_train_batch_end: 1615692217.964016s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.0572 - accuracy: 0.1012
on_train_batch_begin: 1615692217.964309s

38 step training time: 0.135605s

on_train_batch_end: 1615692218.099571s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.0559 - accuracy: 0.1013
on_train_batch_begin: 1615692218.099860s

39 step training time: 0.135550s

on_train_batch_end: 1615692218.234403s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.0539 - accuracy: 0.1013
on_train_batch_begin: 1615692218.234720s

40 step training time: 0.134860s

on_train_batch_end: 1615692218.372813s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.0515 - accuracy: 0.1013
on_train_batch_begin: 1615692218.373101s

41 step training time: 0.138382s

on_train_batch_end: 1615692218.509350s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.0500 - accuracy: 0.1013
on_train_batch_begin: 1615692218.509641s

42 step training time: 0.136540s

on_train_batch_end: 1615692218.643442s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.0498 - accuracy: 0.1013
on_train_batch_begin: 1615692218.643772s

43 step training time: 0.134131s

on_train_batch_end: 1615692218.778146s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.0470 - accuracy: 0.1013
on_train_batch_begin: 1615692218.778444s

44 step training time: 0.134672s

on_train_batch_end: 1615692218.915354s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.0448 - accuracy: 0.1013
on_train_batch_begin: 1615692218.915665s

45 step training time: 0.137221s

on_train_batch_end: 1615692219.049522s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.0441 - accuracy: 0.1013
on_train_batch_begin: 1615692219.049818s

46 step training time: 0.134153s

on_train_batch_end: 1615692219.183623s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.0430 - accuracy: 0.1013
on_train_batch_begin: 1615692219.183918s

47 step training time: 0.134100s

on_train_batch_end: 1615692219.320146s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0428 - accuracy: 0.1013
on_train_batch_begin: 1615692219.320437s

48 step training time: 0.136520s

on_train_batch_end: 1615692219.441446s

on_test_batch_begin: 1615692219.462632s

49 step training time: 0.142195s

on_epoch_end: 1615692219.783227s

Validation time: 0.320582s

Real time: 1615692219.783227s

Epoch time: 6.9646360874176025s

50000/50000 [==============================] - 7s 139us/sample - loss: 1.0411 - accuracy: 0.1013 - val_loss: 6.8757 - val_accuracy: 0.1000

on_epoch_begin: 1615692219.783408s

Real time: 1615692219.7834144
Epoch 5/5

on_train_batch_begin: 1615692219.787824s

on_train_batch_end: 1615692219.923942s

 1024/50000 [..............................] - ETA: 6s - loss: 0.7254 - accuracy: 0.1010
on_train_batch_begin: 1615692219.924219s

1 step training time: 0.136394s

on_train_batch_end: 1615692220.057174s

 2048/50000 [>.............................] - ETA: 6s - loss: 0.6948 - accuracy: 0.1014
on_train_batch_begin: 1615692220.057476s

2 step training time: 0.133258s

on_train_batch_end: 1615692220.194322s

 3072/50000 [>.............................] - ETA: 6s - loss: 0.7282 - accuracy: 0.1012
on_train_batch_begin: 1615692220.194613s

3 step training time: 0.137137s

on_train_batch_end: 1615692220.328519s

 4096/50000 [=>............................] - ETA: 6s - loss: 0.7182 - accuracy: 0.1013
on_train_batch_begin: 1615692220.328803s

4 step training time: 0.134190s

on_train_batch_end: 1615692220.461844s

 5120/50000 [==>...........................] - ETA: 5s - loss: 0.7220 - accuracy: 0.1013
on_train_batch_begin: 1615692220.462134s

5 step training time: 0.133331s

on_train_batch_end: 1615692220.597347s

 6144/50000 [==>...........................] - ETA: 5s - loss: 0.7277 - accuracy: 0.1014
on_train_batch_begin: 1615692220.597636s

6 step training time: 0.135502s

on_train_batch_end: 1615692220.730525s

 7168/50000 [===>..........................] - ETA: 5s - loss: 0.7313 - accuracy: 0.1014
on_train_batch_begin: 1615692220.730814s

7 step training time: 0.133178s

on_train_batch_end: 1615692220.867125s

 8192/50000 [===>..........................] - ETA: 5s - loss: 0.7385 - accuracy: 0.1014
on_train_batch_begin: 1615692220.867412s

8 step training time: 0.136598s

on_train_batch_end: 1615692221.002510s

 9216/50000 [====>.........................] - ETA: 5s - loss: 0.7433 - accuracy: 0.1013
on_train_batch_begin: 1615692221.002812s

9 step training time: 0.135400s

on_train_batch_end: 1615692221.136545s

10240/50000 [=====>........................] - ETA: 5s - loss: 0.7380 - accuracy: 0.1014
on_train_batch_begin: 1615692221.136841s

10 step training time: 0.134029s

on_train_batch_end: 1615692221.272877s

11264/50000 [=====>........................] - ETA: 5s - loss: 0.7356 - accuracy: 0.1014
on_train_batch_begin: 1615692221.273172s

11 step training time: 0.136331s

on_train_batch_end: 1615692221.408105s

12288/50000 [======>.......................] - ETA: 4s - loss: 0.7354 - accuracy: 0.1014
on_train_batch_begin: 1615692221.408400s

12 step training time: 0.135228s

on_train_batch_end: 1615692221.542177s

13312/50000 [======>.......................] - ETA: 4s - loss: 0.7379 - accuracy: 0.1014
on_train_batch_begin: 1615692221.542471s

13 step training time: 0.134071s

on_train_batch_end: 1615692221.679178s

14336/50000 [=======>......................] - ETA: 4s - loss: 0.7380 - accuracy: 0.1014
on_train_batch_begin: 1615692221.679465s

14 step training time: 0.136994s

on_train_batch_end: 1615692221.813737s

15360/50000 [========>.....................] - ETA: 4s - loss: 0.7397 - accuracy: 0.1015
on_train_batch_begin: 1615692221.814034s

15 step training time: 0.134569s

on_train_batch_end: 1615692221.947536s

16384/50000 [========>.....................] - ETA: 4s - loss: 0.7337 - accuracy: 0.1014
on_train_batch_begin: 1615692221.947831s

16 step training time: 0.133797s

on_train_batch_end: 1615692222.083402s

17408/50000 [=========>....................] - ETA: 4s - loss: 0.7364 - accuracy: 0.1014
on_train_batch_begin: 1615692222.083730s

17 step training time: 0.135899s

on_train_batch_end: 1615692222.217891s

18432/50000 [==========>...................] - ETA: 4s - loss: 0.7351 - accuracy: 0.1014
on_train_batch_begin: 1615692222.218185s

18 step training time: 0.134455s

on_train_batch_end: 1615692222.351566s

19456/50000 [==========>...................] - ETA: 4s - loss: 0.7399 - accuracy: 0.1014
on_train_batch_begin: 1615692222.351856s

19 step training time: 0.133671s

on_train_batch_end: 1615692222.489347s

20480/50000 [===========>..................] - ETA: 3s - loss: 0.7395 - accuracy: 0.1014
on_train_batch_begin: 1615692222.489643s

20 step training time: 0.137787s

on_train_batch_end: 1615692222.628933s

21504/50000 [===========>..................] - ETA: 3s - loss: 0.7439 - accuracy: 0.1014
on_train_batch_begin: 1615692222.629224s

21 step training time: 0.139581s

on_train_batch_end: 1615692222.764010s

22528/50000 [============>.................] - ETA: 3s - loss: 0.7409 - accuracy: 0.1014
on_train_batch_begin: 1615692222.764302s

22 step training time: 0.135078s

on_train_batch_end: 1615692222.898566s

23552/50000 [=============>................] - ETA: 3s - loss: 0.7393 - accuracy: 0.1014
on_train_batch_begin: 1615692222.898859s

23 step training time: 0.134557s

on_train_batch_end: 1615692223.035858s

24576/50000 [=============>................] - ETA: 3s - loss: 0.7350 - accuracy: 0.1015
on_train_batch_begin: 1615692223.036151s

24 step training time: 0.137292s

on_train_batch_end: 1615692223.171170s

25600/50000 [==============>...............] - ETA: 3s - loss: 0.7379 - accuracy: 0.1015
on_train_batch_begin: 1615692223.171466s

25 step training time: 0.135315s

on_train_batch_end: 1615692223.304216s

26624/50000 [==============>...............] - ETA: 3s - loss: 0.7329 - accuracy: 0.1015
on_train_batch_begin: 1615692223.304508s

26 step training time: 0.133043s

on_train_batch_end: 1615692223.441225s

27648/50000 [===============>..............] - ETA: 2s - loss: 0.7303 - accuracy: 0.1015
on_train_batch_begin: 1615692223.441545s

27 step training time: 0.137037s

on_train_batch_end: 1615692223.576238s

28672/50000 [================>.............] - ETA: 2s - loss: 0.7312 - accuracy: 0.1015
on_train_batch_begin: 1615692223.576528s

28 step training time: 0.134983s

on_train_batch_end: 1615692223.710294s

29696/50000 [================>.............] - ETA: 2s - loss: 0.7288 - accuracy: 0.1015
on_train_batch_begin: 1615692223.710580s

29 step training time: 0.134052s

on_train_batch_end: 1615692223.845441s

30720/50000 [=================>............] - ETA: 2s - loss: 0.7257 - accuracy: 0.1015
on_train_batch_begin: 1615692223.845734s

30 step training time: 0.135154s

on_train_batch_end: 1615692223.980310s

31744/50000 [==================>...........] - ETA: 2s - loss: 0.7230 - accuracy: 0.1015
on_train_batch_begin: 1615692223.980602s

31 step training time: 0.134868s

on_train_batch_end: 1615692224.115465s

32768/50000 [==================>...........] - ETA: 2s - loss: 0.7229 - accuracy: 0.1015
on_train_batch_begin: 1615692224.115771s

32 step training time: 0.135169s

on_train_batch_end: 1615692224.250628s

33792/50000 [===================>..........] - ETA: 2s - loss: 0.7212 - accuracy: 0.1015
on_train_batch_begin: 1615692224.250921s

33 step training time: 0.135150s

on_train_batch_end: 1615692224.384674s

34816/50000 [===================>..........] - ETA: 2s - loss: 0.7206 - accuracy: 0.1015
on_train_batch_begin: 1615692224.384995s

34 step training time: 0.134074s

on_train_batch_end: 1615692224.522333s

35840/50000 [====================>.........] - ETA: 1s - loss: 0.7230 - accuracy: 0.1015
on_train_batch_begin: 1615692224.522624s

35 step training time: 0.137629s

on_train_batch_end: 1615692224.658053s

36864/50000 [=====================>........] - ETA: 1s - loss: 0.7235 - accuracy: 0.1015
on_train_batch_begin: 1615692224.658349s

36 step training time: 0.135725s

on_train_batch_end: 1615692224.792362s

37888/50000 [=====================>........] - ETA: 1s - loss: 0.7223 - accuracy: 0.1015
on_train_batch_begin: 1615692224.792655s

37 step training time: 0.134306s

on_train_batch_end: 1615692224.928401s

38912/50000 [======================>.......] - ETA: 1s - loss: 0.7217 - accuracy: 0.1015
on_train_batch_begin: 1615692224.928699s

38 step training time: 0.136045s

on_train_batch_end: 1615692225.063278s

39936/50000 [======================>.......] - ETA: 1s - loss: 0.7217 - accuracy: 0.1015
on_train_batch_begin: 1615692225.063596s

39 step training time: 0.134896s

on_train_batch_end: 1615692225.198015s

40960/50000 [=======================>......] - ETA: 1s - loss: 0.7215 - accuracy: 0.1015
on_train_batch_begin: 1615692225.198304s

40 step training time: 0.134709s

on_train_batch_end: 1615692225.333448s

41984/50000 [========================>.....] - ETA: 1s - loss: 0.7219 - accuracy: 0.1015
on_train_batch_begin: 1615692225.333772s

41 step training time: 0.135468s

on_train_batch_end: 1615692225.467362s

43008/50000 [========================>.....] - ETA: 0s - loss: 0.7230 - accuracy: 0.1015
on_train_batch_begin: 1615692225.467651s

42 step training time: 0.133879s

on_train_batch_end: 1615692225.601857s

44032/50000 [=========================>....] - ETA: 0s - loss: 0.7213 - accuracy: 0.1015
on_train_batch_begin: 1615692225.602147s

43 step training time: 0.134496s

on_train_batch_end: 1615692225.739041s

45056/50000 [==========================>...] - ETA: 0s - loss: 0.7228 - accuracy: 0.1015
on_train_batch_begin: 1615692225.739327s

44 step training time: 0.137180s

on_train_batch_end: 1615692225.876992s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.7226 - accuracy: 0.1015
on_train_batch_begin: 1615692225.877310s

45 step training time: 0.137983s

on_train_batch_end: 1615692226.011998s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.7218 - accuracy: 0.1015
on_train_batch_begin: 1615692226.012290s

46 step training time: 0.134980s

on_train_batch_end: 1615692226.147400s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.7225 - accuracy: 0.1015
on_train_batch_begin: 1615692226.147694s

47 step training time: 0.135404s

on_train_batch_end: 1615692226.281977s

49152/50000 [============================>.] - ETA: 0s - loss: 0.7197 - accuracy: 0.1015
on_train_batch_begin: 1615692226.282266s

48 step training time: 0.134572s

on_train_batch_end: 1615692226.404451s

on_test_batch_begin: 1615692226.423617s

49 step training time: 0.141351s

on_epoch_end: 1615692226.735672s

Validation time: 0.312044s

Real time: 1615692226.735672s

Epoch time: 6.952271461486816s

50000/50000 [==============================] - 7s 139us/sample - loss: 0.7190 - accuracy: 0.1015 - val_loss: 5.5805 - val_accuracy: 0.1001
Tempo do fit: 94.80390954017639