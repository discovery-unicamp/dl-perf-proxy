wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:44
   204800/170498071 [..............................] - ETA: 1:17
  1187840/170498071 [..............................] - ETA: 20s 
  3825664/170498071 [..............................] - ETA: 8s 
  7168000/170498071 [>.............................] - ETA: 5s
 10493952/170498071 [>.............................] - ETA: 4s
 13688832/170498071 [=>............................] - ETA: 3s
 16670720/170498071 [=>............................] - ETA: 3s
 19537920/170498071 [==>...........................] - ETA: 3s
 22306816/170498071 [==>...........................] - ETA: 3s
 24993792/170498071 [===>..........................] - ETA: 3s
 27795456/170498071 [===>..........................] - ETA: 3s
 30531584/170498071 [====>.........................] - ETA: 2s
 33136640/170498071 [====>.........................] - ETA: 2s
 35807232/170498071 [=====>........................] - ETA: 2s
 38477824/170498071 [=====>........................] - ETA: 2s
 41213952/170498071 [======>.......................] - ETA: 2s
 43999232/170498071 [======>.......................] - ETA: 2s
 46637056/170498071 [=======>......................] - ETA: 2s
 49307648/170498071 [=======>......................] - ETA: 2s
 51929088/170498071 [========>.....................] - ETA: 2s
 54009856/170498071 [========>.....................] - ETA: 2s
 57221120/170498071 [=========>....................] - ETA: 2s
 59891712/170498071 [=========>....................] - ETA: 2s
 62504960/170498071 [=========>....................] - ETA: 2s
 65069056/170498071 [==========>...................] - ETA: 2s
 67690496/170498071 [==========>...................] - ETA: 2s
 70328320/170498071 [===========>..................] - ETA: 1s
 73146368/170498071 [===========>..................] - ETA: 1s
 75849728/170498071 [============>.................] - ETA: 1s
 78487552/170498071 [============>.................] - ETA: 1s
 81174528/170498071 [=============>................] - ETA: 1s
 83828736/170498071 [=============>................] - ETA: 1s
 86564864/170498071 [==============>...............] - ETA: 1s
 89300992/170498071 [==============>...............] - ETA: 1s
 92037120/170498071 [===============>..............] - ETA: 1s
 94691328/170498071 [===============>..............] - ETA: 1s
 97361920/170498071 [================>.............] - ETA: 1s
 99999744/170498071 [================>.............] - ETA: 1s
102801408/170498071 [=================>............] - ETA: 1s
105570304/170498071 [=================>............] - ETA: 1s
108240896/170498071 [==================>...........] - ETA: 1s
110895104/170498071 [==================>...........] - ETA: 1s
113565696/170498071 [==================>...........] - ETA: 1s
116367360/170498071 [===================>..........] - ETA: 1s
119119872/170498071 [===================>..........] - ETA: 0s
121839616/170498071 [====================>.........] - ETA: 0s
124493824/170498071 [====================>.........] - ETA: 0s
127164416/170498071 [=====================>........] - ETA: 0s
129835008/170498071 [=====================>........] - ETA: 0s
132587520/170498071 [======================>.......] - ETA: 0s
135356416/170498071 [======================>.......] - ETA: 0s
137994240/170498071 [=======================>......] - ETA: 0s
140632064/170498071 [=======================>......] - ETA: 0s
143319040/170498071 [========================>.....] - ETA: 0s
146038784/170498071 [========================>.....] - ETA: 0s
148774912/170498071 [=========================>....] - ETA: 0s
151511040/170498071 [=========================>....] - ETA: 0s
154198016/170498071 [==========================>...] - ETA: 0s
156884992/170498071 [==========================>...] - ETA: 0s
159555584/170498071 [===========================>..] - ETA: 0s
162275328/170498071 [===========================>..] - ETA: 0s
164978688/170498071 [============================>.] - ETA: 0s
167714816/170498071 [============================>.] - ETA: 0s
170369024/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 3465216/94765736 [>.............................] - ETA: 2s
 8200192/94765736 [=>............................] - ETA: 2s
10567680/94765736 [==>...........................] - ETA: 2s
12926976/94765736 [===>..........................] - ETA: 2s
18841600/94765736 [====>.........................] - ETA: 1s
20021248/94765736 [=====>........................] - ETA: 2s
22388736/94765736 [======>.......................] - ETA: 1s
24748032/94765736 [======>.......................] - ETA: 1s
27115520/94765736 [=======>......................] - ETA: 2s
29409280/94765736 [========>.....................] - ETA: 1s
31776768/94765736 [=========>....................] - ETA: 1s
34127872/94765736 [=========>....................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
38936576/94765736 [===========>..................] - ETA: 1s
43122688/94765736 [============>.................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 1s
50683904/94765736 [===============>..............] - ETA: 1s
55410688/94765736 [================>.............] - ETA: 1s
59416576/94765736 [=================>............] - ETA: 1s
66322432/94765736 [===================>..........] - ETA: 0s
70713344/94765736 [=====================>........] - ETA: 0s
71892992/94765736 [=====================>........] - ETA: 0s
73596928/94765736 [======================>.......] - ETA: 0s
80199680/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
89513984/94765736 [===========================>..] - ETA: 0s
91709440/94765736 [============================>.] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 3s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.920982360839844
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615857881.331191s

Real time: 1615857881.3312078
Epoch 1/5

on_train_batch_begin: 1615857882.084756s

on_train_batch_end: 1615857899.189176s

 1024/50000 [..............................] - ETA: 14:14 - loss: 17.8192 - accuracy: 1.0014e-04
on_train_batch_begin: 1615857899.189802s

1 step training time: 17.105046s

on_train_batch_end: 1615857899.525038s

 2048/50000 [>.............................] - ETA: 7:05 - loss: 14.2161 - accuracy: 4.4394e-04 
on_train_batch_begin: 1615857899.525360s

2 step training time: 0.335558s

on_train_batch_end: 1615857899.857821s

 3072/50000 [>.............................] - ETA: 4:43 - loss: 12.3271 - accuracy: 6.4405e-04
on_train_batch_begin: 1615857899.858127s

3 step training time: 0.332768s

on_train_batch_end: 1615857900.198997s

 4096/50000 [=>............................] - ETA: 3:31 - loss: 11.3139 - accuracy: 0.0027    
on_train_batch_begin: 1615857900.199320s

4 step training time: 0.341192s

on_train_batch_end: 1615857900.532800s

 5120/50000 [==>...........................] - ETA: 2:48 - loss: 10.6459 - accuracy: 0.0040
on_train_batch_begin: 1615857900.533099s

5 step training time: 0.333780s

on_train_batch_end: 1615857900.868468s

 6144/50000 [==>...........................] - ETA: 2:19 - loss: 10.2200 - accuracy: 0.0062
on_train_batch_begin: 1615857900.868765s

6 step training time: 0.335665s

on_train_batch_end: 1615857901.205075s

 7168/50000 [===>..........................] - ETA: 1:58 - loss: 9.8861 - accuracy: 0.0104 
on_train_batch_begin: 1615857901.205379s

7 step training time: 0.336614s

on_train_batch_end: 1615857901.539077s

 8192/50000 [===>..........................] - ETA: 1:43 - loss: 9.6174 - accuracy: 0.0145
on_train_batch_begin: 1615857901.539383s

8 step training time: 0.334004s

on_train_batch_end: 1615857901.874744s

 9216/50000 [====>.........................] - ETA: 1:30 - loss: 9.4081 - accuracy: 0.0184
on_train_batch_begin: 1615857901.875048s

9 step training time: 0.335665s

on_train_batch_end: 1615857902.207870s

10240/50000 [=====>........................] - ETA: 1:21 - loss: 9.2583 - accuracy: 0.0226
on_train_batch_begin: 1615857902.208174s

10 step training time: 0.333125s

on_train_batch_end: 1615857902.546382s

11264/50000 [=====>........................] - ETA: 1:12 - loss: 9.1272 - accuracy: 0.0277
on_train_batch_begin: 1615857902.546683s

11 step training time: 0.338510s

on_train_batch_end: 1615857902.879995s

12288/50000 [======>.......................] - ETA: 1:06 - loss: 9.0239 - accuracy: 0.0320
on_train_batch_begin: 1615857902.880297s

12 step training time: 0.333614s

on_train_batch_end: 1615857903.216788s

13312/50000 [======>.......................] - ETA: 1:00 - loss: 8.9416 - accuracy: 0.0357
on_train_batch_begin: 1615857903.217094s

13 step training time: 0.336797s

on_train_batch_end: 1615857903.548734s

14336/50000 [=======>......................] - ETA: 55s - loss: 8.8631 - accuracy: 0.0405 
on_train_batch_begin: 1615857903.549037s

14 step training time: 0.331944s

on_train_batch_end: 1615857903.886097s

15360/50000 [========>.....................] - ETA: 50s - loss: 8.7847 - accuracy: 0.0439
on_train_batch_begin: 1615857903.886399s

15 step training time: 0.337362s

on_train_batch_end: 1615857904.220659s

16384/50000 [========>.....................] - ETA: 46s - loss: 8.7194 - accuracy: 0.0460
on_train_batch_begin: 1615857904.220974s

16 step training time: 0.334574s

on_train_batch_end: 1615857904.557101s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.6703 - accuracy: 0.0482
on_train_batch_begin: 1615857904.557407s

17 step training time: 0.336433s

on_train_batch_end: 1615857904.878266s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.6161 - accuracy: 0.0502
on_train_batch_begin: 1615857904.878585s

18 step training time: 0.321178s

on_train_batch_end: 1615857905.212232s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.5652 - accuracy: 0.0519
on_train_batch_begin: 1615857905.212538s

19 step training time: 0.333953s

on_train_batch_end: 1615857905.549930s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.5140 - accuracy: 0.0533
on_train_batch_begin: 1615857905.550239s

20 step training time: 0.337702s

on_train_batch_end: 1615857905.883592s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.4708 - accuracy: 0.0548
on_train_batch_begin: 1615857905.883894s

21 step training time: 0.333655s

on_train_batch_end: 1615857906.216384s

22528/50000 [============>.................] - ETA: 30s - loss: 8.4288 - accuracy: 0.0567
on_train_batch_begin: 1615857906.216679s

22 step training time: 0.332785s

on_train_batch_end: 1615857906.551461s

23552/50000 [=============>................] - ETA: 28s - loss: 8.3940 - accuracy: 0.0586
on_train_batch_begin: 1615857906.551764s

23 step training time: 0.335085s

on_train_batch_end: 1615857906.884807s

24576/50000 [=============>................] - ETA: 26s - loss: 8.3564 - accuracy: 0.0599
on_train_batch_begin: 1615857906.885104s

24 step training time: 0.333340s

on_train_batch_end: 1615857907.220925s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.3277 - accuracy: 0.0608
on_train_batch_begin: 1615857907.221236s

25 step training time: 0.336132s

on_train_batch_end: 1615857907.555110s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.2999 - accuracy: 0.0623
on_train_batch_begin: 1615857907.555415s

26 step training time: 0.334179s

on_train_batch_end: 1615857907.892992s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.2685 - accuracy: 0.0631
on_train_batch_begin: 1615857907.893288s

27 step training time: 0.337873s

on_train_batch_end: 1615857908.234206s

28672/50000 [================>.............] - ETA: 20s - loss: 8.2424 - accuracy: 0.0640
on_train_batch_begin: 1615857908.234511s

28 step training time: 0.341223s

on_train_batch_end: 1615857908.569072s

29696/50000 [================>.............] - ETA: 18s - loss: 8.2208 - accuracy: 0.0650
on_train_batch_begin: 1615857908.569373s

29 step training time: 0.334862s

on_train_batch_end: 1615857908.908569s

30720/50000 [=================>............] - ETA: 17s - loss: 8.1932 - accuracy: 0.0656
on_train_batch_begin: 1615857908.908877s

30 step training time: 0.339505s

on_train_batch_end: 1615857909.249971s

31744/50000 [==================>...........] - ETA: 16s - loss: 8.1688 - accuracy: 0.0663
on_train_batch_begin: 1615857909.250270s

31 step training time: 0.341393s

on_train_batch_end: 1615857909.583879s

32768/50000 [==================>...........] - ETA: 14s - loss: 8.1402 - accuracy: 0.0670
on_train_batch_begin: 1615857909.584180s

32 step training time: 0.333910s

on_train_batch_end: 1615857909.923274s

33792/50000 [===================>..........] - ETA: 13s - loss: 8.1174 - accuracy: 0.0678
on_train_batch_begin: 1615857909.923572s

33 step training time: 0.339392s

on_train_batch_end: 1615857910.264794s

34816/50000 [===================>..........] - ETA: 12s - loss: 8.0935 - accuracy: 0.0684
on_train_batch_begin: 1615857910.265099s

34 step training time: 0.341527s

on_train_batch_end: 1615857910.598763s

35840/50000 [====================>.........] - ETA: 11s - loss: 8.0695 - accuracy: 0.0689
on_train_batch_begin: 1615857910.599063s

35 step training time: 0.333964s

on_train_batch_end: 1615857910.937904s

36864/50000 [=====================>........] - ETA: 10s - loss: 8.0484 - accuracy: 0.0694
on_train_batch_begin: 1615857910.938202s

36 step training time: 0.339139s

on_train_batch_end: 1615857911.275218s

37888/50000 [=====================>........] - ETA: 9s - loss: 8.0252 - accuracy: 0.0702 
on_train_batch_begin: 1615857911.275514s

37 step training time: 0.337312s

on_train_batch_end: 1615857911.611511s

38912/50000 [======================>.......] - ETA: 8s - loss: 8.0036 - accuracy: 0.0709
on_train_batch_begin: 1615857911.611808s

38 step training time: 0.336294s

on_train_batch_end: 1615857911.951197s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.9826 - accuracy: 0.0715
on_train_batch_begin: 1615857911.951496s

39 step training time: 0.339689s

on_train_batch_end: 1615857912.288751s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.9589 - accuracy: 0.0721
on_train_batch_begin: 1615857912.289052s

40 step training time: 0.337556s

on_train_batch_end: 1615857912.629894s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.9397 - accuracy: 0.0728
on_train_batch_begin: 1615857912.630192s

41 step training time: 0.341139s

on_train_batch_end: 1615857912.970483s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.9214 - accuracy: 0.0732
on_train_batch_begin: 1615857912.970784s

42 step training time: 0.340592s

on_train_batch_end: 1615857913.309320s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.9005 - accuracy: 0.0735
on_train_batch_begin: 1615857913.309647s

43 step training time: 0.338863s

on_train_batch_end: 1615857913.646759s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.8788 - accuracy: 0.0738
on_train_batch_begin: 1615857913.647055s

44 step training time: 0.337408s

on_train_batch_end: 1615857913.987755s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.8557 - accuracy: 0.0742
on_train_batch_begin: 1615857913.988050s

45 step training time: 0.340996s

on_train_batch_end: 1615857914.329778s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.8375 - accuracy: 0.0748
on_train_batch_begin: 1615857914.330074s

46 step training time: 0.342024s

on_train_batch_end: 1615857914.668759s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.8173 - accuracy: 0.0752
on_train_batch_begin: 1615857914.669063s

47 step training time: 0.338989s

on_train_batch_end: 1615857915.006488s

49152/50000 [============================>.] - ETA: 0s - loss: 7.7971 - accuracy: 0.0756
on_train_batch_begin: 1615857915.006785s

48 step training time: 0.337723s

on_train_batch_end: 1615857921.136419s

on_test_batch_begin: 1615857921.325424s

49 step training time: 6.318639s

on_epoch_end: 1615857926.089289s

Validation time: 4.763850s

Real time: 1615857926.089289s

Epoch time: 44.7580988407135s

50000/50000 [==============================] - 45s 895us/sample - loss: 7.7805 - accuracy: 0.0758 - val_loss: 361.8397 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615857926.089497s

Real time: 1615857926.0895026
Epoch 2/5

on_train_batch_begin: 1615857926.093036s

on_train_batch_end: 1615857926.442096s

 1024/50000 [..............................] - ETA: 16s - loss: 6.8086 - accuracy: 0.0899
on_train_batch_begin: 1615857926.442421s

1 step training time: 0.349385s

on_train_batch_end: 1615857926.783730s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.7688 - accuracy: 0.0915
on_train_batch_begin: 1615857926.784029s

2 step training time: 0.341609s

on_train_batch_end: 1615857927.125139s

 3072/50000 [>.............................] - ETA: 15s - loss: 6.7469 - accuracy: 0.0893
on_train_batch_begin: 1615857927.125441s

3 step training time: 0.341412s

on_train_batch_end: 1615857927.470166s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.7543 - accuracy: 0.0892
on_train_batch_begin: 1615857927.470465s

4 step training time: 0.345024s

on_train_batch_end: 1615857927.811114s

 5120/50000 [==>...........................] - ETA: 15s - loss: 6.7662 - accuracy: 0.0888
on_train_batch_begin: 1615857927.811413s

5 step training time: 0.340948s

on_train_batch_end: 1615857928.151630s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.7697 - accuracy: 0.0879
on_train_batch_begin: 1615857928.151930s

6 step training time: 0.340518s

on_train_batch_end: 1615857928.496952s

 7168/50000 [===>..........................] - ETA: 14s - loss: 6.7534 - accuracy: 0.0882
on_train_batch_begin: 1615857928.497247s

7 step training time: 0.345316s

on_train_batch_end: 1615857928.835362s

 8192/50000 [===>..........................] - ETA: 14s - loss: 6.7501 - accuracy: 0.0884
on_train_batch_begin: 1615857928.835664s

8 step training time: 0.338417s

on_train_batch_end: 1615857929.180819s

 9216/50000 [====>.........................] - ETA: 13s - loss: 6.7403 - accuracy: 0.0879
on_train_batch_begin: 1615857929.181137s

9 step training time: 0.345473s

on_train_batch_end: 1615857929.524555s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.7336 - accuracy: 0.0860
on_train_batch_begin: 1615857929.524856s

10 step training time: 0.343719s

on_train_batch_end: 1615857929.869355s

11264/50000 [=====>........................] - ETA: 12s - loss: 6.7103 - accuracy: 0.0860
on_train_batch_begin: 1615857929.869681s

11 step training time: 0.344826s

on_train_batch_end: 1615857930.213261s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.7012 - accuracy: 0.0849
on_train_batch_begin: 1615857930.213580s

12 step training time: 0.343899s

on_train_batch_end: 1615857930.557546s

13312/50000 [======>.......................] - ETA: 12s - loss: 6.6883 - accuracy: 0.0850
on_train_batch_begin: 1615857930.557854s

13 step training time: 0.344274s

on_train_batch_end: 1615857930.901676s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.6751 - accuracy: 0.0841
on_train_batch_begin: 1615857930.901973s

14 step training time: 0.344119s

on_train_batch_end: 1615857931.245845s

15360/50000 [========>.....................] - ETA: 11s - loss: 6.6705 - accuracy: 0.0840
on_train_batch_begin: 1615857931.246147s

15 step training time: 0.344174s

on_train_batch_end: 1615857931.587348s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.6607 - accuracy: 0.0835
on_train_batch_begin: 1615857931.587645s

16 step training time: 0.341498s

on_train_batch_end: 1615857931.930325s

17408/50000 [=========>....................] - ETA: 10s - loss: 6.6507 - accuracy: 0.0831
on_train_batch_begin: 1615857931.930626s

17 step training time: 0.342981s

on_train_batch_end: 1615857932.272049s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.6433 - accuracy: 0.0830
on_train_batch_begin: 1615857932.272362s

18 step training time: 0.341736s

on_train_batch_end: 1615857932.616184s

19456/50000 [==========>...................] - ETA: 10s - loss: 6.6434 - accuracy: 0.0823
on_train_batch_begin: 1615857932.616483s

19 step training time: 0.344121s

on_train_batch_end: 1615857932.960962s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.6331 - accuracy: 0.0822 
on_train_batch_begin: 1615857932.961272s

20 step training time: 0.344789s

on_train_batch_end: 1615857933.305840s

21504/50000 [===========>..................] - ETA: 9s - loss: 6.6257 - accuracy: 0.0823
on_train_batch_begin: 1615857933.306149s

21 step training time: 0.344876s

on_train_batch_end: 1615857933.648379s

22528/50000 [============>.................] - ETA: 9s - loss: 6.6118 - accuracy: 0.0822
on_train_batch_begin: 1615857933.648685s

22 step training time: 0.342536s

on_train_batch_end: 1615857933.990356s

23552/50000 [=============>................] - ETA: 8s - loss: 6.6017 - accuracy: 0.0820
on_train_batch_begin: 1615857933.990656s

23 step training time: 0.341971s

on_train_batch_end: 1615857934.335937s

24576/50000 [=============>................] - ETA: 8s - loss: 6.5886 - accuracy: 0.0820
on_train_batch_begin: 1615857934.336231s

24 step training time: 0.345575s

on_train_batch_end: 1615857934.682530s

25600/50000 [==============>...............] - ETA: 8s - loss: 6.5846 - accuracy: 0.0820
on_train_batch_begin: 1615857934.682828s

25 step training time: 0.346597s

on_train_batch_end: 1615857935.028805s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.5782 - accuracy: 0.0816
on_train_batch_begin: 1615857935.029100s

26 step training time: 0.346272s

on_train_batch_end: 1615857935.376307s

27648/50000 [===============>..............] - ETA: 7s - loss: 6.5740 - accuracy: 0.0813
on_train_batch_begin: 1615857935.376603s

27 step training time: 0.347502s

on_train_batch_end: 1615857935.720865s

28672/50000 [================>.............] - ETA: 7s - loss: 6.5684 - accuracy: 0.0812
on_train_batch_begin: 1615857935.721176s

28 step training time: 0.344573s

on_train_batch_end: 1615857936.063876s

29696/50000 [================>.............] - ETA: 6s - loss: 6.5625 - accuracy: 0.0815
on_train_batch_begin: 1615857936.064174s

29 step training time: 0.342998s

on_train_batch_end: 1615857936.411513s

30720/50000 [=================>............] - ETA: 6s - loss: 6.5568 - accuracy: 0.0811
on_train_batch_begin: 1615857936.411812s

30 step training time: 0.347638s

on_train_batch_end: 1615857936.754631s

31744/50000 [==================>...........] - ETA: 6s - loss: 6.5476 - accuracy: 0.0809
on_train_batch_begin: 1615857936.754926s

31 step training time: 0.343114s

on_train_batch_end: 1615857937.099554s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.5404 - accuracy: 0.0806
on_train_batch_begin: 1615857937.099858s

32 step training time: 0.344932s

on_train_batch_end: 1615857937.445190s

33792/50000 [===================>..........] - ETA: 5s - loss: 6.5272 - accuracy: 0.0802
on_train_batch_begin: 1615857937.445487s

33 step training time: 0.345630s

on_train_batch_end: 1615857937.789332s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.5193 - accuracy: 0.0797
on_train_batch_begin: 1615857937.789659s

34 step training time: 0.344172s

on_train_batch_end: 1615857938.133658s

35840/50000 [====================>.........] - ETA: 4s - loss: 6.5187 - accuracy: 0.0790
on_train_batch_begin: 1615857938.133961s

35 step training time: 0.344302s

on_train_batch_end: 1615857938.478394s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.5108 - accuracy: 0.0786
on_train_batch_begin: 1615857938.478688s

36 step training time: 0.344727s

on_train_batch_end: 1615857938.824657s

37888/50000 [=====================>........] - ETA: 4s - loss: 6.5046 - accuracy: 0.0780
on_train_batch_begin: 1615857938.824958s

37 step training time: 0.346270s

on_train_batch_end: 1615857939.169910s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.4945 - accuracy: 0.0775
on_train_batch_begin: 1615857939.170208s

38 step training time: 0.345250s

on_train_batch_end: 1615857939.514452s

39936/50000 [======================>.......] - ETA: 3s - loss: 6.4849 - accuracy: 0.0770
on_train_batch_begin: 1615857939.514750s

39 step training time: 0.344542s

on_train_batch_end: 1615857939.861040s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.4785 - accuracy: 0.0764
on_train_batch_begin: 1615857939.861336s

40 step training time: 0.346586s

on_train_batch_end: 1615857940.205600s

41984/50000 [========================>.....] - ETA: 2s - loss: 6.4696 - accuracy: 0.0757
on_train_batch_begin: 1615857940.205897s

41 step training time: 0.344561s

on_train_batch_end: 1615857940.552917s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.4587 - accuracy: 0.0750
on_train_batch_begin: 1615857940.553217s

42 step training time: 0.347320s

on_train_batch_end: 1615857940.903706s

44032/50000 [=========================>....] - ETA: 2s - loss: 6.4434 - accuracy: 0.0744
on_train_batch_begin: 1615857940.904006s

43 step training time: 0.350789s

on_train_batch_end: 1615857941.250665s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.4326 - accuracy: 0.0738
on_train_batch_begin: 1615857941.250958s

44 step training time: 0.346952s

on_train_batch_end: 1615857941.598238s

46080/50000 [==========================>...] - ETA: 1s - loss: 6.4195 - accuracy: 0.0734
on_train_batch_begin: 1615857941.598534s

45 step training time: 0.347576s

on_train_batch_end: 1615857941.947219s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.4053 - accuracy: 0.0729
on_train_batch_begin: 1615857941.947526s

46 step training time: 0.348992s

on_train_batch_end: 1615857942.295068s

48128/50000 [===========================>..] - ETA: 0s - loss: 6.3889 - accuracy: 0.0725
on_train_batch_begin: 1615857942.295365s

47 step training time: 0.347840s

on_train_batch_end: 1615857942.642074s

49152/50000 [============================>.] - ETA: 0s - loss: 6.3746 - accuracy: 0.0722
on_train_batch_begin: 1615857942.642368s

48 step training time: 0.347003s

on_train_batch_end: 1615857942.935291s

on_test_batch_begin: 1615857942.945747s

49 step training time: 0.303378s

on_epoch_end: 1615857943.772260s

Validation time: 0.826502s

Real time: 1615857943.772260s

Epoch time: 17.68277406692505s

50000/50000 [==============================] - 18s 354us/sample - loss: 6.3637 - accuracy: 0.0719 - val_loss: 7.5153 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615857943.772450s

Real time: 1615857943.7724555
Epoch 3/5

on_train_batch_begin: 1615857943.775837s

on_train_batch_end: 1615857944.124012s

 1024/50000 [..............................] - ETA: 16s - loss: 5.4108 - accuracy: 0.0566
on_train_batch_begin: 1615857944.124314s

1 step training time: 0.348477s

on_train_batch_end: 1615857944.470543s

 2048/50000 [>.............................] - ETA: 16s - loss: 5.3034 - accuracy: 0.0595
on_train_batch_begin: 1615857944.470835s

2 step training time: 0.346521s

on_train_batch_end: 1615857944.821152s

 3072/50000 [>.............................] - ETA: 16s - loss: 5.2774 - accuracy: 0.0585
on_train_batch_begin: 1615857944.821444s

3 step training time: 0.350609s

on_train_batch_end: 1615857945.171500s

 4096/50000 [=>............................] - ETA: 15s - loss: 5.1864 - accuracy: 0.0595
on_train_batch_begin: 1615857945.171796s

4 step training time: 0.350352s

on_train_batch_end: 1615857945.517834s

 5120/50000 [==>...........................] - ETA: 15s - loss: 5.1367 - accuracy: 0.0604
on_train_batch_begin: 1615857945.518137s

5 step training time: 0.346340s

on_train_batch_end: 1615857945.867979s

 6144/50000 [==>...........................] - ETA: 14s - loss: 5.0866 - accuracy: 0.0616
on_train_batch_begin: 1615857945.868278s

6 step training time: 0.350141s

on_train_batch_end: 1615857946.218502s

 7168/50000 [===>..........................] - ETA: 14s - loss: 5.0288 - accuracy: 0.0626
on_train_batch_begin: 1615857946.218795s

7 step training time: 0.350518s

on_train_batch_end: 1615857946.567036s

 8192/50000 [===>..........................] - ETA: 14s - loss: 4.9593 - accuracy: 0.0637
on_train_batch_begin: 1615857946.567329s

8 step training time: 0.348534s

on_train_batch_end: 1615857946.917304s

 9216/50000 [====>.........................] - ETA: 13s - loss: 4.8756 - accuracy: 0.0647
on_train_batch_begin: 1615857946.917620s

9 step training time: 0.350291s

on_train_batch_end: 1615857947.269633s

10240/50000 [=====>........................] - ETA: 13s - loss: 4.7994 - accuracy: 0.0654
on_train_batch_begin: 1615857947.269926s

10 step training time: 0.352306s

on_train_batch_end: 1615857947.622410s

11264/50000 [=====>........................] - ETA: 13s - loss: 4.7170 - accuracy: 0.0662
on_train_batch_begin: 1615857947.622709s

11 step training time: 0.352783s

on_train_batch_end: 1615857947.971363s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.6492 - accuracy: 0.0672
on_train_batch_begin: 1615857947.971659s

12 step training time: 0.348950s

on_train_batch_end: 1615857948.322977s

13312/50000 [======>.......................] - ETA: 12s - loss: 4.5786 - accuracy: 0.0684
on_train_batch_begin: 1615857948.323270s

13 step training time: 0.351610s

on_train_batch_end: 1615857948.673351s

14336/50000 [=======>......................] - ETA: 12s - loss: 4.5042 - accuracy: 0.0696
on_train_batch_begin: 1615857948.673678s

14 step training time: 0.350408s

on_train_batch_end: 1615857949.024044s

15360/50000 [========>.....................] - ETA: 11s - loss: 4.4389 - accuracy: 0.0709
on_train_batch_begin: 1615857949.024345s

15 step training time: 0.350667s

on_train_batch_end: 1615857949.378417s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.3723 - accuracy: 0.0722
on_train_batch_begin: 1615857949.378717s

16 step training time: 0.354372s

on_train_batch_end: 1615857949.728553s

17408/50000 [=========>....................] - ETA: 11s - loss: 4.3099 - accuracy: 0.0734
on_train_batch_begin: 1615857949.728851s

17 step training time: 0.350134s

on_train_batch_end: 1615857950.079526s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.2465 - accuracy: 0.0746
on_train_batch_begin: 1615857950.079821s

18 step training time: 0.350970s

on_train_batch_end: 1615857950.432346s

19456/50000 [==========>...................] - ETA: 10s - loss: 4.1863 - accuracy: 0.0757
on_train_batch_begin: 1615857950.432645s

19 step training time: 0.352824s

on_train_batch_end: 1615857950.782808s

20480/50000 [===========>..................] - ETA: 10s - loss: 4.1358 - accuracy: 0.0768
on_train_batch_begin: 1615857950.783109s

20 step training time: 0.350464s

on_train_batch_end: 1615857951.135173s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.0846 - accuracy: 0.0779 
on_train_batch_begin: 1615857951.135470s

21 step training time: 0.352361s

on_train_batch_end: 1615857951.487999s

22528/50000 [============>.................] - ETA: 9s - loss: 4.0334 - accuracy: 0.0789
on_train_batch_begin: 1615857951.488297s

22 step training time: 0.352827s

on_train_batch_end: 1615857951.832140s

23552/50000 [=============>................] - ETA: 9s - loss: 3.9938 - accuracy: 0.0796
on_train_batch_begin: 1615857951.832439s

23 step training time: 0.344142s

on_train_batch_end: 1615857952.187529s

24576/50000 [=============>................] - ETA: 8s - loss: 3.9598 - accuracy: 0.0805
on_train_batch_begin: 1615857952.187829s

24 step training time: 0.355390s

on_train_batch_end: 1615857952.540077s

25600/50000 [==============>...............] - ETA: 8s - loss: 3.9229 - accuracy: 0.0812
on_train_batch_begin: 1615857952.540374s

25 step training time: 0.352546s

on_train_batch_end: 1615857952.893902s

26624/50000 [==============>...............] - ETA: 8s - loss: 3.8834 - accuracy: 0.0819
on_train_batch_begin: 1615857952.894206s

26 step training time: 0.353832s

on_train_batch_end: 1615857953.249948s

27648/50000 [===============>..............] - ETA: 7s - loss: 3.8485 - accuracy: 0.0825
on_train_batch_begin: 1615857953.250247s

27 step training time: 0.356041s

on_train_batch_end: 1615857953.605494s

28672/50000 [================>.............] - ETA: 7s - loss: 3.8207 - accuracy: 0.0831
on_train_batch_begin: 1615857953.605814s

28 step training time: 0.355566s

on_train_batch_end: 1615857953.959219s

29696/50000 [================>.............] - ETA: 6s - loss: 3.7840 - accuracy: 0.0836
on_train_batch_begin: 1615857953.959515s

29 step training time: 0.353701s

on_train_batch_end: 1615857954.313133s

30720/50000 [=================>............] - ETA: 6s - loss: 3.7550 - accuracy: 0.0842
on_train_batch_begin: 1615857954.313437s

30 step training time: 0.353922s

on_train_batch_end: 1615857954.670962s

31744/50000 [==================>...........] - ETA: 6s - loss: 3.7277 - accuracy: 0.0847
on_train_batch_begin: 1615857954.671261s

31 step training time: 0.357824s

on_train_batch_end: 1615857955.027061s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.7012 - accuracy: 0.0852
on_train_batch_begin: 1615857955.027357s

32 step training time: 0.356097s

on_train_batch_end: 1615857955.380681s

33792/50000 [===================>..........] - ETA: 5s - loss: 3.6771 - accuracy: 0.0856
on_train_batch_begin: 1615857955.381000s

33 step training time: 0.353643s

on_train_batch_end: 1615857955.733580s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.6494 - accuracy: 0.0861
on_train_batch_begin: 1615857955.733882s

34 step training time: 0.352882s

on_train_batch_end: 1615857956.087726s

35840/50000 [====================>.........] - ETA: 4s - loss: 3.6247 - accuracy: 0.0865
on_train_batch_begin: 1615857956.088023s

35 step training time: 0.354141s

on_train_batch_end: 1615857956.442682s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.6056 - accuracy: 0.0868
on_train_batch_begin: 1615857956.442982s

36 step training time: 0.354959s

on_train_batch_end: 1615857956.799005s

37888/50000 [=====================>........] - ETA: 4s - loss: 3.5795 - accuracy: 0.0872
on_train_batch_begin: 1615857956.799299s

37 step training time: 0.356317s

on_train_batch_end: 1615857957.154363s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.5596 - accuracy: 0.0875
on_train_batch_begin: 1615857957.154661s

38 step training time: 0.355361s

on_train_batch_end: 1615857957.511373s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.5335 - accuracy: 0.0878
on_train_batch_begin: 1615857957.511673s

39 step training time: 0.357013s

on_train_batch_end: 1615857957.865282s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.5066 - accuracy: 0.0881
on_train_batch_begin: 1615857957.865599s

40 step training time: 0.353925s

on_train_batch_end: 1615857958.221602s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.4796 - accuracy: 0.0884
on_train_batch_begin: 1615857958.221898s

41 step training time: 0.356299s

on_train_batch_end: 1615857958.577980s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.4504 - accuracy: 0.0887
on_train_batch_begin: 1615857958.578279s

42 step training time: 0.356381s

on_train_batch_end: 1615857958.931813s

44032/50000 [=========================>....] - ETA: 2s - loss: 3.4268 - accuracy: 0.0890
on_train_batch_begin: 1615857958.932113s

43 step training time: 0.353835s

on_train_batch_end: 1615857959.285185s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.4038 - accuracy: 0.0892
on_train_batch_begin: 1615857959.285484s

44 step training time: 0.353371s

on_train_batch_end: 1615857959.641150s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.3832 - accuracy: 0.0895
on_train_batch_begin: 1615857959.641446s

45 step training time: 0.355962s

on_train_batch_end: 1615857959.994906s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.3620 - accuracy: 0.0897
on_train_batch_begin: 1615857959.995208s

46 step training time: 0.353762s

on_train_batch_end: 1615857960.352091s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.3386 - accuracy: 0.0899
on_train_batch_begin: 1615857960.352392s

47 step training time: 0.357184s

on_train_batch_end: 1615857960.705566s

49152/50000 [============================>.] - ETA: 0s - loss: 3.3165 - accuracy: 0.0901
on_train_batch_begin: 1615857960.705867s

48 step training time: 0.353475s

on_train_batch_end: 1615857960.998579s

on_test_batch_begin: 1615857961.008785s

49 step training time: 0.302918s

on_epoch_end: 1615857961.842802s

Validation time: 0.834005s

Real time: 1615857961.842802s

Epoch time: 18.070362329483032s

50000/50000 [==============================] - 18s 361us/sample - loss: 3.2941 - accuracy: 0.0903 - val_loss: 7.4245 - val_accuracy: 0.0402

on_epoch_begin: 1615857961.842990s

Real time: 1615857961.8429947
Epoch 4/5

on_train_batch_begin: 1615857961.846395s

on_train_batch_end: 1615857962.196105s

 1024/50000 [..............................] - ETA: 16s - loss: 2.0003 - accuracy: 0.1001
on_train_batch_begin: 1615857962.196404s

1 step training time: 0.350008s

on_train_batch_end: 1615857962.549439s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.0200 - accuracy: 0.0998
on_train_batch_begin: 1615857962.549765s

2 step training time: 0.353361s

on_train_batch_end: 1615857962.911137s

 3072/50000 [>.............................] - ETA: 16s - loss: 2.0554 - accuracy: 0.0998
on_train_batch_begin: 1615857962.911429s

3 step training time: 0.361664s

on_train_batch_end: 1615857963.267836s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.0604 - accuracy: 0.0998
on_train_batch_begin: 1615857963.268136s

4 step training time: 0.356707s

on_train_batch_end: 1615857963.625017s

 5120/50000 [==>...........................] - ETA: 15s - loss: 2.0352 - accuracy: 0.1000
on_train_batch_begin: 1615857963.625318s

5 step training time: 0.357182s

on_train_batch_end: 1615857963.985201s

 6144/50000 [==>...........................] - ETA: 15s - loss: 2.0194 - accuracy: 0.0999
on_train_batch_begin: 1615857963.985502s

6 step training time: 0.360184s

on_train_batch_end: 1615857964.343211s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.0248 - accuracy: 0.1000
on_train_batch_begin: 1615857964.343509s

7 step training time: 0.358007s

on_train_batch_end: 1615857964.703690s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.0031 - accuracy: 0.1000
on_train_batch_begin: 1615857964.704002s

8 step training time: 0.360494s

on_train_batch_end: 1615857965.061748s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.9834 - accuracy: 0.1000
on_train_batch_begin: 1615857965.062050s

9 step training time: 0.358048s

on_train_batch_end: 1615857965.420316s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.9512 - accuracy: 0.1001
on_train_batch_begin: 1615857965.420616s

10 step training time: 0.358566s

on_train_batch_end: 1615857965.780559s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.9218 - accuracy: 0.1001
on_train_batch_begin: 1615857965.780871s

11 step training time: 0.360254s

on_train_batch_end: 1615857966.138700s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.9021 - accuracy: 0.1001
on_train_batch_begin: 1615857966.138996s

12 step training time: 0.358125s

on_train_batch_end: 1615857966.495959s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.8941 - accuracy: 0.1001
on_train_batch_begin: 1615857966.496260s

13 step training time: 0.357264s

on_train_batch_end: 1615857966.856342s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.8847 - accuracy: 0.1001
on_train_batch_begin: 1615857966.856644s

14 step training time: 0.360384s

on_train_batch_end: 1615857967.218966s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.8726 - accuracy: 0.1001
on_train_batch_begin: 1615857967.219263s

15 step training time: 0.362619s

on_train_batch_end: 1615857967.575627s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.8567 - accuracy: 0.1001
on_train_batch_begin: 1615857967.575926s

16 step training time: 0.356663s

on_train_batch_end: 1615857967.934042s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.8442 - accuracy: 0.1001
on_train_batch_begin: 1615857967.934338s

17 step training time: 0.358412s

on_train_batch_end: 1615857968.294660s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.8290 - accuracy: 0.1001
on_train_batch_begin: 1615857968.294966s

18 step training time: 0.360627s

on_train_batch_end: 1615857968.653421s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.8267 - accuracy: 0.1001
on_train_batch_begin: 1615857968.653746s

19 step training time: 0.358780s

on_train_batch_end: 1615857969.012206s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.8171 - accuracy: 0.1001
on_train_batch_begin: 1615857969.012507s

20 step training time: 0.358761s

on_train_batch_end: 1615857969.372301s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.8067 - accuracy: 0.1002 
on_train_batch_begin: 1615857969.372604s

21 step training time: 0.360097s

on_train_batch_end: 1615857969.732650s

22528/50000 [============>.................] - ETA: 9s - loss: 1.7998 - accuracy: 0.1001
on_train_batch_begin: 1615857969.732950s

22 step training time: 0.360346s

on_train_batch_end: 1615857970.092159s

23552/50000 [=============>................] - ETA: 9s - loss: 1.7958 - accuracy: 0.1001
on_train_batch_begin: 1615857970.092468s

23 step training time: 0.359518s

on_train_batch_end: 1615857970.452858s

24576/50000 [=============>................] - ETA: 8s - loss: 1.8004 - accuracy: 0.1002
on_train_batch_begin: 1615857970.453156s

24 step training time: 0.360688s

on_train_batch_end: 1615857970.814400s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.8004 - accuracy: 0.1002
on_train_batch_begin: 1615857970.814702s

25 step training time: 0.361546s

on_train_batch_end: 1615857971.177170s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.8040 - accuracy: 0.1002
on_train_batch_begin: 1615857971.177472s

26 step training time: 0.362770s

on_train_batch_end: 1615857971.536654s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.8030 - accuracy: 0.1002
on_train_batch_begin: 1615857971.536953s

27 step training time: 0.359481s

on_train_batch_end: 1615857971.897732s

28672/50000 [================>.............] - ETA: 7s - loss: 1.8009 - accuracy: 0.1002
on_train_batch_begin: 1615857971.898029s

28 step training time: 0.361076s

on_train_batch_end: 1615857972.256609s

29696/50000 [================>.............] - ETA: 7s - loss: 1.7973 - accuracy: 0.1002
on_train_batch_begin: 1615857972.256906s

29 step training time: 0.358877s

on_train_batch_end: 1615857972.616533s

30720/50000 [=================>............] - ETA: 6s - loss: 1.7962 - accuracy: 0.1002
on_train_batch_begin: 1615857972.616829s

30 step training time: 0.359923s

on_train_batch_end: 1615857972.977191s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.7977 - accuracy: 0.1002
on_train_batch_begin: 1615857972.977491s

31 step training time: 0.360662s

on_train_batch_end: 1615857973.336669s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.7951 - accuracy: 0.1002
on_train_batch_begin: 1615857973.336969s

32 step training time: 0.359478s

on_train_batch_end: 1615857973.699651s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.7868 - accuracy: 0.1002
on_train_batch_begin: 1615857973.699953s

33 step training time: 0.362984s

on_train_batch_end: 1615857974.064467s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.7837 - accuracy: 0.1002
on_train_batch_begin: 1615857974.064766s

34 step training time: 0.364813s

on_train_batch_end: 1615857974.427284s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.7784 - accuracy: 0.1002
on_train_batch_begin: 1615857974.427586s

35 step training time: 0.362820s

on_train_batch_end: 1615857974.785687s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.7774 - accuracy: 0.1002
on_train_batch_begin: 1615857974.785998s

36 step training time: 0.358412s

on_train_batch_end: 1615857975.146971s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.7746 - accuracy: 0.1002
on_train_batch_begin: 1615857975.147267s

37 step training time: 0.361269s

on_train_batch_end: 1615857975.508705s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.7697 - accuracy: 0.1002
on_train_batch_begin: 1615857975.509008s

38 step training time: 0.361742s

on_train_batch_end: 1615857975.872670s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.7683 - accuracy: 0.1002
on_train_batch_begin: 1615857975.872975s

39 step training time: 0.363966s

on_train_batch_end: 1615857976.236791s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.7614 - accuracy: 0.1002
on_train_batch_begin: 1615857976.237093s

40 step training time: 0.364118s

on_train_batch_end: 1615857976.600252s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.7564 - accuracy: 0.1002
on_train_batch_begin: 1615857976.600548s

41 step training time: 0.363455s

on_train_batch_end: 1615857976.963124s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.7486 - accuracy: 0.1002
on_train_batch_begin: 1615857976.963423s

42 step training time: 0.362875s

on_train_batch_end: 1615857977.327356s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.7449 - accuracy: 0.1002
on_train_batch_begin: 1615857977.327660s

43 step training time: 0.364237s

on_train_batch_end: 1615857977.691926s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.7451 - accuracy: 0.1002
on_train_batch_begin: 1615857977.692225s

44 step training time: 0.364564s

on_train_batch_end: 1615857978.053695s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.7449 - accuracy: 0.1002
on_train_batch_begin: 1615857978.053999s

45 step training time: 0.361774s

on_train_batch_end: 1615857978.416399s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.7412 - accuracy: 0.1002
on_train_batch_begin: 1615857978.416709s

46 step training time: 0.362710s

on_train_batch_end: 1615857978.780474s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7372 - accuracy: 0.1002
on_train_batch_begin: 1615857978.780785s

47 step training time: 0.364076s

on_train_batch_end: 1615857979.142611s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7338 - accuracy: 0.1002
on_train_batch_begin: 1615857979.142913s

48 step training time: 0.362128s

on_train_batch_end: 1615857979.441733s

on_test_batch_begin: 1615857979.452026s

49 step training time: 0.309114s

on_epoch_end: 1615857980.293916s

Validation time: 0.841877s

Real time: 1615857980.293916s

Epoch time: 18.450937509536743s

50000/50000 [==============================] - 18s 369us/sample - loss: 1.7328 - accuracy: 0.1002 - val_loss: 7.3527 - val_accuracy: 0.0999

on_epoch_begin: 1615857980.294101s

Real time: 1615857980.2941065
Epoch 5/5

on_train_batch_begin: 1615857980.297512s

on_train_batch_end: 1615857980.653968s

 1024/50000 [..............................] - ETA: 17s - loss: 1.3284 - accuracy: 0.1001
on_train_batch_begin: 1615857980.654268s

1 step training time: 0.356755s

on_train_batch_end: 1615857981.014666s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.4094 - accuracy: 0.1001
on_train_batch_begin: 1615857981.014965s

2 step training time: 0.360697s

on_train_batch_end: 1615857981.383341s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.4246 - accuracy: 0.1000
on_train_batch_begin: 1615857981.383639s

3 step training time: 0.368674s

on_train_batch_end: 1615857981.747653s

 4096/50000 [=>............................] - ETA: 16s - loss: 1.4042 - accuracy: 0.1001
on_train_batch_begin: 1615857981.747959s

4 step training time: 0.364320s

on_train_batch_end: 1615857982.108996s

 5120/50000 [==>...........................] - ETA: 15s - loss: 1.4051 - accuracy: 0.1001
on_train_batch_begin: 1615857982.109297s

5 step training time: 0.361338s

on_train_batch_end: 1615857982.475286s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.3896 - accuracy: 0.1001
on_train_batch_begin: 1615857982.475582s

6 step training time: 0.366285s

on_train_batch_end: 1615857982.842209s

 7168/50000 [===>..........................] - ETA: 15s - loss: 1.3810 - accuracy: 0.1001
on_train_batch_begin: 1615857982.842510s

7 step training time: 0.366928s

on_train_batch_end: 1615857983.203202s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.3965 - accuracy: 0.1002
on_train_batch_begin: 1615857983.203497s

8 step training time: 0.360988s

on_train_batch_end: 1615857983.568973s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.4040 - accuracy: 0.1002
on_train_batch_begin: 1615857983.569274s

9 step training time: 0.365777s

on_train_batch_end: 1615857983.934020s

10240/50000 [=====>........................] - ETA: 14s - loss: 1.4107 - accuracy: 0.1002
on_train_batch_begin: 1615857983.934329s

10 step training time: 0.365054s

on_train_batch_end: 1615857984.297605s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.4139 - accuracy: 0.1002
on_train_batch_begin: 1615857984.297905s

11 step training time: 0.363576s

on_train_batch_end: 1615857984.663680s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.4155 - accuracy: 0.1002
on_train_batch_begin: 1615857984.663979s

12 step training time: 0.366074s

on_train_batch_end: 1615857985.029252s

13312/50000 [======>.......................] - ETA: 13s - loss: 1.4136 - accuracy: 0.1002
on_train_batch_begin: 1615857985.029576s

13 step training time: 0.365597s

on_train_batch_end: 1615857985.380205s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.4022 - accuracy: 0.1002
on_train_batch_begin: 1615857985.380506s

14 step training time: 0.350930s

on_train_batch_end: 1615857985.747807s

15360/50000 [========>.....................] - ETA: 12s - loss: 1.3927 - accuracy: 0.1002
on_train_batch_begin: 1615857985.748114s

15 step training time: 0.367609s

on_train_batch_end: 1615857986.114859s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.3864 - accuracy: 0.1002
on_train_batch_begin: 1615857986.115158s

16 step training time: 0.367044s

on_train_batch_end: 1615857986.477109s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.3831 - accuracy: 0.1002
on_train_batch_begin: 1615857986.477412s

17 step training time: 0.362253s

on_train_batch_end: 1615857986.844448s

18432/50000 [==========>...................] - ETA: 11s - loss: 1.3835 - accuracy: 0.1002
on_train_batch_begin: 1615857986.844742s

18 step training time: 0.367331s

on_train_batch_end: 1615857987.209677s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.3751 - accuracy: 0.1002
on_train_batch_begin: 1615857987.209979s

19 step training time: 0.365237s

on_train_batch_end: 1615857987.573812s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.3725 - accuracy: 0.1002
on_train_batch_begin: 1615857987.574111s

20 step training time: 0.364132s

on_train_batch_end: 1615857987.941664s

21504/50000 [===========>..................] - ETA: 10s - loss: 1.3726 - accuracy: 0.1002
on_train_batch_begin: 1615857987.941964s

21 step training time: 0.367853s

on_train_batch_end: 1615857988.306705s

22528/50000 [============>.................] - ETA: 9s - loss: 1.3654 - accuracy: 0.1002 
on_train_batch_begin: 1615857988.307005s

22 step training time: 0.365041s

on_train_batch_end: 1615857988.672101s

23552/50000 [=============>................] - ETA: 9s - loss: 1.3591 - accuracy: 0.1002
on_train_batch_begin: 1615857988.672404s

23 step training time: 0.365399s

on_train_batch_end: 1615857989.038466s

24576/50000 [=============>................] - ETA: 9s - loss: 1.3522 - accuracy: 0.1002
on_train_batch_begin: 1615857989.038769s

24 step training time: 0.366365s

on_train_batch_end: 1615857989.404170s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.3472 - accuracy: 0.1002
on_train_batch_begin: 1615857989.404473s

25 step training time: 0.365704s

on_train_batch_end: 1615857989.772073s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.3414 - accuracy: 0.1002
on_train_batch_begin: 1615857989.772375s

26 step training time: 0.367902s

on_train_batch_end: 1615857990.137054s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.3389 - accuracy: 0.1002
on_train_batch_begin: 1615857990.137356s

27 step training time: 0.364981s

on_train_batch_end: 1615857990.503752s

28672/50000 [================>.............] - ETA: 7s - loss: 1.3337 - accuracy: 0.1002
on_train_batch_begin: 1615857990.504062s

28 step training time: 0.366706s

on_train_batch_end: 1615857990.872241s

29696/50000 [================>.............] - ETA: 7s - loss: 1.3311 - accuracy: 0.1002
on_train_batch_begin: 1615857990.872545s

29 step training time: 0.368484s

on_train_batch_end: 1615857991.235697s

30720/50000 [=================>............] - ETA: 6s - loss: 1.3287 - accuracy: 0.1002
on_train_batch_begin: 1615857991.235999s

30 step training time: 0.363453s

on_train_batch_end: 1615857991.602237s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.3286 - accuracy: 0.1002
on_train_batch_begin: 1615857991.602537s

31 step training time: 0.366538s

on_train_batch_end: 1615857991.965997s

32768/50000 [==================>...........] - ETA: 6s - loss: 1.3268 - accuracy: 0.1002
on_train_batch_begin: 1615857991.966296s

32 step training time: 0.363760s

on_train_batch_end: 1615857992.332919s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.3260 - accuracy: 0.1002
on_train_batch_begin: 1615857992.333225s

33 step training time: 0.366929s

on_train_batch_end: 1615857992.699023s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.3214 - accuracy: 0.1002
on_train_batch_begin: 1615857992.699325s

34 step training time: 0.366099s

on_train_batch_end: 1615857993.062378s

35840/50000 [====================>.........] - ETA: 5s - loss: 1.3165 - accuracy: 0.1002
on_train_batch_begin: 1615857993.062678s

35 step training time: 0.363353s

on_train_batch_end: 1615857993.428521s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.3139 - accuracy: 0.1002
on_train_batch_begin: 1615857993.428824s

36 step training time: 0.366146s

on_train_batch_end: 1615857993.795264s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.3098 - accuracy: 0.1002
on_train_batch_begin: 1615857993.795565s

37 step training time: 0.366741s

on_train_batch_end: 1615857994.162494s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.3087 - accuracy: 0.1002
on_train_batch_begin: 1615857994.162791s

38 step training time: 0.367226s

on_train_batch_end: 1615857994.526887s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.3034 - accuracy: 0.1002
on_train_batch_begin: 1615857994.527189s

39 step training time: 0.364398s

on_train_batch_end: 1615857994.893274s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.3010 - accuracy: 0.1002
on_train_batch_begin: 1615857994.893607s

40 step training time: 0.366418s

on_train_batch_end: 1615857995.258346s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.3001 - accuracy: 0.1002
on_train_batch_begin: 1615857995.258649s

41 step training time: 0.365042s

on_train_batch_end: 1615857995.624575s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.2976 - accuracy: 0.1002
on_train_batch_begin: 1615857995.624877s

42 step training time: 0.366228s

on_train_batch_end: 1615857995.989640s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.2958 - accuracy: 0.1002
on_train_batch_begin: 1615857995.989946s

43 step training time: 0.365069s

on_train_batch_end: 1615857996.355619s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.2946 - accuracy: 0.1002
on_train_batch_begin: 1615857996.355922s

44 step training time: 0.365976s

on_train_batch_end: 1615857996.720800s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.2920 - accuracy: 0.1002
on_train_batch_begin: 1615857996.721101s

45 step training time: 0.365180s

on_train_batch_end: 1615857997.088292s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.2870 - accuracy: 0.1002
on_train_batch_begin: 1615857997.088592s

46 step training time: 0.367491s

on_train_batch_end: 1615857997.459522s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.2840 - accuracy: 0.1002
on_train_batch_begin: 1615857997.459824s

47 step training time: 0.371232s

on_train_batch_end: 1615857997.824656s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2830 - accuracy: 0.1002
on_train_batch_begin: 1615857997.824956s

48 step training time: 0.365132s

on_train_batch_end: 1615857998.129602s

on_test_batch_begin: 1615857998.141473s

49 step training time: 0.316517s

on_epoch_end: 1615857998.995956s

Validation time: 0.854469s

Real time: 1615857998.995956s

Epoch time: 18.701865673065186s

50000/50000 [==============================] - 19s 374us/sample - loss: 1.2833 - accuracy: 0.1002 - val_loss: 7.5512 - val_accuracy: 0.0999
Tempo do fit: 121.08457851409912