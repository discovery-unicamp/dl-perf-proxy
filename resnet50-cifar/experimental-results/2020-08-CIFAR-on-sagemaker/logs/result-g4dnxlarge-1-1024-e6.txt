wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:36
   172032/170498071 [..............................] - ETA: 1:11
   786432/170498071 [..............................] - ETA: 26s 
  2351104/170498071 [..............................] - ETA: 12s
  5480448/170498071 [..............................] - ETA: 6s 
  8658944/170498071 [>.............................] - ETA: 5s
 11902976/170498071 [=>............................] - ETA: 4s
 15081472/170498071 [=>............................] - ETA: 3s
 18259968/170498071 [==>...........................] - ETA: 3s
 21487616/170498071 [==>...........................] - ETA: 3s
 24707072/170498071 [===>..........................] - ETA: 3s
 27910144/170498071 [===>..........................] - ETA: 2s
 31080448/170498071 [====>.........................] - ETA: 2s
 34283520/170498071 [=====>........................] - ETA: 2s
 37511168/170498071 [=====>........................] - ETA: 2s
 40738816/170498071 [======>.......................] - ETA: 2s
 43966464/170498071 [======>.......................] - ETA: 2s
 47144960/170498071 [=======>......................] - ETA: 2s
 50339840/170498071 [=======>......................] - ETA: 2s
 53600256/170498071 [========>.....................] - ETA: 2s
 56745984/170498071 [========>.....................] - ETA: 2s
 59940864/170498071 [=========>....................] - ETA: 1s
 63184896/170498071 [==========>...................] - ETA: 1s
 66379776/170498071 [==========>...................] - ETA: 1s
 69574656/170498071 [===========>..................] - ETA: 1s
 72802304/170498071 [===========>..................] - ETA: 1s
 76013568/170498071 [============>.................] - ETA: 1s
 79241216/170498071 [============>.................] - ETA: 1s
 82452480/170498071 [=============>................] - ETA: 1s
 85688320/170498071 [==============>...............] - ETA: 1s
 88956928/170498071 [==============>...............] - ETA: 1s
 92119040/170498071 [===============>..............] - ETA: 1s
 95346688/170498071 [===============>..............] - ETA: 1s
 98590720/170498071 [================>.............] - ETA: 1s
101785600/170498071 [================>.............] - ETA: 1s
105013248/170498071 [=================>............] - ETA: 1s
108240896/170498071 [==================>...........] - ETA: 1s
111517696/170498071 [==================>...........] - ETA: 0s
114778112/170498071 [===================>..........] - ETA: 0s
118112256/170498071 [===================>..........] - ETA: 0s
121266176/170498071 [====================>.........] - ETA: 0s
124477440/170498071 [====================>.........] - ETA: 0s
127688704/170498071 [=====================>........] - ETA: 0s
130924544/170498071 [======================>.......] - ETA: 0s
134144000/170498071 [======================>.......] - ETA: 0s
137273344/170498071 [=======================>......] - ETA: 0s
140451840/170498071 [=======================>......] - ETA: 0s
143646720/170498071 [========================>.....] - ETA: 0s
146890752/170498071 [========================>.....] - ETA: 0s
150134784/170498071 [=========================>....] - ETA: 0s
153346048/170498071 [=========================>....] - ETA: 0s
156508160/170498071 [==========================>...] - ETA: 0s
159703040/170498071 [===========================>..] - ETA: 0s
162947072/170498071 [===========================>..] - ETA: 0s
166158336/170498071 [============================>.] - ETA: 0s
169385984/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 16:30
 9682944/94765736 [==>...........................] - ETA: 1s   
23609344/94765736 [======>.......................] - ETA: 0s
35430400/94765736 [==========>...................] - ETA: 0s
49283072/94765736 [==============>...............] - ETA: 0s
63537152/94765736 [===================>..........] - ETA: 0s
73555968/94765736 [======================>.......] - ETA: 0s
86360064/94765736 [==========================>...] - ETA: 0s
94773248/94765736 [==============================] - 0s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.047968864440918
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615853606.730609s

Real time: 1615853606.7306266
Epoch 1/5

on_train_batch_begin: 1615853607.492997s

on_train_batch_end: 1615853625.049523s

 1024/50000 [..............................] - ETA: 14:36 - loss: 17.7529 - accuracy: 2.6894e-04
on_train_batch_begin: 1615853625.050147s

1 step training time: 17.557150s

on_train_batch_end: 1615853625.369613s

 2048/50000 [>.............................] - ETA: 7:16 - loss: 14.3810 - accuracy: 3.1996e-04 
on_train_batch_begin: 1615853625.369933s

2 step training time: 0.319786s

on_train_batch_end: 1615853625.686127s

 3072/50000 [>.............................] - ETA: 4:49 - loss: 12.3836 - accuracy: 9.5336e-04
on_train_batch_begin: 1615853625.686417s

3 step training time: 0.316484s

on_train_batch_end: 1615853626.002624s

 4096/50000 [=>............................] - ETA: 3:35 - loss: 11.3813 - accuracy: 0.0021    
on_train_batch_begin: 1615853626.002903s

4 step training time: 0.316486s

on_train_batch_end: 1615853626.324963s

 5120/50000 [==>...........................] - ETA: 2:51 - loss: 10.7068 - accuracy: 0.0039
on_train_batch_begin: 1615853626.325270s

5 step training time: 0.322367s

on_train_batch_end: 1615853626.640450s

 6144/50000 [==>...........................] - ETA: 2:22 - loss: 10.2411 - accuracy: 0.0043
on_train_batch_begin: 1615853626.640756s

6 step training time: 0.315486s

on_train_batch_end: 1615853626.957332s

 7168/50000 [===>..........................] - ETA: 2:00 - loss: 9.9481 - accuracy: 0.0059 
on_train_batch_begin: 1615853626.957638s

7 step training time: 0.316882s

on_train_batch_end: 1615853627.279583s

 8192/50000 [===>..........................] - ETA: 1:44 - loss: 9.7033 - accuracy: 0.0089
on_train_batch_begin: 1615853627.279884s

8 step training time: 0.322246s

on_train_batch_end: 1615853627.590312s

 9216/50000 [====>.........................] - ETA: 1:32 - loss: 9.5258 - accuracy: 0.0137
on_train_batch_begin: 1615853627.590598s

9 step training time: 0.310714s

on_train_batch_end: 1615853627.908997s

10240/50000 [=====>........................] - ETA: 1:22 - loss: 9.3776 - accuracy: 0.0177
on_train_batch_begin: 1615853627.909303s

10 step training time: 0.318705s

on_train_batch_end: 1615853628.222896s

11264/50000 [=====>........................] - ETA: 1:13 - loss: 9.2504 - accuracy: 0.0209
on_train_batch_begin: 1615853628.223202s

11 step training time: 0.313899s

on_train_batch_end: 1615853628.538896s

12288/50000 [======>.......................] - ETA: 1:06 - loss: 9.1455 - accuracy: 0.0257
on_train_batch_begin: 1615853628.539200s

12 step training time: 0.315998s

on_train_batch_end: 1615853628.858849s

13312/50000 [======>.......................] - ETA: 1:00 - loss: 9.0383 - accuracy: 0.0297
on_train_batch_begin: 1615853628.859149s

13 step training time: 0.319950s

on_train_batch_end: 1615853629.174087s

14336/50000 [=======>......................] - ETA: 55s - loss: 8.9467 - accuracy: 0.0326 
on_train_batch_begin: 1615853629.174410s

14 step training time: 0.315261s

on_train_batch_end: 1615853629.490841s

15360/50000 [========>.....................] - ETA: 51s - loss: 8.8608 - accuracy: 0.0357
on_train_batch_begin: 1615853629.491280s

15 step training time: 0.316870s

on_train_batch_end: 1615853629.802821s

16384/50000 [========>.....................] - ETA: 47s - loss: 8.7873 - accuracy: 0.0387
on_train_batch_begin: 1615853629.803126s

16 step training time: 0.311845s

on_train_batch_end: 1615853630.119765s

17408/50000 [=========>....................] - ETA: 43s - loss: 8.7168 - accuracy: 0.0416
on_train_batch_begin: 1615853630.120059s

17 step training time: 0.316933s

on_train_batch_end: 1615853630.436189s

18432/50000 [==========>...................] - ETA: 40s - loss: 8.6476 - accuracy: 0.0436
on_train_batch_begin: 1615853630.436466s

18 step training time: 0.316408s

on_train_batch_end: 1615853630.750077s

19456/50000 [==========>...................] - ETA: 37s - loss: 8.5876 - accuracy: 0.0451
on_train_batch_begin: 1615853630.750354s

19 step training time: 0.313888s

on_train_batch_end: 1615853631.069625s

20480/50000 [===========>..................] - ETA: 35s - loss: 8.5304 - accuracy: 0.0470
on_train_batch_begin: 1615853631.069904s

20 step training time: 0.319550s

on_train_batch_end: 1615853631.382761s

21504/50000 [===========>..................] - ETA: 32s - loss: 8.4765 - accuracy: 0.0495
on_train_batch_begin: 1615853631.383004s

21 step training time: 0.313100s

on_train_batch_end: 1615853631.700588s

22528/50000 [============>.................] - ETA: 30s - loss: 8.4262 - accuracy: 0.0509
on_train_batch_begin: 1615853631.700879s

22 step training time: 0.317874s

on_train_batch_end: 1615853632.022952s

23552/50000 [=============>................] - ETA: 28s - loss: 8.3814 - accuracy: 0.0524
on_train_batch_begin: 1615853632.023227s

23 step training time: 0.322348s

on_train_batch_end: 1615853632.334267s

24576/50000 [=============>................] - ETA: 26s - loss: 8.3399 - accuracy: 0.0537
on_train_batch_begin: 1615853632.334555s

24 step training time: 0.311328s

on_train_batch_end: 1615853632.651224s

25600/50000 [==============>...............] - ETA: 24s - loss: 8.3064 - accuracy: 0.0549
on_train_batch_begin: 1615853632.651503s

25 step training time: 0.316948s

on_train_batch_end: 1615853632.966221s

26624/50000 [==============>...............] - ETA: 23s - loss: 8.2711 - accuracy: 0.0561
on_train_batch_begin: 1615853632.966487s

26 step training time: 0.314984s

on_train_batch_end: 1615853633.285619s

27648/50000 [===============>..............] - ETA: 21s - loss: 8.2323 - accuracy: 0.0574
on_train_batch_begin: 1615853633.285934s

27 step training time: 0.319448s

on_train_batch_end: 1615853633.604791s

28672/50000 [================>.............] - ETA: 19s - loss: 8.2030 - accuracy: 0.0586
on_train_batch_begin: 1615853633.605060s

28 step training time: 0.319125s

on_train_batch_end: 1615853633.924971s

29696/50000 [================>.............] - ETA: 18s - loss: 8.1695 - accuracy: 0.0595
on_train_batch_begin: 1615853633.925243s

29 step training time: 0.320183s

on_train_batch_end: 1615853634.243188s

30720/50000 [=================>............] - ETA: 17s - loss: 8.1366 - accuracy: 0.0601
on_train_batch_begin: 1615853634.243671s

30 step training time: 0.318428s

on_train_batch_end: 1615853634.562665s

31744/50000 [==================>...........] - ETA: 16s - loss: 8.1073 - accuracy: 0.0610
on_train_batch_begin: 1615853634.562961s

31 step training time: 0.319290s

on_train_batch_end: 1615853634.871953s

32768/50000 [==================>...........] - ETA: 14s - loss: 8.0822 - accuracy: 0.0615
on_train_batch_begin: 1615853634.872229s

32 step training time: 0.309268s

on_train_batch_end: 1615853635.189304s

33792/50000 [===================>..........] - ETA: 13s - loss: 8.0511 - accuracy: 0.0626
on_train_batch_begin: 1615853635.189591s

33 step training time: 0.317362s

on_train_batch_end: 1615853635.508755s

34816/50000 [===================>..........] - ETA: 12s - loss: 8.0220 - accuracy: 0.0635
on_train_batch_begin: 1615853635.509035s

34 step training time: 0.319444s

on_train_batch_end: 1615853635.822212s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.9925 - accuracy: 0.0643
on_train_batch_begin: 1615853635.822478s

35 step training time: 0.313443s

on_train_batch_end: 1615853636.141323s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.9606 - accuracy: 0.0652
on_train_batch_begin: 1615853636.141617s

36 step training time: 0.319139s

on_train_batch_end: 1615853636.452888s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.9318 - accuracy: 0.0658 
on_train_batch_begin: 1615853636.453191s

37 step training time: 0.311574s

on_train_batch_end: 1615853636.773436s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.9065 - accuracy: 0.0660
on_train_batch_begin: 1615853636.773725s

38 step training time: 0.320533s

on_train_batch_end: 1615853637.088486s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.8801 - accuracy: 0.0668
on_train_batch_begin: 1615853637.088741s

39 step training time: 0.315017s

on_train_batch_end: 1615853637.404144s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.8548 - accuracy: 0.0673
on_train_batch_begin: 1615853637.404395s

40 step training time: 0.315654s

on_train_batch_end: 1615853637.719887s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.8296 - accuracy: 0.0680
on_train_batch_begin: 1615853637.720154s

41 step training time: 0.315759s

on_train_batch_end: 1615853638.035182s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.8058 - accuracy: 0.0684
on_train_batch_begin: 1615853638.035452s

42 step training time: 0.315299s

on_train_batch_end: 1615853638.353318s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.7820 - accuracy: 0.0689
on_train_batch_begin: 1615853638.353619s

43 step training time: 0.318167s

on_train_batch_end: 1615853638.666051s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.7605 - accuracy: 0.0691
on_train_batch_begin: 1615853638.666314s

44 step training time: 0.312695s

on_train_batch_end: 1615853638.983990s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.7407 - accuracy: 0.0693
on_train_batch_begin: 1615853638.984231s

45 step training time: 0.317917s

on_train_batch_end: 1615853639.296180s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.7194 - accuracy: 0.0700
on_train_batch_begin: 1615853639.296446s

46 step training time: 0.312215s

on_train_batch_end: 1615853639.612521s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.6977 - accuracy: 0.0705
on_train_batch_begin: 1615853639.612812s

47 step training time: 0.316366s

on_train_batch_end: 1615853639.923765s

49152/50000 [============================>.] - ETA: 0s - loss: 7.6763 - accuracy: 0.0708
on_train_batch_begin: 1615853639.924050s

48 step training time: 0.311238s

on_train_batch_end: 1615853645.488008s

on_test_batch_begin: 1615853645.678838s

49 step training time: 5.754789s

on_epoch_end: 1615853650.164070s

Validation time: 4.485217s

Real time: 1615853650.164070s

Epoch time: 43.43346095085144s

50000/50000 [==============================] - 43s 869us/sample - loss: 7.6584 - accuracy: 0.0710 - val_loss: 9204.5607 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615853650.164271s

Real time: 1615853650.1642768
Epoch 2/5

on_train_batch_begin: 1615853650.167729s

on_train_batch_end: 1615853650.487637s

 1024/50000 [..............................] - ETA: 15s - loss: 6.6481 - accuracy: 0.0840
on_train_batch_begin: 1615853650.487898s

1 step training time: 0.320169s

on_train_batch_end: 1615853650.799646s

 2048/50000 [>.............................] - ETA: 14s - loss: 6.6390 - accuracy: 0.0826
on_train_batch_begin: 1615853650.799903s

2 step training time: 0.312004s

on_train_batch_end: 1615853651.116689s

 3072/50000 [>.............................] - ETA: 14s - loss: 6.6245 - accuracy: 0.0798
on_train_batch_begin: 1615853651.116922s

3 step training time: 0.317019s

on_train_batch_end: 1615853651.430568s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.5976 - accuracy: 0.0844
on_train_batch_begin: 1615853651.430823s

4 step training time: 0.313901s

on_train_batch_end: 1615853651.748544s

 5120/50000 [==>...........................] - ETA: 13s - loss: 6.5616 - accuracy: 0.0908
on_train_batch_begin: 1615853651.748795s

5 step training time: 0.317972s

on_train_batch_end: 1615853652.068769s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.5418 - accuracy: 0.0920
on_train_batch_begin: 1615853652.069030s

6 step training time: 0.320235s

on_train_batch_end: 1615853652.382634s

 7168/50000 [===>..........................] - ETA: 13s - loss: 6.5451 - accuracy: 0.0894
on_train_batch_begin: 1615853652.382908s

7 step training time: 0.313879s

on_train_batch_end: 1615853652.699948s

 8192/50000 [===>..........................] - ETA: 12s - loss: 6.5479 - accuracy: 0.0890
on_train_batch_begin: 1615853652.700192s

8 step training time: 0.317284s

on_train_batch_end: 1615853653.021945s

 9216/50000 [====>.........................] - ETA: 12s - loss: 6.5553 - accuracy: 0.0877
on_train_batch_begin: 1615853653.022200s

9 step training time: 0.322008s

on_train_batch_end: 1615853653.338704s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.5438 - accuracy: 0.0881
on_train_batch_begin: 1615853653.338965s

10 step training time: 0.316765s

on_train_batch_end: 1615853653.657534s

11264/50000 [=====>........................] - ETA: 12s - loss: 6.5373 - accuracy: 0.0878
on_train_batch_begin: 1615853653.657818s

11 step training time: 0.318853s

on_train_batch_end: 1615853653.976180s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.5231 - accuracy: 0.0883
on_train_batch_begin: 1615853653.976431s

12 step training time: 0.318613s

on_train_batch_end: 1615853654.291771s

13312/50000 [======>.......................] - ETA: 11s - loss: 6.5200 - accuracy: 0.0876
on_train_batch_begin: 1615853654.292024s

13 step training time: 0.315593s

on_train_batch_end: 1615853654.609549s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.5219 - accuracy: 0.0868
on_train_batch_begin: 1615853654.609847s

14 step training time: 0.317823s

on_train_batch_end: 1615853654.930007s

15360/50000 [========>.....................] - ETA: 10s - loss: 6.5285 - accuracy: 0.0861
on_train_batch_begin: 1615853654.930305s

15 step training time: 0.320459s

on_train_batch_end: 1615853655.247175s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.5268 - accuracy: 0.0859
on_train_batch_begin: 1615853655.247439s

16 step training time: 0.317134s

on_train_batch_end: 1615853655.562337s

17408/50000 [=========>....................] - ETA: 10s - loss: 6.5237 - accuracy: 0.0852
on_train_batch_begin: 1615853655.562582s

17 step training time: 0.315143s

on_train_batch_end: 1615853655.885036s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.5201 - accuracy: 0.0849 
on_train_batch_begin: 1615853655.885310s

18 step training time: 0.322727s

on_train_batch_end: 1615853656.208198s

19456/50000 [==========>...................] - ETA: 9s - loss: 6.5102 - accuracy: 0.0848
on_train_batch_begin: 1615853656.208462s

19 step training time: 0.323152s

on_train_batch_end: 1615853656.522960s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.5063 - accuracy: 0.0847
on_train_batch_begin: 1615853656.523229s

20 step training time: 0.314768s

on_train_batch_end: 1615853656.837880s

21504/50000 [===========>..................] - ETA: 8s - loss: 6.4974 - accuracy: 0.0852
on_train_batch_begin: 1615853656.838142s

21 step training time: 0.314912s

on_train_batch_end: 1615853657.156683s

22528/50000 [============>.................] - ETA: 8s - loss: 6.4945 - accuracy: 0.0852
on_train_batch_begin: 1615853657.156936s

22 step training time: 0.318794s

on_train_batch_end: 1615853657.470026s

23552/50000 [=============>................] - ETA: 8s - loss: 6.4836 - accuracy: 0.0854
on_train_batch_begin: 1615853657.470280s

23 step training time: 0.313344s

on_train_batch_end: 1615853657.788671s

24576/50000 [=============>................] - ETA: 7s - loss: 6.4873 - accuracy: 0.0851
on_train_batch_begin: 1615853657.788919s

24 step training time: 0.318639s

on_train_batch_end: 1615853658.100057s

25600/50000 [==============>...............] - ETA: 7s - loss: 6.4758 - accuracy: 0.0851
on_train_batch_begin: 1615853658.100299s

25 step training time: 0.311380s

on_train_batch_end: 1615853658.419347s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.4659 - accuracy: 0.0848
on_train_batch_begin: 1615853658.419598s

26 step training time: 0.319299s

on_train_batch_end: 1615853658.734017s

27648/50000 [===============>..............] - ETA: 6s - loss: 6.4596 - accuracy: 0.0841
on_train_batch_begin: 1615853658.734262s

27 step training time: 0.314663s

on_train_batch_end: 1615853659.050831s

28672/50000 [================>.............] - ETA: 6s - loss: 6.4538 - accuracy: 0.0840
on_train_batch_begin: 1615853659.051082s

28 step training time: 0.316820s

on_train_batch_end: 1615853659.366861s

29696/50000 [================>.............] - ETA: 6s - loss: 6.4493 - accuracy: 0.0831
on_train_batch_begin: 1615853659.367104s

29 step training time: 0.316022s

on_train_batch_end: 1615853659.680492s

30720/50000 [=================>............] - ETA: 5s - loss: 6.4391 - accuracy: 0.0829
on_train_batch_begin: 1615853659.680759s

30 step training time: 0.313655s

on_train_batch_end: 1615853660.000398s

31744/50000 [==================>...........] - ETA: 5s - loss: 6.4298 - accuracy: 0.0825
on_train_batch_begin: 1615853660.000702s

31 step training time: 0.319944s

on_train_batch_end: 1615853660.317274s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.4261 - accuracy: 0.0818
on_train_batch_begin: 1615853660.317593s

32 step training time: 0.316891s

on_train_batch_end: 1615853660.633673s

33792/50000 [===================>..........] - ETA: 5s - loss: 6.4178 - accuracy: 0.0816
on_train_batch_begin: 1615853660.633957s

33 step training time: 0.316364s

on_train_batch_end: 1615853660.948736s

34816/50000 [===================>..........] - ETA: 4s - loss: 6.4084 - accuracy: 0.0813
on_train_batch_begin: 1615853660.948989s

34 step training time: 0.315032s

on_train_batch_end: 1615853661.263788s

35840/50000 [====================>.........] - ETA: 4s - loss: 6.3991 - accuracy: 0.0810
on_train_batch_begin: 1615853661.264040s

35 step training time: 0.315051s

on_train_batch_end: 1615853661.582131s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.3868 - accuracy: 0.0808
on_train_batch_begin: 1615853661.582379s

36 step training time: 0.318339s

on_train_batch_end: 1615853661.894130s

37888/50000 [=====================>........] - ETA: 3s - loss: 6.3820 - accuracy: 0.0803
on_train_batch_begin: 1615853661.894386s

37 step training time: 0.312006s

on_train_batch_end: 1615853662.214454s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.3754 - accuracy: 0.0797
on_train_batch_begin: 1615853662.214743s

38 step training time: 0.320358s

on_train_batch_end: 1615853662.531785s

39936/50000 [======================>.......] - ETA: 3s - loss: 6.3653 - accuracy: 0.0795
on_train_batch_begin: 1615853662.532048s

39 step training time: 0.317305s

on_train_batch_end: 1615853662.845098s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.3568 - accuracy: 0.0790
on_train_batch_begin: 1615853662.845367s

40 step training time: 0.313318s

on_train_batch_end: 1615853663.163917s

41984/50000 [========================>.....] - ETA: 2s - loss: 6.3462 - accuracy: 0.0785
on_train_batch_begin: 1615853663.164185s

41 step training time: 0.318818s

on_train_batch_end: 1615853663.477058s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.3339 - accuracy: 0.0783
on_train_batch_begin: 1615853663.477338s

42 step training time: 0.313153s

on_train_batch_end: 1615853663.795874s

44032/50000 [=========================>....] - ETA: 1s - loss: 6.3228 - accuracy: 0.0777
on_train_batch_begin: 1615853663.796129s

43 step training time: 0.318791s

on_train_batch_end: 1615853664.115650s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.3094 - accuracy: 0.0770
on_train_batch_begin: 1615853664.115912s

44 step training time: 0.319783s

on_train_batch_end: 1615853664.429342s

46080/50000 [==========================>...] - ETA: 1s - loss: 6.2961 - accuracy: 0.0765
on_train_batch_begin: 1615853664.429581s

45 step training time: 0.313669s

on_train_batch_end: 1615853664.746769s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.2843 - accuracy: 0.0759
on_train_batch_begin: 1615853664.747036s

46 step training time: 0.317456s

on_train_batch_end: 1615853665.061488s

48128/50000 [===========================>..] - ETA: 0s - loss: 6.2684 - accuracy: 0.0755
on_train_batch_begin: 1615853665.061802s

47 step training time: 0.314766s

on_train_batch_end: 1615853665.378600s

49152/50000 [============================>.] - ETA: 0s - loss: 6.2508 - accuracy: 0.0752
on_train_batch_begin: 1615853665.378877s

48 step training time: 0.317075s

on_train_batch_end: 1615853665.643268s

on_test_batch_begin: 1615853665.656383s

49 step training time: 0.277506s

on_epoch_end: 1615853666.436051s

Validation time: 0.779657s

Real time: 1615853666.436051s

Epoch time: 16.271790504455566s

50000/50000 [==============================] - 16s 325us/sample - loss: 6.2362 - accuracy: 0.0749 - val_loss: 7.6246 - val_accuracy: 0.0999

on_epoch_begin: 1615853666.436249s

Real time: 1615853666.436256
Epoch 3/5

on_train_batch_begin: 1615853666.439566s

on_train_batch_end: 1615853666.756626s

 1024/50000 [..............................] - ETA: 15s - loss: 5.3268 - accuracy: 0.0624
on_train_batch_begin: 1615853666.756883s

1 step training time: 0.317317s

on_train_batch_end: 1615853667.074239s

 2048/50000 [>.............................] - ETA: 14s - loss: 5.3269 - accuracy: 0.0644
on_train_batch_begin: 1615853667.074476s

2 step training time: 0.317593s

on_train_batch_end: 1615853667.389055s

 3072/50000 [>.............................] - ETA: 14s - loss: 5.3117 - accuracy: 0.0650
on_train_batch_begin: 1615853667.389302s

3 step training time: 0.314825s

on_train_batch_end: 1615853667.708647s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.2803 - accuracy: 0.0658
on_train_batch_begin: 1615853667.709032s

4 step training time: 0.319731s

on_train_batch_end: 1615853668.023927s

 5120/50000 [==>...........................] - ETA: 13s - loss: 5.2637 - accuracy: 0.0672
on_train_batch_begin: 1615853668.024189s

5 step training time: 0.315157s

on_train_batch_end: 1615853668.340822s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.2368 - accuracy: 0.0681
on_train_batch_begin: 1615853668.341094s

6 step training time: 0.316905s

on_train_batch_end: 1615853668.660766s

 7168/50000 [===>..........................] - ETA: 13s - loss: 5.2203 - accuracy: 0.0692
on_train_batch_begin: 1615853668.661034s

7 step training time: 0.319941s

on_train_batch_end: 1615853668.977282s

 8192/50000 [===>..........................] - ETA: 12s - loss: 5.2001 - accuracy: 0.0700
on_train_batch_begin: 1615853668.977543s

8 step training time: 0.316509s

on_train_batch_end: 1615853669.295268s

 9216/50000 [====>.........................] - ETA: 12s - loss: 5.1916 - accuracy: 0.0698
on_train_batch_begin: 1615853669.295526s

9 step training time: 0.317983s

on_train_batch_end: 1615853669.612842s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.1702 - accuracy: 0.0694
on_train_batch_begin: 1615853669.613098s

10 step training time: 0.317572s

on_train_batch_end: 1615853669.928639s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.1430 - accuracy: 0.0692
on_train_batch_begin: 1615853669.928886s

11 step training time: 0.315788s

on_train_batch_end: 1615853670.245334s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.1266 - accuracy: 0.0688
on_train_batch_begin: 1615853670.245631s

12 step training time: 0.316745s

on_train_batch_end: 1615853670.565959s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.0959 - accuracy: 0.0689
on_train_batch_begin: 1615853670.566240s

13 step training time: 0.320608s

on_train_batch_end: 1615853670.881694s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.0759 - accuracy: 0.0690
on_train_batch_begin: 1615853670.881981s

14 step training time: 0.315742s

on_train_batch_end: 1615853671.201271s

15360/50000 [========>.....................] - ETA: 10s - loss: 5.0546 - accuracy: 0.0686
on_train_batch_begin: 1615853671.201536s

15 step training time: 0.319555s

on_train_batch_end: 1615853671.520742s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.0119 - accuracy: 0.0692
on_train_batch_begin: 1615853671.521008s

16 step training time: 0.319472s

on_train_batch_end: 1615853671.836955s

17408/50000 [=========>....................] - ETA: 10s - loss: 4.9881 - accuracy: 0.0695
on_train_batch_begin: 1615853671.837243s

17 step training time: 0.316235s

on_train_batch_end: 1615853672.156778s

18432/50000 [==========>...................] - ETA: 9s - loss: 4.9757 - accuracy: 0.0697 
on_train_batch_begin: 1615853672.157060s

18 step training time: 0.319817s

on_train_batch_end: 1615853672.475064s

19456/50000 [==========>...................] - ETA: 9s - loss: 4.9522 - accuracy: 0.0701
on_train_batch_begin: 1615853672.475348s

19 step training time: 0.318288s

on_train_batch_end: 1615853672.791316s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.9314 - accuracy: 0.0702
on_train_batch_begin: 1615853672.791586s

20 step training time: 0.316238s

on_train_batch_end: 1615853673.117210s

21504/50000 [===========>..................] - ETA: 8s - loss: 4.9129 - accuracy: 0.0703
on_train_batch_begin: 1615853673.117472s

21 step training time: 0.325886s

on_train_batch_end: 1615853673.434189s

22528/50000 [============>.................] - ETA: 8s - loss: 4.8926 - accuracy: 0.0705
on_train_batch_begin: 1615853673.434451s

22 step training time: 0.316979s

on_train_batch_end: 1615853673.754451s

23552/50000 [=============>................] - ETA: 8s - loss: 4.8734 - accuracy: 0.0705
on_train_batch_begin: 1615853673.754930s

23 step training time: 0.320479s

on_train_batch_end: 1615853674.080175s

24576/50000 [=============>................] - ETA: 7s - loss: 4.8614 - accuracy: 0.0707
on_train_batch_begin: 1615853674.080466s

24 step training time: 0.325536s

on_train_batch_end: 1615853674.402126s

25600/50000 [==============>...............] - ETA: 7s - loss: 4.8462 - accuracy: 0.0709
on_train_batch_begin: 1615853674.402393s

25 step training time: 0.321927s

on_train_batch_end: 1615853674.715250s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.8281 - accuracy: 0.0712
on_train_batch_begin: 1615853674.715521s

26 step training time: 0.313128s

on_train_batch_end: 1615853675.034353s

27648/50000 [===============>..............] - ETA: 6s - loss: 4.8023 - accuracy: 0.0717
on_train_batch_begin: 1615853675.034626s

27 step training time: 0.319105s

on_train_batch_end: 1615853675.353617s

28672/50000 [================>.............] - ETA: 6s - loss: 4.7866 - accuracy: 0.0718
on_train_batch_begin: 1615853675.353932s

28 step training time: 0.319306s

on_train_batch_end: 1615853675.669593s

29696/50000 [================>.............] - ETA: 6s - loss: 4.7568 - accuracy: 0.0721
on_train_batch_begin: 1615853675.669885s

29 step training time: 0.315953s

on_train_batch_end: 1615853675.987062s

30720/50000 [=================>............] - ETA: 5s - loss: 4.7265 - accuracy: 0.0727
on_train_batch_begin: 1615853675.987320s

30 step training time: 0.317435s

on_train_batch_end: 1615853676.300683s

31744/50000 [==================>...........] - ETA: 5s - loss: 4.6951 - accuracy: 0.0732
on_train_batch_begin: 1615853676.300922s

31 step training time: 0.313602s

on_train_batch_end: 1615853676.617434s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.6662 - accuracy: 0.0736
on_train_batch_begin: 1615853676.617671s

32 step training time: 0.316749s

on_train_batch_end: 1615853676.938032s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.6414 - accuracy: 0.0740
on_train_batch_begin: 1615853676.938286s

33 step training time: 0.320615s

on_train_batch_end: 1615853677.252043s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.6194 - accuracy: 0.0744
on_train_batch_begin: 1615853677.252295s

34 step training time: 0.314009s

on_train_batch_end: 1615853677.570803s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.5907 - accuracy: 0.0747
on_train_batch_begin: 1615853677.571059s

35 step training time: 0.318764s

on_train_batch_end: 1615853677.884038s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.5710 - accuracy: 0.0750
on_train_batch_begin: 1615853677.884298s

36 step training time: 0.313239s

on_train_batch_end: 1615853678.202496s

37888/50000 [=====================>........] - ETA: 3s - loss: 4.5490 - accuracy: 0.0754
on_train_batch_begin: 1615853678.202737s

37 step training time: 0.318438s

on_train_batch_end: 1615853678.519421s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.5180 - accuracy: 0.0758
on_train_batch_begin: 1615853678.519677s

38 step training time: 0.316940s

on_train_batch_end: 1615853678.834274s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.4881 - accuracy: 0.0762
on_train_batch_begin: 1615853678.834532s

39 step training time: 0.314856s

on_train_batch_end: 1615853679.155373s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.4558 - accuracy: 0.0767
on_train_batch_begin: 1615853679.155616s

40 step training time: 0.321084s

on_train_batch_end: 1615853679.473583s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.4181 - accuracy: 0.0772
on_train_batch_begin: 1615853679.473831s

41 step training time: 0.318215s

on_train_batch_end: 1615853679.790232s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.3854 - accuracy: 0.0776
on_train_batch_begin: 1615853679.790486s

42 step training time: 0.316654s

on_train_batch_end: 1615853680.111852s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.3487 - accuracy: 0.0780
on_train_batch_begin: 1615853680.112133s

43 step training time: 0.321648s

on_train_batch_end: 1615853680.426677s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.3154 - accuracy: 0.0785
on_train_batch_begin: 1615853680.426967s

44 step training time: 0.314834s

on_train_batch_end: 1615853680.743982s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.2802 - accuracy: 0.0789
on_train_batch_begin: 1615853680.744255s

45 step training time: 0.317288s

on_train_batch_end: 1615853681.062243s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.2465 - accuracy: 0.0793
on_train_batch_begin: 1615853681.062509s

46 step training time: 0.318253s

on_train_batch_end: 1615853681.389719s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.2092 - accuracy: 0.0798
on_train_batch_begin: 1615853681.390016s

47 step training time: 0.327508s

on_train_batch_end: 1615853681.706586s

49152/50000 [============================>.] - ETA: 0s - loss: 4.1765 - accuracy: 0.0802
on_train_batch_begin: 1615853681.706836s

48 step training time: 0.316820s

on_train_batch_end: 1615853681.971429s

on_test_batch_begin: 1615853681.981279s

49 step training time: 0.274442s

on_epoch_end: 1615853682.757125s

Validation time: 0.775836s

Real time: 1615853682.757125s

Epoch time: 16.32088541984558s

50000/50000 [==============================] - 16s 326us/sample - loss: 4.1455 - accuracy: 0.0805 - val_loss: 6.9986 - val_accuracy: 0.0999

on_epoch_begin: 1615853682.757308s

Real time: 1615853682.7573135
Epoch 4/5

on_train_batch_begin: 1615853682.760625s

on_train_batch_end: 1615853683.080633s

 1024/50000 [..............................] - ETA: 15s - loss: 2.4458 - accuracy: 0.0991
on_train_batch_begin: 1615853683.080884s

1 step training time: 0.320259s

on_train_batch_end: 1615853683.398747s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.3815 - accuracy: 0.0999
on_train_batch_begin: 1615853683.399003s

2 step training time: 0.318119s

on_train_batch_end: 1615853683.714571s

 3072/50000 [>.............................] - ETA: 14s - loss: 2.3985 - accuracy: 0.0996
on_train_batch_begin: 1615853683.714862s

3 step training time: 0.315859s

on_train_batch_end: 1615853684.035819s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.3144 - accuracy: 0.1001
on_train_batch_begin: 1615853684.036094s

4 step training time: 0.321232s

on_train_batch_end: 1615853684.358005s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.2992 - accuracy: 0.0999
on_train_batch_begin: 1615853684.358267s

5 step training time: 0.322173s

on_train_batch_end: 1615853684.671366s

 6144/50000 [==>...........................] - ETA: 13s - loss: 2.2769 - accuracy: 0.0999
on_train_batch_begin: 1615853684.671636s

6 step training time: 0.313369s

on_train_batch_end: 1615853684.991331s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.2203 - accuracy: 0.0998
on_train_batch_begin: 1615853684.991592s

7 step training time: 0.319956s

on_train_batch_end: 1615853685.312624s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.2128 - accuracy: 0.0999
on_train_batch_begin: 1615853685.312886s

8 step training time: 0.321295s

on_train_batch_end: 1615853685.626540s

 9216/50000 [====>.........................] - ETA: 12s - loss: 2.2120 - accuracy: 0.0998
on_train_batch_begin: 1615853685.626833s

9 step training time: 0.313946s

on_train_batch_end: 1615853685.944538s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.1923 - accuracy: 0.0999
on_train_batch_begin: 1615853685.944849s

10 step training time: 0.318016s

on_train_batch_end: 1615853686.259824s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.1759 - accuracy: 0.1000
on_train_batch_begin: 1615853686.260093s

11 step training time: 0.315244s

on_train_batch_end: 1615853686.578864s

12288/50000 [======>.......................] - ETA: 11s - loss: 2.1564 - accuracy: 0.1000
on_train_batch_begin: 1615853686.579139s

12 step training time: 0.319046s

on_train_batch_end: 1615853686.898978s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.1314 - accuracy: 0.1000
on_train_batch_begin: 1615853686.899251s

13 step training time: 0.320112s

on_train_batch_end: 1615853687.219602s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.1336 - accuracy: 0.0999
on_train_batch_begin: 1615853687.219867s

14 step training time: 0.320616s

on_train_batch_end: 1615853687.536114s

15360/50000 [========>.....................] - ETA: 10s - loss: 2.1176 - accuracy: 0.0999
on_train_batch_begin: 1615853687.536382s

15 step training time: 0.316515s

on_train_batch_end: 1615853687.859111s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.0912 - accuracy: 0.0999
on_train_batch_begin: 1615853687.859375s

16 step training time: 0.322994s

on_train_batch_end: 1615853688.177361s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.0820 - accuracy: 0.0999
on_train_batch_begin: 1615853688.177611s

17 step training time: 0.318236s

on_train_batch_end: 1615853688.492435s

18432/50000 [==========>...................] - ETA: 9s - loss: 2.0653 - accuracy: 0.1000 
on_train_batch_begin: 1615853688.492676s

18 step training time: 0.315065s

on_train_batch_end: 1615853688.811568s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.0595 - accuracy: 0.1000
on_train_batch_begin: 1615853688.811802s

19 step training time: 0.319126s

on_train_batch_end: 1615853689.132353s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.0468 - accuracy: 0.1000
on_train_batch_begin: 1615853689.132623s

20 step training time: 0.320822s

on_train_batch_end: 1615853689.449359s

21504/50000 [===========>..................] - ETA: 8s - loss: 2.0397 - accuracy: 0.1000
on_train_batch_begin: 1615853689.449619s

21 step training time: 0.316996s

on_train_batch_end: 1615853689.769763s

22528/50000 [============>.................] - ETA: 8s - loss: 2.0333 - accuracy: 0.1000
on_train_batch_begin: 1615853689.770056s

22 step training time: 0.320437s

on_train_batch_end: 1615853690.088132s

23552/50000 [=============>................] - ETA: 8s - loss: 2.0094 - accuracy: 0.1000
on_train_batch_begin: 1615853690.088390s

23 step training time: 0.318333s

on_train_batch_end: 1615853690.403992s

24576/50000 [=============>................] - ETA: 7s - loss: 1.9964 - accuracy: 0.1000
on_train_batch_begin: 1615853690.404254s

24 step training time: 0.315864s

on_train_batch_end: 1615853690.721440s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.9846 - accuracy: 0.1000
on_train_batch_begin: 1615853690.721736s

25 step training time: 0.317482s

on_train_batch_end: 1615853691.042346s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.9675 - accuracy: 0.1000
on_train_batch_begin: 1615853691.042626s

26 step training time: 0.320890s

on_train_batch_end: 1615853691.366851s

27648/50000 [===============>..............] - ETA: 6s - loss: 1.9581 - accuracy: 0.1000
on_train_batch_begin: 1615853691.367111s

27 step training time: 0.324485s

on_train_batch_end: 1615853691.691735s

28672/50000 [================>.............] - ETA: 6s - loss: 1.9475 - accuracy: 0.1001
on_train_batch_begin: 1615853691.692003s

28 step training time: 0.324891s

on_train_batch_end: 1615853692.009727s

29696/50000 [================>.............] - ETA: 6s - loss: 1.9349 - accuracy: 0.1000
on_train_batch_begin: 1615853692.010008s

29 step training time: 0.318006s

on_train_batch_end: 1615853692.327694s

30720/50000 [=================>............] - ETA: 6s - loss: 1.9176 - accuracy: 0.1000
on_train_batch_begin: 1615853692.327948s

30 step training time: 0.317940s

on_train_batch_end: 1615853692.648775s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.9055 - accuracy: 0.1000
on_train_batch_begin: 1615853692.649021s

31 step training time: 0.321073s

on_train_batch_end: 1615853692.970224s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.8976 - accuracy: 0.1001
on_train_batch_begin: 1615853692.970469s

32 step training time: 0.321447s

on_train_batch_end: 1615853693.286776s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.8825 - accuracy: 0.1001
on_train_batch_begin: 1615853693.287019s

33 step training time: 0.316550s

on_train_batch_end: 1615853693.604126s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.8710 - accuracy: 0.1001
on_train_batch_begin: 1615853693.604378s

34 step training time: 0.317359s

on_train_batch_end: 1615853693.926368s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.8598 - accuracy: 0.1001
on_train_batch_begin: 1615853693.926636s

35 step training time: 0.322258s

on_train_batch_end: 1615853694.250195s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.8421 - accuracy: 0.1001
on_train_batch_begin: 1615853694.250438s

36 step training time: 0.323802s

on_train_batch_end: 1615853694.562805s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.8316 - accuracy: 0.1001
on_train_batch_begin: 1615853694.563045s

37 step training time: 0.312608s

on_train_batch_end: 1615853694.882265s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.8221 - accuracy: 0.1001
on_train_batch_begin: 1615853694.882500s

38 step training time: 0.319455s

on_train_batch_end: 1615853695.199203s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.8142 - accuracy: 0.1001
on_train_batch_begin: 1615853695.199459s

39 step training time: 0.316959s

on_train_batch_end: 1615853695.515584s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.8074 - accuracy: 0.1001
on_train_batch_begin: 1615853695.515850s

40 step training time: 0.316391s

on_train_batch_end: 1615853695.836958s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.7988 - accuracy: 0.1001
on_train_batch_begin: 1615853695.837252s

41 step training time: 0.321402s

on_train_batch_end: 1615853696.158362s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.7904 - accuracy: 0.1001
on_train_batch_begin: 1615853696.158625s

42 step training time: 0.321372s

on_train_batch_end: 1615853696.472015s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.7788 - accuracy: 0.1001
on_train_batch_begin: 1615853696.472275s

43 step training time: 0.313650s

on_train_batch_end: 1615853696.791011s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.7681 - accuracy: 0.1001
on_train_batch_begin: 1615853696.791278s

44 step training time: 0.319003s

on_train_batch_end: 1615853697.114006s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.7606 - accuracy: 0.1001
on_train_batch_begin: 1615853697.114263s

45 step training time: 0.322985s

on_train_batch_end: 1615853697.434560s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7521 - accuracy: 0.1001
on_train_batch_begin: 1615853697.434833s

46 step training time: 0.320570s

on_train_batch_end: 1615853697.751707s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7456 - accuracy: 0.1001
on_train_batch_begin: 1615853697.751972s

47 step training time: 0.317139s

on_train_batch_end: 1615853698.069866s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7399 - accuracy: 0.1002
on_train_batch_begin: 1615853698.070145s

48 step training time: 0.318173s

on_train_batch_end: 1615853698.334728s

on_test_batch_begin: 1615853698.344308s

49 step training time: 0.274163s

on_epoch_end: 1615853699.120830s

Validation time: 0.776511s

Real time: 1615853699.120830s

Epoch time: 16.363532304763794s

50000/50000 [==============================] - 16s 327us/sample - loss: 1.7320 - accuracy: 0.1002 - val_loss: 7.2956 - val_accuracy: 0.0999

on_epoch_begin: 1615853699.121011s

Real time: 1615853699.1210153
Epoch 5/5

on_train_batch_begin: 1615853699.124337s

on_train_batch_end: 1615853699.444938s

 1024/50000 [..............................] - ETA: 15s - loss: 1.0901 - accuracy: 0.1000
on_train_batch_begin: 1615853699.445183s

1 step training time: 0.320845s

on_train_batch_end: 1615853699.767432s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.1238 - accuracy: 0.1002
on_train_batch_begin: 1615853699.767672s

2 step training time: 0.322490s

on_train_batch_end: 1615853700.079655s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.1422 - accuracy: 0.1003
on_train_batch_begin: 1615853700.079944s

3 step training time: 0.312272s

on_train_batch_end: 1615853700.403532s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.1322 - accuracy: 0.1002
on_train_batch_begin: 1615853700.403822s

4 step training time: 0.323878s

on_train_batch_end: 1615853700.725127s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.1353 - accuracy: 0.1001
on_train_batch_begin: 1615853700.725427s

5 step training time: 0.321606s

on_train_batch_end: 1615853701.046074s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.1367 - accuracy: 0.1002
on_train_batch_begin: 1615853701.046363s

6 step training time: 0.320935s

on_train_batch_end: 1615853701.360513s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.1306 - accuracy: 0.1002
on_train_batch_begin: 1615853701.360777s

7 step training time: 0.314414s

on_train_batch_end: 1615853701.681364s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.1081 - accuracy: 0.1002
on_train_batch_begin: 1615853701.681669s

8 step training time: 0.320892s

on_train_batch_end: 1615853702.004178s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.1176 - accuracy: 0.1002
on_train_batch_begin: 1615853702.004466s

9 step training time: 0.322798s

on_train_batch_end: 1615853702.325842s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.1201 - accuracy: 0.1002
on_train_batch_begin: 1615853702.326155s

10 step training time: 0.321689s

on_train_batch_end: 1615853702.648788s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.1230 - accuracy: 0.1003
on_train_batch_begin: 1615853702.649084s

11 step training time: 0.322929s

on_train_batch_end: 1615853702.963726s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.1205 - accuracy: 0.1003
on_train_batch_begin: 1615853702.963990s

12 step training time: 0.314907s

on_train_batch_end: 1615853703.285084s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.1216 - accuracy: 0.1003
on_train_batch_begin: 1615853703.285345s

13 step training time: 0.321355s

on_train_batch_end: 1615853703.608516s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.1213 - accuracy: 0.1003
on_train_batch_begin: 1615853703.608830s

14 step training time: 0.323485s

on_train_batch_end: 1615853703.928914s

15360/50000 [========>.....................] - ETA: 10s - loss: 1.1316 - accuracy: 0.1003
on_train_batch_begin: 1615853703.929184s

15 step training time: 0.320353s

on_train_batch_end: 1615853704.251973s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.1242 - accuracy: 0.1003
on_train_batch_begin: 1615853704.252268s

16 step training time: 0.323084s

on_train_batch_end: 1615853704.576504s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.1158 - accuracy: 0.1003
on_train_batch_begin: 1615853704.576930s

17 step training time: 0.324662s

on_train_batch_end: 1615853704.902529s

18432/50000 [==========>...................] - ETA: 9s - loss: 1.1166 - accuracy: 0.1003 
on_train_batch_begin: 1615853704.902844s

18 step training time: 0.325914s

on_train_batch_end: 1615853705.226713s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.1091 - accuracy: 0.1003
on_train_batch_begin: 1615853705.227125s

19 step training time: 0.324281s

on_train_batch_end: 1615853705.549575s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.1049 - accuracy: 0.1003
on_train_batch_begin: 1615853705.549900s

20 step training time: 0.322775s

on_train_batch_end: 1615853705.863141s

21504/50000 [===========>..................] - ETA: 8s - loss: 1.1027 - accuracy: 0.1003
on_train_batch_begin: 1615853705.863440s

21 step training time: 0.313541s

on_train_batch_end: 1615853706.182708s

22528/50000 [============>.................] - ETA: 8s - loss: 1.0979 - accuracy: 0.1003
on_train_batch_begin: 1615853706.182990s

22 step training time: 0.319549s

on_train_batch_end: 1615853706.504380s

23552/50000 [=============>................] - ETA: 8s - loss: 1.1012 - accuracy: 0.1003
on_train_batch_begin: 1615853706.504654s

23 step training time: 0.321664s

on_train_batch_end: 1615853706.828331s

24576/50000 [=============>................] - ETA: 7s - loss: 1.1083 - accuracy: 0.1003
on_train_batch_begin: 1615853706.828596s

24 step training time: 0.323942s

on_train_batch_end: 1615853707.146298s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.1010 - accuracy: 0.1003
on_train_batch_begin: 1615853707.146567s

25 step training time: 0.317972s

on_train_batch_end: 1615853707.463532s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.0927 - accuracy: 0.1003
on_train_batch_begin: 1615853707.463802s

26 step training time: 0.317234s

on_train_batch_end: 1615853707.783939s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.0886 - accuracy: 0.1003
on_train_batch_begin: 1615853707.784226s

27 step training time: 0.320424s

on_train_batch_end: 1615853708.108411s

28672/50000 [================>.............] - ETA: 6s - loss: 1.0891 - accuracy: 0.1003
on_train_batch_begin: 1615853708.108688s

28 step training time: 0.324462s

on_train_batch_end: 1615853708.429423s

29696/50000 [================>.............] - ETA: 6s - loss: 1.0896 - accuracy: 0.1003
on_train_batch_begin: 1615853708.429697s

29 step training time: 0.321009s

on_train_batch_end: 1615853708.753922s

30720/50000 [=================>............] - ETA: 6s - loss: 1.0929 - accuracy: 0.1003
on_train_batch_begin: 1615853708.754214s

30 step training time: 0.324517s

on_train_batch_end: 1615853709.071431s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.0883 - accuracy: 0.1003
on_train_batch_begin: 1615853709.071693s

31 step training time: 0.317480s

on_train_batch_end: 1615853709.389375s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.0840 - accuracy: 0.1003
on_train_batch_begin: 1615853709.389664s

32 step training time: 0.317971s

on_train_batch_end: 1615853709.711170s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.0857 - accuracy: 0.1003
on_train_batch_begin: 1615853709.711438s

33 step training time: 0.321774s

on_train_batch_end: 1615853710.034185s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.0813 - accuracy: 0.1003
on_train_batch_begin: 1615853710.034449s

34 step training time: 0.323010s

on_train_batch_end: 1615853710.356927s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.0782 - accuracy: 0.1003
on_train_batch_begin: 1615853710.357198s

35 step training time: 0.322749s

on_train_batch_end: 1615853710.675791s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.0769 - accuracy: 0.1003
on_train_batch_begin: 1615853710.676093s

36 step training time: 0.318895s

on_train_batch_end: 1615853710.992324s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.0717 - accuracy: 0.1003
on_train_batch_begin: 1615853710.992621s

37 step training time: 0.316528s

on_train_batch_end: 1615853711.313662s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.0703 - accuracy: 0.1003
on_train_batch_begin: 1615853711.313961s

38 step training time: 0.321340s

on_train_batch_end: 1615853711.636062s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.0724 - accuracy: 0.1003
on_train_batch_begin: 1615853711.636330s

39 step training time: 0.322369s

on_train_batch_end: 1615853711.956942s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.0706 - accuracy: 0.1003
on_train_batch_begin: 1615853711.957213s

40 step training time: 0.320883s

on_train_batch_end: 1615853712.270158s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.0724 - accuracy: 0.1003
on_train_batch_begin: 1615853712.270422s

41 step training time: 0.313209s

on_train_batch_end: 1615853712.591113s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.0754 - accuracy: 0.1003
on_train_batch_begin: 1615853712.591377s

42 step training time: 0.320956s

on_train_batch_end: 1615853712.913696s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.0721 - accuracy: 0.1003
on_train_batch_begin: 1615853712.913963s

43 step training time: 0.322585s

on_train_batch_end: 1615853713.239288s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.0716 - accuracy: 0.1003
on_train_batch_begin: 1615853713.239571s

44 step training time: 0.325608s

on_train_batch_end: 1615853713.561465s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.0694 - accuracy: 0.1003
on_train_batch_begin: 1615853713.561719s

45 step training time: 0.322148s

on_train_batch_end: 1615853713.887375s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.0684 - accuracy: 0.1003
on_train_batch_begin: 1615853713.887647s

46 step training time: 0.325928s

on_train_batch_end: 1615853714.209533s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.0705 - accuracy: 0.1003
on_train_batch_begin: 1615853714.209824s

47 step training time: 0.322177s

on_train_batch_end: 1615853714.534498s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0681 - accuracy: 0.1003
on_train_batch_begin: 1615853714.534761s

48 step training time: 0.324937s

on_train_batch_end: 1615853714.806899s

on_test_batch_begin: 1615853714.816483s

49 step training time: 0.281721s

on_epoch_end: 1615853715.591996s

Validation time: 0.775503s

Real time: 1615853715.591996s

Epoch time: 16.470997095108032s

50000/50000 [==============================] - 16s 329us/sample - loss: 1.0689 - accuracy: 0.1003 - val_loss: 7.1929 - val_accuracy: 0.1001
Tempo do fit: 112.25065231323242