wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:43
   139264/170498071 [..............................] - ETA: 1:36
   614400/170498071 [..............................] - ETA: 35s 
  1400832/170498071 [..............................] - ETA: 21s
  2334720/170498071 [..............................] - ETA: 16s
  3350528/170498071 [..............................] - ETA: 14s
  4431872/170498071 [..............................] - ETA: 12s
  5578752/170498071 [..............................] - ETA: 11s
  6889472/170498071 [>.............................] - ETA: 10s
  8314880/170498071 [>.............................] - ETA: 9s 
  9789440/170498071 [>.............................] - ETA: 8s
 11427840/170498071 [=>............................] - ETA: 8s
 13180928/170498071 [=>............................] - ETA: 7s
 14540800/170498071 [=>............................] - ETA: 7s
 15851520/170498071 [=>............................] - ETA: 7s
 17276928/170498071 [==>...........................] - ETA: 7s
 18735104/170498071 [==>...........................] - ETA: 6s
 20103168/170498071 [==>...........................] - ETA: 6s
 21520384/170498071 [==>...........................] - ETA: 6s
 22945792/170498071 [===>..........................] - ETA: 6s
 24371200/170498071 [===>..........................] - ETA: 6s
 25731072/170498071 [===>..........................] - ETA: 6s
 27172864/170498071 [===>..........................] - ETA: 6s
 28598272/170498071 [====>.........................] - ETA: 5s
 29966336/170498071 [====>.........................] - ETA: 5s
 31424512/170498071 [====>.........................] - ETA: 5s
 32759808/170498071 [====>.........................] - ETA: 5s
 34086912/170498071 [====>.........................] - ETA: 5s
 35381248/170498071 [=====>........................] - ETA: 5s
 36823040/170498071 [=====>........................] - ETA: 5s
 38133760/170498071 [=====>........................] - ETA: 5s
 39460864/170498071 [=====>........................] - ETA: 5s
 40706048/170498071 [======>.......................] - ETA: 5s
 42065920/170498071 [======>.......................] - ETA: 5s
 43425792/170498071 [======>.......................] - ETA: 5s
 44998656/170498071 [======>.......................] - ETA: 5s
 46489600/170498071 [=======>......................] - ETA: 4s
 47996928/170498071 [=======>......................] - ETA: 4s
 49487872/170498071 [=======>......................] - ETA: 4s
 50978816/170498071 [=======>......................] - ETA: 4s
 52895744/170498071 [========>.....................] - ETA: 4s
 55156736/170498071 [========>.....................] - ETA: 4s
 57581568/170498071 [=========>....................] - ETA: 4s
 60235776/170498071 [=========>....................] - ETA: 4s
 63119360/170498071 [==========>...................] - ETA: 3s
 65970176/170498071 [==========>...................] - ETA: 3s
 68804608/170498071 [===========>..................] - ETA: 3s
 71884800/170498071 [===========>..................] - ETA: 3s
 75046912/170498071 [============>.................] - ETA: 3s
 77553664/170498071 [============>.................] - ETA: 3s
 80486400/170498071 [=============>................] - ETA: 2s
 83025920/170498071 [=============>................] - ETA: 2s
 86138880/170498071 [==============>...............] - ETA: 2s
 89006080/170498071 [==============>...............] - ETA: 2s
 92020736/170498071 [===============>..............] - ETA: 2s
 95068160/170498071 [===============>..............] - ETA: 2s
 98246656/170498071 [================>.............] - ETA: 2s
101081088/170498071 [================>.............] - ETA: 1s
104325120/170498071 [=================>............] - ETA: 1s
107618304/170498071 [=================>............] - ETA: 1s
110813184/170498071 [==================>...........] - ETA: 1s
114106368/170498071 [===================>..........] - ETA: 1s
117399552/170498071 [===================>..........] - ETA: 1s
120676352/170498071 [====================>.........] - ETA: 1s
123953152/170498071 [====================>.........] - ETA: 1s
127246336/170498071 [=====================>........] - ETA: 1s
130465792/170498071 [=====================>........] - ETA: 1s
133701632/170498071 [======================>.......] - ETA: 0s
136921088/170498071 [=======================>......] - ETA: 0s
140156928/170498071 [=======================>......] - ETA: 0s
143400960/170498071 [========================>.....] - ETA: 0s
146620416/170498071 [========================>.....] - ETA: 0s
149880832/170498071 [=========================>....] - ETA: 0s
153083904/170498071 [=========================>....] - ETA: 0s
156352512/170498071 [==========================>...] - ETA: 0s
159580160/170498071 [===========================>..] - ETA: 0s
162865152/170498071 [===========================>..] - ETA: 0s
166158336/170498071 [============================>.] - ETA: 0s
169435136/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 4s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 12s
 3293184/94765736 [>.............................] - ETA: 1s 
10567680/94765736 [==>...........................] - ETA: 1s
17620992/94765736 [====>.........................] - ETA: 0s
26238976/94765736 [=======>......................] - ETA: 0s
28688384/94765736 [========>.....................] - ETA: 1s
37216256/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
38862848/94765736 [===========>..................] - ETA: 0s
42082304/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
50814976/94765736 [===============>..............] - ETA: 0s
60358656/94765736 [==================>...........] - ETA: 0s
63619072/94765736 [===================>..........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
74260480/94765736 [======================>.......] - ETA: 0s
76619776/94765736 [=======================>......] - ETA: 0s
81346560/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
86007808/94765736 [==========================>...] - ETA: 0s
87777280/94765736 [==========================>...] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.677708625793457
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598501629.286088s

Real time: 1598501629.2861063
Epoch 1/5

on_train_batch_begin: 1598501630.028494s

on_train_batch_end: 1598501648.634271s

 1024/50000 [..............................] - ETA: 15:25 - loss: 17.8055 - accuracy: 1.8120e-04
on_train_batch_begin: 1598501648.634870s

1 step training time: 18.606376s

on_train_batch_end: 1598501648.967640s

 2048/50000 [>.............................] - ETA: 7:40 - loss: 15.7355 - accuracy: 4.0007e-04 
on_train_batch_begin: 1598501648.967932s

2 step training time: 0.333061s

on_train_batch_end: 1598501649.301077s

 3072/50000 [>.............................] - ETA: 5:05 - loss: 13.7403 - accuracy: 3.9291e-04
on_train_batch_begin: 1598501649.301309s

3 step training time: 0.333377s

on_train_batch_end: 1598501649.631150s

 4096/50000 [=>............................] - ETA: 3:48 - loss: 12.4444 - accuracy: 6.4707e-04
on_train_batch_begin: 1598501649.631388s

4 step training time: 0.330080s

on_train_batch_end: 1598501649.960434s

 5120/50000 [==>...........................] - ETA: 3:01 - loss: 11.6107 - accuracy: 0.0015    
on_train_batch_begin: 1598501649.960671s

5 step training time: 0.329283s

on_train_batch_end: 1598501650.294943s

 6144/50000 [==>...........................] - ETA: 2:29 - loss: 11.0233 - accuracy: 0.0029
on_train_batch_begin: 1598501650.295216s

6 step training time: 0.334545s

on_train_batch_end: 1598501650.625822s

 7168/50000 [===>..........................] - ETA: 2:07 - loss: 10.5665 - accuracy: 0.0055
on_train_batch_begin: 1598501650.626081s

7 step training time: 0.330865s

on_train_batch_end: 1598501650.954059s

 8192/50000 [===>..........................] - ETA: 1:50 - loss: 10.2158 - accuracy: 0.0090
on_train_batch_begin: 1598501650.954278s

8 step training time: 0.328196s

on_train_batch_end: 1598501651.281434s

 9216/50000 [====>.........................] - ETA: 1:37 - loss: 9.9307 - accuracy: 0.0125 
on_train_batch_begin: 1598501651.281657s

9 step training time: 0.327379s

on_train_batch_end: 1598501651.617040s

10240/50000 [=====>........................] - ETA: 1:26 - loss: 9.7093 - accuracy: 0.0163
on_train_batch_begin: 1598501651.617295s

10 step training time: 0.335638s

on_train_batch_end: 1598501651.948285s

11264/50000 [=====>........................] - ETA: 1:17 - loss: 9.4929 - accuracy: 0.0192
on_train_batch_begin: 1598501651.948523s

11 step training time: 0.331228s

on_train_batch_end: 1598501652.276319s

12288/50000 [======>.......................] - ETA: 1:10 - loss: 9.3074 - accuracy: 0.0221
on_train_batch_begin: 1598501652.276558s

12 step training time: 0.328034s

on_train_batch_end: 1598501652.607754s

13312/50000 [======>.......................] - ETA: 1:04 - loss: 9.1382 - accuracy: 0.0256
on_train_batch_begin: 1598501652.608035s

13 step training time: 0.331477s

on_train_batch_end: 1598501652.942994s

14336/50000 [=======>......................] - ETA: 58s - loss: 8.9943 - accuracy: 0.0290 
on_train_batch_begin: 1598501652.943241s

14 step training time: 0.335207s

on_train_batch_end: 1598501653.274779s

15360/50000 [========>.....................] - ETA: 54s - loss: 8.8660 - accuracy: 0.0317
on_train_batch_begin: 1598501653.275031s

15 step training time: 0.331790s

on_train_batch_end: 1598501653.588799s

16384/50000 [========>.....................] - ETA: 49s - loss: 8.7478 - accuracy: 0.0345
on_train_batch_begin: 1598501653.589066s

16 step training time: 0.314035s

on_train_batch_end: 1598501653.927055s

17408/50000 [=========>....................] - ETA: 46s - loss: 8.6362 - accuracy: 0.0367
on_train_batch_begin: 1598501653.927311s

17 step training time: 0.338245s

on_train_batch_end: 1598501654.262437s

18432/50000 [==========>...................] - ETA: 42s - loss: 8.5301 - accuracy: 0.0385
on_train_batch_begin: 1598501654.262686s

18 step training time: 0.335375s

on_train_batch_end: 1598501654.595073s

19456/50000 [==========>...................] - ETA: 39s - loss: 8.4410 - accuracy: 0.0403
on_train_batch_begin: 1598501654.595315s

19 step training time: 0.332628s

on_train_batch_end: 1598501654.924186s

20480/50000 [===========>..................] - ETA: 36s - loss: 8.3489 - accuracy: 0.0419
on_train_batch_begin: 1598501654.924443s

20 step training time: 0.329129s

on_train_batch_end: 1598501655.254122s

21504/50000 [===========>..................] - ETA: 34s - loss: 8.2645 - accuracy: 0.0427
on_train_batch_begin: 1598501655.254397s

21 step training time: 0.329953s

on_train_batch_end: 1598501655.589302s

22528/50000 [============>.................] - ETA: 32s - loss: 8.1861 - accuracy: 0.0441
on_train_batch_begin: 1598501655.589542s

22 step training time: 0.335145s

on_train_batch_end: 1598501655.921243s

23552/50000 [=============>................] - ETA: 29s - loss: 8.1105 - accuracy: 0.0458
on_train_batch_begin: 1598501655.921481s

23 step training time: 0.331939s

on_train_batch_end: 1598501656.252635s

24576/50000 [=============>................] - ETA: 27s - loss: 8.0375 - accuracy: 0.0474
on_train_batch_begin: 1598501656.252869s

24 step training time: 0.331388s

on_train_batch_end: 1598501656.587836s

25600/50000 [==============>...............] - ETA: 26s - loss: 7.9705 - accuracy: 0.0488
on_train_batch_begin: 1598501656.588106s

25 step training time: 0.335236s

on_train_batch_end: 1598501656.919466s

26624/50000 [==============>...............] - ETA: 24s - loss: 7.9038 - accuracy: 0.0503
on_train_batch_begin: 1598501656.919711s

26 step training time: 0.331605s

on_train_batch_end: 1598501657.253144s

27648/50000 [===============>..............] - ETA: 22s - loss: 7.8392 - accuracy: 0.0514
on_train_batch_begin: 1598501657.253385s

27 step training time: 0.333673s

on_train_batch_end: 1598501657.583970s

28672/50000 [================>.............] - ETA: 21s - loss: 7.7803 - accuracy: 0.0523
on_train_batch_begin: 1598501657.584231s

28 step training time: 0.330846s

on_train_batch_end: 1598501657.913779s

29696/50000 [================>.............] - ETA: 19s - loss: 7.7236 - accuracy: 0.0533
on_train_batch_begin: 1598501657.914016s

29 step training time: 0.329786s

on_train_batch_end: 1598501658.249462s

30720/50000 [=================>............] - ETA: 18s - loss: 7.6675 - accuracy: 0.0543
on_train_batch_begin: 1598501658.249709s

30 step training time: 0.335693s

on_train_batch_end: 1598501658.580320s

31744/50000 [==================>...........] - ETA: 16s - loss: 7.6160 - accuracy: 0.0551
on_train_batch_begin: 1598501658.580563s

31 step training time: 0.330854s

on_train_batch_end: 1598501658.910774s

32768/50000 [==================>...........] - ETA: 15s - loss: 7.5619 - accuracy: 0.0561
on_train_batch_begin: 1598501658.910995s

32 step training time: 0.330431s

on_train_batch_end: 1598501659.245742s

33792/50000 [===================>..........] - ETA: 14s - loss: 7.5109 - accuracy: 0.0570
on_train_batch_begin: 1598501659.245981s

33 step training time: 0.334986s

on_train_batch_end: 1598501659.577508s

34816/50000 [===================>..........] - ETA: 13s - loss: 7.4671 - accuracy: 0.0578
on_train_batch_begin: 1598501659.577737s

34 step training time: 0.331756s

on_train_batch_end: 1598501659.905604s

35840/50000 [====================>.........] - ETA: 12s - loss: 7.4250 - accuracy: 0.0584
on_train_batch_begin: 1598501659.905826s

35 step training time: 0.328089s

on_train_batch_end: 1598501660.242048s

36864/50000 [=====================>........] - ETA: 11s - loss: 7.3818 - accuracy: 0.0590
on_train_batch_begin: 1598501660.242320s

36 step training time: 0.336494s

on_train_batch_end: 1598501660.573908s

37888/50000 [=====================>........] - ETA: 10s - loss: 7.3381 - accuracy: 0.0597
on_train_batch_begin: 1598501660.574150s

37 step training time: 0.331831s

on_train_batch_end: 1598501660.909540s

38912/50000 [======================>.......] - ETA: 9s - loss: 7.2970 - accuracy: 0.0600 
on_train_batch_begin: 1598501660.909781s

38 step training time: 0.335630s

on_train_batch_end: 1598501661.243159s

39936/50000 [======================>.......] - ETA: 8s - loss: 7.2547 - accuracy: 0.0607
on_train_batch_begin: 1598501661.243399s

39 step training time: 0.333618s

on_train_batch_end: 1598501661.579197s

40960/50000 [=======================>......] - ETA: 7s - loss: 7.2178 - accuracy: 0.0610
on_train_batch_begin: 1598501661.579454s

40 step training time: 0.336055s

on_train_batch_end: 1598501661.911894s

41984/50000 [========================>.....] - ETA: 6s - loss: 7.1778 - accuracy: 0.0613
on_train_batch_begin: 1598501661.912127s

41 step training time: 0.332674s

on_train_batch_end: 1598501662.247619s

43008/50000 [========================>.....] - ETA: 5s - loss: 7.1445 - accuracy: 0.0619
on_train_batch_begin: 1598501662.247853s

42 step training time: 0.335726s

on_train_batch_end: 1598501662.582014s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.1080 - accuracy: 0.0625
on_train_batch_begin: 1598501662.582253s

43 step training time: 0.334400s

on_train_batch_end: 1598501662.916307s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.0747 - accuracy: 0.0630
on_train_batch_begin: 1598501662.916533s

44 step training time: 0.334280s

on_train_batch_end: 1598501663.249779s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.0421 - accuracy: 0.0635
on_train_batch_begin: 1598501663.249998s

45 step training time: 0.333465s

on_train_batch_end: 1598501663.584524s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.0058 - accuracy: 0.0641
on_train_batch_begin: 1598501663.584748s

46 step training time: 0.334750s

on_train_batch_end: 1598501663.919465s

48128/50000 [===========================>..] - ETA: 1s - loss: 6.9729 - accuracy: 0.0646
on_train_batch_begin: 1598501663.919688s

47 step training time: 0.334939s

on_train_batch_end: 1598501664.253239s

49152/50000 [============================>.] - ETA: 0s - loss: 6.9416 - accuracy: 0.0651
on_train_batch_begin: 1598501664.253468s

48 step training time: 0.333780s

on_train_batch_end: 1598501670.276140s

on_test_batch_begin: 1598501670.458087s

49 step training time: 6.204619s

on_epoch_end: 1598501675.148775s

Validation time: 4.690674s

Real time: 1598501675.148775s

Epoch time: 45.862685680389404s

50000/50000 [==============================] - 46s 917us/sample - loss: 6.9163 - accuracy: 0.0653 - val_loss: 8.8776 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598501675.148976s

Real time: 1598501675.1489813
Epoch 2/5

on_train_batch_begin: 1598501675.152313s

on_train_batch_end: 1598501675.494077s

 1024/50000 [..............................] - ETA: 16s - loss: 5.3666 - accuracy: 0.0901
on_train_batch_begin: 1598501675.494329s

1 step training time: 0.342016s

on_train_batch_end: 1598501675.830595s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.3397 - accuracy: 0.0895
on_train_batch_begin: 1598501675.830835s

2 step training time: 0.336506s

on_train_batch_end: 1598501676.168637s

 3072/50000 [>.............................] - ETA: 15s - loss: 5.2465 - accuracy: 0.0917
on_train_batch_begin: 1598501676.168854s

3 step training time: 0.338018s

on_train_batch_end: 1598501676.509577s

 4096/50000 [=>............................] - ETA: 15s - loss: 5.2177 - accuracy: 0.0897
on_train_batch_begin: 1598501676.509800s

4 step training time: 0.340946s

on_train_batch_end: 1598501676.846137s

 5120/50000 [==>...........................] - ETA: 14s - loss: 5.2030 - accuracy: 0.0886
on_train_batch_begin: 1598501676.846351s

5 step training time: 0.336551s

on_train_batch_end: 1598501677.183637s

 6144/50000 [==>...........................] - ETA: 14s - loss: 5.1784 - accuracy: 0.0877
on_train_batch_begin: 1598501677.183856s

6 step training time: 0.337505s

on_train_batch_end: 1598501677.522976s

 7168/50000 [===>..........................] - ETA: 14s - loss: 5.1737 - accuracy: 0.0862
on_train_batch_begin: 1598501677.523205s

7 step training time: 0.339349s

on_train_batch_end: 1598501677.859821s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.1583 - accuracy: 0.0851
on_train_batch_begin: 1598501677.860031s

8 step training time: 0.336826s

on_train_batch_end: 1598501678.199061s

 9216/50000 [====>.........................] - ETA: 13s - loss: 5.1253 - accuracy: 0.0836
on_train_batch_begin: 1598501678.199272s

9 step training time: 0.339241s

on_train_batch_end: 1598501678.539656s

10240/50000 [=====>........................] - ETA: 13s - loss: 5.0936 - accuracy: 0.0820
on_train_batch_begin: 1598501678.539882s

10 step training time: 0.340611s

on_train_batch_end: 1598501678.876354s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.0491 - accuracy: 0.0807
on_train_batch_begin: 1598501678.876613s

11 step training time: 0.336731s

on_train_batch_end: 1598501679.215595s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.0065 - accuracy: 0.0798
on_train_batch_begin: 1598501679.215809s

12 step training time: 0.339196s

on_train_batch_end: 1598501679.558727s

13312/50000 [======>.......................] - ETA: 12s - loss: 4.9600 - accuracy: 0.0792
on_train_batch_begin: 1598501679.558942s

13 step training time: 0.343132s

on_train_batch_end: 1598501679.898961s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.9317 - accuracy: 0.0787
on_train_batch_begin: 1598501679.899182s

14 step training time: 0.340240s

on_train_batch_end: 1598501680.237247s

15360/50000 [========>.....................] - ETA: 11s - loss: 4.9007 - accuracy: 0.0782
on_train_batch_begin: 1598501680.237474s

15 step training time: 0.338293s

on_train_batch_end: 1598501680.577664s

16384/50000 [========>.....................] - ETA: 11s - loss: 4.8549 - accuracy: 0.0782
on_train_batch_begin: 1598501680.577927s

16 step training time: 0.340453s

on_train_batch_end: 1598501680.921240s

17408/50000 [=========>....................] - ETA: 10s - loss: 4.8151 - accuracy: 0.0782
on_train_batch_begin: 1598501680.921490s

17 step training time: 0.343563s

on_train_batch_end: 1598501681.262937s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.7707 - accuracy: 0.0785
on_train_batch_begin: 1598501681.263177s

18 step training time: 0.341686s

on_train_batch_end: 1598501681.602364s

19456/50000 [==========>...................] - ETA: 10s - loss: 4.7132 - accuracy: 0.0788
on_train_batch_begin: 1598501681.602601s

19 step training time: 0.339425s

on_train_batch_end: 1598501681.941455s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.6637 - accuracy: 0.0790 
on_train_batch_begin: 1598501681.941689s

20 step training time: 0.339087s

on_train_batch_end: 1598501682.281710s

21504/50000 [===========>..................] - ETA: 9s - loss: 4.6093 - accuracy: 0.0793
on_train_batch_begin: 1598501682.281949s

21 step training time: 0.340261s

on_train_batch_end: 1598501682.627096s

22528/50000 [============>.................] - ETA: 9s - loss: 4.5617 - accuracy: 0.0796
on_train_batch_begin: 1598501682.627339s

22 step training time: 0.345390s

on_train_batch_end: 1598501682.970118s

23552/50000 [=============>................] - ETA: 8s - loss: 4.5048 - accuracy: 0.0801
on_train_batch_begin: 1598501682.970370s

23 step training time: 0.343031s

on_train_batch_end: 1598501683.311582s

24576/50000 [=============>................] - ETA: 8s - loss: 4.4450 - accuracy: 0.0806
on_train_batch_begin: 1598501683.311819s

24 step training time: 0.341449s

on_train_batch_end: 1598501683.654015s

25600/50000 [==============>...............] - ETA: 8s - loss: 4.3900 - accuracy: 0.0810
on_train_batch_begin: 1598501683.654249s

25 step training time: 0.342431s

on_train_batch_end: 1598501683.993300s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.3408 - accuracy: 0.0814
on_train_batch_begin: 1598501683.993536s

26 step training time: 0.339287s

on_train_batch_end: 1598501684.332959s

27648/50000 [===============>..............] - ETA: 7s - loss: 4.2909 - accuracy: 0.0818
on_train_batch_begin: 1598501684.333184s

27 step training time: 0.339647s

on_train_batch_end: 1598501684.676433s

28672/50000 [================>.............] - ETA: 7s - loss: 4.2439 - accuracy: 0.0822
on_train_batch_begin: 1598501684.676675s

28 step training time: 0.343492s

on_train_batch_end: 1598501685.019373s

29696/50000 [================>.............] - ETA: 6s - loss: 4.1914 - accuracy: 0.0826
on_train_batch_begin: 1598501685.019613s

29 step training time: 0.342938s

on_train_batch_end: 1598501685.362579s

30720/50000 [=================>............] - ETA: 6s - loss: 4.1443 - accuracy: 0.0831
on_train_batch_begin: 1598501685.362848s

30 step training time: 0.343235s

on_train_batch_end: 1598501685.707634s

31744/50000 [==================>...........] - ETA: 6s - loss: 4.0996 - accuracy: 0.0835
on_train_batch_begin: 1598501685.707874s

31 step training time: 0.345026s

on_train_batch_end: 1598501686.050588s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.0586 - accuracy: 0.0839
on_train_batch_begin: 1598501686.050829s

32 step training time: 0.342955s

on_train_batch_end: 1598501686.392481s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.0118 - accuracy: 0.0843
on_train_batch_begin: 1598501686.392708s

33 step training time: 0.341879s

on_train_batch_end: 1598501686.731271s

34816/50000 [===================>..........] - ETA: 5s - loss: 3.9724 - accuracy: 0.0848
on_train_batch_begin: 1598501686.731506s

34 step training time: 0.338798s

on_train_batch_end: 1598501687.075169s

35840/50000 [====================>.........] - ETA: 4s - loss: 3.9239 - accuracy: 0.0852
on_train_batch_begin: 1598501687.075405s

35 step training time: 0.343899s

on_train_batch_end: 1598501687.417904s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.8927 - accuracy: 0.0855
on_train_batch_begin: 1598501687.418153s

36 step training time: 0.342748s

on_train_batch_end: 1598501687.760600s

37888/50000 [=====================>........] - ETA: 4s - loss: 3.8529 - accuracy: 0.0859
on_train_batch_begin: 1598501687.760832s

37 step training time: 0.342679s

on_train_batch_end: 1598501688.105012s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.8160 - accuracy: 0.0862
on_train_batch_begin: 1598501688.105254s

38 step training time: 0.344422s

on_train_batch_end: 1598501688.448891s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.7763 - accuracy: 0.0866
on_train_batch_begin: 1598501688.449139s

39 step training time: 0.343885s

on_train_batch_end: 1598501688.792755s

40960/50000 [=======================>......] - ETA: 3s - loss: 3.7459 - accuracy: 0.0869
on_train_batch_begin: 1598501688.793002s

40 step training time: 0.343863s

on_train_batch_end: 1598501689.134476s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.7134 - accuracy: 0.0872
on_train_batch_begin: 1598501689.134719s

41 step training time: 0.341717s

on_train_batch_end: 1598501689.476880s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.6816 - accuracy: 0.0875
on_train_batch_begin: 1598501689.477117s

42 step training time: 0.342398s

on_train_batch_end: 1598501689.817643s

44032/50000 [=========================>....] - ETA: 1s - loss: 3.6536 - accuracy: 0.0878
on_train_batch_begin: 1598501689.817883s

43 step training time: 0.340767s

on_train_batch_end: 1598501690.158419s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.6265 - accuracy: 0.0881
on_train_batch_begin: 1598501690.158654s

44 step training time: 0.340771s

on_train_batch_end: 1598501690.501325s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.5985 - accuracy: 0.0884
on_train_batch_begin: 1598501690.501590s

45 step training time: 0.342936s

on_train_batch_end: 1598501690.845865s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.5748 - accuracy: 0.0886
on_train_batch_begin: 1598501690.846111s

46 step training time: 0.344521s

on_train_batch_end: 1598501691.190077s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.5516 - accuracy: 0.0889
on_train_batch_begin: 1598501691.190299s

47 step training time: 0.344188s

on_train_batch_end: 1598501691.533953s

49152/50000 [============================>.] - ETA: 0s - loss: 3.5266 - accuracy: 0.0891
on_train_batch_begin: 1598501691.534181s

48 step training time: 0.343882s

on_train_batch_end: 1598501691.820871s

on_test_batch_begin: 1598501691.834267s

49 step training time: 0.300086s

on_epoch_end: 1598501692.665103s

Validation time: 0.830827s

Real time: 1598501692.665103s

Epoch time: 17.51613736152649s

50000/50000 [==============================] - 18s 350us/sample - loss: 3.5042 - accuracy: 0.0893 - val_loss: 7.0810 - val_accuracy: 0.1000

on_epoch_begin: 1598501692.665278s

Real time: 1598501692.665283
Epoch 3/5

on_train_batch_begin: 1598501692.668550s

on_train_batch_end: 1598501693.011453s

 1024/50000 [..............................] - ETA: 16s - loss: 2.2320 - accuracy: 0.1006
on_train_batch_begin: 1598501693.011677s

1 step training time: 0.343127s

on_train_batch_end: 1598501693.350487s

 2048/50000 [>.............................] - ETA: 16s - loss: 2.2419 - accuracy: 0.1006
on_train_batch_begin: 1598501693.350703s

2 step training time: 0.339027s

on_train_batch_end: 1598501693.694748s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.2460 - accuracy: 0.1005
on_train_batch_begin: 1598501693.695011s

3 step training time: 0.344307s

on_train_batch_end: 1598501694.038639s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.1854 - accuracy: 0.1004
on_train_batch_begin: 1598501694.038878s

4 step training time: 0.343867s

on_train_batch_end: 1598501694.380776s

 5120/50000 [==>...........................] - ETA: 15s - loss: 2.1547 - accuracy: 0.1005
on_train_batch_begin: 1598501694.380995s

5 step training time: 0.342117s

on_train_batch_end: 1598501694.724235s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.1050 - accuracy: 0.1004
on_train_batch_begin: 1598501694.724456s

6 step training time: 0.343461s

on_train_batch_end: 1598501695.071263s

 7168/50000 [===>..........................] - ETA: 14s - loss: 2.1358 - accuracy: 0.1004
on_train_batch_begin: 1598501695.071475s

7 step training time: 0.347019s

on_train_batch_end: 1598501695.415689s

 8192/50000 [===>..........................] - ETA: 14s - loss: 2.1461 - accuracy: 0.1003
on_train_batch_begin: 1598501695.415952s

8 step training time: 0.344478s

on_train_batch_end: 1598501695.759769s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.1640 - accuracy: 0.1004
on_train_batch_begin: 1598501695.760018s

9 step training time: 0.344065s

on_train_batch_end: 1598501696.106250s

10240/50000 [=====>........................] - ETA: 13s - loss: 2.1647 - accuracy: 0.1003
on_train_batch_begin: 1598501696.106477s

10 step training time: 0.346459s

on_train_batch_end: 1598501696.452410s

11264/50000 [=====>........................] - ETA: 13s - loss: 2.1707 - accuracy: 0.1003
on_train_batch_begin: 1598501696.452640s

11 step training time: 0.346163s

on_train_batch_end: 1598501696.796264s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.1589 - accuracy: 0.1003
on_train_batch_begin: 1598501696.796490s

12 step training time: 0.343850s

on_train_batch_end: 1598501697.143039s

13312/50000 [======>.......................] - ETA: 12s - loss: 2.1650 - accuracy: 0.1002
on_train_batch_begin: 1598501697.143267s

13 step training time: 0.346777s

on_train_batch_end: 1598501697.489187s

14336/50000 [=======>......................] - ETA: 12s - loss: 2.1652 - accuracy: 0.1002
on_train_batch_begin: 1598501697.489416s

14 step training time: 0.346148s

on_train_batch_end: 1598501697.832888s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.1624 - accuracy: 0.1002
on_train_batch_begin: 1598501697.833111s

15 step training time: 0.343695s

on_train_batch_end: 1598501698.178349s

16384/50000 [========>.....................] - ETA: 11s - loss: 2.1660 - accuracy: 0.1001
on_train_batch_begin: 1598501698.178587s

16 step training time: 0.345476s

on_train_batch_end: 1598501698.522169s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.1589 - accuracy: 0.1001
on_train_batch_begin: 1598501698.522397s

17 step training time: 0.343810s

on_train_batch_end: 1598501698.867074s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.1513 - accuracy: 0.1001
on_train_batch_begin: 1598501698.867312s

18 step training time: 0.344915s

on_train_batch_end: 1598501699.212418s

19456/50000 [==========>...................] - ETA: 10s - loss: 2.1343 - accuracy: 0.1001
on_train_batch_begin: 1598501699.212657s

19 step training time: 0.345345s

on_train_batch_end: 1598501699.554955s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.1274 - accuracy: 0.1001 
on_train_batch_begin: 1598501699.555197s

20 step training time: 0.342540s

on_train_batch_end: 1598501699.900026s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.1193 - accuracy: 0.1001
on_train_batch_begin: 1598501699.900286s

21 step training time: 0.345089s

on_train_batch_end: 1598501700.245943s

22528/50000 [============>.................] - ETA: 9s - loss: 2.1054 - accuracy: 0.1001
on_train_batch_begin: 1598501700.246196s

22 step training time: 0.345909s

on_train_batch_end: 1598501700.591785s

23552/50000 [=============>................] - ETA: 8s - loss: 2.0949 - accuracy: 0.1001
on_train_batch_begin: 1598501700.592087s

23 step training time: 0.345891s

on_train_batch_end: 1598501700.937423s

24576/50000 [=============>................] - ETA: 8s - loss: 2.0852 - accuracy: 0.1002
on_train_batch_begin: 1598501700.937685s

24 step training time: 0.345598s

on_train_batch_end: 1598501701.282105s

25600/50000 [==============>...............] - ETA: 8s - loss: 2.0832 - accuracy: 0.1002
on_train_batch_begin: 1598501701.282375s

25 step training time: 0.344690s

on_train_batch_end: 1598501701.627629s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.0775 - accuracy: 0.1002
on_train_batch_begin: 1598501701.627889s

26 step training time: 0.345514s

on_train_batch_end: 1598501701.973594s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.0680 - accuracy: 0.1002
on_train_batch_begin: 1598501701.973841s

27 step training time: 0.345952s

on_train_batch_end: 1598501702.320325s

28672/50000 [================>.............] - ETA: 7s - loss: 2.0606 - accuracy: 0.1002
on_train_batch_begin: 1598501702.320544s

28 step training time: 0.346703s

on_train_batch_end: 1598501702.665440s

29696/50000 [================>.............] - ETA: 6s - loss: 2.0529 - accuracy: 0.1002
on_train_batch_begin: 1598501702.665670s

29 step training time: 0.345125s

on_train_batch_end: 1598501703.012721s

30720/50000 [=================>............] - ETA: 6s - loss: 2.0476 - accuracy: 0.1002
on_train_batch_begin: 1598501703.012954s

30 step training time: 0.347284s

on_train_batch_end: 1598501703.360950s

31744/50000 [==================>...........] - ETA: 6s - loss: 2.0417 - accuracy: 0.1002
on_train_batch_begin: 1598501703.361180s

31 step training time: 0.348226s

on_train_batch_end: 1598501703.709758s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.0376 - accuracy: 0.1002
on_train_batch_begin: 1598501703.709997s

32 step training time: 0.348817s

on_train_batch_end: 1598501704.054960s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.0363 - accuracy: 0.1002
on_train_batch_begin: 1598501704.055199s

33 step training time: 0.345202s

on_train_batch_end: 1598501704.401986s

34816/50000 [===================>..........] - ETA: 5s - loss: 2.0363 - accuracy: 0.1002
on_train_batch_begin: 1598501704.402214s

34 step training time: 0.347014s

on_train_batch_end: 1598501704.748260s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.0322 - accuracy: 0.1002
on_train_batch_begin: 1598501704.748497s

35 step training time: 0.346284s

on_train_batch_end: 1598501705.094903s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.0287 - accuracy: 0.1002
on_train_batch_begin: 1598501705.095137s

36 step training time: 0.346639s

on_train_batch_end: 1598501705.442094s

37888/50000 [=====================>........] - ETA: 4s - loss: 2.0236 - accuracy: 0.1002
on_train_batch_begin: 1598501705.442360s

37 step training time: 0.347224s

on_train_batch_end: 1598501705.788298s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.0206 - accuracy: 0.1002
on_train_batch_begin: 1598501705.788554s

38 step training time: 0.346194s

on_train_batch_end: 1598501706.135578s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.0159 - accuracy: 0.1002
on_train_batch_begin: 1598501706.135837s

39 step training time: 0.347282s

on_train_batch_end: 1598501706.481925s

40960/50000 [=======================>......] - ETA: 3s - loss: 2.0075 - accuracy: 0.1002
on_train_batch_begin: 1598501706.482169s

40 step training time: 0.346332s

on_train_batch_end: 1598501706.827964s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.0044 - accuracy: 0.1002
on_train_batch_begin: 1598501706.828224s

41 step training time: 0.346055s

on_train_batch_end: 1598501707.172387s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.9952 - accuracy: 0.1002
on_train_batch_begin: 1598501707.172606s

42 step training time: 0.344383s

on_train_batch_end: 1598501707.519228s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.9888 - accuracy: 0.1002
on_train_batch_begin: 1598501707.519469s

43 step training time: 0.346863s

on_train_batch_end: 1598501707.863661s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.9831 - accuracy: 0.1002
on_train_batch_begin: 1598501707.863902s

44 step training time: 0.344433s

on_train_batch_end: 1598501708.208750s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.9744 - accuracy: 0.1002
on_train_batch_begin: 1598501708.208986s

45 step training time: 0.345084s

on_train_batch_end: 1598501708.552902s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.9695 - accuracy: 0.1002
on_train_batch_begin: 1598501708.553145s

46 step training time: 0.344159s

on_train_batch_end: 1598501708.897391s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.9637 - accuracy: 0.1002
on_train_batch_begin: 1598501708.897618s

47 step training time: 0.344473s

on_train_batch_end: 1598501709.244283s

49152/50000 [============================>.] - ETA: 0s - loss: 1.9613 - accuracy: 0.1002
on_train_batch_begin: 1598501709.244534s

48 step training time: 0.346916s

on_train_batch_end: 1598501709.531445s

on_test_batch_begin: 1598501709.542489s

49 step training time: 0.297956s

on_epoch_end: 1598501710.365725s

Validation time: 0.823226s

Real time: 1598501710.365725s

Epoch time: 17.70045757293701s

50000/50000 [==============================] - 18s 354us/sample - loss: 1.9583 - accuracy: 0.1002 - val_loss: 6.3953 - val_accuracy: 0.0999

on_epoch_begin: 1598501710.365898s

Real time: 1598501710.3659031
Epoch 4/5

on_train_batch_begin: 1598501710.369189s

on_train_batch_end: 1598501710.715630s

 1024/50000 [..............................] - ETA: 16s - loss: 1.3679 - accuracy: 0.1004
on_train_batch_begin: 1598501710.715881s

1 step training time: 0.346692s

on_train_batch_end: 1598501711.062342s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.4767 - accuracy: 0.1002
on_train_batch_begin: 1598501711.062584s

2 step training time: 0.346703s

on_train_batch_end: 1598501711.411635s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.4616 - accuracy: 0.1003
on_train_batch_begin: 1598501711.411862s

3 step training time: 0.349278s

on_train_batch_end: 1598501711.761980s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.4702 - accuracy: 0.1004
on_train_batch_begin: 1598501711.762210s

4 step training time: 0.350348s

on_train_batch_end: 1598501712.109472s

 5120/50000 [==>...........................] - ETA: 15s - loss: 1.4698 - accuracy: 0.1003
on_train_batch_begin: 1598501712.109697s

5 step training time: 0.347487s

on_train_batch_end: 1598501712.456807s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.4600 - accuracy: 0.1002
on_train_batch_begin: 1598501712.457037s

6 step training time: 0.347340s

on_train_batch_end: 1598501712.805421s

 7168/50000 [===>..........................] - ETA: 14s - loss: 1.4775 - accuracy: 0.1002
on_train_batch_begin: 1598501712.805643s

7 step training time: 0.348607s

on_train_batch_end: 1598501713.154630s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.4783 - accuracy: 0.1002
on_train_batch_begin: 1598501713.154851s

8 step training time: 0.349208s

on_train_batch_end: 1598501713.505200s

 9216/50000 [====>.........................] - ETA: 13s - loss: 1.4810 - accuracy: 0.1002
on_train_batch_begin: 1598501713.505441s

9 step training time: 0.350590s

on_train_batch_end: 1598501713.854780s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.4965 - accuracy: 0.1002
on_train_batch_begin: 1598501713.855006s

10 step training time: 0.349565s

on_train_batch_end: 1598501714.202285s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.4881 - accuracy: 0.1002
on_train_batch_begin: 1598501714.202515s

11 step training time: 0.347509s

on_train_batch_end: 1598501714.552594s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.4892 - accuracy: 0.1002
on_train_batch_begin: 1598501714.552823s

12 step training time: 0.350308s

on_train_batch_end: 1598501714.901129s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.5030 - accuracy: 0.1002
on_train_batch_begin: 1598501714.901371s

13 step training time: 0.348547s

on_train_batch_end: 1598501715.248289s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.5118 - accuracy: 0.1002
on_train_batch_begin: 1598501715.248511s

14 step training time: 0.347140s

on_train_batch_end: 1598501715.594838s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.5162 - accuracy: 0.1002
on_train_batch_begin: 1598501715.595115s

15 step training time: 0.346604s

on_train_batch_end: 1598501715.941381s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.5301 - accuracy: 0.1002
on_train_batch_begin: 1598501715.941642s

16 step training time: 0.346527s

on_train_batch_end: 1598501716.276568s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.5322 - accuracy: 0.1002
on_train_batch_begin: 1598501716.276821s

17 step training time: 0.335179s

on_train_batch_end: 1598501716.629157s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.5296 - accuracy: 0.1002
on_train_batch_begin: 1598501716.629383s

18 step training time: 0.352562s

on_train_batch_end: 1598501716.981843s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.5385 - accuracy: 0.1002
on_train_batch_begin: 1598501716.982060s

19 step training time: 0.352677s

on_train_batch_end: 1598501717.333172s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.5381 - accuracy: 0.1002
on_train_batch_begin: 1598501717.333409s

20 step training time: 0.351349s

on_train_batch_end: 1598501717.682942s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.5415 - accuracy: 0.1002 
on_train_batch_begin: 1598501717.683184s

21 step training time: 0.349775s

on_train_batch_end: 1598501718.034369s

22528/50000 [============>.................] - ETA: 9s - loss: 1.5380 - accuracy: 0.1002
on_train_batch_begin: 1598501718.034612s

22 step training time: 0.351428s

on_train_batch_end: 1598501718.384014s

23552/50000 [=============>................] - ETA: 9s - loss: 1.5414 - accuracy: 0.1002
on_train_batch_begin: 1598501718.384303s

23 step training time: 0.349691s

on_train_batch_end: 1598501718.718508s

24576/50000 [=============>................] - ETA: 8s - loss: 1.5397 - accuracy: 0.1002
on_train_batch_begin: 1598501718.718749s

24 step training time: 0.334446s

on_train_batch_end: 1598501719.072512s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.5380 - accuracy: 0.1002
on_train_batch_begin: 1598501719.072759s

25 step training time: 0.354010s

on_train_batch_end: 1598501719.424829s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.5359 - accuracy: 0.1002
on_train_batch_begin: 1598501719.425047s

26 step training time: 0.352288s

on_train_batch_end: 1598501719.774062s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.5345 - accuracy: 0.1002
on_train_batch_begin: 1598501719.774302s

27 step training time: 0.349254s

on_train_batch_end: 1598501720.125499s

28672/50000 [================>.............] - ETA: 7s - loss: 1.5320 - accuracy: 0.1002
on_train_batch_begin: 1598501720.125729s

28 step training time: 0.351427s

on_train_batch_end: 1598501720.477780s

29696/50000 [================>.............] - ETA: 6s - loss: 1.5299 - accuracy: 0.1002
on_train_batch_begin: 1598501720.478009s

29 step training time: 0.352280s

on_train_batch_end: 1598501720.828756s

30720/50000 [=================>............] - ETA: 6s - loss: 1.5307 - accuracy: 0.1002
on_train_batch_begin: 1598501720.829036s

30 step training time: 0.351027s

on_train_batch_end: 1598501721.179675s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.5258 - accuracy: 0.1002
on_train_batch_begin: 1598501721.179956s

31 step training time: 0.350921s

on_train_batch_end: 1598501721.532596s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.5199 - accuracy: 0.1002
on_train_batch_begin: 1598501721.532850s

32 step training time: 0.352893s

on_train_batch_end: 1598501721.885731s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.5231 - accuracy: 0.1002
on_train_batch_begin: 1598501721.886009s

33 step training time: 0.353159s

on_train_batch_end: 1598501722.237065s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.5187 - accuracy: 0.1002
on_train_batch_begin: 1598501722.237308s

34 step training time: 0.351300s

on_train_batch_end: 1598501722.587964s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.5156 - accuracy: 0.1002
on_train_batch_begin: 1598501722.588224s

35 step training time: 0.350916s

on_train_batch_end: 1598501722.938522s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.5072 - accuracy: 0.1002
on_train_batch_begin: 1598501722.938765s

36 step training time: 0.350541s

on_train_batch_end: 1598501723.294296s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.5029 - accuracy: 0.1002
on_train_batch_begin: 1598501723.294531s

37 step training time: 0.355766s

on_train_batch_end: 1598501723.645709s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.4992 - accuracy: 0.1002
on_train_batch_begin: 1598501723.645976s

38 step training time: 0.351445s

on_train_batch_end: 1598501723.996679s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.4954 - accuracy: 0.1002
on_train_batch_begin: 1598501723.996920s

39 step training time: 0.350943s

on_train_batch_end: 1598501724.347051s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.4922 - accuracy: 0.1002
on_train_batch_begin: 1598501724.347300s

40 step training time: 0.350380s

on_train_batch_end: 1598501724.699613s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.4890 - accuracy: 0.1002
on_train_batch_begin: 1598501724.699852s

41 step training time: 0.352552s

on_train_batch_end: 1598501725.052243s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.4869 - accuracy: 0.1002
on_train_batch_begin: 1598501725.052487s

42 step training time: 0.352636s

on_train_batch_end: 1598501725.406403s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.4817 - accuracy: 0.1002
on_train_batch_begin: 1598501725.406633s

43 step training time: 0.354146s

on_train_batch_end: 1598501725.759018s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.4786 - accuracy: 0.1002
on_train_batch_begin: 1598501725.759298s

44 step training time: 0.352665s

on_train_batch_end: 1598501726.113637s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.4756 - accuracy: 0.1002
on_train_batch_begin: 1598501726.113898s

45 step training time: 0.354601s

on_train_batch_end: 1598501726.465693s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.4739 - accuracy: 0.1002
on_train_batch_begin: 1598501726.465980s

46 step training time: 0.352082s

on_train_batch_end: 1598501726.819816s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.4718 - accuracy: 0.1002
on_train_batch_begin: 1598501726.820052s

47 step training time: 0.354072s

on_train_batch_end: 1598501727.173445s

49152/50000 [============================>.] - ETA: 0s - loss: 1.4721 - accuracy: 0.1002
on_train_batch_begin: 1598501727.173678s

48 step training time: 0.353626s

on_train_batch_end: 1598501727.469702s

on_test_batch_begin: 1598501727.482905s

49 step training time: 0.309227s

on_epoch_end: 1598501728.321376s

Validation time: 0.838461s

Real time: 1598501728.321376s

Epoch time: 17.955487489700317s

50000/50000 [==============================] - 18s 359us/sample - loss: 1.4684 - accuracy: 0.1002 - val_loss: 6.9122 - val_accuracy: 0.0999

on_epoch_begin: 1598501728.321550s

Real time: 1598501728.3215547
Epoch 5/5

on_train_batch_begin: 1598501728.324730s

on_train_batch_end: 1598501728.675218s

 1024/50000 [..............................] - ETA: 16s - loss: 1.0357 - accuracy: 0.1005
on_train_batch_begin: 1598501728.675435s

1 step training time: 0.350705s

on_train_batch_end: 1598501729.026294s

 2048/50000 [>.............................] - ETA: 16s - loss: 1.0790 - accuracy: 0.1004
on_train_batch_begin: 1598501729.026517s

2 step training time: 0.351082s

on_train_batch_end: 1598501729.383246s

 3072/50000 [>.............................] - ETA: 16s - loss: 1.0858 - accuracy: 0.1003
on_train_batch_begin: 1598501729.383474s

3 step training time: 0.356957s

on_train_batch_end: 1598501729.736614s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.0743 - accuracy: 0.1004
on_train_batch_begin: 1598501729.736830s

4 step training time: 0.353357s

on_train_batch_end: 1598501730.087234s

 5120/50000 [==>...........................] - ETA: 15s - loss: 1.1014 - accuracy: 0.1003
on_train_batch_begin: 1598501730.087455s

5 step training time: 0.350625s

on_train_batch_end: 1598501730.444362s

 6144/50000 [==>...........................] - ETA: 15s - loss: 1.0911 - accuracy: 0.1003
on_train_batch_begin: 1598501730.444595s

6 step training time: 0.357140s

on_train_batch_end: 1598501730.798018s

 7168/50000 [===>..........................] - ETA: 14s - loss: 1.0961 - accuracy: 0.1003
on_train_batch_begin: 1598501730.798312s

7 step training time: 0.353717s

on_train_batch_end: 1598501731.153492s

 8192/50000 [===>..........................] - ETA: 14s - loss: 1.1152 - accuracy: 0.1003
on_train_batch_begin: 1598501731.153749s

8 step training time: 0.355437s

on_train_batch_end: 1598501731.506984s

 9216/50000 [====>.........................] - ETA: 14s - loss: 1.1066 - accuracy: 0.1003
on_train_batch_begin: 1598501731.507213s

9 step training time: 0.353464s

on_train_batch_end: 1598501731.861542s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.1159 - accuracy: 0.1003
on_train_batch_begin: 1598501731.861764s

10 step training time: 0.354551s

on_train_batch_end: 1598501732.215731s

11264/50000 [=====>........................] - ETA: 13s - loss: 1.1061 - accuracy: 0.1003
on_train_batch_begin: 1598501732.215971s

11 step training time: 0.354207s

on_train_batch_end: 1598501732.570949s

12288/50000 [======>.......................] - ETA: 13s - loss: 1.1125 - accuracy: 0.1003
on_train_batch_begin: 1598501732.571191s

12 step training time: 0.355220s

on_train_batch_end: 1598501732.924736s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.1194 - accuracy: 0.1003
on_train_batch_begin: 1598501732.924977s

13 step training time: 0.353786s

on_train_batch_end: 1598501733.280531s

14336/50000 [=======>......................] - ETA: 12s - loss: 1.1081 - accuracy: 0.1003
on_train_batch_begin: 1598501733.280773s

14 step training time: 0.355796s

on_train_batch_end: 1598501733.635162s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.1107 - accuracy: 0.1002
on_train_batch_begin: 1598501733.635402s

15 step training time: 0.354629s

on_train_batch_end: 1598501733.987191s

16384/50000 [========>.....................] - ETA: 11s - loss: 1.1218 - accuracy: 0.1003
on_train_batch_begin: 1598501733.987423s

16 step training time: 0.352021s

on_train_batch_end: 1598501734.342113s

17408/50000 [=========>....................] - ETA: 11s - loss: 1.1194 - accuracy: 0.1004
on_train_batch_begin: 1598501734.342354s

17 step training time: 0.354930s

on_train_batch_end: 1598501734.696895s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.1208 - accuracy: 0.1003
on_train_batch_begin: 1598501734.697159s

18 step training time: 0.354805s

on_train_batch_end: 1598501735.050370s

19456/50000 [==========>...................] - ETA: 10s - loss: 1.1138 - accuracy: 0.1004
on_train_batch_begin: 1598501735.050614s

19 step training time: 0.353456s

on_train_batch_end: 1598501735.403232s

20480/50000 [===========>..................] - ETA: 10s - loss: 1.1098 - accuracy: 0.1004
on_train_batch_begin: 1598501735.403474s

20 step training time: 0.352860s

on_train_batch_end: 1598501735.757850s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.1087 - accuracy: 0.1003 
on_train_batch_begin: 1598501735.758135s

21 step training time: 0.354661s

on_train_batch_end: 1598501736.114663s

22528/50000 [============>.................] - ETA: 9s - loss: 1.1061 - accuracy: 0.1003
on_train_batch_begin: 1598501736.114935s

22 step training time: 0.356800s

on_train_batch_end: 1598501736.470467s

23552/50000 [=============>................] - ETA: 9s - loss: 1.1047 - accuracy: 0.1003
on_train_batch_begin: 1598501736.470727s

23 step training time: 0.355792s

on_train_batch_end: 1598501736.824274s

24576/50000 [=============>................] - ETA: 8s - loss: 1.0939 - accuracy: 0.1003
on_train_batch_begin: 1598501736.824510s

24 step training time: 0.353782s

on_train_batch_end: 1598501737.177674s

25600/50000 [==============>...............] - ETA: 8s - loss: 1.0922 - accuracy: 0.1003
on_train_batch_begin: 1598501737.177918s

25 step training time: 0.353408s

on_train_batch_end: 1598501737.533452s

26624/50000 [==============>...............] - ETA: 8s - loss: 1.0881 - accuracy: 0.1003
on_train_batch_begin: 1598501737.533702s

26 step training time: 0.355784s

on_train_batch_end: 1598501737.890223s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.0859 - accuracy: 0.1003
on_train_batch_begin: 1598501737.890457s

27 step training time: 0.356755s

on_train_batch_end: 1598501738.246448s

28672/50000 [================>.............] - ETA: 7s - loss: 1.0876 - accuracy: 0.1003
on_train_batch_begin: 1598501738.246681s

28 step training time: 0.356224s

on_train_batch_end: 1598501738.601347s

29696/50000 [================>.............] - ETA: 7s - loss: 1.0857 - accuracy: 0.1003
on_train_batch_begin: 1598501738.601594s

29 step training time: 0.354913s

on_train_batch_end: 1598501738.955188s

30720/50000 [=================>............] - ETA: 6s - loss: 1.0847 - accuracy: 0.1003
on_train_batch_begin: 1598501738.955427s

30 step training time: 0.353833s

on_train_batch_end: 1598501739.313751s

31744/50000 [==================>...........] - ETA: 6s - loss: 1.0793 - accuracy: 0.1003
on_train_batch_begin: 1598501739.313992s

31 step training time: 0.358565s

on_train_batch_end: 1598501739.667048s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.0757 - accuracy: 0.1003
on_train_batch_begin: 1598501739.667293s

32 step training time: 0.353301s

on_train_batch_end: 1598501740.024451s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.0750 - accuracy: 0.1003
on_train_batch_begin: 1598501740.024681s

33 step training time: 0.357388s

on_train_batch_end: 1598501740.378904s

34816/50000 [===================>..........] - ETA: 5s - loss: 1.0746 - accuracy: 0.1003
on_train_batch_begin: 1598501740.379141s

34 step training time: 0.354460s

on_train_batch_end: 1598501740.733147s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.0705 - accuracy: 0.1003
on_train_batch_begin: 1598501740.733425s

35 step training time: 0.354284s

on_train_batch_end: 1598501741.089806s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.0689 - accuracy: 0.1003
on_train_batch_begin: 1598501741.090060s

36 step training time: 0.356636s

on_train_batch_end: 1598501741.444812s

37888/50000 [=====================>........] - ETA: 4s - loss: 1.0661 - accuracy: 0.1003
on_train_batch_begin: 1598501741.445043s

37 step training time: 0.354983s

on_train_batch_end: 1598501741.805338s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.0645 - accuracy: 0.1003
on_train_batch_begin: 1598501741.805599s

38 step training time: 0.360556s

on_train_batch_end: 1598501742.161551s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.0612 - accuracy: 0.1003
on_train_batch_begin: 1598501742.161783s

39 step training time: 0.356183s

on_train_batch_end: 1598501742.519254s

40960/50000 [=======================>......] - ETA: 3s - loss: 1.0581 - accuracy: 0.1003
on_train_batch_begin: 1598501742.519481s

40 step training time: 0.357699s

on_train_batch_end: 1598501742.874338s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.0537 - accuracy: 0.1003
on_train_batch_begin: 1598501742.874557s

41 step training time: 0.355076s

on_train_batch_end: 1598501743.232440s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.0482 - accuracy: 0.1003
on_train_batch_begin: 1598501743.232657s

42 step training time: 0.358100s

on_train_batch_end: 1598501743.587179s

44032/50000 [=========================>....] - ETA: 2s - loss: 1.0463 - accuracy: 0.1003
on_train_batch_begin: 1598501743.587411s

43 step training time: 0.354754s

on_train_batch_end: 1598501743.945863s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.0434 - accuracy: 0.1003
on_train_batch_begin: 1598501743.946096s

44 step training time: 0.358685s

on_train_batch_end: 1598501744.302408s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.0410 - accuracy: 0.1003
on_train_batch_begin: 1598501744.302643s

45 step training time: 0.356547s

on_train_batch_end: 1598501744.658143s

47104/50000 [===========================>..] - ETA: 1s - loss: 1.0400 - accuracy: 0.1003
on_train_batch_begin: 1598501744.658369s

46 step training time: 0.355726s

on_train_batch_end: 1598501745.014840s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.0397 - accuracy: 0.1003
on_train_batch_begin: 1598501745.015059s

47 step training time: 0.356690s

on_train_batch_end: 1598501745.368227s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0387 - accuracy: 0.1003
on_train_batch_begin: 1598501745.368453s

48 step training time: 0.353394s

on_train_batch_end: 1598501745.664684s

on_test_batch_begin: 1598501745.679619s

49 step training time: 0.311167s

on_epoch_end: 1598501746.513500s

Validation time: 0.833869s

Real time: 1598501746.513500s

Epoch time: 18.191962718963623s

50000/50000 [==============================] - 18s 364us/sample - loss: 1.0346 - accuracy: 0.1003 - val_loss: 6.2637 - val_accuracy: 0.1001
Tempo do fit: 120.55296063423157