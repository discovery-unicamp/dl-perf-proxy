wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 6:56
   188416/170498071 [..............................] - ETA: 1:18
  1417216/170498071 [..............................] - ETA: 16s 
  4349952/170498071 [..............................] - ETA: 7s 
  7757824/170498071 [>.............................] - ETA: 5s
 11214848/170498071 [>.............................] - ETA: 4s
 14884864/170498071 [=>............................] - ETA: 3s
 18554880/170498071 [==>...........................] - ETA: 3s
 21815296/170498071 [==>...........................] - ETA: 3s
 25092096/170498071 [===>..........................] - ETA: 2s
 28680192/170498071 [====>.........................] - ETA: 2s
 32333824/170498071 [====>.........................] - ETA: 2s
 35872768/170498071 [=====>........................] - ETA: 2s
 39133184/170498071 [=====>........................] - ETA: 2s
 42721280/170498071 [======>.......................] - ETA: 2s
 46342144/170498071 [=======>......................] - ETA: 2s
 49930240/170498071 [=======>......................] - ETA: 2s
 53190656/170498071 [========>.....................] - ETA: 1s
 56696832/170498071 [========>.....................] - ETA: 1s
 60293120/170498071 [=========>....................] - ETA: 1s
 63946752/170498071 [==========>...................] - ETA: 1s
 67231744/170498071 [==========>...................] - ETA: 1s
 70713344/170498071 [===========>..................] - ETA: 1s
 74293248/170498071 [============>.................] - ETA: 1s
 77914112/170498071 [============>.................] - ETA: 1s
 81289216/170498071 [=============>................] - ETA: 1s
 84664320/170498071 [=============>................] - ETA: 1s
 88252416/170498071 [==============>...............] - ETA: 1s
 91824128/170498071 [===============>..............] - ETA: 1s
 95297536/170498071 [===============>..............] - ETA: 1s
 98574336/170498071 [================>.............] - ETA: 1s
102014976/170498071 [================>.............] - ETA: 1s
105684992/170498071 [=================>............] - ETA: 1s
109273088/170498071 [==================>...........] - ETA: 0s
112599040/170498071 [==================>...........] - ETA: 0s
115990528/170498071 [===================>..........] - ETA: 0s
119627776/170498071 [====================>.........] - ETA: 0s
123248640/170498071 [====================>.........] - ETA: 0s
126623744/170498071 [=====================>........] - ETA: 0s
129605632/170498071 [=====================>........] - ETA: 0s
132571136/170498071 [======================>.......] - ETA: 0s
135536640/170498071 [======================>.......] - ETA: 0s
138469376/170498071 [=======================>......] - ETA: 0s
141418496/170498071 [=======================>......] - ETA: 0s
144384000/170498071 [========================>.....] - ETA: 0s
147349504/170498071 [========================>.....] - ETA: 0s
150315008/170498071 [=========================>....] - ETA: 0s
153395200/170498071 [=========================>....] - ETA: 0s
156393472/170498071 [==========================>...] - ETA: 0s
159375360/170498071 [===========================>..] - ETA: 0s
162357248/170498071 [===========================>..] - ETA: 0s
165257216/170498071 [============================>.] - ETA: 0s
168239104/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 5521408/94765736 [>.............................] - ETA: 0s
13017088/94765736 [===>..........................] - ETA: 0s
18989056/94765736 [=====>........................] - ETA: 0s
24223744/94765736 [======>.......................] - ETA: 0s
29106176/94765736 [========>.....................] - ETA: 0s
31940608/94765736 [=========>....................] - ETA: 0s
39403520/94765736 [===========>..................] - ETA: 0s
44531712/94765736 [=============>................] - ETA: 0s
48619520/94765736 [==============>...............] - ETA: 0s
53551104/94765736 [===============>..............] - ETA: 0s
59654144/94765736 [=================>............] - ETA: 0s
61104128/94765736 [==================>...........] - ETA: 0s
69992448/94765736 [=====================>........] - ETA: 0s
75997184/94765736 [=======================>......] - ETA: 0s
81100800/94765736 [========================>.....] - ETA: 0s
85811200/94765736 [==========================>...] - ETA: 0s
90923008/94765736 [===========================>..] - ETA: 0s
94478336/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.243422985076904
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615677051.878590s

Real time: 1615677051.878607
Epoch 1/5

on_train_batch_begin: 1615677052.632363s

on_train_batch_end: 1615677069.351077s

 1024/50000 [..............................] - ETA: 13:55 - loss: 17.7026 - accuracy: 1.8406e-04
on_train_batch_begin: 1615677069.351840s

1 step training time: 16.719477s

on_train_batch_end: 1615677069.682690s

 2048/50000 [>.............................] - ETA: 6:56 - loss: 15.8846 - accuracy: 2.8419e-04 
on_train_batch_begin: 1615677069.683019s

2 step training time: 0.331178s

on_train_batch_end: 1615677070.006371s

 3072/50000 [>.............................] - ETA: 4:36 - loss: 13.8221 - accuracy: 5.9319e-04
on_train_batch_begin: 1615677070.006707s

3 step training time: 0.323689s

on_train_batch_end: 1615677070.327592s

 4096/50000 [=>............................] - ETA: 3:26 - loss: 12.5759 - accuracy: 7.6032e-04
on_train_batch_begin: 1615677070.327908s

4 step training time: 0.321200s

on_train_batch_end: 1615677070.650962s

 5120/50000 [==>...........................] - ETA: 2:44 - loss: 11.6548 - accuracy: 0.0013    
on_train_batch_begin: 1615677070.651284s

5 step training time: 0.323376s

on_train_batch_end: 1615677070.972298s

 6144/50000 [==>...........................] - ETA: 2:16 - loss: 11.0241 - accuracy: 0.0024
on_train_batch_begin: 1615677070.972609s

6 step training time: 0.321325s

on_train_batch_end: 1615677071.298080s

 7168/50000 [===>..........................] - ETA: 1:56 - loss: 10.5477 - accuracy: 0.0039
on_train_batch_begin: 1615677071.298394s

7 step training time: 0.325785s

on_train_batch_end: 1615677071.617864s

 8192/50000 [===>..........................] - ETA: 1:40 - loss: 10.1382 - accuracy: 0.0055
on_train_batch_begin: 1615677071.618189s

8 step training time: 0.319795s

on_train_batch_end: 1615677071.941536s

 9216/50000 [====>.........................] - ETA: 1:28 - loss: 9.8210 - accuracy: 0.0073 
on_train_batch_begin: 1615677071.941834s

9 step training time: 0.323645s

on_train_batch_end: 1615677072.262797s

10240/50000 [=====>........................] - ETA: 1:19 - loss: 9.5363 - accuracy: 0.0091
on_train_batch_begin: 1615677072.263104s

10 step training time: 0.321270s

on_train_batch_end: 1615677072.584865s

11264/50000 [=====>........................] - ETA: 1:11 - loss: 9.3024 - accuracy: 0.0115
on_train_batch_begin: 1615677072.585176s

11 step training time: 0.322072s

on_train_batch_end: 1615677072.906092s

12288/50000 [======>.......................] - ETA: 1:04 - loss: 9.1011 - accuracy: 0.0137
on_train_batch_begin: 1615677072.906396s

12 step training time: 0.321219s

on_train_batch_end: 1615677073.231218s

13312/50000 [======>.......................] - ETA: 58s - loss: 8.9228 - accuracy: 0.0157 
on_train_batch_begin: 1615677073.231522s

13 step training time: 0.325126s

on_train_batch_end: 1615677073.553097s

14336/50000 [=======>......................] - ETA: 53s - loss: 8.7652 - accuracy: 0.0174
on_train_batch_begin: 1615677073.553413s

14 step training time: 0.321892s

on_train_batch_end: 1615677073.876820s

15360/50000 [========>.....................] - ETA: 49s - loss: 8.6232 - accuracy: 0.0190
on_train_batch_begin: 1615677073.877108s

15 step training time: 0.323694s

on_train_batch_end: 1615677074.200816s

16384/50000 [========>.....................] - ETA: 45s - loss: 8.4868 - accuracy: 0.0211
on_train_batch_begin: 1615677074.201134s

16 step training time: 0.324026s

on_train_batch_end: 1615677074.521411s

17408/50000 [=========>....................] - ETA: 42s - loss: 8.3573 - accuracy: 0.0231
on_train_batch_begin: 1615677074.521827s

17 step training time: 0.320693s

on_train_batch_end: 1615677074.842260s

18432/50000 [==========>...................] - ETA: 39s - loss: 8.2433 - accuracy: 0.0247
on_train_batch_begin: 1615677074.842568s

18 step training time: 0.320742s

on_train_batch_end: 1615677075.163458s

19456/50000 [==========>...................] - ETA: 36s - loss: 8.1430 - accuracy: 0.0261
on_train_batch_begin: 1615677075.163755s

19 step training time: 0.321187s

on_train_batch_end: 1615677075.490668s

20480/50000 [===========>..................] - ETA: 34s - loss: 8.0361 - accuracy: 0.0276
on_train_batch_begin: 1615677075.491089s

20 step training time: 0.327334s

on_train_batch_end: 1615677075.813269s

21504/50000 [===========>..................] - ETA: 31s - loss: 7.9433 - accuracy: 0.0290
on_train_batch_begin: 1615677075.813543s

21 step training time: 0.322454s

on_train_batch_end: 1615677076.136031s

22528/50000 [============>.................] - ETA: 29s - loss: 7.8447 - accuracy: 0.0300
on_train_batch_begin: 1615677076.136329s

22 step training time: 0.322786s

on_train_batch_end: 1615677076.459496s

23552/50000 [=============>................] - ETA: 27s - loss: 7.7512 - accuracy: 0.0313
on_train_batch_begin: 1615677076.459799s

23 step training time: 0.323469s

on_train_batch_end: 1615677076.780474s

24576/50000 [=============>................] - ETA: 25s - loss: 7.6561 - accuracy: 0.0326
on_train_batch_begin: 1615677076.780745s

24 step training time: 0.320946s

on_train_batch_end: 1615677077.108969s

25600/50000 [==============>...............] - ETA: 24s - loss: 7.5655 - accuracy: 0.0339
on_train_batch_begin: 1615677077.109261s

25 step training time: 0.328516s

on_train_batch_end: 1615677077.435571s

26624/50000 [==============>...............] - ETA: 22s - loss: 7.4811 - accuracy: 0.0352
on_train_batch_begin: 1615677077.435879s

26 step training time: 0.326618s

on_train_batch_end: 1615677077.760643s

27648/50000 [===============>..............] - ETA: 20s - loss: 7.3988 - accuracy: 0.0365
on_train_batch_begin: 1615677077.760947s

27 step training time: 0.325068s

on_train_batch_end: 1615677078.082649s

28672/50000 [================>.............] - ETA: 19s - loss: 7.3233 - accuracy: 0.0377
on_train_batch_begin: 1615677078.082943s

28 step training time: 0.321996s

on_train_batch_end: 1615677078.407234s

29696/50000 [================>.............] - ETA: 18s - loss: 7.2481 - accuracy: 0.0389
on_train_batch_begin: 1615677078.407538s

29 step training time: 0.324595s

on_train_batch_end: 1615677078.731271s

30720/50000 [=================>............] - ETA: 16s - loss: 7.1801 - accuracy: 0.0399
on_train_batch_begin: 1615677078.731568s

30 step training time: 0.324030s

on_train_batch_end: 1615677079.052505s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.1081 - accuracy: 0.0410
on_train_batch_begin: 1615677079.052805s

31 step training time: 0.321237s

on_train_batch_end: 1615677079.371483s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.0425 - accuracy: 0.0420
on_train_batch_begin: 1615677079.371792s

32 step training time: 0.318986s

on_train_batch_end: 1615677079.694082s

33792/50000 [===================>..........] - ETA: 13s - loss: 6.9760 - accuracy: 0.0428
on_train_batch_begin: 1615677079.694395s

33 step training time: 0.322603s

on_train_batch_end: 1615677080.015934s

34816/50000 [===================>..........] - ETA: 12s - loss: 6.9102 - accuracy: 0.0438
on_train_batch_begin: 1615677080.016236s

34 step training time: 0.321841s

on_train_batch_end: 1615677080.340045s

35840/50000 [====================>.........] - ETA: 11s - loss: 6.8476 - accuracy: 0.0447
on_train_batch_begin: 1615677080.340341s

35 step training time: 0.324106s

on_train_batch_end: 1615677080.664171s

36864/50000 [=====================>........] - ETA: 10s - loss: 6.7828 - accuracy: 0.0455
on_train_batch_begin: 1615677080.664475s

36 step training time: 0.324133s

on_train_batch_end: 1615677080.985321s

37888/50000 [=====================>........] - ETA: 9s - loss: 6.7235 - accuracy: 0.0463 
on_train_batch_begin: 1615677080.985620s

37 step training time: 0.321146s

on_train_batch_end: 1615677081.313175s

38912/50000 [======================>.......] - ETA: 8s - loss: 6.6628 - accuracy: 0.0470
on_train_batch_begin: 1615677081.313478s

38 step training time: 0.327857s

on_train_batch_end: 1615677081.638127s

39936/50000 [======================>.......] - ETA: 7s - loss: 6.6031 - accuracy: 0.0478
on_train_batch_begin: 1615677081.638426s

39 step training time: 0.324948s

on_train_batch_end: 1615677081.962457s

40960/50000 [=======================>......] - ETA: 6s - loss: 6.5501 - accuracy: 0.0485
on_train_batch_begin: 1615677081.962774s

40 step training time: 0.324348s

on_train_batch_end: 1615677082.290572s

41984/50000 [========================>.....] - ETA: 5s - loss: 6.4942 - accuracy: 0.0491
on_train_batch_begin: 1615677082.290911s

41 step training time: 0.328137s

on_train_batch_end: 1615677082.617774s

43008/50000 [========================>.....] - ETA: 4s - loss: 6.4383 - accuracy: 0.0498
on_train_batch_begin: 1615677082.618059s

42 step training time: 0.327147s

on_train_batch_end: 1615677082.942843s

44032/50000 [=========================>....] - ETA: 4s - loss: 6.3782 - accuracy: 0.0506
on_train_batch_begin: 1615677082.943129s

43 step training time: 0.325070s

on_train_batch_end: 1615677083.266410s

45056/50000 [==========================>...] - ETA: 3s - loss: 6.3272 - accuracy: 0.0512
on_train_batch_begin: 1615677083.266734s

44 step training time: 0.323605s

on_train_batch_end: 1615677083.588246s

46080/50000 [==========================>...] - ETA: 2s - loss: 6.2731 - accuracy: 0.0519
on_train_batch_begin: 1615677083.588525s

45 step training time: 0.321791s

on_train_batch_end: 1615677083.912299s

47104/50000 [===========================>..] - ETA: 1s - loss: 6.2232 - accuracy: 0.0525
on_train_batch_begin: 1615677083.912712s

46 step training time: 0.324187s

on_train_batch_end: 1615677084.238817s

48128/50000 [===========================>..] - ETA: 1s - loss: 6.1737 - accuracy: 0.0532
on_train_batch_begin: 1615677084.239118s

47 step training time: 0.326405s

on_train_batch_end: 1615677084.563468s

49152/50000 [============================>.] - ETA: 0s - loss: 6.1209 - accuracy: 0.0538
on_train_batch_begin: 1615677084.563777s

48 step training time: 0.324659s

on_train_batch_end: 1615677090.327680s

on_test_batch_begin: 1615677090.517514s

49 step training time: 5.953737s

on_epoch_end: 1615677095.075642s

Validation time: 4.558114s

Real time: 1615677095.075642s

Epoch time: 43.19704484939575s

50000/50000 [==============================] - 43s 864us/sample - loss: 6.0763 - accuracy: 0.0542 - val_loss: 199.2251 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615677095.075858s

Real time: 1615677095.0758626
Epoch 2/5

on_train_batch_begin: 1615677095.079428s

on_train_batch_end: 1615677095.405312s

 1024/50000 [..............................] - ETA: 15s - loss: 3.5008 - accuracy: 0.0827
on_train_batch_begin: 1615677095.405591s

1 step training time: 0.326163s

on_train_batch_end: 1615677095.727177s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.4026 - accuracy: 0.0860
on_train_batch_begin: 1615677095.727475s

2 step training time: 0.321884s

on_train_batch_end: 1615677096.051753s

 3072/50000 [>.............................] - ETA: 14s - loss: 3.2907 - accuracy: 0.0869
on_train_batch_begin: 1615677096.052063s

3 step training time: 0.324588s

on_train_batch_end: 1615677096.373333s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.3197 - accuracy: 0.0868
on_train_batch_begin: 1615677096.373635s

4 step training time: 0.321572s

on_train_batch_end: 1615677096.698169s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.3104 - accuracy: 0.0876
on_train_batch_begin: 1615677096.698444s

5 step training time: 0.324809s

on_train_batch_end: 1615677097.019898s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.2657 - accuracy: 0.0880
on_train_batch_begin: 1615677097.020193s

6 step training time: 0.321749s

on_train_batch_end: 1615677097.344329s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.2384 - accuracy: 0.0884
on_train_batch_begin: 1615677097.344623s

7 step training time: 0.324430s

on_train_batch_end: 1615677097.666764s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.1988 - accuracy: 0.0893
on_train_batch_begin: 1615677097.667049s

8 step training time: 0.322426s

on_train_batch_end: 1615677097.993537s

 9216/50000 [====>.........................] - ETA: 12s - loss: 3.1654 - accuracy: 0.0901
on_train_batch_begin: 1615677097.993835s

9 step training time: 0.326786s

on_train_batch_end: 1615677098.317617s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.1487 - accuracy: 0.0906
on_train_batch_begin: 1615677098.317921s

10 step training time: 0.324085s

on_train_batch_end: 1615677098.641592s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.0955 - accuracy: 0.0914
on_train_batch_begin: 1615677098.641900s

11 step training time: 0.323980s

on_train_batch_end: 1615677098.966958s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.0657 - accuracy: 0.0918
on_train_batch_begin: 1615677098.967257s

12 step training time: 0.325357s

on_train_batch_end: 1615677099.293316s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.0302 - accuracy: 0.0923
on_train_batch_begin: 1615677099.293635s

13 step training time: 0.326378s

on_train_batch_end: 1615677099.617887s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.9894 - accuracy: 0.0927
on_train_batch_begin: 1615677099.618208s

14 step training time: 0.324573s

on_train_batch_end: 1615677099.942273s

15360/50000 [========>.....................] - ETA: 10s - loss: 2.9571 - accuracy: 0.0932
on_train_batch_begin: 1615677099.942588s

15 step training time: 0.324381s

on_train_batch_end: 1615677100.270266s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.9288 - accuracy: 0.0934
on_train_batch_begin: 1615677100.270570s

16 step training time: 0.327981s

on_train_batch_end: 1615677100.594261s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.9027 - accuracy: 0.0938
on_train_batch_begin: 1615677100.594687s

17 step training time: 0.324118s

on_train_batch_end: 1615677100.918339s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.8806 - accuracy: 0.0941
on_train_batch_begin: 1615677100.918650s

18 step training time: 0.323963s

on_train_batch_end: 1615677101.242990s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.8549 - accuracy: 0.0944 
on_train_batch_begin: 1615677101.243280s

19 step training time: 0.324630s

on_train_batch_end: 1615677101.567245s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.8375 - accuracy: 0.0946
on_train_batch_begin: 1615677101.567522s

20 step training time: 0.324242s

on_train_batch_end: 1615677101.891552s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.8056 - accuracy: 0.0949
on_train_batch_begin: 1615677101.891858s

21 step training time: 0.324335s

on_train_batch_end: 1615677102.214796s

22528/50000 [============>.................] - ETA: 8s - loss: 2.7925 - accuracy: 0.0951
on_train_batch_begin: 1615677102.215090s

22 step training time: 0.323233s

on_train_batch_end: 1615677102.538888s

23552/50000 [=============>................] - ETA: 8s - loss: 2.7777 - accuracy: 0.0953
on_train_batch_begin: 1615677102.539171s

23 step training time: 0.324080s

on_train_batch_end: 1615677102.866692s

24576/50000 [=============>................] - ETA: 8s - loss: 2.7622 - accuracy: 0.0955
on_train_batch_begin: 1615677102.866980s

24 step training time: 0.327810s

on_train_batch_end: 1615677103.189066s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.7439 - accuracy: 0.0957
on_train_batch_begin: 1615677103.189353s

25 step training time: 0.322373s

on_train_batch_end: 1615677103.512408s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.7241 - accuracy: 0.0958
on_train_batch_begin: 1615677103.512684s

26 step training time: 0.323331s

on_train_batch_end: 1615677103.839488s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.7128 - accuracy: 0.0960
on_train_batch_begin: 1615677103.839776s

27 step training time: 0.327092s

on_train_batch_end: 1615677104.162916s

28672/50000 [================>.............] - ETA: 6s - loss: 2.7037 - accuracy: 0.0961
on_train_batch_begin: 1615677104.163219s

28 step training time: 0.323444s

on_train_batch_end: 1615677104.487301s

29696/50000 [================>.............] - ETA: 6s - loss: 2.6910 - accuracy: 0.0963
on_train_batch_begin: 1615677104.487588s

29 step training time: 0.324368s

on_train_batch_end: 1615677104.812599s

30720/50000 [=================>............] - ETA: 6s - loss: 2.6852 - accuracy: 0.0964
on_train_batch_begin: 1615677104.812883s

30 step training time: 0.325295s

on_train_batch_end: 1615677105.135389s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.6713 - accuracy: 0.0965
on_train_batch_begin: 1615677105.135708s

31 step training time: 0.322825s

on_train_batch_end: 1615677105.462950s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.6626 - accuracy: 0.0967
on_train_batch_begin: 1615677105.463248s

32 step training time: 0.327540s

on_train_batch_end: 1615677105.786859s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.6549 - accuracy: 0.0967
on_train_batch_begin: 1615677105.787139s

33 step training time: 0.323892s

on_train_batch_end: 1615677106.110309s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.6455 - accuracy: 0.0968
on_train_batch_begin: 1615677106.110645s

34 step training time: 0.323505s

on_train_batch_end: 1615677106.436724s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.6393 - accuracy: 0.0969
on_train_batch_begin: 1615677106.437017s

35 step training time: 0.326372s

on_train_batch_end: 1615677106.760262s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.6304 - accuracy: 0.0970
on_train_batch_begin: 1615677106.760555s

36 step training time: 0.323538s

on_train_batch_end: 1615677107.083964s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.6245 - accuracy: 0.0971
on_train_batch_begin: 1615677107.084270s

37 step training time: 0.323715s

on_train_batch_end: 1615677107.412996s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.6158 - accuracy: 0.0972
on_train_batch_begin: 1615677107.413295s

38 step training time: 0.329026s

on_train_batch_end: 1615677107.736267s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.6031 - accuracy: 0.0973
on_train_batch_begin: 1615677107.736577s

39 step training time: 0.323282s

on_train_batch_end: 1615677108.061499s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.5946 - accuracy: 0.0973
on_train_batch_begin: 1615677108.061804s

40 step training time: 0.325227s

on_train_batch_end: 1615677108.386170s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.5868 - accuracy: 0.0974
on_train_batch_begin: 1615677108.386474s

41 step training time: 0.324670s

on_train_batch_end: 1615677108.710290s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.5725 - accuracy: 0.0974
on_train_batch_begin: 1615677108.710578s

42 step training time: 0.324104s

on_train_batch_end: 1615677109.032558s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.5579 - accuracy: 0.0975
on_train_batch_begin: 1615677109.032847s

43 step training time: 0.322269s

on_train_batch_end: 1615677109.355629s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.5490 - accuracy: 0.0975
on_train_batch_begin: 1615677109.355924s

44 step training time: 0.323077s

on_train_batch_end: 1615677109.678686s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.5396 - accuracy: 0.0976
on_train_batch_begin: 1615677109.678992s

45 step training time: 0.323067s

on_train_batch_end: 1615677110.002504s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.5319 - accuracy: 0.0977
on_train_batch_begin: 1615677110.002837s

46 step training time: 0.323845s

on_train_batch_end: 1615677110.330711s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.5195 - accuracy: 0.0977
on_train_batch_begin: 1615677110.331010s

47 step training time: 0.328173s

on_train_batch_end: 1615677110.653978s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5096 - accuracy: 0.0978
on_train_batch_begin: 1615677110.654281s

48 step training time: 0.323271s

on_train_batch_end: 1615677110.922451s

on_test_batch_begin: 1615677110.932704s

49 step training time: 0.278423s

on_epoch_end: 1615677111.722169s

Validation time: 0.789454s

Real time: 1615677111.722169s

Epoch time: 16.646323442459106s

50000/50000 [==============================] - 17s 333us/sample - loss: 2.5027 - accuracy: 0.0978 - val_loss: 8.1770 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615677111.722360s

Real time: 1615677111.722365
Epoch 3/5

on_train_batch_begin: 1615677111.725749s

on_train_batch_end: 1615677112.048544s

 1024/50000 [..............................] - ETA: 15s - loss: 1.9682 - accuracy: 0.1006
on_train_batch_begin: 1615677112.048814s

1 step training time: 0.323065s

on_train_batch_end: 1615677112.374343s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.9104 - accuracy: 0.1006
on_train_batch_begin: 1615677112.374656s

2 step training time: 0.325842s

on_train_batch_end: 1615677112.699669s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.9762 - accuracy: 0.1004
on_train_batch_begin: 1615677112.699968s

3 step training time: 0.325311s

on_train_batch_end: 1615677113.025158s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.9638 - accuracy: 0.1005
on_train_batch_begin: 1615677113.025448s

4 step training time: 0.325480s

on_train_batch_end: 1615677113.351234s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.9440 - accuracy: 0.1004
on_train_batch_begin: 1615677113.351506s

5 step training time: 0.326058s

on_train_batch_end: 1615677113.675119s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.9767 - accuracy: 0.1003
on_train_batch_begin: 1615677113.675411s

6 step training time: 0.323905s

on_train_batch_end: 1615677113.997030s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.9819 - accuracy: 0.1003
on_train_batch_begin: 1615677113.997310s

7 step training time: 0.321899s

on_train_batch_end: 1615677114.320744s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.9846 - accuracy: 0.1002
on_train_batch_begin: 1615677114.321016s

8 step training time: 0.323706s

on_train_batch_end: 1615677114.646193s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.9737 - accuracy: 0.1002
on_train_batch_begin: 1615677114.646467s

9 step training time: 0.325451s

on_train_batch_end: 1615677114.971811s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.9676 - accuracy: 0.1002
on_train_batch_begin: 1615677114.972124s

10 step training time: 0.325657s

on_train_batch_end: 1615677115.295982s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.9600 - accuracy: 0.1002
on_train_batch_begin: 1615677115.296285s

11 step training time: 0.324161s

on_train_batch_end: 1615677115.619933s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.9506 - accuracy: 0.1001
on_train_batch_begin: 1615677115.620225s

12 step training time: 0.323940s

on_train_batch_end: 1615677115.944726s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.9408 - accuracy: 0.1002
on_train_batch_begin: 1615677115.945033s

13 step training time: 0.324808s

on_train_batch_end: 1615677116.272913s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.9405 - accuracy: 0.1002
on_train_batch_begin: 1615677116.273205s

14 step training time: 0.328172s

on_train_batch_end: 1615677116.592491s

15360/50000 [========>.....................] - ETA: 10s - loss: 1.9391 - accuracy: 0.1002
on_train_batch_begin: 1615677116.592766s

15 step training time: 0.319561s

on_train_batch_end: 1615677116.915982s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.9419 - accuracy: 0.1001
on_train_batch_begin: 1615677116.916266s

16 step training time: 0.323500s

on_train_batch_end: 1615677117.241511s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.9368 - accuracy: 0.1001
on_train_batch_begin: 1615677117.241801s

17 step training time: 0.325535s

on_train_batch_end: 1615677117.565455s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.9321 - accuracy: 0.1001
on_train_batch_begin: 1615677117.565747s

18 step training time: 0.323946s

on_train_batch_end: 1615677117.890259s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.9266 - accuracy: 0.1001 
on_train_batch_begin: 1615677117.890558s

19 step training time: 0.324812s

on_train_batch_end: 1615677118.213040s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.9224 - accuracy: 0.1002
on_train_batch_begin: 1615677118.213339s

20 step training time: 0.322780s

on_train_batch_end: 1615677118.537180s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.9192 - accuracy: 0.1002
on_train_batch_begin: 1615677118.537486s

21 step training time: 0.324147s

on_train_batch_end: 1615677118.861109s

22528/50000 [============>.................] - ETA: 8s - loss: 1.9197 - accuracy: 0.1002
on_train_batch_begin: 1615677118.861406s

22 step training time: 0.323920s

on_train_batch_end: 1615677119.185751s

23552/50000 [=============>................] - ETA: 8s - loss: 1.9155 - accuracy: 0.1002
on_train_batch_begin: 1615677119.186064s

23 step training time: 0.324659s

on_train_batch_end: 1615677119.509719s

24576/50000 [=============>................] - ETA: 8s - loss: 1.9130 - accuracy: 0.1002
on_train_batch_begin: 1615677119.510001s

24 step training time: 0.323937s

on_train_batch_end: 1615677119.833533s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.9120 - accuracy: 0.1002
on_train_batch_begin: 1615677119.833813s

25 step training time: 0.323812s

on_train_batch_end: 1615677120.159255s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.9065 - accuracy: 0.1002
on_train_batch_begin: 1615677120.159583s

26 step training time: 0.325770s

on_train_batch_end: 1615677120.482248s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.8990 - accuracy: 0.1001
on_train_batch_begin: 1615677120.482545s

27 step training time: 0.322962s

on_train_batch_end: 1615677120.806381s

28672/50000 [================>.............] - ETA: 6s - loss: 1.8904 - accuracy: 0.1001
on_train_batch_begin: 1615677120.806693s

28 step training time: 0.324147s

on_train_batch_end: 1615677121.131684s

29696/50000 [================>.............] - ETA: 6s - loss: 1.8889 - accuracy: 0.1001
on_train_batch_begin: 1615677121.131981s

29 step training time: 0.325289s

on_train_batch_end: 1615677121.458562s

30720/50000 [=================>............] - ETA: 6s - loss: 1.8794 - accuracy: 0.1001
on_train_batch_begin: 1615677121.458890s

30 step training time: 0.326909s

on_train_batch_end: 1615677121.783727s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.8726 - accuracy: 0.1001
on_train_batch_begin: 1615677121.784030s

31 step training time: 0.325140s

on_train_batch_end: 1615677122.112230s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.8656 - accuracy: 0.1001
on_train_batch_begin: 1615677122.112532s

32 step training time: 0.328502s

on_train_batch_end: 1615677122.442217s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.8635 - accuracy: 0.1002
on_train_batch_begin: 1615677122.442525s

33 step training time: 0.329993s

on_train_batch_end: 1615677122.768438s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.8555 - accuracy: 0.1002
on_train_batch_begin: 1615677122.768726s

34 step training time: 0.326201s

on_train_batch_end: 1615677123.094499s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.8561 - accuracy: 0.1002
on_train_batch_begin: 1615677123.094826s

35 step training time: 0.326100s

on_train_batch_end: 1615677123.422090s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.8444 - accuracy: 0.1002
on_train_batch_begin: 1615677123.422413s

36 step training time: 0.327587s

on_train_batch_end: 1615677123.749632s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.8424 - accuracy: 0.1002
on_train_batch_begin: 1615677123.749938s

37 step training time: 0.327525s

on_train_batch_end: 1615677124.071758s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.8406 - accuracy: 0.1002
on_train_batch_begin: 1615677124.072162s

38 step training time: 0.322224s

on_train_batch_end: 1615677124.398331s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.8377 - accuracy: 0.1002
on_train_batch_begin: 1615677124.398678s

39 step training time: 0.326516s

on_train_batch_end: 1615677124.721972s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.8416 - accuracy: 0.1002
on_train_batch_begin: 1615677124.722278s

40 step training time: 0.323600s

on_train_batch_end: 1615677125.050639s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.8388 - accuracy: 0.1002
on_train_batch_begin: 1615677125.050935s

41 step training time: 0.328657s

on_train_batch_end: 1615677125.379001s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.8392 - accuracy: 0.1002
on_train_batch_begin: 1615677125.379470s

42 step training time: 0.328535s

on_train_batch_end: 1615677125.712977s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.8398 - accuracy: 0.1002
on_train_batch_begin: 1615677125.713280s

43 step training time: 0.333810s

on_train_batch_end: 1615677126.039627s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8433 - accuracy: 0.1002
on_train_batch_begin: 1615677126.040027s

44 step training time: 0.326747s

on_train_batch_end: 1615677126.368036s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.8429 - accuracy: 0.1002
on_train_batch_begin: 1615677126.368357s

45 step training time: 0.328331s

on_train_batch_end: 1615677126.692339s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8452 - accuracy: 0.1002
on_train_batch_begin: 1615677126.692643s

46 step training time: 0.324286s

on_train_batch_end: 1615677127.018894s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.8481 - accuracy: 0.1002
on_train_batch_begin: 1615677127.019199s

47 step training time: 0.326556s

on_train_batch_end: 1615677127.340569s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8465 - accuracy: 0.1002
on_train_batch_begin: 1615677127.340869s

48 step training time: 0.321669s

on_train_batch_end: 1615677127.606950s

on_test_batch_begin: 1615677127.620173s

49 step training time: 0.279304s

on_epoch_end: 1615677128.419334s

Validation time: 0.799149s

Real time: 1615677128.419334s

Epoch time: 16.69698476791382s

50000/50000 [==============================] - 17s 334us/sample - loss: 1.8477 - accuracy: 0.1002 - val_loss: 7.4274 - val_accuracy: 0.1001

on_epoch_begin: 1615677128.419521s

Real time: 1615677128.4195259
Epoch 4/5

on_train_batch_begin: 1615677128.422959s

on_train_batch_end: 1615677128.749432s

 1024/50000 [..............................] - ETA: 15s - loss: 1.5467 - accuracy: 0.1000
on_train_batch_begin: 1615677128.749714s

1 step training time: 0.326756s

on_train_batch_end: 1615677129.074591s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.6474 - accuracy: 0.1001
on_train_batch_begin: 1615677129.074912s

2 step training time: 0.325198s

on_train_batch_end: 1615677129.403811s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.7104 - accuracy: 0.1000
on_train_batch_begin: 1615677129.404103s

3 step training time: 0.329190s

on_train_batch_end: 1615677129.729940s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.6806 - accuracy: 0.1002
on_train_batch_begin: 1615677129.730221s

4 step training time: 0.326118s

on_train_batch_end: 1615677130.055955s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.6760 - accuracy: 0.1003
on_train_batch_begin: 1615677130.056264s

5 step training time: 0.326043s

on_train_batch_end: 1615677130.380410s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.6761 - accuracy: 0.1002
on_train_batch_begin: 1615677130.380709s

6 step training time: 0.324445s

on_train_batch_end: 1615677130.703875s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.6745 - accuracy: 0.1002
on_train_batch_begin: 1615677130.704179s

7 step training time: 0.323470s

on_train_batch_end: 1615677131.028300s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.7224 - accuracy: 0.1002
on_train_batch_begin: 1615677131.028624s

8 step training time: 0.324445s

on_train_batch_end: 1615677131.354968s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.7136 - accuracy: 0.1002
on_train_batch_begin: 1615677131.355280s

9 step training time: 0.326656s

on_train_batch_end: 1615677131.686539s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.7023 - accuracy: 0.1002
on_train_batch_begin: 1615677131.686885s

10 step training time: 0.331605s

on_train_batch_end: 1615677132.014421s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.6906 - accuracy: 0.1002
on_train_batch_begin: 1615677132.014757s

11 step training time: 0.327873s

on_train_batch_end: 1615677132.341335s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.6771 - accuracy: 0.1002
on_train_batch_begin: 1615677132.341635s

12 step training time: 0.326878s

on_train_batch_end: 1615677132.666157s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.6575 - accuracy: 0.1001
on_train_batch_begin: 1615677132.666433s

13 step training time: 0.324798s

on_train_batch_end: 1615677132.993026s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.6436 - accuracy: 0.1001
on_train_batch_begin: 1615677132.993320s

14 step training time: 0.326886s

on_train_batch_end: 1615677133.317001s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.6339 - accuracy: 0.1002
on_train_batch_begin: 1615677133.317301s

15 step training time: 0.323981s

on_train_batch_end: 1615677133.640051s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.6186 - accuracy: 0.1002
on_train_batch_begin: 1615677133.640322s

16 step training time: 0.323021s

on_train_batch_end: 1615677133.963941s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.6052 - accuracy: 0.1001
on_train_batch_begin: 1615677133.964232s

17 step training time: 0.323911s

on_train_batch_end: 1615677134.289996s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.5951 - accuracy: 0.1001
on_train_batch_begin: 1615677134.290290s

18 step training time: 0.326058s

on_train_batch_end: 1615677134.612149s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.5859 - accuracy: 0.1002 
on_train_batch_begin: 1615677134.612436s

19 step training time: 0.322146s

on_train_batch_end: 1615677134.935224s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.5767 - accuracy: 0.1002
on_train_batch_begin: 1615677134.935508s

20 step training time: 0.323072s

on_train_batch_end: 1615677135.261375s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.5811 - accuracy: 0.1002
on_train_batch_begin: 1615677135.261666s

21 step training time: 0.326158s

on_train_batch_end: 1615677135.587457s

22528/50000 [============>.................] - ETA: 8s - loss: 1.5654 - accuracy: 0.1002
on_train_batch_begin: 1615677135.587766s

22 step training time: 0.326100s

on_train_batch_end: 1615677135.913076s

23552/50000 [=============>................] - ETA: 8s - loss: 1.5534 - accuracy: 0.1002
on_train_batch_begin: 1615677135.913368s

23 step training time: 0.325602s

on_train_batch_end: 1615677136.235321s

24576/50000 [=============>................] - ETA: 8s - loss: 1.5414 - accuracy: 0.1002
on_train_batch_begin: 1615677136.235605s

24 step training time: 0.322237s

on_train_batch_end: 1615677136.560232s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.5379 - accuracy: 0.1002
on_train_batch_begin: 1615677136.560599s

25 step training time: 0.324994s

on_train_batch_end: 1615677136.888252s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.5271 - accuracy: 0.1002
on_train_batch_begin: 1615677136.888543s

26 step training time: 0.327944s

on_train_batch_end: 1615677137.213010s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.5209 - accuracy: 0.1002
on_train_batch_begin: 1615677137.213298s

27 step training time: 0.324755s

on_train_batch_end: 1615677137.536479s

28672/50000 [================>.............] - ETA: 6s - loss: 1.5101 - accuracy: 0.1002
on_train_batch_begin: 1615677137.536767s

28 step training time: 0.323470s

on_train_batch_end: 1615677137.867840s

29696/50000 [================>.............] - ETA: 6s - loss: 1.5021 - accuracy: 0.1002
on_train_batch_begin: 1615677137.868125s

29 step training time: 0.331357s

on_train_batch_end: 1615677138.195944s

30720/50000 [=================>............] - ETA: 6s - loss: 1.5003 - accuracy: 0.1002
on_train_batch_begin: 1615677138.196255s

30 step training time: 0.328131s

on_train_batch_end: 1615677138.523118s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.4919 - accuracy: 0.1002
on_train_batch_begin: 1615677138.523427s

31 step training time: 0.327172s

on_train_batch_end: 1615677138.848556s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.4909 - accuracy: 0.1002
on_train_batch_begin: 1615677138.848860s

32 step training time: 0.325433s

on_train_batch_end: 1615677139.172322s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.4836 - accuracy: 0.1002
on_train_batch_begin: 1615677139.172624s

33 step training time: 0.323763s

on_train_batch_end: 1615677139.499820s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.4791 - accuracy: 0.1002
on_train_batch_begin: 1615677139.500118s

34 step training time: 0.327494s

on_train_batch_end: 1615677139.826195s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.4720 - accuracy: 0.1002
on_train_batch_begin: 1615677139.826490s

35 step training time: 0.326372s

on_train_batch_end: 1615677140.149992s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.4627 - accuracy: 0.1002
on_train_batch_begin: 1615677140.150291s

36 step training time: 0.323802s

on_train_batch_end: 1615677140.474107s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.4521 - accuracy: 0.1002
on_train_batch_begin: 1615677140.474403s

37 step training time: 0.324112s

on_train_batch_end: 1615677140.799521s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.4445 - accuracy: 0.1002
on_train_batch_begin: 1615677140.799825s

38 step training time: 0.325422s

on_train_batch_end: 1615677141.126189s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.4370 - accuracy: 0.1002
on_train_batch_begin: 1615677141.126493s

39 step training time: 0.326667s

on_train_batch_end: 1615677141.451885s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.4272 - accuracy: 0.1002
on_train_batch_begin: 1615677141.452160s

40 step training time: 0.325667s

on_train_batch_end: 1615677141.775496s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.4196 - accuracy: 0.1002
on_train_batch_begin: 1615677141.775784s

41 step training time: 0.323624s

on_train_batch_end: 1615677142.102981s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.4140 - accuracy: 0.1002
on_train_batch_begin: 1615677142.103287s

42 step training time: 0.327503s

on_train_batch_end: 1615677142.428086s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.4098 - accuracy: 0.1002
on_train_batch_begin: 1615677142.428378s

43 step training time: 0.325092s

on_train_batch_end: 1615677142.753290s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.4042 - accuracy: 0.1002
on_train_batch_begin: 1615677142.753545s

44 step training time: 0.325167s

on_train_batch_end: 1615677143.083598s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.3965 - accuracy: 0.1002
on_train_batch_begin: 1615677143.083927s

45 step training time: 0.330382s

on_train_batch_end: 1615677143.412361s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.3914 - accuracy: 0.1002
on_train_batch_begin: 1615677143.412657s

46 step training time: 0.328730s

on_train_batch_end: 1615677143.740427s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.3881 - accuracy: 0.1002
on_train_batch_begin: 1615677143.740726s

47 step training time: 0.328068s

on_train_batch_end: 1615677144.065735s

49152/50000 [============================>.] - ETA: 0s - loss: 1.3841 - accuracy: 0.1002
on_train_batch_begin: 1615677144.066036s

48 step training time: 0.325311s

on_train_batch_end: 1615677144.342721s

on_test_batch_begin: 1615677144.352727s

49 step training time: 0.286690s

on_epoch_end: 1615677145.141106s

Validation time: 0.788367s

Real time: 1615677145.141106s

Epoch time: 16.721595764160156s

50000/50000 [==============================] - 17s 334us/sample - loss: 1.3802 - accuracy: 0.1002 - val_loss: 6.8326 - val_accuracy: 0.1001

on_epoch_begin: 1615677145.141295s

Real time: 1615677145.1413002
Epoch 5/5

on_train_batch_begin: 1615677145.144752s

on_train_batch_end: 1615677145.470306s

 1024/50000 [..............................] - ETA: 15s - loss: 0.9653 - accuracy: 0.1003
on_train_batch_begin: 1615677145.470555s

1 step training time: 0.325803s

on_train_batch_end: 1615677145.794636s

 2048/50000 [>.............................] - ETA: 15s - loss: 0.9883 - accuracy: 0.1004
on_train_batch_begin: 1615677145.794939s

2 step training time: 0.324384s

on_train_batch_end: 1615677146.123678s

 3072/50000 [>.............................] - ETA: 15s - loss: 0.9635 - accuracy: 0.1005
on_train_batch_begin: 1615677146.123982s

3 step training time: 0.329043s

on_train_batch_end: 1615677146.447005s

 4096/50000 [=>............................] - ETA: 14s - loss: 0.9447 - accuracy: 0.1004
on_train_batch_begin: 1615677146.447311s

4 step training time: 0.323329s

on_train_batch_end: 1615677146.769416s

 5120/50000 [==>...........................] - ETA: 14s - loss: 0.9769 - accuracy: 0.1002
on_train_batch_begin: 1615677146.769681s

5 step training time: 0.322370s

on_train_batch_end: 1615677147.094563s

 6144/50000 [==>...........................] - ETA: 13s - loss: 0.9836 - accuracy: 0.1002
on_train_batch_begin: 1615677147.094865s

6 step training time: 0.325184s

on_train_batch_end: 1615677147.426718s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.0018 - accuracy: 0.1003
on_train_batch_begin: 1615677147.427010s

7 step training time: 0.332145s

on_train_batch_end: 1615677147.756448s

 8192/50000 [===>..........................] - ETA: 13s - loss: 0.9903 - accuracy: 0.1003
on_train_batch_begin: 1615677147.756727s

8 step training time: 0.329717s

on_train_batch_end: 1615677148.082360s

 9216/50000 [====>.........................] - ETA: 13s - loss: 0.9872 - accuracy: 0.1002
on_train_batch_begin: 1615677148.082669s

9 step training time: 0.325943s

on_train_batch_end: 1615677148.412776s

10240/50000 [=====>........................] - ETA: 12s - loss: 0.9821 - accuracy: 0.1003
on_train_batch_begin: 1615677148.413079s

10 step training time: 0.330409s

on_train_batch_end: 1615677148.739311s

11264/50000 [=====>........................] - ETA: 12s - loss: 0.9686 - accuracy: 0.1004
on_train_batch_begin: 1615677148.739600s

11 step training time: 0.326521s

on_train_batch_end: 1615677149.055740s

12288/50000 [======>.......................] - ETA: 12s - loss: 0.9651 - accuracy: 0.1003
on_train_batch_begin: 1615677149.056043s

12 step training time: 0.316443s

on_train_batch_end: 1615677149.384258s

13312/50000 [======>.......................] - ETA: 11s - loss: 0.9577 - accuracy: 0.1003
on_train_batch_begin: 1615677149.384557s

13 step training time: 0.328514s

on_train_batch_end: 1615677149.712103s

14336/50000 [=======>......................] - ETA: 11s - loss: 0.9576 - accuracy: 0.1003
on_train_batch_begin: 1615677149.712395s

14 step training time: 0.327838s

on_train_batch_end: 1615677150.038916s

15360/50000 [========>.....................] - ETA: 11s - loss: 0.9535 - accuracy: 0.1003
on_train_batch_begin: 1615677150.039224s

15 step training time: 0.326829s

on_train_batch_end: 1615677150.365798s

16384/50000 [========>.....................] - ETA: 10s - loss: 0.9519 - accuracy: 0.1003
on_train_batch_begin: 1615677150.366099s

16 step training time: 0.326875s

on_train_batch_end: 1615677150.688875s

17408/50000 [=========>....................] - ETA: 10s - loss: 0.9526 - accuracy: 0.1003
on_train_batch_begin: 1615677150.689182s

17 step training time: 0.323083s

on_train_batch_end: 1615677151.013196s

18432/50000 [==========>...................] - ETA: 10s - loss: 0.9520 - accuracy: 0.1003
on_train_batch_begin: 1615677151.013511s

18 step training time: 0.324329s

on_train_batch_end: 1615677151.340370s

19456/50000 [==========>...................] - ETA: 9s - loss: 0.9483 - accuracy: 0.1003 
on_train_batch_begin: 1615677151.340678s

19 step training time: 0.327167s

on_train_batch_end: 1615677151.664761s

20480/50000 [===========>..................] - ETA: 9s - loss: 0.9427 - accuracy: 0.1003
on_train_batch_begin: 1615677151.665066s

20 step training time: 0.324388s

on_train_batch_end: 1615677151.991504s

21504/50000 [===========>..................] - ETA: 9s - loss: 0.9381 - accuracy: 0.1003
on_train_batch_begin: 1615677151.991818s

21 step training time: 0.326752s

on_train_batch_end: 1615677152.315774s

22528/50000 [============>.................] - ETA: 8s - loss: 0.9339 - accuracy: 0.1004
on_train_batch_begin: 1615677152.316091s

22 step training time: 0.324273s

on_train_batch_end: 1615677152.640062s

23552/50000 [=============>................] - ETA: 8s - loss: 0.9289 - accuracy: 0.1004
on_train_batch_begin: 1615677152.640369s

23 step training time: 0.324278s

on_train_batch_end: 1615677152.964941s

24576/50000 [=============>................] - ETA: 8s - loss: 0.9275 - accuracy: 0.1003
on_train_batch_begin: 1615677152.965250s

24 step training time: 0.324881s

on_train_batch_end: 1615677153.290334s

25600/50000 [==============>...............] - ETA: 7s - loss: 0.9263 - accuracy: 0.1003
on_train_batch_begin: 1615677153.290651s

25 step training time: 0.325401s

on_train_batch_end: 1615677153.613891s

26624/50000 [==============>...............] - ETA: 7s - loss: 0.9246 - accuracy: 0.1003
on_train_batch_begin: 1615677153.614189s

26 step training time: 0.323538s

on_train_batch_end: 1615677153.939065s

27648/50000 [===============>..............] - ETA: 7s - loss: 0.9221 - accuracy: 0.1003
on_train_batch_begin: 1615677153.939362s

27 step training time: 0.325173s

on_train_batch_end: 1615677154.263677s

28672/50000 [================>.............] - ETA: 6s - loss: 0.9206 - accuracy: 0.1003
on_train_batch_begin: 1615677154.263970s

28 step training time: 0.324609s

on_train_batch_end: 1615677154.587770s

29696/50000 [================>.............] - ETA: 6s - loss: 0.9191 - accuracy: 0.1003
on_train_batch_begin: 1615677154.588048s

29 step training time: 0.324078s

on_train_batch_end: 1615677154.912972s

30720/50000 [=================>............] - ETA: 6s - loss: 0.9162 - accuracy: 0.1004
on_train_batch_begin: 1615677154.913255s

30 step training time: 0.325207s

on_train_batch_end: 1615677155.238022s

31744/50000 [==================>...........] - ETA: 5s - loss: 0.9155 - accuracy: 0.1003
on_train_batch_begin: 1615677155.238322s

31 step training time: 0.325067s

on_train_batch_end: 1615677155.562477s

32768/50000 [==================>...........] - ETA: 5s - loss: 0.9146 - accuracy: 0.1003
on_train_batch_begin: 1615677155.562781s

32 step training time: 0.324459s

on_train_batch_end: 1615677155.889852s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.9127 - accuracy: 0.1003
on_train_batch_begin: 1615677155.890251s

33 step training time: 0.327470s

on_train_batch_end: 1615677156.213379s

34816/50000 [===================>..........] - ETA: 4s - loss: 0.9155 - accuracy: 0.1003
on_train_batch_begin: 1615677156.213687s

34 step training time: 0.323436s

on_train_batch_end: 1615677156.540156s

35840/50000 [====================>.........] - ETA: 4s - loss: 0.9140 - accuracy: 0.1003
on_train_batch_begin: 1615677156.540477s

35 step training time: 0.326789s

on_train_batch_end: 1615677156.865448s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.9140 - accuracy: 0.1003
on_train_batch_begin: 1615677156.865716s

36 step training time: 0.325239s

on_train_batch_end: 1615677157.189774s

37888/50000 [=====================>........] - ETA: 3s - loss: 0.9144 - accuracy: 0.1003
on_train_batch_begin: 1615677157.190076s

37 step training time: 0.324361s

on_train_batch_end: 1615677157.519682s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.9111 - accuracy: 0.1003
on_train_batch_begin: 1615677157.519989s

38 step training time: 0.329912s

on_train_batch_end: 1615677157.849489s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.9099 - accuracy: 0.1003
on_train_batch_begin: 1615677157.849894s

39 step training time: 0.329905s

on_train_batch_end: 1615677158.177765s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.9076 - accuracy: 0.1003
on_train_batch_begin: 1615677158.178066s

40 step training time: 0.328172s

on_train_batch_end: 1615677158.505934s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.9065 - accuracy: 0.1003
on_train_batch_begin: 1615677158.506224s

41 step training time: 0.328157s

on_train_batch_end: 1615677158.832021s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.9066 - accuracy: 0.1003
on_train_batch_begin: 1615677158.832305s

42 step training time: 0.326081s

on_train_batch_end: 1615677159.157471s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.9056 - accuracy: 0.1003
on_train_batch_begin: 1615677159.157777s

43 step training time: 0.325472s

on_train_batch_end: 1615677159.484664s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.9032 - accuracy: 0.1003
on_train_batch_begin: 1615677159.484975s

44 step training time: 0.327198s

on_train_batch_end: 1615677159.810218s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.9028 - accuracy: 0.1003
on_train_batch_begin: 1615677159.810518s

45 step training time: 0.325543s

on_train_batch_end: 1615677160.135767s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.9015 - accuracy: 0.1003
on_train_batch_begin: 1615677160.136060s

46 step training time: 0.325542s

on_train_batch_end: 1615677160.464705s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9006 - accuracy: 0.1003
on_train_batch_begin: 1615677160.465007s

47 step training time: 0.328947s

on_train_batch_end: 1615677160.787118s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9014 - accuracy: 0.1003
on_train_batch_begin: 1615677160.787388s

48 step training time: 0.322381s

on_train_batch_end: 1615677161.054326s

on_test_batch_begin: 1615677161.064551s

49 step training time: 0.277163s

on_epoch_end: 1615677161.857314s

Validation time: 0.792751s

Real time: 1615677161.857314s

Epoch time: 16.71602988243103s

50000/50000 [==============================] - 17s 334us/sample - loss: 0.8999 - accuracy: 0.1003 - val_loss: 6.7759 - val_accuracy: 0.1001
Tempo do fit: 113.40814304351807