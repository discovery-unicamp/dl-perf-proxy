wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:42
    90112/170498071 [..............................] - ETA: 2:26
   303104/170498071 [..............................] - ETA: 1:12
   548864/170498071 [..............................] - ETA: 56s 
   794624/170498071 [..............................] - ETA: 49s
  1073152/170498071 [..............................] - ETA: 44s
  1384448/170498071 [..............................] - ETA: 41s
  1712128/170498071 [..............................] - ETA: 38s
  2056192/170498071 [..............................] - ETA: 35s
  2449408/170498071 [..............................] - ETA: 33s
  2891776/170498071 [..............................] - ETA: 31s
  3366912/170498071 [..............................] - ETA: 29s
  3874816/170498071 [..............................] - ETA: 27s
  4431872/170498071 [..............................] - ETA: 26s
  5038080/170498071 [..............................] - ETA: 24s
  5726208/170498071 [>.............................] - ETA: 22s
  6414336/170498071 [>.............................] - ETA: 21s
  7184384/170498071 [>.............................] - ETA: 20s
  8003584/170498071 [>.............................] - ETA: 19s
  8855552/170498071 [>.............................] - ETA: 18s
  9805824/170498071 [>.............................] - ETA: 17s
 10985472/170498071 [>.............................] - ETA: 15s
 12214272/170498071 [=>............................] - ETA: 14s
 13524992/170498071 [=>............................] - ETA: 13s
 14868480/170498071 [=>............................] - ETA: 13s
 16310272/170498071 [=>............................] - ETA: 12s
 17801216/170498071 [==>...........................] - ETA: 11s
 19275776/170498071 [==>...........................] - ETA: 11s
 20307968/170498071 [==>...........................] - ETA: 10s
 22634496/170498071 [==>...........................] - ETA: 9s 
 24059904/170498071 [===>..........................] - ETA: 9s
 25485312/170498071 [===>..........................] - ETA: 9s
 26927104/170498071 [===>..........................] - ETA: 8s
 28352512/170498071 [===>..........................] - ETA: 8s
 29810688/170498071 [====>.........................] - ETA: 8s
 31285248/170498071 [====>.........................] - ETA: 8s
 32776192/170498071 [====>.........................] - ETA: 7s
 34234368/170498071 [=====>........................] - ETA: 7s
 35643392/170498071 [=====>........................] - ETA: 7s
 37085184/170498071 [=====>........................] - ETA: 7s
 38576128/170498071 [=====>........................] - ETA: 7s
 40067072/170498071 [======>.......................] - ETA: 6s
 41558016/170498071 [======>.......................] - ETA: 6s
 43065344/170498071 [======>.......................] - ETA: 6s
 44490752/170498071 [======>.......................] - ETA: 6s
 45981696/170498071 [=======>......................] - ETA: 6s
 47554560/170498071 [=======>......................] - ETA: 6s
 49045504/170498071 [=======>......................] - ETA: 6s
 50536448/170498071 [=======>......................] - ETA: 5s
 52174848/170498071 [========>.....................] - ETA: 5s
 53616640/170498071 [========>.....................] - ETA: 5s
 55173120/170498071 [========>.....................] - ETA: 5s
 56729600/170498071 [========>.....................] - ETA: 5s
 58286080/170498071 [=========>....................] - ETA: 5s
 59793408/170498071 [=========>....................] - ETA: 5s
 61349888/170498071 [=========>....................] - ETA: 5s
 62791680/170498071 [==========>...................] - ETA: 4s
 64282624/170498071 [==========>...................] - ETA: 4s
 65773568/170498071 [==========>...................] - ETA: 4s
 67264512/170498071 [==========>...................] - ETA: 4s
 68771840/170498071 [===========>..................] - ETA: 4s
 70213632/170498071 [===========>..................] - ETA: 4s
 71704576/170498071 [===========>..................] - ETA: 4s
 73211904/170498071 [===========>..................] - ETA: 4s
 74752000/170498071 [============>.................] - ETA: 4s
 76242944/170498071 [============>.................] - ETA: 4s
 77881344/170498071 [============>.................] - ETA: 4s
 79372288/170498071 [============>.................] - ETA: 3s
 80928768/170498071 [=============>................] - ETA: 3s
 82452480/170498071 [=============>................] - ETA: 3s
 84058112/170498071 [=============>................] - ETA: 3s
 85630976/170498071 [==============>...............] - ETA: 3s
 87187456/170498071 [==============>...............] - ETA: 3s
 88727552/170498071 [==============>...............] - ETA: 3s
 90218496/170498071 [==============>...............] - ETA: 3s
 91742208/170498071 [===============>..............] - ETA: 3s
 93364224/170498071 [===============>..............] - ETA: 3s
 94871552/170498071 [===============>..............] - ETA: 3s
 96428032/170498071 [===============>..............] - ETA: 3s
 97918976/170498071 [================>.............] - ETA: 3s
 99540992/170498071 [================>.............] - ETA: 2s
101097472/170498071 [================>.............] - ETA: 2s
102670336/170498071 [=================>............] - ETA: 2s
104505344/170498071 [=================>............] - ETA: 2s
106799104/170498071 [=================>............] - ETA: 2s
109289472/170498071 [==================>...........] - ETA: 2s
111861760/170498071 [==================>...........] - ETA: 2s
114630656/170498071 [===================>..........] - ETA: 2s
117465088/170498071 [===================>..........] - ETA: 2s
120315904/170498071 [====================>.........] - ETA: 1s
123183104/170498071 [====================>.........] - ETA: 1s
126083072/170498071 [=====================>........] - ETA: 1s
128933888/170498071 [=====================>........] - ETA: 1s
131809280/170498071 [======================>.......] - ETA: 1s
134651904/170498071 [======================>.......] - ETA: 1s
137437184/170498071 [=======================>......] - ETA: 1s
140353536/170498071 [=======================>......] - ETA: 1s
143155200/170498071 [========================>.....] - ETA: 0s
146022400/170498071 [========================>.....] - ETA: 0s
148889600/170498071 [=========================>....] - ETA: 0s
151740416/170498071 [=========================>....] - ETA: 0s
154542080/170498071 [==========================>...] - ETA: 0s
157409280/170498071 [==========================>...] - ETA: 0s
160276480/170498071 [===========================>..] - ETA: 0s
163143680/170498071 [===========================>..] - ETA: 0s
166010880/170498071 [============================>.] - ETA: 0s
168869888/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 5s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 5988352/94765736 [>.............................] - ETA: 0s
12984320/94765736 [===>..........................] - ETA: 0s
18456576/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
24100864/94765736 [======>.......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
35282944/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
43778048/94765736 [============>.................] - ETA: 0s
50962432/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
61890560/94765736 [==================>...........] - ETA: 0s
66985984/94765736 [====================>.........] - ETA: 0s
68870144/94765736 [====================>.........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
81707008/94765736 [========================>.....] - ETA: 0s
89702400/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 15.70434284210205
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1598476064.074343s

Real time: 1598476064.0743616
Epoch 1/5

on_train_batch_begin: 1598476064.813510s

on_train_batch_end: 1598476085.180192s

 2048/50000 [>.............................] - ETA: 8:14 - loss: 17.8217 - accuracy: 1.9789e-04
on_train_batch_begin: 1598476085.180810s

1 step training time: 20.367300s

on_train_batch_end: 1598476085.847741s

 4096/50000 [=>............................] - ETA: 4:04 - loss: 14.1446 - accuracy: 2.3055e-04
on_train_batch_begin: 1598476085.848061s

2 step training time: 0.667251s

on_train_batch_end: 1598476086.509396s

 6144/50000 [==>...........................] - ETA: 2:40 - loss: 12.2347 - accuracy: 7.1462e-04
on_train_batch_begin: 1598476086.509697s

3 step training time: 0.661637s

on_train_batch_end: 1598476087.134474s

 8192/50000 [===>..........................] - ETA: 1:57 - loss: 11.2074 - accuracy: 0.0025    
on_train_batch_begin: 1598476087.134779s

4 step training time: 0.625082s

on_train_batch_end: 1598476087.806649s

10240/50000 [=====>........................] - ETA: 1:32 - loss: 10.5922 - accuracy: 0.0071
on_train_batch_begin: 1598476087.806968s

5 step training time: 0.672189s

on_train_batch_end: 1598476088.468722s

12288/50000 [======>.......................] - ETA: 1:14 - loss: 10.1409 - accuracy: 0.0121
on_train_batch_begin: 1598476088.469030s

6 step training time: 0.662062s

on_train_batch_end: 1598476089.127798s

14336/50000 [=======>......................] - ETA: 1:02 - loss: 9.8220 - accuracy: 0.0162 
on_train_batch_begin: 1598476089.128108s

7 step training time: 0.659078s

on_train_batch_end: 1598476089.795098s

16384/50000 [========>.....................] - ETA: 52s - loss: 9.5727 - accuracy: 0.0202 
on_train_batch_begin: 1598476089.795399s

8 step training time: 0.667291s

on_train_batch_end: 1598476090.466972s

18432/50000 [==========>...................] - ETA: 45s - loss: 9.3820 - accuracy: 0.0249
on_train_batch_begin: 1598476090.467272s

9 step training time: 0.671873s

on_train_batch_end: 1598476091.120637s

20480/50000 [===========>..................] - ETA: 38s - loss: 9.2178 - accuracy: 0.0297
on_train_batch_begin: 1598476091.120928s

10 step training time: 0.653656s

on_train_batch_end: 1598476091.784393s

22528/50000 [============>.................] - ETA: 33s - loss: 9.0762 - accuracy: 0.0341
on_train_batch_begin: 1598476091.784682s

11 step training time: 0.663754s

on_train_batch_end: 1598476092.447280s

24576/50000 [=============>................] - ETA: 29s - loss: 8.9641 - accuracy: 0.0371
on_train_batch_begin: 1598476092.447597s

12 step training time: 0.662915s

on_train_batch_end: 1598476093.111272s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.8645 - accuracy: 0.0401
on_train_batch_begin: 1598476093.111601s

13 step training time: 0.664004s

on_train_batch_end: 1598476093.781493s

28672/50000 [================>.............] - ETA: 22s - loss: 8.7723 - accuracy: 0.0432
on_train_batch_begin: 1598476093.781790s

14 step training time: 0.670189s

on_train_batch_end: 1598476094.445462s

30720/50000 [=================>............] - ETA: 19s - loss: 8.6894 - accuracy: 0.0454
on_train_batch_begin: 1598476094.445770s

15 step training time: 0.663980s

on_train_batch_end: 1598476095.103042s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.6200 - accuracy: 0.0479
on_train_batch_begin: 1598476095.103336s

16 step training time: 0.657566s

on_train_batch_end: 1598476095.770845s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.5500 - accuracy: 0.0506
on_train_batch_begin: 1598476095.771139s

17 step training time: 0.667803s

on_train_batch_end: 1598476096.439993s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.4929 - accuracy: 0.0528
on_train_batch_begin: 1598476096.440300s

18 step training time: 0.669161s

on_train_batch_end: 1598476097.096702s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.4347 - accuracy: 0.0554 
on_train_batch_begin: 1598476097.097032s

19 step training time: 0.656732s

on_train_batch_end: 1598476097.760680s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.3874 - accuracy: 0.0571
on_train_batch_begin: 1598476097.760972s

20 step training time: 0.663940s

on_train_batch_end: 1598476098.417822s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.3390 - accuracy: 0.0590
on_train_batch_begin: 1598476098.418126s

21 step training time: 0.657154s

on_train_batch_end: 1598476099.081529s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.3027 - accuracy: 0.0602
on_train_batch_begin: 1598476099.081829s

22 step training time: 0.663703s

on_train_batch_end: 1598476099.718060s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.2662 - accuracy: 0.0611
on_train_batch_begin: 1598476099.718371s

23 step training time: 0.636542s

on_train_batch_end: 1598476100.387470s

49152/50000 [============================>.] - ETA: 0s - loss: 8.2329 - accuracy: 0.0622
on_train_batch_begin: 1598476100.387769s

24 step training time: 0.669397s

on_train_batch_end: 1598476106.274478s

on_test_batch_begin: 1598476106.465994s

25 step training time: 6.078226s

on_epoch_end: 1598476111.621490s

Validation time: 5.155480s

Real time: 1598476111.621490s

Epoch time: 47.5471453666687s

50000/50000 [==============================] - 48s 951us/sample - loss: 8.2184 - accuracy: 0.0623 - val_loss: 3950.8240 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598476111.621690s

Real time: 1598476111.6216948
Epoch 2/5

on_train_batch_begin: 1598476111.625033s

on_train_batch_end: 1598476112.294240s

 2048/50000 [>.............................] - ETA: 15s - loss: 7.1881 - accuracy: 0.0891
on_train_batch_begin: 1598476112.294564s

1 step training time: 0.669531s

on_train_batch_end: 1598476112.959573s

 4096/50000 [=>............................] - ETA: 14s - loss: 7.2983 - accuracy: 0.0895
on_train_batch_begin: 1598476112.959890s

2 step training time: 0.665327s

on_train_batch_end: 1598476113.637425s

 6144/50000 [==>...........................] - ETA: 14s - loss: 7.2870 - accuracy: 0.0932
on_train_batch_begin: 1598476113.637730s

3 step training time: 0.677840s

on_train_batch_end: 1598476114.309917s

 8192/50000 [===>..........................] - ETA: 13s - loss: 7.3033 - accuracy: 0.0946
on_train_batch_begin: 1598476114.310204s

4 step training time: 0.672473s

on_train_batch_end: 1598476114.976238s

10240/50000 [=====>........................] - ETA: 13s - loss: 7.3075 - accuracy: 0.0918
on_train_batch_begin: 1598476114.976543s

5 step training time: 0.666339s

on_train_batch_end: 1598476115.657835s

12288/50000 [======>.......................] - ETA: 12s - loss: 7.3273 - accuracy: 0.0929
on_train_batch_begin: 1598476115.658161s

6 step training time: 0.681618s

on_train_batch_end: 1598476116.330620s

14336/50000 [=======>......................] - ETA: 11s - loss: 7.3334 - accuracy: 0.0929
on_train_batch_begin: 1598476116.330924s

7 step training time: 0.672764s

on_train_batch_end: 1598476117.001548s

16384/50000 [========>.....................] - ETA: 11s - loss: 7.3236 - accuracy: 0.0937
on_train_batch_begin: 1598476117.001839s

8 step training time: 0.670915s

on_train_batch_end: 1598476117.674381s

18432/50000 [==========>...................] - ETA: 10s - loss: 7.3133 - accuracy: 0.0935
on_train_batch_begin: 1598476117.674673s

9 step training time: 0.672834s

on_train_batch_end: 1598476118.345906s

20480/50000 [===========>..................] - ETA: 9s - loss: 7.3064 - accuracy: 0.0932 
on_train_batch_begin: 1598476118.346201s

10 step training time: 0.671528s

on_train_batch_end: 1598476119.020493s

22528/50000 [============>.................] - ETA: 9s - loss: 7.3001 - accuracy: 0.0938
on_train_batch_begin: 1598476119.020801s

11 step training time: 0.674600s

on_train_batch_end: 1598476119.698509s

24576/50000 [=============>................] - ETA: 8s - loss: 7.2927 - accuracy: 0.0941
on_train_batch_begin: 1598476119.698806s

12 step training time: 0.678005s

on_train_batch_end: 1598476120.371775s

26624/50000 [==============>...............] - ETA: 7s - loss: 7.2861 - accuracy: 0.0952
on_train_batch_begin: 1598476120.372086s

13 step training time: 0.673280s

on_train_batch_end: 1598476121.043874s

28672/50000 [================>.............] - ETA: 7s - loss: 7.2781 - accuracy: 0.0947
on_train_batch_begin: 1598476121.044248s

14 step training time: 0.672162s

on_train_batch_end: 1598476121.717661s

30720/50000 [=================>............] - ETA: 6s - loss: 7.2723 - accuracy: 0.0942
on_train_batch_begin: 1598476121.717956s

15 step training time: 0.673708s

on_train_batch_end: 1598476122.394706s

32768/50000 [==================>...........] - ETA: 5s - loss: 7.2588 - accuracy: 0.0939
on_train_batch_begin: 1598476122.395009s

16 step training time: 0.677053s

on_train_batch_end: 1598476123.077549s

34816/50000 [===================>..........] - ETA: 4s - loss: 7.2492 - accuracy: 0.0942
on_train_batch_begin: 1598476123.077861s

17 step training time: 0.682852s

on_train_batch_end: 1598476123.747717s

36864/50000 [=====================>........] - ETA: 4s - loss: 7.2411 - accuracy: 0.0940
on_train_batch_begin: 1598476123.748019s

18 step training time: 0.670159s

on_train_batch_end: 1598476124.423704s

38912/50000 [======================>.......] - ETA: 3s - loss: 7.2422 - accuracy: 0.0934
on_train_batch_begin: 1598476124.424024s

19 step training time: 0.676004s

on_train_batch_end: 1598476125.104094s

40960/50000 [=======================>......] - ETA: 2s - loss: 7.2307 - accuracy: 0.0937
on_train_batch_begin: 1598476125.104394s

20 step training time: 0.680371s

on_train_batch_end: 1598476125.780111s

43008/50000 [========================>.....] - ETA: 2s - loss: 7.2201 - accuracy: 0.0937
on_train_batch_begin: 1598476125.780398s

21 step training time: 0.676004s

on_train_batch_end: 1598476126.448756s

45056/50000 [==========================>...] - ETA: 1s - loss: 7.2127 - accuracy: 0.0940
on_train_batch_begin: 1598476126.449078s

22 step training time: 0.668680s

on_train_batch_end: 1598476127.123984s

47104/50000 [===========================>..] - ETA: 0s - loss: 7.2088 - accuracy: 0.0941
on_train_batch_begin: 1598476127.124279s

23 step training time: 0.675200s

on_train_batch_end: 1598476127.802887s

49152/50000 [============================>.] - ETA: 0s - loss: 7.2070 - accuracy: 0.0939
on_train_batch_begin: 1598476127.803199s

24 step training time: 0.678921s

on_train_batch_end: 1598476128.090912s

on_test_batch_begin: 1598476128.110659s

25 step training time: 0.307460s

on_epoch_end: 1598476128.999137s

Validation time: 0.888465s

Real time: 1598476128.999137s

Epoch time: 17.377459287643433s

50000/50000 [==============================] - 17s 348us/sample - loss: 7.2045 - accuracy: 0.0940 - val_loss: 1059226.9858 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598476128.999332s

Real time: 1598476128.9993377
Epoch 3/5

on_train_batch_begin: 1598476129.002763s

on_train_batch_end: 1598476129.672989s

 2048/50000 [>.............................] - ETA: 15s - loss: 7.1574 - accuracy: 0.1112
on_train_batch_begin: 1598476129.673301s

1 step training time: 0.670538s

on_train_batch_end: 1598476130.356988s

 4096/50000 [=>............................] - ETA: 15s - loss: 7.1153 - accuracy: 0.1031
on_train_batch_begin: 1598476130.357291s

2 step training time: 0.683989s

on_train_batch_end: 1598476131.038681s

 6144/50000 [==>...........................] - ETA: 14s - loss: 7.0900 - accuracy: 0.1007
on_train_batch_begin: 1598476131.038983s

3 step training time: 0.681693s

on_train_batch_end: 1598476131.723520s

 8192/50000 [===>..........................] - ETA: 13s - loss: 7.0590 - accuracy: 0.0981
on_train_batch_begin: 1598476131.723816s

4 step training time: 0.684833s

on_train_batch_end: 1598476132.410341s

10240/50000 [=====>........................] - ETA: 13s - loss: 7.0556 - accuracy: 0.0972
on_train_batch_begin: 1598476132.410665s

5 step training time: 0.686849s

on_train_batch_end: 1598476133.085315s

12288/50000 [======>.......................] - ETA: 12s - loss: 7.0556 - accuracy: 0.0957
on_train_batch_begin: 1598476133.085619s

6 step training time: 0.674954s

on_train_batch_end: 1598476133.763388s

14336/50000 [=======>......................] - ETA: 11s - loss: 7.0402 - accuracy: 0.0960
on_train_batch_begin: 1598476133.763721s

7 step training time: 0.678102s

on_train_batch_end: 1598476134.438834s

16384/50000 [========>.....................] - ETA: 11s - loss: 7.0234 - accuracy: 0.0950
on_train_batch_begin: 1598476134.439145s

8 step training time: 0.675424s

on_train_batch_end: 1598476135.126339s

18432/50000 [==========>...................] - ETA: 10s - loss: 7.0177 - accuracy: 0.0944
on_train_batch_begin: 1598476135.126637s

9 step training time: 0.687492s

on_train_batch_end: 1598476135.811147s

20480/50000 [===========>..................] - ETA: 9s - loss: 7.0051 - accuracy: 0.0943 
on_train_batch_begin: 1598476135.811464s

10 step training time: 0.684826s

on_train_batch_end: 1598476136.486141s

22528/50000 [============>.................] - ETA: 9s - loss: 7.0059 - accuracy: 0.0940
on_train_batch_begin: 1598476136.486441s

11 step training time: 0.674978s

on_train_batch_end: 1598476137.172447s

24576/50000 [=============>................] - ETA: 8s - loss: 6.9979 - accuracy: 0.0946
on_train_batch_begin: 1598476137.172744s

12 step training time: 0.686303s

on_train_batch_end: 1598476137.855204s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.9934 - accuracy: 0.0949
on_train_batch_begin: 1598476137.855526s

13 step training time: 0.682781s

on_train_batch_end: 1598476138.536364s

28672/50000 [================>.............] - ETA: 7s - loss: 6.9820 - accuracy: 0.0952
on_train_batch_begin: 1598476138.536656s

14 step training time: 0.681130s

on_train_batch_end: 1598476139.218300s

30720/50000 [=================>............] - ETA: 6s - loss: 6.9785 - accuracy: 0.0956
on_train_batch_begin: 1598476139.218602s

15 step training time: 0.681946s

on_train_batch_end: 1598476139.900795s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.9696 - accuracy: 0.0959
on_train_batch_begin: 1598476139.901095s

16 step training time: 0.682493s

on_train_batch_end: 1598476140.577584s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.9681 - accuracy: 0.0963
on_train_batch_begin: 1598476140.577882s

17 step training time: 0.676787s

on_train_batch_end: 1598476141.265846s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.9655 - accuracy: 0.0961
on_train_batch_begin: 1598476141.266151s

18 step training time: 0.688269s

on_train_batch_end: 1598476141.951510s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.9614 - accuracy: 0.0962
on_train_batch_begin: 1598476141.951806s

19 step training time: 0.685654s

on_train_batch_end: 1598476142.639185s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.9591 - accuracy: 0.0961
on_train_batch_begin: 1598476142.639536s

20 step training time: 0.687730s

on_train_batch_end: 1598476143.299682s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.9561 - accuracy: 0.0958
on_train_batch_begin: 1598476143.299980s

21 step training time: 0.660444s

on_train_batch_end: 1598476143.991505s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.9598 - accuracy: 0.0961
on_train_batch_begin: 1598476143.991817s

22 step training time: 0.691838s

on_train_batch_end: 1598476144.683554s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.9621 - accuracy: 0.0959
on_train_batch_begin: 1598476144.683844s

23 step training time: 0.692026s

on_train_batch_end: 1598476145.334642s

49152/50000 [============================>.] - ETA: 0s - loss: 6.9609 - accuracy: 0.0963
on_train_batch_begin: 1598476145.334934s

24 step training time: 0.651090s

on_train_batch_end: 1598476145.626637s

on_test_batch_begin: 1598476145.646293s

25 step training time: 0.311359s

on_epoch_end: 1598476146.542266s

Validation time: 0.895959s

Real time: 1598476146.542266s

Epoch time: 17.5429470539093s

50000/50000 [==============================] - 18s 351us/sample - loss: 6.9609 - accuracy: 0.0964 - val_loss: 428.6718 - val_accuracy: 0.0000e+00

on_epoch_begin: 1598476146.542467s

Real time: 1598476146.5424752
Epoch 4/5

on_train_batch_begin: 1598476146.545937s

on_train_batch_end: 1598476147.226347s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.8816 - accuracy: 0.0965
on_train_batch_begin: 1598476147.226636s

1 step training time: 0.680699s

on_train_batch_end: 1598476147.910203s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.8557 - accuracy: 0.0951
on_train_batch_begin: 1598476147.910497s

2 step training time: 0.683861s

on_train_batch_end: 1598476148.593785s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.8974 - accuracy: 0.0939
on_train_batch_begin: 1598476148.594076s

3 step training time: 0.683579s

on_train_batch_end: 1598476149.275997s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.8860 - accuracy: 0.0948
on_train_batch_begin: 1598476149.276288s

4 step training time: 0.682212s

on_train_batch_end: 1598476149.963862s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.8722 - accuracy: 0.0945
on_train_batch_begin: 1598476149.964158s

5 step training time: 0.687870s

on_train_batch_end: 1598476150.649648s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.8585 - accuracy: 0.0965
on_train_batch_begin: 1598476150.649947s

6 step training time: 0.685789s

on_train_batch_end: 1598476151.341856s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.8563 - accuracy: 0.0970
on_train_batch_begin: 1598476151.342163s

7 step training time: 0.692215s

on_train_batch_end: 1598476152.025385s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.8384 - accuracy: 0.0963
on_train_batch_begin: 1598476152.025684s

8 step training time: 0.683521s

on_train_batch_end: 1598476152.722109s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.8240 - accuracy: 0.0963
on_train_batch_begin: 1598476152.722408s

9 step training time: 0.696724s

on_train_batch_end: 1598476153.417703s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.8206 - accuracy: 0.0968 
on_train_batch_begin: 1598476153.418001s

10 step training time: 0.695594s

on_train_batch_end: 1598476154.108104s

22528/50000 [============>.................] - ETA: 9s - loss: 6.8140 - accuracy: 0.0965
on_train_batch_begin: 1598476154.108421s

11 step training time: 0.690420s

on_train_batch_end: 1598476154.799562s

24576/50000 [=============>................] - ETA: 8s - loss: 6.8003 - accuracy: 0.0963
on_train_batch_begin: 1598476154.799865s

12 step training time: 0.691443s

on_train_batch_end: 1598476155.495085s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.7871 - accuracy: 0.0962
on_train_batch_begin: 1598476155.495379s

13 step training time: 0.695515s

on_train_batch_end: 1598476156.183652s

28672/50000 [================>.............] - ETA: 7s - loss: 6.7864 - accuracy: 0.0957
on_train_batch_begin: 1598476156.183943s

14 step training time: 0.688564s

on_train_batch_end: 1598476156.867731s

30720/50000 [=================>............] - ETA: 6s - loss: 6.7787 - accuracy: 0.0959
on_train_batch_begin: 1598476156.868028s

15 step training time: 0.684085s

on_train_batch_end: 1598476157.563864s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.7751 - accuracy: 0.0953
on_train_batch_begin: 1598476157.564179s

16 step training time: 0.696151s

on_train_batch_end: 1598476158.251683s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.7709 - accuracy: 0.0948
on_train_batch_begin: 1598476158.251978s

17 step training time: 0.687799s

on_train_batch_end: 1598476158.949609s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.7606 - accuracy: 0.0941
on_train_batch_begin: 1598476158.949908s

18 step training time: 0.697930s

on_train_batch_end: 1598476159.644984s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.7487 - accuracy: 0.0938
on_train_batch_begin: 1598476159.645290s

19 step training time: 0.695382s

on_train_batch_end: 1598476160.334207s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.7409 - accuracy: 0.0937
on_train_batch_begin: 1598476160.334518s

20 step training time: 0.689228s

on_train_batch_end: 1598476161.031568s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.7311 - accuracy: 0.0933
on_train_batch_begin: 1598476161.031862s

21 step training time: 0.697343s

on_train_batch_end: 1598476161.718224s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.7263 - accuracy: 0.0925
on_train_batch_begin: 1598476161.718517s

22 step training time: 0.686656s

on_train_batch_end: 1598476162.411645s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.7191 - accuracy: 0.0919
on_train_batch_begin: 1598476162.411937s

23 step training time: 0.693420s

on_train_batch_end: 1598476163.100317s

49152/50000 [============================>.] - ETA: 0s - loss: 6.7098 - accuracy: 0.0917
on_train_batch_begin: 1598476163.100630s

24 step training time: 0.688692s

on_train_batch_end: 1598476163.399167s

on_test_batch_begin: 1598476163.418769s

25 step training time: 0.318139s

on_epoch_end: 1598476164.311147s

Validation time: 0.892365s

Real time: 1598476164.311147s

Epoch time: 17.768688678741455s

50000/50000 [==============================] - 18s 355us/sample - loss: 6.7058 - accuracy: 0.0916 - val_loss: 7.6246 - val_accuracy: 0.1001

on_epoch_begin: 1598476164.311333s

Real time: 1598476164.3113382
Epoch 5/5

on_train_batch_begin: 1598476164.314731s

on_train_batch_end: 1598476164.998206s

 2048/50000 [>.............................] - ETA: 16s - loss: 6.5508 - accuracy: 0.0797
on_train_batch_begin: 1598476164.998498s

1 step training time: 0.683766s

on_train_batch_end: 1598476165.703838s

 4096/50000 [=>............................] - ETA: 15s - loss: 6.5419 - accuracy: 0.0828
on_train_batch_begin: 1598476165.704129s

2 step training time: 0.705631s

on_train_batch_end: 1598476166.403230s

 6144/50000 [==>...........................] - ETA: 14s - loss: 6.5510 - accuracy: 0.0844
on_train_batch_begin: 1598476166.403545s

3 step training time: 0.699416s

on_train_batch_end: 1598476167.097648s

 8192/50000 [===>..........................] - ETA: 14s - loss: 6.5562 - accuracy: 0.0859
on_train_batch_begin: 1598476167.097968s

4 step training time: 0.694423s

on_train_batch_end: 1598476167.788333s

10240/50000 [=====>........................] - ETA: 13s - loss: 6.5454 - accuracy: 0.0859
on_train_batch_begin: 1598476167.788629s

5 step training time: 0.690661s

on_train_batch_end: 1598476168.495224s

12288/50000 [======>.......................] - ETA: 12s - loss: 6.5347 - accuracy: 0.0880
on_train_batch_begin: 1598476168.495550s

6 step training time: 0.706921s

on_train_batch_end: 1598476169.198127s

14336/50000 [=======>......................] - ETA: 12s - loss: 6.5350 - accuracy: 0.0884
on_train_batch_begin: 1598476169.198425s

7 step training time: 0.702875s

on_train_batch_end: 1598476169.904675s

16384/50000 [========>.....................] - ETA: 11s - loss: 6.5137 - accuracy: 0.0900
on_train_batch_begin: 1598476169.904969s

8 step training time: 0.706545s

on_train_batch_end: 1598476170.608193s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.5112 - accuracy: 0.0904
on_train_batch_begin: 1598476170.608488s

9 step training time: 0.703518s

on_train_batch_end: 1598476171.312811s

20480/50000 [===========>..................] - ETA: 10s - loss: 6.5028 - accuracy: 0.0909
on_train_batch_begin: 1598476171.313111s

10 step training time: 0.704623s

on_train_batch_end: 1598476172.016505s

22528/50000 [============>.................] - ETA: 9s - loss: 6.4914 - accuracy: 0.0914 
on_train_batch_begin: 1598476172.016808s

11 step training time: 0.703697s

on_train_batch_end: 1598476172.715387s

24576/50000 [=============>................] - ETA: 8s - loss: 6.4829 - accuracy: 0.0915
on_train_batch_begin: 1598476172.715703s

12 step training time: 0.698895s

on_train_batch_end: 1598476173.418216s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.4803 - accuracy: 0.0922
on_train_batch_begin: 1598476173.418518s

13 step training time: 0.702815s

on_train_batch_end: 1598476174.120174s

28672/50000 [================>.............] - ETA: 7s - loss: 6.4771 - accuracy: 0.0922
on_train_batch_begin: 1598476174.120466s

14 step training time: 0.701948s

on_train_batch_end: 1598476174.820082s

30720/50000 [=================>............] - ETA: 6s - loss: 6.4794 - accuracy: 0.0926
on_train_batch_begin: 1598476174.820382s

15 step training time: 0.699915s

on_train_batch_end: 1598476175.524088s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.4721 - accuracy: 0.0927
on_train_batch_begin: 1598476175.524377s

16 step training time: 0.703995s

on_train_batch_end: 1598476176.202537s

34816/50000 [===================>..........] - ETA: 5s - loss: 6.4654 - accuracy: 0.0928
on_train_batch_begin: 1598476176.202827s

17 step training time: 0.678450s

on_train_batch_end: 1598476176.905314s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.4596 - accuracy: 0.0930
on_train_batch_begin: 1598476176.905606s

18 step training time: 0.702779s

on_train_batch_end: 1598476177.610288s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.4548 - accuracy: 0.0919
on_train_batch_begin: 1598476177.610588s

19 step training time: 0.704982s

on_train_batch_end: 1598476178.308946s

40960/50000 [=======================>......] - ETA: 3s - loss: 6.4497 - accuracy: 0.0914
on_train_batch_begin: 1598476178.309237s

20 step training time: 0.698650s

on_train_batch_end: 1598476179.018465s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.4427 - accuracy: 0.0914
on_train_batch_begin: 1598476179.018926s

21 step training time: 0.709688s

on_train_batch_end: 1598476179.729008s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.4361 - accuracy: 0.0907
on_train_batch_begin: 1598476179.729311s

22 step training time: 0.710386s

on_train_batch_end: 1598476180.429702s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.4295 - accuracy: 0.0898
on_train_batch_begin: 1598476180.430002s

23 step training time: 0.700691s

on_train_batch_end: 1598476181.130847s

49152/50000 [============================>.] - ETA: 0s - loss: 6.4184 - accuracy: 0.0897
on_train_batch_begin: 1598476181.131152s

24 step training time: 0.701150s

on_train_batch_end: 1598476181.427340s

on_test_batch_begin: 1598476181.447474s

25 step training time: 0.316321s

on_epoch_end: 1598476182.354833s

Validation time: 0.907345s

Real time: 1598476182.354833s

Epoch time: 18.043510913848877s

50000/50000 [==============================] - 18s 361us/sample - loss: 6.4126 - accuracy: 0.0895 - val_loss: 7.4983 - val_accuracy: 0.0913
Tempo do fit: 122.7885160446167