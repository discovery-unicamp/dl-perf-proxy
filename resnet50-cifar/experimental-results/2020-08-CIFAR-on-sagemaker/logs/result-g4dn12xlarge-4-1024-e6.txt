wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:26
   139264/170498071 [..............................] - ETA: 1:29
   712704/170498071 [..............................] - ETA: 29s 
  2023424/170498071 [..............................] - ETA: 14s
  4743168/170498071 [..............................] - ETA: 7s 
  7438336/170498071 [>.............................] - ETA: 6s
 10592256/170498071 [>.............................] - ETA: 4s
 13082624/170498071 [=>............................] - ETA: 4s
 15425536/170498071 [=>............................] - ETA: 4s
 18554880/170498071 [==>...........................] - ETA: 3s
 21176320/170498071 [==>...........................] - ETA: 3s
 23945216/170498071 [===>..........................] - ETA: 3s
 26288128/170498071 [===>..........................] - ETA: 3s
 29368320/170498071 [====>.........................] - ETA: 3s
 32645120/170498071 [====>.........................] - ETA: 3s
 35725312/170498071 [=====>........................] - ETA: 2s
 38248448/170498071 [=====>........................] - ETA: 2s
 40935424/170498071 [======>.......................] - ETA: 2s
 43786240/170498071 [======>.......................] - ETA: 2s
 46653440/170498071 [=======>......................] - ETA: 2s
 49324032/170498071 [=======>......................] - ETA: 2s
 52060160/170498071 [========>.....................] - ETA: 2s
 54829056/170498071 [========>.....................] - ETA: 2s
 57319424/170498071 [=========>....................] - ETA: 2s
 59990016/170498071 [=========>....................] - ETA: 2s
 62922752/170498071 [==========>...................] - ETA: 2s
 65658880/170498071 [==========>...................] - ETA: 2s
 68526080/170498071 [===========>..................] - ETA: 2s
 71442432/170498071 [===========>..................] - ETA: 1s
 74244096/170498071 [============>.................] - ETA: 1s
 76980224/170498071 [============>.................] - ETA: 1s
 79765504/170498071 [=============>................] - ETA: 1s
 82518016/170498071 [=============>................] - ETA: 1s
 85344256/170498071 [==============>...............] - ETA: 1s
 88039424/170498071 [==============>...............] - ETA: 1s
 90849280/170498071 [==============>...............] - ETA: 1s
 93691904/170498071 [===============>..............] - ETA: 1s
 96559104/170498071 [===============>..............] - ETA: 1s
 99262464/170498071 [================>.............] - ETA: 1s
102064128/170498071 [================>.............] - ETA: 1s
104833024/170498071 [=================>............] - ETA: 1s
107569152/170498071 [=================>............] - ETA: 1s
110239744/170498071 [==================>...........] - ETA: 1s
113025024/170498071 [==================>...........] - ETA: 1s
115679232/170498071 [===================>..........] - ETA: 1s
118235136/170498071 [===================>..........] - ETA: 1s
121036800/170498071 [====================>.........] - ETA: 0s
123871232/170498071 [====================>.........] - ETA: 0s
126623744/170498071 [=====================>........] - ETA: 0s
129376256/170498071 [=====================>........] - ETA: 0s
132177920/170498071 [======================>.......] - ETA: 0s
134848512/170498071 [======================>.......] - ETA: 0s
137486336/170498071 [=======================>......] - ETA: 0s
140222464/170498071 [=======================>......] - ETA: 0s
143024128/170498071 [========================>.....] - ETA: 0s
145760256/170498071 [========================>.....] - ETA: 0s
148561920/170498071 [=========================>....] - ETA: 0s
151298048/170498071 [=========================>....] - ETA: 0s
154017792/170498071 [==========================>...] - ETA: 0s
156590080/170498071 [==========================>...] - ETA: 0s
159211520/170498071 [===========================>..] - ETA: 0s
162160640/170498071 [===========================>..] - ETA: 0s
164626432/170498071 [===========================>..] - ETA: 0s
167264256/170498071 [============================>.] - ETA: 0s
169975808/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 2s
 3825664/94765736 [>.............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 1s
16203776/94765736 [====>.........................] - ETA: 1s
20021248/94765736 [=====>........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
37494784/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
42139648/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
74358784/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
89939968/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 17.759770393371582
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615863370.345224s

Real time: 1615863370.345239
Epoch 1/5

on_train_batch_begin: 1615863371.135329s

on_train_batch_end: 1615863417.401016s

 1024/50000 [..............................] - ETA: 37:30 - loss: 17.4654 - accuracy: 1.9455e-04
on_train_batch_begin: 1615863417.401623s

1 step training time: 46.266294s

on_train_batch_end: 1615863417.538506s

 2048/50000 [>.............................] - ETA: 18:24 - loss: 15.1120 - accuracy: 3.7575e-04
on_train_batch_begin: 1615863417.538812s

2 step training time: 0.137189s

on_train_batch_end: 1615863417.670641s

 3072/50000 [>.............................] - ETA: 12:02 - loss: 13.1946 - accuracy: 6.3578e-04
on_train_batch_begin: 1615863417.670934s

3 step training time: 0.132122s

on_train_batch_end: 1615863417.806232s

 4096/50000 [=>............................] - ETA: 8:51 - loss: 12.0403 - accuracy: 0.0012     
on_train_batch_begin: 1615863417.806526s

4 step training time: 0.135592s

on_train_batch_end: 1615863417.939043s

 5120/50000 [==>...........................] - ETA: 6:57 - loss: 11.2644 - accuracy: 0.0016
on_train_batch_begin: 1615863417.939341s

5 step training time: 0.132815s

on_train_batch_end: 1615863418.074577s

 6144/50000 [==>...........................] - ETA: 5:40 - loss: 10.6841 - accuracy: 0.0035
on_train_batch_begin: 1615863418.074867s

6 step training time: 0.135526s

on_train_batch_end: 1615863418.209268s

 7168/50000 [===>..........................] - ETA: 4:46 - loss: 10.2513 - accuracy: 0.0062
on_train_batch_begin: 1615863418.209558s

7 step training time: 0.134691s

on_train_batch_end: 1615863418.341763s

 8192/50000 [===>..........................] - ETA: 4:04 - loss: 9.8996 - accuracy: 0.0093 
on_train_batch_begin: 1615863418.342109s

8 step training time: 0.132551s

on_train_batch_end: 1615863418.477087s

 9216/50000 [====>.........................] - ETA: 3:33 - loss: 9.5992 - accuracy: 0.0127
on_train_batch_begin: 1615863418.477376s

9 step training time: 0.135267s

on_train_batch_end: 1615863418.610411s

10240/50000 [=====>........................] - ETA: 3:07 - loss: 9.3503 - accuracy: 0.0155
on_train_batch_begin: 1615863418.610704s

10 step training time: 0.133328s

on_train_batch_end: 1615863418.743643s

11264/50000 [=====>........................] - ETA: 2:46 - loss: 9.1436 - accuracy: 0.0192
on_train_batch_begin: 1615863418.743930s

11 step training time: 0.133226s

on_train_batch_end: 1615863418.878570s

12288/50000 [======>.......................] - ETA: 2:28 - loss: 8.9529 - accuracy: 0.0222
on_train_batch_begin: 1615863418.878870s

12 step training time: 0.134940s

on_train_batch_end: 1615863419.012421s

13312/50000 [======>.......................] - ETA: 2:14 - loss: 8.7791 - accuracy: 0.0244
on_train_batch_begin: 1615863419.012716s

13 step training time: 0.133846s

on_train_batch_end: 1615863419.147408s

14336/50000 [=======>......................] - ETA: 2:01 - loss: 8.6313 - accuracy: 0.0269
on_train_batch_begin: 1615863419.147712s

14 step training time: 0.134996s

on_train_batch_end: 1615863419.281565s

15360/50000 [========>.....................] - ETA: 1:50 - loss: 8.4857 - accuracy: 0.0297
on_train_batch_begin: 1615863419.281905s

15 step training time: 0.134193s

on_train_batch_end: 1615863419.416157s

16384/50000 [========>.....................] - ETA: 1:40 - loss: 8.3563 - accuracy: 0.0316
on_train_batch_begin: 1615863419.416448s

16 step training time: 0.134544s

on_train_batch_end: 1615863419.550989s

17408/50000 [=========>....................] - ETA: 1:32 - loss: 8.2404 - accuracy: 0.0333
on_train_batch_begin: 1615863419.551280s

17 step training time: 0.134831s

on_train_batch_end: 1615863419.684488s

18432/50000 [==========>...................] - ETA: 1:24 - loss: 8.1306 - accuracy: 0.0351
on_train_batch_begin: 1615863419.684788s

18 step training time: 0.133508s

on_train_batch_end: 1615863419.819200s

19456/50000 [==========>...................] - ETA: 1:17 - loss: 8.0259 - accuracy: 0.0373
on_train_batch_begin: 1615863419.819484s

19 step training time: 0.134696s

on_train_batch_end: 1615863419.952692s

20480/50000 [===========>..................] - ETA: 1:11 - loss: 7.9273 - accuracy: 0.0390
on_train_batch_begin: 1615863419.953001s

20 step training time: 0.133518s

on_train_batch_end: 1615863420.086388s

21504/50000 [===========>..................] - ETA: 1:05 - loss: 7.8340 - accuracy: 0.0405
on_train_batch_begin: 1615863420.086677s

21 step training time: 0.133676s

on_train_batch_end: 1615863420.221584s

22528/50000 [============>.................] - ETA: 1:00 - loss: 7.7450 - accuracy: 0.0421
on_train_batch_begin: 1615863420.221973s

22 step training time: 0.135296s

on_train_batch_end: 1615863420.355618s

23552/50000 [=============>................] - ETA: 56s - loss: 7.6682 - accuracy: 0.0436 
on_train_batch_begin: 1615863420.355901s

23 step training time: 0.133928s

on_train_batch_end: 1615863420.488942s

24576/50000 [=============>................] - ETA: 51s - loss: 7.5857 - accuracy: 0.0448
on_train_batch_begin: 1615863420.489235s

24 step training time: 0.133334s

on_train_batch_end: 1615863420.623016s

25600/50000 [==============>...............] - ETA: 47s - loss: 7.5077 - accuracy: 0.0457
on_train_batch_begin: 1615863420.623303s

25 step training time: 0.134068s

on_train_batch_end: 1615863420.755620s

26624/50000 [==============>...............] - ETA: 44s - loss: 7.4341 - accuracy: 0.0467
on_train_batch_begin: 1615863420.755905s

26 step training time: 0.132602s

on_train_batch_end: 1615863420.891386s

27648/50000 [===============>..............] - ETA: 40s - loss: 7.3658 - accuracy: 0.0474
on_train_batch_begin: 1615863420.891680s

27 step training time: 0.135775s

on_train_batch_end: 1615863421.025314s

28672/50000 [================>.............] - ETA: 37s - loss: 7.3017 - accuracy: 0.0480
on_train_batch_begin: 1615863421.025594s

28 step training time: 0.133914s

on_train_batch_end: 1615863421.158531s

29696/50000 [================>.............] - ETA: 34s - loss: 7.2356 - accuracy: 0.0485
on_train_batch_begin: 1615863421.158814s

29 step training time: 0.133220s

on_train_batch_end: 1615863421.292972s

30720/50000 [=================>............] - ETA: 31s - loss: 7.1638 - accuracy: 0.0491
on_train_batch_begin: 1615863421.293252s

30 step training time: 0.134438s

on_train_batch_end: 1615863421.431441s

31744/50000 [==================>...........] - ETA: 29s - loss: 7.1003 - accuracy: 0.0496
on_train_batch_begin: 1615863421.431731s

31 step training time: 0.138479s

on_train_batch_end: 1615863421.565286s

32768/50000 [==================>...........] - ETA: 26s - loss: 7.0363 - accuracy: 0.0502
on_train_batch_begin: 1615863421.565571s

32 step training time: 0.133839s

on_train_batch_end: 1615863421.698343s

33792/50000 [===================>..........] - ETA: 24s - loss: 6.9762 - accuracy: 0.0506
on_train_batch_begin: 1615863421.698626s

33 step training time: 0.133055s

on_train_batch_end: 1615863421.833274s

34816/50000 [===================>..........] - ETA: 22s - loss: 6.9143 - accuracy: 0.0511
on_train_batch_begin: 1615863421.833563s

34 step training time: 0.134937s

on_train_batch_end: 1615863421.969121s

35840/50000 [====================>.........] - ETA: 20s - loss: 6.8566 - accuracy: 0.0516
on_train_batch_begin: 1615863421.969408s

35 step training time: 0.135845s

on_train_batch_end: 1615863422.102710s

36864/50000 [=====================>........] - ETA: 18s - loss: 6.8028 - accuracy: 0.0521
on_train_batch_begin: 1615863422.103023s

36 step training time: 0.133615s

on_train_batch_end: 1615863422.236018s

37888/50000 [=====================>........] - ETA: 16s - loss: 6.7425 - accuracy: 0.0526
on_train_batch_begin: 1615863422.236313s

37 step training time: 0.133290s

on_train_batch_end: 1615863422.370080s

38912/50000 [======================>.......] - ETA: 14s - loss: 6.6832 - accuracy: 0.0532
on_train_batch_begin: 1615863422.370364s

38 step training time: 0.134051s

on_train_batch_end: 1615863422.502082s

39936/50000 [======================>.......] - ETA: 13s - loss: 6.6198 - accuracy: 0.0538
on_train_batch_begin: 1615863422.502373s

39 step training time: 0.132009s

on_train_batch_end: 1615863422.637004s

40960/50000 [=======================>......] - ETA: 11s - loss: 6.5620 - accuracy: 0.0544
on_train_batch_begin: 1615863422.637287s

40 step training time: 0.134915s

on_train_batch_end: 1615863422.769378s

41984/50000 [========================>.....] - ETA: 10s - loss: 6.5021 - accuracy: 0.0550
on_train_batch_begin: 1615863422.769663s

41 step training time: 0.132376s

on_train_batch_end: 1615863422.904084s

43008/50000 [========================>.....] - ETA: 8s - loss: 6.4405 - accuracy: 0.0556 
on_train_batch_begin: 1615863422.904392s

42 step training time: 0.134729s

on_train_batch_end: 1615863423.037657s

44032/50000 [=========================>....] - ETA: 7s - loss: 6.3820 - accuracy: 0.0561
on_train_batch_begin: 1615863423.037963s

43 step training time: 0.133571s

on_train_batch_end: 1615863423.172562s

45056/50000 [==========================>...] - ETA: 5s - loss: 6.3217 - accuracy: 0.0567
on_train_batch_begin: 1615863423.172861s

44 step training time: 0.134898s

on_train_batch_end: 1615863423.308095s

46080/50000 [==========================>...] - ETA: 4s - loss: 6.2575 - accuracy: 0.0574
on_train_batch_begin: 1615863423.308385s

45 step training time: 0.135525s

on_train_batch_end: 1615863423.441775s

47104/50000 [===========================>..] - ETA: 3s - loss: 6.1924 - accuracy: 0.0582
on_train_batch_begin: 1615863423.442091s

46 step training time: 0.133706s

on_train_batch_end: 1615863423.575877s

48128/50000 [===========================>..] - ETA: 2s - loss: 6.1297 - accuracy: 0.0588
on_train_batch_begin: 1615863423.576160s

47 step training time: 0.134069s

on_train_batch_end: 1615863423.709853s

49152/50000 [============================>.] - ETA: 0s - loss: 6.0685 - accuracy: 0.0596
on_train_batch_begin: 1615863423.710169s

48 step training time: 0.134009s

on_train_batch_end: 1615863426.417665s

on_test_batch_begin: 1615863426.652656s

49 step training time: 2.942487s

on_epoch_end: 1615863431.605747s

Validation time: 4.953076s

Real time: 1615863431.605747s

Epoch time: 61.26052522659302s

50000/50000 [==============================] - 61s 1ms/sample - loss: 6.0171 - accuracy: 0.0601 - val_loss: 14.6656 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615863431.605973s

Real time: 1615863431.605979
Epoch 2/5

on_train_batch_begin: 1615863431.610462s

on_train_batch_end: 1615863431.750296s

 1024/50000 [..............................] - ETA: 6s - loss: 2.8142 - accuracy: 0.0963
on_train_batch_begin: 1615863431.750568s

1 step training time: 0.140106s

on_train_batch_end: 1615863431.883977s

 2048/50000 [>.............................] - ETA: 6s - loss: 2.9153 - accuracy: 0.0970
on_train_batch_begin: 1615863431.884256s

2 step training time: 0.133687s

on_train_batch_end: 1615863432.017388s

 3072/50000 [>.............................] - ETA: 6s - loss: 2.8985 - accuracy: 0.0974
on_train_batch_begin: 1615863432.017664s

3 step training time: 0.133409s

on_train_batch_end: 1615863432.152290s

 4096/50000 [=>............................] - ETA: 6s - loss: 2.9027 - accuracy: 0.0976
on_train_batch_begin: 1615863432.152579s

4 step training time: 0.134915s

on_train_batch_end: 1615863432.286759s

 5120/50000 [==>...........................] - ETA: 5s - loss: 2.8467 - accuracy: 0.0980
on_train_batch_begin: 1615863432.287037s

5 step training time: 0.134458s

on_train_batch_end: 1615863432.420487s

 6144/50000 [==>...........................] - ETA: 5s - loss: 2.8165 - accuracy: 0.0979
on_train_batch_begin: 1615863432.420767s

6 step training time: 0.133730s

on_train_batch_end: 1615863432.555535s

 7168/50000 [===>..........................] - ETA: 5s - loss: 2.7684 - accuracy: 0.0982
on_train_batch_begin: 1615863432.555817s

7 step training time: 0.135050s

on_train_batch_end: 1615863432.688605s

 8192/50000 [===>..........................] - ETA: 5s - loss: 2.7356 - accuracy: 0.0984
on_train_batch_begin: 1615863432.688885s

8 step training time: 0.133068s

on_train_batch_end: 1615863432.824627s

 9216/50000 [====>.........................] - ETA: 5s - loss: 2.7119 - accuracy: 0.0985
on_train_batch_begin: 1615863432.824912s

9 step training time: 0.136027s

on_train_batch_end: 1615863432.958276s

10240/50000 [=====>........................] - ETA: 5s - loss: 2.7072 - accuracy: 0.0986
on_train_batch_begin: 1615863432.958573s

10 step training time: 0.133660s

on_train_batch_end: 1615863433.091509s

11264/50000 [=====>........................] - ETA: 5s - loss: 2.6841 - accuracy: 0.0986
on_train_batch_begin: 1615863433.091821s

11 step training time: 0.133248s

on_train_batch_end: 1615863433.229303s

12288/50000 [======>.......................] - ETA: 4s - loss: 2.6619 - accuracy: 0.0988
on_train_batch_begin: 1615863433.229584s

12 step training time: 0.137763s

on_train_batch_end: 1615863433.363354s

13312/50000 [======>.......................] - ETA: 4s - loss: 2.6570 - accuracy: 0.0989
on_train_batch_begin: 1615863433.363633s

13 step training time: 0.134049s

on_train_batch_end: 1615863433.497101s

14336/50000 [=======>......................] - ETA: 4s - loss: 2.6262 - accuracy: 0.0990
on_train_batch_begin: 1615863433.497380s

14 step training time: 0.133747s

on_train_batch_end: 1615863433.632176s

15360/50000 [========>.....................] - ETA: 4s - loss: 2.6156 - accuracy: 0.0990
on_train_batch_begin: 1615863433.632461s

15 step training time: 0.135081s

on_train_batch_end: 1615863433.765332s

16384/50000 [========>.....................] - ETA: 4s - loss: 2.5982 - accuracy: 0.0991
on_train_batch_begin: 1615863433.765609s

16 step training time: 0.133148s

on_train_batch_end: 1615863433.901054s

17408/50000 [=========>....................] - ETA: 4s - loss: 2.5871 - accuracy: 0.0992
on_train_batch_begin: 1615863433.901332s

17 step training time: 0.135723s

on_train_batch_end: 1615863434.035496s

18432/50000 [==========>...................] - ETA: 4s - loss: 2.5816 - accuracy: 0.0993
on_train_batch_begin: 1615863434.035779s

18 step training time: 0.134447s

on_train_batch_end: 1615863434.168536s

19456/50000 [==========>...................] - ETA: 4s - loss: 2.5661 - accuracy: 0.0994
on_train_batch_begin: 1615863434.168819s

19 step training time: 0.133040s

on_train_batch_end: 1615863434.303502s

20480/50000 [===========>..................] - ETA: 3s - loss: 2.5527 - accuracy: 0.0995
on_train_batch_begin: 1615863434.303787s

20 step training time: 0.134969s

on_train_batch_end: 1615863434.438214s

21504/50000 [===========>..................] - ETA: 3s - loss: 2.5350 - accuracy: 0.0995
on_train_batch_begin: 1615863434.438498s

21 step training time: 0.134710s

on_train_batch_end: 1615863434.572566s

22528/50000 [============>.................] - ETA: 3s - loss: 2.5247 - accuracy: 0.0996
on_train_batch_begin: 1615863434.572853s

22 step training time: 0.134356s

on_train_batch_end: 1615863434.708331s

23552/50000 [=============>................] - ETA: 3s - loss: 2.5168 - accuracy: 0.0996
on_train_batch_begin: 1615863434.708613s

23 step training time: 0.135760s

on_train_batch_end: 1615863434.841454s

24576/50000 [=============>................] - ETA: 3s - loss: 2.5075 - accuracy: 0.0996
on_train_batch_begin: 1615863434.841765s

24 step training time: 0.133152s

on_train_batch_end: 1615863434.977738s

25600/50000 [==============>...............] - ETA: 3s - loss: 2.4946 - accuracy: 0.0997
on_train_batch_begin: 1615863434.978054s

25 step training time: 0.136288s

on_train_batch_end: 1615863435.112539s

26624/50000 [==============>...............] - ETA: 3s - loss: 2.4892 - accuracy: 0.0997
on_train_batch_begin: 1615863435.112830s

26 step training time: 0.134776s

on_train_batch_end: 1615863435.245893s

27648/50000 [===============>..............] - ETA: 2s - loss: 2.4730 - accuracy: 0.0997
on_train_batch_begin: 1615863435.246177s

27 step training time: 0.133348s

on_train_batch_end: 1615863435.382007s

28672/50000 [================>.............] - ETA: 2s - loss: 2.4579 - accuracy: 0.0998
on_train_batch_begin: 1615863435.382294s

28 step training time: 0.136117s

on_train_batch_end: 1615863435.516583s

29696/50000 [================>.............] - ETA: 2s - loss: 2.4429 - accuracy: 0.0998
on_train_batch_begin: 1615863435.516865s

29 step training time: 0.134570s

on_train_batch_end: 1615863435.652047s

30720/50000 [=================>............] - ETA: 2s - loss: 2.4411 - accuracy: 0.0998
on_train_batch_begin: 1615863435.652336s

30 step training time: 0.135471s

on_train_batch_end: 1615863435.788387s

31744/50000 [==================>...........] - ETA: 2s - loss: 2.4363 - accuracy: 0.0998
on_train_batch_begin: 1615863435.788670s

31 step training time: 0.136334s

on_train_batch_end: 1615863435.923296s

32768/50000 [==================>...........] - ETA: 2s - loss: 2.4253 - accuracy: 0.0999
on_train_batch_begin: 1615863435.923573s

32 step training time: 0.134903s

on_train_batch_end: 1615863436.056211s

33792/50000 [===================>..........] - ETA: 2s - loss: 2.4250 - accuracy: 0.0999
on_train_batch_begin: 1615863436.056495s

33 step training time: 0.132922s

on_train_batch_end: 1615863436.191864s

34816/50000 [===================>..........] - ETA: 2s - loss: 2.4239 - accuracy: 0.0999
on_train_batch_begin: 1615863436.192151s

34 step training time: 0.135656s

on_train_batch_end: 1615863436.326513s

35840/50000 [====================>.........] - ETA: 1s - loss: 2.4179 - accuracy: 0.0999
on_train_batch_begin: 1615863436.326797s

35 step training time: 0.134646s

on_train_batch_end: 1615863436.461978s

36864/50000 [=====================>........] - ETA: 1s - loss: 2.4065 - accuracy: 0.1000
on_train_batch_begin: 1615863436.462270s

36 step training time: 0.135473s

on_train_batch_end: 1615863436.597651s

37888/50000 [=====================>........] - ETA: 1s - loss: 2.3922 - accuracy: 0.1000
on_train_batch_begin: 1615863436.597960s

37 step training time: 0.135690s

on_train_batch_end: 1615863436.731754s

38912/50000 [======================>.......] - ETA: 1s - loss: 2.3863 - accuracy: 0.1000
on_train_batch_begin: 1615863436.732042s

38 step training time: 0.134082s

on_train_batch_end: 1615863436.867882s

39936/50000 [======================>.......] - ETA: 1s - loss: 2.3812 - accuracy: 0.1000
on_train_batch_begin: 1615863436.868163s

39 step training time: 0.136122s

on_train_batch_end: 1615863437.003655s

40960/50000 [=======================>......] - ETA: 1s - loss: 2.3771 - accuracy: 0.1000
on_train_batch_begin: 1615863437.003950s

40 step training time: 0.135787s

on_train_batch_end: 1615863437.136915s

41984/50000 [========================>.....] - ETA: 1s - loss: 2.3701 - accuracy: 0.1000
on_train_batch_begin: 1615863437.137195s

41 step training time: 0.133245s

on_train_batch_end: 1615863437.273429s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.3617 - accuracy: 0.1000
on_train_batch_begin: 1615863437.273717s

42 step training time: 0.136522s

on_train_batch_end: 1615863437.409692s

44032/50000 [=========================>....] - ETA: 0s - loss: 2.3564 - accuracy: 0.1000
on_train_batch_begin: 1615863437.409996s

43 step training time: 0.136279s

on_train_batch_end: 1615863437.544561s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.3511 - accuracy: 0.1000
on_train_batch_begin: 1615863437.544848s

44 step training time: 0.134852s

on_train_batch_end: 1615863437.679961s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.3457 - accuracy: 0.1001
on_train_batch_begin: 1615863437.680247s

45 step training time: 0.135400s

on_train_batch_end: 1615863437.816776s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.3374 - accuracy: 0.1001
on_train_batch_begin: 1615863437.817056s

46 step training time: 0.136808s

on_train_batch_end: 1615863437.950664s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.3268 - accuracy: 0.1001
on_train_batch_begin: 1615863437.950975s

47 step training time: 0.133919s

on_train_batch_end: 1615863438.086328s

49152/50000 [============================>.] - ETA: 0s - loss: 2.3221 - accuracy: 0.1001
on_train_batch_begin: 1615863438.086605s

48 step training time: 0.135630s

on_train_batch_end: 1615863438.208484s

on_test_batch_begin: 1615863438.229455s

49 step training time: 0.142851s

on_epoch_end: 1615863438.547962s

Validation time: 0.318496s

Real time: 1615863438.547962s

Epoch time: 6.941998720169067s

50000/50000 [==============================] - 7s 139us/sample - loss: 2.3158 - accuracy: 0.1001 - val_loss: 7.5638 - val_accuracy: 0.0999

on_epoch_begin: 1615863438.548136s

Real time: 1615863438.5481412
Epoch 3/5

on_train_batch_begin: 1615863438.552413s

on_train_batch_end: 1615863438.690412s

 1024/50000 [..............................] - ETA: 6s - loss: 1.9947 - accuracy: 0.1012
on_train_batch_begin: 1615863438.690683s

1 step training time: 0.138270s

on_train_batch_end: 1615863438.824225s

 2048/50000 [>.............................] - ETA: 6s - loss: 1.9850 - accuracy: 0.1009
on_train_batch_begin: 1615863438.824491s

2 step training time: 0.133809s

on_train_batch_end: 1615863438.958547s

 3072/50000 [>.............................] - ETA: 6s - loss: 1.9700 - accuracy: 0.1011
on_train_batch_begin: 1615863438.958849s

3 step training time: 0.134358s

on_train_batch_end: 1615863439.094519s

 4096/50000 [=>............................] - ETA: 6s - loss: 1.9253 - accuracy: 0.1011
on_train_batch_begin: 1615863439.094814s

4 step training time: 0.135965s

on_train_batch_end: 1615863439.227599s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.9247 - accuracy: 0.1012
on_train_batch_begin: 1615863439.227885s

5 step training time: 0.133070s

on_train_batch_end: 1615863439.363803s

 6144/50000 [==>...........................] - ETA: 5s - loss: 1.9017 - accuracy: 0.1012
on_train_batch_begin: 1615863439.364085s

6 step training time: 0.136201s

on_train_batch_end: 1615863439.500867s

 7168/50000 [===>..........................] - ETA: 5s - loss: 1.8785 - accuracy: 0.1011
on_train_batch_begin: 1615863439.501145s

7 step training time: 0.137059s

on_train_batch_end: 1615863439.634319s

 8192/50000 [===>..........................] - ETA: 5s - loss: 1.8872 - accuracy: 0.1010
on_train_batch_begin: 1615863439.634624s

8 step training time: 0.133479s

on_train_batch_end: 1615863439.770775s

 9216/50000 [====>.........................] - ETA: 5s - loss: 1.8876 - accuracy: 0.1010
on_train_batch_begin: 1615863439.771059s

9 step training time: 0.136435s

on_train_batch_end: 1615863439.907065s

10240/50000 [=====>........................] - ETA: 5s - loss: 1.8806 - accuracy: 0.1010
on_train_batch_begin: 1615863439.907351s

10 step training time: 0.136292s

on_train_batch_end: 1615863440.041467s

11264/50000 [=====>........................] - ETA: 5s - loss: 1.8668 - accuracy: 0.1009
on_train_batch_begin: 1615863440.041777s

11 step training time: 0.134426s

on_train_batch_end: 1615863440.177181s

12288/50000 [======>.......................] - ETA: 5s - loss: 1.8483 - accuracy: 0.1009
on_train_batch_begin: 1615863440.177464s

12 step training time: 0.135687s

on_train_batch_end: 1615863440.312409s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.8360 - accuracy: 0.1010
on_train_batch_begin: 1615863440.312696s

13 step training time: 0.135232s

on_train_batch_end: 1615863440.445628s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.8326 - accuracy: 0.1010
on_train_batch_begin: 1615863440.445936s

14 step training time: 0.133240s

on_train_batch_end: 1615863440.581926s

15360/50000 [========>.....................] - ETA: 4s - loss: 1.8308 - accuracy: 0.1010
on_train_batch_begin: 1615863440.582215s

15 step training time: 0.136279s

on_train_batch_end: 1615863440.719056s

16384/50000 [========>.....................] - ETA: 4s - loss: 1.8241 - accuracy: 0.1010
on_train_batch_begin: 1615863440.719345s

16 step training time: 0.137130s

on_train_batch_end: 1615863440.851893s

17408/50000 [=========>....................] - ETA: 4s - loss: 1.8150 - accuracy: 0.1010
on_train_batch_begin: 1615863440.852183s

17 step training time: 0.132838s

on_train_batch_end: 1615863440.991542s

18432/50000 [==========>...................] - ETA: 4s - loss: 1.8068 - accuracy: 0.1010
on_train_batch_begin: 1615863440.991856s

18 step training time: 0.139673s

on_train_batch_end: 1615863441.127905s

19456/50000 [==========>...................] - ETA: 4s - loss: 1.8011 - accuracy: 0.1010
on_train_batch_begin: 1615863441.128187s

19 step training time: 0.136331s

on_train_batch_end: 1615863441.261968s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.8010 - accuracy: 0.1010
on_train_batch_begin: 1615863441.262259s

20 step training time: 0.134072s

on_train_batch_end: 1615863441.395779s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.7964 - accuracy: 0.1010
on_train_batch_begin: 1615863441.396060s

21 step training time: 0.133802s

on_train_batch_end: 1615863441.531385s

22528/50000 [============>.................] - ETA: 3s - loss: 1.7894 - accuracy: 0.1010
on_train_batch_begin: 1615863441.531706s

22 step training time: 0.135646s

on_train_batch_end: 1615863441.666543s

23552/50000 [=============>................] - ETA: 3s - loss: 1.7879 - accuracy: 0.1010
on_train_batch_begin: 1615863441.666825s

23 step training time: 0.135119s

on_train_batch_end: 1615863441.803632s

24576/50000 [=============>................] - ETA: 3s - loss: 1.7797 - accuracy: 0.1010
on_train_batch_begin: 1615863441.803908s

24 step training time: 0.137083s

on_train_batch_end: 1615863441.939377s

25600/50000 [==============>...............] - ETA: 3s - loss: 1.7751 - accuracy: 0.1010
on_train_batch_begin: 1615863441.939661s

25 step training time: 0.135753s

on_train_batch_end: 1615863442.075864s

26624/50000 [==============>...............] - ETA: 3s - loss: 1.7735 - accuracy: 0.1010
on_train_batch_begin: 1615863442.076148s

26 step training time: 0.136487s

on_train_batch_end: 1615863442.209021s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.7717 - accuracy: 0.1010
on_train_batch_begin: 1615863442.209301s

27 step training time: 0.133152s

on_train_batch_end: 1615863442.345959s

28672/50000 [================>.............] - ETA: 2s - loss: 1.7633 - accuracy: 0.1010
on_train_batch_begin: 1615863442.346243s

28 step training time: 0.136942s

on_train_batch_end: 1615863442.482853s

29696/50000 [================>.............] - ETA: 2s - loss: 1.7589 - accuracy: 0.1011
on_train_batch_begin: 1615863442.483169s

29 step training time: 0.136926s

on_train_batch_end: 1615863442.616455s

30720/50000 [=================>............] - ETA: 2s - loss: 1.7478 - accuracy: 0.1011
on_train_batch_begin: 1615863442.616739s

30 step training time: 0.133570s

on_train_batch_end: 1615863442.752666s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.7462 - accuracy: 0.1010
on_train_batch_begin: 1615863442.752977s

31 step training time: 0.136238s

on_train_batch_end: 1615863442.888817s

32768/50000 [==================>...........] - ETA: 2s - loss: 1.7439 - accuracy: 0.1010
on_train_batch_begin: 1615863442.889105s

32 step training time: 0.136128s

on_train_batch_end: 1615863443.022365s

33792/50000 [===================>..........] - ETA: 2s - loss: 1.7420 - accuracy: 0.1010
on_train_batch_begin: 1615863443.022654s

33 step training time: 0.133548s

on_train_batch_end: 1615863443.159573s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.7347 - accuracy: 0.1010
on_train_batch_begin: 1615863443.159859s

34 step training time: 0.137206s

on_train_batch_end: 1615863443.294817s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.7308 - accuracy: 0.1010
on_train_batch_begin: 1615863443.295105s

35 step training time: 0.135245s

on_train_batch_end: 1615863443.428839s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.7274 - accuracy: 0.1010
on_train_batch_begin: 1615863443.429124s

36 step training time: 0.134019s

on_train_batch_end: 1615863443.565601s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.7231 - accuracy: 0.1010
on_train_batch_begin: 1615863443.565918s

37 step training time: 0.136795s

on_train_batch_end: 1615863443.701524s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.7185 - accuracy: 0.1010
on_train_batch_begin: 1615863443.701836s

38 step training time: 0.135918s

on_train_batch_end: 1615863443.834630s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.7134 - accuracy: 0.1010
on_train_batch_begin: 1615863443.834916s

39 step training time: 0.133079s

on_train_batch_end: 1615863443.971169s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.7058 - accuracy: 0.1010
on_train_batch_begin: 1615863443.971456s

40 step training time: 0.136540s

on_train_batch_end: 1615863444.108026s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.6993 - accuracy: 0.1010
on_train_batch_begin: 1615863444.108336s

41 step training time: 0.136880s

on_train_batch_end: 1615863444.241839s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.6909 - accuracy: 0.1010
on_train_batch_begin: 1615863444.242144s

42 step training time: 0.133808s

on_train_batch_end: 1615863444.377586s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.6854 - accuracy: 0.1010
on_train_batch_begin: 1615863444.377887s

43 step training time: 0.135743s

on_train_batch_end: 1615863444.514195s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.6793 - accuracy: 0.1010
on_train_batch_begin: 1615863444.514476s

44 step training time: 0.136589s

on_train_batch_end: 1615863444.647954s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.6768 - accuracy: 0.1010
on_train_batch_begin: 1615863444.648250s

45 step training time: 0.133774s

on_train_batch_end: 1615863444.784393s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.6698 - accuracy: 0.1010
on_train_batch_begin: 1615863444.784675s

46 step training time: 0.136425s

on_train_batch_end: 1615863444.919760s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.6650 - accuracy: 0.1010
on_train_batch_begin: 1615863444.920041s

47 step training time: 0.135365s

on_train_batch_end: 1615863445.053046s

49152/50000 [============================>.] - ETA: 0s - loss: 1.6585 - accuracy: 0.1010
on_train_batch_begin: 1615863445.053339s

48 step training time: 0.133299s

on_train_batch_end: 1615863445.176460s

on_test_batch_begin: 1615863445.194986s

49 step training time: 0.141647s

on_epoch_end: 1615863445.510373s

Validation time: 0.315375s

Real time: 1615863445.510373s

Epoch time: 6.962246894836426s

50000/50000 [==============================] - 7s 139us/sample - loss: 1.6565 - accuracy: 0.1010 - val_loss: 7.1274 - val_accuracy: 0.0999

on_epoch_begin: 1615863445.510553s

Real time: 1615863445.510558
Epoch 4/5

on_train_batch_begin: 1615863445.515025s

on_train_batch_end: 1615863445.651536s

 1024/50000 [..............................] - ETA: 6s - loss: 1.1899 - accuracy: 0.1004
on_train_batch_begin: 1615863445.651843s

1 step training time: 0.136818s

on_train_batch_end: 1615863445.786563s

 2048/50000 [>.............................] - ETA: 6s - loss: 1.2544 - accuracy: 0.1011
on_train_batch_begin: 1615863445.786838s

2 step training time: 0.134995s

on_train_batch_end: 1615863445.921273s

 3072/50000 [>.............................] - ETA: 6s - loss: 1.2269 - accuracy: 0.1012
on_train_batch_begin: 1615863445.921557s

3 step training time: 0.134720s

on_train_batch_end: 1615863446.056751s

 4096/50000 [=>............................] - ETA: 6s - loss: 1.2220 - accuracy: 0.1011
on_train_batch_begin: 1615863446.057035s

4 step training time: 0.135478s

on_train_batch_end: 1615863446.191504s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.2210 - accuracy: 0.1011
on_train_batch_begin: 1615863446.191819s

5 step training time: 0.134784s

on_train_batch_end: 1615863446.327464s

 6144/50000 [==>...........................] - ETA: 5s - loss: 1.2308 - accuracy: 0.1012
on_train_batch_begin: 1615863446.327747s

6 step training time: 0.135928s

on_train_batch_end: 1615863446.462408s

 7168/50000 [===>..........................] - ETA: 5s - loss: 1.2202 - accuracy: 0.1012
on_train_batch_begin: 1615863446.462695s

7 step training time: 0.134948s

on_train_batch_end: 1615863446.597535s

 8192/50000 [===>..........................] - ETA: 5s - loss: 1.2193 - accuracy: 0.1012
on_train_batch_begin: 1615863446.597820s

8 step training time: 0.135125s

on_train_batch_end: 1615863446.732887s

 9216/50000 [====>.........................] - ETA: 5s - loss: 1.2140 - accuracy: 0.1011
on_train_batch_begin: 1615863446.733168s

9 step training time: 0.135349s

on_train_batch_end: 1615863446.867862s

10240/50000 [=====>........................] - ETA: 5s - loss: 1.2143 - accuracy: 0.1012
on_train_batch_begin: 1615863446.868145s

10 step training time: 0.134976s

on_train_batch_end: 1615863447.004460s

11264/50000 [=====>........................] - ETA: 5s - loss: 1.2165 - accuracy: 0.1012
on_train_batch_begin: 1615863447.004738s

11 step training time: 0.136594s

on_train_batch_end: 1615863447.140368s

12288/50000 [======>.......................] - ETA: 5s - loss: 1.2147 - accuracy: 0.1012
on_train_batch_begin: 1615863447.140649s

12 step training time: 0.135911s

on_train_batch_end: 1615863447.276742s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.2166 - accuracy: 0.1012
on_train_batch_begin: 1615863447.277030s

13 step training time: 0.136382s

on_train_batch_end: 1615863447.414483s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.2070 - accuracy: 0.1012
on_train_batch_begin: 1615863447.414794s

14 step training time: 0.137764s

on_train_batch_end: 1615863447.547898s

15360/50000 [========>.....................] - ETA: 4s - loss: 1.2023 - accuracy: 0.1012
on_train_batch_begin: 1615863447.548181s

15 step training time: 0.133387s

on_train_batch_end: 1615863447.685318s

16384/50000 [========>.....................] - ETA: 4s - loss: 1.1922 - accuracy: 0.1012
on_train_batch_begin: 1615863447.685600s

16 step training time: 0.137419s

on_train_batch_end: 1615863447.820631s

17408/50000 [=========>....................] - ETA: 4s - loss: 1.1943 - accuracy: 0.1012
on_train_batch_begin: 1615863447.820915s

17 step training time: 0.135314s

on_train_batch_end: 1615863447.954160s

18432/50000 [==========>...................] - ETA: 4s - loss: 1.1829 - accuracy: 0.1012
on_train_batch_begin: 1615863447.954440s

18 step training time: 0.133526s

on_train_batch_end: 1615863448.093006s

19456/50000 [==========>...................] - ETA: 4s - loss: 1.1851 - accuracy: 0.1012
on_train_batch_begin: 1615863448.093304s

19 step training time: 0.138864s

on_train_batch_end: 1615863448.229995s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.1865 - accuracy: 0.1012
on_train_batch_begin: 1615863448.230278s

20 step training time: 0.136974s

on_train_batch_end: 1615863448.366443s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.1925 - accuracy: 0.1012
on_train_batch_begin: 1615863448.366727s

21 step training time: 0.136450s

on_train_batch_end: 1615863448.500477s

22528/50000 [============>.................] - ETA: 3s - loss: 1.1804 - accuracy: 0.1012
on_train_batch_begin: 1615863448.500774s

22 step training time: 0.134047s

on_train_batch_end: 1615863448.637645s

23552/50000 [=============>................] - ETA: 3s - loss: 1.1813 - accuracy: 0.1012
on_train_batch_begin: 1615863448.637948s

23 step training time: 0.137174s

on_train_batch_end: 1615863448.773685s

24576/50000 [=============>................] - ETA: 3s - loss: 1.1778 - accuracy: 0.1012
on_train_batch_begin: 1615863448.773990s

24 step training time: 0.136041s

on_train_batch_end: 1615863448.908342s

25600/50000 [==============>...............] - ETA: 3s - loss: 1.1770 - accuracy: 0.1012
on_train_batch_begin: 1615863448.908624s

25 step training time: 0.134634s

on_train_batch_end: 1615863449.044642s

26624/50000 [==============>...............] - ETA: 3s - loss: 1.1762 - accuracy: 0.1012
on_train_batch_begin: 1615863449.044925s

26 step training time: 0.136302s

on_train_batch_end: 1615863449.181504s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.1748 - accuracy: 0.1012
on_train_batch_begin: 1615863449.181826s

27 step training time: 0.136900s

on_train_batch_end: 1615863449.316554s

28672/50000 [================>.............] - ETA: 2s - loss: 1.1763 - accuracy: 0.1012
on_train_batch_begin: 1615863449.316846s

28 step training time: 0.135021s

on_train_batch_end: 1615863449.451921s

29696/50000 [================>.............] - ETA: 2s - loss: 1.1768 - accuracy: 0.1012
on_train_batch_begin: 1615863449.452206s

29 step training time: 0.135359s

on_train_batch_end: 1615863449.587637s

30720/50000 [=================>............] - ETA: 2s - loss: 1.1760 - accuracy: 0.1012
on_train_batch_begin: 1615863449.587918s

30 step training time: 0.135712s

on_train_batch_end: 1615863449.723377s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.1772 - accuracy: 0.1012
on_train_batch_begin: 1615863449.723665s

31 step training time: 0.135747s

on_train_batch_end: 1615863449.858349s

32768/50000 [==================>...........] - ETA: 2s - loss: 1.1768 - accuracy: 0.1012
on_train_batch_begin: 1615863449.858634s

32 step training time: 0.134969s

on_train_batch_end: 1615863449.994432s

33792/50000 [===================>..........] - ETA: 2s - loss: 1.1798 - accuracy: 0.1012
on_train_batch_begin: 1615863449.994716s

33 step training time: 0.136082s

on_train_batch_end: 1615863450.129840s

34816/50000 [===================>..........] - ETA: 2s - loss: 1.1769 - accuracy: 0.1012
on_train_batch_begin: 1615863450.130156s

34 step training time: 0.135439s

on_train_batch_end: 1615863450.264400s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.1735 - accuracy: 0.1012
on_train_batch_begin: 1615863450.264682s

35 step training time: 0.134526s

on_train_batch_end: 1615863450.399734s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.1694 - accuracy: 0.1012
on_train_batch_begin: 1615863450.400016s

36 step training time: 0.135334s

on_train_batch_end: 1615863450.535186s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.1696 - accuracy: 0.1012
on_train_batch_begin: 1615863450.535474s

37 step training time: 0.135458s

on_train_batch_end: 1615863450.669728s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.1688 - accuracy: 0.1012
on_train_batch_begin: 1615863450.670040s

38 step training time: 0.134567s

on_train_batch_end: 1615863450.807220s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.1659 - accuracy: 0.1012
on_train_batch_begin: 1615863450.807506s

39 step training time: 0.137466s

on_train_batch_end: 1615863450.943471s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.1670 - accuracy: 0.1012
on_train_batch_begin: 1615863450.943760s

40 step training time: 0.136254s

on_train_batch_end: 1615863451.078126s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.1700 - accuracy: 0.1012
on_train_batch_begin: 1615863451.078418s

41 step training time: 0.134658s

on_train_batch_end: 1615863451.214589s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.1693 - accuracy: 0.1012
on_train_batch_begin: 1615863451.214869s

42 step training time: 0.136451s

on_train_batch_end: 1615863451.351077s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.1673 - accuracy: 0.1012
on_train_batch_begin: 1615863451.351363s

43 step training time: 0.136493s

on_train_batch_end: 1615863451.484389s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.1635 - accuracy: 0.1012
on_train_batch_begin: 1615863451.484669s

44 step training time: 0.133307s

on_train_batch_end: 1615863451.621655s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.1624 - accuracy: 0.1012
on_train_batch_begin: 1615863451.621964s

45 step training time: 0.137294s

on_train_batch_end: 1615863451.757237s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.1603 - accuracy: 0.1012
on_train_batch_begin: 1615863451.757520s

46 step training time: 0.135557s

on_train_batch_end: 1615863451.894127s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1580 - accuracy: 0.1012
on_train_batch_begin: 1615863451.894430s

47 step training time: 0.136910s

on_train_batch_end: 1615863452.031068s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1565 - accuracy: 0.1012
on_train_batch_begin: 1615863452.031356s

48 step training time: 0.136926s

on_train_batch_end: 1615863452.155484s

on_test_batch_begin: 1615863452.172898s

49 step training time: 0.141542s

on_epoch_end: 1615863452.491333s

Validation time: 0.318424s

Real time: 1615863452.491333s

Epoch time: 6.9807915687561035s

50000/50000 [==============================] - 7s 140us/sample - loss: 1.1537 - accuracy: 0.1012 - val_loss: 7.2895 - val_accuracy: 0.0999

on_epoch_begin: 1615863452.491508s

Real time: 1615863452.4915128
Epoch 5/5

on_train_batch_begin: 1615863452.495932s

on_train_batch_end: 1615863452.634409s

 1024/50000 [..............................] - ETA: 6s - loss: 1.0660 - accuracy: 0.1017
on_train_batch_begin: 1615863452.634675s

1 step training time: 0.138743s

on_train_batch_end: 1615863452.770394s

 2048/50000 [>.............................] - ETA: 6s - loss: 1.0459 - accuracy: 0.1012
on_train_batch_begin: 1615863452.770664s

2 step training time: 0.135989s

on_train_batch_end: 1615863452.904444s

 3072/50000 [>.............................] - ETA: 6s - loss: 0.9736 - accuracy: 0.1015
on_train_batch_begin: 1615863452.904719s

3 step training time: 0.134055s

on_train_batch_end: 1615863453.041456s

 4096/50000 [=>............................] - ETA: 6s - loss: 0.9461 - accuracy: 0.1014
on_train_batch_begin: 1615863453.041771s

4 step training time: 0.137052s

on_train_batch_end: 1615863453.176440s

 5120/50000 [==>...........................] - ETA: 6s - loss: 0.9487 - accuracy: 0.1013
on_train_batch_begin: 1615863453.176718s

5 step training time: 0.134947s

on_train_batch_end: 1615863453.311344s

 6144/50000 [==>...........................] - ETA: 5s - loss: 0.9492 - accuracy: 0.1013
on_train_batch_begin: 1615863453.311653s

6 step training time: 0.134936s

on_train_batch_end: 1615863453.447694s

 7168/50000 [===>..........................] - ETA: 5s - loss: 0.9593 - accuracy: 0.1014
on_train_batch_begin: 1615863453.447989s

7 step training time: 0.136335s

on_train_batch_end: 1615863453.583176s

 8192/50000 [===>..........................] - ETA: 5s - loss: 0.9681 - accuracy: 0.1015
on_train_batch_begin: 1615863453.583454s

8 step training time: 0.135466s

on_train_batch_end: 1615863453.718471s

 9216/50000 [====>.........................] - ETA: 5s - loss: 0.9452 - accuracy: 0.1015
on_train_batch_begin: 1615863453.718750s

9 step training time: 0.135296s

on_train_batch_end: 1615863453.856846s

10240/50000 [=====>........................] - ETA: 5s - loss: 0.9447 - accuracy: 0.1015
on_train_batch_begin: 1615863453.857139s

10 step training time: 0.138389s

on_train_batch_end: 1615863453.992330s

11264/50000 [=====>........................] - ETA: 5s - loss: 0.9475 - accuracy: 0.1015
on_train_batch_begin: 1615863453.992622s

11 step training time: 0.135483s

on_train_batch_end: 1615863454.129471s

12288/50000 [======>.......................] - ETA: 5s - loss: 0.9478 - accuracy: 0.1014
on_train_batch_begin: 1615863454.129765s

12 step training time: 0.137143s

on_train_batch_end: 1615863454.266536s

13312/50000 [======>.......................] - ETA: 4s - loss: 0.9413 - accuracy: 0.1015
on_train_batch_begin: 1615863454.266817s

13 step training time: 0.137053s

on_train_batch_end: 1615863454.402963s

14336/50000 [=======>......................] - ETA: 4s - loss: 0.9343 - accuracy: 0.1015
on_train_batch_begin: 1615863454.403247s

14 step training time: 0.136430s

on_train_batch_end: 1615863454.538249s

15360/50000 [========>.....................] - ETA: 4s - loss: 0.9267 - accuracy: 0.1015
on_train_batch_begin: 1615863454.538530s

15 step training time: 0.135283s

on_train_batch_end: 1615863454.672953s

16384/50000 [========>.....................] - ETA: 4s - loss: 0.9207 - accuracy: 0.1015
on_train_batch_begin: 1615863454.673247s

16 step training time: 0.134717s

on_train_batch_end: 1615863454.811713s

17408/50000 [=========>....................] - ETA: 4s - loss: 0.9166 - accuracy: 0.1014
on_train_batch_begin: 1615863454.811998s

17 step training time: 0.138751s

on_train_batch_end: 1615863454.946705s

18432/50000 [==========>...................] - ETA: 4s - loss: 0.9203 - accuracy: 0.1015
on_train_batch_begin: 1615863454.947012s

18 step training time: 0.135014s

on_train_batch_end: 1615863455.083550s

19456/50000 [==========>...................] - ETA: 4s - loss: 0.9196 - accuracy: 0.1015
on_train_batch_begin: 1615863455.083828s

19 step training time: 0.136817s

on_train_batch_end: 1615863455.221193s

20480/50000 [===========>..................] - ETA: 3s - loss: 0.9174 - accuracy: 0.1014
on_train_batch_begin: 1615863455.221474s

20 step training time: 0.137645s

on_train_batch_end: 1615863455.358428s

21504/50000 [===========>..................] - ETA: 3s - loss: 0.9132 - accuracy: 0.1014
on_train_batch_begin: 1615863455.358708s

21 step training time: 0.137234s

on_train_batch_end: 1615863455.493176s

22528/50000 [============>.................] - ETA: 3s - loss: 0.9139 - accuracy: 0.1014
on_train_batch_begin: 1615863455.493457s

22 step training time: 0.134749s

on_train_batch_end: 1615863455.630773s

23552/50000 [=============>................] - ETA: 3s - loss: 0.9126 - accuracy: 0.1014
on_train_batch_begin: 1615863455.631058s

23 step training time: 0.137601s

on_train_batch_end: 1615863455.767911s

24576/50000 [=============>................] - ETA: 3s - loss: 0.9104 - accuracy: 0.1014
on_train_batch_begin: 1615863455.768194s

24 step training time: 0.137136s

on_train_batch_end: 1615863455.903823s

25600/50000 [==============>...............] - ETA: 3s - loss: 0.9073 - accuracy: 0.1014
on_train_batch_begin: 1615863455.904113s

25 step training time: 0.135919s

on_train_batch_end: 1615863456.039798s

26624/50000 [==============>...............] - ETA: 3s - loss: 0.9033 - accuracy: 0.1014
on_train_batch_begin: 1615863456.040082s

26 step training time: 0.135969s

on_train_batch_end: 1615863456.174709s

27648/50000 [===============>..............] - ETA: 2s - loss: 0.8973 - accuracy: 0.1013
on_train_batch_begin: 1615863456.174988s

27 step training time: 0.134906s

on_train_batch_end: 1615863456.311118s

28672/50000 [================>.............] - ETA: 2s - loss: 0.8963 - accuracy: 0.1013
on_train_batch_begin: 1615863456.311396s

28 step training time: 0.136408s

on_train_batch_end: 1615863456.446666s

29696/50000 [================>.............] - ETA: 2s - loss: 0.8952 - accuracy: 0.1013
on_train_batch_begin: 1615863456.446951s

29 step training time: 0.135555s

on_train_batch_end: 1615863456.581673s

30720/50000 [=================>............] - ETA: 2s - loss: 0.8940 - accuracy: 0.1013
on_train_batch_begin: 1615863456.581978s

30 step training time: 0.135027s

on_train_batch_end: 1615863456.718248s

31744/50000 [==================>...........] - ETA: 2s - loss: 0.8916 - accuracy: 0.1013
on_train_batch_begin: 1615863456.718528s

31 step training time: 0.136549s

on_train_batch_end: 1615863456.853407s

32768/50000 [==================>...........] - ETA: 2s - loss: 0.8893 - accuracy: 0.1013
on_train_batch_begin: 1615863456.853688s

32 step training time: 0.135160s

on_train_batch_end: 1615863456.988592s

33792/50000 [===================>..........] - ETA: 2s - loss: 0.8886 - accuracy: 0.1013
on_train_batch_begin: 1615863456.988875s

33 step training time: 0.135187s

on_train_batch_end: 1615863457.123931s

34816/50000 [===================>..........] - ETA: 2s - loss: 0.8903 - accuracy: 0.1013
on_train_batch_begin: 1615863457.124228s

34 step training time: 0.135353s

on_train_batch_end: 1615863457.261758s

35840/50000 [====================>.........] - ETA: 1s - loss: 0.8874 - accuracy: 0.1013
on_train_batch_begin: 1615863457.262062s

35 step training time: 0.137834s

on_train_batch_end: 1615863457.409348s

36864/50000 [=====================>........] - ETA: 1s - loss: 0.8899 - accuracy: 0.1013
on_train_batch_begin: 1615863457.409630s

36 step training time: 0.147568s

on_train_batch_end: 1615863457.545542s

37888/50000 [=====================>........] - ETA: 1s - loss: 0.8866 - accuracy: 0.1013
on_train_batch_begin: 1615863457.545828s

37 step training time: 0.136198s

on_train_batch_end: 1615863457.680749s

38912/50000 [======================>.......] - ETA: 1s - loss: 0.8869 - accuracy: 0.1013
on_train_batch_begin: 1615863457.681033s

38 step training time: 0.135206s

on_train_batch_end: 1615863457.816854s

39936/50000 [======================>.......] - ETA: 1s - loss: 0.8863 - accuracy: 0.1013
on_train_batch_begin: 1615863457.817138s

39 step training time: 0.136105s

on_train_batch_end: 1615863457.952359s

40960/50000 [=======================>......] - ETA: 1s - loss: 0.8882 - accuracy: 0.1013
on_train_batch_begin: 1615863457.952648s

40 step training time: 0.135509s

on_train_batch_end: 1615863458.087856s

41984/50000 [========================>.....] - ETA: 1s - loss: 0.8851 - accuracy: 0.1013
on_train_batch_begin: 1615863458.088140s

41 step training time: 0.135493s

on_train_batch_end: 1615863458.230509s

43008/50000 [========================>.....] - ETA: 0s - loss: 0.8839 - accuracy: 0.1013
on_train_batch_begin: 1615863458.230794s

42 step training time: 0.142654s

on_train_batch_end: 1615863458.367911s

44032/50000 [=========================>....] - ETA: 0s - loss: 0.8827 - accuracy: 0.1013
on_train_batch_begin: 1615863458.368206s

43 step training time: 0.137412s

on_train_batch_end: 1615863458.504568s

45056/50000 [==========================>...] - ETA: 0s - loss: 0.8797 - accuracy: 0.1013
on_train_batch_begin: 1615863458.504849s

44 step training time: 0.136643s

on_train_batch_end: 1615863458.639244s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.8791 - accuracy: 0.1013
on_train_batch_begin: 1615863458.639525s

45 step training time: 0.134676s

on_train_batch_end: 1615863458.776288s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.8764 - accuracy: 0.1013
on_train_batch_begin: 1615863458.776605s

46 step training time: 0.137080s

on_train_batch_end: 1615863458.911910s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.8763 - accuracy: 0.1013
on_train_batch_begin: 1615863458.912197s

47 step training time: 0.135592s

on_train_batch_end: 1615863459.048296s

49152/50000 [============================>.] - ETA: 0s - loss: 0.8759 - accuracy: 0.1013
on_train_batch_begin: 1615863459.048580s

48 step training time: 0.136383s

on_train_batch_end: 1615863459.171971s

on_test_batch_begin: 1615863459.190862s

49 step training time: 0.142282s

on_epoch_end: 1615863459.508014s

Validation time: 0.317142s

Real time: 1615863459.508014s

Epoch time: 7.016500234603882s

50000/50000 [==============================] - 7s 140us/sample - loss: 0.8763 - accuracy: 0.1013 - val_loss: 6.9762 - val_accuracy: 0.1001
Tempo do fit: 92.50038409233093