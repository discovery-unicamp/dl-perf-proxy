wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:33
   221184/170498071 [..............................] - ETA: 1:11
  1171456/170498071 [..............................] - ETA: 20s 
  3964928/170498071 [..............................] - ETA: 8s 
  7299072/170498071 [>.............................] - ETA: 5s
 10657792/170498071 [>.............................] - ETA: 4s
 13967360/170498071 [=>............................] - ETA: 3s
 17309696/170498071 [==>...........................] - ETA: 3s
 20553728/170498071 [==>...........................] - ETA: 3s
 23683072/170498071 [===>..........................] - ETA: 3s
 26877952/170498071 [===>..........................] - ETA: 2s
 30154752/170498071 [====>.........................] - ETA: 2s
 33497088/170498071 [====>.........................] - ETA: 2s
 36855808/170498071 [=====>........................] - ETA: 2s
 40148992/170498071 [======>.......................] - ETA: 2s
 43499520/170498071 [======>.......................] - ETA: 2s
 46850048/170498071 [=======>......................] - ETA: 2s
 50192384/170498071 [=======>......................] - ETA: 2s
 53354496/170498071 [========>.....................] - ETA: 2s
 56565760/170498071 [========>.....................] - ETA: 2s
 59727872/170498071 [=========>....................] - ETA: 1s
 62922752/170498071 [==========>...................] - ETA: 1s
 66281472/170498071 [==========>...................] - ETA: 1s
 69574656/170498071 [===========>..................] - ETA: 1s
 72949760/170498071 [===========>..................] - ETA: 1s
 76259328/170498071 [============>.................] - ETA: 1s
 79634432/170498071 [=============>................] - ETA: 1s
 82960384/170498071 [=============>................] - ETA: 1s
 86319104/170498071 [==============>...............] - ETA: 1s
 89464832/170498071 [==============>...............] - ETA: 1s
 92717056/170498071 [===============>..............] - ETA: 1s
 95903744/170498071 [===============>..............] - ETA: 1s
 99295232/170498071 [================>.............] - ETA: 1s
102621184/170498071 [=================>............] - ETA: 1s
105930752/170498071 [=================>............] - ETA: 1s
109305856/170498071 [==================>...........] - ETA: 1s
112631808/170498071 [==================>...........] - ETA: 0s
115982336/170498071 [===================>..........] - ETA: 0s
119234560/170498071 [===================>..........] - ETA: 0s
122396672/170498071 [====================>.........] - ETA: 0s
125640704/170498071 [=====================>........] - ETA: 0s
128942080/170498071 [=====================>........] - ETA: 0s
132292608/170498071 [======================>.......] - ETA: 0s
135659520/170498071 [======================>.......] - ETA: 0s
138993664/170498071 [=======================>......] - ETA: 0s
142336000/170498071 [========================>.....] - ETA: 0s
145686528/170498071 [========================>.....] - ETA: 0s
148987904/170498071 [=========================>....] - ETA: 0s
152199168/170498071 [=========================>....] - ETA: 0s
155394048/170498071 [==========================>...] - ETA: 0s
158654464/170498071 [==========================>...] - ETA: 0s
161914880/170498071 [===========================>..] - ETA: 0s
165257216/170498071 [============================>.] - ETA: 0s
168550400/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 3s
 6455296/94765736 [=>............................] - ETA: 0s
11534336/94765736 [==>...........................] - ETA: 0s
16539648/94765736 [====>.........................] - ETA: 0s
21495808/94765736 [=====>........................] - ETA: 0s
26607616/94765736 [=======>......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
35725312/94765736 [==========>...................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
45334528/94765736 [=============>................] - ETA: 0s
47439872/94765736 [==============>...............] - ETA: 0s
55631872/94765736 [================>.............] - ETA: 0s
58040320/94765736 [=================>............] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
71745536/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
75964416/94765736 [=======================>......] - ETA: 0s
80986112/94765736 [========================>.....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
89874432/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 27.057207107543945
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1609169229.629106s

Real time: 1609169229.6291296
Epoch 1/5

on_train_batch_begin: 1609169230.933692s

on_train_batch_end: 1609169364.754908s

 1024/50000 [..............................] - ETA: 1:47:42 - loss: 16.7455 - accuracy: 2.7466e-04
on_train_batch_begin: 1609169364.755653s

1 step training time: 133.821961s

on_train_batch_end: 1609169364.964750s

 2048/50000 [>.............................] - ETA: 52:48 - loss: 14.9594 - accuracy: 2.7084e-04  
on_train_batch_begin: 1609169364.965162s

2 step training time: 0.209509s

on_train_batch_end: 1609169365.213020s

 3072/50000 [>.............................] - ETA: 34:31 - loss: 13.1616 - accuracy: 3.5095e-04
on_train_batch_begin: 1609169365.213427s

3 step training time: 0.248265s

on_train_batch_end: 1609169365.449793s

 4096/50000 [=>............................] - ETA: 25:22 - loss: 11.9973 - accuracy: 6.1226e-04
on_train_batch_begin: 1609169365.450193s

4 step training time: 0.236766s

on_train_batch_end: 1609169365.696721s

 5120/50000 [==>...........................] - ETA: 19:52 - loss: 11.2409 - accuracy: 0.0012    
on_train_batch_begin: 1609169365.697109s

5 step training time: 0.246916s

on_train_batch_end: 1609169365.928929s

 6144/50000 [==>...........................] - ETA: 16:12 - loss: 10.7006 - accuracy: 0.0018
on_train_batch_begin: 1609169365.929327s

6 step training time: 0.232217s

on_train_batch_end: 1609169366.135212s

 7168/50000 [===>..........................] - ETA: 13:35 - loss: 10.2859 - accuracy: 0.0030
on_train_batch_begin: 1609169366.135599s

7 step training time: 0.206273s

on_train_batch_end: 1609169366.342204s

 8192/50000 [===>..........................] - ETA: 11:37 - loss: 9.9737 - accuracy: 0.0049 
on_train_batch_begin: 1609169366.342590s

8 step training time: 0.206991s

on_train_batch_end: 1609169366.592554s

 9216/50000 [====>.........................] - ETA: 10:06 - loss: 9.7033 - accuracy: 0.0073
on_train_batch_begin: 1609169366.592944s

9 step training time: 0.250354s

on_train_batch_end: 1609169366.822542s

10240/50000 [=====>........................] - ETA: 8:52 - loss: 9.4698 - accuracy: 0.0095 
on_train_batch_begin: 1609169366.822932s

10 step training time: 0.229987s

on_train_batch_end: 1609169367.029254s

11264/50000 [=====>........................] - ETA: 7:52 - loss: 9.2841 - accuracy: 0.0117
on_train_batch_begin: 1609169367.029673s

11 step training time: 0.206741s

on_train_batch_end: 1609169367.278136s

12288/50000 [======>.......................] - ETA: 7:02 - loss: 9.1094 - accuracy: 0.0141
on_train_batch_begin: 1609169367.278528s

12 step training time: 0.248855s

on_train_batch_end: 1609169367.508880s

13312/50000 [======>.......................] - ETA: 6:19 - loss: 8.9593 - accuracy: 0.0164
on_train_batch_begin: 1609169367.509270s

13 step training time: 0.230742s

on_train_batch_end: 1609169367.714661s

14336/50000 [=======>......................] - ETA: 5:43 - loss: 8.8483 - accuracy: 0.0188
on_train_batch_begin: 1609169367.715039s

14 step training time: 0.205770s

on_train_batch_end: 1609169367.964015s

15360/50000 [========>.....................] - ETA: 5:11 - loss: 8.7331 - accuracy: 0.0213
on_train_batch_begin: 1609169367.964390s

15 step training time: 0.249350s

on_train_batch_end: 1609169368.198533s

16384/50000 [========>.....................] - ETA: 4:44 - loss: 8.6220 - accuracy: 0.0237
on_train_batch_begin: 1609169368.198908s

16 step training time: 0.234518s

on_train_batch_end: 1609169368.405141s

17408/50000 [=========>....................] - ETA: 4:19 - loss: 8.5246 - accuracy: 0.0258
on_train_batch_begin: 1609169368.405516s

17 step training time: 0.206609s

on_train_batch_end: 1609169368.654177s

18432/50000 [==========>...................] - ETA: 3:58 - loss: 8.4351 - accuracy: 0.0276
on_train_batch_begin: 1609169368.654549s

18 step training time: 0.249032s

on_train_batch_end: 1609169368.884396s

19456/50000 [==========>...................] - ETA: 3:38 - loss: 8.3492 - accuracy: 0.0293
on_train_batch_begin: 1609169368.884774s

19 step training time: 0.230225s

on_train_batch_end: 1609169369.134331s

20480/50000 [===========>..................] - ETA: 3:21 - loss: 8.2645 - accuracy: 0.0309
on_train_batch_begin: 1609169369.134703s

20 step training time: 0.249929s

on_train_batch_end: 1609169369.363009s

21504/50000 [===========>..................] - ETA: 3:05 - loss: 8.1835 - accuracy: 0.0324
on_train_batch_begin: 1609169369.363397s

21 step training time: 0.228695s

on_train_batch_end: 1609169369.612155s

22528/50000 [============>.................] - ETA: 2:50 - loss: 8.1060 - accuracy: 0.0337
on_train_batch_begin: 1609169369.612527s

22 step training time: 0.249130s

on_train_batch_end: 1609169369.842214s

23552/50000 [=============>................] - ETA: 2:37 - loss: 8.0287 - accuracy: 0.0350
on_train_batch_begin: 1609169369.842587s

23 step training time: 0.230060s

on_train_batch_end: 1609169370.092862s

24576/50000 [=============>................] - ETA: 2:25 - loss: 7.9630 - accuracy: 0.0361
on_train_batch_begin: 1609169370.093236s

24 step training time: 0.250649s

on_train_batch_end: 1609169370.322269s

25600/50000 [==============>...............] - ETA: 2:14 - loss: 7.8953 - accuracy: 0.0370
on_train_batch_begin: 1609169370.322665s

25 step training time: 0.229428s

on_train_batch_end: 1609169370.528897s

26624/50000 [==============>...............] - ETA: 2:03 - loss: 7.8253 - accuracy: 0.0383
on_train_batch_begin: 1609169370.529285s

26 step training time: 0.206621s

on_train_batch_end: 1609169370.779820s

27648/50000 [===============>..............] - ETA: 1:54 - loss: 7.7680 - accuracy: 0.0394
on_train_batch_begin: 1609169370.780205s

27 step training time: 0.250919s

on_train_batch_end: 1609169371.016458s

28672/50000 [================>.............] - ETA: 1:45 - loss: 7.7062 - accuracy: 0.0403
on_train_batch_begin: 1609169371.016844s

28 step training time: 0.236639s

on_train_batch_end: 1609169371.223067s

29696/50000 [================>.............] - ETA: 1:36 - loss: 7.6528 - accuracy: 0.0412
on_train_batch_begin: 1609169371.223484s

29 step training time: 0.206640s

on_train_batch_end: 1609169371.472097s

30720/50000 [=================>............] - ETA: 1:29 - loss: 7.5933 - accuracy: 0.0419
on_train_batch_begin: 1609169371.472482s

30 step training time: 0.248998s

on_train_batch_end: 1609169371.704093s

31744/50000 [==================>...........] - ETA: 1:21 - loss: 7.5351 - accuracy: 0.0430
on_train_batch_begin: 1609169371.704484s

31 step training time: 0.232002s

on_train_batch_end: 1609169371.954961s

32768/50000 [==================>...........] - ETA: 1:14 - loss: 7.4760 - accuracy: 0.0440
on_train_batch_begin: 1609169371.955356s

32 step training time: 0.250872s

on_train_batch_end: 1609169372.184436s

33792/50000 [===================>..........] - ETA: 1:08 - loss: 7.4139 - accuracy: 0.0450
on_train_batch_begin: 1609169372.184819s

33 step training time: 0.229464s

on_train_batch_end: 1609169372.433970s

34816/50000 [===================>..........] - ETA: 1:02 - loss: 7.3538 - accuracy: 0.0459
on_train_batch_begin: 1609169372.434356s

34 step training time: 0.249537s

on_train_batch_end: 1609169372.663304s

35840/50000 [====================>.........] - ETA: 56s - loss: 7.2911 - accuracy: 0.0468 
on_train_batch_begin: 1609169372.663691s

35 step training time: 0.229334s

on_train_batch_end: 1609169372.913711s

36864/50000 [=====================>........] - ETA: 51s - loss: 7.2327 - accuracy: 0.0475
on_train_batch_begin: 1609169372.914100s

36 step training time: 0.250409s

on_train_batch_end: 1609169373.143547s

37888/50000 [=====================>........] - ETA: 45s - loss: 7.1700 - accuracy: 0.0483
on_train_batch_begin: 1609169373.143928s

37 step training time: 0.229828s

on_train_batch_end: 1609169373.392243s

38912/50000 [======================>.......] - ETA: 40s - loss: 7.1117 - accuracy: 0.0490
on_train_batch_begin: 1609169373.392633s

38 step training time: 0.248706s

on_train_batch_end: 1609169373.624286s

39936/50000 [======================>.......] - ETA: 36s - loss: 7.0493 - accuracy: 0.0497
on_train_batch_begin: 1609169373.624669s

39 step training time: 0.232035s

on_train_batch_end: 1609169373.831747s

40960/50000 [=======================>......] - ETA: 31s - loss: 6.9924 - accuracy: 0.0504
on_train_batch_begin: 1609169373.832125s

40 step training time: 0.207457s

on_train_batch_end: 1609169374.081514s

41984/50000 [========================>.....] - ETA: 27s - loss: 6.9340 - accuracy: 0.0511
on_train_batch_begin: 1609169374.081922s

41 step training time: 0.249796s

on_train_batch_end: 1609169374.311489s

43008/50000 [========================>.....] - ETA: 23s - loss: 6.8706 - accuracy: 0.0519
on_train_batch_begin: 1609169374.311871s

42 step training time: 0.229949s

on_train_batch_end: 1609169374.563759s

44032/50000 [=========================>....] - ETA: 19s - loss: 6.8102 - accuracy: 0.0525
on_train_batch_begin: 1609169374.564144s

43 step training time: 0.252273s

on_train_batch_end: 1609169374.800151s

45056/50000 [==========================>...] - ETA: 15s - loss: 6.7527 - accuracy: 0.0533
on_train_batch_begin: 1609169374.800534s

44 step training time: 0.236390s

on_train_batch_end: 1609169375.047570s

46080/50000 [==========================>...] - ETA: 12s - loss: 6.6941 - accuracy: 0.0541
on_train_batch_begin: 1609169375.047951s

45 step training time: 0.247416s

on_train_batch_end: 1609169375.279019s

47104/50000 [===========================>..] - ETA: 8s - loss: 6.6357 - accuracy: 0.0549 
on_train_batch_begin: 1609169375.279410s

46 step training time: 0.231460s

on_train_batch_end: 1609169375.530508s

48128/50000 [===========================>..] - ETA: 5s - loss: 6.5832 - accuracy: 0.0556
on_train_batch_begin: 1609169375.530885s

47 step training time: 0.251475s

on_train_batch_end: 1609169375.767532s

49152/50000 [============================>.] - ETA: 2s - loss: 6.5317 - accuracy: 0.0563
on_train_batch_begin: 1609169375.767905s

48 step training time: 0.237019s

on_train_batch_end: 1609169382.914008s

on_test_batch_begin: 1609169383.296559s

49 step training time: 7.528654s

on_epoch_end: 1609169399.484005s

Validation time: 16.187427s

Real time: 1609169399.484005s

Epoch time: 169.85489964485168s

50000/50000 [==============================] - 170s 3ms/sample - loss: 6.4871 - accuracy: 0.0568 - val_loss: 10.2460 - val_accuracy: 0.0999

on_epoch_begin: 1609169399.484267s

Real time: 1609169399.4842758
Epoch 2/5

on_train_batch_begin: 1609169399.491902s

on_train_batch_end: 1609169399.698513s

 1024/50000 [..............................] - ETA: 10s - loss: 3.8618 - accuracy: 0.0932
on_train_batch_begin: 1609169399.698894s

1 step training time: 0.206992s

on_train_batch_end: 1609169399.904192s

 2048/50000 [>.............................] - ETA: 9s - loss: 3.7821 - accuracy: 0.0939 
on_train_batch_begin: 1609169399.904565s

2 step training time: 0.205671s

on_train_batch_end: 1609169400.110432s

 3072/50000 [>.............................] - ETA: 9s - loss: 3.7412 - accuracy: 0.0943
on_train_batch_begin: 1609169400.110800s

3 step training time: 0.206235s

on_train_batch_end: 1609169400.359648s

 4096/50000 [=>............................] - ETA: 9s - loss: 3.6909 - accuracy: 0.0941
on_train_batch_begin: 1609169400.360064s

4 step training time: 0.249264s

on_train_batch_end: 1609169400.590115s

 5120/50000 [==>...........................] - ETA: 9s - loss: 3.6700 - accuracy: 0.0947
on_train_batch_begin: 1609169400.590495s

5 step training time: 0.230431s

on_train_batch_end: 1609169400.842416s

 6144/50000 [==>...........................] - ETA: 9s - loss: 3.6507 - accuracy: 0.0952
on_train_batch_begin: 1609169400.842787s

6 step training time: 0.252292s

on_train_batch_end: 1609169401.071656s

 7168/50000 [===>..........................] - ETA: 9s - loss: 3.6187 - accuracy: 0.0953
on_train_batch_begin: 1609169401.072032s

7 step training time: 0.229245s

on_train_batch_end: 1609169401.321909s

 8192/50000 [===>..........................] - ETA: 9s - loss: 3.6005 - accuracy: 0.0957
on_train_batch_begin: 1609169401.322286s

8 step training time: 0.250255s

on_train_batch_end: 1609169401.569607s

 9216/50000 [====>.........................] - ETA: 9s - loss: 3.5824 - accuracy: 0.0959
on_train_batch_begin: 1609169401.570010s

9 step training time: 0.247724s

on_train_batch_end: 1609169401.824131s

10240/50000 [=====>........................] - ETA: 9s - loss: 3.5672 - accuracy: 0.0961
on_train_batch_begin: 1609169401.824503s

10 step training time: 0.254493s

on_train_batch_end: 1609169402.051651s

11264/50000 [=====>........................] - ETA: 8s - loss: 3.5475 - accuracy: 0.0965
on_train_batch_begin: 1609169402.052035s

11 step training time: 0.227532s

on_train_batch_end: 1609169402.259911s

12288/50000 [======>.......................] - ETA: 8s - loss: 3.5283 - accuracy: 0.0968
on_train_batch_begin: 1609169402.260289s

12 step training time: 0.208254s

on_train_batch_end: 1609169402.509853s

13312/50000 [======>.......................] - ETA: 8s - loss: 3.5036 - accuracy: 0.0971
on_train_batch_begin: 1609169402.510257s

13 step training time: 0.249968s

on_train_batch_end: 1609169402.741210s

14336/50000 [=======>......................] - ETA: 8s - loss: 3.4951 - accuracy: 0.0973
on_train_batch_begin: 1609169402.741580s

14 step training time: 0.231323s

on_train_batch_end: 1609169402.991020s

15360/50000 [========>.....................] - ETA: 7s - loss: 3.4706 - accuracy: 0.0975
on_train_batch_begin: 1609169402.991405s

15 step training time: 0.249826s

on_train_batch_end: 1609169403.223048s

16384/50000 [========>.....................] - ETA: 7s - loss: 3.4598 - accuracy: 0.0977
on_train_batch_begin: 1609169403.223427s

16 step training time: 0.232021s

on_train_batch_end: 1609169403.469543s

17408/50000 [=========>....................] - ETA: 7s - loss: 3.4361 - accuracy: 0.0978
on_train_batch_begin: 1609169403.469941s

17 step training time: 0.246514s

on_train_batch_end: 1609169403.701516s

18432/50000 [==========>...................] - ETA: 7s - loss: 3.4026 - accuracy: 0.0981
on_train_batch_begin: 1609169403.701917s

18 step training time: 0.231976s

on_train_batch_end: 1609169403.948897s

19456/50000 [==========>...................] - ETA: 7s - loss: 3.3768 - accuracy: 0.0983
on_train_batch_begin: 1609169403.949273s

19 step training time: 0.247357s

on_train_batch_end: 1609169404.180226s

20480/50000 [===========>..................] - ETA: 6s - loss: 3.3569 - accuracy: 0.0983
on_train_batch_begin: 1609169404.180610s

20 step training time: 0.231337s

on_train_batch_end: 1609169404.430366s

21504/50000 [===========>..................] - ETA: 6s - loss: 3.3362 - accuracy: 0.0984
on_train_batch_begin: 1609169404.430748s

21 step training time: 0.250138s

on_train_batch_end: 1609169404.681149s

22528/50000 [============>.................] - ETA: 6s - loss: 3.3124 - accuracy: 0.0984
on_train_batch_begin: 1609169404.681523s

22 step training time: 0.250775s

on_train_batch_end: 1609169404.933796s

23552/50000 [=============>................] - ETA: 6s - loss: 3.2851 - accuracy: 0.0985
on_train_batch_begin: 1609169404.934167s

23 step training time: 0.252645s

on_train_batch_end: 1609169405.162526s

24576/50000 [=============>................] - ETA: 5s - loss: 3.2634 - accuracy: 0.0986
on_train_batch_begin: 1609169405.162905s

24 step training time: 0.228737s

on_train_batch_end: 1609169405.412112s

25600/50000 [==============>...............] - ETA: 5s - loss: 3.2378 - accuracy: 0.0988
on_train_batch_begin: 1609169405.412512s

25 step training time: 0.249607s

on_train_batch_end: 1609169405.643620s

26624/50000 [==============>...............] - ETA: 5s - loss: 3.2198 - accuracy: 0.0989
on_train_batch_begin: 1609169405.643996s

26 step training time: 0.231484s

on_train_batch_end: 1609169405.892159s

27648/50000 [===============>..............] - ETA: 5s - loss: 3.2045 - accuracy: 0.0989
on_train_batch_begin: 1609169405.892534s

27 step training time: 0.248538s

on_train_batch_end: 1609169406.124135s

28672/50000 [================>.............] - ETA: 4s - loss: 3.1893 - accuracy: 0.0989
on_train_batch_begin: 1609169406.124511s

28 step training time: 0.231978s

on_train_batch_end: 1609169406.375717s

29696/50000 [================>.............] - ETA: 4s - loss: 3.1711 - accuracy: 0.0989
on_train_batch_begin: 1609169406.376109s

29 step training time: 0.251598s

on_train_batch_end: 1609169406.606532s

30720/50000 [=================>............] - ETA: 4s - loss: 3.1546 - accuracy: 0.0989
on_train_batch_begin: 1609169406.606907s

30 step training time: 0.230798s

on_train_batch_end: 1609169406.856203s

31744/50000 [==================>...........] - ETA: 4s - loss: 3.1379 - accuracy: 0.0990
on_train_batch_begin: 1609169406.856573s

31 step training time: 0.249666s

on_train_batch_end: 1609169407.086576s

32768/50000 [==================>...........] - ETA: 3s - loss: 3.1235 - accuracy: 0.0991
on_train_batch_begin: 1609169407.086951s

32 step training time: 0.230378s

on_train_batch_end: 1609169407.337079s

33792/50000 [===================>..........] - ETA: 3s - loss: 3.1099 - accuracy: 0.0991
on_train_batch_begin: 1609169407.337452s

33 step training time: 0.250502s

on_train_batch_end: 1609169407.569344s

34816/50000 [===================>..........] - ETA: 3s - loss: 3.0928 - accuracy: 0.0992
on_train_batch_begin: 1609169407.569750s

34 step training time: 0.232298s

on_train_batch_end: 1609169407.820290s

35840/50000 [====================>.........] - ETA: 3s - loss: 3.0799 - accuracy: 0.0992
on_train_batch_begin: 1609169407.820663s

35 step training time: 0.250913s

on_train_batch_end: 1609169408.052152s

36864/50000 [=====================>........] - ETA: 3s - loss: 3.0682 - accuracy: 0.0993
on_train_batch_begin: 1609169408.052521s

36 step training time: 0.231858s

on_train_batch_end: 1609169408.303572s

37888/50000 [=====================>........] - ETA: 2s - loss: 3.0495 - accuracy: 0.0993
on_train_batch_begin: 1609169408.303967s

37 step training time: 0.251446s

on_train_batch_end: 1609169408.553587s

38912/50000 [======================>.......] - ETA: 2s - loss: 3.0317 - accuracy: 0.0994
on_train_batch_begin: 1609169408.554009s

38 step training time: 0.250042s

on_train_batch_end: 1609169408.808047s

39936/50000 [======================>.......] - ETA: 2s - loss: 3.0096 - accuracy: 0.0994
on_train_batch_begin: 1609169408.808439s

39 step training time: 0.254431s

on_train_batch_end: 1609169409.038923s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.9942 - accuracy: 0.0995
on_train_batch_begin: 1609169409.039315s

40 step training time: 0.230875s

on_train_batch_end: 1609169409.288221s

41984/50000 [========================>.....] - ETA: 1s - loss: 2.9838 - accuracy: 0.0995
on_train_batch_begin: 1609169409.288611s

41 step training time: 0.249296s

on_train_batch_end: 1609169409.521476s

43008/50000 [========================>.....] - ETA: 1s - loss: 2.9723 - accuracy: 0.0995
on_train_batch_begin: 1609169409.521898s

42 step training time: 0.233288s

on_train_batch_end: 1609169409.774713s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.9531 - accuracy: 0.0996
on_train_batch_begin: 1609169409.775103s

43 step training time: 0.253205s

on_train_batch_end: 1609169410.003717s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.9422 - accuracy: 0.0996
on_train_batch_begin: 1609169410.004106s

44 step training time: 0.229003s

on_train_batch_end: 1609169410.257305s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.9215 - accuracy: 0.0996
on_train_batch_begin: 1609169410.257714s

45 step training time: 0.253608s

on_train_batch_end: 1609169410.488482s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.9032 - accuracy: 0.0997
on_train_batch_begin: 1609169410.488872s

46 step training time: 0.231158s

on_train_batch_end: 1609169410.696750s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.8898 - accuracy: 0.0997
on_train_batch_begin: 1609169410.697134s

47 step training time: 0.208262s

on_train_batch_end: 1609169410.947225s

49152/50000 [============================>.] - ETA: 0s - loss: 2.8764 - accuracy: 0.0998
on_train_batch_begin: 1609169410.947623s

48 step training time: 0.250489s

on_train_batch_end: 1609169411.168488s

on_test_batch_begin: 1609169411.208667s

49 step training time: 0.261044s

on_epoch_end: 1609169411.714290s

Validation time: 0.505607s

Real time: 1609169411.714290s

Epoch time: 12.230037689208984s

50000/50000 [==============================] - 12s 245us/sample - loss: 2.8626 - accuracy: 0.0998 - val_loss: 7.2961 - val_accuracy: 0.0999

on_epoch_begin: 1609169411.714552s

Real time: 1609169411.7145615
Epoch 3/5

on_train_batch_begin: 1609169411.722467s

on_train_batch_end: 1609169411.974363s

 1024/50000 [..............................] - ETA: 12s - loss: 2.0249 - accuracy: 0.1008
on_train_batch_begin: 1609169411.974737s

1 step training time: 0.252270s

on_train_batch_end: 1609169412.206650s

 2048/50000 [>.............................] - ETA: 11s - loss: 1.9929 - accuracy: 0.1009
on_train_batch_begin: 1609169412.207021s

2 step training time: 0.232284s

on_train_batch_end: 1609169412.455671s

 3072/50000 [>.............................] - ETA: 11s - loss: 2.0168 - accuracy: 0.1009
on_train_batch_begin: 1609169412.456045s

3 step training time: 0.249024s

on_train_batch_end: 1609169412.685983s

 4096/50000 [=>............................] - ETA: 10s - loss: 2.0081 - accuracy: 0.1011
on_train_batch_begin: 1609169412.686351s

4 step training time: 0.230306s

on_train_batch_end: 1609169412.893010s

 5120/50000 [==>...........................] - ETA: 10s - loss: 2.0014 - accuracy: 0.1013
on_train_batch_begin: 1609169412.893398s

5 step training time: 0.207047s

on_train_batch_end: 1609169413.143688s

 6144/50000 [==>...........................] - ETA: 10s - loss: 1.9933 - accuracy: 0.1014
on_train_batch_begin: 1609169413.144061s

6 step training time: 0.250664s

on_train_batch_end: 1609169413.371626s

 7168/50000 [===>..........................] - ETA: 9s - loss: 1.9690 - accuracy: 0.1015 
on_train_batch_begin: 1609169413.371997s

7 step training time: 0.227936s

on_train_batch_end: 1609169413.619596s

 8192/50000 [===>..........................] - ETA: 9s - loss: 1.9746 - accuracy: 0.1016
on_train_batch_begin: 1609169413.619968s

8 step training time: 0.247971s

on_train_batch_end: 1609169413.854361s

 9216/50000 [====>.........................] - ETA: 9s - loss: 1.9754 - accuracy: 0.1015
on_train_batch_begin: 1609169413.854737s

9 step training time: 0.234768s

on_train_batch_end: 1609169414.108402s

10240/50000 [=====>........................] - ETA: 9s - loss: 1.9635 - accuracy: 0.1015
on_train_batch_begin: 1609169414.108783s

10 step training time: 0.254047s

on_train_batch_end: 1609169414.336920s

11264/50000 [=====>........................] - ETA: 9s - loss: 1.9504 - accuracy: 0.1015
on_train_batch_begin: 1609169414.337296s

11 step training time: 0.228513s

on_train_batch_end: 1609169414.588328s

12288/50000 [======>.......................] - ETA: 8s - loss: 1.9427 - accuracy: 0.1015
on_train_batch_begin: 1609169414.588701s

12 step training time: 0.251405s

on_train_batch_end: 1609169414.817388s

13312/50000 [======>.......................] - ETA: 8s - loss: 1.9414 - accuracy: 0.1016
on_train_batch_begin: 1609169414.817788s

13 step training time: 0.229087s

on_train_batch_end: 1609169415.067396s

14336/50000 [=======>......................] - ETA: 8s - loss: 1.9406 - accuracy: 0.1016
on_train_batch_begin: 1609169415.067768s

14 step training time: 0.249980s

on_train_batch_end: 1609169415.295492s

15360/50000 [========>.....................] - ETA: 8s - loss: 1.9438 - accuracy: 0.1016
on_train_batch_begin: 1609169415.295861s

15 step training time: 0.228094s

on_train_batch_end: 1609169415.541022s

16384/50000 [========>.....................] - ETA: 7s - loss: 1.9387 - accuracy: 0.1015
on_train_batch_begin: 1609169415.541394s

16 step training time: 0.245533s

on_train_batch_end: 1609169415.795348s

17408/50000 [=========>....................] - ETA: 7s - loss: 1.9258 - accuracy: 0.1016
on_train_batch_begin: 1609169415.795832s

17 step training time: 0.254438s

on_train_batch_end: 1609169416.032305s

18432/50000 [==========>...................] - ETA: 7s - loss: 1.9196 - accuracy: 0.1015
on_train_batch_begin: 1609169416.032674s

18 step training time: 0.236842s

on_train_batch_end: 1609169416.280039s

19456/50000 [==========>...................] - ETA: 7s - loss: 1.9164 - accuracy: 0.1015
on_train_batch_begin: 1609169416.280415s

19 step training time: 0.247740s

on_train_batch_end: 1609169416.527395s

20480/50000 [===========>..................] - ETA: 6s - loss: 1.9227 - accuracy: 0.1015
on_train_batch_begin: 1609169416.527768s

20 step training time: 0.247353s

on_train_batch_end: 1609169416.780541s

21504/50000 [===========>..................] - ETA: 6s - loss: 1.9268 - accuracy: 0.1015
on_train_batch_begin: 1609169416.780925s

21 step training time: 0.253157s

on_train_batch_end: 1609169417.017103s

22528/50000 [============>.................] - ETA: 6s - loss: 1.9285 - accuracy: 0.1015
on_train_batch_begin: 1609169417.017476s

22 step training time: 0.236552s

on_train_batch_end: 1609169417.266208s

23552/50000 [=============>................] - ETA: 6s - loss: 1.9205 - accuracy: 0.1015
on_train_batch_begin: 1609169417.266588s

23 step training time: 0.249112s

on_train_batch_end: 1609169417.495412s

24576/50000 [=============>................] - ETA: 5s - loss: 1.9177 - accuracy: 0.1015
on_train_batch_begin: 1609169417.495785s

24 step training time: 0.229197s

on_train_batch_end: 1609169417.744853s

25600/50000 [==============>...............] - ETA: 5s - loss: 1.9027 - accuracy: 0.1016
on_train_batch_begin: 1609169417.745228s

25 step training time: 0.249443s

on_train_batch_end: 1609169417.980412s

26624/50000 [==============>...............] - ETA: 5s - loss: 1.8923 - accuracy: 0.1016
on_train_batch_begin: 1609169417.980782s

26 step training time: 0.235554s

on_train_batch_end: 1609169418.232263s

27648/50000 [===============>..............] - ETA: 5s - loss: 1.8858 - accuracy: 0.1016
on_train_batch_begin: 1609169418.232644s

27 step training time: 0.251862s

on_train_batch_end: 1609169418.459706s

28672/50000 [================>.............] - ETA: 5s - loss: 1.8824 - accuracy: 0.1017
on_train_batch_begin: 1609169418.460079s

28 step training time: 0.227436s

on_train_batch_end: 1609169418.710034s

29696/50000 [================>.............] - ETA: 4s - loss: 1.8735 - accuracy: 0.1017
on_train_batch_begin: 1609169418.710407s

29 step training time: 0.250327s

on_train_batch_end: 1609169418.948205s

30720/50000 [=================>............] - ETA: 4s - loss: 1.8658 - accuracy: 0.1017
on_train_batch_begin: 1609169418.948581s

30 step training time: 0.238174s

on_train_batch_end: 1609169419.200320s

31744/50000 [==================>...........] - ETA: 4s - loss: 1.8633 - accuracy: 0.1017
on_train_batch_begin: 1609169419.200704s

31 step training time: 0.252124s

on_train_batch_end: 1609169419.429610s

32768/50000 [==================>...........] - ETA: 4s - loss: 1.8580 - accuracy: 0.1017
on_train_batch_begin: 1609169419.430007s

32 step training time: 0.229303s

on_train_batch_end: 1609169419.635193s

33792/50000 [===================>..........] - ETA: 3s - loss: 1.8503 - accuracy: 0.1017
on_train_batch_begin: 1609169419.635568s

33 step training time: 0.205560s

on_train_batch_end: 1609169419.886365s

34816/50000 [===================>..........] - ETA: 3s - loss: 1.8439 - accuracy: 0.1017
on_train_batch_begin: 1609169419.886737s

34 step training time: 0.251169s

on_train_batch_end: 1609169420.113943s

35840/50000 [====================>.........] - ETA: 3s - loss: 1.8352 - accuracy: 0.1017
on_train_batch_begin: 1609169420.114314s

35 step training time: 0.227577s

on_train_batch_end: 1609169420.360768s

36864/50000 [=====================>........] - ETA: 3s - loss: 1.8305 - accuracy: 0.1018
on_train_batch_begin: 1609169420.361140s

36 step training time: 0.246826s

on_train_batch_end: 1609169420.594590s

37888/50000 [=====================>........] - ETA: 2s - loss: 1.8243 - accuracy: 0.1018
on_train_batch_begin: 1609169420.594964s

37 step training time: 0.233824s

on_train_batch_end: 1609169420.847795s

38912/50000 [======================>.......] - ETA: 2s - loss: 1.8215 - accuracy: 0.1018
on_train_batch_begin: 1609169420.848170s

38 step training time: 0.253206s

on_train_batch_end: 1609169421.075760s

39936/50000 [======================>.......] - ETA: 2s - loss: 1.8153 - accuracy: 0.1018
on_train_batch_begin: 1609169421.076135s

39 step training time: 0.227965s

on_train_batch_end: 1609169421.327989s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.8085 - accuracy: 0.1018
on_train_batch_begin: 1609169421.328358s

40 step training time: 0.252223s

on_train_batch_end: 1609169421.578698s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.8042 - accuracy: 0.1018
on_train_batch_begin: 1609169421.579073s

41 step training time: 0.250715s

on_train_batch_end: 1609169421.832579s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.7998 - accuracy: 0.1018
on_train_batch_begin: 1609169421.832947s

42 step training time: 0.253874s

on_train_batch_end: 1609169422.081260s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.7947 - accuracy: 0.1018
on_train_batch_begin: 1609169422.081720s

43 step training time: 0.248773s

on_train_batch_end: 1609169422.338444s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.7905 - accuracy: 0.1018
on_train_batch_begin: 1609169422.338832s

44 step training time: 0.257113s

on_train_batch_end: 1609169422.566912s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.7862 - accuracy: 0.1018
on_train_batch_begin: 1609169422.567304s

45 step training time: 0.228472s

on_train_batch_end: 1609169422.816215s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7798 - accuracy: 0.1018
on_train_batch_begin: 1609169422.816611s

46 step training time: 0.249307s

on_train_batch_end: 1609169423.047945s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7754 - accuracy: 0.1018
on_train_batch_begin: 1609169423.048333s

47 step training time: 0.231722s

on_train_batch_end: 1609169423.299124s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7714 - accuracy: 0.1018
on_train_batch_begin: 1609169423.299509s

48 step training time: 0.251175s

on_train_batch_end: 1609169423.522694s

on_test_batch_begin: 1609169423.558212s

49 step training time: 0.258703s

on_epoch_end: 1609169424.060232s

Validation time: 0.502005s

Real time: 1609169424.060232s

Epoch time: 12.345690965652466s

50000/50000 [==============================] - 12s 247us/sample - loss: 1.7672 - accuracy: 0.1018 - val_loss: 7.2704 - val_accuracy: 0.0999

on_epoch_begin: 1609169424.060478s

Real time: 1609169424.0604868
Epoch 4/5

on_train_batch_begin: 1609169424.067928s

on_train_batch_end: 1609169424.315126s

 1024/50000 [..............................] - ETA: 12s - loss: 1.3783 - accuracy: 0.1019
on_train_batch_begin: 1609169424.315500s

1 step training time: 0.247572s

on_train_batch_end: 1609169424.566054s

 2048/50000 [>.............................] - ETA: 11s - loss: 1.2807 - accuracy: 0.1017
on_train_batch_begin: 1609169424.566426s

2 step training time: 0.250926s

on_train_batch_end: 1609169424.816730s

 3072/50000 [>.............................] - ETA: 11s - loss: 1.2903 - accuracy: 0.1020
on_train_batch_begin: 1609169424.817100s

3 step training time: 0.250674s

on_train_batch_end: 1609169425.046978s

 4096/50000 [=>............................] - ETA: 11s - loss: 1.3024 - accuracy: 0.1020
on_train_batch_begin: 1609169425.047352s

4 step training time: 0.230252s

on_train_batch_end: 1609169425.293555s

 5120/50000 [==>...........................] - ETA: 10s - loss: 1.2887 - accuracy: 0.1017
on_train_batch_begin: 1609169425.293957s

5 step training time: 0.246606s

on_train_batch_end: 1609169425.528328s

 6144/50000 [==>...........................] - ETA: 10s - loss: 1.2648 - accuracy: 0.1017
on_train_batch_begin: 1609169425.528698s

6 step training time: 0.234741s

on_train_batch_end: 1609169425.778616s

 7168/50000 [===>..........................] - ETA: 10s - loss: 1.2985 - accuracy: 0.1017
on_train_batch_begin: 1609169425.778985s

7 step training time: 0.250287s

on_train_batch_end: 1609169426.007443s

 8192/50000 [===>..........................] - ETA: 9s - loss: 1.3036 - accuracy: 0.1018 
on_train_batch_begin: 1609169426.007817s

8 step training time: 0.228832s

on_train_batch_end: 1609169426.257073s

 9216/50000 [====>.........................] - ETA: 9s - loss: 1.3175 - accuracy: 0.1019
on_train_batch_begin: 1609169426.257442s

9 step training time: 0.249624s

on_train_batch_end: 1609169426.487494s

10240/50000 [=====>........................] - ETA: 9s - loss: 1.3164 - accuracy: 0.1019
on_train_batch_begin: 1609169426.487867s

10 step training time: 0.230426s

on_train_batch_end: 1609169426.738605s

11264/50000 [=====>........................] - ETA: 9s - loss: 1.3185 - accuracy: 0.1019
on_train_batch_begin: 1609169426.738980s

11 step training time: 0.251113s

on_train_batch_end: 1609169426.974739s

12288/50000 [======>.......................] - ETA: 8s - loss: 1.3196 - accuracy: 0.1020
on_train_batch_begin: 1609169426.975111s

12 step training time: 0.236131s

on_train_batch_end: 1609169427.225767s

13312/50000 [======>.......................] - ETA: 8s - loss: 1.3138 - accuracy: 0.1020
on_train_batch_begin: 1609169427.226137s

13 step training time: 0.251026s

on_train_batch_end: 1609169427.477598s

14336/50000 [=======>......................] - ETA: 8s - loss: 1.3071 - accuracy: 0.1020
on_train_batch_begin: 1609169427.477994s

14 step training time: 0.251857s

on_train_batch_end: 1609169427.730994s

15360/50000 [========>.....................] - ETA: 8s - loss: 1.3038 - accuracy: 0.1020
on_train_batch_begin: 1609169427.731367s

15 step training time: 0.253373s

on_train_batch_end: 1609169427.958434s

16384/50000 [========>.....................] - ETA: 7s - loss: 1.2968 - accuracy: 0.1020
on_train_batch_begin: 1609169427.958817s

16 step training time: 0.227450s

on_train_batch_end: 1609169428.211457s

17408/50000 [=========>....................] - ETA: 7s - loss: 1.2978 - accuracy: 0.1020
on_train_batch_begin: 1609169428.211830s

17 step training time: 0.253013s

on_train_batch_end: 1609169428.447758s

18432/50000 [==========>...................] - ETA: 7s - loss: 1.2966 - accuracy: 0.1020
on_train_batch_begin: 1609169428.448131s

18 step training time: 0.236300s

on_train_batch_end: 1609169428.698915s

19456/50000 [==========>...................] - ETA: 7s - loss: 1.2953 - accuracy: 0.1021
on_train_batch_begin: 1609169428.699291s

19 step training time: 0.251161s

on_train_batch_end: 1609169428.931771s

20480/50000 [===========>..................] - ETA: 7s - loss: 1.2920 - accuracy: 0.1021
on_train_batch_begin: 1609169428.932143s

20 step training time: 0.232851s

on_train_batch_end: 1609169429.180470s

21504/50000 [===========>..................] - ETA: 6s - loss: 1.2870 - accuracy: 0.1021
on_train_batch_begin: 1609169429.180843s

21 step training time: 0.248701s

on_train_batch_end: 1609169429.414879s

22528/50000 [============>.................] - ETA: 6s - loss: 1.2879 - accuracy: 0.1021
on_train_batch_begin: 1609169429.415248s

22 step training time: 0.234405s

on_train_batch_end: 1609169429.668089s

23552/50000 [=============>................] - ETA: 6s - loss: 1.2897 - accuracy: 0.1021
on_train_batch_begin: 1609169429.668480s

23 step training time: 0.253232s

on_train_batch_end: 1609169429.917003s

24576/50000 [=============>................] - ETA: 6s - loss: 1.2834 - accuracy: 0.1022
on_train_batch_begin: 1609169429.917370s

24 step training time: 0.248890s

on_train_batch_end: 1609169430.171670s

25600/50000 [==============>...............] - ETA: 5s - loss: 1.2782 - accuracy: 0.1022
on_train_batch_begin: 1609169430.172039s

25 step training time: 0.254669s

on_train_batch_end: 1609169430.405662s

26624/50000 [==============>...............] - ETA: 5s - loss: 1.2710 - accuracy: 0.1022
on_train_batch_begin: 1609169430.406039s

26 step training time: 0.234001s

on_train_batch_end: 1609169430.657758s

27648/50000 [===============>..............] - ETA: 5s - loss: 1.2709 - accuracy: 0.1022
on_train_batch_begin: 1609169430.658133s

27 step training time: 0.252093s

on_train_batch_end: 1609169430.907039s

28672/50000 [================>.............] - ETA: 5s - loss: 1.2724 - accuracy: 0.1022
on_train_batch_begin: 1609169430.907413s

28 step training time: 0.249281s

on_train_batch_end: 1609169431.161161s

29696/50000 [================>.............] - ETA: 4s - loss: 1.2723 - accuracy: 0.1023
on_train_batch_begin: 1609169431.161542s

29 step training time: 0.254128s

on_train_batch_end: 1609169431.396672s

30720/50000 [=================>............] - ETA: 4s - loss: 1.2659 - accuracy: 0.1023
on_train_batch_begin: 1609169431.397042s

30 step training time: 0.235500s

on_train_batch_end: 1609169431.648806s

31744/50000 [==================>...........] - ETA: 4s - loss: 1.2623 - accuracy: 0.1023
on_train_batch_begin: 1609169431.649186s

31 step training time: 0.252144s

on_train_batch_end: 1609169431.883020s

32768/50000 [==================>...........] - ETA: 4s - loss: 1.2614 - accuracy: 0.1023
on_train_batch_begin: 1609169431.883398s

32 step training time: 0.234212s

on_train_batch_end: 1609169432.134776s

33792/50000 [===================>..........] - ETA: 3s - loss: 1.2592 - accuracy: 0.1023
on_train_batch_begin: 1609169432.135146s

33 step training time: 0.251748s

on_train_batch_end: 1609169432.365434s

34816/50000 [===================>..........] - ETA: 3s - loss: 1.2563 - accuracy: 0.1023
on_train_batch_begin: 1609169432.365838s

34 step training time: 0.230692s

on_train_batch_end: 1609169432.616282s

35840/50000 [====================>.........] - ETA: 3s - loss: 1.2519 - accuracy: 0.1023
on_train_batch_begin: 1609169432.616659s

35 step training time: 0.250821s

on_train_batch_end: 1609169432.846009s

36864/50000 [=====================>........] - ETA: 3s - loss: 1.2479 - accuracy: 0.1024
on_train_batch_begin: 1609169432.846383s

36 step training time: 0.229724s

on_train_batch_end: 1609169433.098549s

37888/50000 [=====================>........] - ETA: 2s - loss: 1.2462 - accuracy: 0.1024
on_train_batch_begin: 1609169433.098922s

37 step training time: 0.252539s

on_train_batch_end: 1609169433.332017s

38912/50000 [======================>.......] - ETA: 2s - loss: 1.2412 - accuracy: 0.1023
on_train_batch_begin: 1609169433.332399s

38 step training time: 0.233477s

on_train_batch_end: 1609169433.585988s

39936/50000 [======================>.......] - ETA: 2s - loss: 1.2382 - accuracy: 0.1024
on_train_batch_begin: 1609169433.586363s

39 step training time: 0.253964s

on_train_batch_end: 1609169433.814708s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.2338 - accuracy: 0.1024
on_train_batch_begin: 1609169433.815103s

40 step training time: 0.228740s

on_train_batch_end: 1609169434.063614s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.2296 - accuracy: 0.1024
on_train_batch_begin: 1609169434.063989s

41 step training time: 0.248885s

on_train_batch_end: 1609169434.297309s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.2288 - accuracy: 0.1024
on_train_batch_begin: 1609169434.297703s

42 step training time: 0.233714s

on_train_batch_end: 1609169434.545779s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.2254 - accuracy: 0.1024
on_train_batch_begin: 1609169434.546151s

43 step training time: 0.248448s

on_train_batch_end: 1609169434.776511s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.2250 - accuracy: 0.1024
on_train_batch_begin: 1609169434.776883s

44 step training time: 0.230732s

on_train_batch_end: 1609169435.028748s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.2222 - accuracy: 0.1024
on_train_batch_begin: 1609169435.029128s

45 step training time: 0.252245s

on_train_batch_end: 1609169435.262251s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.2192 - accuracy: 0.1024
on_train_batch_begin: 1609169435.262622s

46 step training time: 0.233494s

on_train_batch_end: 1609169435.512439s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.2147 - accuracy: 0.1024
on_train_batch_begin: 1609169435.512821s

47 step training time: 0.250199s

on_train_batch_end: 1609169435.743113s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2135 - accuracy: 0.1024
on_train_batch_begin: 1609169435.743492s

48 step training time: 0.230671s

on_train_batch_end: 1609169435.982023s

on_test_batch_begin: 1609169436.021398s

49 step training time: 0.277906s

on_epoch_end: 1609169436.528832s

Validation time: 0.507420s

Real time: 1609169436.528832s

Epoch time: 12.46836805343628s

50000/50000 [==============================] - 12s 249us/sample - loss: 1.2140 - accuracy: 0.1024 - val_loss: 7.4860 - val_accuracy: 0.0999

on_epoch_begin: 1609169436.529093s

Real time: 1609169436.5291028
Epoch 5/5

on_train_batch_begin: 1609169436.536733s

on_train_batch_end: 1609169436.787713s

 1024/50000 [..............................] - ETA: 12s - loss: 1.0812 - accuracy: 0.1016
on_train_batch_begin: 1609169436.788094s

1 step training time: 0.251361s

on_train_batch_end: 1609169437.019157s

 2048/50000 [>.............................] - ETA: 11s - loss: 1.0446 - accuracy: 0.1028
on_train_batch_begin: 1609169437.019542s

2 step training time: 0.231448s

on_train_batch_end: 1609169437.270711s

 3072/50000 [>.............................] - ETA: 11s - loss: 0.9962 - accuracy: 0.1029
on_train_batch_begin: 1609169437.271091s

3 step training time: 0.251549s

on_train_batch_end: 1609169437.506557s

 4096/50000 [=>............................] - ETA: 10s - loss: 0.9781 - accuracy: 0.1031
on_train_batch_begin: 1609169437.506935s

4 step training time: 0.235844s

on_train_batch_end: 1609169437.756973s

 5120/50000 [==>...........................] - ETA: 10s - loss: 0.9629 - accuracy: 0.1028
on_train_batch_begin: 1609169437.757340s

5 step training time: 0.250406s

on_train_batch_end: 1609169437.987132s

 6144/50000 [==>...........................] - ETA: 10s - loss: 0.9470 - accuracy: 0.1029
on_train_batch_begin: 1609169437.987505s

6 step training time: 0.230164s

on_train_batch_end: 1609169438.241738s

 7168/50000 [===>..........................] - ETA: 10s - loss: 0.9382 - accuracy: 0.1027
on_train_batch_begin: 1609169438.242115s

7 step training time: 0.254610s

on_train_batch_end: 1609169438.470446s

 8192/50000 [===>..........................] - ETA: 9s - loss: 0.9345 - accuracy: 0.1028 
on_train_batch_begin: 1609169438.470815s

8 step training time: 0.228700s

on_train_batch_end: 1609169438.721146s

 9216/50000 [====>.........................] - ETA: 9s - loss: 0.9227 - accuracy: 0.1028
on_train_batch_begin: 1609169438.721516s

9 step training time: 0.250701s

on_train_batch_end: 1609169438.952052s

10240/50000 [=====>........................] - ETA: 9s - loss: 0.9322 - accuracy: 0.1027
on_train_batch_begin: 1609169438.952424s

10 step training time: 0.230908s

on_train_batch_end: 1609169439.204865s

11264/50000 [=====>........................] - ETA: 9s - loss: 0.9205 - accuracy: 0.1028
on_train_batch_begin: 1609169439.205242s

11 step training time: 0.252818s

on_train_batch_end: 1609169439.432337s

12288/50000 [======>.......................] - ETA: 8s - loss: 0.9035 - accuracy: 0.1029
on_train_batch_begin: 1609169439.432706s

12 step training time: 0.227464s

on_train_batch_end: 1609169439.684166s

13312/50000 [======>.......................] - ETA: 8s - loss: 0.9013 - accuracy: 0.1029
on_train_batch_begin: 1609169439.684536s

13 step training time: 0.251830s

on_train_batch_end: 1609169439.913662s

14336/50000 [=======>......................] - ETA: 8s - loss: 0.8967 - accuracy: 0.1029
on_train_batch_begin: 1609169439.914040s

14 step training time: 0.229504s

on_train_batch_end: 1609169440.162255s

15360/50000 [========>.....................] - ETA: 8s - loss: 0.8941 - accuracy: 0.1028
on_train_batch_begin: 1609169440.162636s

15 step training time: 0.248595s

on_train_batch_end: 1609169440.397180s

16384/50000 [========>.....................] - ETA: 7s - loss: 0.8923 - accuracy: 0.1028
on_train_batch_begin: 1609169440.397566s

16 step training time: 0.234930s

on_train_batch_end: 1609169440.649912s

17408/50000 [=========>....................] - ETA: 7s - loss: 0.8907 - accuracy: 0.1029
on_train_batch_begin: 1609169440.650283s

17 step training time: 0.252717s

on_train_batch_end: 1609169440.900267s

18432/50000 [==========>...................] - ETA: 7s - loss: 0.8918 - accuracy: 0.1029
on_train_batch_begin: 1609169440.900640s

18 step training time: 0.250357s

on_train_batch_end: 1609169441.154532s

19456/50000 [==========>...................] - ETA: 7s - loss: 0.8937 - accuracy: 0.1028
on_train_batch_begin: 1609169441.154902s

19 step training time: 0.254262s

on_train_batch_end: 1609169441.405619s

20480/50000 [===========>..................] - ETA: 7s - loss: 0.8908 - accuracy: 0.1028
on_train_batch_begin: 1609169441.406017s

20 step training time: 0.251115s

on_train_batch_end: 1609169441.662269s

21504/50000 [===========>..................] - ETA: 6s - loss: 0.8946 - accuracy: 0.1028
on_train_batch_begin: 1609169441.662640s

21 step training time: 0.256624s

on_train_batch_end: 1609169441.914264s

22528/50000 [============>.................] - ETA: 6s - loss: 0.8921 - accuracy: 0.1028
on_train_batch_begin: 1609169441.914634s

22 step training time: 0.251994s

on_train_batch_end: 1609169442.167910s

23552/50000 [=============>................] - ETA: 6s - loss: 0.9001 - accuracy: 0.1028
on_train_batch_begin: 1609169442.168280s

23 step training time: 0.253646s

on_train_batch_end: 1609169442.417392s

24576/50000 [=============>................] - ETA: 6s - loss: 0.9043 - accuracy: 0.1028
on_train_batch_begin: 1609169442.417797s

24 step training time: 0.249517s

on_train_batch_end: 1609169442.672982s

25600/50000 [==============>...............] - ETA: 5s - loss: 0.9066 - accuracy: 0.1028
on_train_batch_begin: 1609169442.673356s

25 step training time: 0.255558s

on_train_batch_end: 1609169442.925072s

26624/50000 [==============>...............] - ETA: 5s - loss: 0.9144 - accuracy: 0.1029
on_train_batch_begin: 1609169442.925447s

26 step training time: 0.252091s

on_train_batch_end: 1609169443.178887s

27648/50000 [===============>..............] - ETA: 5s - loss: 0.9142 - accuracy: 0.1029
on_train_batch_begin: 1609169443.179257s

27 step training time: 0.253811s

on_train_batch_end: 1609169443.431000s

28672/50000 [================>.............] - ETA: 5s - loss: 0.9166 - accuracy: 0.1029
on_train_batch_begin: 1609169443.431382s

28 step training time: 0.252125s

on_train_batch_end: 1609169443.685364s

29696/50000 [================>.............] - ETA: 4s - loss: 0.9180 - accuracy: 0.1029
on_train_batch_begin: 1609169443.685774s

29 step training time: 0.254392s

on_train_batch_end: 1609169443.938462s

30720/50000 [=================>............] - ETA: 4s - loss: 0.9229 - accuracy: 0.1029
on_train_batch_begin: 1609169443.938834s

30 step training time: 0.253060s

on_train_batch_end: 1609169444.193556s

31744/50000 [==================>...........] - ETA: 4s - loss: 0.9173 - accuracy: 0.1029
on_train_batch_begin: 1609169444.193980s

31 step training time: 0.255146s

on_train_batch_end: 1609169444.420671s

32768/50000 [==================>...........] - ETA: 4s - loss: 0.9143 - accuracy: 0.1029
on_train_batch_begin: 1609169444.421053s

32 step training time: 0.227073s

on_train_batch_end: 1609169444.672194s

33792/50000 [===================>..........] - ETA: 3s - loss: 0.9116 - accuracy: 0.1029
on_train_batch_begin: 1609169444.672570s

33 step training time: 0.251518s

on_train_batch_end: 1609169444.900572s

34816/50000 [===================>..........] - ETA: 3s - loss: 0.9108 - accuracy: 0.1029
on_train_batch_begin: 1609169444.900945s

34 step training time: 0.228375s

on_train_batch_end: 1609169445.151521s

35840/50000 [====================>.........] - ETA: 3s - loss: 0.9119 - accuracy: 0.1029
on_train_batch_begin: 1609169445.151894s

35 step training time: 0.250949s

on_train_batch_end: 1609169445.386121s

36864/50000 [=====================>........] - ETA: 3s - loss: 0.9119 - accuracy: 0.1029
on_train_batch_begin: 1609169445.386522s

36 step training time: 0.234627s

on_train_batch_end: 1609169445.638466s

37888/50000 [=====================>........] - ETA: 2s - loss: 0.9110 - accuracy: 0.1029
on_train_batch_begin: 1609169445.638838s

37 step training time: 0.252316s

on_train_batch_end: 1609169445.871629s

38912/50000 [======================>.......] - ETA: 2s - loss: 0.9087 - accuracy: 0.1029
on_train_batch_begin: 1609169445.872007s

38 step training time: 0.233169s

on_train_batch_end: 1609169446.124163s

39936/50000 [======================>.......] - ETA: 2s - loss: 0.9097 - accuracy: 0.1028
on_train_batch_begin: 1609169446.124540s

39 step training time: 0.252533s

on_train_batch_end: 1609169446.353122s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.9122 - accuracy: 0.1028
on_train_batch_begin: 1609169446.353501s

40 step training time: 0.228961s

on_train_batch_end: 1609169446.603185s

41984/50000 [========================>.....] - ETA: 1s - loss: 0.9093 - accuracy: 0.1028
on_train_batch_begin: 1609169446.603566s

41 step training time: 0.250065s

on_train_batch_end: 1609169446.830627s

43008/50000 [========================>.....] - ETA: 1s - loss: 0.9105 - accuracy: 0.1029
on_train_batch_begin: 1609169446.831001s

42 step training time: 0.227435s

on_train_batch_end: 1609169447.082114s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.9105 - accuracy: 0.1029
on_train_batch_begin: 1609169447.082491s

43 step training time: 0.251491s

on_train_batch_end: 1609169447.312249s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.9082 - accuracy: 0.1029
on_train_batch_begin: 1609169447.312621s

44 step training time: 0.230129s

on_train_batch_end: 1609169447.562954s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.9062 - accuracy: 0.1029
on_train_batch_begin: 1609169447.563334s

45 step training time: 0.250714s

on_train_batch_end: 1609169447.796282s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.9058 - accuracy: 0.1029
on_train_batch_begin: 1609169447.796653s

46 step training time: 0.233319s

on_train_batch_end: 1609169448.048641s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9010 - accuracy: 0.1029
on_train_batch_begin: 1609169448.049018s

47 step training time: 0.252365s

on_train_batch_end: 1609169448.278289s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9006 - accuracy: 0.1029
on_train_batch_begin: 1609169448.278683s

48 step training time: 0.229666s

on_train_batch_end: 1609169448.516004s

on_test_batch_begin: 1609169448.548677s

49 step training time: 0.269994s

on_epoch_end: 1609169449.057545s

Validation time: 0.508853s

Real time: 1609169449.057545s

Epoch time: 12.528462886810303s

50000/50000 [==============================] - 13s 251us/sample - loss: 0.9018 - accuracy: 0.1029 - val_loss: 7.5181 - val_accuracy: 0.0999
Tempo do fit: 223.32858324050903