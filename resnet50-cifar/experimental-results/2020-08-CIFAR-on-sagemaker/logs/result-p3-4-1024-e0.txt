wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:53
   188416/170498071 [..............................] - ETA: 1:05
   614400/170498071 [..............................] - ETA: 33s 
  2318336/170498071 [..............................] - ETA: 12s
  5545984/170498071 [..............................] - ETA: 6s 
  8749056/170498071 [>.............................] - ETA: 5s
 11902976/170498071 [=>............................] - ETA: 4s
 15114240/170498071 [=>............................] - ETA: 3s
 18374656/170498071 [==>...........................] - ETA: 3s
 21618688/170498071 [==>...........................] - ETA: 3s
 24829952/170498071 [===>..........................] - ETA: 3s
 28082176/170498071 [===>..........................] - ETA: 2s
 31268864/170498071 [====>.........................] - ETA: 2s
 34496512/170498071 [=====>........................] - ETA: 2s
 37675008/170498071 [=====>........................] - ETA: 2s
 40886272/170498071 [======>.......................] - ETA: 2s
 44064768/170498071 [======>.......................] - ETA: 2s
 47243264/170498071 [=======>......................] - ETA: 2s
 50438144/170498071 [=======>......................] - ETA: 2s
 53649408/170498071 [========>.....................] - ETA: 2s
 56877056/170498071 [=========>....................] - ETA: 2s
 60104704/170498071 [=========>....................] - ETA: 1s
 63250432/170498071 [==========>...................] - ETA: 1s
 66494464/170498071 [==========>...................] - ETA: 1s
 69705728/170498071 [===========>..................] - ETA: 1s
 72908800/170498071 [===========>..................] - ETA: 1s
 76144640/170498071 [============>.................] - ETA: 1s
 79405056/170498071 [============>.................] - ETA: 1s
 82681856/170498071 [=============>................] - ETA: 1s
 85893120/170498071 [==============>...............] - ETA: 1s
 89153536/170498071 [==============>...............] - ETA: 1s
 92348416/170498071 [===============>..............] - ETA: 1s
 95592448/170498071 [===============>..............] - ETA: 1s
 98836480/170498071 [================>.............] - ETA: 1s
102031360/170498071 [================>.............] - ETA: 1s
105259008/170498071 [=================>............] - ETA: 1s
108445696/170498071 [==================>...........] - ETA: 1s
111648768/170498071 [==================>...........] - ETA: 0s
114827264/170498071 [===================>..........] - ETA: 0s
117776384/170498071 [===================>..........] - ETA: 0s
120512512/170498071 [====================>.........] - ETA: 0s
123248640/170498071 [====================>.........] - ETA: 0s
126001152/170498071 [=====================>........] - ETA: 0s
128655360/170498071 [=====================>........] - ETA: 0s
131407872/170498071 [======================>.......] - ETA: 0s
134111232/170498071 [======================>.......] - ETA: 0s
136847360/170498071 [=======================>......] - ETA: 0s
139583488/170498071 [=======================>......] - ETA: 0s
142303232/170498071 [========================>.....] - ETA: 0s
144990208/170498071 [========================>.....] - ETA: 0s
147709952/170498071 [========================>.....] - ETA: 0s
150446080/170498071 [=========================>....] - ETA: 0s
153182208/170498071 [=========================>....] - ETA: 0s
155918336/170498071 [==========================>...] - ETA: 0s
158654464/170498071 [==========================>...] - ETA: 0s
161390592/170498071 [===========================>..] - ETA: 0s
164110336/170498071 [===========================>..] - ETA: 0s
166879232/170498071 [============================>.] - ETA: 0s
169844736/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 4s
 5767168/94765736 [>.............................] - ETA: 0s
11501568/94765736 [==>...........................] - ETA: 0s
12926976/94765736 [===>..........................] - ETA: 0s
15908864/94765736 [====>.........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
23887872/94765736 [======>.......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 1s
29409280/94765736 [========>.....................] - ETA: 1s
31055872/94765736 [========>.....................] - ETA: 1s
36110336/94765736 [==========>...................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
41230336/94765736 [============>.................] - ETA: 1s
43597824/94765736 [============>.................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 1s
49463296/94765736 [==============>...............] - ETA: 1s
49504256/94765736 [==============>...............] - ETA: 1s
50683904/94765736 [===============>..............] - ETA: 1s
54231040/94765736 [================>.............] - ETA: 1s
56352768/94765736 [================>.............] - ETA: 1s
57712640/94765736 [=================>............] - ETA: 1s
61792256/94765736 [==================>...........] - ETA: 1s
62439424/94765736 [==================>...........] - ETA: 1s
65986560/94765736 [===================>..........] - ETA: 0s
67534848/94765736 [====================>.........] - ETA: 0s
69533696/94765736 [=====================>........] - ETA: 0s
70713344/94765736 [=====================>........] - ETA: 0s
74260480/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
77799424/94765736 [=======================>......] - ETA: 0s
78987264/94765736 [========================>.....] - ETA: 0s
82092032/94765736 [========================>.....] - ETA: 0s
83714048/94765736 [=========================>....] - ETA: 0s
88375296/94765736 [==========================>...] - ETA: 0s
91086848/94765736 [===========================>..] - ETA: 0s
93102080/94765736 [============================>.] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 3s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 21.443814516067505
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1599688387.764636s

Real time: 1599688387.7646554
Epoch 1/5

on_train_batch_begin: 1599688388.690970s

on_train_batch_end: 1599688447.439338s

 1024/50000 [..............................] - ETA: 47:34 - loss: 17.0409 - accuracy: 0.0000e+00
on_train_batch_begin: 1599688447.440114s

1 step training time: 58.749143s

on_train_batch_end: 1599688447.508097s

 2048/50000 [>.............................] - ETA: 23:18 - loss: 14.4254 - accuracy: 1.6785e-04
on_train_batch_begin: 1599688447.508511s

2 step training time: 0.068397s

on_train_batch_end: 1599688447.574644s

 3072/50000 [>.............................] - ETA: 15:13 - loss: 12.5647 - accuracy: 8.5068e-04
on_train_batch_begin: 1599688447.575037s

3 step training time: 0.066527s

on_train_batch_end: 1599688447.639899s

 4096/50000 [=>............................] - ETA: 11:11 - loss: 11.5392 - accuracy: 0.0020    
on_train_batch_begin: 1599688447.640290s

4 step training time: 0.065253s

on_train_batch_end: 1599688447.707964s

 5120/50000 [==>...........................] - ETA: 8:45 - loss: 10.9098 - accuracy: 0.0041 
on_train_batch_begin: 1599688447.708360s

5 step training time: 0.068069s

on_train_batch_end: 1599688447.772216s

 6144/50000 [==>...........................] - ETA: 7:08 - loss: 10.4652 - accuracy: 0.0067
on_train_batch_begin: 1599688447.772611s

6 step training time: 0.064251s

on_train_batch_end: 1599688447.840247s

 7168/50000 [===>..........................] - ETA: 5:58 - loss: 10.1491 - accuracy: 0.0112
on_train_batch_begin: 1599688447.840641s

7 step training time: 0.068030s

on_train_batch_end: 1599688447.909473s

 8192/50000 [===>..........................] - ETA: 5:06 - loss: 9.8904 - accuracy: 0.0151 
on_train_batch_begin: 1599688447.909890s

8 step training time: 0.069249s

on_train_batch_end: 1599688447.973025s

 9216/50000 [====>.........................] - ETA: 4:26 - loss: 9.6903 - accuracy: 0.0199
on_train_batch_begin: 1599688447.973400s

9 step training time: 0.063510s

on_train_batch_end: 1599688448.037010s

10240/50000 [=====>........................] - ETA: 3:54 - loss: 9.5202 - accuracy: 0.0256
on_train_batch_begin: 1599688448.037389s

10 step training time: 0.063989s

on_train_batch_end: 1599688448.101125s

11264/50000 [=====>........................] - ETA: 3:27 - loss: 9.3677 - accuracy: 0.0300
on_train_batch_begin: 1599688448.101497s

11 step training time: 0.064108s

on_train_batch_end: 1599688448.162841s

12288/50000 [======>.......................] - ETA: 3:05 - loss: 9.2483 - accuracy: 0.0340
on_train_batch_begin: 1599688448.163217s

12 step training time: 0.061720s

on_train_batch_end: 1599688448.226232s

13312/50000 [======>.......................] - ETA: 2:46 - loss: 9.1336 - accuracy: 0.0377
on_train_batch_begin: 1599688448.226618s

13 step training time: 0.063401s

on_train_batch_end: 1599688448.291150s

14336/50000 [=======>......................] - ETA: 2:30 - loss: 9.0374 - accuracy: 0.0406
on_train_batch_begin: 1599688448.291528s

14 step training time: 0.064910s

on_train_batch_end: 1599688448.355693s

15360/50000 [========>.....................] - ETA: 2:16 - loss: 8.9402 - accuracy: 0.0428
on_train_batch_begin: 1599688448.356076s

15 step training time: 0.064548s

on_train_batch_end: 1599688448.419084s

16384/50000 [========>.....................] - ETA: 2:04 - loss: 8.8585 - accuracy: 0.0446
on_train_batch_begin: 1599688448.419463s

16 step training time: 0.063387s

on_train_batch_end: 1599688448.482101s

17408/50000 [=========>....................] - ETA: 1:53 - loss: 8.7848 - accuracy: 0.0464
on_train_batch_begin: 1599688448.482479s

17 step training time: 0.063016s

on_train_batch_end: 1599688448.551948s

18432/50000 [==========>...................] - ETA: 1:44 - loss: 8.7082 - accuracy: 0.0480
on_train_batch_begin: 1599688448.552323s

18 step training time: 0.069844s

on_train_batch_end: 1599688448.616978s

19456/50000 [==========>...................] - ETA: 1:35 - loss: 8.6434 - accuracy: 0.0496
on_train_batch_begin: 1599688448.617352s

19 step training time: 0.065029s

on_train_batch_end: 1599688448.679563s

20480/50000 [===========>..................] - ETA: 1:27 - loss: 8.5844 - accuracy: 0.0523
on_train_batch_begin: 1599688448.679939s

20 step training time: 0.062587s

on_train_batch_end: 1599688448.744512s

21504/50000 [===========>..................] - ETA: 1:20 - loss: 8.5290 - accuracy: 0.0540
on_train_batch_begin: 1599688448.744888s

21 step training time: 0.064950s

on_train_batch_end: 1599688448.807088s

22528/50000 [============>.................] - ETA: 1:14 - loss: 8.4848 - accuracy: 0.0553
on_train_batch_begin: 1599688448.807464s

22 step training time: 0.062576s

on_train_batch_end: 1599688448.870414s

23552/50000 [=============>................] - ETA: 1:08 - loss: 8.4359 - accuracy: 0.0575
on_train_batch_begin: 1599688448.870790s

23 step training time: 0.063325s

on_train_batch_end: 1599688448.933927s

24576/50000 [=============>................] - ETA: 1:03 - loss: 8.3899 - accuracy: 0.0593
on_train_batch_begin: 1599688448.934305s

24 step training time: 0.063515s

on_train_batch_end: 1599688448.999438s

25600/50000 [==============>...............] - ETA: 58s - loss: 8.3467 - accuracy: 0.0608 
on_train_batch_begin: 1599688448.999810s

25 step training time: 0.065505s

on_train_batch_end: 1599688449.061130s

26624/50000 [==============>...............] - ETA: 53s - loss: 8.3098 - accuracy: 0.0620
on_train_batch_begin: 1599688449.061506s

26 step training time: 0.061696s

on_train_batch_end: 1599688449.126709s

27648/50000 [===============>..............] - ETA: 49s - loss: 8.2670 - accuracy: 0.0633
on_train_batch_begin: 1599688449.127090s

27 step training time: 0.065584s

on_train_batch_end: 1599688449.190678s

28672/50000 [================>.............] - ETA: 45s - loss: 8.2316 - accuracy: 0.0644
on_train_batch_begin: 1599688449.191050s

28 step training time: 0.063961s

on_train_batch_end: 1599688449.252950s

29696/50000 [================>.............] - ETA: 42s - loss: 8.1957 - accuracy: 0.0658
on_train_batch_begin: 1599688449.253324s

29 step training time: 0.062273s

on_train_batch_end: 1599688449.317457s

30720/50000 [=================>............] - ETA: 38s - loss: 8.1685 - accuracy: 0.0670
on_train_batch_begin: 1599688449.317897s

30 step training time: 0.064573s

on_train_batch_end: 1599688449.380977s

31744/50000 [==================>...........] - ETA: 35s - loss: 8.1429 - accuracy: 0.0678
on_train_batch_begin: 1599688449.381366s

31 step training time: 0.063470s

on_train_batch_end: 1599688449.447121s

32768/50000 [==================>...........] - ETA: 32s - loss: 8.1119 - accuracy: 0.0686
on_train_batch_begin: 1599688449.447508s

32 step training time: 0.066142s

on_train_batch_end: 1599688449.508871s

33792/50000 [===================>..........] - ETA: 29s - loss: 8.0813 - accuracy: 0.0695
on_train_batch_begin: 1599688449.509260s

33 step training time: 0.061752s

on_train_batch_end: 1599688449.577809s

34816/50000 [===================>..........] - ETA: 26s - loss: 8.0602 - accuracy: 0.0702
on_train_batch_begin: 1599688449.578204s

34 step training time: 0.068944s

on_train_batch_end: 1599688449.641918s

35840/50000 [====================>.........] - ETA: 24s - loss: 8.0374 - accuracy: 0.0708
on_train_batch_begin: 1599688449.642305s

35 step training time: 0.064101s

on_train_batch_end: 1599688449.705776s

36864/50000 [=====================>........] - ETA: 22s - loss: 8.0171 - accuracy: 0.0713
on_train_batch_begin: 1599688449.706198s

36 step training time: 0.063893s

on_train_batch_end: 1599688449.772536s

37888/50000 [=====================>........] - ETA: 19s - loss: 7.9979 - accuracy: 0.0717
on_train_batch_begin: 1599688449.772930s

37 step training time: 0.066732s

on_train_batch_end: 1599688449.840235s

38912/50000 [======================>.......] - ETA: 17s - loss: 7.9738 - accuracy: 0.0723
on_train_batch_begin: 1599688449.840627s

38 step training time: 0.067697s

on_train_batch_end: 1599688449.904974s

39936/50000 [======================>.......] - ETA: 15s - loss: 7.9473 - accuracy: 0.0735
on_train_batch_begin: 1599688449.905367s

39 step training time: 0.064741s

on_train_batch_end: 1599688449.970059s

40960/50000 [=======================>......] - ETA: 13s - loss: 7.9249 - accuracy: 0.0739
on_train_batch_begin: 1599688449.970455s

40 step training time: 0.065087s

on_train_batch_end: 1599688450.035562s

41984/50000 [========================>.....] - ETA: 11s - loss: 7.9037 - accuracy: 0.0740
on_train_batch_begin: 1599688450.035959s

41 step training time: 0.065504s

on_train_batch_end: 1599688450.099726s

43008/50000 [========================>.....] - ETA: 10s - loss: 7.8823 - accuracy: 0.0745
on_train_batch_begin: 1599688450.100116s

42 step training time: 0.064157s

on_train_batch_end: 1599688450.163956s

44032/50000 [=========================>....] - ETA: 8s - loss: 7.8643 - accuracy: 0.0750 
on_train_batch_begin: 1599688450.164345s

43 step training time: 0.064229s

on_train_batch_end: 1599688450.228289s

45056/50000 [==========================>...] - ETA: 6s - loss: 7.8464 - accuracy: 0.0752
on_train_batch_begin: 1599688450.228677s

44 step training time: 0.064332s

on_train_batch_end: 1599688450.293487s

46080/50000 [==========================>...] - ETA: 5s - loss: 7.8244 - accuracy: 0.0754
on_train_batch_begin: 1599688450.293916s

45 step training time: 0.065239s

on_train_batch_end: 1599688450.362080s

47104/50000 [===========================>..] - ETA: 3s - loss: 7.8061 - accuracy: 0.0759
on_train_batch_begin: 1599688450.362469s

46 step training time: 0.068553s

on_train_batch_end: 1599688450.429456s

48128/50000 [===========================>..] - ETA: 2s - loss: 7.7863 - accuracy: 0.0762
on_train_batch_begin: 1599688450.429855s

47 step training time: 0.067387s

on_train_batch_end: 1599688450.498116s

49152/50000 [============================>.] - ETA: 1s - loss: 7.7672 - accuracy: 0.0767
on_train_batch_begin: 1599688450.498491s

48 step training time: 0.068635s

on_train_batch_end: 1599688451.519660s

on_test_batch_begin: 1599688451.801281s

49 step training time: 1.302790s

on_epoch_end: 1599688458.307787s

Validation time: 6.506488s

Real time: 1599688458.307787s

Epoch time: 70.54315638542175s

50000/50000 [==============================] - 71s 1ms/sample - loss: 7.7516 - accuracy: 0.0768 - val_loss: 7.4730 - val_accuracy: 0.0000e+00

on_epoch_begin: 1599688458.308062s

Real time: 1599688458.3080719
Epoch 2/5

on_train_batch_begin: 1599688458.313936s

on_train_batch_end: 1599688458.382922s

 1024/50000 [..............................] - ETA: 3s - loss: 6.8451 - accuracy: 0.0951
on_train_batch_begin: 1599688458.383314s

1 step training time: 0.069377s

on_train_batch_end: 1599688458.447603s

 2048/50000 [>.............................] - ETA: 3s - loss: 6.8597 - accuracy: 0.0948
on_train_batch_begin: 1599688458.447974s

2 step training time: 0.064660s

on_train_batch_end: 1599688458.512540s

 3072/50000 [>.............................] - ETA: 3s - loss: 6.8226 - accuracy: 0.0900
on_train_batch_begin: 1599688458.512916s

3 step training time: 0.064943s

on_train_batch_end: 1599688458.579088s

 4096/50000 [=>............................] - ETA: 3s - loss: 6.7899 - accuracy: 0.0869
on_train_batch_begin: 1599688458.579458s

4 step training time: 0.066541s

on_train_batch_end: 1599688458.647374s

 5120/50000 [==>...........................] - ETA: 2s - loss: 6.7420 - accuracy: 0.0866
on_train_batch_begin: 1599688458.647767s

5 step training time: 0.068310s

on_train_batch_end: 1599688458.713555s

 6144/50000 [==>...........................] - ETA: 2s - loss: 6.7350 - accuracy: 0.0842
on_train_batch_begin: 1599688458.713955s

6 step training time: 0.066188s

on_train_batch_end: 1599688458.776665s

 7168/50000 [===>..........................] - ETA: 2s - loss: 6.7178 - accuracy: 0.0808
on_train_batch_begin: 1599688458.777036s

7 step training time: 0.063081s

on_train_batch_end: 1599688458.845136s

 8192/50000 [===>..........................] - ETA: 2s - loss: 6.6891 - accuracy: 0.0786
on_train_batch_begin: 1599688458.845505s

8 step training time: 0.068470s

on_train_batch_end: 1599688458.908318s

 9216/50000 [====>.........................] - ETA: 2s - loss: 6.6649 - accuracy: 0.0764
on_train_batch_begin: 1599688458.908689s

9 step training time: 0.063183s

on_train_batch_end: 1599688458.971330s

10240/50000 [=====>........................] - ETA: 2s - loss: 6.6444 - accuracy: 0.0751
on_train_batch_begin: 1599688458.971704s

10 step training time: 0.063016s

on_train_batch_end: 1599688459.034986s

11264/50000 [=====>........................] - ETA: 2s - loss: 6.6107 - accuracy: 0.0738
on_train_batch_begin: 1599688459.035367s

11 step training time: 0.063663s

on_train_batch_end: 1599688459.101321s

12288/50000 [======>.......................] - ETA: 2s - loss: 6.5819 - accuracy: 0.0735
on_train_batch_begin: 1599688459.101696s

12 step training time: 0.066329s

on_train_batch_end: 1599688459.163902s

13312/50000 [======>.......................] - ETA: 2s - loss: 6.5683 - accuracy: 0.0729
on_train_batch_begin: 1599688459.164277s

13 step training time: 0.062581s

on_train_batch_end: 1599688459.227854s

14336/50000 [=======>......................] - ETA: 2s - loss: 6.5381 - accuracy: 0.0727
on_train_batch_begin: 1599688459.228228s

14 step training time: 0.063951s

on_train_batch_end: 1599688459.292241s

15360/50000 [========>.....................] - ETA: 2s - loss: 6.5224 - accuracy: 0.0722
on_train_batch_begin: 1599688459.292618s

15 step training time: 0.064391s

on_train_batch_end: 1599688459.355507s

16384/50000 [========>.....................] - ETA: 2s - loss: 6.4949 - accuracy: 0.0719
on_train_batch_begin: 1599688459.355916s

16 step training time: 0.063297s

on_train_batch_end: 1599688459.420028s

17408/50000 [=========>....................] - ETA: 2s - loss: 6.4764 - accuracy: 0.0711
on_train_batch_begin: 1599688459.420403s

17 step training time: 0.064488s

on_train_batch_end: 1599688459.483905s

18432/50000 [==========>...................] - ETA: 2s - loss: 6.4508 - accuracy: 0.0706
on_train_batch_begin: 1599688459.484278s

18 step training time: 0.063874s

on_train_batch_end: 1599688459.550381s

19456/50000 [==========>...................] - ETA: 1s - loss: 6.4280 - accuracy: 0.0705
on_train_batch_begin: 1599688459.550756s

19 step training time: 0.066478s

on_train_batch_end: 1599688459.613240s

20480/50000 [===========>..................] - ETA: 1s - loss: 6.4050 - accuracy: 0.0700
on_train_batch_begin: 1599688459.613611s

20 step training time: 0.062856s

on_train_batch_end: 1599688459.678070s

21504/50000 [===========>..................] - ETA: 1s - loss: 6.3897 - accuracy: 0.0697
on_train_batch_begin: 1599688459.678440s

21 step training time: 0.064829s

on_train_batch_end: 1599688459.740659s

22528/50000 [============>.................] - ETA: 1s - loss: 6.3652 - accuracy: 0.0692
on_train_batch_begin: 1599688459.741036s

22 step training time: 0.062595s

on_train_batch_end: 1599688459.806131s

23552/50000 [=============>................] - ETA: 1s - loss: 6.3399 - accuracy: 0.0688
on_train_batch_begin: 1599688459.806504s

23 step training time: 0.065468s

on_train_batch_end: 1599688459.871773s

24576/50000 [=============>................] - ETA: 1s - loss: 6.3146 - accuracy: 0.0684
on_train_batch_begin: 1599688459.872149s

24 step training time: 0.065645s

on_train_batch_end: 1599688459.934590s

25600/50000 [==============>...............] - ETA: 1s - loss: 6.2920 - accuracy: 0.0681
on_train_batch_begin: 1599688459.934976s

25 step training time: 0.062828s

on_train_batch_end: 1599688459.997846s

26624/50000 [==============>...............] - ETA: 1s - loss: 6.2680 - accuracy: 0.0676
on_train_batch_begin: 1599688459.998218s

26 step training time: 0.063242s

on_train_batch_end: 1599688460.060477s

27648/50000 [===============>..............] - ETA: 1s - loss: 6.2452 - accuracy: 0.0672
on_train_batch_begin: 1599688460.060857s

27 step training time: 0.062639s

on_train_batch_end: 1599688460.124694s

28672/50000 [================>.............] - ETA: 1s - loss: 6.2176 - accuracy: 0.0669
on_train_batch_begin: 1599688460.125069s

28 step training time: 0.064213s

on_train_batch_end: 1599688460.186360s

29696/50000 [================>.............] - ETA: 1s - loss: 6.1908 - accuracy: 0.0666
on_train_batch_begin: 1599688460.186738s

29 step training time: 0.061669s

on_train_batch_end: 1599688460.248938s

30720/50000 [=================>............] - ETA: 1s - loss: 6.1650 - accuracy: 0.0663
on_train_batch_begin: 1599688460.249316s

30 step training time: 0.062578s

on_train_batch_end: 1599688460.312352s

31744/50000 [==================>...........] - ETA: 1s - loss: 6.1341 - accuracy: 0.0661
on_train_batch_begin: 1599688460.312730s

31 step training time: 0.063413s

on_train_batch_end: 1599688460.372911s

32768/50000 [==================>...........] - ETA: 1s - loss: 6.1095 - accuracy: 0.0659
on_train_batch_begin: 1599688460.373293s

32 step training time: 0.060563s

on_train_batch_end: 1599688460.435584s

33792/50000 [===================>..........] - ETA: 1s - loss: 6.0787 - accuracy: 0.0658
on_train_batch_begin: 1599688460.435955s

33 step training time: 0.062662s

on_train_batch_end: 1599688460.500080s

34816/50000 [===================>..........] - ETA: 0s - loss: 6.0504 - accuracy: 0.0656
on_train_batch_begin: 1599688460.500454s

34 step training time: 0.064500s

on_train_batch_end: 1599688460.563920s

35840/50000 [====================>.........] - ETA: 0s - loss: 6.0246 - accuracy: 0.0655
on_train_batch_begin: 1599688460.564291s

35 step training time: 0.063837s

on_train_batch_end: 1599688460.628502s

36864/50000 [=====================>........] - ETA: 0s - loss: 5.9922 - accuracy: 0.0656
on_train_batch_begin: 1599688460.628872s

36 step training time: 0.064580s

on_train_batch_end: 1599688460.695123s

37888/50000 [=====================>........] - ETA: 0s - loss: 5.9574 - accuracy: 0.0657
on_train_batch_begin: 1599688460.695504s

37 step training time: 0.066632s

on_train_batch_end: 1599688460.757410s

38912/50000 [======================>.......] - ETA: 0s - loss: 5.9246 - accuracy: 0.0658
on_train_batch_begin: 1599688460.757805s

38 step training time: 0.062301s

on_train_batch_end: 1599688460.820821s

39936/50000 [======================>.......] - ETA: 0s - loss: 5.8891 - accuracy: 0.0660
on_train_batch_begin: 1599688460.821198s

39 step training time: 0.063393s

on_train_batch_end: 1599688460.885832s

40960/50000 [=======================>......] - ETA: 0s - loss: 5.8533 - accuracy: 0.0663
on_train_batch_begin: 1599688460.886209s

40 step training time: 0.065012s

on_train_batch_end: 1599688460.949530s

41984/50000 [========================>.....] - ETA: 0s - loss: 5.8179 - accuracy: 0.0666
on_train_batch_begin: 1599688460.949927s

41 step training time: 0.063718s

on_train_batch_end: 1599688461.013324s

43008/50000 [========================>.....] - ETA: 0s - loss: 5.7802 - accuracy: 0.0670
on_train_batch_begin: 1599688461.013694s

42 step training time: 0.063767s

on_train_batch_end: 1599688461.077769s

44032/50000 [=========================>....] - ETA: 0s - loss: 5.7385 - accuracy: 0.0674
on_train_batch_begin: 1599688461.078172s

43 step training time: 0.064478s

on_train_batch_end: 1599688461.143902s

45056/50000 [==========================>...] - ETA: 0s - loss: 5.6989 - accuracy: 0.0679
on_train_batch_begin: 1599688461.144273s

44 step training time: 0.066100s

on_train_batch_end: 1599688461.208886s

46080/50000 [==========================>...] - ETA: 0s - loss: 5.6606 - accuracy: 0.0683
on_train_batch_begin: 1599688461.209260s

45 step training time: 0.064987s

on_train_batch_end: 1599688461.272783s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.6190 - accuracy: 0.0687
on_train_batch_begin: 1599688461.273157s

46 step training time: 0.063898s

on_train_batch_end: 1599688461.338430s

48128/50000 [===========================>..] - ETA: 0s - loss: 5.5788 - accuracy: 0.0692
on_train_batch_begin: 1599688461.338812s

47 step training time: 0.065655s

on_train_batch_end: 1599688461.401829s

49152/50000 [============================>.] - ETA: 0s - loss: 5.5449 - accuracy: 0.0696
on_train_batch_begin: 1599688461.402200s

48 step training time: 0.063388s

on_train_batch_end: 1599688461.463610s

on_test_batch_begin: 1599688461.485732s

49 step training time: 0.083532s

on_epoch_end: 1599688461.731148s

Validation time: 0.245403s

Real time: 1599688461.731148s

Epoch time: 3.4230971336364746s

50000/50000 [==============================] - 3s 68us/sample - loss: 5.5137 - accuracy: 0.0699 - val_loss: 7.1622 - val_accuracy: 8.4363e-05

on_epoch_begin: 1599688461.731402s

Real time: 1599688461.7314117
Epoch 3/5

on_train_batch_begin: 1599688461.737041s

on_train_batch_end: 1599688461.804784s

 1024/50000 [..............................] - ETA: 3s - loss: 3.4389 - accuracy: 0.0949
on_train_batch_begin: 1599688461.805158s

1 step training time: 0.068117s

on_train_batch_end: 1599688461.868319s

 2048/50000 [>.............................] - ETA: 3s - loss: 3.4765 - accuracy: 0.0951
on_train_batch_begin: 1599688461.868692s

2 step training time: 0.063534s

on_train_batch_end: 1599688461.931366s

 3072/50000 [>.............................] - ETA: 3s - loss: 3.5142 - accuracy: 0.0944
on_train_batch_begin: 1599688461.931734s

3 step training time: 0.063042s

on_train_batch_end: 1599688461.994020s

 4096/50000 [=>............................] - ETA: 2s - loss: 3.5068 - accuracy: 0.0943
on_train_batch_begin: 1599688461.994390s

4 step training time: 0.062656s

on_train_batch_end: 1599688462.057863s

 5120/50000 [==>...........................] - ETA: 2s - loss: 3.4718 - accuracy: 0.0949
on_train_batch_begin: 1599688462.058232s

5 step training time: 0.063841s

on_train_batch_end: 1599688462.123984s

 6144/50000 [==>...........................] - ETA: 2s - loss: 3.4677 - accuracy: 0.0950
on_train_batch_begin: 1599688462.124353s

6 step training time: 0.066121s

on_train_batch_end: 1599688462.187310s

 7168/50000 [===>..........................] - ETA: 2s - loss: 3.4877 - accuracy: 0.0958
on_train_batch_begin: 1599688462.187679s

7 step training time: 0.063326s

on_train_batch_end: 1599688462.253757s

 8192/50000 [===>..........................] - ETA: 2s - loss: 3.4938 - accuracy: 0.0959
on_train_batch_begin: 1599688462.254182s

8 step training time: 0.066504s

on_train_batch_end: 1599688462.318151s

 9216/50000 [====>.........................] - ETA: 2s - loss: 3.4595 - accuracy: 0.0962
on_train_batch_begin: 1599688462.318523s

9 step training time: 0.064341s

on_train_batch_end: 1599688462.381127s

10240/50000 [=====>........................] - ETA: 2s - loss: 3.4301 - accuracy: 0.0966
on_train_batch_begin: 1599688462.381517s

10 step training time: 0.062994s

on_train_batch_end: 1599688462.445757s

11264/50000 [=====>........................] - ETA: 2s - loss: 3.4155 - accuracy: 0.0969
on_train_batch_begin: 1599688462.446176s

11 step training time: 0.064659s

on_train_batch_end: 1599688462.513357s

12288/50000 [======>.......................] - ETA: 2s - loss: 3.4110 - accuracy: 0.0971
on_train_batch_begin: 1599688462.513738s

12 step training time: 0.067562s

on_train_batch_end: 1599688462.579343s

13312/50000 [======>.......................] - ETA: 2s - loss: 3.4061 - accuracy: 0.0971
on_train_batch_begin: 1599688462.579726s

13 step training time: 0.065988s

on_train_batch_end: 1599688462.645766s

14336/50000 [=======>......................] - ETA: 2s - loss: 3.3991 - accuracy: 0.0973
on_train_batch_begin: 1599688462.646183s

14 step training time: 0.066458s

on_train_batch_end: 1599688462.707167s

15360/50000 [========>.....................] - ETA: 2s - loss: 3.3930 - accuracy: 0.0974
on_train_batch_begin: 1599688462.707551s

15 step training time: 0.061367s

on_train_batch_end: 1599688462.774161s

16384/50000 [========>.....................] - ETA: 2s - loss: 3.3889 - accuracy: 0.0976
on_train_batch_begin: 1599688462.774545s

16 step training time: 0.066994s

on_train_batch_end: 1599688462.837977s

17408/50000 [=========>....................] - ETA: 2s - loss: 3.3780 - accuracy: 0.0977
on_train_batch_begin: 1599688462.838367s

17 step training time: 0.063822s

on_train_batch_end: 1599688462.900313s

18432/50000 [==========>...................] - ETA: 2s - loss: 3.3729 - accuracy: 0.0979
on_train_batch_begin: 1599688462.900690s

18 step training time: 0.062324s

on_train_batch_end: 1599688462.963834s

19456/50000 [==========>...................] - ETA: 1s - loss: 3.3536 - accuracy: 0.0980
on_train_batch_begin: 1599688462.964204s

19 step training time: 0.063514s

on_train_batch_end: 1599688463.026630s

20480/50000 [===========>..................] - ETA: 1s - loss: 3.3380 - accuracy: 0.0981
on_train_batch_begin: 1599688463.027003s

20 step training time: 0.062799s

on_train_batch_end: 1599688463.090444s

21504/50000 [===========>..................] - ETA: 1s - loss: 3.3286 - accuracy: 0.0982
on_train_batch_begin: 1599688463.090826s

21 step training time: 0.063823s

on_train_batch_end: 1599688463.152812s

22528/50000 [============>.................] - ETA: 1s - loss: 3.3291 - accuracy: 0.0983
on_train_batch_begin: 1599688463.153193s

22 step training time: 0.062367s

on_train_batch_end: 1599688463.216071s

23552/50000 [=============>................] - ETA: 1s - loss: 3.3160 - accuracy: 0.0983
on_train_batch_begin: 1599688463.216440s

23 step training time: 0.063247s

on_train_batch_end: 1599688463.279178s

24576/50000 [=============>................] - ETA: 1s - loss: 3.3093 - accuracy: 0.0984
on_train_batch_begin: 1599688463.279557s

24 step training time: 0.063116s

on_train_batch_end: 1599688463.346304s

25600/50000 [==============>...............] - ETA: 1s - loss: 3.2992 - accuracy: 0.0984
on_train_batch_begin: 1599688463.346687s

25 step training time: 0.067131s

on_train_batch_end: 1599688463.410015s

26624/50000 [==============>...............] - ETA: 1s - loss: 3.2924 - accuracy: 0.0985
on_train_batch_begin: 1599688463.410394s

26 step training time: 0.063707s

on_train_batch_end: 1599688463.472330s

27648/50000 [===============>..............] - ETA: 1s - loss: 3.2829 - accuracy: 0.0985
on_train_batch_begin: 1599688463.472704s

27 step training time: 0.062310s

on_train_batch_end: 1599688463.535898s

28672/50000 [================>.............] - ETA: 1s - loss: 3.2782 - accuracy: 0.0985
on_train_batch_begin: 1599688463.536277s

28 step training time: 0.063573s

on_train_batch_end: 1599688463.599891s

29696/50000 [================>.............] - ETA: 1s - loss: 3.2696 - accuracy: 0.0985
on_train_batch_begin: 1599688463.600297s

29 step training time: 0.064021s

on_train_batch_end: 1599688463.666406s

30720/50000 [=================>............] - ETA: 1s - loss: 3.2599 - accuracy: 0.0986
on_train_batch_begin: 1599688463.666794s

30 step training time: 0.066497s

on_train_batch_end: 1599688463.730871s

31744/50000 [==================>...........] - ETA: 1s - loss: 3.2527 - accuracy: 0.0986
on_train_batch_begin: 1599688463.731249s

31 step training time: 0.064455s

on_train_batch_end: 1599688463.793367s

32768/50000 [==================>...........] - ETA: 1s - loss: 3.2454 - accuracy: 0.0986
on_train_batch_begin: 1599688463.793742s

32 step training time: 0.062493s

on_train_batch_end: 1599688463.859076s

33792/50000 [===================>..........] - ETA: 1s - loss: 3.2284 - accuracy: 0.0987
on_train_batch_begin: 1599688463.859450s

33 step training time: 0.065708s

on_train_batch_end: 1599688463.922622s

34816/50000 [===================>..........] - ETA: 0s - loss: 3.2260 - accuracy: 0.0987
on_train_batch_begin: 1599688463.922997s

34 step training time: 0.063546s

on_train_batch_end: 1599688463.987502s

35840/50000 [====================>.........] - ETA: 0s - loss: 3.2187 - accuracy: 0.0987
on_train_batch_begin: 1599688463.987879s

35 step training time: 0.064882s

on_train_batch_end: 1599688464.053374s

36864/50000 [=====================>........] - ETA: 0s - loss: 3.2046 - accuracy: 0.0988
on_train_batch_begin: 1599688464.053771s

36 step training time: 0.065892s

on_train_batch_end: 1599688464.121560s

37888/50000 [=====================>........] - ETA: 0s - loss: 3.1938 - accuracy: 0.0988
on_train_batch_begin: 1599688464.121959s

37 step training time: 0.068188s

on_train_batch_end: 1599688464.184895s

38912/50000 [======================>.......] - ETA: 0s - loss: 3.1796 - accuracy: 0.0989
on_train_batch_begin: 1599688464.185271s

38 step training time: 0.063311s

on_train_batch_end: 1599688464.247787s

39936/50000 [======================>.......] - ETA: 0s - loss: 3.1698 - accuracy: 0.0989
on_train_batch_begin: 1599688464.248161s

39 step training time: 0.062890s

on_train_batch_end: 1599688464.312380s

40960/50000 [=======================>......] - ETA: 0s - loss: 3.1586 - accuracy: 0.0989
on_train_batch_begin: 1599688464.312755s

40 step training time: 0.064594s

on_train_batch_end: 1599688464.380044s

41984/50000 [========================>.....] - ETA: 0s - loss: 3.1446 - accuracy: 0.0990
on_train_batch_begin: 1599688464.380418s

41 step training time: 0.067663s

on_train_batch_end: 1599688464.443249s

43008/50000 [========================>.....] - ETA: 0s - loss: 3.1302 - accuracy: 0.0990
on_train_batch_begin: 1599688464.443616s

42 step training time: 0.063198s

on_train_batch_end: 1599688464.507586s

44032/50000 [=========================>....] - ETA: 0s - loss: 3.1164 - accuracy: 0.0991
on_train_batch_begin: 1599688464.507965s

43 step training time: 0.064349s

on_train_batch_end: 1599688464.569758s

45056/50000 [==========================>...] - ETA: 0s - loss: 3.1029 - accuracy: 0.0991
on_train_batch_begin: 1599688464.570183s

44 step training time: 0.062218s

on_train_batch_end: 1599688464.632857s

46080/50000 [==========================>...] - ETA: 0s - loss: 3.0869 - accuracy: 0.0992
on_train_batch_begin: 1599688464.633230s

45 step training time: 0.063047s

on_train_batch_end: 1599688464.697374s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.0687 - accuracy: 0.0992
on_train_batch_begin: 1599688464.697747s

46 step training time: 0.064517s

on_train_batch_end: 1599688464.765100s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.0547 - accuracy: 0.0992
on_train_batch_begin: 1599688464.765468s

47 step training time: 0.067721s

on_train_batch_end: 1599688464.832017s

49152/50000 [============================>.] - ETA: 0s - loss: 3.0347 - accuracy: 0.0993
on_train_batch_begin: 1599688464.832390s

48 step training time: 0.066922s

on_train_batch_end: 1599688464.894424s

on_test_batch_begin: 1599688464.919365s

49 step training time: 0.086974s

on_epoch_end: 1599688465.165155s

Validation time: 0.245777s

Real time: 1599688465.165155s

Epoch time: 3.4337642192840576s

50000/50000 [==============================] - 3s 69us/sample - loss: 3.0221 - accuracy: 0.0993 - val_loss: 7.1889 - val_accuracy: 0.0999

on_epoch_begin: 1599688465.165398s

Real time: 1599688465.1654077
Epoch 4/5

on_train_batch_begin: 1599688465.171027s

on_train_batch_end: 1599688465.235570s

 1024/50000 [..............................] - ETA: 3s - loss: 2.1720 - accuracy: 0.1011
on_train_batch_begin: 1599688465.235948s

1 step training time: 0.064921s

on_train_batch_end: 1599688465.299456s

 2048/50000 [>.............................] - ETA: 3s - loss: 2.2022 - accuracy: 0.1007
on_train_batch_begin: 1599688465.299829s

2 step training time: 0.063880s

on_train_batch_end: 1599688465.363276s

 3072/50000 [>.............................] - ETA: 3s - loss: 2.1798 - accuracy: 0.1008
on_train_batch_begin: 1599688465.363648s

3 step training time: 0.063819s

on_train_batch_end: 1599688465.427062s

 4096/50000 [=>............................] - ETA: 2s - loss: 2.1628 - accuracy: 0.1006
on_train_batch_begin: 1599688465.427429s

4 step training time: 0.063781s

on_train_batch_end: 1599688465.496102s

 5120/50000 [==>...........................] - ETA: 2s - loss: 2.1490 - accuracy: 0.1006
on_train_batch_begin: 1599688465.496475s

5 step training time: 0.069046s

on_train_batch_end: 1599688465.560326s

 6144/50000 [==>...........................] - ETA: 2s - loss: 2.1483 - accuracy: 0.1006
on_train_batch_begin: 1599688465.560705s

6 step training time: 0.064230s

on_train_batch_end: 1599688465.625561s

 7168/50000 [===>..........................] - ETA: 2s - loss: 2.1432 - accuracy: 0.1006
on_train_batch_begin: 1599688465.625960s

7 step training time: 0.065256s

on_train_batch_end: 1599688465.688091s

 8192/50000 [===>..........................] - ETA: 2s - loss: 2.1058 - accuracy: 0.1007
on_train_batch_begin: 1599688465.688465s

8 step training time: 0.062505s

on_train_batch_end: 1599688465.752687s

 9216/50000 [====>.........................] - ETA: 2s - loss: 2.1062 - accuracy: 0.1006
on_train_batch_begin: 1599688465.753064s

9 step training time: 0.064599s

on_train_batch_end: 1599688465.819345s

10240/50000 [=====>........................] - ETA: 2s - loss: 2.0899 - accuracy: 0.1007
on_train_batch_begin: 1599688465.819729s

10 step training time: 0.066665s

on_train_batch_end: 1599688465.884208s

11264/50000 [=====>........................] - ETA: 2s - loss: 2.0854 - accuracy: 0.1007
on_train_batch_begin: 1599688465.884585s

11 step training time: 0.064856s

on_train_batch_end: 1599688465.951766s

12288/50000 [======>.......................] - ETA: 2s - loss: 2.0551 - accuracy: 0.1007
on_train_batch_begin: 1599688465.952137s

12 step training time: 0.067553s

on_train_batch_end: 1599688466.018152s

13312/50000 [======>.......................] - ETA: 2s - loss: 2.0415 - accuracy: 0.1007
on_train_batch_begin: 1599688466.018528s

13 step training time: 0.066390s

on_train_batch_end: 1599688466.085140s

14336/50000 [=======>......................] - ETA: 2s - loss: 2.0258 - accuracy: 0.1007
on_train_batch_begin: 1599688466.085513s

14 step training time: 0.066985s

on_train_batch_end: 1599688466.155108s

15360/50000 [========>.....................] - ETA: 2s - loss: 2.0177 - accuracy: 0.1007
on_train_batch_begin: 1599688466.155482s

15 step training time: 0.069969s

on_train_batch_end: 1599688466.219941s

16384/50000 [========>.....................] - ETA: 2s - loss: 2.0085 - accuracy: 0.1008
on_train_batch_begin: 1599688466.220317s

16 step training time: 0.064835s

on_train_batch_end: 1599688466.284144s

17408/50000 [=========>....................] - ETA: 2s - loss: 1.9914 - accuracy: 0.1008
on_train_batch_begin: 1599688466.284520s

17 step training time: 0.064202s

on_train_batch_end: 1599688466.352854s

18432/50000 [==========>...................] - ETA: 2s - loss: 1.9726 - accuracy: 0.1008
on_train_batch_begin: 1599688466.353229s

18 step training time: 0.068709s

on_train_batch_end: 1599688466.418214s

19456/50000 [==========>...................] - ETA: 1s - loss: 1.9647 - accuracy: 0.1008
on_train_batch_begin: 1599688466.418585s

19 step training time: 0.065356s

on_train_batch_end: 1599688466.482162s

20480/50000 [===========>..................] - ETA: 1s - loss: 1.9671 - accuracy: 0.1008
on_train_batch_begin: 1599688466.482540s

20 step training time: 0.063955s

on_train_batch_end: 1599688466.546321s

21504/50000 [===========>..................] - ETA: 1s - loss: 1.9500 - accuracy: 0.1008
on_train_batch_begin: 1599688466.546693s

21 step training time: 0.064153s

on_train_batch_end: 1599688466.614483s

22528/50000 [============>.................] - ETA: 1s - loss: 1.9458 - accuracy: 0.1008
on_train_batch_begin: 1599688466.614856s

22 step training time: 0.068163s

on_train_batch_end: 1599688466.683460s

23552/50000 [=============>................] - ETA: 1s - loss: 1.9305 - accuracy: 0.1008
on_train_batch_begin: 1599688466.683834s

23 step training time: 0.068978s

on_train_batch_end: 1599688466.748307s

24576/50000 [=============>................] - ETA: 1s - loss: 1.9185 - accuracy: 0.1008
on_train_batch_begin: 1599688466.748679s

24 step training time: 0.064845s

on_train_batch_end: 1599688466.812702s

25600/50000 [==============>...............] - ETA: 1s - loss: 1.9126 - accuracy: 0.1009
on_train_batch_begin: 1599688466.813088s

25 step training time: 0.064409s

on_train_batch_end: 1599688466.874993s

26624/50000 [==============>...............] - ETA: 1s - loss: 1.9074 - accuracy: 0.1009
on_train_batch_begin: 1599688466.875371s

26 step training time: 0.062284s

on_train_batch_end: 1599688466.940018s

27648/50000 [===============>..............] - ETA: 1s - loss: 1.8951 - accuracy: 0.1009
on_train_batch_begin: 1599688466.940398s

27 step training time: 0.065027s

on_train_batch_end: 1599688467.007559s

28672/50000 [================>.............] - ETA: 1s - loss: 1.8823 - accuracy: 0.1009
on_train_batch_begin: 1599688467.007935s

28 step training time: 0.067537s

on_train_batch_end: 1599688467.074240s

29696/50000 [================>.............] - ETA: 1s - loss: 1.8723 - accuracy: 0.1009
on_train_batch_begin: 1599688467.074644s

29 step training time: 0.066710s

on_train_batch_end: 1599688467.141365s

30720/50000 [=================>............] - ETA: 1s - loss: 1.8660 - accuracy: 0.1009
on_train_batch_begin: 1599688467.141744s

30 step training time: 0.067100s

on_train_batch_end: 1599688467.209149s

31744/50000 [==================>...........] - ETA: 1s - loss: 1.8537 - accuracy: 0.1009
on_train_batch_begin: 1599688467.209525s

31 step training time: 0.067781s

on_train_batch_end: 1599688467.278899s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.8468 - accuracy: 0.1009
on_train_batch_begin: 1599688467.279276s

32 step training time: 0.069751s

on_train_batch_end: 1599688467.346008s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.8439 - accuracy: 0.1009
on_train_batch_begin: 1599688467.346391s

33 step training time: 0.067115s

on_train_batch_end: 1599688467.413347s

34816/50000 [===================>..........] - ETA: 0s - loss: 1.8344 - accuracy: 0.1009
on_train_batch_begin: 1599688467.413731s

34 step training time: 0.067339s

on_train_batch_end: 1599688467.483194s

35840/50000 [====================>.........] - ETA: 0s - loss: 1.8286 - accuracy: 0.1009
on_train_batch_begin: 1599688467.483570s

35 step training time: 0.069840s

on_train_batch_end: 1599688467.546882s

36864/50000 [=====================>........] - ETA: 0s - loss: 1.8279 - accuracy: 0.1009
on_train_batch_begin: 1599688467.547256s

36 step training time: 0.063685s

on_train_batch_end: 1599688467.609920s

37888/50000 [=====================>........] - ETA: 0s - loss: 1.8207 - accuracy: 0.1009
on_train_batch_begin: 1599688467.610292s

37 step training time: 0.063037s

on_train_batch_end: 1599688467.674912s

38912/50000 [======================>.......] - ETA: 0s - loss: 1.8128 - accuracy: 0.1009
on_train_batch_begin: 1599688467.675289s

38 step training time: 0.064996s

on_train_batch_end: 1599688467.739395s

39936/50000 [======================>.......] - ETA: 0s - loss: 1.8061 - accuracy: 0.1009
on_train_batch_begin: 1599688467.739770s

39 step training time: 0.064481s

on_train_batch_end: 1599688467.802209s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.7993 - accuracy: 0.1009
on_train_batch_begin: 1599688467.802587s

40 step training time: 0.062817s

on_train_batch_end: 1599688467.870376s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.7940 - accuracy: 0.1009
on_train_batch_begin: 1599688467.870749s

41 step training time: 0.068161s

on_train_batch_end: 1599688467.933608s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.7889 - accuracy: 0.1009
on_train_batch_begin: 1599688467.934012s

42 step training time: 0.063264s

on_train_batch_end: 1599688467.997936s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.7829 - accuracy: 0.1009
on_train_batch_begin: 1599688467.998312s

43 step training time: 0.064299s

on_train_batch_end: 1599688468.063162s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.7754 - accuracy: 0.1009
on_train_batch_begin: 1599688468.063536s

44 step training time: 0.065225s

on_train_batch_end: 1599688468.126447s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.7724 - accuracy: 0.1009
on_train_batch_begin: 1599688468.126824s

45 step training time: 0.063287s

on_train_batch_end: 1599688468.188961s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7664 - accuracy: 0.1009
on_train_batch_begin: 1599688468.189334s

46 step training time: 0.062510s

on_train_batch_end: 1599688468.253345s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7583 - accuracy: 0.1009
on_train_batch_begin: 1599688468.253716s

47 step training time: 0.064383s

on_train_batch_end: 1599688468.314758s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7515 - accuracy: 0.1009
on_train_batch_begin: 1599688468.315132s

48 step training time: 0.061415s

on_train_batch_end: 1599688468.375749s

on_test_batch_begin: 1599688468.395417s

49 step training time: 0.080286s

on_epoch_end: 1599688468.636883s

Validation time: 0.241452s

Real time: 1599688468.636883s

Epoch time: 3.4714956283569336s

50000/50000 [==============================] - 3s 69us/sample - loss: 1.7499 - accuracy: 0.1009 - val_loss: 7.2938 - val_accuracy: 0.0999

on_epoch_begin: 1599688468.637126s

Real time: 1599688468.637136
Epoch 5/5

on_train_batch_begin: 1599688468.642810s

on_train_batch_end: 1599688468.707013s

 1024/50000 [..............................] - ETA: 3s - loss: 1.2571 - accuracy: 0.1009
on_train_batch_begin: 1599688468.707386s

1 step training time: 0.064575s

on_train_batch_end: 1599688468.774299s

 2048/50000 [>.............................] - ETA: 3s - loss: 1.2907 - accuracy: 0.1010
on_train_batch_begin: 1599688468.774673s

2 step training time: 0.067288s

on_train_batch_end: 1599688468.839409s

 3072/50000 [>.............................] - ETA: 3s - loss: 1.2889 - accuracy: 0.1012
on_train_batch_begin: 1599688468.839784s

3 step training time: 0.065111s

on_train_batch_end: 1599688468.902474s

 4096/50000 [=>............................] - ETA: 2s - loss: 1.3080 - accuracy: 0.1012
on_train_batch_begin: 1599688468.902852s

4 step training time: 0.063068s

on_train_batch_end: 1599688468.969391s

 5120/50000 [==>...........................] - ETA: 2s - loss: 1.3031 - accuracy: 0.1012
on_train_batch_begin: 1599688468.969763s

5 step training time: 0.066911s

on_train_batch_end: 1599688469.036993s

 6144/50000 [==>...........................] - ETA: 2s - loss: 1.3008 - accuracy: 0.1012
on_train_batch_begin: 1599688469.037363s

6 step training time: 0.067599s

on_train_batch_end: 1599688469.100626s

 7168/50000 [===>..........................] - ETA: 2s - loss: 1.2893 - accuracy: 0.1011
on_train_batch_begin: 1599688469.100997s

7 step training time: 0.063634s

on_train_batch_end: 1599688469.164379s

 8192/50000 [===>..........................] - ETA: 2s - loss: 1.3026 - accuracy: 0.1012
on_train_batch_begin: 1599688469.164747s

8 step training time: 0.063750s

on_train_batch_end: 1599688469.232721s

 9216/50000 [====>.........................] - ETA: 2s - loss: 1.2987 - accuracy: 0.1011
on_train_batch_begin: 1599688469.233094s

9 step training time: 0.068348s

on_train_batch_end: 1599688469.296119s

10240/50000 [=====>........................] - ETA: 2s - loss: 1.3137 - accuracy: 0.1012
on_train_batch_begin: 1599688469.296497s

10 step training time: 0.063403s

on_train_batch_end: 1599688469.359493s

11264/50000 [=====>........................] - ETA: 2s - loss: 1.3091 - accuracy: 0.1012
on_train_batch_begin: 1599688469.359878s

11 step training time: 0.063380s

on_train_batch_end: 1599688469.423593s

12288/50000 [======>.......................] - ETA: 2s - loss: 1.2992 - accuracy: 0.1012
on_train_batch_begin: 1599688469.423959s

12 step training time: 0.064082s

on_train_batch_end: 1599688469.486535s

13312/50000 [======>.......................] - ETA: 2s - loss: 1.2959 - accuracy: 0.1011
on_train_batch_begin: 1599688469.486908s

13 step training time: 0.062948s

on_train_batch_end: 1599688469.550068s

14336/50000 [=======>......................] - ETA: 2s - loss: 1.2916 - accuracy: 0.1012
on_train_batch_begin: 1599688469.550436s

14 step training time: 0.063528s

on_train_batch_end: 1599688469.613532s

15360/50000 [========>.....................] - ETA: 2s - loss: 1.2817 - accuracy: 0.1011
on_train_batch_begin: 1599688469.613930s

15 step training time: 0.063493s

on_train_batch_end: 1599688469.677770s

16384/50000 [========>.....................] - ETA: 2s - loss: 1.2709 - accuracy: 0.1012
on_train_batch_begin: 1599688469.678171s

16 step training time: 0.064242s

on_train_batch_end: 1599688469.742323s

17408/50000 [=========>....................] - ETA: 2s - loss: 1.2676 - accuracy: 0.1012
on_train_batch_begin: 1599688469.742691s

17 step training time: 0.064519s

on_train_batch_end: 1599688469.805884s

18432/50000 [==========>...................] - ETA: 2s - loss: 1.2614 - accuracy: 0.1012
on_train_batch_begin: 1599688469.806261s

18 step training time: 0.063570s

on_train_batch_end: 1599688469.869819s

19456/50000 [==========>...................] - ETA: 1s - loss: 1.2615 - accuracy: 0.1012
on_train_batch_begin: 1599688469.870190s

19 step training time: 0.063930s

on_train_batch_end: 1599688469.933976s

20480/50000 [===========>..................] - ETA: 1s - loss: 1.2568 - accuracy: 0.1012
on_train_batch_begin: 1599688469.934345s

20 step training time: 0.064155s

on_train_batch_end: 1599688470.001161s

21504/50000 [===========>..................] - ETA: 1s - loss: 1.2547 - accuracy: 0.1012
on_train_batch_begin: 1599688470.001534s

21 step training time: 0.067188s

on_train_batch_end: 1599688470.064555s

22528/50000 [============>.................] - ETA: 1s - loss: 1.2510 - accuracy: 0.1012
on_train_batch_begin: 1599688470.064930s

22 step training time: 0.063397s

on_train_batch_end: 1599688470.130758s

23552/50000 [=============>................] - ETA: 1s - loss: 1.2417 - accuracy: 0.1012
on_train_batch_begin: 1599688470.131135s

23 step training time: 0.066205s

on_train_batch_end: 1599688470.196411s

24576/50000 [=============>................] - ETA: 1s - loss: 1.2364 - accuracy: 0.1012
on_train_batch_begin: 1599688470.196782s

24 step training time: 0.065647s

on_train_batch_end: 1599688470.259508s

25600/50000 [==============>...............] - ETA: 1s - loss: 1.2369 - accuracy: 0.1012
on_train_batch_begin: 1599688470.259881s

25 step training time: 0.063098s

on_train_batch_end: 1599688470.323591s

26624/50000 [==============>...............] - ETA: 1s - loss: 1.2352 - accuracy: 0.1012
on_train_batch_begin: 1599688470.323958s

26 step training time: 0.064077s

on_train_batch_end: 1599688470.390839s

27648/50000 [===============>..............] - ETA: 1s - loss: 1.2298 - accuracy: 0.1012
on_train_batch_begin: 1599688470.391206s

27 step training time: 0.067248s

on_train_batch_end: 1599688470.454963s

28672/50000 [================>.............] - ETA: 1s - loss: 1.2255 - accuracy: 0.1012
on_train_batch_begin: 1599688470.455338s

28 step training time: 0.064132s

on_train_batch_end: 1599688470.519952s

29696/50000 [================>.............] - ETA: 1s - loss: 1.2207 - accuracy: 0.1012
on_train_batch_begin: 1599688470.520328s

29 step training time: 0.064991s

on_train_batch_end: 1599688470.584768s

30720/50000 [=================>............] - ETA: 1s - loss: 1.2190 - accuracy: 0.1012
on_train_batch_begin: 1599688470.585140s

30 step training time: 0.064811s

on_train_batch_end: 1599688470.650294s

31744/50000 [==================>...........] - ETA: 1s - loss: 1.2151 - accuracy: 0.1012
on_train_batch_begin: 1599688470.650669s

31 step training time: 0.065529s

on_train_batch_end: 1599688470.711855s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.2111 - accuracy: 0.1013
on_train_batch_begin: 1599688470.712226s

32 step training time: 0.061557s

on_train_batch_end: 1599688470.774589s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.2101 - accuracy: 0.1013
on_train_batch_begin: 1599688470.774966s

33 step training time: 0.062740s

on_train_batch_end: 1599688470.838871s

34816/50000 [===================>..........] - ETA: 0s - loss: 1.2074 - accuracy: 0.1013
on_train_batch_begin: 1599688470.839251s

34 step training time: 0.064285s

on_train_batch_end: 1599688470.902629s

35840/50000 [====================>.........] - ETA: 0s - loss: 1.2044 - accuracy: 0.1013
on_train_batch_begin: 1599688470.903000s

35 step training time: 0.063749s

on_train_batch_end: 1599688470.966455s

36864/50000 [=====================>........] - ETA: 0s - loss: 1.2013 - accuracy: 0.1013
on_train_batch_begin: 1599688470.966824s

36 step training time: 0.063824s

on_train_batch_end: 1599688471.032961s

37888/50000 [=====================>........] - ETA: 0s - loss: 1.1973 - accuracy: 0.1013
on_train_batch_begin: 1599688471.033333s

37 step training time: 0.066509s

on_train_batch_end: 1599688471.099015s

38912/50000 [======================>.......] - ETA: 0s - loss: 1.1945 - accuracy: 0.1013
on_train_batch_begin: 1599688471.099392s

38 step training time: 0.066058s

on_train_batch_end: 1599688471.162184s

39936/50000 [======================>.......] - ETA: 0s - loss: 1.1903 - accuracy: 0.1013
on_train_batch_begin: 1599688471.162582s

39 step training time: 0.063190s

on_train_batch_end: 1599688471.226061s

40960/50000 [=======================>......] - ETA: 0s - loss: 1.1840 - accuracy: 0.1013
on_train_batch_begin: 1599688471.226447s

40 step training time: 0.063866s

on_train_batch_end: 1599688471.289394s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.1824 - accuracy: 0.1013
on_train_batch_begin: 1599688471.289768s

41 step training time: 0.063321s

on_train_batch_end: 1599688471.353193s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.1790 - accuracy: 0.1013
on_train_batch_begin: 1599688471.353562s

42 step training time: 0.063794s

on_train_batch_end: 1599688471.417062s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.1756 - accuracy: 0.1013
on_train_batch_begin: 1599688471.417434s

43 step training time: 0.063872s

on_train_batch_end: 1599688471.481746s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.1748 - accuracy: 0.1013
on_train_batch_begin: 1599688471.482164s

44 step training time: 0.064730s

on_train_batch_end: 1599688471.545433s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.1719 - accuracy: 0.1013
on_train_batch_begin: 1599688471.545824s

45 step training time: 0.063660s

on_train_batch_end: 1599688471.608831s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.1690 - accuracy: 0.1013
on_train_batch_begin: 1599688471.609215s

46 step training time: 0.063390s

on_train_batch_end: 1599688471.673358s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1669 - accuracy: 0.1013
on_train_batch_begin: 1599688471.673736s

47 step training time: 0.064521s

on_train_batch_end: 1599688471.735857s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1660 - accuracy: 0.1013
on_train_batch_begin: 1599688471.736232s

48 step training time: 0.062496s

on_train_batch_end: 1599688471.797225s

on_test_batch_begin: 1599688471.818858s

49 step training time: 0.082626s

on_epoch_end: 1599688472.059428s

Validation time: 0.240556s

Real time: 1599688472.059428s

Epoch time: 3.4223122596740723s

50000/50000 [==============================] - 3s 68us/sample - loss: 1.1648 - accuracy: 0.1013 - val_loss: 7.2457 - val_accuracy: 0.1016
Tempo do fit: 88.11411142349243