wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:49
   221184/170498071 [..............................] - ETA: 1:11
  1187840/170498071 [..............................] - ETA: 20s 
  3743744/170498071 [..............................] - ETA: 8s 
  7135232/170498071 [>.............................] - ETA: 5s
 10510336/170498071 [>.............................] - ETA: 4s
 13901824/170498071 [=>............................] - ETA: 3s
 17276928/170498071 [==>...........................] - ETA: 3s
 20553728/170498071 [==>...........................] - ETA: 3s
 23748608/170498071 [===>..........................] - ETA: 3s
 27140096/170498071 [===>..........................] - ETA: 2s
 30531584/170498071 [====>.........................] - ETA: 2s
 33906688/170498071 [====>.........................] - ETA: 2s
 37265408/170498071 [=====>........................] - ETA: 2s
 40656896/170498071 [======>.......................] - ETA: 2s
 44048384/170498071 [======>.......................] - ETA: 2s
 47341568/170498071 [=======>......................] - ETA: 2s
 50503680/170498071 [=======>......................] - ETA: 2s
 53796864/170498071 [========>.....................] - ETA: 2s
 57188352/170498071 [=========>....................] - ETA: 1s
 60563456/170498071 [=========>....................] - ETA: 1s
 63954944/170498071 [==========>...................] - ETA: 1s
 67330048/170498071 [==========>...................] - ETA: 1s
 70721536/170498071 [===========>..................] - ETA: 1s
 74096640/170498071 [============>.................] - ETA: 1s
 77307904/170498071 [============>.................] - ETA: 1s
 80502784/170498071 [=============>................] - ETA: 1s
 83697664/170498071 [=============>................] - ETA: 1s
 87040000/170498071 [==============>...............] - ETA: 1s
 90447872/170498071 [==============>...............] - ETA: 1s
 93839360/170498071 [===============>..............] - ETA: 1s
 97214464/170498071 [================>.............] - ETA: 1s
100605952/170498071 [================>.............] - ETA: 1s
103931904/170498071 [=================>............] - ETA: 1s
107257856/170498071 [=================>............] - ETA: 1s
110485504/170498071 [==================>...........] - ETA: 0s
113811456/170498071 [===================>..........] - ETA: 0s
117170176/170498071 [===================>..........] - ETA: 0s
120561664/170498071 [====================>.........] - ETA: 0s
123920384/170498071 [====================>.........] - ETA: 0s
127311872/170498071 [=====================>........] - ETA: 0s
130670592/170498071 [=====================>........] - ETA: 0s
134062080/170498071 [======================>.......] - ETA: 0s
137240576/170498071 [=======================>......] - ETA: 0s
140517376/170498071 [=======================>......] - ETA: 0s
143892480/170498071 [========================>.....] - ETA: 0s
147267584/170498071 [========================>.....] - ETA: 0s
150659072/170498071 [=========================>....] - ETA: 0s
154017792/170498071 [==========================>...] - ETA: 0s
157409280/170498071 [==========================>...] - ETA: 0s
160800768/170498071 [===========================>..] - ETA: 0s
164061184/170498071 [===========================>..] - ETA: 0s
167305216/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 1s
 6553600/94765736 [=>............................] - ETA: 0s
14344192/94765736 [===>..........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
21200896/94765736 [=====>........................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
37634048/94765736 [==========>...................] - ETA: 0s
43720704/94765736 [============>.................] - ETA: 0s
50626560/94765736 [===============>..............] - ETA: 0s
55705600/94765736 [================>.............] - ETA: 0s
60792832/94765736 [==================>...........] - ETA: 0s
65822720/94765736 [===================>..........] - ETA: 0s
70336512/94765736 [=====================>........] - ETA: 0s
75620352/94765736 [======================>.......] - ETA: 0s
81805312/94765736 [========================>.....] - ETA: 0s
86007808/94765736 [==========================>...] - ETA: 0s
94461952/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.557240724563599
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615751440.858846s

Real time: 1615751440.8588643
Epoch 1/5

on_train_batch_begin: 1615751441.601161s

on_train_batch_end: 1615751461.327804s

 2048/50000 [>.............................] - ETA: 7:59 - loss: 17.9501 - accuracy: 1.9622e-04
on_train_batch_begin: 1615751461.328441s

1 step training time: 19.727280s

on_train_batch_end: 1615751461.973166s

 4096/50000 [=>............................] - ETA: 3:56 - loss: 14.2843 - accuracy: 4.3917e-04
on_train_batch_begin: 1615751461.973482s

2 step training time: 0.645041s

on_train_batch_end: 1615751462.621948s

 6144/50000 [==>...........................] - ETA: 2:35 - loss: 12.3331 - accuracy: 0.0010    
on_train_batch_begin: 1615751462.622255s

3 step training time: 0.648773s

on_train_batch_end: 1615751463.272774s

 8192/50000 [===>..........................] - ETA: 1:54 - loss: 11.2980 - accuracy: 0.0018
on_train_batch_begin: 1615751463.273087s

4 step training time: 0.650832s

on_train_batch_end: 1615751463.922988s

10240/50000 [=====>........................] - ETA: 1:29 - loss: 10.6490 - accuracy: 0.0037
on_train_batch_begin: 1615751463.923314s

5 step training time: 0.650227s

on_train_batch_end: 1615751464.572346s

12288/50000 [======>.......................] - ETA: 1:12 - loss: 10.1619 - accuracy: 0.0074
on_train_batch_begin: 1615751464.572663s

6 step training time: 0.649349s

on_train_batch_end: 1615751465.224666s

14336/50000 [=======>......................] - ETA: 1:00 - loss: 9.7953 - accuracy: 0.0118 
on_train_batch_begin: 1615751465.225080s

7 step training time: 0.652418s

on_train_batch_end: 1615751465.875885s

16384/50000 [========>.....................] - ETA: 51s - loss: 9.5254 - accuracy: 0.0156 
on_train_batch_begin: 1615751465.876187s

8 step training time: 0.651107s

on_train_batch_end: 1615751466.523122s

18432/50000 [==========>...................] - ETA: 43s - loss: 9.2983 - accuracy: 0.0196
on_train_batch_begin: 1615751466.523432s

9 step training time: 0.647244s

on_train_batch_end: 1615751467.171965s

20480/50000 [===========>..................] - ETA: 37s - loss: 9.1161 - accuracy: 0.0233
on_train_batch_begin: 1615751467.172268s

10 step training time: 0.648836s

on_train_batch_end: 1615751467.820290s

22528/50000 [============>.................] - ETA: 32s - loss: 8.9580 - accuracy: 0.0258
on_train_batch_begin: 1615751467.820585s

11 step training time: 0.648318s

on_train_batch_end: 1615751468.468051s

24576/50000 [=============>................] - ETA: 28s - loss: 8.8168 - accuracy: 0.0288
on_train_batch_begin: 1615751468.468381s

12 step training time: 0.647796s

on_train_batch_end: 1615751469.114808s

26624/50000 [==============>...............] - ETA: 24s - loss: 8.7034 - accuracy: 0.0309
on_train_batch_begin: 1615751469.115108s

13 step training time: 0.646727s

on_train_batch_end: 1615751469.767178s

28672/50000 [================>.............] - ETA: 21s - loss: 8.6023 - accuracy: 0.0332
on_train_batch_begin: 1615751469.767487s

14 step training time: 0.652379s

on_train_batch_end: 1615751470.413991s

30720/50000 [=================>............] - ETA: 18s - loss: 8.5105 - accuracy: 0.0352
on_train_batch_begin: 1615751470.414328s

15 step training time: 0.646841s

on_train_batch_end: 1615751471.062464s

32768/50000 [==================>...........] - ETA: 15s - loss: 8.4272 - accuracy: 0.0372
on_train_batch_begin: 1615751471.062769s

16 step training time: 0.648442s

on_train_batch_end: 1615751471.710894s

34816/50000 [===================>..........] - ETA: 13s - loss: 8.3483 - accuracy: 0.0393
on_train_batch_begin: 1615751471.711196s

17 step training time: 0.648427s

on_train_batch_end: 1615751472.361602s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.2771 - accuracy: 0.0411
on_train_batch_begin: 1615751472.361904s

18 step training time: 0.650708s

on_train_batch_end: 1615751473.011161s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.2041 - accuracy: 0.0432 
on_train_batch_begin: 1615751473.011548s

19 step training time: 0.649644s

on_train_batch_end: 1615751473.658399s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.1420 - accuracy: 0.0447
on_train_batch_begin: 1615751473.658702s

20 step training time: 0.647154s

on_train_batch_end: 1615751474.310766s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.0902 - accuracy: 0.0461
on_train_batch_begin: 1615751474.311066s

21 step training time: 0.652364s

on_train_batch_end: 1615751474.959703s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.0318 - accuracy: 0.0474
on_train_batch_begin: 1615751474.960034s

22 step training time: 0.648968s

on_train_batch_end: 1615751475.608709s

47104/50000 [===========================>..] - ETA: 2s - loss: 7.9811 - accuracy: 0.0486
on_train_batch_begin: 1615751475.609017s

23 step training time: 0.648983s

on_train_batch_end: 1615751476.257415s

49152/50000 [============================>.] - ETA: 0s - loss: 7.9315 - accuracy: 0.0499
on_train_batch_begin: 1615751476.257739s

24 step training time: 0.648722s

on_train_batch_end: 1615751482.007287s

on_test_batch_begin: 1615751482.193080s

25 step training time: 5.935341s

on_epoch_end: 1615751487.283587s

Validation time: 5.090492s

Real time: 1615751487.283587s

Epoch time: 46.42474055290222s

50000/50000 [==============================] - 46s 928us/sample - loss: 7.9121 - accuracy: 0.0501 - val_loss: 464621.6040 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615751487.283811s

Real time: 1615751487.2838168
Epoch 2/5

on_train_batch_begin: 1615751487.287431s

on_train_batch_end: 1615751487.938983s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.7864 - accuracy: 0.0777
on_train_batch_begin: 1615751487.939298s

1 step training time: 0.651868s

on_train_batch_end: 1615751488.592459s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.7700 - accuracy: 0.0777
on_train_batch_begin: 1615751488.592751s

2 step training time: 0.653452s

on_train_batch_end: 1615751489.242047s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.7121 - accuracy: 0.0787
on_train_batch_begin: 1615751489.242363s

3 step training time: 0.649612s

on_train_batch_end: 1615751489.892101s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.7284 - accuracy: 0.0761
on_train_batch_begin: 1615751489.892392s

4 step training time: 0.650029s

on_train_batch_end: 1615751490.539509s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.7151 - accuracy: 0.0760
on_train_batch_begin: 1615751490.539808s

5 step training time: 0.647416s

on_train_batch_end: 1615751491.190485s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.7262 - accuracy: 0.0745
on_train_batch_begin: 1615751491.190781s

6 step training time: 0.650974s

on_train_batch_end: 1615751491.840326s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.7126 - accuracy: 0.0748
on_train_batch_begin: 1615751491.840636s

7 step training time: 0.649855s

on_train_batch_end: 1615751492.493699s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.7096 - accuracy: 0.0743
on_train_batch_begin: 1615751492.493994s

8 step training time: 0.653358s

on_train_batch_end: 1615751493.152405s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.6984 - accuracy: 0.0748
on_train_batch_begin: 1615751493.152699s

9 step training time: 0.658705s

on_train_batch_end: 1615751493.803404s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.6862 - accuracy: 0.0753 
on_train_batch_begin: 1615751493.803697s

10 step training time: 0.650998s

on_train_batch_end: 1615751494.454880s

22528/50000 [============>.................] - ETA: 8s - loss: 6.6842 - accuracy: 0.0740
on_train_batch_begin: 1615751494.455167s

11 step training time: 0.651470s

on_train_batch_end: 1615751495.104657s

24576/50000 [=============>................] - ETA: 8s - loss: 6.6758 - accuracy: 0.0751
on_train_batch_begin: 1615751495.104950s

12 step training time: 0.649783s

on_train_batch_end: 1615751495.755307s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.6701 - accuracy: 0.0763
on_train_batch_begin: 1615751495.755620s

13 step training time: 0.650670s

on_train_batch_end: 1615751496.402789s

28672/50000 [================>.............] - ETA: 6s - loss: 6.6591 - accuracy: 0.0772
on_train_batch_begin: 1615751496.403106s

14 step training time: 0.647486s

on_train_batch_end: 1615751497.053419s

30720/50000 [=================>............] - ETA: 6s - loss: 6.6477 - accuracy: 0.0778
on_train_batch_begin: 1615751497.053719s

15 step training time: 0.650613s

on_train_batch_end: 1615751497.700962s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.6378 - accuracy: 0.0789
on_train_batch_begin: 1615751497.701272s

16 step training time: 0.647553s

on_train_batch_end: 1615751498.353310s

34816/50000 [===================>..........] - ETA: 4s - loss: 6.6319 - accuracy: 0.0794
on_train_batch_begin: 1615751498.353616s

17 step training time: 0.652344s

on_train_batch_end: 1615751499.000321s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.6252 - accuracy: 0.0804
on_train_batch_begin: 1615751499.000618s

18 step training time: 0.647002s

on_train_batch_end: 1615751499.651648s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.6192 - accuracy: 0.0809
on_train_batch_begin: 1615751499.651939s

19 step training time: 0.651320s

on_train_batch_end: 1615751500.303329s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.6033 - accuracy: 0.0815
on_train_batch_begin: 1615751500.303638s

20 step training time: 0.651699s

on_train_batch_end: 1615751500.958266s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.5859 - accuracy: 0.0820
on_train_batch_begin: 1615751500.958606s

21 step training time: 0.654969s

on_train_batch_end: 1615751501.610922s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.5686 - accuracy: 0.0821
on_train_batch_begin: 1615751501.611238s

22 step training time: 0.652632s

on_train_batch_end: 1615751502.263582s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.5560 - accuracy: 0.0823
on_train_batch_begin: 1615751502.263895s

23 step training time: 0.652656s

on_train_batch_end: 1615751502.913077s

49152/50000 [============================>.] - ETA: 0s - loss: 6.5395 - accuracy: 0.0825
on_train_batch_begin: 1615751502.913379s

24 step training time: 0.649484s

on_train_batch_end: 1615751503.199076s

on_test_batch_begin: 1615751503.225186s

25 step training time: 0.311807s

on_epoch_end: 1615751504.063284s

Validation time: 0.838082s

Real time: 1615751504.063284s

Epoch time: 16.779484510421753s

50000/50000 [==============================] - 17s 336us/sample - loss: 6.5339 - accuracy: 0.0825 - val_loss: 573667.3237 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615751504.063478s

Real time: 1615751504.0634835
Epoch 3/5

on_train_batch_begin: 1615751504.066831s

on_train_batch_end: 1615751504.716144s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.1415 - accuracy: 0.0916
on_train_batch_begin: 1615751504.716447s

1 step training time: 0.649616s

on_train_batch_end: 1615751505.367386s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.0423 - accuracy: 0.0915
on_train_batch_begin: 1615751505.367684s

2 step training time: 0.651237s

on_train_batch_end: 1615751506.016409s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.0626 - accuracy: 0.0886
on_train_batch_begin: 1615751506.016706s

3 step training time: 0.649022s

on_train_batch_end: 1615751506.664508s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.0595 - accuracy: 0.0877
on_train_batch_begin: 1615751506.664814s

4 step training time: 0.648107s

on_train_batch_end: 1615751507.313974s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.0177 - accuracy: 0.0884
on_train_batch_begin: 1615751507.314276s

5 step training time: 0.649463s

on_train_batch_end: 1615751507.968744s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.9952 - accuracy: 0.0882
on_train_batch_begin: 1615751507.969053s

6 step training time: 0.654777s

on_train_batch_end: 1615751508.624949s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.9827 - accuracy: 0.0883
on_train_batch_begin: 1615751508.625250s

7 step training time: 0.656197s

on_train_batch_end: 1615751509.280349s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.9780 - accuracy: 0.0877
on_train_batch_begin: 1615751509.280653s

8 step training time: 0.655403s

on_train_batch_end: 1615751509.929388s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.9593 - accuracy: 0.0874
on_train_batch_begin: 1615751509.929700s

9 step training time: 0.649047s

on_train_batch_end: 1615751510.580186s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.9553 - accuracy: 0.0882 
on_train_batch_begin: 1615751510.580496s

10 step training time: 0.650795s

on_train_batch_end: 1615751511.227604s

22528/50000 [============>.................] - ETA: 8s - loss: 5.9454 - accuracy: 0.0876
on_train_batch_begin: 1615751511.227961s

11 step training time: 0.647465s

on_train_batch_end: 1615751511.879699s

24576/50000 [=============>................] - ETA: 8s - loss: 5.9356 - accuracy: 0.0881
on_train_batch_begin: 1615751511.880017s

12 step training time: 0.652056s

on_train_batch_end: 1615751512.524036s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.9274 - accuracy: 0.0871
on_train_batch_begin: 1615751512.524357s

13 step training time: 0.644340s

on_train_batch_end: 1615751513.177484s

28672/50000 [================>.............] - ETA: 6s - loss: 5.9157 - accuracy: 0.0871
on_train_batch_begin: 1615751513.177785s

14 step training time: 0.653427s

on_train_batch_end: 1615751513.825284s

30720/50000 [=================>............] - ETA: 6s - loss: 5.9091 - accuracy: 0.0878
on_train_batch_begin: 1615751513.825607s

15 step training time: 0.647822s

on_train_batch_end: 1615751514.477217s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.8954 - accuracy: 0.0881
on_train_batch_begin: 1615751514.477538s

16 step training time: 0.651931s

on_train_batch_end: 1615751515.124758s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.8817 - accuracy: 0.0883
on_train_batch_begin: 1615751515.125077s

17 step training time: 0.647539s

on_train_batch_end: 1615751515.784923s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.8682 - accuracy: 0.0885
on_train_batch_begin: 1615751515.785236s

18 step training time: 0.660159s

on_train_batch_end: 1615751516.434566s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.8666 - accuracy: 0.0887
on_train_batch_begin: 1615751516.434876s

19 step training time: 0.649640s

on_train_batch_end: 1615751517.090114s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.8602 - accuracy: 0.0890
on_train_batch_begin: 1615751517.090460s

20 step training time: 0.655584s

on_train_batch_end: 1615751517.740091s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.8545 - accuracy: 0.0891
on_train_batch_begin: 1615751517.740386s

21 step training time: 0.649927s

on_train_batch_end: 1615751518.389604s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.8493 - accuracy: 0.0891
on_train_batch_begin: 1615751518.389910s

22 step training time: 0.649523s

on_train_batch_end: 1615751519.040537s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.8423 - accuracy: 0.0893
on_train_batch_begin: 1615751519.040859s

23 step training time: 0.650950s

on_train_batch_end: 1615751519.685740s

49152/50000 [============================>.] - ETA: 0s - loss: 5.8347 - accuracy: 0.0895
on_train_batch_begin: 1615751519.686060s

24 step training time: 0.645201s

on_train_batch_end: 1615751519.968632s

on_test_batch_begin: 1615751519.995152s

25 step training time: 0.309091s

on_epoch_end: 1615751520.830905s

Validation time: 0.835736s

Real time: 1615751520.830905s

Epoch time: 16.767440795898438s

50000/50000 [==============================] - 17s 335us/sample - loss: 5.8324 - accuracy: 0.0895 - val_loss: 17580.0323 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615751520.831113s

Real time: 1615751520.8311188
Epoch 4/5

on_train_batch_begin: 1615751520.834504s

on_train_batch_end: 1615751521.485064s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.5739 - accuracy: 0.1012
on_train_batch_begin: 1615751521.485367s

1 step training time: 0.650863s

on_train_batch_end: 1615751522.138636s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.5274 - accuracy: 0.0958
on_train_batch_begin: 1615751522.138946s

2 step training time: 0.653579s

on_train_batch_end: 1615751522.786778s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.5772 - accuracy: 0.0900
on_train_batch_begin: 1615751522.787081s

3 step training time: 0.648135s

on_train_batch_end: 1615751523.440225s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.5585 - accuracy: 0.0879
on_train_batch_begin: 1615751523.440535s

4 step training time: 0.653454s

on_train_batch_end: 1615751524.098528s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.5414 - accuracy: 0.0872
on_train_batch_begin: 1615751524.098835s

5 step training time: 0.658300s

on_train_batch_end: 1615751524.752280s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.5354 - accuracy: 0.0859
on_train_batch_begin: 1615751524.752641s

6 step training time: 0.653805s

on_train_batch_end: 1615751525.403746s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.5367 - accuracy: 0.0854
on_train_batch_begin: 1615751525.404052s

7 step training time: 0.651412s

on_train_batch_end: 1615751526.057922s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.5271 - accuracy: 0.0843
on_train_batch_begin: 1615751526.058236s

8 step training time: 0.654183s

on_train_batch_end: 1615751526.711049s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.5172 - accuracy: 0.0822
on_train_batch_begin: 1615751526.711355s

9 step training time: 0.653119s

on_train_batch_end: 1615751527.366958s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.5116 - accuracy: 0.0790 
on_train_batch_begin: 1615751527.367273s

10 step training time: 0.655919s

on_train_batch_end: 1615751528.016979s

22528/50000 [============>.................] - ETA: 8s - loss: 5.5006 - accuracy: 0.0764
on_train_batch_begin: 1615751528.017282s

11 step training time: 0.650008s

on_train_batch_end: 1615751528.665726s

24576/50000 [=============>................] - ETA: 8s - loss: 5.4901 - accuracy: 0.0747
on_train_batch_begin: 1615751528.666025s

12 step training time: 0.648744s

on_train_batch_end: 1615751529.320615s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.4712 - accuracy: 0.0733
on_train_batch_begin: 1615751529.320912s

13 step training time: 0.654886s

on_train_batch_end: 1615751529.975812s

28672/50000 [================>.............] - ETA: 6s - loss: 5.4481 - accuracy: 0.0719
on_train_batch_begin: 1615751529.976119s

14 step training time: 0.655207s

on_train_batch_end: 1615751530.629767s

30720/50000 [=================>............] - ETA: 6s - loss: 5.4359 - accuracy: 0.0705
on_train_batch_begin: 1615751530.630073s

15 step training time: 0.653954s

on_train_batch_end: 1615751531.284528s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.4229 - accuracy: 0.0690
on_train_batch_begin: 1615751531.284838s

16 step training time: 0.654766s

on_train_batch_end: 1615751531.934561s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.4097 - accuracy: 0.0676
on_train_batch_begin: 1615751531.934892s

17 step training time: 0.650053s

on_train_batch_end: 1615751532.585119s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.3957 - accuracy: 0.0666
on_train_batch_begin: 1615751532.585428s

18 step training time: 0.650537s

on_train_batch_end: 1615751533.237535s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.3802 - accuracy: 0.0657
on_train_batch_begin: 1615751533.237885s

19 step training time: 0.652457s

on_train_batch_end: 1615751533.895869s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.3581 - accuracy: 0.0650
on_train_batch_begin: 1615751533.896197s

20 step training time: 0.658313s

on_train_batch_end: 1615751534.550933s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.3441 - accuracy: 0.0644
on_train_batch_begin: 1615751534.551249s

21 step training time: 0.655052s

on_train_batch_end: 1615751535.203351s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.3289 - accuracy: 0.0640
on_train_batch_begin: 1615751535.203664s

22 step training time: 0.652415s

on_train_batch_end: 1615751535.853365s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.3169 - accuracy: 0.0637
on_train_batch_begin: 1615751535.853684s

23 step training time: 0.650020s

on_train_batch_end: 1615751536.501964s

49152/50000 [============================>.] - ETA: 0s - loss: 5.2966 - accuracy: 0.0635
on_train_batch_begin: 1615751536.502268s

24 step training time: 0.648584s

on_train_batch_end: 1615751536.784759s

on_test_batch_begin: 1615751536.811510s

25 step training time: 0.309242s

on_epoch_end: 1615751537.651175s

Validation time: 0.839649s

Real time: 1615751537.651175s

Epoch time: 16.82007360458374s

50000/50000 [==============================] - 17s 336us/sample - loss: 5.2895 - accuracy: 0.0635 - val_loss: 14.2412 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615751537.651377s

Real time: 1615751537.6513822
Epoch 5/5

on_train_batch_begin: 1615751537.654845s

on_train_batch_end: 1615751538.304997s

 2048/50000 [>.............................] - ETA: 15s - loss: 4.6359 - accuracy: 0.0573
on_train_batch_begin: 1615751538.305317s

1 step training time: 0.650473s

on_train_batch_end: 1615751538.962438s

 4096/50000 [=>............................] - ETA: 14s - loss: 4.6084 - accuracy: 0.0569
on_train_batch_begin: 1615751538.962749s

2 step training time: 0.657432s

on_train_batch_end: 1615751539.615405s

 6144/50000 [==>...........................] - ETA: 14s - loss: 4.5508 - accuracy: 0.0577
on_train_batch_begin: 1615751539.615707s

3 step training time: 0.652958s

on_train_batch_end: 1615751540.268862s

 8192/50000 [===>..........................] - ETA: 13s - loss: 4.5507 - accuracy: 0.0580
on_train_batch_begin: 1615751540.269169s

4 step training time: 0.653462s

on_train_batch_end: 1615751540.925576s

10240/50000 [=====>........................] - ETA: 12s - loss: 4.4980 - accuracy: 0.0589
on_train_batch_begin: 1615751540.925893s

5 step training time: 0.656724s

on_train_batch_end: 1615751541.579966s

12288/50000 [======>.......................] - ETA: 12s - loss: 4.4777 - accuracy: 0.0595
on_train_batch_begin: 1615751541.580264s

6 step training time: 0.654371s

on_train_batch_end: 1615751542.235760s

14336/50000 [=======>......................] - ETA: 11s - loss: 4.4148 - accuracy: 0.0603
on_train_batch_begin: 1615751542.236060s

7 step training time: 0.655796s

on_train_batch_end: 1615751542.890479s

16384/50000 [========>.....................] - ETA: 10s - loss: 4.3790 - accuracy: 0.0608
on_train_batch_begin: 1615751542.890777s

8 step training time: 0.654717s

on_train_batch_end: 1615751543.547290s

18432/50000 [==========>...................] - ETA: 10s - loss: 4.3331 - accuracy: 0.0615
on_train_batch_begin: 1615751543.547626s

9 step training time: 0.656849s

on_train_batch_end: 1615751544.202866s

20480/50000 [===========>..................] - ETA: 9s - loss: 4.2887 - accuracy: 0.0622 
on_train_batch_begin: 1615751544.203194s

10 step training time: 0.655568s

on_train_batch_end: 1615751544.855002s

22528/50000 [============>.................] - ETA: 8s - loss: 4.2502 - accuracy: 0.0630
on_train_batch_begin: 1615751544.855306s

11 step training time: 0.652112s

on_train_batch_end: 1615751545.508494s

24576/50000 [=============>................] - ETA: 8s - loss: 4.1996 - accuracy: 0.0638
on_train_batch_begin: 1615751545.508899s

12 step training time: 0.653593s

on_train_batch_end: 1615751546.166214s

26624/50000 [==============>...............] - ETA: 7s - loss: 4.1602 - accuracy: 0.0647
on_train_batch_begin: 1615751546.166554s

13 step training time: 0.657655s

on_train_batch_end: 1615751546.821335s

28672/50000 [================>.............] - ETA: 6s - loss: 4.1193 - accuracy: 0.0655
on_train_batch_begin: 1615751546.821632s

14 step training time: 0.655078s

on_train_batch_end: 1615751547.474505s

30720/50000 [=================>............] - ETA: 6s - loss: 4.0662 - accuracy: 0.0666
on_train_batch_begin: 1615751547.474799s

15 step training time: 0.653167s

on_train_batch_end: 1615751548.127815s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.0019 - accuracy: 0.0682
on_train_batch_begin: 1615751548.128117s

16 step training time: 0.653318s

on_train_batch_end: 1615751548.778575s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.9384 - accuracy: 0.0697
on_train_batch_begin: 1615751548.778898s

17 step training time: 0.650780s

on_train_batch_end: 1615751549.438499s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.8689 - accuracy: 0.0711
on_train_batch_begin: 1615751549.438816s

18 step training time: 0.659918s

on_train_batch_end: 1615751550.094579s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.7972 - accuracy: 0.0726
on_train_batch_begin: 1615751550.094879s

19 step training time: 0.656064s

on_train_batch_end: 1615751550.745238s

40960/50000 [=======================>......] - ETA: 2s - loss: 3.7362 - accuracy: 0.0739
on_train_batch_begin: 1615751550.745535s

20 step training time: 0.650656s

on_train_batch_end: 1615751551.402623s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.6756 - accuracy: 0.0751
on_train_batch_begin: 1615751551.402950s

21 step training time: 0.657415s

on_train_batch_end: 1615751552.060050s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.6100 - accuracy: 0.0763
on_train_batch_begin: 1615751552.060350s

22 step training time: 0.657400s

on_train_batch_end: 1615751552.713928s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.5480 - accuracy: 0.0773
on_train_batch_begin: 1615751552.714240s

23 step training time: 0.653890s

on_train_batch_end: 1615751553.365205s

49152/50000 [============================>.] - ETA: 0s - loss: 3.4853 - accuracy: 0.0782
on_train_batch_begin: 1615751553.365505s

24 step training time: 0.651265s

on_train_batch_end: 1615751553.647726s

on_test_batch_begin: 1615751553.674167s

25 step training time: 0.308662s

on_epoch_end: 1615751554.512305s

Validation time: 0.838120s

Real time: 1615751554.512305s

Epoch time: 16.86094093322754s

50000/50000 [==============================] - 17s 337us/sample - loss: 3.4628 - accuracy: 0.0784 - val_loss: 7.6291 - val_accuracy: 0.0000e+00
Tempo do fit: 117.06814312934875