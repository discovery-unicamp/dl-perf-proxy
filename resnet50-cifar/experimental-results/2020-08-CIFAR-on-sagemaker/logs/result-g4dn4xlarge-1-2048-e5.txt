wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:51
   188416/170498071 [..............................] - ETA: 1:05
   778240/170498071 [..............................] - ETA: 26s 
   974848/170498071 [..............................] - ETA: 30s
  2498560/170498071 [..............................] - ETA: 14s
  5742592/170498071 [>.............................] - ETA: 7s 
  7168000/170498071 [>.............................] - ETA: 7s
 10379264/170498071 [>.............................] - ETA: 5s
 13623296/170498071 [=>............................] - ETA: 5s
 16850944/170498071 [=>............................] - ETA: 4s
 20094976/170498071 [==>...........................] - ETA: 4s
 23339008/170498071 [===>..........................] - ETA: 3s
 26566656/170498071 [===>..........................] - ETA: 3s
 29810688/170498071 [====>.........................] - ETA: 3s
 33021952/170498071 [====>.........................] - ETA: 3s
 36265984/170498071 [=====>........................] - ETA: 2s
 39477248/170498071 [=====>........................] - ETA: 2s
 42737664/170498071 [======>.......................] - ETA: 2s
 45981696/170498071 [=======>......................] - ETA: 2s
 49225728/170498071 [=======>......................] - ETA: 2s
 52404224/170498071 [========>.....................] - ETA: 2s
 55549952/170498071 [========>.....................] - ETA: 2s
 58728448/170498071 [=========>....................] - ETA: 2s
 61906944/170498071 [=========>....................] - ETA: 2s
 65150976/170498071 [==========>...................] - ETA: 2s
 68395008/170498071 [===========>..................] - ETA: 1s
 71639040/170498071 [===========>..................] - ETA: 1s
 74866688/170498071 [============>.................] - ETA: 1s
 78110720/170498071 [============>.................] - ETA: 1s
 81371136/170498071 [=============>................] - ETA: 1s
 84615168/170498071 [=============>................] - ETA: 1s
 87842816/170498071 [==============>...............] - ETA: 1s
 91070464/170498071 [===============>..............] - ETA: 1s
 94298112/170498071 [===============>..............] - ETA: 1s
 97550336/170498071 [================>.............] - ETA: 1s
100769792/170498071 [================>.............] - ETA: 1s
103948288/170498071 [=================>............] - ETA: 1s
107126784/170498071 [=================>............] - ETA: 1s
110321664/170498071 [==================>...........] - ETA: 1s
113516544/170498071 [==================>...........] - ETA: 1s
116645888/170498071 [===================>..........] - ETA: 0s
119906304/170498071 [====================>.........] - ETA: 0s
123166720/170498071 [====================>.........] - ETA: 0s
126394368/170498071 [=====================>........] - ETA: 0s
129654784/170498071 [=====================>........] - ETA: 0s
132898816/170498071 [======================>.......] - ETA: 0s
136159232/170498071 [======================>.......] - ETA: 0s
139403264/170498071 [=======================>......] - ETA: 0s
142630912/170498071 [========================>.....] - ETA: 0s
145874944/170498071 [========================>.....] - ETA: 0s
149102592/170498071 [=========================>....] - ETA: 0s
152363008/170498071 [=========================>....] - ETA: 0s
155541504/170498071 [==========================>...] - ETA: 0s
158736384/170498071 [==========================>...] - ETA: 0s
161931264/170498071 [===========================>..] - ETA: 0s
165109760/170498071 [============================>.] - ETA: 0s
168321024/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 39s
 5742592/94765736 [>.............................] - ETA: 0s 
 9388032/94765736 [=>............................] - ETA: 1s
12926976/94765736 [===>..........................] - ETA: 1s
15294464/94765736 [===>..........................] - ETA: 1s
19709952/94765736 [=====>........................] - ETA: 1s
21594112/94765736 [=====>........................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
34521088/94765736 [=========>....................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
40050688/94765736 [===========>..................] - ETA: 1s
43802624/94765736 [============>.................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 1s
50003968/94765736 [==============>...............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
57712640/94765736 [=================>............] - ETA: 0s
59940864/94765736 [=================>............] - ETA: 0s
60801024/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
67510272/94765736 [====================>.........] - ETA: 0s
71942144/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
77799424/94765736 [=======================>......] - ETA: 0s
83714048/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
87965696/94765736 [==========================>...] - ETA: 0s
90734592/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 15.334380388259888
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615756481.235478s

Real time: 1615756481.2354963
Epoch 1/5

on_train_batch_begin: 1615756482.010299s

on_train_batch_end: 1615756503.183373s

 2048/50000 [>.............................] - ETA: 8:33 - loss: 17.9147 - accuracy: 2.6655e-04
on_train_batch_begin: 1615756503.183979s

1 step training time: 21.173680s

on_train_batch_end: 1615756503.825838s

 4096/50000 [=>............................] - ETA: 4:13 - loss: 14.3106 - accuracy: 3.7456e-04
on_train_batch_begin: 1615756503.826158s

2 step training time: 0.642179s

on_train_batch_end: 1615756504.471060s

 6144/50000 [==>...........................] - ETA: 2:45 - loss: 12.3527 - accuracy: 6.8196e-04
on_train_batch_begin: 1615756504.471366s

3 step training time: 0.645208s

on_train_batch_end: 1615756505.073678s

 8192/50000 [===>..........................] - ETA: 2:01 - loss: 11.3348 - accuracy: 0.0023    
on_train_batch_begin: 1615756505.073987s

4 step training time: 0.602621s

on_train_batch_end: 1615756505.720181s

10240/50000 [=====>........................] - ETA: 1:35 - loss: 10.6646 - accuracy: 0.0053
on_train_batch_begin: 1615756505.720498s

5 step training time: 0.646511s

on_train_batch_end: 1615756506.358176s

12288/50000 [======>.......................] - ETA: 1:17 - loss: 10.2099 - accuracy: 0.0094
on_train_batch_begin: 1615756506.358483s

6 step training time: 0.637985s

on_train_batch_end: 1615756506.998086s

14336/50000 [=======>......................] - ETA: 1:04 - loss: 9.8722 - accuracy: 0.0141 
on_train_batch_begin: 1615756506.998388s

7 step training time: 0.639905s

on_train_batch_end: 1615756507.640531s

16384/50000 [========>.....................] - ETA: 54s - loss: 9.6005 - accuracy: 0.0186 
on_train_batch_begin: 1615756507.640850s

8 step training time: 0.642462s

on_train_batch_end: 1615756508.283863s

18432/50000 [==========>...................] - ETA: 46s - loss: 9.3861 - accuracy: 0.0216
on_train_batch_begin: 1615756508.284169s

9 step training time: 0.643320s

on_train_batch_end: 1615756508.923011s

20480/50000 [===========>..................] - ETA: 39s - loss: 9.2241 - accuracy: 0.0254
on_train_batch_begin: 1615756508.923316s

10 step training time: 0.639146s

on_train_batch_end: 1615756509.565618s

22528/50000 [============>.................] - ETA: 34s - loss: 9.0802 - accuracy: 0.0297
on_train_batch_begin: 1615756509.565917s

11 step training time: 0.642602s

on_train_batch_end: 1615756510.206009s

24576/50000 [=============>................] - ETA: 29s - loss: 8.9461 - accuracy: 0.0320
on_train_batch_begin: 1615756510.206319s

12 step training time: 0.640401s

on_train_batch_end: 1615756510.847044s

26624/50000 [==============>...............] - ETA: 25s - loss: 8.8456 - accuracy: 0.0341
on_train_batch_begin: 1615756510.847345s

13 step training time: 0.641026s

on_train_batch_end: 1615756511.491286s

28672/50000 [================>.............] - ETA: 22s - loss: 8.7541 - accuracy: 0.0355
on_train_batch_begin: 1615756511.491620s

14 step training time: 0.644275s

on_train_batch_end: 1615756512.129874s

30720/50000 [=================>............] - ETA: 19s - loss: 8.6676 - accuracy: 0.0363
on_train_batch_begin: 1615756512.130195s

15 step training time: 0.638575s

on_train_batch_end: 1615756512.773899s

32768/50000 [==================>...........] - ETA: 16s - loss: 8.6074 - accuracy: 0.0374
on_train_batch_begin: 1615756512.774213s

16 step training time: 0.644018s

on_train_batch_end: 1615756513.415525s

34816/50000 [===================>..........] - ETA: 14s - loss: 8.5475 - accuracy: 0.0385
on_train_batch_begin: 1615756513.415830s

17 step training time: 0.641617s

on_train_batch_end: 1615756514.059338s

36864/50000 [=====================>........] - ETA: 11s - loss: 8.4825 - accuracy: 0.0400
on_train_batch_begin: 1615756514.059648s

18 step training time: 0.643817s

on_train_batch_end: 1615756514.702461s

38912/50000 [======================>.......] - ETA: 9s - loss: 8.4260 - accuracy: 0.0413 
on_train_batch_begin: 1615756514.702775s

19 step training time: 0.643128s

on_train_batch_end: 1615756515.341687s

40960/50000 [=======================>......] - ETA: 7s - loss: 8.3746 - accuracy: 0.0422
on_train_batch_begin: 1615756515.341997s

20 step training time: 0.639222s

on_train_batch_end: 1615756515.985073s

43008/50000 [========================>.....] - ETA: 5s - loss: 8.3253 - accuracy: 0.0424
on_train_batch_begin: 1615756515.985380s

21 step training time: 0.643383s

on_train_batch_end: 1615756516.629188s

45056/50000 [==========================>...] - ETA: 3s - loss: 8.2821 - accuracy: 0.0426
on_train_batch_begin: 1615756516.629493s

22 step training time: 0.644113s

on_train_batch_end: 1615756517.268400s

47104/50000 [===========================>..] - ETA: 2s - loss: 8.2423 - accuracy: 0.0422
on_train_batch_begin: 1615756517.268695s

23 step training time: 0.639202s

on_train_batch_end: 1615756517.909258s

49152/50000 [============================>.] - ETA: 0s - loss: 8.2051 - accuracy: 0.0421
on_train_batch_begin: 1615756517.909573s

24 step training time: 0.640879s

on_train_batch_end: 1615756523.632562s

on_test_batch_begin: 1615756523.821098s

25 step training time: 5.911525s

on_epoch_end: 1615756528.914801s

Validation time: 5.093688s

Real time: 1615756528.914801s

Epoch time: 47.6793212890625s

50000/50000 [==============================] - 48s 954us/sample - loss: 8.1916 - accuracy: 0.0421 - val_loss: 6347.3718 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615756528.915004s

Real time: 1615756528.9150093
Epoch 2/5

on_train_batch_begin: 1615756528.918407s

on_train_batch_end: 1615756529.558318s

 2048/50000 [>.............................] - ETA: 15s - loss: 7.2661 - accuracy: 0.0676
on_train_batch_begin: 1615756529.558619s

1 step training time: 0.640212s

on_train_batch_end: 1615756530.200004s

 4096/50000 [=>............................] - ETA: 14s - loss: 7.2668 - accuracy: 0.0685
on_train_batch_begin: 1615756530.200300s

2 step training time: 0.641681s

on_train_batch_end: 1615756530.844773s

 6144/50000 [==>...........................] - ETA: 13s - loss: 7.2694 - accuracy: 0.0730
on_train_batch_begin: 1615756530.845072s

3 step training time: 0.644771s

on_train_batch_end: 1615756531.488508s

 8192/50000 [===>..........................] - ETA: 13s - loss: 7.2763 - accuracy: 0.0755
on_train_batch_begin: 1615756531.488822s

4 step training time: 0.643751s

on_train_batch_end: 1615756532.133757s

10240/50000 [=====>........................] - ETA: 12s - loss: 7.2623 - accuracy: 0.0768
on_train_batch_begin: 1615756532.134056s

5 step training time: 0.645234s

on_train_batch_end: 1615756532.778950s

12288/50000 [======>.......................] - ETA: 11s - loss: 7.2532 - accuracy: 0.0778
on_train_batch_begin: 1615756532.779253s

6 step training time: 0.645197s

on_train_batch_end: 1615756533.420759s

14336/50000 [=======>......................] - ETA: 11s - loss: 7.2558 - accuracy: 0.0789
on_train_batch_begin: 1615756533.421070s

7 step training time: 0.641817s

on_train_batch_end: 1615756534.066359s

16384/50000 [========>.....................] - ETA: 10s - loss: 7.2462 - accuracy: 0.0792
on_train_batch_begin: 1615756534.066667s

8 step training time: 0.645596s

on_train_batch_end: 1615756534.709516s

18432/50000 [==========>...................] - ETA: 9s - loss: 7.2408 - accuracy: 0.0801 
on_train_batch_begin: 1615756534.709832s

9 step training time: 0.643165s

on_train_batch_end: 1615756535.352640s

20480/50000 [===========>..................] - ETA: 9s - loss: 7.2419 - accuracy: 0.0809
on_train_batch_begin: 1615756535.352960s

10 step training time: 0.643128s

on_train_batch_end: 1615756535.997145s

22528/50000 [============>.................] - ETA: 8s - loss: 7.2369 - accuracy: 0.0820
on_train_batch_begin: 1615756535.997451s

11 step training time: 0.644491s

on_train_batch_end: 1615756536.644613s

24576/50000 [=============>................] - ETA: 7s - loss: 7.2334 - accuracy: 0.0826
on_train_batch_begin: 1615756536.644916s

12 step training time: 0.647465s

on_train_batch_end: 1615756537.288919s

26624/50000 [==============>...............] - ETA: 7s - loss: 7.2367 - accuracy: 0.0829
on_train_batch_begin: 1615756537.289226s

13 step training time: 0.644310s

on_train_batch_end: 1615756537.904328s

28672/50000 [================>.............] - ETA: 6s - loss: 7.2328 - accuracy: 0.0831
on_train_batch_begin: 1615756537.904633s

14 step training time: 0.615407s

on_train_batch_end: 1615756538.555099s

30720/50000 [=================>............] - ETA: 6s - loss: 7.2234 - accuracy: 0.0835
on_train_batch_begin: 1615756538.555399s

15 step training time: 0.650766s

on_train_batch_end: 1615756539.188127s

32768/50000 [==================>...........] - ETA: 5s - loss: 7.2150 - accuracy: 0.0840
on_train_batch_begin: 1615756539.188433s

16 step training time: 0.633034s

on_train_batch_end: 1615756539.835696s

34816/50000 [===================>..........] - ETA: 4s - loss: 7.2123 - accuracy: 0.0841
on_train_batch_begin: 1615756539.835994s

17 step training time: 0.647562s

on_train_batch_end: 1615756540.476566s

36864/50000 [=====================>........] - ETA: 4s - loss: 7.2018 - accuracy: 0.0844
on_train_batch_begin: 1615756540.476869s

18 step training time: 0.640875s

on_train_batch_end: 1615756541.118909s

38912/50000 [======================>.......] - ETA: 3s - loss: 7.1951 - accuracy: 0.0847
on_train_batch_begin: 1615756541.119222s

19 step training time: 0.642353s

on_train_batch_end: 1615756541.760028s

40960/50000 [=======================>......] - ETA: 2s - loss: 7.1898 - accuracy: 0.0849
on_train_batch_begin: 1615756541.760347s

20 step training time: 0.641124s

on_train_batch_end: 1615756542.404399s

43008/50000 [========================>.....] - ETA: 2s - loss: 7.1833 - accuracy: 0.0846
on_train_batch_begin: 1615756542.404710s

21 step training time: 0.644363s

on_train_batch_end: 1615756543.048809s

45056/50000 [==========================>...] - ETA: 1s - loss: 7.1824 - accuracy: 0.0850
on_train_batch_begin: 1615756543.049115s

22 step training time: 0.644405s

on_train_batch_end: 1615756543.695665s

47104/50000 [===========================>..] - ETA: 0s - loss: 7.1787 - accuracy: 0.0854
on_train_batch_begin: 1615756543.695972s

23 step training time: 0.646858s

on_train_batch_end: 1615756544.335626s

49152/50000 [============================>.] - ETA: 0s - loss: 7.1733 - accuracy: 0.0857
on_train_batch_begin: 1615756544.335957s

24 step training time: 0.639985s

on_train_batch_end: 1615756544.605671s

on_test_batch_begin: 1615756544.645321s

25 step training time: 0.309364s

on_epoch_end: 1615756545.466403s

Validation time: 0.821066s

Real time: 1615756545.466403s

Epoch time: 16.551412343978882s

50000/50000 [==============================] - 17s 331us/sample - loss: 7.1735 - accuracy: 0.0857 - val_loss: 325.7062 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615756545.466619s

Real time: 1615756545.4666247
Epoch 3/5

on_train_batch_begin: 1615756545.470044s

on_train_batch_end: 1615756546.105911s

 2048/50000 [>.............................] - ETA: 14s - loss: 7.0285 - accuracy: 0.0871
on_train_batch_begin: 1615756546.106230s

1 step training time: 0.636187s

on_train_batch_end: 1615756546.749280s

 4096/50000 [=>............................] - ETA: 14s - loss: 7.0180 - accuracy: 0.0884
on_train_batch_begin: 1615756546.749621s

2 step training time: 0.643391s

on_train_batch_end: 1615756547.393760s

 6144/50000 [==>...........................] - ETA: 13s - loss: 7.0122 - accuracy: 0.0890
on_train_batch_begin: 1615756547.394061s

3 step training time: 0.644440s

on_train_batch_end: 1615756548.042313s

 8192/50000 [===>..........................] - ETA: 13s - loss: 7.0159 - accuracy: 0.0895
on_train_batch_begin: 1615756548.042610s

4 step training time: 0.648549s

on_train_batch_end: 1615756548.687882s

10240/50000 [=====>........................] - ETA: 12s - loss: 7.0179 - accuracy: 0.0882
on_train_batch_begin: 1615756548.688182s

5 step training time: 0.645572s

on_train_batch_end: 1615756549.335162s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.9982 - accuracy: 0.0887
on_train_batch_begin: 1615756549.335470s

6 step training time: 0.647288s

on_train_batch_end: 1615756549.972996s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.9866 - accuracy: 0.0893
on_train_batch_begin: 1615756549.973299s

7 step training time: 0.637828s

on_train_batch_end: 1615756550.615743s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.9812 - accuracy: 0.0894
on_train_batch_begin: 1615756550.616036s

8 step training time: 0.642737s

on_train_batch_end: 1615756551.252096s

18432/50000 [==========>...................] - ETA: 9s - loss: 6.9832 - accuracy: 0.0895 
on_train_batch_begin: 1615756551.252393s

9 step training time: 0.636357s

on_train_batch_end: 1615756551.898638s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.9803 - accuracy: 0.0888
on_train_batch_begin: 1615756551.898958s

10 step training time: 0.646565s

on_train_batch_end: 1615756552.540929s

22528/50000 [============>.................] - ETA: 8s - loss: 6.9756 - accuracy: 0.0881
on_train_batch_begin: 1615756552.541249s

11 step training time: 0.642291s

on_train_batch_end: 1615756553.189201s

24576/50000 [=============>................] - ETA: 7s - loss: 6.9736 - accuracy: 0.0879
on_train_batch_begin: 1615756553.189523s

12 step training time: 0.648273s

on_train_batch_end: 1615756553.835335s

26624/50000 [==============>...............] - ETA: 7s - loss: 6.9656 - accuracy: 0.0873
on_train_batch_begin: 1615756553.835646s

13 step training time: 0.646123s

on_train_batch_end: 1615756554.481407s

28672/50000 [================>.............] - ETA: 6s - loss: 6.9581 - accuracy: 0.0868
on_train_batch_begin: 1615756554.481747s

14 step training time: 0.646101s

on_train_batch_end: 1615756555.131710s

30720/50000 [=================>............] - ETA: 6s - loss: 6.9510 - accuracy: 0.0860
on_train_batch_begin: 1615756555.132010s

15 step training time: 0.650263s

on_train_batch_end: 1615756555.775698s

32768/50000 [==================>...........] - ETA: 5s - loss: 6.9422 - accuracy: 0.0855
on_train_batch_begin: 1615756555.776001s

16 step training time: 0.643991s

on_train_batch_end: 1615756556.415673s

34816/50000 [===================>..........] - ETA: 4s - loss: 6.9283 - accuracy: 0.0854
on_train_batch_begin: 1615756556.415973s

17 step training time: 0.639972s

on_train_batch_end: 1615756557.062792s

36864/50000 [=====================>........] - ETA: 4s - loss: 6.9213 - accuracy: 0.0853
on_train_batch_begin: 1615756557.063100s

18 step training time: 0.647127s

on_train_batch_end: 1615756557.708187s

38912/50000 [======================>.......] - ETA: 3s - loss: 6.9098 - accuracy: 0.0845
on_train_batch_begin: 1615756557.708503s

19 step training time: 0.645403s

on_train_batch_end: 1615756558.355657s

40960/50000 [=======================>......] - ETA: 2s - loss: 6.8986 - accuracy: 0.0834
on_train_batch_begin: 1615756558.355954s

20 step training time: 0.647451s

on_train_batch_end: 1615756558.998248s

43008/50000 [========================>.....] - ETA: 2s - loss: 6.8859 - accuracy: 0.0825
on_train_batch_begin: 1615756558.998545s

21 step training time: 0.642591s

on_train_batch_end: 1615756559.642022s

45056/50000 [==========================>...] - ETA: 1s - loss: 6.8774 - accuracy: 0.0816
on_train_batch_begin: 1615756559.642316s

22 step training time: 0.643771s

on_train_batch_end: 1615756560.288558s

47104/50000 [===========================>..] - ETA: 0s - loss: 6.8619 - accuracy: 0.0800
on_train_batch_begin: 1615756560.288855s

23 step training time: 0.646539s

on_train_batch_end: 1615756560.931218s

49152/50000 [============================>.] - ETA: 0s - loss: 6.8478 - accuracy: 0.0787
on_train_batch_begin: 1615756560.931521s

24 step training time: 0.642666s

on_train_batch_end: 1615756561.206945s

on_test_batch_begin: 1615756561.245087s

25 step training time: 0.313566s

on_epoch_end: 1615756562.055314s

Validation time: 0.810212s

Real time: 1615756562.055314s

Epoch time: 16.588707447052002s

50000/50000 [==============================] - 17s 332us/sample - loss: 6.8409 - accuracy: 0.0786 - val_loss: 7.8878 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615756562.055511s

Real time: 1615756562.0555172
Epoch 4/5

on_train_batch_begin: 1615756562.058852s

on_train_batch_end: 1615756562.699216s

 2048/50000 [>.............................] - ETA: 15s - loss: 6.4747 - accuracy: 0.0700
on_train_batch_begin: 1615756562.699505s

1 step training time: 0.640653s

on_train_batch_end: 1615756563.353272s

 4096/50000 [=>............................] - ETA: 14s - loss: 6.4162 - accuracy: 0.0715
on_train_batch_begin: 1615756563.353616s

2 step training time: 0.654111s

on_train_batch_end: 1615756564.000961s

 6144/50000 [==>...........................] - ETA: 13s - loss: 6.3725 - accuracy: 0.0670
on_train_batch_begin: 1615756564.001274s

3 step training time: 0.647659s

on_train_batch_end: 1615756564.648351s

 8192/50000 [===>..........................] - ETA: 13s - loss: 6.3372 - accuracy: 0.0606
on_train_batch_begin: 1615756564.648665s

4 step training time: 0.647391s

on_train_batch_end: 1615756565.297769s

10240/50000 [=====>........................] - ETA: 12s - loss: 6.2947 - accuracy: 0.0554
on_train_batch_begin: 1615756565.298082s

5 step training time: 0.649416s

on_train_batch_end: 1615756565.948805s

12288/50000 [======>.......................] - ETA: 11s - loss: 6.2449 - accuracy: 0.0528
on_train_batch_begin: 1615756565.949108s

6 step training time: 0.651026s

on_train_batch_end: 1615756566.597406s

14336/50000 [=======>......................] - ETA: 11s - loss: 6.2039 - accuracy: 0.0513
on_train_batch_begin: 1615756566.597732s

7 step training time: 0.648623s

on_train_batch_end: 1615756567.246494s

16384/50000 [========>.....................] - ETA: 10s - loss: 6.1638 - accuracy: 0.0504
on_train_batch_begin: 1615756567.246804s

8 step training time: 0.649072s

on_train_batch_end: 1615756567.895246s

18432/50000 [==========>...................] - ETA: 10s - loss: 6.1169 - accuracy: 0.0498
on_train_batch_begin: 1615756567.895551s

9 step training time: 0.648747s

on_train_batch_end: 1615756568.542683s

20480/50000 [===========>..................] - ETA: 9s - loss: 6.0776 - accuracy: 0.0491 
on_train_batch_begin: 1615756568.542992s

10 step training time: 0.647440s

on_train_batch_end: 1615756569.193007s

22528/50000 [============>.................] - ETA: 8s - loss: 6.0406 - accuracy: 0.0489
on_train_batch_begin: 1615756569.193318s

11 step training time: 0.650326s

on_train_batch_end: 1615756569.840029s

24576/50000 [=============>................] - ETA: 8s - loss: 6.0087 - accuracy: 0.0490
on_train_batch_begin: 1615756569.840333s

12 step training time: 0.647015s

on_train_batch_end: 1615756570.491519s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.9762 - accuracy: 0.0495
on_train_batch_begin: 1615756570.491827s

13 step training time: 0.651494s

on_train_batch_end: 1615756571.137702s

28672/50000 [================>.............] - ETA: 6s - loss: 5.9363 - accuracy: 0.0504
on_train_batch_begin: 1615756571.138010s

14 step training time: 0.646183s

on_train_batch_end: 1615756571.790120s

30720/50000 [=================>............] - ETA: 6s - loss: 5.8926 - accuracy: 0.0513
on_train_batch_begin: 1615756571.790430s

15 step training time: 0.652421s

on_train_batch_end: 1615756572.438550s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.8395 - accuracy: 0.0527
on_train_batch_begin: 1615756572.438861s

16 step training time: 0.648431s

on_train_batch_end: 1615756573.091169s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.7880 - accuracy: 0.0541
on_train_batch_begin: 1615756573.091477s

17 step training time: 0.652616s

on_train_batch_end: 1615756573.736922s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.7310 - accuracy: 0.0554
on_train_batch_begin: 1615756573.737226s

18 step training time: 0.645749s

on_train_batch_end: 1615756574.385457s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.6737 - accuracy: 0.0567
on_train_batch_begin: 1615756574.385790s

19 step training time: 0.648563s

on_train_batch_end: 1615756575.034179s

40960/50000 [=======================>......] - ETA: 2s - loss: 5.6149 - accuracy: 0.0582
on_train_batch_begin: 1615756575.034489s

20 step training time: 0.648699s

on_train_batch_end: 1615756575.686989s

43008/50000 [========================>.....] - ETA: 2s - loss: 5.5529 - accuracy: 0.0595
on_train_batch_begin: 1615756575.687298s

21 step training time: 0.652809s

on_train_batch_end: 1615756576.336911s

45056/50000 [==========================>...] - ETA: 1s - loss: 5.4890 - accuracy: 0.0608
on_train_batch_begin: 1615756576.337233s

22 step training time: 0.649935s

on_train_batch_end: 1615756576.988786s

47104/50000 [===========================>..] - ETA: 0s - loss: 5.4224 - accuracy: 0.0619
on_train_batch_begin: 1615756576.989097s

23 step training time: 0.651864s

on_train_batch_end: 1615756577.633249s

49152/50000 [============================>.] - ETA: 0s - loss: 5.3529 - accuracy: 0.0630
on_train_batch_begin: 1615756577.633590s

24 step training time: 0.644492s

on_train_batch_end: 1615756577.907419s

on_test_batch_begin: 1615756577.946611s

25 step training time: 0.313022s

on_epoch_end: 1615756578.772020s

Validation time: 0.825393s

Real time: 1615756578.772020s

Epoch time: 16.716522216796875s

50000/50000 [==============================] - 17s 334us/sample - loss: 5.3266 - accuracy: 0.0632 - val_loss: 9.7606 - val_accuracy: 0.0998

on_epoch_begin: 1615756578.772230s

Real time: 1615756578.7722359
Epoch 5/5

on_train_batch_begin: 1615756578.775629s

on_train_batch_end: 1615756579.420170s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.5247 - accuracy: 0.0922
on_train_batch_begin: 1615756579.420488s

1 step training time: 0.644859s

on_train_batch_end: 1615756580.071451s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.4852 - accuracy: 0.0925
on_train_batch_begin: 1615756580.071769s

2 step training time: 0.651281s

on_train_batch_end: 1615756580.721416s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.4341 - accuracy: 0.0928
on_train_batch_begin: 1615756580.721767s

3 step training time: 0.649998s

on_train_batch_end: 1615756581.367513s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.4070 - accuracy: 0.0934
on_train_batch_begin: 1615756581.367842s

4 step training time: 0.646075s

on_train_batch_end: 1615756582.024175s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.3464 - accuracy: 0.0939
on_train_batch_begin: 1615756582.024496s

5 step training time: 0.656654s

on_train_batch_end: 1615756582.668363s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.3207 - accuracy: 0.0942
on_train_batch_begin: 1615756582.668686s

6 step training time: 0.644190s

on_train_batch_end: 1615756583.324387s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.2928 - accuracy: 0.0947
on_train_batch_begin: 1615756583.324708s

7 step training time: 0.656022s

on_train_batch_end: 1615756583.972589s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.2692 - accuracy: 0.0948
on_train_batch_begin: 1615756583.972912s

8 step training time: 0.648204s

on_train_batch_end: 1615756584.624009s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.2505 - accuracy: 0.0950
on_train_batch_begin: 1615756584.624338s

9 step training time: 0.651426s

on_train_batch_end: 1615756585.272927s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.2311 - accuracy: 0.0953 
on_train_batch_begin: 1615756585.273236s

10 step training time: 0.648898s

on_train_batch_end: 1615756585.921289s

22528/50000 [============>.................] - ETA: 8s - loss: 3.2093 - accuracy: 0.0955
on_train_batch_begin: 1615756585.921820s

11 step training time: 0.648584s

on_train_batch_end: 1615756586.572892s

24576/50000 [=============>................] - ETA: 8s - loss: 3.1768 - accuracy: 0.0955
on_train_batch_begin: 1615756586.573203s

12 step training time: 0.651383s

on_train_batch_end: 1615756587.223451s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.1394 - accuracy: 0.0958
on_train_batch_begin: 1615756587.223757s

13 step training time: 0.650554s

on_train_batch_end: 1615756587.874517s

28672/50000 [================>.............] - ETA: 6s - loss: 3.1004 - accuracy: 0.0959
on_train_batch_begin: 1615756587.874820s

14 step training time: 0.651063s

on_train_batch_end: 1615756588.523097s

30720/50000 [=================>............] - ETA: 6s - loss: 3.0787 - accuracy: 0.0960
on_train_batch_begin: 1615756588.523404s

15 step training time: 0.648584s

on_train_batch_end: 1615756589.174274s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.0415 - accuracy: 0.0962
on_train_batch_begin: 1615756589.174592s

16 step training time: 0.651188s

on_train_batch_end: 1615756589.825902s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.0035 - accuracy: 0.0963
on_train_batch_begin: 1615756589.826205s

17 step training time: 0.651613s

on_train_batch_end: 1615756590.477211s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.9689 - accuracy: 0.0965
on_train_batch_begin: 1615756590.477515s

18 step training time: 0.651310s

on_train_batch_end: 1615756591.127924s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.9383 - accuracy: 0.0966
on_train_batch_begin: 1615756591.128225s

19 step training time: 0.650710s

on_train_batch_end: 1615756591.777255s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.9070 - accuracy: 0.0968
on_train_batch_begin: 1615756591.777578s

20 step training time: 0.649353s

on_train_batch_end: 1615756592.425187s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.8747 - accuracy: 0.0969
on_train_batch_begin: 1615756592.425516s

21 step training time: 0.647938s

on_train_batch_end: 1615756593.075569s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.8500 - accuracy: 0.0971
on_train_batch_begin: 1615756593.075874s

22 step training time: 0.650358s

on_train_batch_end: 1615756593.727464s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.8264 - accuracy: 0.0972
on_train_batch_begin: 1615756593.727770s

23 step training time: 0.651896s

on_train_batch_end: 1615756594.373954s

49152/50000 [============================>.] - ETA: 0s - loss: 2.8073 - accuracy: 0.0973
on_train_batch_begin: 1615756594.374251s

24 step training time: 0.646482s

on_train_batch_end: 1615756594.648327s

on_test_batch_begin: 1615756594.686358s

25 step training time: 0.312106s

on_epoch_end: 1615756595.512005s

Validation time: 0.825633s

Real time: 1615756595.512005s

Epoch time: 16.739784717559814s

50000/50000 [==============================] - 17s 335us/sample - loss: 2.7926 - accuracy: 0.0973 - val_loss: 7.6246 - val_accuracy: 0.1001
Tempo do fit: 117.80110287666321