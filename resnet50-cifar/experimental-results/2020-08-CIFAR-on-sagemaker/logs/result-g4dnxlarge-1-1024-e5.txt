wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:45
   221184/170498071 [..............................] - ETA: 1:11
  1236992/170498071 [..............................] - ETA: 19s 
  3973120/170498071 [..............................] - ETA: 8s 
  7249920/170498071 [>.............................] - ETA: 5s
 10559488/170498071 [>.............................] - ETA: 4s
 13787136/170498071 [=>............................] - ETA: 3s
 17113088/170498071 [==>...........................] - ETA: 3s
 20471808/170498071 [==>...........................] - ETA: 3s
 23650304/170498071 [===>..........................] - ETA: 3s
 26861568/170498071 [===>..........................] - ETA: 2s
 30072832/170498071 [====>.........................] - ETA: 2s
 33382400/170498071 [====>.........................] - ETA: 2s
 36708352/170498071 [=====>........................] - ETA: 2s
 40050688/170498071 [======>.......................] - ETA: 2s
 43376640/170498071 [======>.......................] - ETA: 2s
 46727168/170498071 [=======>......................] - ETA: 2s
 50003968/170498071 [=======>......................] - ETA: 2s
 53288960/170498071 [========>.....................] - ETA: 2s
 56451072/170498071 [========>.....................] - ETA: 2s
 59629568/170498071 [=========>....................] - ETA: 1s
 62857216/170498071 [==========>...................] - ETA: 1s
 66019328/170498071 [==========>...................] - ETA: 1s
 69378048/170498071 [===========>..................] - ETA: 1s
 72687616/170498071 [===========>..................] - ETA: 1s
 76029952/170498071 [============>.................] - ETA: 1s
 79388672/170498071 [============>.................] - ETA: 1s
 82681856/170498071 [=============>................] - ETA: 1s
 86007808/170498071 [==============>...............] - ETA: 1s
 89268224/170498071 [==============>...............] - ETA: 1s
 92512256/170498071 [===============>..............] - ETA: 1s
 95707136/170498071 [===============>..............] - ETA: 1s
 98918400/170498071 [================>.............] - ETA: 1s
102211584/170498071 [================>.............] - ETA: 1s
105586688/170498071 [=================>............] - ETA: 1s
108847104/170498071 [==================>...........] - ETA: 1s
112189440/170498071 [==================>...........] - ETA: 0s
115531776/170498071 [===================>..........] - ETA: 0s
118841344/170498071 [===================>..........] - ETA: 0s
122036224/170498071 [====================>.........] - ETA: 0s
125403136/170498071 [=====================>........] - ETA: 0s
128540672/170498071 [=====================>........] - ETA: 0s
131735552/170498071 [======================>.......] - ETA: 0s
135045120/170498071 [======================>.......] - ETA: 0s
138403840/170498071 [=======================>......] - ETA: 0s
141746176/170498071 [=======================>......] - ETA: 0s
145063936/170498071 [========================>.....] - ETA: 0s
148398080/170498071 [=========================>....] - ETA: 0s
151691264/170498071 [=========================>....] - ETA: 0s
154902528/170498071 [==========================>...] - ETA: 0s
158244864/170498071 [==========================>...] - ETA: 0s
161406976/170498071 [===========================>..] - ETA: 0s
164651008/170498071 [===========================>..] - ETA: 0s
167829504/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 0s
18022400/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
46022656/94765736 [=============>................] - ETA: 0s
47783936/94765736 [==============>...............] - ETA: 0s
56000512/94765736 [================>.............] - ETA: 0s
61161472/94765736 [==================>...........] - ETA: 0s
65945600/94765736 [===================>..........] - ETA: 0s
71139328/94765736 [=====================>........] - ETA: 0s
76128256/94765736 [=======================>......] - ETA: 0s
81158144/94765736 [========================>.....] - ETA: 0s
86163456/94765736 [==========================>...] - ETA: 0s
91209728/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 13.115479469299316
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615749528.505884s

Real time: 1615749528.5059009
Epoch 1/5

on_train_batch_begin: 1615749529.253168s

on_train_batch_end: 1615749545.711912s

 1024/50000 [..............................] - ETA: 13:42 - loss: 17.7291 - accuracy: 3.9482e-04
on_train_batch_begin: 1615749545.712553s

1 step training time: 16.459385s

on_train_batch_end: 1615749546.048284s

 2048/50000 [>.............................] - ETA: 6:50 - loss: 15.6994 - accuracy: 3.4952e-04 
on_train_batch_begin: 1615749546.048718s

2 step training time: 0.336164s

on_train_batch_end: 1615749546.377143s

 3072/50000 [>.............................] - ETA: 4:33 - loss: 13.7663 - accuracy: 2.9627e-04
on_train_batch_begin: 1615749546.377436s

3 step training time: 0.328719s

on_train_batch_end: 1615749546.698195s

 4096/50000 [=>............................] - ETA: 3:23 - loss: 12.4826 - accuracy: 0.0012    
on_train_batch_begin: 1615749546.698483s

4 step training time: 0.321047s

on_train_batch_end: 1615749547.011896s

 5120/50000 [==>...........................] - ETA: 2:42 - loss: 11.6639 - accuracy: 0.0021
on_train_batch_begin: 1615749547.012194s

5 step training time: 0.313711s

on_train_batch_end: 1615749547.335218s

 6144/50000 [==>...........................] - ETA: 2:14 - loss: 11.0538 - accuracy: 0.0039
on_train_batch_begin: 1615749547.335481s

6 step training time: 0.323287s

on_train_batch_end: 1615749547.660105s

 7168/50000 [===>..........................] - ETA: 1:54 - loss: 10.6261 - accuracy: 0.0066
on_train_batch_begin: 1615749547.660389s

7 step training time: 0.324908s

on_train_batch_end: 1615749547.983020s

 8192/50000 [===>..........................] - ETA: 1:39 - loss: 10.2955 - accuracy: 0.0095
on_train_batch_begin: 1615749547.983322s

8 step training time: 0.322933s

on_train_batch_end: 1615749548.308421s

 9216/50000 [====>.........................] - ETA: 1:27 - loss: 10.0261 - accuracy: 0.0136
on_train_batch_begin: 1615749548.308699s

9 step training time: 0.325377s

on_train_batch_end: 1615749548.630563s

10240/50000 [=====>........................] - ETA: 1:18 - loss: 9.7952 - accuracy: 0.0172 
on_train_batch_begin: 1615749548.630822s

10 step training time: 0.322123s

on_train_batch_end: 1615749548.945225s

11264/50000 [=====>........................] - ETA: 1:10 - loss: 9.5842 - accuracy: 0.0210
on_train_batch_begin: 1615749548.945518s

11 step training time: 0.314696s

on_train_batch_end: 1615749549.265825s

12288/50000 [======>.......................] - ETA: 1:03 - loss: 9.4108 - accuracy: 0.0240
on_train_batch_begin: 1615749549.266054s

12 step training time: 0.320536s

on_train_batch_end: 1615749549.586425s

13312/50000 [======>.......................] - ETA: 58s - loss: 9.2510 - accuracy: 0.0264 
on_train_batch_begin: 1615749549.586647s

13 step training time: 0.320593s

on_train_batch_end: 1615749549.903686s

14336/50000 [=======>......................] - ETA: 53s - loss: 9.1094 - accuracy: 0.0292
on_train_batch_begin: 1615749549.903928s

14 step training time: 0.317281s

on_train_batch_end: 1615749550.224103s

15360/50000 [========>.....................] - ETA: 48s - loss: 8.9823 - accuracy: 0.0320
on_train_batch_begin: 1615749550.224363s

15 step training time: 0.320435s

on_train_batch_end: 1615749550.545348s

16384/50000 [========>.....................] - ETA: 45s - loss: 8.8604 - accuracy: 0.0348
on_train_batch_begin: 1615749550.545629s

16 step training time: 0.321266s

on_train_batch_end: 1615749550.867872s

17408/50000 [=========>....................] - ETA: 41s - loss: 8.7559 - accuracy: 0.0371
on_train_batch_begin: 1615749550.868116s

17 step training time: 0.322487s

on_train_batch_end: 1615749551.190554s

18432/50000 [==========>...................] - ETA: 38s - loss: 8.6600 - accuracy: 0.0393
on_train_batch_begin: 1615749551.190844s

18 step training time: 0.322729s

on_train_batch_end: 1615749551.509222s

19456/50000 [==========>...................] - ETA: 36s - loss: 8.5712 - accuracy: 0.0417
on_train_batch_begin: 1615749551.509477s

19 step training time: 0.318632s

on_train_batch_end: 1615749551.830652s

20480/50000 [===========>..................] - ETA: 33s - loss: 8.4823 - accuracy: 0.0438
on_train_batch_begin: 1615749551.830908s

20 step training time: 0.321431s

on_train_batch_end: 1615749552.152565s

21504/50000 [===========>..................] - ETA: 31s - loss: 8.4116 - accuracy: 0.0455
on_train_batch_begin: 1615749552.152831s

21 step training time: 0.321923s

on_train_batch_end: 1615749552.473473s

22528/50000 [============>.................] - ETA: 29s - loss: 8.3471 - accuracy: 0.0467
on_train_batch_begin: 1615749552.473752s

22 step training time: 0.320921s

on_train_batch_end: 1615749552.788551s

23552/50000 [=============>................] - ETA: 27s - loss: 8.2778 - accuracy: 0.0484
on_train_batch_begin: 1615749552.788823s

23 step training time: 0.315072s

on_train_batch_end: 1615749553.108299s

24576/50000 [=============>................] - ETA: 25s - loss: 8.2178 - accuracy: 0.0499
on_train_batch_begin: 1615749553.108566s

24 step training time: 0.319742s

on_train_batch_end: 1615749553.432398s

25600/50000 [==============>...............] - ETA: 23s - loss: 8.1599 - accuracy: 0.0513
on_train_batch_begin: 1615749553.432695s

25 step training time: 0.324130s

on_train_batch_end: 1615749553.756004s

26624/50000 [==============>...............] - ETA: 22s - loss: 8.1021 - accuracy: 0.0527
on_train_batch_begin: 1615749553.756277s

26 step training time: 0.323582s

on_train_batch_end: 1615749554.072175s

27648/50000 [===============>..............] - ETA: 20s - loss: 8.0491 - accuracy: 0.0542
on_train_batch_begin: 1615749554.072454s

27 step training time: 0.316177s

on_train_batch_end: 1615749554.393297s

28672/50000 [================>.............] - ETA: 19s - loss: 7.9955 - accuracy: 0.0556
on_train_batch_begin: 1615749554.393580s

28 step training time: 0.321126s

on_train_batch_end: 1615749554.712886s

29696/50000 [================>.............] - ETA: 17s - loss: 7.9466 - accuracy: 0.0570
on_train_batch_begin: 1615749554.713147s

29 step training time: 0.319567s

on_train_batch_end: 1615749555.034931s

30720/50000 [=================>............] - ETA: 16s - loss: 7.8945 - accuracy: 0.0583
on_train_batch_begin: 1615749555.035165s

30 step training time: 0.322018s

on_train_batch_end: 1615749555.357946s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.8451 - accuracy: 0.0595
on_train_batch_begin: 1615749555.358207s

31 step training time: 0.323042s

on_train_batch_end: 1615749555.688251s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.7980 - accuracy: 0.0606
on_train_batch_begin: 1615749555.688512s

32 step training time: 0.330305s

on_train_batch_end: 1615749556.006530s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.7575 - accuracy: 0.0611
on_train_batch_begin: 1615749556.006767s

33 step training time: 0.318255s

on_train_batch_end: 1615749556.324460s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.7155 - accuracy: 0.0615
on_train_batch_begin: 1615749556.324754s

34 step training time: 0.317987s

on_train_batch_end: 1615749556.648625s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.6769 - accuracy: 0.0611
on_train_batch_begin: 1615749556.648899s

35 step training time: 0.324145s

on_train_batch_end: 1615749556.973369s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.6323 - accuracy: 0.0616
on_train_batch_begin: 1615749556.973665s

36 step training time: 0.324766s

on_train_batch_end: 1615749557.296488s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.5914 - accuracy: 0.0616 
on_train_batch_begin: 1615749557.296745s

37 step training time: 0.323080s

on_train_batch_end: 1615749557.620255s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.5502 - accuracy: 0.0622
on_train_batch_begin: 1615749557.620489s

38 step training time: 0.323745s

on_train_batch_end: 1615749557.942995s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.5097 - accuracy: 0.0628
on_train_batch_begin: 1615749557.943245s

39 step training time: 0.322756s

on_train_batch_end: 1615749558.267543s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.4717 - accuracy: 0.0634
on_train_batch_begin: 1615749558.267790s

40 step training time: 0.324544s

on_train_batch_end: 1615749558.593550s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.4351 - accuracy: 0.0637
on_train_batch_begin: 1615749558.593780s

41 step training time: 0.325990s

on_train_batch_end: 1615749558.916291s

43008/50000 [========================>.....] - ETA: 4s - loss: 7.3994 - accuracy: 0.0642
on_train_batch_begin: 1615749558.916536s

42 step training time: 0.322756s

on_train_batch_end: 1615749559.234843s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.3636 - accuracy: 0.0645
on_train_batch_begin: 1615749559.235082s

43 step training time: 0.318546s

on_train_batch_end: 1615749559.556962s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.3244 - accuracy: 0.0650
on_train_batch_begin: 1615749559.557211s

44 step training time: 0.322129s

on_train_batch_end: 1615749559.879315s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.2883 - accuracy: 0.0651
on_train_batch_begin: 1615749559.879567s

45 step training time: 0.322356s

on_train_batch_end: 1615749560.202131s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.2545 - accuracy: 0.0653
on_train_batch_begin: 1615749560.202393s

46 step training time: 0.322826s

on_train_batch_end: 1615749560.524461s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.2201 - accuracy: 0.0654
on_train_batch_begin: 1615749560.524705s

47 step training time: 0.322312s

on_train_batch_end: 1615749560.850724s

49152/50000 [============================>.] - ETA: 0s - loss: 7.1857 - accuracy: 0.0655
on_train_batch_begin: 1615749560.850994s

48 step training time: 0.326289s

on_train_batch_end: 1615749566.596540s

on_test_batch_begin: 1615749566.782317s

49 step training time: 5.931323s

on_epoch_end: 1615749571.298467s

Validation time: 4.516136s

Real time: 1615749571.298467s

Epoch time: 42.79258322715759s

50000/50000 [==============================] - 43s 856us/sample - loss: 7.1584 - accuracy: 0.0654 - val_loss: 305520.9865 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615749571.298668s

Real time: 1615749571.2986736
Epoch 2/5

on_train_batch_begin: 1615749571.302053s

on_train_batch_end: 1615749571.627744s

 1024/50000 [..............................] - ETA: 15s - loss: 5.2795 - accuracy: 0.0669
on_train_batch_begin: 1615749571.628041s

1 step training time: 0.325988s

on_train_batch_end: 1615749571.953259s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.3478 - accuracy: 0.0697
on_train_batch_begin: 1615749571.953563s

2 step training time: 0.325522s

on_train_batch_end: 1615749572.275999s

 3072/50000 [>.............................] - ETA: 14s - loss: 5.2830 - accuracy: 0.0690
on_train_batch_begin: 1615749572.276251s

3 step training time: 0.322688s

on_train_batch_end: 1615749572.600297s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.2926 - accuracy: 0.0672
on_train_batch_begin: 1615749572.600539s

4 step training time: 0.324288s

on_train_batch_end: 1615749572.924807s

 5120/50000 [==>...........................] - ETA: 14s - loss: 5.2877 - accuracy: 0.0681
on_train_batch_begin: 1615749572.925055s

5 step training time: 0.324516s

on_train_batch_end: 1615749573.255265s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.2775 - accuracy: 0.0690
on_train_batch_begin: 1615749573.255523s

6 step training time: 0.330468s

on_train_batch_end: 1615749573.580879s

 7168/50000 [===>..........................] - ETA: 13s - loss: 5.2723 - accuracy: 0.0710
on_train_batch_begin: 1615749573.581141s

7 step training time: 0.325618s

on_train_batch_end: 1615749573.907559s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.2438 - accuracy: 0.0720
on_train_batch_begin: 1615749573.907792s

8 step training time: 0.326651s

on_train_batch_end: 1615749574.233325s

 9216/50000 [====>.........................] - ETA: 12s - loss: 5.2337 - accuracy: 0.0719
on_train_batch_begin: 1615749574.233586s

9 step training time: 0.325794s

on_train_batch_end: 1615749574.559489s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.2160 - accuracy: 0.0715
on_train_batch_begin: 1615749574.559705s

10 step training time: 0.326119s

on_train_batch_end: 1615749574.886111s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.1953 - accuracy: 0.0710
on_train_batch_begin: 1615749574.886345s

11 step training time: 0.326641s

on_train_batch_end: 1615749575.211931s

12288/50000 [======>.......................] - ETA: 12s - loss: 5.1893 - accuracy: 0.0694
on_train_batch_begin: 1615749575.212190s

12 step training time: 0.325845s

on_train_batch_end: 1615749575.538778s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.1595 - accuracy: 0.0695
on_train_batch_begin: 1615749575.538999s

13 step training time: 0.326808s

on_train_batch_end: 1615749575.864484s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.1573 - accuracy: 0.0695
on_train_batch_begin: 1615749575.864851s

14 step training time: 0.325852s

on_train_batch_end: 1615749576.191665s

15360/50000 [========>.....................] - ETA: 11s - loss: 5.1593 - accuracy: 0.0697
on_train_batch_begin: 1615749576.191993s

15 step training time: 0.327142s

on_train_batch_end: 1615749576.517136s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.1506 - accuracy: 0.0703
on_train_batch_begin: 1615749576.517406s

16 step training time: 0.325414s

on_train_batch_end: 1615749576.841204s

17408/50000 [=========>....................] - ETA: 10s - loss: 5.1311 - accuracy: 0.0704
on_train_batch_begin: 1615749576.841519s

17 step training time: 0.324112s

on_train_batch_end: 1615749577.164772s

18432/50000 [==========>...................] - ETA: 10s - loss: 5.1189 - accuracy: 0.0709
on_train_batch_begin: 1615749577.165014s

18 step training time: 0.323495s

on_train_batch_end: 1615749577.486940s

19456/50000 [==========>...................] - ETA: 9s - loss: 5.1051 - accuracy: 0.0715 
on_train_batch_begin: 1615749577.487178s

19 step training time: 0.322164s

on_train_batch_end: 1615749577.815227s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.0933 - accuracy: 0.0716
on_train_batch_begin: 1615749577.815494s

20 step training time: 0.328316s

on_train_batch_end: 1615749578.141118s

21504/50000 [===========>..................] - ETA: 9s - loss: 5.0732 - accuracy: 0.0718
on_train_batch_begin: 1615749578.141369s

21 step training time: 0.325875s

on_train_batch_end: 1615749578.470592s

22528/50000 [============>.................] - ETA: 8s - loss: 5.0653 - accuracy: 0.0719
on_train_batch_begin: 1615749578.470847s

22 step training time: 0.329478s

on_train_batch_end: 1615749578.799973s

23552/50000 [=============>................] - ETA: 8s - loss: 5.0570 - accuracy: 0.0719
on_train_batch_begin: 1615749578.800213s

23 step training time: 0.329366s

on_train_batch_end: 1615749579.129262s

24576/50000 [=============>................] - ETA: 8s - loss: 5.0442 - accuracy: 0.0720
on_train_batch_begin: 1615749579.129532s

24 step training time: 0.329319s

on_train_batch_end: 1615749579.456144s

25600/50000 [==============>...............] - ETA: 7s - loss: 5.0312 - accuracy: 0.0720
on_train_batch_begin: 1615749579.456390s

25 step training time: 0.326858s

on_train_batch_end: 1615749579.779208s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.0182 - accuracy: 0.0723
on_train_batch_begin: 1615749579.779448s

26 step training time: 0.323058s

on_train_batch_end: 1615749580.105387s

27648/50000 [===============>..............] - ETA: 7s - loss: 5.0061 - accuracy: 0.0724
on_train_batch_begin: 1615749580.105637s

27 step training time: 0.326189s

on_train_batch_end: 1615749580.432132s

28672/50000 [================>.............] - ETA: 6s - loss: 4.9921 - accuracy: 0.0725
on_train_batch_begin: 1615749580.432403s

28 step training time: 0.326766s

on_train_batch_end: 1615749580.756019s

29696/50000 [================>.............] - ETA: 6s - loss: 4.9704 - accuracy: 0.0729
on_train_batch_begin: 1615749580.756291s

29 step training time: 0.323888s

on_train_batch_end: 1615749581.083658s

30720/50000 [=================>............] - ETA: 6s - loss: 4.9538 - accuracy: 0.0731
on_train_batch_begin: 1615749581.083926s

30 step training time: 0.327635s

on_train_batch_end: 1615749581.410022s

31744/50000 [==================>...........] - ETA: 5s - loss: 4.9422 - accuracy: 0.0732
on_train_batch_begin: 1615749581.410270s

31 step training time: 0.326345s

on_train_batch_end: 1615749581.743596s

32768/50000 [==================>...........] - ETA: 5s - loss: 4.9212 - accuracy: 0.0734
on_train_batch_begin: 1615749581.743913s

32 step training time: 0.333643s

on_train_batch_end: 1615749582.070786s

33792/50000 [===================>..........] - ETA: 5s - loss: 4.9061 - accuracy: 0.0736
on_train_batch_begin: 1615749582.071072s

33 step training time: 0.327159s

on_train_batch_end: 1615749582.399037s

34816/50000 [===================>..........] - ETA: 4s - loss: 4.8884 - accuracy: 0.0736
on_train_batch_begin: 1615749582.399288s

34 step training time: 0.328216s

on_train_batch_end: 1615749582.725315s

35840/50000 [====================>.........] - ETA: 4s - loss: 4.8672 - accuracy: 0.0738
on_train_batch_begin: 1615749582.725580s

35 step training time: 0.326292s

on_train_batch_end: 1615749583.049616s

36864/50000 [=====================>........] - ETA: 4s - loss: 4.8600 - accuracy: 0.0738
on_train_batch_begin: 1615749583.049880s

36 step training time: 0.324299s

on_train_batch_end: 1615749583.360987s

37888/50000 [=====================>........] - ETA: 3s - loss: 4.8465 - accuracy: 0.0738
on_train_batch_begin: 1615749583.361256s

37 step training time: 0.311377s

on_train_batch_end: 1615749583.693767s

38912/50000 [======================>.......] - ETA: 3s - loss: 4.8329 - accuracy: 0.0738
on_train_batch_begin: 1615749583.694039s

38 step training time: 0.332783s

on_train_batch_end: 1615749584.024246s

39936/50000 [======================>.......] - ETA: 3s - loss: 4.8201 - accuracy: 0.0737
on_train_batch_begin: 1615749584.024506s

39 step training time: 0.330466s

on_train_batch_end: 1615749584.350164s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.8044 - accuracy: 0.0737
on_train_batch_begin: 1615749584.350400s

40 step training time: 0.325894s

on_train_batch_end: 1615749584.675921s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.7906 - accuracy: 0.0738
on_train_batch_begin: 1615749584.676150s

41 step training time: 0.325750s

on_train_batch_end: 1615749585.002335s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.7779 - accuracy: 0.0738
on_train_batch_begin: 1615749585.002576s

42 step training time: 0.326426s

on_train_batch_end: 1615749585.328276s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.7634 - accuracy: 0.0738
on_train_batch_begin: 1615749585.328516s

43 step training time: 0.325941s

on_train_batch_end: 1615749585.660281s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.7428 - accuracy: 0.0739
on_train_batch_begin: 1615749585.660529s

44 step training time: 0.332012s

on_train_batch_end: 1615749585.989357s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.7287 - accuracy: 0.0740
on_train_batch_begin: 1615749585.989628s

45 step training time: 0.329099s

on_train_batch_end: 1615749586.317333s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.7090 - accuracy: 0.0742
on_train_batch_begin: 1615749586.317606s

46 step training time: 0.327978s

on_train_batch_end: 1615749586.646385s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.6904 - accuracy: 0.0743
on_train_batch_begin: 1615749586.646621s

47 step training time: 0.329015s

on_train_batch_end: 1615749586.983900s

49152/50000 [============================>.] - ETA: 0s - loss: 4.6695 - accuracy: 0.0745
on_train_batch_begin: 1615749586.984195s

48 step training time: 0.337574s

on_train_batch_end: 1615749587.256117s

on_test_batch_begin: 1615749587.266349s

49 step training time: 0.282154s

on_epoch_end: 1615749588.064988s

Validation time: 0.798629s

Real time: 1615749588.064988s

Epoch time: 16.766329050064087s

50000/50000 [==============================] - 17s 335us/sample - loss: 4.6545 - accuracy: 0.0745 - val_loss: 7.3076 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615749588.065171s

Real time: 1615749588.0651762
Epoch 3/5

on_train_batch_begin: 1615749588.068389s

on_train_batch_end: 1615749588.395863s

 1024/50000 [..............................] - ETA: 15s - loss: 3.8474 - accuracy: 0.0794
on_train_batch_begin: 1615749588.396103s

1 step training time: 0.327714s

on_train_batch_end: 1615749588.724541s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.7045 - accuracy: 0.0825
on_train_batch_begin: 1615749588.724790s

2 step training time: 0.328687s

on_train_batch_end: 1615749589.055110s

 3072/50000 [>.............................] - ETA: 15s - loss: 3.6120 - accuracy: 0.0830
on_train_batch_begin: 1615749589.055363s

3 step training time: 0.330573s

on_train_batch_end: 1615749589.378966s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.6039 - accuracy: 0.0828
on_train_batch_begin: 1615749589.379205s

4 step training time: 0.323842s

on_train_batch_end: 1615749589.709046s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.5310 - accuracy: 0.0835
on_train_batch_begin: 1615749589.709319s

5 step training time: 0.330114s

on_train_batch_end: 1615749590.038749s

 6144/50000 [==>...........................] - ETA: 14s - loss: 3.5182 - accuracy: 0.0837
on_train_batch_begin: 1615749590.039033s

6 step training time: 0.329714s

on_train_batch_end: 1615749590.370463s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.4893 - accuracy: 0.0841
on_train_batch_begin: 1615749590.370699s

7 step training time: 0.331665s

on_train_batch_end: 1615749590.701067s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.4497 - accuracy: 0.0845
on_train_batch_begin: 1615749590.701326s

8 step training time: 0.330628s

on_train_batch_end: 1615749591.033926s

 9216/50000 [====>.........................] - ETA: 13s - loss: 3.4256 - accuracy: 0.0849
on_train_batch_begin: 1615749591.034169s

9 step training time: 0.332842s

on_train_batch_end: 1615749591.364917s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.4024 - accuracy: 0.0854
on_train_batch_begin: 1615749591.365164s

10 step training time: 0.330996s

on_train_batch_end: 1615749591.689867s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.3638 - accuracy: 0.0860
on_train_batch_begin: 1615749591.690116s

11 step training time: 0.324951s

on_train_batch_end: 1615749592.019267s

12288/50000 [======>.......................] - ETA: 12s - loss: 3.3425 - accuracy: 0.0864
on_train_batch_begin: 1615749592.019559s

12 step training time: 0.329444s

on_train_batch_end: 1615749592.350391s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.3071 - accuracy: 0.0869
on_train_batch_begin: 1615749592.350659s

13 step training time: 0.331100s

on_train_batch_end: 1615749592.681339s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.2692 - accuracy: 0.0874
on_train_batch_begin: 1615749592.681660s

14 step training time: 0.331001s

on_train_batch_end: 1615749593.009218s

15360/50000 [========>.....................] - ETA: 11s - loss: 3.2357 - accuracy: 0.0879
on_train_batch_begin: 1615749593.009537s

15 step training time: 0.327877s

on_train_batch_end: 1615749593.337073s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.2000 - accuracy: 0.0884
on_train_batch_begin: 1615749593.337326s

16 step training time: 0.327790s

on_train_batch_end: 1615749593.660790s

17408/50000 [=========>....................] - ETA: 10s - loss: 3.1785 - accuracy: 0.0888
on_train_batch_begin: 1615749593.661032s

17 step training time: 0.323706s

on_train_batch_end: 1615749593.987573s

18432/50000 [==========>...................] - ETA: 10s - loss: 3.1476 - accuracy: 0.0893
on_train_batch_begin: 1615749593.987798s

18 step training time: 0.326766s

on_train_batch_end: 1615749594.319760s

19456/50000 [==========>...................] - ETA: 9s - loss: 3.1271 - accuracy: 0.0896 
on_train_batch_begin: 1615749594.319985s

19 step training time: 0.332187s

on_train_batch_end: 1615749594.649719s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.1041 - accuracy: 0.0900
on_train_batch_begin: 1615749594.649965s

20 step training time: 0.329979s

on_train_batch_end: 1615749594.975673s

21504/50000 [===========>..................] - ETA: 9s - loss: 3.0783 - accuracy: 0.0904
on_train_batch_begin: 1615749594.975912s

21 step training time: 0.325948s

on_train_batch_end: 1615749595.308858s

22528/50000 [============>.................] - ETA: 8s - loss: 3.0499 - accuracy: 0.0908
on_train_batch_begin: 1615749595.309094s

22 step training time: 0.333182s

on_train_batch_end: 1615749595.639522s

23552/50000 [=============>................] - ETA: 8s - loss: 3.0222 - accuracy: 0.0911
on_train_batch_begin: 1615749595.639758s

23 step training time: 0.330664s

on_train_batch_end: 1615749595.966001s

24576/50000 [=============>................] - ETA: 8s - loss: 2.9971 - accuracy: 0.0914
on_train_batch_begin: 1615749595.966247s

24 step training time: 0.326489s

on_train_batch_end: 1615749596.293248s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.9776 - accuracy: 0.0917
on_train_batch_begin: 1615749596.293509s

25 step training time: 0.327261s

on_train_batch_end: 1615749596.620503s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.9536 - accuracy: 0.0919
on_train_batch_begin: 1615749596.620748s

26 step training time: 0.327240s

on_train_batch_end: 1615749596.950871s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.9290 - accuracy: 0.0922
on_train_batch_begin: 1615749596.951135s

27 step training time: 0.330387s

on_train_batch_end: 1615749597.279861s

28672/50000 [================>.............] - ETA: 6s - loss: 2.9103 - accuracy: 0.0925
on_train_batch_begin: 1615749597.280145s

28 step training time: 0.329009s

on_train_batch_end: 1615749597.609122s

29696/50000 [================>.............] - ETA: 6s - loss: 2.8867 - accuracy: 0.0927
on_train_batch_begin: 1615749597.609382s

29 step training time: 0.329237s

on_train_batch_end: 1615749597.934530s

30720/50000 [=================>............] - ETA: 6s - loss: 2.8639 - accuracy: 0.0929
on_train_batch_begin: 1615749597.934786s

30 step training time: 0.325404s

on_train_batch_end: 1615749598.263104s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.8451 - accuracy: 0.0931
on_train_batch_begin: 1615749598.263365s

31 step training time: 0.328579s

on_train_batch_end: 1615749598.592942s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.8223 - accuracy: 0.0933
on_train_batch_begin: 1615749598.593188s

32 step training time: 0.329823s

on_train_batch_end: 1615749598.921576s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.8050 - accuracy: 0.0935
on_train_batch_begin: 1615749598.921832s

33 step training time: 0.328644s

on_train_batch_end: 1615749599.249894s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.7910 - accuracy: 0.0936
on_train_batch_begin: 1615749599.250123s

34 step training time: 0.328291s

on_train_batch_end: 1615749599.576435s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.7808 - accuracy: 0.0938
on_train_batch_begin: 1615749599.576658s

35 step training time: 0.326536s

on_train_batch_end: 1615749599.902084s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.7742 - accuracy: 0.0940
on_train_batch_begin: 1615749599.902333s

36 step training time: 0.325675s

on_train_batch_end: 1615749600.226701s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.7632 - accuracy: 0.0941
on_train_batch_begin: 1615749600.226954s

37 step training time: 0.324620s

on_train_batch_end: 1615749600.557445s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.7588 - accuracy: 0.0943
on_train_batch_begin: 1615749600.557712s

38 step training time: 0.330759s

on_train_batch_end: 1615749600.884451s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.7510 - accuracy: 0.0945
on_train_batch_begin: 1615749600.884691s

39 step training time: 0.326979s

on_train_batch_end: 1615749601.213918s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.7457 - accuracy: 0.0946
on_train_batch_begin: 1615749601.214145s

40 step training time: 0.329454s

on_train_batch_end: 1615749601.540527s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.7428 - accuracy: 0.0947
on_train_batch_begin: 1615749601.540807s

41 step training time: 0.326661s

on_train_batch_end: 1615749601.865984s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.7375 - accuracy: 0.0948
on_train_batch_begin: 1615749601.866283s

42 step training time: 0.325476s

on_train_batch_end: 1615749602.191841s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.7336 - accuracy: 0.0949
on_train_batch_begin: 1615749602.192156s

43 step training time: 0.325873s

on_train_batch_end: 1615749602.516396s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.7287 - accuracy: 0.0950
on_train_batch_begin: 1615749602.516670s

44 step training time: 0.324514s

on_train_batch_end: 1615749602.841899s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.7288 - accuracy: 0.0951
on_train_batch_begin: 1615749602.842325s

45 step training time: 0.325655s

on_train_batch_end: 1615749603.169464s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.7220 - accuracy: 0.0952
on_train_batch_begin: 1615749603.169747s

46 step training time: 0.327422s

on_train_batch_end: 1615749603.497456s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.7146 - accuracy: 0.0953
on_train_batch_begin: 1615749603.497739s

47 step training time: 0.327992s

on_train_batch_end: 1615749603.819987s

49152/50000 [============================>.] - ETA: 0s - loss: 2.7048 - accuracy: 0.0954
on_train_batch_begin: 1615749603.820287s

48 step training time: 0.322548s

on_train_batch_end: 1615749604.093637s

on_test_batch_begin: 1615749604.105396s

49 step training time: 0.285109s

on_epoch_end: 1615749604.932649s

Validation time: 0.827241s

Real time: 1615749604.932649s

Epoch time: 16.8674898147583s

50000/50000 [==============================] - 17s 337us/sample - loss: 2.6980 - accuracy: 0.0955 - val_loss: 7.4021 - val_accuracy: 0.1000

on_epoch_begin: 1615749604.932831s

Real time: 1615749604.932836
Epoch 4/5

on_train_batch_begin: 1615749604.936168s

on_train_batch_end: 1615749605.259714s

 1024/50000 [..............................] - ETA: 15s - loss: 2.1673 - accuracy: 0.1002
on_train_batch_begin: 1615749605.259929s

1 step training time: 0.323762s

on_train_batch_end: 1615749605.579563s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.2252 - accuracy: 0.0995
on_train_batch_begin: 1615749605.579787s

2 step training time: 0.319857s

on_train_batch_end: 1615749605.905069s

 3072/50000 [>.............................] - ETA: 14s - loss: 2.1894 - accuracy: 0.0996
on_train_batch_begin: 1615749605.905302s

3 step training time: 0.325515s

on_train_batch_end: 1615749606.226887s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.1719 - accuracy: 0.0998
on_train_batch_begin: 1615749606.227250s

4 step training time: 0.321948s

on_train_batch_end: 1615749606.553868s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.1390 - accuracy: 0.0998
on_train_batch_begin: 1615749606.554160s

5 step training time: 0.326910s

on_train_batch_end: 1615749606.881266s

 6144/50000 [==>...........................] - ETA: 13s - loss: 2.1508 - accuracy: 0.0998
on_train_batch_begin: 1615749606.881539s

6 step training time: 0.327379s

on_train_batch_end: 1615749607.203841s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.1361 - accuracy: 0.0999
on_train_batch_begin: 1615749607.204128s

7 step training time: 0.322589s

on_train_batch_end: 1615749607.526886s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.1186 - accuracy: 0.0999
on_train_batch_begin: 1615749607.527148s

8 step training time: 0.323020s

on_train_batch_end: 1615749607.852333s

 9216/50000 [====>.........................] - ETA: 12s - loss: 2.1325 - accuracy: 0.1000
on_train_batch_begin: 1615749607.852595s

9 step training time: 0.325447s

on_train_batch_end: 1615749608.177606s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.1443 - accuracy: 0.1000
on_train_batch_begin: 1615749608.177836s

10 step training time: 0.325241s

on_train_batch_end: 1615749608.501735s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.1283 - accuracy: 0.1001
on_train_batch_begin: 1615749608.501995s

11 step training time: 0.324159s

on_train_batch_end: 1615749608.825249s

12288/50000 [======>.......................] - ETA: 11s - loss: 2.1280 - accuracy: 0.1002
on_train_batch_begin: 1615749608.825483s

12 step training time: 0.323488s

on_train_batch_end: 1615749609.147197s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.1292 - accuracy: 0.1001
on_train_batch_begin: 1615749609.147414s

13 step training time: 0.321931s

on_train_batch_end: 1615749609.470822s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.1060 - accuracy: 0.1001
on_train_batch_begin: 1615749609.471035s

14 step training time: 0.323620s

on_train_batch_end: 1615749609.798127s

15360/50000 [========>.....................] - ETA: 10s - loss: 2.1039 - accuracy: 0.1001
on_train_batch_begin: 1615749609.798372s

15 step training time: 0.327338s

on_train_batch_end: 1615749610.124721s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.1008 - accuracy: 0.1001
on_train_batch_begin: 1615749610.124957s

16 step training time: 0.326585s

on_train_batch_end: 1615749610.447360s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.0896 - accuracy: 0.1001
on_train_batch_begin: 1615749610.447598s

17 step training time: 0.322641s

on_train_batch_end: 1615749610.772254s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.0906 - accuracy: 0.1001
on_train_batch_begin: 1615749610.772500s

18 step training time: 0.324902s

on_train_batch_end: 1615749611.098862s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.0797 - accuracy: 0.1001 
on_train_batch_begin: 1615749611.099105s

19 step training time: 0.326606s

on_train_batch_end: 1615749611.421161s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.0768 - accuracy: 0.1001
on_train_batch_begin: 1615749611.421400s

20 step training time: 0.322295s

on_train_batch_end: 1615749611.745506s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.0637 - accuracy: 0.1001
on_train_batch_begin: 1615749611.745743s

21 step training time: 0.324343s

on_train_batch_end: 1615749612.068133s

22528/50000 [============>.................] - ETA: 8s - loss: 2.0622 - accuracy: 0.1001
on_train_batch_begin: 1615749612.068367s

22 step training time: 0.322623s

on_train_batch_end: 1615749612.390157s

23552/50000 [=============>................] - ETA: 8s - loss: 2.0509 - accuracy: 0.1001
on_train_batch_begin: 1615749612.390440s

23 step training time: 0.322074s

on_train_batch_end: 1615749612.716698s

24576/50000 [=============>................] - ETA: 8s - loss: 2.0411 - accuracy: 0.1001
on_train_batch_begin: 1615749612.716965s

24 step training time: 0.326525s

on_train_batch_end: 1615749613.041475s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.0326 - accuracy: 0.1001
on_train_batch_begin: 1615749613.041767s

25 step training time: 0.324802s

on_train_batch_end: 1615749613.365363s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.0188 - accuracy: 0.1001
on_train_batch_begin: 1615749613.365623s

26 step training time: 0.323855s

on_train_batch_end: 1615749613.690900s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.0122 - accuracy: 0.1001
on_train_batch_begin: 1615749613.691145s

27 step training time: 0.325523s

on_train_batch_end: 1615749614.005829s

28672/50000 [================>.............] - ETA: 6s - loss: 2.0127 - accuracy: 0.1001
on_train_batch_begin: 1615749614.006086s

28 step training time: 0.314941s

on_train_batch_end: 1615749614.326530s

29696/50000 [================>.............] - ETA: 6s - loss: 1.9967 - accuracy: 0.1001
on_train_batch_begin: 1615749614.326763s

29 step training time: 0.320677s

on_train_batch_end: 1615749614.652314s

30720/50000 [=================>............] - ETA: 6s - loss: 1.9862 - accuracy: 0.1001
on_train_batch_begin: 1615749614.652594s

30 step training time: 0.325832s

on_train_batch_end: 1615749614.975450s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.9790 - accuracy: 0.1001
on_train_batch_begin: 1615749614.975692s

31 step training time: 0.323098s

on_train_batch_end: 1615749615.299235s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.9714 - accuracy: 0.1001
on_train_batch_begin: 1615749615.299458s

32 step training time: 0.323765s

on_train_batch_end: 1615749615.623463s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.9624 - accuracy: 0.1001
on_train_batch_begin: 1615749615.623685s

33 step training time: 0.324227s

on_train_batch_end: 1615749615.945896s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.9546 - accuracy: 0.1001
on_train_batch_begin: 1615749615.946127s

34 step training time: 0.322442s

on_train_batch_end: 1615749616.269931s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.9439 - accuracy: 0.1002
on_train_batch_begin: 1615749616.270153s

35 step training time: 0.324026s

on_train_batch_end: 1615749616.599741s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.9364 - accuracy: 0.1001
on_train_batch_begin: 1615749616.600075s

36 step training time: 0.329922s

on_train_batch_end: 1615749616.922693s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.9278 - accuracy: 0.1002
on_train_batch_begin: 1615749616.922947s

37 step training time: 0.322872s

on_train_batch_end: 1615749617.247554s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.9217 - accuracy: 0.1002
on_train_batch_begin: 1615749617.247786s

38 step training time: 0.324839s

on_train_batch_end: 1615749617.574010s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.9131 - accuracy: 0.1002
on_train_batch_begin: 1615749617.574308s

39 step training time: 0.326522s

on_train_batch_end: 1615749617.898047s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.9048 - accuracy: 0.1001
on_train_batch_begin: 1615749617.898318s

40 step training time: 0.324010s

on_train_batch_end: 1615749618.224848s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.8961 - accuracy: 0.1001
on_train_batch_begin: 1615749618.225116s

41 step training time: 0.326799s

on_train_batch_end: 1615749618.551517s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.8903 - accuracy: 0.1001
on_train_batch_begin: 1615749618.551748s

42 step training time: 0.326631s

on_train_batch_end: 1615749618.874641s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.8805 - accuracy: 0.1002
on_train_batch_begin: 1615749618.874882s

43 step training time: 0.323134s

on_train_batch_end: 1615749619.201141s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.8713 - accuracy: 0.1002
on_train_batch_begin: 1615749619.201390s

44 step training time: 0.326508s

on_train_batch_end: 1615749619.528282s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.8656 - accuracy: 0.1002
on_train_batch_begin: 1615749619.528513s

45 step training time: 0.327122s

on_train_batch_end: 1615749619.853983s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.8585 - accuracy: 0.1002
on_train_batch_begin: 1615749619.854249s

46 step training time: 0.325736s

on_train_batch_end: 1615749620.180379s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.8497 - accuracy: 0.1002
on_train_batch_begin: 1615749620.180612s

47 step training time: 0.326363s

on_train_batch_end: 1615749620.505208s

49152/50000 [============================>.] - ETA: 0s - loss: 1.8407 - accuracy: 0.1002
on_train_batch_begin: 1615749620.505433s

48 step training time: 0.324821s

on_train_batch_end: 1615749620.779291s

on_test_batch_begin: 1615749620.791387s

49 step training time: 0.285954s

on_epoch_end: 1615749621.572627s

Validation time: 0.781230s

Real time: 1615749621.572627s

Epoch time: 16.639806747436523s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.8366 - accuracy: 0.1002 - val_loss: 6.7881 - val_accuracy: 0.0999

on_epoch_begin: 1615749621.572812s

Real time: 1615749621.5728185
Epoch 5/5

on_train_batch_begin: 1615749621.576205s

on_train_batch_end: 1615749621.901232s

 1024/50000 [..............................] - ETA: 15s - loss: 1.2612 - accuracy: 0.1000
on_train_batch_begin: 1615749621.901522s

1 step training time: 0.325316s

on_train_batch_end: 1615749622.222560s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.2701 - accuracy: 0.1002
on_train_batch_begin: 1615749622.222819s

2 step training time: 0.321298s

on_train_batch_end: 1615749622.549663s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.3058 - accuracy: 0.1002
on_train_batch_begin: 1615749622.549953s

3 step training time: 0.327133s

on_train_batch_end: 1615749622.874355s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.3474 - accuracy: 0.1002
on_train_batch_begin: 1615749622.874666s

4 step training time: 0.324713s

on_train_batch_end: 1615749623.198273s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.3690 - accuracy: 0.1001
on_train_batch_begin: 1615749623.198553s

5 step training time: 0.323887s

on_train_batch_end: 1615749623.517515s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.3753 - accuracy: 0.1001
on_train_batch_begin: 1615749623.517770s

6 step training time: 0.319217s

on_train_batch_end: 1615749623.840700s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.3548 - accuracy: 0.1002
on_train_batch_begin: 1615749623.840940s

7 step training time: 0.323170s

on_train_batch_end: 1615749624.166182s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.3473 - accuracy: 0.1002
on_train_batch_begin: 1615749624.166419s

8 step training time: 0.325479s

on_train_batch_end: 1615749624.490513s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.3352 - accuracy: 0.1001
on_train_batch_begin: 1615749624.490754s

9 step training time: 0.324335s

on_train_batch_end: 1615749624.814537s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.3203 - accuracy: 0.1001
on_train_batch_begin: 1615749624.814780s

10 step training time: 0.324026s

on_train_batch_end: 1615749625.139576s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.3119 - accuracy: 0.1002
on_train_batch_begin: 1615749625.139802s

11 step training time: 0.325022s

on_train_batch_end: 1615749625.466221s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.3045 - accuracy: 0.1002
on_train_batch_begin: 1615749625.466448s

12 step training time: 0.326645s

on_train_batch_end: 1615749625.792033s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.2976 - accuracy: 0.1002
on_train_batch_begin: 1615749625.792289s

13 step training time: 0.325841s

on_train_batch_end: 1615749626.116190s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.2841 - accuracy: 0.1002
on_train_batch_begin: 1615749626.116450s

14 step training time: 0.324162s

on_train_batch_end: 1615749626.442845s

15360/50000 [========>.....................] - ETA: 10s - loss: 1.2746 - accuracy: 0.1002
on_train_batch_begin: 1615749626.443114s

15 step training time: 0.326664s

on_train_batch_end: 1615749626.771494s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.2679 - accuracy: 0.1002
on_train_batch_begin: 1615749626.771754s

16 step training time: 0.328640s

on_train_batch_end: 1615749627.095784s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.2687 - accuracy: 0.1002
on_train_batch_begin: 1615749627.096039s

17 step training time: 0.324285s

on_train_batch_end: 1615749627.421251s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.2570 - accuracy: 0.1002
on_train_batch_begin: 1615749627.421512s

18 step training time: 0.325473s

on_train_batch_end: 1615749627.746825s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.2477 - accuracy: 0.1002 
on_train_batch_begin: 1615749627.747114s

19 step training time: 0.325602s

on_train_batch_end: 1615749628.069959s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.2411 - accuracy: 0.1002
on_train_batch_begin: 1615749628.070233s

20 step training time: 0.323119s

on_train_batch_end: 1615749628.394527s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.2366 - accuracy: 0.1002
on_train_batch_begin: 1615749628.394766s

21 step training time: 0.324533s

on_train_batch_end: 1615749628.718452s

22528/50000 [============>.................] - ETA: 8s - loss: 1.2337 - accuracy: 0.1002
on_train_batch_begin: 1615749628.718686s

22 step training time: 0.323920s

on_train_batch_end: 1615749629.043057s

23552/50000 [=============>................] - ETA: 8s - loss: 1.2256 - accuracy: 0.1002
on_train_batch_begin: 1615749629.043309s

23 step training time: 0.324623s

on_train_batch_end: 1615749629.369580s

24576/50000 [=============>................] - ETA: 8s - loss: 1.2216 - accuracy: 0.1002
on_train_batch_begin: 1615749629.369817s

24 step training time: 0.326507s

on_train_batch_end: 1615749629.692731s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.2158 - accuracy: 0.1003
on_train_batch_begin: 1615749629.692969s

25 step training time: 0.323153s

on_train_batch_end: 1615749630.016178s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.2125 - accuracy: 0.1002
on_train_batch_begin: 1615749630.016418s

26 step training time: 0.323448s

on_train_batch_end: 1615749630.342083s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.2068 - accuracy: 0.1002
on_train_batch_begin: 1615749630.342318s

27 step training time: 0.325900s

on_train_batch_end: 1615749630.666013s

28672/50000 [================>.............] - ETA: 6s - loss: 1.2003 - accuracy: 0.1003
on_train_batch_begin: 1615749630.666235s

28 step training time: 0.323918s

on_train_batch_end: 1615749630.994106s

29696/50000 [================>.............] - ETA: 6s - loss: 1.2037 - accuracy: 0.1002
on_train_batch_begin: 1615749630.994355s

29 step training time: 0.328120s

on_train_batch_end: 1615749631.319406s

30720/50000 [=================>............] - ETA: 6s - loss: 1.2033 - accuracy: 0.1002
on_train_batch_begin: 1615749631.319630s

30 step training time: 0.325274s

on_train_batch_end: 1615749631.641620s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.1974 - accuracy: 0.1002
on_train_batch_begin: 1615749631.641865s

31 step training time: 0.322236s

on_train_batch_end: 1615749631.965058s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.1906 - accuracy: 0.1002
on_train_batch_begin: 1615749631.965321s

32 step training time: 0.323456s

on_train_batch_end: 1615749632.289388s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.1890 - accuracy: 0.1002
on_train_batch_begin: 1615749632.289661s

33 step training time: 0.324340s

on_train_batch_end: 1615749632.615139s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.1858 - accuracy: 0.1002
on_train_batch_begin: 1615749632.615426s

34 step training time: 0.325765s

on_train_batch_end: 1615749632.941214s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.1851 - accuracy: 0.1002
on_train_batch_begin: 1615749632.941513s

35 step training time: 0.326087s

on_train_batch_end: 1615749633.270137s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.1789 - accuracy: 0.1002
on_train_batch_begin: 1615749633.270391s

36 step training time: 0.328878s

on_train_batch_end: 1615749633.593481s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.1766 - accuracy: 0.1002
on_train_batch_begin: 1615749633.593730s

37 step training time: 0.323339s

on_train_batch_end: 1615749633.916556s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.1767 - accuracy: 0.1002
on_train_batch_begin: 1615749633.916822s

38 step training time: 0.323092s

on_train_batch_end: 1615749634.241516s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.1749 - accuracy: 0.1002
on_train_batch_begin: 1615749634.241768s

39 step training time: 0.324946s

on_train_batch_end: 1615749634.565927s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.1727 - accuracy: 0.1003
on_train_batch_begin: 1615749634.566156s

40 step training time: 0.324389s

on_train_batch_end: 1615749634.890028s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.1674 - accuracy: 0.1003
on_train_batch_begin: 1615749634.890287s

41 step training time: 0.324131s

on_train_batch_end: 1615749635.215276s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.1639 - accuracy: 0.1003
on_train_batch_begin: 1615749635.215526s

42 step training time: 0.325240s

on_train_batch_end: 1615749635.538853s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.1599 - accuracy: 0.1002
on_train_batch_begin: 1615749635.539092s

43 step training time: 0.323566s

on_train_batch_end: 1615749635.861620s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.1591 - accuracy: 0.1002
on_train_batch_begin: 1615749635.861908s

44 step training time: 0.322816s

on_train_batch_end: 1615749636.190250s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.1586 - accuracy: 0.1002
on_train_batch_begin: 1615749636.190511s

45 step training time: 0.328602s

on_train_batch_end: 1615749636.514203s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.1571 - accuracy: 0.1002
on_train_batch_begin: 1615749636.514477s

46 step training time: 0.323966s

on_train_batch_end: 1615749636.837340s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1547 - accuracy: 0.1002
on_train_batch_begin: 1615749636.837644s

47 step training time: 0.323167s

on_train_batch_end: 1615749637.161997s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1535 - accuracy: 0.1003
on_train_batch_begin: 1615749637.162297s

48 step training time: 0.324652s

on_train_batch_end: 1615749637.430733s

on_test_batch_begin: 1615749637.442089s

49 step training time: 0.279792s

on_epoch_end: 1615749638.224687s

Validation time: 0.782585s

Real time: 1615749638.224687s

Epoch time: 16.651883840560913s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.1522 - accuracy: 0.1002 - val_loss: 6.7737 - val_accuracy: 0.0999
Tempo do fit: 113.09402799606323