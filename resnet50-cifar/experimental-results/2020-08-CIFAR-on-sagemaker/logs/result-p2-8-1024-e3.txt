wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:49
   204800/170498071 [..............................] - ETA: 1:17
  1056768/170498071 [..............................] - ETA: 23s 
  3153920/170498071 [..............................] - ETA: 10s
  6602752/170498071 [>.............................] - ETA: 6s 
 10002432/170498071 [>.............................] - ETA: 4s
 13377536/170498071 [=>............................] - ETA: 4s
 16588800/170498071 [=>............................] - ETA: 3s
 19865600/170498071 [==>...........................] - ETA: 3s
 23257088/170498071 [===>..........................] - ETA: 3s
 26533888/170498071 [===>..........................] - ETA: 3s
 29892608/170498071 [====>.........................] - ETA: 2s
 32497664/170498071 [====>.........................] - ETA: 2s
 33955840/170498071 [====>.........................] - ETA: 2s
 37347328/170498071 [=====>........................] - ETA: 2s
 40738816/170498071 [======>.......................] - ETA: 2s
 43229184/170498071 [======>.......................] - ETA: 2s
 46129152/170498071 [=======>......................] - ETA: 2s
 49602560/170498071 [=======>......................] - ETA: 2s
 52862976/170498071 [========>.....................] - ETA: 2s
 55812096/170498071 [========>.....................] - ETA: 2s
 57712640/170498071 [=========>....................] - ETA: 2s
 60907520/170498071 [=========>....................] - ETA: 2s
 63873024/170498071 [==========>...................] - ETA: 2s
 67313664/170498071 [==========>...................] - ETA: 2s
 70680576/170498071 [===========>..................] - ETA: 1s
 74072064/170498071 [============>.................] - ETA: 1s
 77422592/170498071 [============>.................] - ETA: 1s
 80453632/170498071 [=============>................] - ETA: 1s
 83812352/170498071 [=============>................] - ETA: 1s
 87121920/170498071 [==============>...............] - ETA: 1s
 89366528/170498071 [==============>...............] - ETA: 1s
 92766208/170498071 [===============>..............] - ETA: 1s
 95936512/170498071 [===============>..............] - ETA: 1s
 99262464/170498071 [================>.............] - ETA: 1s
102637568/170498071 [=================>............] - ETA: 1s
106029056/170498071 [=================>............] - ETA: 1s
109420544/170498071 [==================>...........] - ETA: 1s
112795648/170498071 [==================>...........] - ETA: 1s
116088832/170498071 [===================>..........] - ETA: 0s
119398400/170498071 [====================>.........] - ETA: 0s
122626048/170498071 [====================>.........] - ETA: 0s
126001152/170498071 [=====================>........] - ETA: 0s
129327104/170498071 [=====================>........] - ETA: 0s
132685824/170498071 [======================>.......] - ETA: 0s
136077312/170498071 [======================>.......] - ETA: 0s
139452416/170498071 [=======================>......] - ETA: 0s
142794752/170498071 [========================>.....] - ETA: 0s
146137088/170498071 [========================>.....] - ETA: 0s
149495808/170498071 [=========================>....] - ETA: 0s
152690688/170498071 [=========================>....] - ETA: 0s
156000256/170498071 [==========================>...] - ETA: 0s
159342592/170498071 [===========================>..] - ETA: 0s
162684928/170498071 [===========================>..] - ETA: 0s
166060032/170498071 [============================>.] - ETA: 0s
169435136/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 6s
 3407872/94765736 [>.............................] - ETA: 1s
 9388032/94765736 [=>............................] - ETA: 0s
12320768/94765736 [==>...........................] - ETA: 1s
17211392/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 1s
21200896/94765736 [=====>........................] - ETA: 1s
25976832/94765736 [=======>......................] - ETA: 1s
28286976/94765736 [=======>......................] - ETA: 1s
32645120/94765736 [=========>....................] - ETA: 0s
37330944/94765736 [==========>...................] - ETA: 0s
44236800/94765736 [=============>................] - ETA: 0s
50995200/94765736 [===============>..............] - ETA: 0s
57606144/94765736 [=================>............] - ETA: 0s
63488000/94765736 [===================>..........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
67321856/94765736 [====================>.........] - ETA: 0s
72876032/94765736 [======================>.......] - ETA: 0s
76308480/94765736 [=======================>......] - ETA: 0s
81379328/94765736 [========================>.....] - ETA: 0s
88023040/94765736 [==========================>...] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 29.056793212890625
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1607801102.333492s

Real time: 1607801102.3335195
Epoch 1/5

on_train_batch_begin: 1607801103.411481s

on_train_batch_end: 1607801240.362118s

 1024/50000 [..............................] - ETA: 1:50:01 - loss: 16.7865 - accuracy: 2.4414e-04
on_train_batch_begin: 1607801240.362963s

1 step training time: 136.951482s

on_train_batch_end: 1607801240.614143s

 2048/50000 [>.............................] - ETA: 53:57 - loss: 14.9844 - accuracy: 2.3651e-04  
on_train_batch_begin: 1607801240.614682s

2 step training time: 0.251719s

on_train_batch_end: 1607801240.844776s

 3072/50000 [>.............................] - ETA: 35:15 - loss: 13.1184 - accuracy: 3.2806e-04
on_train_batch_begin: 1607801240.845275s

3 step training time: 0.230592s

on_train_batch_end: 1607801241.051685s

 4096/50000 [=>............................] - ETA: 25:54 - loss: 11.9860 - accuracy: 0.0011    
on_train_batch_begin: 1607801241.052171s

4 step training time: 0.206896s

on_train_batch_end: 1607801241.259426s

 5120/50000 [==>...........................] - ETA: 20:17 - loss: 11.2554 - accuracy: 0.0019
on_train_batch_begin: 1607801241.259920s

5 step training time: 0.207749s

on_train_batch_end: 1607801241.508093s

 6144/50000 [==>...........................] - ETA: 16:33 - loss: 10.7254 - accuracy: 0.0045
on_train_batch_begin: 1607801241.508581s

6 step training time: 0.248662s

on_train_batch_end: 1607801241.756371s

 7168/50000 [===>..........................] - ETA: 13:53 - loss: 10.3180 - accuracy: 0.0071
on_train_batch_begin: 1607801241.756851s

7 step training time: 0.248270s

on_train_batch_end: 1607801242.000327s

 8192/50000 [===>..........................] - ETA: 11:52 - loss: 10.0243 - accuracy: 0.0095
on_train_batch_begin: 1607801242.000799s

8 step training time: 0.243948s

on_train_batch_end: 1607801242.204964s

 9216/50000 [====>.........................] - ETA: 10:18 - loss: 9.7523 - accuracy: 0.0122 
on_train_batch_begin: 1607801242.205432s

9 step training time: 0.204633s

on_train_batch_end: 1607801242.411337s

10240/50000 [=====>........................] - ETA: 9:03 - loss: 9.5334 - accuracy: 0.0152 
on_train_batch_begin: 1607801242.411803s

10 step training time: 0.206370s

on_train_batch_end: 1607801242.617928s

11264/50000 [=====>........................] - ETA: 8:02 - loss: 9.3246 - accuracy: 0.0190
on_train_batch_begin: 1607801242.618391s

11 step training time: 0.206588s

on_train_batch_end: 1607801242.860468s

12288/50000 [======>.......................] - ETA: 7:11 - loss: 9.1565 - accuracy: 0.0223
on_train_batch_begin: 1607801242.860932s

12 step training time: 0.242541s

on_train_batch_end: 1607801243.095583s

13312/50000 [======>.......................] - ETA: 6:27 - loss: 9.0088 - accuracy: 0.0254
on_train_batch_begin: 1607801243.096050s

13 step training time: 0.235117s

on_train_batch_end: 1607801243.342197s

14336/50000 [=======>......................] - ETA: 5:50 - loss: 8.8677 - accuracy: 0.0285
on_train_batch_begin: 1607801243.342657s

14 step training time: 0.246607s

on_train_batch_end: 1607801243.571980s

15360/50000 [========>.....................] - ETA: 5:18 - loss: 8.7445 - accuracy: 0.0308
on_train_batch_begin: 1607801243.572448s

15 step training time: 0.229792s

on_train_batch_end: 1607801243.779152s

16384/50000 [========>.....................] - ETA: 4:50 - loss: 8.6373 - accuracy: 0.0331
on_train_batch_begin: 1607801243.779650s

16 step training time: 0.207201s

on_train_batch_end: 1607801244.026024s

17408/50000 [=========>....................] - ETA: 4:25 - loss: 8.5358 - accuracy: 0.0355
on_train_batch_begin: 1607801244.026490s

17 step training time: 0.246841s

on_train_batch_end: 1607801244.255388s

18432/50000 [==========>...................] - ETA: 4:03 - loss: 8.4272 - accuracy: 0.0375
on_train_batch_begin: 1607801244.255854s

18 step training time: 0.229364s

on_train_batch_end: 1607801244.460301s

19456/50000 [==========>...................] - ETA: 3:43 - loss: 8.3365 - accuracy: 0.0397
on_train_batch_begin: 1607801244.460762s

19 step training time: 0.204908s

on_train_batch_end: 1607801244.666105s

20480/50000 [===========>..................] - ETA: 3:25 - loss: 8.2472 - accuracy: 0.0415
on_train_batch_begin: 1607801244.666574s

20 step training time: 0.205812s

on_train_batch_end: 1607801244.873214s

21504/50000 [===========>..................] - ETA: 3:08 - loss: 8.1623 - accuracy: 0.0434
on_train_batch_begin: 1607801244.873679s

21 step training time: 0.207105s

on_train_batch_end: 1607801245.078117s

22528/50000 [============>.................] - ETA: 2:54 - loss: 8.0905 - accuracy: 0.0452
on_train_batch_begin: 1607801245.078584s

22 step training time: 0.204905s

on_train_batch_end: 1607801245.324221s

23552/50000 [=============>................] - ETA: 2:40 - loss: 8.0157 - accuracy: 0.0468
on_train_batch_begin: 1607801245.324697s

23 step training time: 0.246113s

on_train_batch_end: 1607801245.570295s

24576/50000 [=============>................] - ETA: 2:28 - loss: 7.9459 - accuracy: 0.0483
on_train_batch_begin: 1607801245.570759s

24 step training time: 0.246062s

on_train_batch_end: 1607801245.775586s

25600/50000 [==============>...............] - ETA: 2:16 - loss: 7.8760 - accuracy: 0.0497
on_train_batch_begin: 1607801245.776047s

25 step training time: 0.205288s

on_train_batch_end: 1607801245.981452s

26624/50000 [==============>...............] - ETA: 2:06 - loss: 7.8093 - accuracy: 0.0513
on_train_batch_begin: 1607801245.981909s

26 step training time: 0.205862s

on_train_batch_end: 1607801246.185509s

27648/50000 [===============>..............] - ETA: 1:56 - loss: 7.7488 - accuracy: 0.0526
on_train_batch_begin: 1607801246.185970s

27 step training time: 0.204060s

on_train_batch_end: 1607801246.391474s

28672/50000 [================>.............] - ETA: 1:47 - loss: 7.6879 - accuracy: 0.0538
on_train_batch_begin: 1607801246.391936s

28 step training time: 0.205967s

on_train_batch_end: 1607801246.597050s

29696/50000 [================>.............] - ETA: 1:38 - loss: 7.6290 - accuracy: 0.0548
on_train_batch_begin: 1607801246.597540s

29 step training time: 0.205604s

on_train_batch_end: 1607801246.803535s

30720/50000 [=================>............] - ETA: 1:30 - loss: 7.5742 - accuracy: 0.0560
on_train_batch_begin: 1607801246.804017s

30 step training time: 0.206477s

on_train_batch_end: 1607801247.010761s

31744/50000 [==================>...........] - ETA: 1:23 - loss: 7.5166 - accuracy: 0.0567
on_train_batch_begin: 1607801247.011247s

31 step training time: 0.207230s

on_train_batch_end: 1607801247.218131s

32768/50000 [==================>...........] - ETA: 1:16 - loss: 7.4610 - accuracy: 0.0578
on_train_batch_begin: 1607801247.218613s

32 step training time: 0.207366s

on_train_batch_end: 1607801247.464283s

33792/50000 [===================>..........] - ETA: 1:09 - loss: 7.4051 - accuracy: 0.0586
on_train_batch_begin: 1607801247.464766s

33 step training time: 0.246153s

on_train_batch_end: 1607801247.695830s

34816/50000 [===================>..........] - ETA: 1:03 - loss: 7.3535 - accuracy: 0.0595
on_train_batch_begin: 1607801247.696350s

34 step training time: 0.231584s

on_train_batch_end: 1607801247.902558s

35840/50000 [====================>.........] - ETA: 57s - loss: 7.2993 - accuracy: 0.0603 
on_train_batch_begin: 1607801247.903038s

35 step training time: 0.206688s

on_train_batch_end: 1607801248.110319s

36864/50000 [=====================>........] - ETA: 51s - loss: 7.2457 - accuracy: 0.0609
on_train_batch_begin: 1607801248.110804s

36 step training time: 0.207766s

on_train_batch_end: 1607801248.318853s

37888/50000 [=====================>........] - ETA: 46s - loss: 7.1887 - accuracy: 0.0615
on_train_batch_begin: 1607801248.319341s

37 step training time: 0.208537s

on_train_batch_end: 1607801248.524189s

38912/50000 [======================>.......] - ETA: 41s - loss: 7.1362 - accuracy: 0.0619
on_train_batch_begin: 1607801248.524650s

38 step training time: 0.205310s

on_train_batch_end: 1607801248.775576s

39936/50000 [======================>.......] - ETA: 36s - loss: 7.0847 - accuracy: 0.0623
on_train_batch_begin: 1607801248.776039s

39 step training time: 0.251389s

on_train_batch_end: 1607801249.041580s

40960/50000 [=======================>......] - ETA: 32s - loss: 7.0375 - accuracy: 0.0625
on_train_batch_begin: 1607801249.042040s

40 step training time: 0.266001s

on_train_batch_end: 1607801249.279188s

41984/50000 [========================>.....] - ETA: 28s - loss: 6.9843 - accuracy: 0.0628
on_train_batch_begin: 1607801249.279682s

41 step training time: 0.237642s

on_train_batch_end: 1607801249.487163s

43008/50000 [========================>.....] - ETA: 23s - loss: 6.9294 - accuracy: 0.0630
on_train_batch_begin: 1607801249.487654s

42 step training time: 0.207972s

on_train_batch_end: 1607801249.692075s

44032/50000 [=========================>....] - ETA: 19s - loss: 6.8788 - accuracy: 0.0632
on_train_batch_begin: 1607801249.692531s

43 step training time: 0.204877s

on_train_batch_end: 1607801249.898259s

45056/50000 [==========================>...] - ETA: 16s - loss: 6.8329 - accuracy: 0.0633
on_train_batch_begin: 1607801249.898725s

44 step training time: 0.206194s

on_train_batch_end: 1607801250.104793s

46080/50000 [==========================>...] - ETA: 12s - loss: 6.7840 - accuracy: 0.0635
on_train_batch_begin: 1607801250.105254s

45 step training time: 0.206529s

on_train_batch_end: 1607801250.310887s

47104/50000 [===========================>..] - ETA: 9s - loss: 6.7351 - accuracy: 0.0638 
on_train_batch_begin: 1607801250.311373s

46 step training time: 0.206119s

on_train_batch_end: 1607801250.515366s

48128/50000 [===========================>..] - ETA: 5s - loss: 6.6840 - accuracy: 0.0641
on_train_batch_begin: 1607801250.515827s

47 step training time: 0.204455s

on_train_batch_end: 1607801250.762853s

49152/50000 [============================>.] - ETA: 2s - loss: 6.6376 - accuracy: 0.0644
on_train_batch_begin: 1607801250.763358s

48 step training time: 0.247530s

on_train_batch_end: 1607801258.328266s

on_test_batch_begin: 1607801258.734016s

49 step training time: 7.970658s

on_epoch_end: 1607801275.072476s

Validation time: 16.338434s

Real time: 1607801275.072476s

Epoch time: 172.73899102210999s

50000/50000 [==============================] - 173s 3ms/sample - loss: 6.5962 - accuracy: 0.0647 - val_loss: 45.7696 - val_accuracy: 0.0000e+00

on_epoch_begin: 1607801275.072794s

Real time: 1607801275.072805
Epoch 2/5

on_train_batch_begin: 1607801275.081401s

on_train_batch_end: 1607801275.288585s

 1024/50000 [..............................] - ETA: 10s - loss: 4.1690 - accuracy: 0.0809
on_train_batch_begin: 1607801275.289060s

1 step training time: 0.207658s

on_train_batch_end: 1607801275.493244s

 2048/50000 [>.............................] - ETA: 9s - loss: 4.0883 - accuracy: 0.0826 
on_train_batch_begin: 1607801275.493709s

2 step training time: 0.204649s

on_train_batch_end: 1607801275.700465s

 3072/50000 [>.............................] - ETA: 9s - loss: 4.0277 - accuracy: 0.0838
on_train_batch_begin: 1607801275.700932s

3 step training time: 0.207223s

on_train_batch_end: 1607801275.907502s

 4096/50000 [=>............................] - ETA: 9s - loss: 3.9431 - accuracy: 0.0860
on_train_batch_begin: 1607801275.907959s

4 step training time: 0.207027s

on_train_batch_end: 1607801276.113279s

 5120/50000 [==>...........................] - ETA: 9s - loss: 3.9076 - accuracy: 0.0872
on_train_batch_begin: 1607801276.113764s

5 step training time: 0.205806s

on_train_batch_end: 1607801276.319033s

 6144/50000 [==>...........................] - ETA: 8s - loss: 3.8588 - accuracy: 0.0883
on_train_batch_begin: 1607801276.319547s

6 step training time: 0.205782s

on_train_batch_end: 1607801276.562036s

 7168/50000 [===>..........................] - ETA: 8s - loss: 3.8134 - accuracy: 0.0889
on_train_batch_begin: 1607801276.562518s

7 step training time: 0.242971s

on_train_batch_end: 1607801276.807438s

 8192/50000 [===>..........................] - ETA: 8s - loss: 3.8035 - accuracy: 0.0894
on_train_batch_begin: 1607801276.807921s

8 step training time: 0.245403s

on_train_batch_end: 1607801277.014345s

 9216/50000 [====>.........................] - ETA: 8s - loss: 3.8010 - accuracy: 0.0895
on_train_batch_begin: 1607801277.014827s

9 step training time: 0.206906s

on_train_batch_end: 1607801277.219882s

10240/50000 [=====>........................] - ETA: 8s - loss: 3.7801 - accuracy: 0.0900
on_train_batch_begin: 1607801277.220397s

10 step training time: 0.205571s

on_train_batch_end: 1607801277.427559s

11264/50000 [=====>........................] - ETA: 8s - loss: 3.7452 - accuracy: 0.0905
on_train_batch_begin: 1607801277.428038s

11 step training time: 0.207641s

on_train_batch_end: 1607801277.635493s

12288/50000 [======>.......................] - ETA: 7s - loss: 3.6954 - accuracy: 0.0912
on_train_batch_begin: 1607801277.635972s

12 step training time: 0.207934s

on_train_batch_end: 1607801277.843321s

13312/50000 [======>.......................] - ETA: 7s - loss: 3.6818 - accuracy: 0.0915
on_train_batch_begin: 1607801277.843808s

13 step training time: 0.207836s

on_train_batch_end: 1607801278.087800s

14336/50000 [=======>......................] - ETA: 7s - loss: 3.6424 - accuracy: 0.0919
on_train_batch_begin: 1607801278.088282s

14 step training time: 0.244474s

on_train_batch_end: 1607801278.319957s

15360/50000 [========>.....................] - ETA: 7s - loss: 3.6058 - accuracy: 0.0924
on_train_batch_begin: 1607801278.320437s

15 step training time: 0.232155s

on_train_batch_end: 1607801278.525710s

16384/50000 [========>.....................] - ETA: 7s - loss: 3.5713 - accuracy: 0.0929
on_train_batch_begin: 1607801278.526197s

16 step training time: 0.205760s

on_train_batch_end: 1607801278.776220s

17408/50000 [=========>....................] - ETA: 6s - loss: 3.5549 - accuracy: 0.0931
on_train_batch_begin: 1607801278.776704s

17 step training time: 0.250507s

on_train_batch_end: 1607801279.005268s

18432/50000 [==========>...................] - ETA: 6s - loss: 3.5244 - accuracy: 0.0936
on_train_batch_begin: 1607801279.005757s

18 step training time: 0.229053s

on_train_batch_end: 1607801279.212037s

19456/50000 [==========>...................] - ETA: 6s - loss: 3.4952 - accuracy: 0.0941
on_train_batch_begin: 1607801279.212520s

19 step training time: 0.206764s

on_train_batch_end: 1607801279.417801s

20480/50000 [===========>..................] - ETA: 6s - loss: 3.4685 - accuracy: 0.0944
on_train_batch_begin: 1607801279.418279s

20 step training time: 0.205759s

on_train_batch_end: 1607801279.665938s

21504/50000 [===========>..................] - ETA: 6s - loss: 3.4495 - accuracy: 0.0947
on_train_batch_begin: 1607801279.666419s

21 step training time: 0.248141s

on_train_batch_end: 1607801279.895265s

22528/50000 [============>.................] - ETA: 5s - loss: 3.4343 - accuracy: 0.0949
on_train_batch_begin: 1607801279.895778s

22 step training time: 0.229358s

on_train_batch_end: 1607801280.141368s

23552/50000 [=============>................] - ETA: 5s - loss: 3.4128 - accuracy: 0.0951
on_train_batch_begin: 1607801280.141850s

23 step training time: 0.246073s

on_train_batch_end: 1607801280.385514s

24576/50000 [=============>................] - ETA: 5s - loss: 3.3799 - accuracy: 0.0954
on_train_batch_begin: 1607801280.386001s

24 step training time: 0.244150s

on_train_batch_end: 1607801280.592219s

25600/50000 [==============>...............] - ETA: 5s - loss: 3.3645 - accuracy: 0.0956
on_train_batch_begin: 1607801280.592698s

25 step training time: 0.206697s

on_train_batch_end: 1607801280.841589s

26624/50000 [==============>...............] - ETA: 5s - loss: 3.3551 - accuracy: 0.0957
on_train_batch_begin: 1607801280.842078s

26 step training time: 0.249380s

on_train_batch_end: 1607801281.072135s

27648/50000 [===============>..............] - ETA: 4s - loss: 3.3390 - accuracy: 0.0958
on_train_batch_begin: 1607801281.072597s

27 step training time: 0.230519s

on_train_batch_end: 1607801281.277399s

28672/50000 [================>.............] - ETA: 4s - loss: 3.3174 - accuracy: 0.0960
on_train_batch_begin: 1607801281.277863s

28 step training time: 0.205266s

on_train_batch_end: 1607801281.523885s

29696/50000 [================>.............] - ETA: 4s - loss: 3.2933 - accuracy: 0.0962
on_train_batch_begin: 1607801281.524359s

29 step training time: 0.246496s

on_train_batch_end: 1607801281.755793s

30720/50000 [=================>............] - ETA: 4s - loss: 3.2777 - accuracy: 0.0964
on_train_batch_begin: 1607801281.756254s

30 step training time: 0.231896s

on_train_batch_end: 1607801281.961015s

31744/50000 [==================>...........] - ETA: 3s - loss: 3.2611 - accuracy: 0.0966
on_train_batch_begin: 1607801281.961475s

31 step training time: 0.205220s

on_train_batch_end: 1607801282.209078s

32768/50000 [==================>...........] - ETA: 3s - loss: 3.2474 - accuracy: 0.0967
on_train_batch_begin: 1607801282.209543s

32 step training time: 0.248068s

on_train_batch_end: 1607801282.447169s

33792/50000 [===================>..........] - ETA: 3s - loss: 3.2320 - accuracy: 0.0968
on_train_batch_begin: 1607801282.447665s

33 step training time: 0.238122s

on_train_batch_end: 1607801282.653460s

34816/50000 [===================>..........] - ETA: 3s - loss: 3.2157 - accuracy: 0.0970
on_train_batch_begin: 1607801282.653930s

34 step training time: 0.206266s

on_train_batch_end: 1607801282.900720s

35840/50000 [====================>.........] - ETA: 3s - loss: 3.2017 - accuracy: 0.0971
on_train_batch_begin: 1607801282.901189s

35 step training time: 0.247259s

on_train_batch_end: 1607801283.144966s

36864/50000 [=====================>........] - ETA: 2s - loss: 3.1892 - accuracy: 0.0972
on_train_batch_begin: 1607801283.145422s

36 step training time: 0.244233s

on_train_batch_end: 1607801283.350420s

37888/50000 [=====================>........] - ETA: 2s - loss: 3.1731 - accuracy: 0.0973
on_train_batch_begin: 1607801283.350888s

37 step training time: 0.205466s

on_train_batch_end: 1607801283.596905s

38912/50000 [======================>.......] - ETA: 2s - loss: 3.1594 - accuracy: 0.0974
on_train_batch_begin: 1607801283.597362s

38 step training time: 0.246474s

on_train_batch_end: 1607801283.851831s

39936/50000 [======================>.......] - ETA: 2s - loss: 3.1446 - accuracy: 0.0975
on_train_batch_begin: 1607801283.852288s

39 step training time: 0.254926s

on_train_batch_end: 1607801284.096501s

40960/50000 [=======================>......] - ETA: 1s - loss: 3.1305 - accuracy: 0.0976
on_train_batch_begin: 1607801284.096958s

40 step training time: 0.244671s

on_train_batch_end: 1607801284.339874s

41984/50000 [========================>.....] - ETA: 1s - loss: 3.1146 - accuracy: 0.0978
on_train_batch_begin: 1607801284.340335s

41 step training time: 0.243376s

on_train_batch_end: 1607801284.571906s

43008/50000 [========================>.....] - ETA: 1s - loss: 3.1040 - accuracy: 0.0978
on_train_batch_begin: 1607801284.572364s

42 step training time: 0.232029s

on_train_batch_end: 1607801284.816752s

44032/50000 [=========================>....] - ETA: 1s - loss: 3.0916 - accuracy: 0.0979
on_train_batch_begin: 1607801284.817215s

43 step training time: 0.244851s

on_train_batch_end: 1607801285.060407s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.0744 - accuracy: 0.0980
on_train_batch_begin: 1607801285.060876s

44 step training time: 0.243661s

on_train_batch_end: 1607801285.266388s

46080/50000 [==========================>...] - ETA: 0s - loss: 3.0583 - accuracy: 0.0981
on_train_batch_begin: 1607801285.266857s

45 step training time: 0.205981s

on_train_batch_end: 1607801285.471644s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.0417 - accuracy: 0.0982
on_train_batch_begin: 1607801285.472103s

46 step training time: 0.205245s

on_train_batch_end: 1607801285.716668s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.0271 - accuracy: 0.0983
on_train_batch_begin: 1607801285.717126s

47 step training time: 0.245023s

on_train_batch_end: 1607801285.958609s

49152/50000 [============================>.] - ETA: 0s - loss: 3.0131 - accuracy: 0.0983
on_train_batch_begin: 1607801285.959068s

48 step training time: 0.241942s

on_train_batch_end: 1607801286.156173s

on_test_batch_begin: 1607801286.194740s

49 step training time: 0.235672s

on_epoch_end: 1607801286.701880s

Validation time: 0.507117s

Real time: 1607801286.701880s

Epoch time: 11.629103183746338s

50000/50000 [==============================] - 12s 233us/sample - loss: 3.0002 - accuracy: 0.0984 - val_loss: 7.5153 - val_accuracy: 0.0000e+00

on_epoch_begin: 1607801286.702165s

Real time: 1607801286.7021747
Epoch 3/5

on_train_batch_begin: 1607801286.710404s

on_train_batch_end: 1607801286.956437s

 1024/50000 [..............................] - ETA: 12s - loss: 1.9853 - accuracy: 0.1004
on_train_batch_begin: 1607801286.956897s

1 step training time: 0.246493s

on_train_batch_end: 1607801287.188900s

 2048/50000 [>.............................] - ETA: 11s - loss: 2.0234 - accuracy: 0.1012
on_train_batch_begin: 1607801287.189365s

2 step training time: 0.232468s

on_train_batch_end: 1607801287.394604s

 3072/50000 [>.............................] - ETA: 10s - loss: 1.9845 - accuracy: 0.1014
on_train_batch_begin: 1607801287.395068s

3 step training time: 0.205702s

on_train_batch_end: 1607801287.601621s

 4096/50000 [=>............................] - ETA: 10s - loss: 1.9713 - accuracy: 0.1013
on_train_batch_begin: 1607801287.602087s

4 step training time: 0.207019s

on_train_batch_end: 1607801287.807604s

 5120/50000 [==>...........................] - ETA: 9s - loss: 1.9884 - accuracy: 0.1013 
on_train_batch_begin: 1607801287.808065s

5 step training time: 0.205978s

on_train_batch_end: 1607801288.050375s

 6144/50000 [==>...........................] - ETA: 9s - loss: 1.9600 - accuracy: 0.1014
on_train_batch_begin: 1607801288.050845s

6 step training time: 0.242780s

on_train_batch_end: 1607801288.288804s

 7168/50000 [===>..........................] - ETA: 9s - loss: 1.9498 - accuracy: 0.1014
on_train_batch_begin: 1607801288.289270s

7 step training time: 0.238425s

on_train_batch_end: 1607801288.494537s

 8192/50000 [===>..........................] - ETA: 9s - loss: 1.9379 - accuracy: 0.1014
on_train_batch_begin: 1607801288.495004s

8 step training time: 0.205734s

on_train_batch_end: 1607801288.703072s

 9216/50000 [====>.........................] - ETA: 8s - loss: 1.9606 - accuracy: 0.1015
on_train_batch_begin: 1607801288.703566s

9 step training time: 0.208562s

on_train_batch_end: 1607801288.911201s

10240/50000 [=====>........................] - ETA: 8s - loss: 1.9510 - accuracy: 0.1016
on_train_batch_begin: 1607801288.911701s

10 step training time: 0.208135s

on_train_batch_end: 1607801289.156904s

11264/50000 [=====>........................] - ETA: 8s - loss: 1.9451 - accuracy: 0.1015
on_train_batch_begin: 1607801289.157391s

11 step training time: 0.245690s

on_train_batch_end: 1607801289.392309s

12288/50000 [======>.......................] - ETA: 8s - loss: 1.9422 - accuracy: 0.1015
on_train_batch_begin: 1607801289.392787s

12 step training time: 0.235396s

on_train_batch_end: 1607801289.598711s

13312/50000 [======>.......................] - ETA: 7s - loss: 1.9415 - accuracy: 0.1015
on_train_batch_begin: 1607801289.599200s

13 step training time: 0.206412s

on_train_batch_end: 1607801289.844859s

14336/50000 [=======>......................] - ETA: 7s - loss: 1.9328 - accuracy: 0.1016
on_train_batch_begin: 1607801289.845324s

14 step training time: 0.246125s

on_train_batch_end: 1607801290.081363s

15360/50000 [========>.....................] - ETA: 7s - loss: 1.9275 - accuracy: 0.1016
on_train_batch_begin: 1607801290.081832s

15 step training time: 0.236507s

on_train_batch_end: 1607801290.287384s

16384/50000 [========>.....................] - ETA: 7s - loss: 1.9193 - accuracy: 0.1016
on_train_batch_begin: 1607801290.287859s

16 step training time: 0.206027s

on_train_batch_end: 1607801290.494329s

17408/50000 [=========>....................] - ETA: 7s - loss: 1.9175 - accuracy: 0.1017
on_train_batch_begin: 1607801290.494807s

17 step training time: 0.206948s

on_train_batch_end: 1607801290.700284s

18432/50000 [==========>...................] - ETA: 6s - loss: 1.8994 - accuracy: 0.1017
on_train_batch_begin: 1607801290.700756s

18 step training time: 0.205949s

on_train_batch_end: 1607801290.905560s

19456/50000 [==========>...................] - ETA: 6s - loss: 1.8866 - accuracy: 0.1017
on_train_batch_begin: 1607801290.906028s

19 step training time: 0.205272s

on_train_batch_end: 1607801291.152246s

20480/50000 [===========>..................] - ETA: 6s - loss: 1.8794 - accuracy: 0.1017
on_train_batch_begin: 1607801291.152715s

20 step training time: 0.246687s

on_train_batch_end: 1607801291.382312s

21504/50000 [===========>..................] - ETA: 6s - loss: 1.8741 - accuracy: 0.1017
on_train_batch_begin: 1607801291.382780s

21 step training time: 0.230065s

on_train_batch_end: 1607801291.587868s

22528/50000 [============>.................] - ETA: 5s - loss: 1.8676 - accuracy: 0.1017
on_train_batch_begin: 1607801291.588338s

22 step training time: 0.205558s

on_train_batch_end: 1607801291.835215s

23552/50000 [=============>................] - ETA: 5s - loss: 1.8667 - accuracy: 0.1017
on_train_batch_begin: 1607801291.835724s

23 step training time: 0.247385s

on_train_batch_end: 1607801292.067731s

24576/50000 [=============>................] - ETA: 5s - loss: 1.8530 - accuracy: 0.1018
on_train_batch_begin: 1607801292.068198s

24 step training time: 0.232474s

on_train_batch_end: 1607801292.273081s

25600/50000 [==============>...............] - ETA: 5s - loss: 1.8397 - accuracy: 0.1018
on_train_batch_begin: 1607801292.273541s

25 step training time: 0.205343s

on_train_batch_end: 1607801292.519081s

26624/50000 [==============>...............] - ETA: 5s - loss: 1.8345 - accuracy: 0.1018
on_train_batch_begin: 1607801292.519569s

26 step training time: 0.246028s

on_train_batch_end: 1607801292.773248s

27648/50000 [===============>..............] - ETA: 4s - loss: 1.8213 - accuracy: 0.1018
on_train_batch_begin: 1607801292.773708s

27 step training time: 0.254139s

on_train_batch_end: 1607801293.031246s

28672/50000 [================>.............] - ETA: 4s - loss: 1.8160 - accuracy: 0.1018
on_train_batch_begin: 1607801293.031744s

28 step training time: 0.258036s

on_train_batch_end: 1607801293.263278s

29696/50000 [================>.............] - ETA: 4s - loss: 1.8144 - accuracy: 0.1018
on_train_batch_begin: 1607801293.263769s

29 step training time: 0.232025s

on_train_batch_end: 1607801293.470224s

30720/50000 [=================>............] - ETA: 4s - loss: 1.8079 - accuracy: 0.1018
on_train_batch_begin: 1607801293.470686s

30 step training time: 0.206918s

on_train_batch_end: 1607801293.675357s

31744/50000 [==================>...........] - ETA: 4s - loss: 1.8008 - accuracy: 0.1018
on_train_batch_begin: 1607801293.675824s

31 step training time: 0.205137s

on_train_batch_end: 1607801293.879835s

32768/50000 [==================>...........] - ETA: 3s - loss: 1.7971 - accuracy: 0.1018
on_train_batch_begin: 1607801293.880301s

32 step training time: 0.204477s

on_train_batch_end: 1607801294.127504s

33792/50000 [===================>..........] - ETA: 3s - loss: 1.7893 - accuracy: 0.1018
on_train_batch_begin: 1607801294.127970s

33 step training time: 0.247669s

on_train_batch_end: 1607801294.359257s

34816/50000 [===================>..........] - ETA: 3s - loss: 1.7830 - accuracy: 0.1019
on_train_batch_begin: 1607801294.359744s

34 step training time: 0.231774s

on_train_batch_end: 1607801294.566328s

35840/50000 [====================>.........] - ETA: 3s - loss: 1.7769 - accuracy: 0.1019
on_train_batch_begin: 1607801294.566786s

35 step training time: 0.207042s

on_train_batch_end: 1607801294.815642s

36864/50000 [=====================>........] - ETA: 2s - loss: 1.7742 - accuracy: 0.1019
on_train_batch_begin: 1607801294.816122s

36 step training time: 0.249336s

on_train_batch_end: 1607801295.047116s

37888/50000 [=====================>........] - ETA: 2s - loss: 1.7686 - accuracy: 0.1018
on_train_batch_begin: 1607801295.047606s

37 step training time: 0.231484s

on_train_batch_end: 1607801295.255413s

38912/50000 [======================>.......] - ETA: 2s - loss: 1.7616 - accuracy: 0.1019
on_train_batch_begin: 1607801295.255873s

38 step training time: 0.208267s

on_train_batch_end: 1607801295.500208s

39936/50000 [======================>.......] - ETA: 2s - loss: 1.7542 - accuracy: 0.1019
on_train_batch_begin: 1607801295.500670s

39 step training time: 0.244797s

on_train_batch_end: 1607801295.733192s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.7439 - accuracy: 0.1019
on_train_batch_begin: 1607801295.733649s

40 step training time: 0.232979s

on_train_batch_end: 1607801295.976847s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.7391 - accuracy: 0.1019
on_train_batch_begin: 1607801295.977307s

41 step training time: 0.243658s

on_train_batch_end: 1607801296.211600s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.7392 - accuracy: 0.1019
on_train_batch_begin: 1607801296.212062s

42 step training time: 0.234755s

on_train_batch_end: 1607801296.416921s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.7335 - accuracy: 0.1019
on_train_batch_begin: 1607801296.417387s

43 step training time: 0.205325s

on_train_batch_end: 1607801296.661395s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.7312 - accuracy: 0.1019
on_train_batch_begin: 1607801296.661853s

44 step training time: 0.244466s

on_train_batch_end: 1607801296.892195s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.7278 - accuracy: 0.1019
on_train_batch_begin: 1607801296.892656s

45 step training time: 0.230803s

on_train_batch_end: 1607801297.137524s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.7208 - accuracy: 0.1019
on_train_batch_begin: 1607801297.137988s

46 step training time: 0.245332s

on_train_batch_end: 1607801297.377006s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.7154 - accuracy: 0.1019
on_train_batch_begin: 1607801297.377470s

47 step training time: 0.239481s

on_train_batch_end: 1607801297.621791s

49152/50000 [============================>.] - ETA: 0s - loss: 1.7104 - accuracy: 0.1020
on_train_batch_begin: 1607801297.622256s

48 step training time: 0.244786s

on_train_batch_end: 1607801297.848082s

on_test_batch_begin: 1607801297.881721s

49 step training time: 0.259466s

on_epoch_end: 1607801298.390754s

Validation time: 0.509015s

Real time: 1607801298.390754s

Epoch time: 11.688607454299927s

50000/50000 [==============================] - 12s 234us/sample - loss: 1.7042 - accuracy: 0.1020 - val_loss: 7.2745 - val_accuracy: 0.0000e+00

on_epoch_begin: 1607801298.391043s

Real time: 1607801298.3910532
Epoch 4/5

on_train_batch_begin: 1607801298.399647s

on_train_batch_end: 1607801298.648310s

 1024/50000 [..............................] - ETA: 12s - loss: 1.4835 - accuracy: 0.1022
on_train_batch_begin: 1607801298.648788s

1 step training time: 0.249141s

on_train_batch_end: 1607801298.877697s

 2048/50000 [>.............................] - ETA: 11s - loss: 1.4448 - accuracy: 0.1018
on_train_batch_begin: 1607801298.878178s

2 step training time: 0.229390s

on_train_batch_end: 1607801299.083517s

 3072/50000 [>.............................] - ETA: 10s - loss: 1.3983 - accuracy: 0.1023
on_train_batch_begin: 1607801299.083993s

3 step training time: 0.205816s

on_train_batch_end: 1607801299.291453s

 4096/50000 [=>............................] - ETA: 10s - loss: 1.3706 - accuracy: 0.1025
on_train_batch_begin: 1607801299.291938s

4 step training time: 0.207945s

on_train_batch_end: 1607801299.537590s

 5120/50000 [==>...........................] - ETA: 10s - loss: 1.3432 - accuracy: 0.1026
on_train_batch_begin: 1607801299.538073s

5 step training time: 0.246135s

on_train_batch_end: 1607801299.790460s

 6144/50000 [==>...........................] - ETA: 9s - loss: 1.3487 - accuracy: 0.1024 
on_train_batch_begin: 1607801299.790935s

6 step training time: 0.252862s

on_train_batch_end: 1607801300.025797s

 7168/50000 [===>..........................] - ETA: 9s - loss: 1.3415 - accuracy: 0.1024
on_train_batch_begin: 1607801300.026273s

7 step training time: 0.235338s

on_train_batch_end: 1607801300.231696s

 8192/50000 [===>..........................] - ETA: 9s - loss: 1.3290 - accuracy: 0.1025
on_train_batch_begin: 1607801300.232183s

8 step training time: 0.205910s

on_train_batch_end: 1607801300.438956s

 9216/50000 [====>.........................] - ETA: 9s - loss: 1.3178 - accuracy: 0.1024
on_train_batch_begin: 1607801300.439472s

9 step training time: 0.207289s

on_train_batch_end: 1607801300.645565s

10240/50000 [=====>........................] - ETA: 8s - loss: 1.3143 - accuracy: 0.1024
on_train_batch_begin: 1607801300.646048s

10 step training time: 0.206576s

on_train_batch_end: 1607801300.851929s

11264/50000 [=====>........................] - ETA: 8s - loss: 1.3140 - accuracy: 0.1024
on_train_batch_begin: 1607801300.852409s

11 step training time: 0.206361s

on_train_batch_end: 1607801301.058403s

12288/50000 [======>.......................] - ETA: 8s - loss: 1.3119 - accuracy: 0.1023
on_train_batch_begin: 1607801301.058883s

12 step training time: 0.206474s

on_train_batch_end: 1607801301.265475s

13312/50000 [======>.......................] - ETA: 7s - loss: 1.3019 - accuracy: 0.1022
on_train_batch_begin: 1607801301.265954s

13 step training time: 0.207070s

on_train_batch_end: 1607801301.473000s

14336/50000 [=======>......................] - ETA: 7s - loss: 1.3011 - accuracy: 0.1022
on_train_batch_begin: 1607801301.473480s

14 step training time: 0.207526s

on_train_batch_end: 1607801301.721202s

15360/50000 [========>.....................] - ETA: 7s - loss: 1.2998 - accuracy: 0.1021
on_train_batch_begin: 1607801301.721680s

15 step training time: 0.248200s

on_train_batch_end: 1607801301.958100s

16384/50000 [========>.....................] - ETA: 7s - loss: 1.2966 - accuracy: 0.1021
on_train_batch_begin: 1607801301.958581s

16 step training time: 0.236901s

on_train_batch_end: 1607801302.162394s

17408/50000 [=========>....................] - ETA: 7s - loss: 1.2943 - accuracy: 0.1022
on_train_batch_begin: 1607801302.162872s

17 step training time: 0.204290s

on_train_batch_end: 1607801302.410861s

18432/50000 [==========>...................] - ETA: 6s - loss: 1.2883 - accuracy: 0.1022
on_train_batch_begin: 1607801302.411375s

18 step training time: 0.248503s

on_train_batch_end: 1607801302.644890s

19456/50000 [==========>...................] - ETA: 6s - loss: 1.2914 - accuracy: 0.1022
on_train_batch_begin: 1607801302.645368s

19 step training time: 0.233993s

on_train_batch_end: 1607801302.892210s

20480/50000 [===========>..................] - ETA: 6s - loss: 1.2848 - accuracy: 0.1022
on_train_batch_begin: 1607801302.892691s

20 step training time: 0.247324s

on_train_batch_end: 1607801303.125399s

21504/50000 [===========>..................] - ETA: 6s - loss: 1.2801 - accuracy: 0.1022
on_train_batch_begin: 1607801303.125878s

21 step training time: 0.233187s

on_train_batch_end: 1607801303.331235s

22528/50000 [============>.................] - ETA: 6s - loss: 1.2798 - accuracy: 0.1022
on_train_batch_begin: 1607801303.331736s

22 step training time: 0.205858s

on_train_batch_end: 1607801303.580005s

23552/50000 [=============>................] - ETA: 5s - loss: 1.2809 - accuracy: 0.1022
on_train_batch_begin: 1607801303.580467s

23 step training time: 0.248731s

on_train_batch_end: 1607801303.813162s

24576/50000 [=============>................] - ETA: 5s - loss: 1.2762 - accuracy: 0.1022
on_train_batch_begin: 1607801303.813629s

24 step training time: 0.233162s

on_train_batch_end: 1607801304.021181s

25600/50000 [==============>...............] - ETA: 5s - loss: 1.2704 - accuracy: 0.1022
on_train_batch_begin: 1607801304.021646s

25 step training time: 0.208017s

on_train_batch_end: 1607801304.226029s

26624/50000 [==============>...............] - ETA: 5s - loss: 1.2694 - accuracy: 0.1022
on_train_batch_begin: 1607801304.226493s

26 step training time: 0.204847s

on_train_batch_end: 1607801304.433392s

27648/50000 [===============>..............] - ETA: 4s - loss: 1.2684 - accuracy: 0.1023
on_train_batch_begin: 1607801304.433858s

27 step training time: 0.207365s

on_train_batch_end: 1607801304.679607s

28672/50000 [================>.............] - ETA: 4s - loss: 1.2636 - accuracy: 0.1023
on_train_batch_begin: 1607801304.680071s

28 step training time: 0.246212s

on_train_batch_end: 1607801304.911999s

29696/50000 [================>.............] - ETA: 4s - loss: 1.2595 - accuracy: 0.1023
on_train_batch_begin: 1607801304.912467s

29 step training time: 0.232396s

on_train_batch_end: 1607801305.158896s

30720/50000 [=================>............] - ETA: 4s - loss: 1.2557 - accuracy: 0.1023
on_train_batch_begin: 1607801305.159384s

30 step training time: 0.246917s

on_train_batch_end: 1607801305.395032s

31744/50000 [==================>...........] - ETA: 4s - loss: 1.2551 - accuracy: 0.1023
on_train_batch_begin: 1607801305.395529s

31 step training time: 0.236145s

on_train_batch_end: 1607801305.641289s

32768/50000 [==================>...........] - ETA: 3s - loss: 1.2472 - accuracy: 0.1023
on_train_batch_begin: 1607801305.641752s

32 step training time: 0.246223s

on_train_batch_end: 1607801305.874977s

33792/50000 [===================>..........] - ETA: 3s - loss: 1.2420 - accuracy: 0.1023
on_train_batch_begin: 1607801305.875472s

33 step training time: 0.233720s

on_train_batch_end: 1607801306.119553s

34816/50000 [===================>..........] - ETA: 3s - loss: 1.2361 - accuracy: 0.1023
on_train_batch_begin: 1607801306.120015s

34 step training time: 0.244543s

on_train_batch_end: 1607801306.354200s

35840/50000 [====================>.........] - ETA: 3s - loss: 1.2308 - accuracy: 0.1023
on_train_batch_begin: 1607801306.354666s

35 step training time: 0.234651s

on_train_batch_end: 1607801306.603799s

36864/50000 [=====================>........] - ETA: 2s - loss: 1.2277 - accuracy: 0.1023
on_train_batch_begin: 1607801306.604262s

36 step training time: 0.249596s

on_train_batch_end: 1607801306.836549s

37888/50000 [=====================>........] - ETA: 2s - loss: 1.2229 - accuracy: 0.1023
on_train_batch_begin: 1607801306.837011s

37 step training time: 0.232749s

on_train_batch_end: 1607801307.081580s

38912/50000 [======================>.......] - ETA: 2s - loss: 1.2183 - accuracy: 0.1023
on_train_batch_begin: 1607801307.082045s

38 step training time: 0.245034s

on_train_batch_end: 1607801307.316475s

39936/50000 [======================>.......] - ETA: 2s - loss: 1.2173 - accuracy: 0.1023
on_train_batch_begin: 1607801307.316937s

39 step training time: 0.234892s

on_train_batch_end: 1607801307.564502s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.2194 - accuracy: 0.1023
on_train_batch_begin: 1607801307.564968s

40 step training time: 0.248031s

on_train_batch_end: 1607801307.797264s

41984/50000 [========================>.....] - ETA: 1s - loss: 1.2170 - accuracy: 0.1023
on_train_batch_begin: 1607801307.797724s

41 step training time: 0.232757s

on_train_batch_end: 1607801308.002664s

43008/50000 [========================>.....] - ETA: 1s - loss: 1.2147 - accuracy: 0.1023
on_train_batch_begin: 1607801308.003127s

42 step training time: 0.205403s

on_train_batch_end: 1607801308.253364s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.2117 - accuracy: 0.1023
on_train_batch_begin: 1607801308.253825s

43 step training time: 0.250698s

on_train_batch_end: 1607801308.485082s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.2098 - accuracy: 0.1023
on_train_batch_begin: 1607801308.485550s

44 step training time: 0.231725s

on_train_batch_end: 1607801308.730818s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.2082 - accuracy: 0.1023
on_train_batch_begin: 1607801308.731311s

45 step training time: 0.245761s

on_train_batch_end: 1607801308.983027s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.2079 - accuracy: 0.1023
on_train_batch_begin: 1607801308.983521s

46 step training time: 0.252211s

on_train_batch_end: 1607801309.218290s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.2074 - accuracy: 0.1023
on_train_batch_begin: 1607801309.218753s

47 step training time: 0.235232s

on_train_batch_end: 1607801309.464916s

49152/50000 [============================>.] - ETA: 0s - loss: 1.2058 - accuracy: 0.1023
on_train_batch_begin: 1607801309.465382s

48 step training time: 0.246629s

on_train_batch_end: 1607801309.704605s

on_test_batch_begin: 1607801309.740672s

49 step training time: 0.275290s

on_epoch_end: 1607801310.253366s

Validation time: 0.512676s

Real time: 1607801310.253366s

Epoch time: 11.862341165542603s

50000/50000 [==============================] - 12s 237us/sample - loss: 1.2039 - accuracy: 0.1023 - val_loss: 6.8185 - val_accuracy: 0.0999

on_epoch_begin: 1607801310.253694s

Real time: 1607801310.2537048
Epoch 5/5

on_train_batch_begin: 1607801310.262132s

on_train_batch_end: 1607801310.511662s

 1024/50000 [..............................] - ETA: 12s - loss: 1.0553 - accuracy: 0.1031
on_train_batch_begin: 1607801310.512123s

1 step training time: 0.249991s

on_train_batch_end: 1607801310.763811s

 2048/50000 [>.............................] - ETA: 11s - loss: 1.0326 - accuracy: 0.1031
on_train_batch_begin: 1607801310.764268s

2 step training time: 0.252145s

on_train_batch_end: 1607801311.001243s

 3072/50000 [>.............................] - ETA: 11s - loss: 1.0000 - accuracy: 0.1032
on_train_batch_begin: 1607801311.001693s

3 step training time: 0.237426s

on_train_batch_end: 1607801311.206633s

 4096/50000 [=>............................] - ETA: 10s - loss: 0.9896 - accuracy: 0.1034
on_train_batch_begin: 1607801311.207090s

4 step training time: 0.205396s

on_train_batch_end: 1607801311.454988s

 5120/50000 [==>...........................] - ETA: 10s - loss: 1.0023 - accuracy: 0.1033
on_train_batch_begin: 1607801311.455469s

5 step training time: 0.248379s

on_train_batch_end: 1607801311.688149s

 6144/50000 [==>...........................] - ETA: 10s - loss: 0.9967 - accuracy: 0.1031
on_train_batch_begin: 1607801311.688608s

6 step training time: 0.233139s

on_train_batch_end: 1607801311.936510s

 7168/50000 [===>..........................] - ETA: 10s - loss: 0.9890 - accuracy: 0.1030
on_train_batch_begin: 1607801311.936971s

7 step training time: 0.248363s

on_train_batch_end: 1607801312.171040s

 8192/50000 [===>..........................] - ETA: 9s - loss: 0.9798 - accuracy: 0.1028 
on_train_batch_begin: 1607801312.171530s

8 step training time: 0.234558s

on_train_batch_end: 1607801312.378445s

 9216/50000 [====>.........................] - ETA: 9s - loss: 0.9868 - accuracy: 0.1030
on_train_batch_begin: 1607801312.378929s

9 step training time: 0.207400s

on_train_batch_end: 1607801312.626310s

10240/50000 [=====>........................] - ETA: 9s - loss: 0.9881 - accuracy: 0.1030
on_train_batch_begin: 1607801312.626768s

10 step training time: 0.247839s

on_train_batch_end: 1607801312.865224s

11264/50000 [=====>........................] - ETA: 8s - loss: 0.9901 - accuracy: 0.1030
on_train_batch_begin: 1607801312.865686s

11 step training time: 0.238918s

on_train_batch_end: 1607801313.114496s

12288/50000 [======>.......................] - ETA: 8s - loss: 0.9801 - accuracy: 0.1029
on_train_batch_begin: 1607801313.114984s

12 step training time: 0.249298s

on_train_batch_end: 1607801313.366455s

13312/50000 [======>.......................] - ETA: 8s - loss: 0.9726 - accuracy: 0.1030
on_train_batch_begin: 1607801313.366914s

13 step training time: 0.251930s

on_train_batch_end: 1607801313.622358s

14336/50000 [=======>......................] - ETA: 8s - loss: 0.9670 - accuracy: 0.1029
on_train_batch_begin: 1607801313.622815s

14 step training time: 0.255901s

on_train_batch_end: 1607801313.877899s

15360/50000 [========>.....................] - ETA: 8s - loss: 0.9637 - accuracy: 0.1030
on_train_batch_begin: 1607801313.878358s

15 step training time: 0.255543s

on_train_batch_end: 1607801314.110310s

16384/50000 [========>.....................] - ETA: 7s - loss: 0.9644 - accuracy: 0.1030
on_train_batch_begin: 1607801314.110784s

16 step training time: 0.232426s

on_train_batch_end: 1607801314.317153s

17408/50000 [=========>....................] - ETA: 7s - loss: 0.9580 - accuracy: 0.1030
on_train_batch_begin: 1607801314.317626s

17 step training time: 0.206842s

on_train_batch_end: 1607801314.566005s

18432/50000 [==========>...................] - ETA: 7s - loss: 0.9592 - accuracy: 0.1030
on_train_batch_begin: 1607801314.566464s

18 step training time: 0.248838s

on_train_batch_end: 1607801314.819779s

19456/50000 [==========>...................] - ETA: 7s - loss: 0.9562 - accuracy: 0.1030
on_train_batch_begin: 1607801314.820249s

19 step training time: 0.253784s

on_train_batch_end: 1607801315.052441s

20480/50000 [===========>..................] - ETA: 6s - loss: 0.9469 - accuracy: 0.1030
on_train_batch_begin: 1607801315.052909s

20 step training time: 0.232661s

on_train_batch_end: 1607801315.298079s

21504/50000 [===========>..................] - ETA: 6s - loss: 0.9435 - accuracy: 0.1030
on_train_batch_begin: 1607801315.298544s

21 step training time: 0.245634s

on_train_batch_end: 1607801315.531039s

22528/50000 [============>.................] - ETA: 6s - loss: 0.9453 - accuracy: 0.1030
on_train_batch_begin: 1607801315.531546s

22 step training time: 0.233003s

on_train_batch_end: 1607801315.739439s

23552/50000 [=============>................] - ETA: 6s - loss: 0.9407 - accuracy: 0.1030
on_train_batch_begin: 1607801315.739908s

23 step training time: 0.208361s

on_train_batch_end: 1607801315.988091s

24576/50000 [=============>................] - ETA: 5s - loss: 0.9402 - accuracy: 0.1030
on_train_batch_begin: 1607801315.988552s

24 step training time: 0.248644s

on_train_batch_end: 1607801316.219880s

25600/50000 [==============>...............] - ETA: 5s - loss: 0.9370 - accuracy: 0.1030
on_train_batch_begin: 1607801316.220348s

25 step training time: 0.231796s

on_train_batch_end: 1607801316.426562s

26624/50000 [==============>...............] - ETA: 5s - loss: 0.9401 - accuracy: 0.1029
on_train_batch_begin: 1607801316.427027s

26 step training time: 0.206679s

on_train_batch_end: 1607801316.675321s

27648/50000 [===============>..............] - ETA: 5s - loss: 0.9356 - accuracy: 0.1029
on_train_batch_begin: 1607801316.675790s

27 step training time: 0.248763s

on_train_batch_end: 1607801316.907630s

28672/50000 [================>.............] - ETA: 4s - loss: 0.9307 - accuracy: 0.1029
on_train_batch_begin: 1607801316.908101s

28 step training time: 0.232311s

on_train_batch_end: 1607801317.157117s

29696/50000 [================>.............] - ETA: 4s - loss: 0.9267 - accuracy: 0.1029
on_train_batch_begin: 1607801317.157586s

29 step training time: 0.249486s

on_train_batch_end: 1607801317.411187s

30720/50000 [=================>............] - ETA: 4s - loss: 0.9249 - accuracy: 0.1029
on_train_batch_begin: 1607801317.411696s

30 step training time: 0.254110s

on_train_batch_end: 1607801317.646216s

31744/50000 [==================>...........] - ETA: 4s - loss: 0.9224 - accuracy: 0.1030
on_train_batch_begin: 1607801317.646683s

31 step training time: 0.234987s

on_train_batch_end: 1607801317.893162s

32768/50000 [==================>...........] - ETA: 4s - loss: 0.9189 - accuracy: 0.1030
on_train_batch_begin: 1607801317.893632s

32 step training time: 0.246949s

on_train_batch_end: 1607801318.127496s

33792/50000 [===================>..........] - ETA: 3s - loss: 0.9175 - accuracy: 0.1030
on_train_batch_begin: 1607801318.127966s

33 step training time: 0.234334s

on_train_batch_end: 1607801318.376148s

34816/50000 [===================>..........] - ETA: 3s - loss: 0.9197 - accuracy: 0.1030
on_train_batch_begin: 1607801318.376611s

34 step training time: 0.248645s

on_train_batch_end: 1607801318.612447s

35840/50000 [====================>.........] - ETA: 3s - loss: 0.9193 - accuracy: 0.1030
on_train_batch_begin: 1607801318.612919s

35 step training time: 0.236308s

on_train_batch_end: 1607801318.859029s

36864/50000 [=====================>........] - ETA: 3s - loss: 0.9165 - accuracy: 0.1030
on_train_batch_begin: 1607801318.859525s

36 step training time: 0.246607s

on_train_batch_end: 1607801319.114125s

37888/50000 [=====================>........] - ETA: 2s - loss: 0.9172 - accuracy: 0.1030
on_train_batch_begin: 1607801319.114591s

37 step training time: 0.255066s

on_train_batch_end: 1607801319.369122s

38912/50000 [======================>.......] - ETA: 2s - loss: 0.9201 - accuracy: 0.1030
on_train_batch_begin: 1607801319.369590s

38 step training time: 0.254999s

on_train_batch_end: 1607801319.623993s

39936/50000 [======================>.......] - ETA: 2s - loss: 0.9190 - accuracy: 0.1030
on_train_batch_begin: 1607801319.624460s

39 step training time: 0.254869s

on_train_batch_end: 1607801319.877208s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.9185 - accuracy: 0.1030
on_train_batch_begin: 1607801319.877678s

40 step training time: 0.253218s

on_train_batch_end: 1607801320.107468s

41984/50000 [========================>.....] - ETA: 1s - loss: 0.9159 - accuracy: 0.1030
on_train_batch_begin: 1607801320.107936s

41 step training time: 0.230258s

on_train_batch_end: 1607801320.314520s

43008/50000 [========================>.....] - ETA: 1s - loss: 0.9153 - accuracy: 0.1030
on_train_batch_begin: 1607801320.314984s

42 step training time: 0.207048s

on_train_batch_end: 1607801320.563159s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.9132 - accuracy: 0.1030
on_train_batch_begin: 1607801320.563678s

43 step training time: 0.248694s

on_train_batch_end: 1607801320.817717s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.9124 - accuracy: 0.1030
on_train_batch_begin: 1607801320.818188s

44 step training time: 0.254510s

on_train_batch_end: 1607801321.050561s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.9134 - accuracy: 0.1029
on_train_batch_begin: 1607801321.051028s

45 step training time: 0.232840s

on_train_batch_end: 1607801321.299869s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.9139 - accuracy: 0.1030
on_train_batch_begin: 1607801321.300335s

46 step training time: 0.249308s

on_train_batch_end: 1607801321.532154s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9136 - accuracy: 0.1030
on_train_batch_begin: 1607801321.532623s

47 step training time: 0.232287s

on_train_batch_end: 1607801321.779387s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9128 - accuracy: 0.1030
on_train_batch_begin: 1607801321.779857s

48 step training time: 0.247235s

on_train_batch_end: 1607801322.002706s

on_test_batch_begin: 1607801322.037434s

49 step training time: 0.257576s

on_epoch_end: 1607801322.548273s

Validation time: 0.510823s

Real time: 1607801322.548273s

Epoch time: 12.294596672058105s

50000/50000 [==============================] - 12s 246us/sample - loss: 0.9111 - accuracy: 0.1030 - val_loss: 6.1123 - val_accuracy: 0.0999
Tempo do fit: 224.21572184562683