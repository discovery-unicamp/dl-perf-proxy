wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:53
   204800/170498071 [..............................] - ETA: 1:17
  1097728/170498071 [..............................] - ETA: 22s 
  3268608/170498071 [..............................] - ETA: 9s 
  6643712/170498071 [>.............................] - ETA: 6s
 10027008/170498071 [>.............................] - ETA: 4s
 13344768/170498071 [=>............................] - ETA: 4s
 16719872/170498071 [=>............................] - ETA: 3s
 19898368/170498071 [==>...........................] - ETA: 3s
 23052288/170498071 [===>..........................] - ETA: 3s
 26238976/170498071 [===>..........................] - ETA: 3s
 29515776/170498071 [====>.........................] - ETA: 2s
 32882688/170498071 [====>.........................] - ETA: 2s
 36265984/170498071 [=====>........................] - ETA: 2s
 39649280/170498071 [=====>........................] - ETA: 2s
 42999808/170498071 [======>.......................] - ETA: 2s
 46383104/170498071 [=======>......................] - ETA: 2s
 49766400/170498071 [=======>......................] - ETA: 2s
 52994048/170498071 [========>.....................] - ETA: 2s
 56197120/170498071 [========>.....................] - ETA: 2s
 59539456/170498071 [=========>....................] - ETA: 1s
 62922752/170498071 [==========>...................] - ETA: 1s
 66306048/170498071 [==========>...................] - ETA: 1s
 69672960/170498071 [===========>..................] - ETA: 1s
 72998912/170498071 [===========>..................] - ETA: 1s
 76382208/170498071 [============>.................] - ETA: 1s
 79724544/170498071 [=============>................] - ETA: 1s
 82878464/170498071 [=============>................] - ETA: 1s
 86040576/170498071 [==============>...............] - ETA: 1s
 89268224/170498071 [==============>...............] - ETA: 1s
 92667904/170498071 [===============>..............] - ETA: 1s
 95985664/170498071 [===============>..............] - ETA: 1s
 99368960/170498071 [================>.............] - ETA: 1s
102719488/170498071 [=================>............] - ETA: 1s
106119168/170498071 [=================>............] - ETA: 1s
109486080/170498071 [==================>...........] - ETA: 1s
112861184/170498071 [==================>...........] - ETA: 0s
116023296/170498071 [===================>..........] - ETA: 0s
119341056/170498071 [===================>..........] - ETA: 0s
122707968/170498071 [====================>.........] - ETA: 0s
126074880/170498071 [=====================>........] - ETA: 0s
129441792/170498071 [=====================>........] - ETA: 0s
132816896/170498071 [======================>.......] - ETA: 0s
136224768/170498071 [======================>.......] - ETA: 0s
139599872/170498071 [=======================>......] - ETA: 0s
142827520/170498071 [========================>.....] - ETA: 0s
145989632/170498071 [========================>.....] - ETA: 0s
149250048/170498071 [=========================>....] - ETA: 0s
152543232/170498071 [=========================>....] - ETA: 0s
155705344/170498071 [==========================>...] - ETA: 0s
158687232/170498071 [==========================>...] - ETA: 0s
161619968/170498071 [===========================>..] - ETA: 0s
164519936/170498071 [===========================>..] - ETA: 0s
167452672/170498071 [============================>.] - ETA: 0s
170385408/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 4s
 6103040/94765736 [>.............................] - ETA: 0s
 9388032/94765736 [=>............................] - ETA: 1s
14114816/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
25927680/94765736 [=======>......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 1s
35045376/94765736 [==========>...................] - ETA: 1s
37683200/94765736 [==========>...................] - ETA: 1s
42672128/94765736 [============>.................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 0s
51355648/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
63176704/94765736 [==================>...........] - ETA: 0s
66781184/94765736 [====================>.........] - ETA: 0s
73023488/94765736 [======================>.......] - ETA: 0s
77856768/94765736 [=======================>......] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
89251840/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 14.854454278945923
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1607804343.607439s

Real time: 1607804343.6074686
Epoch 1/5

on_train_batch_begin: 1607804344.456408s

on_train_batch_end: 1607804360.140898s

 1024/50000 [..............................] - ETA: 13:10 - loss: 17.8014 - accuracy: 4.8733e-04
on_train_batch_begin: 1607804360.141629s

1 step training time: 15.685221s

on_train_batch_end: 1607804360.258226s

 2048/50000 [>.............................] - ETA: 6:29 - loss: 14.6290 - accuracy: 3.9768e-04 
on_train_batch_begin: 1607804360.258652s

2 step training time: 0.117023s

on_train_batch_end: 1607804360.374113s

 3072/50000 [>.............................] - ETA: 4:16 - loss: 12.6355 - accuracy: 8.8692e-04
on_train_batch_begin: 1607804360.374516s

3 step training time: 0.115864s

on_train_batch_end: 1607804360.489479s

 4096/50000 [=>............................] - ETA: 3:09 - loss: 11.5139 - accuracy: 0.0017    
on_train_batch_begin: 1607804360.489859s

4 step training time: 0.115343s

on_train_batch_end: 1607804360.604761s

 5120/50000 [==>...........................] - ETA: 2:28 - loss: 10.8546 - accuracy: 0.0043
on_train_batch_begin: 1607804360.605143s

5 step training time: 0.115284s

on_train_batch_end: 1607804360.720292s

 6144/50000 [==>...........................] - ETA: 2:02 - loss: 10.3898 - accuracy: 0.0087
on_train_batch_begin: 1607804360.720679s

6 step training time: 0.115535s

on_train_batch_end: 1607804360.835460s

 7168/50000 [===>..........................] - ETA: 1:42 - loss: 10.0317 - accuracy: 0.0142
on_train_batch_begin: 1607804360.835841s

7 step training time: 0.115163s

on_train_batch_end: 1607804360.950566s

 8192/50000 [===>..........................] - ETA: 1:28 - loss: 9.7267 - accuracy: 0.0187 
on_train_batch_begin: 1607804360.950952s

8 step training time: 0.115110s

on_train_batch_end: 1607804361.065944s

 9216/50000 [====>.........................] - ETA: 1:17 - loss: 9.5121 - accuracy: 0.0229
on_train_batch_begin: 1607804361.066326s

9 step training time: 0.115375s

on_train_batch_end: 1607804361.183103s

10240/50000 [=====>........................] - ETA: 1:08 - loss: 9.3241 - accuracy: 0.0267
on_train_batch_begin: 1607804361.183481s

10 step training time: 0.117155s

on_train_batch_end: 1607804361.297708s

11264/50000 [=====>........................] - ETA: 1:00 - loss: 9.1728 - accuracy: 0.0312
on_train_batch_begin: 1607804361.298095s

11 step training time: 0.114614s

on_train_batch_end: 1607804361.412473s

12288/50000 [======>.......................] - ETA: 54s - loss: 9.0306 - accuracy: 0.0342 
on_train_batch_begin: 1607804361.412854s

12 step training time: 0.114758s

on_train_batch_end: 1607804361.527677s

13312/50000 [======>.......................] - ETA: 49s - loss: 8.8958 - accuracy: 0.0367
on_train_batch_begin: 1607804361.528063s

13 step training time: 0.115209s

on_train_batch_end: 1607804361.643090s

14336/50000 [=======>......................] - ETA: 44s - loss: 8.7723 - accuracy: 0.0389
on_train_batch_begin: 1607804361.643469s

14 step training time: 0.115406s

on_train_batch_end: 1607804361.758165s

15360/50000 [========>.....................] - ETA: 40s - loss: 8.6637 - accuracy: 0.0415
on_train_batch_begin: 1607804361.758548s

15 step training time: 0.115079s

on_train_batch_end: 1607804361.873528s

16384/50000 [========>.....................] - ETA: 37s - loss: 8.5625 - accuracy: 0.0437
on_train_batch_begin: 1607804361.873901s

16 step training time: 0.115353s

on_train_batch_end: 1607804361.990593s

17408/50000 [=========>....................] - ETA: 34s - loss: 8.4687 - accuracy: 0.0447
on_train_batch_begin: 1607804361.991018s

17 step training time: 0.117117s

on_train_batch_end: 1607804362.106379s

18432/50000 [==========>...................] - ETA: 31s - loss: 8.3797 - accuracy: 0.0454
on_train_batch_begin: 1607804362.106774s

18 step training time: 0.115756s

on_train_batch_end: 1607804362.221705s

19456/50000 [==========>...................] - ETA: 29s - loss: 8.2968 - accuracy: 0.0457
on_train_batch_begin: 1607804362.222078s

19 step training time: 0.115305s

on_train_batch_end: 1607804362.336819s

20480/50000 [===========>..................] - ETA: 26s - loss: 8.2279 - accuracy: 0.0454
on_train_batch_begin: 1607804362.337192s

20 step training time: 0.115113s

on_train_batch_end: 1607804362.451350s

21504/50000 [===========>..................] - ETA: 24s - loss: 8.1558 - accuracy: 0.0460
on_train_batch_begin: 1607804362.451725s

21 step training time: 0.114533s

on_train_batch_end: 1607804362.566909s

22528/50000 [============>.................] - ETA: 23s - loss: 8.0848 - accuracy: 0.0469
on_train_batch_begin: 1607804362.567336s

22 step training time: 0.115611s

on_train_batch_end: 1607804362.682301s

23552/50000 [=============>................] - ETA: 21s - loss: 8.0185 - accuracy: 0.0475
on_train_batch_begin: 1607804362.682676s

23 step training time: 0.115340s

on_train_batch_end: 1607804362.796956s

24576/50000 [=============>................] - ETA: 19s - loss: 7.9601 - accuracy: 0.0479
on_train_batch_begin: 1607804362.797365s

24 step training time: 0.114690s

on_train_batch_end: 1607804362.912514s

25600/50000 [==============>...............] - ETA: 18s - loss: 7.9036 - accuracy: 0.0487
on_train_batch_begin: 1607804362.912892s

25 step training time: 0.115527s

on_train_batch_end: 1607804363.028986s

26624/50000 [==============>...............] - ETA: 17s - loss: 7.8489 - accuracy: 0.0495
on_train_batch_begin: 1607804363.029411s

26 step training time: 0.116519s

on_train_batch_end: 1607804363.143987s

27648/50000 [===============>..............] - ETA: 15s - loss: 7.7992 - accuracy: 0.0504
on_train_batch_begin: 1607804363.144375s

27 step training time: 0.114964s

on_train_batch_end: 1607804363.258451s

28672/50000 [================>.............] - ETA: 14s - loss: 7.7538 - accuracy: 0.0513
on_train_batch_begin: 1607804363.258828s

28 step training time: 0.114453s

on_train_batch_end: 1607804363.372993s

29696/50000 [================>.............] - ETA: 13s - loss: 7.7094 - accuracy: 0.0521
on_train_batch_begin: 1607804363.373398s

29 step training time: 0.114570s

on_train_batch_end: 1607804363.488214s

30720/50000 [=================>............] - ETA: 12s - loss: 7.6643 - accuracy: 0.0530
on_train_batch_begin: 1607804363.488600s

30 step training time: 0.115202s

on_train_batch_end: 1607804363.603615s

31744/50000 [==================>...........] - ETA: 11s - loss: 7.6212 - accuracy: 0.0539
on_train_batch_begin: 1607804363.604005s

31 step training time: 0.115404s

on_train_batch_end: 1607804363.719105s

32768/50000 [==================>...........] - ETA: 10s - loss: 7.5777 - accuracy: 0.0548
on_train_batch_begin: 1607804363.719490s

32 step training time: 0.115485s

on_train_batch_end: 1607804363.834630s

33792/50000 [===================>..........] - ETA: 9s - loss: 7.5445 - accuracy: 0.0556 
on_train_batch_begin: 1607804363.835014s

33 step training time: 0.115525s

on_train_batch_end: 1607804363.950767s

34816/50000 [===================>..........] - ETA: 8s - loss: 7.5037 - accuracy: 0.0562
on_train_batch_begin: 1607804363.951149s

34 step training time: 0.116134s

on_train_batch_end: 1607804364.066155s

35840/50000 [====================>.........] - ETA: 8s - loss: 7.4646 - accuracy: 0.0567
on_train_batch_begin: 1607804364.066540s

35 step training time: 0.115392s

on_train_batch_end: 1607804364.180746s

36864/50000 [=====================>........] - ETA: 7s - loss: 7.4281 - accuracy: 0.0570
on_train_batch_begin: 1607804364.181158s

36 step training time: 0.114617s

on_train_batch_end: 1607804364.295152s

37888/50000 [=====================>........] - ETA: 6s - loss: 7.3939 - accuracy: 0.0577
on_train_batch_begin: 1607804364.295535s

37 step training time: 0.114378s

on_train_batch_end: 1607804364.409340s

38912/50000 [======================>.......] - ETA: 5s - loss: 7.3573 - accuracy: 0.0586
on_train_batch_begin: 1607804364.409719s

38 step training time: 0.114184s

on_train_batch_end: 1607804364.523752s

39936/50000 [======================>.......] - ETA: 5s - loss: 7.3201 - accuracy: 0.0589
on_train_batch_begin: 1607804364.524133s

39 step training time: 0.114414s

on_train_batch_end: 1607804364.638874s

40960/50000 [=======================>......] - ETA: 4s - loss: 7.2856 - accuracy: 0.0591
on_train_batch_begin: 1607804364.639256s

40 step training time: 0.115123s

on_train_batch_end: 1607804364.753652s

41984/50000 [========================>.....] - ETA: 4s - loss: 7.2512 - accuracy: 0.0594
on_train_batch_begin: 1607804364.754034s

41 step training time: 0.114778s

on_train_batch_end: 1607804364.870433s

43008/50000 [========================>.....] - ETA: 3s - loss: 7.2201 - accuracy: 0.0600
on_train_batch_begin: 1607804364.870844s

42 step training time: 0.116810s

on_train_batch_end: 1607804364.986013s

44032/50000 [=========================>....] - ETA: 2s - loss: 7.1877 - accuracy: 0.0605
on_train_batch_begin: 1607804364.986393s

43 step training time: 0.115549s

on_train_batch_end: 1607804365.101581s

45056/50000 [==========================>...] - ETA: 2s - loss: 7.1583 - accuracy: 0.0609
on_train_batch_begin: 1607804365.101961s

44 step training time: 0.115568s

on_train_batch_end: 1607804365.218720s

46080/50000 [==========================>...] - ETA: 1s - loss: 7.1329 - accuracy: 0.0612
on_train_batch_begin: 1607804365.219120s

45 step training time: 0.117158s

on_train_batch_end: 1607804365.334256s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.1025 - accuracy: 0.0617
on_train_batch_begin: 1607804365.334639s

46 step training time: 0.115520s

on_train_batch_end: 1607804365.448996s

48128/50000 [===========================>..] - ETA: 0s - loss: 7.0725 - accuracy: 0.0620
on_train_batch_begin: 1607804365.449406s

47 step training time: 0.114766s

on_train_batch_end: 1607804365.563102s

49152/50000 [============================>.] - ETA: 0s - loss: 7.0500 - accuracy: 0.0625
on_train_batch_begin: 1607804365.563478s

48 step training time: 0.114073s

on_train_batch_end: 1607804367.410260s

on_test_batch_begin: 1607804367.626599s

49 step training time: 2.063121s

on_epoch_end: 1607804370.975386s

Validation time: 3.348767s

Real time: 1607804370.975386s

Epoch time: 27.36793828010559s

50000/50000 [==============================] - 27s 547us/sample - loss: 7.0256 - accuracy: 0.0627 - val_loss: 36.0409 - val_accuracy: 0.0000e+00

on_epoch_begin: 1607804370.975663s

Real time: 1607804370.975676
Epoch 2/5

on_train_batch_begin: 1607804370.979933s

on_train_batch_end: 1607804371.094187s

 1024/50000 [..............................] - ETA: 5s - loss: 5.6979 - accuracy: 0.0754
on_train_batch_begin: 1607804371.094583s

1 step training time: 0.114650s

on_train_batch_end: 1607804371.209003s

 2048/50000 [>.............................] - ETA: 5s - loss: 5.6486 - accuracy: 0.0783
on_train_batch_begin: 1607804371.209419s

2 step training time: 0.114836s

on_train_batch_end: 1607804371.323598s

 3072/50000 [>.............................] - ETA: 5s - loss: 5.6454 - accuracy: 0.0803
on_train_batch_begin: 1607804371.323974s

3 step training time: 0.114555s

on_train_batch_end: 1607804371.438672s

 4096/50000 [=>............................] - ETA: 5s - loss: 5.5897 - accuracy: 0.0812
on_train_batch_begin: 1607804371.439061s

4 step training time: 0.115087s

on_train_batch_end: 1607804371.554118s

 5120/50000 [==>...........................] - ETA: 5s - loss: 5.5420 - accuracy: 0.0811
on_train_batch_begin: 1607804371.554528s

5 step training time: 0.115468s

on_train_batch_end: 1607804371.669359s

 6144/50000 [==>...........................] - ETA: 4s - loss: 5.5014 - accuracy: 0.0810
on_train_batch_begin: 1607804371.669769s

6 step training time: 0.115240s

on_train_batch_end: 1607804371.784550s

 7168/50000 [===>..........................] - ETA: 4s - loss: 5.4782 - accuracy: 0.0806
on_train_batch_begin: 1607804371.784926s

7 step training time: 0.115157s

on_train_batch_end: 1607804371.899600s

 8192/50000 [===>..........................] - ETA: 4s - loss: 5.4288 - accuracy: 0.0804
on_train_batch_begin: 1607804371.899994s

8 step training time: 0.115068s

on_train_batch_end: 1607804372.015101s

 9216/50000 [====>.........................] - ETA: 4s - loss: 5.4108 - accuracy: 0.0800
on_train_batch_begin: 1607804372.015476s

9 step training time: 0.115482s

on_train_batch_end: 1607804372.134101s

10240/50000 [=====>........................] - ETA: 4s - loss: 5.3950 - accuracy: 0.0797
on_train_batch_begin: 1607804372.134485s

10 step training time: 0.119010s

on_train_batch_end: 1607804372.249795s

11264/50000 [=====>........................] - ETA: 4s - loss: 5.3741 - accuracy: 0.0798
on_train_batch_begin: 1607804372.250179s

11 step training time: 0.115694s

on_train_batch_end: 1607804372.365434s

12288/50000 [======>.......................] - ETA: 4s - loss: 5.3487 - accuracy: 0.0792
on_train_batch_begin: 1607804372.365823s

12 step training time: 0.115644s

on_train_batch_end: 1607804372.479681s

13312/50000 [======>.......................] - ETA: 4s - loss: 5.3155 - accuracy: 0.0787
on_train_batch_begin: 1607804372.480062s

13 step training time: 0.114239s

on_train_batch_end: 1607804372.595000s

14336/50000 [=======>......................] - ETA: 4s - loss: 5.2781 - accuracy: 0.0784
on_train_batch_begin: 1607804372.595374s

14 step training time: 0.115312s

on_train_batch_end: 1607804372.709843s

15360/50000 [========>.....................] - ETA: 3s - loss: 5.2353 - accuracy: 0.0778
on_train_batch_begin: 1607804372.710230s

15 step training time: 0.114856s

on_train_batch_end: 1607804372.824953s

16384/50000 [========>.....................] - ETA: 3s - loss: 5.2009 - accuracy: 0.0773
on_train_batch_begin: 1607804372.825391s

16 step training time: 0.115161s

on_train_batch_end: 1607804372.940107s

17408/50000 [=========>....................] - ETA: 3s - loss: 5.1640 - accuracy: 0.0766
on_train_batch_begin: 1607804372.940489s

17 step training time: 0.115098s

on_train_batch_end: 1607804373.055180s

18432/50000 [==========>...................] - ETA: 3s - loss: 5.1300 - accuracy: 0.0760
on_train_batch_begin: 1607804373.055562s

18 step training time: 0.115073s

on_train_batch_end: 1607804373.170291s

19456/50000 [==========>...................] - ETA: 3s - loss: 5.1022 - accuracy: 0.0753
on_train_batch_begin: 1607804373.170693s

19 step training time: 0.115132s

on_train_batch_end: 1607804373.284781s

20480/50000 [===========>..................] - ETA: 3s - loss: 5.0675 - accuracy: 0.0749
on_train_batch_begin: 1607804373.285160s

20 step training time: 0.114466s

on_train_batch_end: 1607804373.399442s

21504/50000 [===========>..................] - ETA: 3s - loss: 5.0308 - accuracy: 0.0745
on_train_batch_begin: 1607804373.399819s

21 step training time: 0.114660s

on_train_batch_end: 1607804373.515184s

22528/50000 [============>.................] - ETA: 3s - loss: 4.9981 - accuracy: 0.0742
on_train_batch_begin: 1607804373.515560s

22 step training time: 0.115741s

on_train_batch_end: 1607804373.630007s

23552/50000 [=============>................] - ETA: 2s - loss: 4.9594 - accuracy: 0.0742
on_train_batch_begin: 1607804373.630386s

23 step training time: 0.114826s

on_train_batch_end: 1607804373.744036s

24576/50000 [=============>................] - ETA: 2s - loss: 4.9254 - accuracy: 0.0741
on_train_batch_begin: 1607804373.744422s

24 step training time: 0.114036s

on_train_batch_end: 1607804373.860992s

25600/50000 [==============>...............] - ETA: 2s - loss: 4.8859 - accuracy: 0.0743
on_train_batch_begin: 1607804373.861408s

25 step training time: 0.116986s

on_train_batch_end: 1607804373.976571s

26624/50000 [==============>...............] - ETA: 2s - loss: 4.8500 - accuracy: 0.0745
on_train_batch_begin: 1607804373.976951s

26 step training time: 0.115543s

on_train_batch_end: 1607804374.091958s

27648/50000 [===============>..............] - ETA: 2s - loss: 4.8144 - accuracy: 0.0747
on_train_batch_begin: 1607804374.092333s

27 step training time: 0.115382s

on_train_batch_end: 1607804374.206344s

28672/50000 [================>.............] - ETA: 2s - loss: 4.7734 - accuracy: 0.0749
on_train_batch_begin: 1607804374.206725s

28 step training time: 0.114393s

on_train_batch_end: 1607804374.322378s

29696/50000 [================>.............] - ETA: 2s - loss: 4.7336 - accuracy: 0.0752
on_train_batch_begin: 1607804374.322880s

29 step training time: 0.116155s

on_train_batch_end: 1607804374.438636s

30720/50000 [=================>............] - ETA: 2s - loss: 4.6916 - accuracy: 0.0756
on_train_batch_begin: 1607804374.439025s

30 step training time: 0.116145s

on_train_batch_end: 1607804374.553088s

31744/50000 [==================>...........] - ETA: 2s - loss: 4.6388 - accuracy: 0.0761
on_train_batch_begin: 1607804374.553508s

31 step training time: 0.114482s

on_train_batch_end: 1607804374.666487s

32768/50000 [==================>...........] - ETA: 1s - loss: 4.5992 - accuracy: 0.0766
on_train_batch_begin: 1607804374.666869s

32 step training time: 0.113361s

on_train_batch_end: 1607804374.783016s

33792/50000 [===================>..........] - ETA: 1s - loss: 4.5582 - accuracy: 0.0771
on_train_batch_begin: 1607804374.783405s

33 step training time: 0.116536s

on_train_batch_end: 1607804374.899458s

34816/50000 [===================>..........] - ETA: 1s - loss: 4.5256 - accuracy: 0.0774
on_train_batch_begin: 1607804374.899842s

34 step training time: 0.116436s

on_train_batch_end: 1607804375.014345s

35840/50000 [====================>.........] - ETA: 1s - loss: 4.4939 - accuracy: 0.0779
on_train_batch_begin: 1607804375.014723s

35 step training time: 0.114881s

on_train_batch_end: 1607804375.127806s

36864/50000 [=====================>........] - ETA: 1s - loss: 4.4677 - accuracy: 0.0782
on_train_batch_begin: 1607804375.128182s

36 step training time: 0.113460s

on_train_batch_end: 1607804375.242899s

37888/50000 [=====================>........] - ETA: 1s - loss: 4.4310 - accuracy: 0.0787
on_train_batch_begin: 1607804375.243274s

37 step training time: 0.115092s

on_train_batch_end: 1607804375.357550s

38912/50000 [======================>.......] - ETA: 1s - loss: 4.4064 - accuracy: 0.0791
on_train_batch_begin: 1607804375.357933s

38 step training time: 0.114660s

on_train_batch_end: 1607804375.472252s

39936/50000 [======================>.......] - ETA: 1s - loss: 4.3754 - accuracy: 0.0795
on_train_batch_begin: 1607804375.472631s

39 step training time: 0.114698s

on_train_batch_end: 1607804375.587703s

40960/50000 [=======================>......] - ETA: 1s - loss: 4.3534 - accuracy: 0.0799
on_train_batch_begin: 1607804375.588089s

40 step training time: 0.115457s

on_train_batch_end: 1607804375.702821s

41984/50000 [========================>.....] - ETA: 0s - loss: 4.3294 - accuracy: 0.0803
on_train_batch_begin: 1607804375.703204s

41 step training time: 0.115116s

on_train_batch_end: 1607804375.817756s

43008/50000 [========================>.....] - ETA: 0s - loss: 4.3067 - accuracy: 0.0807
on_train_batch_begin: 1607804375.818143s

42 step training time: 0.114938s

on_train_batch_end: 1607804375.932439s

44032/50000 [=========================>....] - ETA: 0s - loss: 4.2806 - accuracy: 0.0811
on_train_batch_begin: 1607804375.932817s

43 step training time: 0.114675s

on_train_batch_end: 1607804376.049828s

45056/50000 [==========================>...] - ETA: 0s - loss: 4.2557 - accuracy: 0.0815
on_train_batch_begin: 1607804376.050209s

44 step training time: 0.117391s

on_train_batch_end: 1607804376.165375s

46080/50000 [==========================>...] - ETA: 0s - loss: 4.2307 - accuracy: 0.0818
on_train_batch_begin: 1607804376.165755s

45 step training time: 0.115546s

on_train_batch_end: 1607804376.281133s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.2070 - accuracy: 0.0821
on_train_batch_begin: 1607804376.281548s

46 step training time: 0.115793s

on_train_batch_end: 1607804376.396127s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.1858 - accuracy: 0.0824
on_train_batch_begin: 1607804376.396507s

47 step training time: 0.114959s

on_train_batch_end: 1607804376.512506s

49152/50000 [============================>.] - ETA: 0s - loss: 4.1678 - accuracy: 0.0827
on_train_batch_begin: 1607804376.512881s

48 step training time: 0.116374s

on_train_batch_end: 1607804376.614089s

on_test_batch_begin: 1607804376.632255s

49 step training time: 0.119374s

on_epoch_end: 1607804377.037616s

Validation time: 0.405347s

Real time: 1607804377.037616s

Epoch time: 6.0619611740112305s

50000/50000 [==============================] - 6s 121us/sample - loss: 4.1517 - accuracy: 0.0829 - val_loss: 7.3730 - val_accuracy: 6.1859e-04

on_epoch_begin: 1607804377.037879s

Real time: 1607804377.0378914
Epoch 3/5

on_train_batch_begin: 1607804377.042063s

on_train_batch_end: 1607804377.156319s

 1024/50000 [..............................] - ETA: 5s - loss: 2.9700 - accuracy: 0.0981
on_train_batch_begin: 1607804377.156708s

1 step training time: 0.114645s

on_train_batch_end: 1607804377.271082s

 2048/50000 [>.............................] - ETA: 5s - loss: 2.9335 - accuracy: 0.0987
on_train_batch_begin: 1607804377.271467s

2 step training time: 0.114759s

on_train_batch_end: 1607804377.387342s

 3072/50000 [>.............................] - ETA: 5s - loss: 2.9481 - accuracy: 0.0987
on_train_batch_begin: 1607804377.387726s

3 step training time: 0.116260s

on_train_batch_end: 1607804377.502045s

 4096/50000 [=>............................] - ETA: 5s - loss: 2.9293 - accuracy: 0.0989
on_train_batch_begin: 1607804377.502433s

4 step training time: 0.114707s

on_train_batch_end: 1607804377.616943s

 5120/50000 [==>...........................] - ETA: 5s - loss: 2.9267 - accuracy: 0.0988
on_train_batch_begin: 1607804377.617356s

5 step training time: 0.114922s

on_train_batch_end: 1607804377.731953s

 6144/50000 [==>...........................] - ETA: 4s - loss: 2.9320 - accuracy: 0.0986
on_train_batch_begin: 1607804377.732341s

6 step training time: 0.114985s

on_train_batch_end: 1607804377.847305s

 7168/50000 [===>..........................] - ETA: 4s - loss: 2.9075 - accuracy: 0.0984
on_train_batch_begin: 1607804377.847691s

7 step training time: 0.115350s

on_train_batch_end: 1607804377.962258s

 8192/50000 [===>..........................] - ETA: 4s - loss: 2.8969 - accuracy: 0.0984
on_train_batch_begin: 1607804377.962640s

8 step training time: 0.114949s

on_train_batch_end: 1607804378.077519s

 9216/50000 [====>.........................] - ETA: 4s - loss: 2.9003 - accuracy: 0.0984
on_train_batch_begin: 1607804378.077893s

9 step training time: 0.115253s

on_train_batch_end: 1607804378.192704s

10240/50000 [=====>........................] - ETA: 4s - loss: 2.9088 - accuracy: 0.0986
on_train_batch_begin: 1607804378.193082s

10 step training time: 0.115190s

on_train_batch_end: 1607804378.307672s

11264/50000 [=====>........................] - ETA: 4s - loss: 2.9385 - accuracy: 0.0986
on_train_batch_begin: 1607804378.308051s

11 step training time: 0.114969s

on_train_batch_end: 1607804378.422083s

12288/50000 [======>.......................] - ETA: 4s - loss: 2.9353 - accuracy: 0.0987
on_train_batch_begin: 1607804378.422473s

12 step training time: 0.114422s

on_train_batch_end: 1607804378.537132s

13312/50000 [======>.......................] - ETA: 4s - loss: 2.9255 - accuracy: 0.0986
on_train_batch_begin: 1607804378.537559s

13 step training time: 0.115086s

on_train_batch_end: 1607804378.652080s

14336/50000 [=======>......................] - ETA: 4s - loss: 2.9151 - accuracy: 0.0986
on_train_batch_begin: 1607804378.652460s

14 step training time: 0.114902s

on_train_batch_end: 1607804378.767230s

15360/50000 [========>.....................] - ETA: 3s - loss: 2.9086 - accuracy: 0.0987
on_train_batch_begin: 1607804378.767613s

15 step training time: 0.115153s

on_train_batch_end: 1607804378.882507s

16384/50000 [========>.....................] - ETA: 3s - loss: 2.9062 - accuracy: 0.0987
on_train_batch_begin: 1607804378.882884s

16 step training time: 0.115270s

on_train_batch_end: 1607804378.997206s

17408/50000 [=========>....................] - ETA: 3s - loss: 2.9020 - accuracy: 0.0987
on_train_batch_begin: 1607804378.997606s

17 step training time: 0.114722s

on_train_batch_end: 1607804379.113767s

18432/50000 [==========>...................] - ETA: 3s - loss: 2.8952 - accuracy: 0.0987
on_train_batch_begin: 1607804379.114146s

18 step training time: 0.116540s

on_train_batch_end: 1607804379.228949s

19456/50000 [==========>...................] - ETA: 3s - loss: 2.8803 - accuracy: 0.0988
on_train_batch_begin: 1607804379.229386s

19 step training time: 0.115240s

on_train_batch_end: 1607804379.344157s

20480/50000 [===========>..................] - ETA: 3s - loss: 2.8721 - accuracy: 0.0989
on_train_batch_begin: 1607804379.344575s

20 step training time: 0.115189s

on_train_batch_end: 1607804379.459404s

21504/50000 [===========>..................] - ETA: 3s - loss: 2.8636 - accuracy: 0.0989
on_train_batch_begin: 1607804379.459786s

21 step training time: 0.115211s

on_train_batch_end: 1607804379.574528s

22528/50000 [============>.................] - ETA: 3s - loss: 2.8456 - accuracy: 0.0990
on_train_batch_begin: 1607804379.574911s

22 step training time: 0.115124s

on_train_batch_end: 1607804379.692036s

23552/50000 [=============>................] - ETA: 2s - loss: 2.8361 - accuracy: 0.0990
on_train_batch_begin: 1607804379.692419s

23 step training time: 0.117509s

on_train_batch_end: 1607804379.806932s

24576/50000 [=============>................] - ETA: 2s - loss: 2.8241 - accuracy: 0.0990
on_train_batch_begin: 1607804379.807317s

24 step training time: 0.114898s

on_train_batch_end: 1607804379.921701s

25600/50000 [==============>...............] - ETA: 2s - loss: 2.8123 - accuracy: 0.0991
on_train_batch_begin: 1607804379.922085s

25 step training time: 0.114768s

on_train_batch_end: 1607804380.039136s

26624/50000 [==============>...............] - ETA: 2s - loss: 2.7989 - accuracy: 0.0991
on_train_batch_begin: 1607804380.039522s

26 step training time: 0.117437s

on_train_batch_end: 1607804380.153647s

27648/50000 [===============>..............] - ETA: 2s - loss: 2.7826 - accuracy: 0.0991
on_train_batch_begin: 1607804380.154027s

27 step training time: 0.114505s

on_train_batch_end: 1607804380.271268s

28672/50000 [================>.............] - ETA: 2s - loss: 2.7763 - accuracy: 0.0991
on_train_batch_begin: 1607804380.271652s

28 step training time: 0.117625s

on_train_batch_end: 1607804380.386056s

29696/50000 [================>.............] - ETA: 2s - loss: 2.7584 - accuracy: 0.0991
on_train_batch_begin: 1607804380.386437s

29 step training time: 0.114785s

on_train_batch_end: 1607804380.500997s

30720/50000 [=================>............] - ETA: 2s - loss: 2.7425 - accuracy: 0.0992
on_train_batch_begin: 1607804380.501417s

30 step training time: 0.114980s

on_train_batch_end: 1607804380.616140s

31744/50000 [==================>...........] - ETA: 2s - loss: 2.7337 - accuracy: 0.0992
on_train_batch_begin: 1607804380.616517s

31 step training time: 0.115100s

on_train_batch_end: 1607804380.731043s

32768/50000 [==================>...........] - ETA: 1s - loss: 2.7238 - accuracy: 0.0992
on_train_batch_begin: 1607804380.731437s

32 step training time: 0.114920s

on_train_batch_end: 1607804380.846289s

33792/50000 [===================>..........] - ETA: 1s - loss: 2.7142 - accuracy: 0.0993
on_train_batch_begin: 1607804380.846682s

33 step training time: 0.115245s

on_train_batch_end: 1607804380.961665s

34816/50000 [===================>..........] - ETA: 1s - loss: 2.7068 - accuracy: 0.0993
on_train_batch_begin: 1607804380.962048s

34 step training time: 0.115366s

on_train_batch_end: 1607804381.076651s

35840/50000 [====================>.........] - ETA: 1s - loss: 2.6998 - accuracy: 0.0994
on_train_batch_begin: 1607804381.077031s

35 step training time: 0.114983s

on_train_batch_end: 1607804381.192307s

36864/50000 [=====================>........] - ETA: 1s - loss: 2.6955 - accuracy: 0.0994
on_train_batch_begin: 1607804381.192690s

36 step training time: 0.115659s

on_train_batch_end: 1607804381.307440s

37888/50000 [=====================>........] - ETA: 1s - loss: 2.6825 - accuracy: 0.0994
on_train_batch_begin: 1607804381.307819s

37 step training time: 0.115129s

on_train_batch_end: 1607804381.423317s

38912/50000 [======================>.......] - ETA: 1s - loss: 2.6732 - accuracy: 0.0994
on_train_batch_begin: 1607804381.423693s

38 step training time: 0.115874s

on_train_batch_end: 1607804381.538216s

39936/50000 [======================>.......] - ETA: 1s - loss: 2.6564 - accuracy: 0.0994
on_train_batch_begin: 1607804381.538597s

39 step training time: 0.114904s

on_train_batch_end: 1607804381.652598s

40960/50000 [=======================>......] - ETA: 1s - loss: 2.6391 - accuracy: 0.0995
on_train_batch_begin: 1607804381.652995s

40 step training time: 0.114398s

on_train_batch_end: 1607804381.766725s

41984/50000 [========================>.....] - ETA: 0s - loss: 2.6322 - accuracy: 0.0994
on_train_batch_begin: 1607804381.767106s

41 step training time: 0.114111s

on_train_batch_end: 1607804381.882050s

43008/50000 [========================>.....] - ETA: 0s - loss: 2.6190 - accuracy: 0.0995
on_train_batch_begin: 1607804381.882430s

42 step training time: 0.115324s

on_train_batch_end: 1607804381.997108s

44032/50000 [=========================>....] - ETA: 0s - loss: 2.6098 - accuracy: 0.0995
on_train_batch_begin: 1607804381.997514s

43 step training time: 0.115084s

on_train_batch_end: 1607804382.111758s

45056/50000 [==========================>...] - ETA: 0s - loss: 2.5959 - accuracy: 0.0995
on_train_batch_begin: 1607804382.112133s

44 step training time: 0.114619s

on_train_batch_end: 1607804382.226732s

46080/50000 [==========================>...] - ETA: 0s - loss: 2.5824 - accuracy: 0.0995
on_train_batch_begin: 1607804382.227110s

45 step training time: 0.114977s

on_train_batch_end: 1607804382.341850s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.5714 - accuracy: 0.0995
on_train_batch_begin: 1607804382.342230s

46 step training time: 0.115120s

on_train_batch_end: 1607804382.457775s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.5579 - accuracy: 0.0995
on_train_batch_begin: 1607804382.458176s

47 step training time: 0.115946s

on_train_batch_end: 1607804382.572390s

49152/50000 [============================>.] - ETA: 0s - loss: 2.5460 - accuracy: 0.0995
on_train_batch_begin: 1607804382.572793s

48 step training time: 0.114616s

on_train_batch_end: 1607804382.673208s

on_test_batch_begin: 1607804382.689394s

49 step training time: 0.116601s

on_epoch_end: 1607804383.094496s

Validation time: 0.405087s

Real time: 1607804383.094496s

Epoch time: 6.056625843048096s

50000/50000 [==============================] - 6s 121us/sample - loss: 2.5364 - accuracy: 0.0995 - val_loss: 7.5645 - val_accuracy: 0.0945

on_epoch_begin: 1607804383.094747s

Real time: 1607804383.0947568
Epoch 4/5

on_train_batch_begin: 1607804383.098941s

on_train_batch_end: 1607804383.213997s

 1024/50000 [..............................] - ETA: 5s - loss: 1.8479 - accuracy: 0.0997
on_train_batch_begin: 1607804383.214378s

1 step training time: 0.115437s

on_train_batch_end: 1607804383.329327s

 2048/50000 [>.............................] - ETA: 5s - loss: 1.8092 - accuracy: 0.1000
on_train_batch_begin: 1607804383.329702s

2 step training time: 0.115324s

on_train_batch_end: 1607804383.446260s

 3072/50000 [>.............................] - ETA: 5s - loss: 1.7970 - accuracy: 0.1000
on_train_batch_begin: 1607804383.446638s

3 step training time: 0.116937s

on_train_batch_end: 1607804383.561830s

 4096/50000 [=>............................] - ETA: 5s - loss: 1.7467 - accuracy: 0.1001
on_train_batch_begin: 1607804383.562234s

4 step training time: 0.115596s

on_train_batch_end: 1607804383.676779s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.7454 - accuracy: 0.1001
on_train_batch_begin: 1607804383.677165s

5 step training time: 0.114931s

on_train_batch_end: 1607804383.792155s

 6144/50000 [==>...........................] - ETA: 4s - loss: 1.7685 - accuracy: 0.1001
on_train_batch_begin: 1607804383.792548s

6 step training time: 0.115383s

on_train_batch_end: 1607804383.907342s

 7168/50000 [===>..........................] - ETA: 4s - loss: 1.7499 - accuracy: 0.1001
on_train_batch_begin: 1607804383.907720s

7 step training time: 0.115172s

on_train_batch_end: 1607804384.022001s

 8192/50000 [===>..........................] - ETA: 4s - loss: 1.7106 - accuracy: 0.1002
on_train_batch_begin: 1607804384.022382s

8 step training time: 0.114662s

on_train_batch_end: 1607804384.136887s

 9216/50000 [====>.........................] - ETA: 4s - loss: 1.7137 - accuracy: 0.1002
on_train_batch_begin: 1607804384.137294s

9 step training time: 0.114912s

on_train_batch_end: 1607804384.251728s

10240/50000 [=====>........................] - ETA: 4s - loss: 1.7077 - accuracy: 0.1002
on_train_batch_begin: 1607804384.252111s

10 step training time: 0.114817s

on_train_batch_end: 1607804384.366782s

11264/50000 [=====>........................] - ETA: 4s - loss: 1.7127 - accuracy: 0.1002
on_train_batch_begin: 1607804384.367163s

11 step training time: 0.115052s

on_train_batch_end: 1607804384.481636s

12288/50000 [======>.......................] - ETA: 4s - loss: 1.7165 - accuracy: 0.1001
on_train_batch_begin: 1607804384.482014s

12 step training time: 0.114851s

on_train_batch_end: 1607804384.598606s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.7061 - accuracy: 0.1002
on_train_batch_begin: 1607804384.598989s

13 step training time: 0.116975s

on_train_batch_end: 1607804384.714174s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.7009 - accuracy: 0.1002
on_train_batch_begin: 1607804384.714565s

14 step training time: 0.115576s

on_train_batch_end: 1607804384.828826s

15360/50000 [========>.....................] - ETA: 3s - loss: 1.6901 - accuracy: 0.1001
on_train_batch_begin: 1607804384.829239s

15 step training time: 0.114674s

on_train_batch_end: 1607804384.943996s

16384/50000 [========>.....................] - ETA: 3s - loss: 1.6848 - accuracy: 0.1002
on_train_batch_begin: 1607804384.944403s

16 step training time: 0.115164s

on_train_batch_end: 1607804385.059162s

17408/50000 [=========>....................] - ETA: 3s - loss: 1.6736 - accuracy: 0.1002
on_train_batch_begin: 1607804385.059548s

17 step training time: 0.115145s

on_train_batch_end: 1607804385.174323s

18432/50000 [==========>...................] - ETA: 3s - loss: 1.6654 - accuracy: 0.1002
on_train_batch_begin: 1607804385.174697s

18 step training time: 0.115149s

on_train_batch_end: 1607804385.290077s

19456/50000 [==========>...................] - ETA: 3s - loss: 1.6540 - accuracy: 0.1002
on_train_batch_begin: 1607804385.290454s

19 step training time: 0.115757s

on_train_batch_end: 1607804385.404659s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.6455 - accuracy: 0.1002
on_train_batch_begin: 1607804385.405050s

20 step training time: 0.114596s

on_train_batch_end: 1607804385.521615s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.6347 - accuracy: 0.1002
on_train_batch_begin: 1607804385.521998s

21 step training time: 0.116948s

on_train_batch_end: 1607804385.637630s

22528/50000 [============>.................] - ETA: 3s - loss: 1.6270 - accuracy: 0.1002
on_train_batch_begin: 1607804385.638011s

22 step training time: 0.116013s

on_train_batch_end: 1607804385.751984s

23552/50000 [=============>................] - ETA: 2s - loss: 1.6204 - accuracy: 0.1002
on_train_batch_begin: 1607804385.752370s

23 step training time: 0.114360s

on_train_batch_end: 1607804385.869336s

24576/50000 [=============>................] - ETA: 2s - loss: 1.6116 - accuracy: 0.1002
on_train_batch_begin: 1607804385.869714s

24 step training time: 0.117344s

on_train_batch_end: 1607804385.984651s

25600/50000 [==============>...............] - ETA: 2s - loss: 1.6037 - accuracy: 0.1002
on_train_batch_begin: 1607804385.985028s

25 step training time: 0.115314s

on_train_batch_end: 1607804386.099682s

26624/50000 [==============>...............] - ETA: 2s - loss: 1.5956 - accuracy: 0.1002
on_train_batch_begin: 1607804386.100060s

26 step training time: 0.115032s

on_train_batch_end: 1607804386.214663s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.5847 - accuracy: 0.1002
on_train_batch_begin: 1607804386.215046s

27 step training time: 0.114985s

on_train_batch_end: 1607804386.329552s

28672/50000 [================>.............] - ETA: 2s - loss: 1.5792 - accuracy: 0.1002
on_train_batch_begin: 1607804386.329931s

28 step training time: 0.114885s

on_train_batch_end: 1607804386.444546s

29696/50000 [================>.............] - ETA: 2s - loss: 1.5756 - accuracy: 0.1002
on_train_batch_begin: 1607804386.444926s

29 step training time: 0.114995s

on_train_batch_end: 1607804386.559363s

30720/50000 [=================>............] - ETA: 2s - loss: 1.5705 - accuracy: 0.1002
on_train_batch_begin: 1607804386.559743s

30 step training time: 0.114818s

on_train_batch_end: 1607804386.674697s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.5646 - accuracy: 0.1002
on_train_batch_begin: 1607804386.675074s

31 step training time: 0.115331s

on_train_batch_end: 1607804386.789331s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.5572 - accuracy: 0.1002
on_train_batch_begin: 1607804386.789707s

32 step training time: 0.114633s

on_train_batch_end: 1607804386.904163s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.5478 - accuracy: 0.1002
on_train_batch_begin: 1607804386.904542s

33 step training time: 0.114835s

on_train_batch_end: 1607804387.019787s

34816/50000 [===================>..........] - ETA: 1s - loss: 1.5466 - accuracy: 0.1002
on_train_batch_begin: 1607804387.020171s

34 step training time: 0.115629s

on_train_batch_end: 1607804387.133840s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.5381 - accuracy: 0.1002
on_train_batch_begin: 1607804387.134223s

35 step training time: 0.114051s

on_train_batch_end: 1607804387.248500s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.5312 - accuracy: 0.1002
on_train_batch_begin: 1607804387.248880s

36 step training time: 0.114657s

on_train_batch_end: 1607804387.363224s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.5287 - accuracy: 0.1002
on_train_batch_begin: 1607804387.363605s

37 step training time: 0.114726s

on_train_batch_end: 1607804387.478382s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.5283 - accuracy: 0.1002
on_train_batch_begin: 1607804387.478760s

38 step training time: 0.115155s

on_train_batch_end: 1607804387.593307s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.5231 - accuracy: 0.1002
on_train_batch_begin: 1607804387.593698s

39 step training time: 0.114937s

on_train_batch_end: 1607804387.708630s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.5180 - accuracy: 0.1002
on_train_batch_begin: 1607804387.709020s

40 step training time: 0.115322s

on_train_batch_end: 1607804387.824263s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.5144 - accuracy: 0.1002
on_train_batch_begin: 1607804387.824647s

41 step training time: 0.115628s

on_train_batch_end: 1607804387.939812s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.5074 - accuracy: 0.1002
on_train_batch_begin: 1607804387.940188s

42 step training time: 0.115541s

on_train_batch_end: 1607804388.056333s

44032/50000 [=========================>....] - ETA: 0s - loss: 1.5001 - accuracy: 0.1002
on_train_batch_begin: 1607804388.056710s

43 step training time: 0.116521s

on_train_batch_end: 1607804388.172008s

45056/50000 [==========================>...] - ETA: 0s - loss: 1.4959 - accuracy: 0.1002
on_train_batch_begin: 1607804388.172424s

44 step training time: 0.115715s

on_train_batch_end: 1607804388.287972s

46080/50000 [==========================>...] - ETA: 0s - loss: 1.4872 - accuracy: 0.1002
on_train_batch_begin: 1607804388.288352s

45 step training time: 0.115928s

on_train_batch_end: 1607804388.404822s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.4805 - accuracy: 0.1002
on_train_batch_begin: 1607804388.405201s

46 step training time: 0.116848s

on_train_batch_end: 1607804388.520859s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.4740 - accuracy: 0.1002
on_train_batch_begin: 1607804388.521230s

47 step training time: 0.116029s

on_train_batch_end: 1607804388.635134s

49152/50000 [============================>.] - ETA: 0s - loss: 1.4684 - accuracy: 0.1002
on_train_batch_begin: 1607804388.635523s

48 step training time: 0.114293s

on_train_batch_end: 1607804388.735196s

on_test_batch_begin: 1607804388.750440s

49 step training time: 0.114917s

on_epoch_end: 1607804389.168992s

Validation time: 0.418538s

Real time: 1607804389.168992s

Epoch time: 6.07425594329834s

50000/50000 [==============================] - 6s 121us/sample - loss: 1.4631 - accuracy: 0.1002 - val_loss: 7.2041 - val_accuracy: 0.1001

on_epoch_begin: 1607804389.169243s

Real time: 1607804389.1692545
Epoch 5/5

on_train_batch_begin: 1607804389.173477s

on_train_batch_end: 1607804389.288410s

 1024/50000 [..............................] - ETA: 5s - loss: 1.0916 - accuracy: 0.1000
on_train_batch_begin: 1607804389.288790s

1 step training time: 0.115313s

on_train_batch_end: 1607804389.403852s

 2048/50000 [>.............................] - ETA: 5s - loss: 1.1379 - accuracy: 0.1000
on_train_batch_begin: 1607804389.404233s

2 step training time: 0.115442s

on_train_batch_end: 1607804389.519165s

 3072/50000 [>.............................] - ETA: 5s - loss: 1.1570 - accuracy: 0.1000
on_train_batch_begin: 1607804389.519540s

3 step training time: 0.115307s

on_train_batch_end: 1607804389.634454s

 4096/50000 [=>............................] - ETA: 5s - loss: 1.1609 - accuracy: 0.1002
on_train_batch_begin: 1607804389.634864s

4 step training time: 0.115324s

on_train_batch_end: 1607804389.751767s

 5120/50000 [==>...........................] - ETA: 5s - loss: 1.1257 - accuracy: 0.1002
on_train_batch_begin: 1607804389.752147s

5 step training time: 0.117283s

on_train_batch_end: 1607804389.869187s

 6144/50000 [==>...........................] - ETA: 4s - loss: 1.1120 - accuracy: 0.1002
on_train_batch_begin: 1607804389.869673s

6 step training time: 0.117526s

on_train_batch_end: 1607804389.984146s

 7168/50000 [===>..........................] - ETA: 4s - loss: 1.1041 - accuracy: 0.1001
on_train_batch_begin: 1607804389.984533s

7 step training time: 0.114860s

on_train_batch_end: 1607804390.100899s

 8192/50000 [===>..........................] - ETA: 4s - loss: 1.0967 - accuracy: 0.1002
on_train_batch_begin: 1607804390.101304s

8 step training time: 0.116771s

on_train_batch_end: 1607804390.216256s

 9216/50000 [====>.........................] - ETA: 4s - loss: 1.0743 - accuracy: 0.1002
on_train_batch_begin: 1607804390.216637s

9 step training time: 0.115332s

on_train_batch_end: 1607804390.330894s

10240/50000 [=====>........................] - ETA: 4s - loss: 1.0684 - accuracy: 0.1002
on_train_batch_begin: 1607804390.331285s

10 step training time: 0.114649s

on_train_batch_end: 1607804390.445145s

11264/50000 [=====>........................] - ETA: 4s - loss: 1.0672 - accuracy: 0.1002
on_train_batch_begin: 1607804390.445549s

11 step training time: 0.114264s

on_train_batch_end: 1607804390.560431s

12288/50000 [======>.......................] - ETA: 4s - loss: 1.0660 - accuracy: 0.1002
on_train_batch_begin: 1607804390.560805s

12 step training time: 0.115256s

on_train_batch_end: 1607804390.677325s

13312/50000 [======>.......................] - ETA: 4s - loss: 1.0661 - accuracy: 0.1003
on_train_batch_begin: 1607804390.677708s

13 step training time: 0.116903s

on_train_batch_end: 1607804390.792314s

14336/50000 [=======>......................] - ETA: 4s - loss: 1.0652 - accuracy: 0.1003
on_train_batch_begin: 1607804390.792699s

14 step training time: 0.114990s

on_train_batch_end: 1607804390.906978s

15360/50000 [========>.....................] - ETA: 3s - loss: 1.0704 - accuracy: 0.1003
on_train_batch_begin: 1607804390.907351s

15 step training time: 0.114652s

on_train_batch_end: 1607804391.021811s

16384/50000 [========>.....................] - ETA: 3s - loss: 1.0683 - accuracy: 0.1003
on_train_batch_begin: 1607804391.022184s

16 step training time: 0.114833s

on_train_batch_end: 1607804391.136562s

17408/50000 [=========>....................] - ETA: 3s - loss: 1.0678 - accuracy: 0.1003
on_train_batch_begin: 1607804391.136946s

17 step training time: 0.114762s

on_train_batch_end: 1607804391.251701s

18432/50000 [==========>...................] - ETA: 3s - loss: 1.0614 - accuracy: 0.1003
on_train_batch_begin: 1607804391.252080s

18 step training time: 0.115134s

on_train_batch_end: 1607804391.366921s

19456/50000 [==========>...................] - ETA: 3s - loss: 1.0586 - accuracy: 0.1004
on_train_batch_begin: 1607804391.367300s

19 step training time: 0.115219s

on_train_batch_end: 1607804391.482203s

20480/50000 [===========>..................] - ETA: 3s - loss: 1.0536 - accuracy: 0.1003
on_train_batch_begin: 1607804391.482600s

20 step training time: 0.115301s

on_train_batch_end: 1607804391.597602s

21504/50000 [===========>..................] - ETA: 3s - loss: 1.0457 - accuracy: 0.1003
on_train_batch_begin: 1607804391.597993s

21 step training time: 0.115393s

on_train_batch_end: 1607804391.712870s

22528/50000 [============>.................] - ETA: 3s - loss: 1.0476 - accuracy: 0.1003
on_train_batch_begin: 1607804391.713315s

22 step training time: 0.115322s

on_train_batch_end: 1607804391.827866s

23552/50000 [=============>................] - ETA: 2s - loss: 1.0453 - accuracy: 0.1003
on_train_batch_begin: 1607804391.828248s

23 step training time: 0.114933s

on_train_batch_end: 1607804391.943419s

24576/50000 [=============>................] - ETA: 2s - loss: 1.0421 - accuracy: 0.1003
on_train_batch_begin: 1607804391.943799s

24 step training time: 0.115551s

on_train_batch_end: 1607804392.058888s

25600/50000 [==============>...............] - ETA: 2s - loss: 1.0385 - accuracy: 0.1003
on_train_batch_begin: 1607804392.059271s

25 step training time: 0.115472s

on_train_batch_end: 1607804392.173967s

26624/50000 [==============>...............] - ETA: 2s - loss: 1.0348 - accuracy: 0.1003
on_train_batch_begin: 1607804392.174350s

26 step training time: 0.115079s

on_train_batch_end: 1607804392.289415s

27648/50000 [===============>..............] - ETA: 2s - loss: 1.0277 - accuracy: 0.1003
on_train_batch_begin: 1607804392.289797s

27 step training time: 0.115447s

on_train_batch_end: 1607804392.404114s

28672/50000 [================>.............] - ETA: 2s - loss: 1.0272 - accuracy: 0.1003
on_train_batch_begin: 1607804392.404496s

28 step training time: 0.114699s

on_train_batch_end: 1607804392.519717s

29696/50000 [================>.............] - ETA: 2s - loss: 1.0285 - accuracy: 0.1003
on_train_batch_begin: 1607804392.520096s

29 step training time: 0.115600s

on_train_batch_end: 1607804392.635501s

30720/50000 [=================>............] - ETA: 2s - loss: 1.0267 - accuracy: 0.1003
on_train_batch_begin: 1607804392.635880s

30 step training time: 0.115784s

on_train_batch_end: 1607804392.750410s

31744/50000 [==================>...........] - ETA: 2s - loss: 1.0258 - accuracy: 0.1003
on_train_batch_begin: 1607804392.750795s

31 step training time: 0.114915s

on_train_batch_end: 1607804392.866167s

32768/50000 [==================>...........] - ETA: 1s - loss: 1.0225 - accuracy: 0.1003
on_train_batch_begin: 1607804392.866545s

32 step training time: 0.115750s

on_train_batch_end: 1607804392.982301s

33792/50000 [===================>..........] - ETA: 1s - loss: 1.0188 - accuracy: 0.1003
on_train_batch_begin: 1607804392.982684s

33 step training time: 0.116139s

on_train_batch_end: 1607804393.097794s

34816/50000 [===================>..........] - ETA: 1s - loss: 1.0155 - accuracy: 0.1003
on_train_batch_begin: 1607804393.098175s

34 step training time: 0.115490s

on_train_batch_end: 1607804393.212669s

35840/50000 [====================>.........] - ETA: 1s - loss: 1.0092 - accuracy: 0.1003
on_train_batch_begin: 1607804393.213067s

35 step training time: 0.114893s

on_train_batch_end: 1607804393.328613s

36864/50000 [=====================>........] - ETA: 1s - loss: 1.0083 - accuracy: 0.1003
on_train_batch_begin: 1607804393.329018s

36 step training time: 0.115951s

on_train_batch_end: 1607804393.443930s

37888/50000 [=====================>........] - ETA: 1s - loss: 1.0047 - accuracy: 0.1003
on_train_batch_begin: 1607804393.444313s

37 step training time: 0.115295s

on_train_batch_end: 1607804393.559556s

38912/50000 [======================>.......] - ETA: 1s - loss: 1.0056 - accuracy: 0.1003
on_train_batch_begin: 1607804393.559936s

38 step training time: 0.115623s

on_train_batch_end: 1607804393.674517s

39936/50000 [======================>.......] - ETA: 1s - loss: 1.0074 - accuracy: 0.1003
on_train_batch_begin: 1607804393.674908s

39 step training time: 0.114973s

on_train_batch_end: 1607804393.791663s

40960/50000 [=======================>......] - ETA: 1s - loss: 1.0060 - accuracy: 0.1003
on_train_batch_begin: 1607804393.792044s

40 step training time: 0.117135s

on_train_batch_end: 1607804393.907459s

41984/50000 [========================>.....] - ETA: 0s - loss: 1.0043 - accuracy: 0.1003
on_train_batch_begin: 1607804393.907839s

41 step training time: 0.115795s

on_train_batch_end: 1607804394.022779s

43008/50000 [========================>.....] - ETA: 0s - loss: 1.0006 - accuracy: 0.1003
on_train_batch_begin: 1607804394.023184s

42 step training time: 0.115345s

on_train_batch_end: 1607804394.138702s

44032/50000 [=========================>....] - ETA: 0s - loss: 0.9991 - accuracy: 0.1003
on_train_batch_begin: 1607804394.139083s

43 step training time: 0.115899s

on_train_batch_end: 1607804394.254164s

45056/50000 [==========================>...] - ETA: 0s - loss: 0.9987 - accuracy: 0.1003
on_train_batch_begin: 1607804394.254544s

44 step training time: 0.115461s

on_train_batch_end: 1607804394.371695s

46080/50000 [==========================>...] - ETA: 0s - loss: 0.9939 - accuracy: 0.1003
on_train_batch_begin: 1607804394.372074s

45 step training time: 0.117531s

on_train_batch_end: 1607804394.486575s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.9937 - accuracy: 0.1003
on_train_batch_begin: 1607804394.486954s

46 step training time: 0.114880s

on_train_batch_end: 1607804394.601736s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.9939 - accuracy: 0.1003
on_train_batch_begin: 1607804394.602132s

47 step training time: 0.115177s

on_train_batch_end: 1607804394.718404s

49152/50000 [============================>.] - ETA: 0s - loss: 0.9910 - accuracy: 0.1003
on_train_batch_begin: 1607804394.718790s

48 step training time: 0.116659s

on_train_batch_end: 1607804394.819784s

on_test_batch_begin: 1607804394.835310s

49 step training time: 0.116519s

on_epoch_end: 1607804395.257072s

Validation time: 0.421747s

Real time: 1607804395.257072s

Epoch time: 6.087836027145386s

50000/50000 [==============================] - 6s 122us/sample - loss: 0.9902 - accuracy: 0.1003 - val_loss: 6.8322 - val_accuracy: 0.1001
Tempo do fit: 55.50638484954834