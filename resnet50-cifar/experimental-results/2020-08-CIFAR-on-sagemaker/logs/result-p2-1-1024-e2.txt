wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:05
   221184/170498071 [..............................] - ETA: 1:13
  1081344/170498071 [..............................] - ETA: 22s 
  3719168/170498071 [..............................] - ETA: 8s 
  6848512/170498071 [>.............................] - ETA: 5s
 10100736/170498071 [>.............................] - ETA: 4s
 13262848/170498071 [=>............................] - ETA: 4s
 16523264/170498071 [=>............................] - ETA: 3s
 19734528/170498071 [==>...........................] - ETA: 3s
 22962176/170498071 [===>..........................] - ETA: 3s
 26148864/170498071 [===>..........................] - ETA: 3s
 29384704/170498071 [====>.........................] - ETA: 2s
 32604160/170498071 [====>.........................] - ETA: 2s
 35774464/170498071 [=====>........................] - ETA: 2s
 39034880/170498071 [=====>........................] - ETA: 2s
 42246144/170498071 [======>.......................] - ETA: 2s
 45424640/170498071 [======>.......................] - ETA: 2s
 48619520/170498071 [=======>......................] - ETA: 2s
 51847168/170498071 [========>.....................] - ETA: 2s
 55042048/170498071 [========>.....................] - ETA: 2s
 58302464/170498071 [=========>....................] - ETA: 2s
 61497344/170498071 [=========>....................] - ETA: 1s
 64716800/170498071 [==========>...................] - ETA: 1s
 67952640/170498071 [==========>...................] - ETA: 1s
 71114752/170498071 [===========>..................] - ETA: 1s
 74342400/170498071 [============>.................] - ETA: 1s
 77553664/170498071 [============>.................] - ETA: 1s
 80814080/170498071 [=============>................] - ETA: 1s
 84058112/170498071 [=============>................] - ETA: 1s
 87318528/170498071 [==============>...............] - ETA: 1s
 90554368/170498071 [==============>...............] - ETA: 1s
 93757440/170498071 [===============>..............] - ETA: 1s
 97034240/170498071 [================>.............] - ETA: 1s
100261888/170498071 [================>.............] - ETA: 1s
103522304/170498071 [=================>............] - ETA: 1s
106700800/170498071 [=================>............] - ETA: 1s
109961216/170498071 [==================>...........] - ETA: 1s
113172480/170498071 [==================>...........] - ETA: 0s
116400128/170498071 [===================>..........] - ETA: 0s
119644160/170498071 [====================>.........] - ETA: 0s
122773504/170498071 [====================>.........] - ETA: 0s
126001152/170498071 [=====================>........] - ETA: 0s
129228800/170498071 [=====================>........] - ETA: 0s
132505600/170498071 [======================>.......] - ETA: 0s
135692288/170498071 [======================>.......] - ETA: 0s
138911744/170498071 [=======================>......] - ETA: 0s
142123008/170498071 [========================>.....] - ETA: 0s
145367040/170498071 [========================>.....] - ETA: 0s
148627456/170498071 [=========================>....] - ETA: 0s
151871488/170498071 [=========================>....] - ETA: 0s
155115520/170498071 [==========================>...] - ETA: 0s
158343168/170498071 [==========================>...] - ETA: 0s
161570816/170498071 [===========================>..] - ETA: 0s
164765696/170498071 [===========================>..] - ETA: 0s
167993344/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 2s
 4071424/94765736 [>.............................] - ETA: 1s
10108928/94765736 [==>...........................] - ETA: 0s
17645568/94765736 [====>.........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
25182208/94765736 [======>.......................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
33685504/94765736 [=========>....................] - ETA: 0s
37683200/94765736 [==========>...................] - ETA: 0s
42082304/94765736 [============>.................] - ETA: 0s
47136768/94765736 [=============>................] - ETA: 0s
51232768/94765736 [===============>..............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
61054976/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
71057408/94765736 [=====================>........] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
81461248/94765736 [========================>.....] - ETA: 0s
84975616/94765736 [=========================>....] - ETA: 0s
90415104/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 16.486130237579346
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1609164762.475013s

Real time: 1609164762.475042
Epoch 1/5

on_train_batch_begin: 1609164763.474643s

on_train_batch_end: 1609164786.616406s

 1024/50000 [..............................] - ETA: 19:14 - loss: 17.9958 - accuracy: 3.1185e-04
on_train_batch_begin: 1609164786.617286s

1 step training time: 23.142642s

on_train_batch_end: 1609164787.370642s

 2048/50000 [>.............................] - ETA: 9:42 - loss: 15.7941 - accuracy: 2.0695e-04 
on_train_batch_begin: 1609164787.371189s

2 step training time: 0.753903s

on_train_batch_end: 1609164788.112708s

 3072/50000 [>.............................] - ETA: 6:31 - loss: 13.6200 - accuracy: 2.9659e-04
on_train_batch_begin: 1609164788.113205s

3 step training time: 0.742016s

on_train_batch_end: 1609164788.852296s

 4096/50000 [=>............................] - ETA: 4:55 - loss: 12.3555 - accuracy: 8.2421e-04
on_train_batch_begin: 1609164788.852833s

4 step training time: 0.739628s

on_train_batch_end: 1609164789.604511s

 5120/50000 [==>...........................] - ETA: 3:57 - loss: 11.5268 - accuracy: 0.0021    
on_train_batch_begin: 1609164789.605036s

5 step training time: 0.752203s

on_train_batch_end: 1609164790.346385s

 6144/50000 [==>...........................] - ETA: 3:18 - loss: 10.9653 - accuracy: 0.0035
on_train_batch_begin: 1609164790.346908s

6 step training time: 0.741872s

on_train_batch_end: 1609164791.092689s

 7168/50000 [===>..........................] - ETA: 2:51 - loss: 10.5662 - accuracy: 0.0056
on_train_batch_begin: 1609164791.093419s

7 step training time: 0.746511s

on_train_batch_end: 1609164791.840624s

 8192/50000 [===>..........................] - ETA: 2:29 - loss: 10.2443 - accuracy: 0.0083
on_train_batch_begin: 1609164791.841116s

8 step training time: 0.747697s

on_train_batch_end: 1609164792.583193s

 9216/50000 [====>.........................] - ETA: 2:13 - loss: 9.9812 - accuracy: 0.0108 
on_train_batch_begin: 1609164792.583685s

9 step training time: 0.742569s

on_train_batch_end: 1609164793.326516s

10240/50000 [=====>........................] - ETA: 1:59 - loss: 9.7496 - accuracy: 0.0144
on_train_batch_begin: 1609164793.327049s

10 step training time: 0.743363s

on_train_batch_end: 1609164794.076648s

11264/50000 [=====>........................] - ETA: 1:48 - loss: 9.5593 - accuracy: 0.0182
on_train_batch_begin: 1609164794.077158s

11 step training time: 0.750110s

on_train_batch_end: 1609164794.821574s

12288/50000 [======>.......................] - ETA: 1:39 - loss: 9.3919 - accuracy: 0.0205
on_train_batch_begin: 1609164794.822240s

12 step training time: 0.745082s

on_train_batch_end: 1609164795.564025s

13312/50000 [======>.......................] - ETA: 1:31 - loss: 9.2547 - accuracy: 0.0226
on_train_batch_begin: 1609164795.564549s

13 step training time: 0.742309s

on_train_batch_end: 1609164796.303915s

14336/50000 [=======>......................] - ETA: 1:24 - loss: 9.1337 - accuracy: 0.0231
on_train_batch_begin: 1609164796.304404s

14 step training time: 0.739854s

on_train_batch_end: 1609164797.048904s

15360/50000 [========>.....................] - ETA: 1:17 - loss: 9.0222 - accuracy: 0.0235
on_train_batch_begin: 1609164797.049397s

15 step training time: 0.744993s

on_train_batch_end: 1609164797.790599s

16384/50000 [========>.....................] - ETA: 1:12 - loss: 8.9356 - accuracy: 0.0260
on_train_batch_begin: 1609164797.791116s

16 step training time: 0.741719s

on_train_batch_end: 1609164798.532934s

17408/50000 [=========>....................] - ETA: 1:07 - loss: 8.8435 - accuracy: 0.0287
on_train_batch_begin: 1609164798.533416s

17 step training time: 0.742300s

on_train_batch_end: 1609164799.282475s

18432/50000 [==========>...................] - ETA: 1:03 - loss: 8.7649 - accuracy: 0.0302
on_train_batch_begin: 1609164799.282994s

18 step training time: 0.749578s

on_train_batch_end: 1609164800.021923s

19456/50000 [==========>...................] - ETA: 58s - loss: 8.6941 - accuracy: 0.0323 
on_train_batch_begin: 1609164800.022450s

19 step training time: 0.739456s

on_train_batch_end: 1609164800.770918s

20480/50000 [===========>..................] - ETA: 55s - loss: 8.6240 - accuracy: 0.0343
on_train_batch_begin: 1609164800.771412s

20 step training time: 0.748962s

on_train_batch_end: 1609164801.518623s

21504/50000 [===========>..................] - ETA: 51s - loss: 8.5676 - accuracy: 0.0358
on_train_batch_begin: 1609164801.519152s

21 step training time: 0.747741s

on_train_batch_end: 1609164802.264236s

22528/50000 [============>.................] - ETA: 48s - loss: 8.5084 - accuracy: 0.0378
on_train_batch_begin: 1609164802.264725s

22 step training time: 0.745573s

on_train_batch_end: 1609164803.011750s

23552/50000 [=============>................] - ETA: 45s - loss: 8.4520 - accuracy: 0.0391
on_train_batch_begin: 1609164803.012233s

23 step training time: 0.747508s

on_train_batch_end: 1609164803.751227s

24576/50000 [=============>................] - ETA: 42s - loss: 8.4035 - accuracy: 0.0407
on_train_batch_begin: 1609164803.751714s

24 step training time: 0.739481s

on_train_batch_end: 1609164804.496041s

25600/50000 [==============>...............] - ETA: 40s - loss: 8.3513 - accuracy: 0.0426
on_train_batch_begin: 1609164804.496532s

25 step training time: 0.744819s

on_train_batch_end: 1609164805.234931s

26624/50000 [==============>...............] - ETA: 37s - loss: 8.3102 - accuracy: 0.0439
on_train_batch_begin: 1609164805.235437s

26 step training time: 0.738905s

on_train_batch_end: 1609164805.980682s

27648/50000 [===============>..............] - ETA: 35s - loss: 8.2711 - accuracy: 0.0449
on_train_batch_begin: 1609164805.981195s

27 step training time: 0.745758s

on_train_batch_end: 1609164806.722816s

28672/50000 [================>.............] - ETA: 32s - loss: 8.2445 - accuracy: 0.0452
on_train_batch_begin: 1609164806.723340s

28 step training time: 0.742145s

on_train_batch_end: 1609164807.472049s

29696/50000 [================>.............] - ETA: 30s - loss: 8.2153 - accuracy: 0.0457
on_train_batch_begin: 1609164807.472532s

29 step training time: 0.749191s

on_train_batch_end: 1609164808.221636s

30720/50000 [=================>............] - ETA: 28s - loss: 8.1854 - accuracy: 0.0466
on_train_batch_begin: 1609164808.222123s

30 step training time: 0.749591s

on_train_batch_end: 1609164808.962375s

31744/50000 [==================>...........] - ETA: 26s - loss: 8.1507 - accuracy: 0.0473
on_train_batch_begin: 1609164808.962925s

31 step training time: 0.740802s

on_train_batch_end: 1609164809.718706s

32768/50000 [==================>...........] - ETA: 24s - loss: 8.1132 - accuracy: 0.0480
on_train_batch_begin: 1609164809.719187s

32 step training time: 0.756263s

on_train_batch_end: 1609164810.466985s

33792/50000 [===================>..........] - ETA: 23s - loss: 8.0747 - accuracy: 0.0489
on_train_batch_begin: 1609164810.467477s

33 step training time: 0.748290s

on_train_batch_end: 1609164811.211241s

34816/50000 [===================>..........] - ETA: 21s - loss: 8.0379 - accuracy: 0.0498
on_train_batch_begin: 1609164811.211725s

34 step training time: 0.744248s

on_train_batch_end: 1609164811.954950s

35840/50000 [====================>.........] - ETA: 19s - loss: 8.0021 - accuracy: 0.0504
on_train_batch_begin: 1609164811.955434s

35 step training time: 0.743709s

on_train_batch_end: 1609164812.701615s

36864/50000 [=====================>........] - ETA: 17s - loss: 7.9637 - accuracy: 0.0509
on_train_batch_begin: 1609164812.702113s

36 step training time: 0.746680s

on_train_batch_end: 1609164813.446041s

37888/50000 [=====================>........] - ETA: 16s - loss: 7.9356 - accuracy: 0.0517
on_train_batch_begin: 1609164813.446524s

37 step training time: 0.744411s

on_train_batch_end: 1609164814.188094s

38912/50000 [======================>.......] - ETA: 14s - loss: 7.9042 - accuracy: 0.0522
on_train_batch_begin: 1609164814.188581s

38 step training time: 0.742057s

on_train_batch_end: 1609164814.934888s

39936/50000 [======================>.......] - ETA: 13s - loss: 7.8738 - accuracy: 0.0523
on_train_batch_begin: 1609164814.935392s

39 step training time: 0.746810s

on_train_batch_end: 1609164815.681449s

40960/50000 [=======================>......] - ETA: 11s - loss: 7.8388 - accuracy: 0.0526
on_train_batch_begin: 1609164815.681948s

40 step training time: 0.746556s

on_train_batch_end: 1609164816.431240s

41984/50000 [========================>.....] - ETA: 10s - loss: 7.8117 - accuracy: 0.0529
on_train_batch_begin: 1609164816.431779s

41 step training time: 0.749831s

on_train_batch_end: 1609164817.178075s

43008/50000 [========================>.....] - ETA: 8s - loss: 7.7849 - accuracy: 0.0532 
on_train_batch_begin: 1609164817.178567s

42 step training time: 0.746788s

on_train_batch_end: 1609164817.929052s

44032/50000 [=========================>....] - ETA: 7s - loss: 7.7550 - accuracy: 0.0534
on_train_batch_begin: 1609164817.929799s

43 step training time: 0.751231s

on_train_batch_end: 1609164818.677903s

45056/50000 [==========================>...] - ETA: 6s - loss: 7.7261 - accuracy: 0.0538
on_train_batch_begin: 1609164818.678402s

44 step training time: 0.748604s

on_train_batch_end: 1609164819.420220s

46080/50000 [==========================>...] - ETA: 4s - loss: 7.6994 - accuracy: 0.0543
on_train_batch_begin: 1609164819.420722s

45 step training time: 0.742320s

on_train_batch_end: 1609164820.168254s

47104/50000 [===========================>..] - ETA: 3s - loss: 7.6742 - accuracy: 0.0547
on_train_batch_begin: 1609164820.168755s

46 step training time: 0.748033s

on_train_batch_end: 1609164820.917112s

48128/50000 [===========================>..] - ETA: 2s - loss: 7.6461 - accuracy: 0.0549
on_train_batch_begin: 1609164820.917599s

47 step training time: 0.748844s

on_train_batch_end: 1609164821.662880s

49152/50000 [============================>.] - ETA: 1s - loss: 7.6193 - accuracy: 0.0553
on_train_batch_begin: 1609164821.663367s

48 step training time: 0.745767s

on_train_batch_end: 1609164829.740990s

on_test_batch_begin: 1609164829.988430s

49 step training time: 8.325063s

on_epoch_end: 1609164836.426751s

Validation time: 6.438296s

Real time: 1609164836.426751s

Epoch time: 73.95173525810242s

50000/50000 [==============================] - 74s 1ms/sample - loss: 7.5998 - accuracy: 0.0554 - val_loss: 292771.8634 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609164836.427077s

Real time: 1609164836.427091
Epoch 2/5

on_train_batch_begin: 1609164836.431591s

on_train_batch_end: 1609164837.180183s

 1024/50000 [..............................] - ETA: 36s - loss: 6.4492 - accuracy: 0.0769
on_train_batch_begin: 1609164837.180699s

1 step training time: 0.749108s

on_train_batch_end: 1609164837.928027s

 2048/50000 [>.............................] - ETA: 35s - loss: 6.3337 - accuracy: 0.0713
on_train_batch_begin: 1609164837.928556s

2 step training time: 0.747857s

on_train_batch_end: 1609164838.683436s

 3072/50000 [>.............................] - ETA: 34s - loss: 6.3596 - accuracy: 0.0704
on_train_batch_begin: 1609164838.683988s

3 step training time: 0.755432s

on_train_batch_end: 1609164839.430639s

 4096/50000 [=>............................] - ETA: 33s - loss: 6.3430 - accuracy: 0.0647
on_train_batch_begin: 1609164839.431158s

4 step training time: 0.747169s

on_train_batch_end: 1609164840.183591s

 5120/50000 [==>...........................] - ETA: 32s - loss: 6.3289 - accuracy: 0.0612
on_train_batch_begin: 1609164840.184072s

5 step training time: 0.752915s

on_train_batch_end: 1609164840.938841s

 6144/50000 [==>...........................] - ETA: 32s - loss: 6.2895 - accuracy: 0.0614
on_train_batch_begin: 1609164840.939327s

6 step training time: 0.755254s

on_train_batch_end: 1609164841.687087s

 7168/50000 [===>..........................] - ETA: 31s - loss: 6.2647 - accuracy: 0.0601
on_train_batch_begin: 1609164841.687577s

7 step training time: 0.748250s

on_train_batch_end: 1609164842.439560s

 8192/50000 [===>..........................] - ETA: 30s - loss: 6.2219 - accuracy: 0.0596
on_train_batch_begin: 1609164842.440047s

8 step training time: 0.752470s

on_train_batch_end: 1609164843.191165s

 9216/50000 [====>.........................] - ETA: 29s - loss: 6.2157 - accuracy: 0.0598
on_train_batch_begin: 1609164843.191673s

9 step training time: 0.751627s

on_train_batch_end: 1609164843.946137s

10240/50000 [=====>........................] - ETA: 29s - loss: 6.1864 - accuracy: 0.0593
on_train_batch_begin: 1609164843.946694s

10 step training time: 0.755021s

on_train_batch_end: 1609164844.695172s

11264/50000 [=====>........................] - ETA: 28s - loss: 6.1568 - accuracy: 0.0591
on_train_batch_begin: 1609164844.695662s

11 step training time: 0.748967s

on_train_batch_end: 1609164845.442197s

12288/50000 [======>.......................] - ETA: 27s - loss: 6.1320 - accuracy: 0.0584
on_train_batch_begin: 1609164845.442763s

12 step training time: 0.747102s

on_train_batch_end: 1609164846.197860s

13312/50000 [======>.......................] - ETA: 26s - loss: 6.1060 - accuracy: 0.0579
on_train_batch_begin: 1609164846.198368s

13 step training time: 0.755605s

on_train_batch_end: 1609164846.941354s

14336/50000 [=======>......................] - ETA: 26s - loss: 6.0911 - accuracy: 0.0570
on_train_batch_begin: 1609164846.941833s

14 step training time: 0.743465s

on_train_batch_end: 1609164847.693519s

15360/50000 [========>.....................] - ETA: 25s - loss: 6.0666 - accuracy: 0.0566
on_train_batch_begin: 1609164847.694021s

15 step training time: 0.752188s

on_train_batch_end: 1609164848.445492s

16384/50000 [========>.....................] - ETA: 24s - loss: 6.0381 - accuracy: 0.0560
on_train_batch_begin: 1609164848.445991s

16 step training time: 0.751969s

on_train_batch_end: 1609164849.200951s

17408/50000 [=========>....................] - ETA: 23s - loss: 6.0121 - accuracy: 0.0555
on_train_batch_begin: 1609164849.201444s

17 step training time: 0.755454s

on_train_batch_end: 1609164849.948136s

18432/50000 [==========>...................] - ETA: 23s - loss: 5.9867 - accuracy: 0.0551
on_train_batch_begin: 1609164849.948618s

18 step training time: 0.747174s

on_train_batch_end: 1609164850.699495s

19456/50000 [==========>...................] - ETA: 22s - loss: 5.9668 - accuracy: 0.0549
on_train_batch_begin: 1609164850.700013s

19 step training time: 0.751395s

on_train_batch_end: 1609164851.448971s

20480/50000 [===========>..................] - ETA: 21s - loss: 5.9450 - accuracy: 0.0545
on_train_batch_begin: 1609164851.449454s

20 step training time: 0.749441s

on_train_batch_end: 1609164852.199014s

21504/50000 [===========>..................] - ETA: 20s - loss: 5.9191 - accuracy: 0.0544
on_train_batch_begin: 1609164852.199498s

21 step training time: 0.750044s

on_train_batch_end: 1609164852.949213s

22528/50000 [============>.................] - ETA: 20s - loss: 5.8902 - accuracy: 0.0544
on_train_batch_begin: 1609164852.949724s

22 step training time: 0.750226s

on_train_batch_end: 1609164853.703578s

23552/50000 [=============>................] - ETA: 19s - loss: 5.8562 - accuracy: 0.0546
on_train_batch_begin: 1609164853.704068s

23 step training time: 0.754344s

on_train_batch_end: 1609164854.454618s

24576/50000 [=============>................] - ETA: 18s - loss: 5.8304 - accuracy: 0.0547
on_train_batch_begin: 1609164854.455142s

24 step training time: 0.751073s

on_train_batch_end: 1609164855.212247s

25600/50000 [==============>...............] - ETA: 17s - loss: 5.7928 - accuracy: 0.0550
on_train_batch_begin: 1609164855.212730s

25 step training time: 0.757588s

on_train_batch_end: 1609164855.964754s

26624/50000 [==============>...............] - ETA: 17s - loss: 5.7619 - accuracy: 0.0552
on_train_batch_begin: 1609164855.965241s

26 step training time: 0.752511s

on_train_batch_end: 1609164856.721786s

27648/50000 [===============>..............] - ETA: 16s - loss: 5.7269 - accuracy: 0.0555
on_train_batch_begin: 1609164856.722271s

27 step training time: 0.757030s

on_train_batch_end: 1609164857.468652s

28672/50000 [================>.............] - ETA: 15s - loss: 5.6846 - accuracy: 0.0559
on_train_batch_begin: 1609164857.469141s

28 step training time: 0.746870s

on_train_batch_end: 1609164858.225618s

29696/50000 [================>.............] - ETA: 14s - loss: 5.6480 - accuracy: 0.0564
on_train_batch_begin: 1609164858.226099s

29 step training time: 0.756959s

on_train_batch_end: 1609164858.982219s

30720/50000 [=================>............] - ETA: 14s - loss: 5.6006 - accuracy: 0.0570
on_train_batch_begin: 1609164858.982733s

30 step training time: 0.756634s

on_train_batch_end: 1609164859.738140s

31744/50000 [==================>...........] - ETA: 13s - loss: 5.5579 - accuracy: 0.0577
on_train_batch_begin: 1609164859.738649s

31 step training time: 0.755915s

on_train_batch_end: 1609164860.489060s

32768/50000 [==================>...........] - ETA: 12s - loss: 5.5104 - accuracy: 0.0585
on_train_batch_begin: 1609164860.489791s

32 step training time: 0.751142s

on_train_batch_end: 1609164861.241614s

33792/50000 [===================>..........] - ETA: 11s - loss: 5.4598 - accuracy: 0.0594
on_train_batch_begin: 1609164861.242155s

33 step training time: 0.752365s

on_train_batch_end: 1609164861.999784s

34816/50000 [===================>..........] - ETA: 11s - loss: 5.4158 - accuracy: 0.0602
on_train_batch_begin: 1609164862.000271s

34 step training time: 0.758116s

on_train_batch_end: 1609164862.757333s

35840/50000 [====================>.........] - ETA: 10s - loss: 5.3663 - accuracy: 0.0611
on_train_batch_begin: 1609164862.757817s

35 step training time: 0.757546s

on_train_batch_end: 1609164863.508309s

36864/50000 [=====================>........] - ETA: 9s - loss: 5.3155 - accuracy: 0.0619 
on_train_batch_begin: 1609164863.508792s

36 step training time: 0.750975s

on_train_batch_end: 1609164864.258421s

37888/50000 [=====================>........] - ETA: 8s - loss: 5.2591 - accuracy: 0.0629
on_train_batch_begin: 1609164864.258947s

37 step training time: 0.750155s

on_train_batch_end: 1609164865.012550s

38912/50000 [======================>.......] - ETA: 8s - loss: 5.2122 - accuracy: 0.0637
on_train_batch_begin: 1609164865.013052s

38 step training time: 0.754105s

on_train_batch_end: 1609164865.770005s

39936/50000 [======================>.......] - ETA: 7s - loss: 5.1608 - accuracy: 0.0645
on_train_batch_begin: 1609164865.770526s

39 step training time: 0.757473s

on_train_batch_end: 1609164866.522731s

40960/50000 [=======================>......] - ETA: 6s - loss: 5.1128 - accuracy: 0.0654
on_train_batch_begin: 1609164866.523236s

40 step training time: 0.752710s

on_train_batch_end: 1609164867.279892s

41984/50000 [========================>.....] - ETA: 5s - loss: 5.0693 - accuracy: 0.0661
on_train_batch_begin: 1609164867.280419s

41 step training time: 0.757183s

on_train_batch_end: 1609164868.032251s

43008/50000 [========================>.....] - ETA: 5s - loss: 5.0230 - accuracy: 0.0669
on_train_batch_begin: 1609164868.032754s

42 step training time: 0.752336s

on_train_batch_end: 1609164868.791174s

44032/50000 [=========================>....] - ETA: 4s - loss: 4.9783 - accuracy: 0.0676
on_train_batch_begin: 1609164868.791677s

43 step training time: 0.758923s

on_train_batch_end: 1609164869.540872s

45056/50000 [==========================>...] - ETA: 3s - loss: 4.9324 - accuracy: 0.0683
on_train_batch_begin: 1609164869.541363s

44 step training time: 0.749686s

on_train_batch_end: 1609164870.298191s

46080/50000 [==========================>...] - ETA: 2s - loss: 4.8884 - accuracy: 0.0690
on_train_batch_begin: 1609164870.298764s

45 step training time: 0.757401s

on_train_batch_end: 1609164871.055387s

47104/50000 [===========================>..] - ETA: 2s - loss: 4.8460 - accuracy: 0.0696
on_train_batch_begin: 1609164871.055882s

46 step training time: 0.757118s

on_train_batch_end: 1609164871.810970s

48128/50000 [===========================>..] - ETA: 1s - loss: 4.8061 - accuracy: 0.0702
on_train_batch_begin: 1609164871.811457s

47 step training time: 0.755575s

on_train_batch_end: 1609164872.564286s

49152/50000 [============================>.] - ETA: 0s - loss: 4.7610 - accuracy: 0.0708
on_train_batch_begin: 1609164872.564774s

48 step training time: 0.753317s

on_train_batch_end: 1609164873.205788s

on_test_batch_begin: 1609164873.220354s

49 step training time: 0.655580s

on_epoch_end: 1609164875.183449s

Validation time: 1.963072s

Real time: 1609164875.183449s

Epoch time: 38.756385803222656s

50000/50000 [==============================] - 39s 775us/sample - loss: 4.7252 - accuracy: 0.0712 - val_loss: 13.7041 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609164875.183757s

Real time: 1609164875.183768
Epoch 3/5

on_train_batch_begin: 1609164875.188482s

on_train_batch_end: 1609164875.952677s

 1024/50000 [..............................] - ETA: 36s - loss: 2.6259 - accuracy: 0.1002
on_train_batch_begin: 1609164875.953171s

1 step training time: 0.764688s

on_train_batch_end: 1609164876.711715s

 2048/50000 [>.............................] - ETA: 35s - loss: 2.7806 - accuracy: 0.1000
on_train_batch_begin: 1609164876.712203s

2 step training time: 0.759032s

on_train_batch_end: 1609164877.470831s

 3072/50000 [>.............................] - ETA: 34s - loss: 2.8323 - accuracy: 0.0993
on_train_batch_begin: 1609164877.471319s

3 step training time: 0.759116s

on_train_batch_end: 1609164878.228387s

 4096/50000 [=>............................] - ETA: 34s - loss: 2.8380 - accuracy: 0.0996
on_train_batch_begin: 1609164878.228889s

4 step training time: 0.757570s

on_train_batch_end: 1609164878.991679s

 5120/50000 [==>...........................] - ETA: 33s - loss: 2.7993 - accuracy: 0.0995
on_train_batch_begin: 1609164878.992213s

5 step training time: 0.763324s

on_train_batch_end: 1609164879.748714s

 6144/50000 [==>...........................] - ETA: 32s - loss: 2.7726 - accuracy: 0.0997
on_train_batch_begin: 1609164879.749202s

6 step training time: 0.756989s

on_train_batch_end: 1609164880.510754s

 7168/50000 [===>..........................] - ETA: 31s - loss: 2.7228 - accuracy: 0.0997
on_train_batch_begin: 1609164880.511304s

7 step training time: 0.762102s

on_train_batch_end: 1609164881.270216s

 8192/50000 [===>..........................] - ETA: 31s - loss: 2.6859 - accuracy: 0.0997
on_train_batch_begin: 1609164881.270736s

8 step training time: 0.759432s

on_train_batch_end: 1609164882.029522s

 9216/50000 [====>.........................] - ETA: 30s - loss: 2.6634 - accuracy: 0.0998
on_train_batch_begin: 1609164882.029997s

9 step training time: 0.759262s

on_train_batch_end: 1609164882.784232s

10240/50000 [=====>........................] - ETA: 29s - loss: 2.6386 - accuracy: 0.0998
on_train_batch_begin: 1609164882.784717s

10 step training time: 0.754720s

on_train_batch_end: 1609164883.544795s

11264/50000 [=====>........................] - ETA: 28s - loss: 2.6304 - accuracy: 0.0998
on_train_batch_begin: 1609164883.545321s

11 step training time: 0.760604s

on_train_batch_end: 1609164884.301497s

12288/50000 [======>.......................] - ETA: 27s - loss: 2.6182 - accuracy: 0.0999
on_train_batch_begin: 1609164884.301980s

12 step training time: 0.756659s

on_train_batch_end: 1609164885.056822s

13312/50000 [======>.......................] - ETA: 27s - loss: 2.6168 - accuracy: 0.0999
on_train_batch_begin: 1609164885.057304s

13 step training time: 0.755323s

on_train_batch_end: 1609164885.807780s

14336/50000 [=======>......................] - ETA: 26s - loss: 2.6091 - accuracy: 0.0999
on_train_batch_begin: 1609164885.808267s

14 step training time: 0.750963s

on_train_batch_end: 1609164886.573963s

15360/50000 [========>.....................] - ETA: 25s - loss: 2.6039 - accuracy: 0.0999
on_train_batch_begin: 1609164886.574444s

15 step training time: 0.766177s

on_train_batch_end: 1609164887.329998s

16384/50000 [========>.....................] - ETA: 24s - loss: 2.6056 - accuracy: 0.0999
on_train_batch_begin: 1609164887.330478s

16 step training time: 0.756034s

on_train_batch_end: 1609164888.092586s

17408/50000 [=========>....................] - ETA: 24s - loss: 2.6075 - accuracy: 0.0999
on_train_batch_begin: 1609164888.093084s

17 step training time: 0.762606s

on_train_batch_end: 1609164888.850560s

18432/50000 [==========>...................] - ETA: 23s - loss: 2.6109 - accuracy: 0.0999
on_train_batch_begin: 1609164888.851097s

18 step training time: 0.758013s

on_train_batch_end: 1609164889.618477s

19456/50000 [==========>...................] - ETA: 22s - loss: 2.6046 - accuracy: 0.0999
on_train_batch_begin: 1609164889.619072s

19 step training time: 0.767975s

on_train_batch_end: 1609164890.375322s

20480/50000 [===========>..................] - ETA: 21s - loss: 2.5939 - accuracy: 0.0999
on_train_batch_begin: 1609164890.375808s

20 step training time: 0.756736s

on_train_batch_end: 1609164891.141477s

21504/50000 [===========>..................] - ETA: 21s - loss: 2.5867 - accuracy: 0.0999
on_train_batch_begin: 1609164891.141991s

21 step training time: 0.766183s

on_train_batch_end: 1609164891.891898s

22528/50000 [============>.................] - ETA: 20s - loss: 2.5880 - accuracy: 0.0999
on_train_batch_begin: 1609164891.892387s

22 step training time: 0.750396s

on_train_batch_end: 1609164892.654245s

23552/50000 [=============>................] - ETA: 19s - loss: 2.5817 - accuracy: 0.1000
on_train_batch_begin: 1609164892.654779s

23 step training time: 0.762392s

on_train_batch_end: 1609164893.409259s

24576/50000 [=============>................] - ETA: 18s - loss: 2.5730 - accuracy: 0.1000
on_train_batch_begin: 1609164893.409757s

24 step training time: 0.754978s

on_train_batch_end: 1609164894.178144s

25600/50000 [==============>...............] - ETA: 18s - loss: 2.5730 - accuracy: 0.1000
on_train_batch_begin: 1609164894.178643s

25 step training time: 0.768886s

on_train_batch_end: 1609164894.933928s

26624/50000 [==============>...............] - ETA: 17s - loss: 2.5639 - accuracy: 0.1000
on_train_batch_begin: 1609164894.934406s

26 step training time: 0.755762s

on_train_batch_end: 1609164895.702203s

27648/50000 [===============>..............] - ETA: 16s - loss: 2.5573 - accuracy: 0.1000
on_train_batch_begin: 1609164895.702708s

27 step training time: 0.768303s

on_train_batch_end: 1609164896.460450s

28672/50000 [================>.............] - ETA: 15s - loss: 2.5547 - accuracy: 0.1000
on_train_batch_begin: 1609164896.460942s

28 step training time: 0.758233s

on_train_batch_end: 1609164897.227408s

29696/50000 [================>.............] - ETA: 15s - loss: 2.5403 - accuracy: 0.1000
on_train_batch_begin: 1609164897.227905s

29 step training time: 0.766963s

on_train_batch_end: 1609164897.989237s

30720/50000 [=================>............] - ETA: 14s - loss: 2.5314 - accuracy: 0.1000
on_train_batch_begin: 1609164897.989808s

30 step training time: 0.761903s

on_train_batch_end: 1609164898.752261s

31744/50000 [==================>...........] - ETA: 13s - loss: 2.5181 - accuracy: 0.1000
on_train_batch_begin: 1609164898.752755s

31 step training time: 0.762948s

on_train_batch_end: 1609164899.515970s

32768/50000 [==================>...........] - ETA: 12s - loss: 2.5071 - accuracy: 0.1000
on_train_batch_begin: 1609164899.516514s

32 step training time: 0.763759s

on_train_batch_end: 1609164900.280375s

33792/50000 [===================>..........] - ETA: 12s - loss: 2.4943 - accuracy: 0.1000
on_train_batch_begin: 1609164900.280866s

33 step training time: 0.764352s

on_train_batch_end: 1609164901.039763s

34816/50000 [===================>..........] - ETA: 11s - loss: 2.4814 - accuracy: 0.1000
on_train_batch_begin: 1609164901.040247s

34 step training time: 0.759381s

on_train_batch_end: 1609164901.814775s

35840/50000 [====================>.........] - ETA: 10s - loss: 2.4698 - accuracy: 0.1000
on_train_batch_begin: 1609164901.815280s

35 step training time: 0.775034s

on_train_batch_end: 1609164902.577899s

36864/50000 [=====================>........] - ETA: 9s - loss: 2.4624 - accuracy: 0.1000 
on_train_batch_begin: 1609164902.578405s

36 step training time: 0.763124s

on_train_batch_end: 1609164903.343845s

37888/50000 [=====================>........] - ETA: 9s - loss: 2.4575 - accuracy: 0.1001
on_train_batch_begin: 1609164903.344331s

37 step training time: 0.765926s

on_train_batch_end: 1609164904.100131s

38912/50000 [======================>.......] - ETA: 8s - loss: 2.4490 - accuracy: 0.1001
on_train_batch_begin: 1609164904.100615s

38 step training time: 0.756284s

on_train_batch_end: 1609164904.864027s

39936/50000 [======================>.......] - ETA: 7s - loss: 2.4399 - accuracy: 0.1001
on_train_batch_begin: 1609164904.864516s

39 step training time: 0.763901s

on_train_batch_end: 1609164905.622575s

40960/50000 [=======================>......] - ETA: 6s - loss: 2.4311 - accuracy: 0.1001
on_train_batch_begin: 1609164905.623094s

40 step training time: 0.758578s

on_train_batch_end: 1609164906.392137s

41984/50000 [========================>.....] - ETA: 5s - loss: 2.4252 - accuracy: 0.1001
on_train_batch_begin: 1609164906.392624s

41 step training time: 0.769531s

on_train_batch_end: 1609164907.153217s

43008/50000 [========================>.....] - ETA: 5s - loss: 2.4161 - accuracy: 0.1001
on_train_batch_begin: 1609164907.153748s

42 step training time: 0.761124s

on_train_batch_end: 1609164907.917874s

44032/50000 [=========================>....] - ETA: 4s - loss: 2.4080 - accuracy: 0.1001
on_train_batch_begin: 1609164907.918364s

43 step training time: 0.764616s

on_train_batch_end: 1609164908.682987s

45056/50000 [==========================>...] - ETA: 3s - loss: 2.4011 - accuracy: 0.1001
on_train_batch_begin: 1609164908.683487s

44 step training time: 0.765123s

on_train_batch_end: 1609164909.449366s

46080/50000 [==========================>...] - ETA: 2s - loss: 2.3895 - accuracy: 0.1001
on_train_batch_begin: 1609164909.449866s

45 step training time: 0.766380s

on_train_batch_end: 1609164910.208987s

47104/50000 [===========================>..] - ETA: 2s - loss: 2.3816 - accuracy: 0.1001
on_train_batch_begin: 1609164910.209471s

46 step training time: 0.759604s

on_train_batch_end: 1609164910.985600s

48128/50000 [===========================>..] - ETA: 1s - loss: 2.3734 - accuracy: 0.1001
on_train_batch_begin: 1609164910.986087s

47 step training time: 0.776616s

on_train_batch_end: 1609164911.749526s

49152/50000 [============================>.] - ETA: 0s - loss: 2.3617 - accuracy: 0.1001
on_train_batch_begin: 1609164911.750103s

48 step training time: 0.764016s

on_train_batch_end: 1609164912.393285s

on_test_batch_begin: 1609164912.407124s

49 step training time: 0.657021s

on_epoch_end: 1609164914.367469s

Validation time: 1.960329s

Real time: 1609164914.367469s

Epoch time: 39.18372964859009s

50000/50000 [==============================] - 39s 784us/sample - loss: 2.3516 - accuracy: 0.1001 - val_loss: 8.6412 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609164914.367768s

Real time: 1609164914.3677952
Epoch 4/5

on_train_batch_begin: 1609164914.372493s

on_train_batch_end: 1609164915.130395s

 1024/50000 [..............................] - ETA: 36s - loss: 1.8465 - accuracy: 0.1003
on_train_batch_begin: 1609164915.130910s

1 step training time: 0.758417s

on_train_batch_end: 1609164915.895263s

 2048/50000 [>.............................] - ETA: 35s - loss: 1.8327 - accuracy: 0.1001
on_train_batch_begin: 1609164915.895748s

2 step training time: 0.764838s

on_train_batch_end: 1609164916.652982s

 3072/50000 [>.............................] - ETA: 34s - loss: 1.7722 - accuracy: 0.1001
on_train_batch_begin: 1609164916.653458s

3 step training time: 0.757710s

on_train_batch_end: 1609164917.407305s

 4096/50000 [=>............................] - ETA: 34s - loss: 1.7572 - accuracy: 0.1001
on_train_batch_begin: 1609164917.407799s

4 step training time: 0.754340s

on_train_batch_end: 1609164918.162967s

 5120/50000 [==>...........................] - ETA: 33s - loss: 1.7838 - accuracy: 0.1001
on_train_batch_begin: 1609164918.163449s

5 step training time: 0.755650s

on_train_batch_end: 1609164918.922193s

 6144/50000 [==>...........................] - ETA: 32s - loss: 1.7616 - accuracy: 0.1001
on_train_batch_begin: 1609164918.922717s

6 step training time: 0.759269s

on_train_batch_end: 1609164919.681323s

 7168/50000 [===>..........................] - ETA: 31s - loss: 1.7577 - accuracy: 0.1002
on_train_batch_begin: 1609164919.681808s

7 step training time: 0.759090s

on_train_batch_end: 1609164920.443644s

 8192/50000 [===>..........................] - ETA: 31s - loss: 1.7351 - accuracy: 0.1001
on_train_batch_begin: 1609164920.444449s

8 step training time: 0.762641s

on_train_batch_end: 1609164921.215361s

 9216/50000 [====>.........................] - ETA: 30s - loss: 1.7376 - accuracy: 0.1001
on_train_batch_begin: 1609164921.216074s

9 step training time: 0.771626s

on_train_batch_end: 1609164921.975284s

10240/50000 [=====>........................] - ETA: 29s - loss: 1.7296 - accuracy: 0.1001
on_train_batch_begin: 1609164921.975803s

10 step training time: 0.759728s

on_train_batch_end: 1609164922.731739s

11264/50000 [=====>........................] - ETA: 28s - loss: 1.7242 - accuracy: 0.1002
on_train_batch_begin: 1609164922.732224s

11 step training time: 0.756421s

on_train_batch_end: 1609164923.491805s

12288/50000 [======>.......................] - ETA: 28s - loss: 1.7319 - accuracy: 0.1002
on_train_batch_begin: 1609164923.492306s

12 step training time: 0.760082s

on_train_batch_end: 1609164924.249575s

13312/50000 [======>.......................] - ETA: 27s - loss: 1.7307 - accuracy: 0.1002
on_train_batch_begin: 1609164924.250076s

13 step training time: 0.757770s

on_train_batch_end: 1609164925.012709s

14336/50000 [=======>......................] - ETA: 26s - loss: 1.7319 - accuracy: 0.1001
on_train_batch_begin: 1609164925.013210s

14 step training time: 0.763134s

on_train_batch_end: 1609164925.772939s

15360/50000 [========>.....................] - ETA: 25s - loss: 1.7296 - accuracy: 0.1001
on_train_batch_begin: 1609164925.773443s

15 step training time: 0.760233s

on_train_batch_end: 1609164926.535551s

16384/50000 [========>.....................] - ETA: 24s - loss: 1.7090 - accuracy: 0.1001
on_train_batch_begin: 1609164926.536049s

16 step training time: 0.762606s

on_train_batch_end: 1609164927.295732s

17408/50000 [=========>....................] - ETA: 24s - loss: 1.7101 - accuracy: 0.1001
on_train_batch_begin: 1609164927.296260s

17 step training time: 0.760211s

on_train_batch_end: 1609164928.055569s

18432/50000 [==========>...................] - ETA: 23s - loss: 1.7024 - accuracy: 0.1001
on_train_batch_begin: 1609164928.056060s

18 step training time: 0.759800s

on_train_batch_end: 1609164928.813507s

19456/50000 [==========>...................] - ETA: 22s - loss: 1.6970 - accuracy: 0.1001
on_train_batch_begin: 1609164928.814010s

19 step training time: 0.757950s

on_train_batch_end: 1609164929.570328s

20480/50000 [===========>..................] - ETA: 21s - loss: 1.6906 - accuracy: 0.1001
on_train_batch_begin: 1609164929.570860s

20 step training time: 0.756850s

on_train_batch_end: 1609164930.329296s

21504/50000 [===========>..................] - ETA: 21s - loss: 1.6838 - accuracy: 0.1001
on_train_batch_begin: 1609164930.329792s

21 step training time: 0.758932s

on_train_batch_end: 1609164931.099399s

22528/50000 [============>.................] - ETA: 20s - loss: 1.6799 - accuracy: 0.1001
on_train_batch_begin: 1609164931.099910s

22 step training time: 0.770118s

on_train_batch_end: 1609164931.861353s

23552/50000 [=============>................] - ETA: 19s - loss: 1.6704 - accuracy: 0.1001
on_train_batch_begin: 1609164931.861849s

23 step training time: 0.761939s

on_train_batch_end: 1609164932.624975s

24576/50000 [=============>................] - ETA: 18s - loss: 1.6693 - accuracy: 0.1001
on_train_batch_begin: 1609164932.625504s

24 step training time: 0.763655s

on_train_batch_end: 1609164933.386003s

25600/50000 [==============>...............] - ETA: 18s - loss: 1.6663 - accuracy: 0.1002
on_train_batch_begin: 1609164933.386492s

25 step training time: 0.760988s

on_train_batch_end: 1609164934.143862s

26624/50000 [==============>...............] - ETA: 17s - loss: 1.6652 - accuracy: 0.1002
on_train_batch_begin: 1609164934.144372s

26 step training time: 0.757880s

on_train_batch_end: 1609164934.904317s

27648/50000 [===============>..............] - ETA: 16s - loss: 1.6664 - accuracy: 0.1002
on_train_batch_begin: 1609164934.904821s

27 step training time: 0.760449s

on_train_batch_end: 1609164935.666816s

28672/50000 [================>.............] - ETA: 15s - loss: 1.6645 - accuracy: 0.1002
on_train_batch_begin: 1609164935.667310s

28 step training time: 0.762489s

on_train_batch_end: 1609164936.430755s

29696/50000 [================>.............] - ETA: 15s - loss: 1.6572 - accuracy: 0.1002
on_train_batch_begin: 1609164936.431255s

29 step training time: 0.763945s

on_train_batch_end: 1609164937.192411s

30720/50000 [=================>............] - ETA: 14s - loss: 1.6511 - accuracy: 0.1002
on_train_batch_begin: 1609164937.192927s

30 step training time: 0.761672s

on_train_batch_end: 1609164937.950685s

31744/50000 [==================>...........] - ETA: 13s - loss: 1.6440 - accuracy: 0.1002
on_train_batch_begin: 1609164937.951179s

31 step training time: 0.758252s

on_train_batch_end: 1609164938.712213s

32768/50000 [==================>...........] - ETA: 12s - loss: 1.6378 - accuracy: 0.1002
on_train_batch_begin: 1609164938.712701s

32 step training time: 0.761522s

on_train_batch_end: 1609164939.470761s

33792/50000 [===================>..........] - ETA: 12s - loss: 1.6338 - accuracy: 0.1002
on_train_batch_begin: 1609164939.471249s

33 step training time: 0.758548s

on_train_batch_end: 1609164940.235737s

34816/50000 [===================>..........] - ETA: 11s - loss: 1.6256 - accuracy: 0.1002
on_train_batch_begin: 1609164940.236226s

34 step training time: 0.764977s

on_train_batch_end: 1609164940.997062s

35840/50000 [====================>.........] - ETA: 10s - loss: 1.6197 - accuracy: 0.1002
on_train_batch_begin: 1609164940.997555s

35 step training time: 0.761329s

on_train_batch_end: 1609164941.760359s

36864/50000 [=====================>........] - ETA: 9s - loss: 1.6150 - accuracy: 0.1003 
on_train_batch_begin: 1609164941.760854s

36 step training time: 0.763299s

on_train_batch_end: 1609164942.519944s

37888/50000 [=====================>........] - ETA: 8s - loss: 1.6119 - accuracy: 0.1003
on_train_batch_begin: 1609164942.520436s

37 step training time: 0.759581s

on_train_batch_end: 1609164943.283288s

38912/50000 [======================>.......] - ETA: 8s - loss: 1.6065 - accuracy: 0.1003
on_train_batch_begin: 1609164943.283788s

38 step training time: 0.763352s

on_train_batch_end: 1609164944.047436s

39936/50000 [======================>.......] - ETA: 7s - loss: 1.6062 - accuracy: 0.1003
on_train_batch_begin: 1609164944.047945s

39 step training time: 0.764157s

on_train_batch_end: 1609164944.815520s

40960/50000 [=======================>......] - ETA: 6s - loss: 1.6014 - accuracy: 0.1003
on_train_batch_begin: 1609164944.816004s

40 step training time: 0.768059s

on_train_batch_end: 1609164945.577513s

41984/50000 [========================>.....] - ETA: 5s - loss: 1.5984 - accuracy: 0.1003
on_train_batch_begin: 1609164945.577998s

41 step training time: 0.761995s

on_train_batch_end: 1609164946.341325s

43008/50000 [========================>.....] - ETA: 5s - loss: 1.5932 - accuracy: 0.1003
on_train_batch_begin: 1609164946.341811s

42 step training time: 0.763812s

on_train_batch_end: 1609164947.099529s

44032/50000 [=========================>....] - ETA: 4s - loss: 1.5881 - accuracy: 0.1003
on_train_batch_begin: 1609164947.100039s

43 step training time: 0.758228s

on_train_batch_end: 1609164947.867556s

45056/50000 [==========================>...] - ETA: 3s - loss: 1.5829 - accuracy: 0.1003
on_train_batch_begin: 1609164947.868091s

44 step training time: 0.768052s

on_train_batch_end: 1609164948.631500s

46080/50000 [==========================>...] - ETA: 2s - loss: 1.5764 - accuracy: 0.1003
on_train_batch_begin: 1609164948.631996s

45 step training time: 0.763905s

on_train_batch_end: 1609164949.392725s

47104/50000 [===========================>..] - ETA: 2s - loss: 1.5727 - accuracy: 0.1003
on_train_batch_begin: 1609164949.393210s

46 step training time: 0.761214s

on_train_batch_end: 1609164950.151606s

48128/50000 [===========================>..] - ETA: 1s - loss: 1.5711 - accuracy: 0.1003
on_train_batch_begin: 1609164950.152092s

47 step training time: 0.758881s

on_train_batch_end: 1609164950.910883s

49152/50000 [============================>.] - ETA: 0s - loss: 1.5653 - accuracy: 0.1003
on_train_batch_begin: 1609164950.911374s

48 step training time: 0.759283s

on_train_batch_end: 1609164951.559712s

on_test_batch_begin: 1609164951.574398s

49 step training time: 0.663023s

on_epoch_end: 1609164953.546811s

Validation time: 1.972396s

Real time: 1609164953.546811s

Epoch time: 39.179043769836426s

50000/50000 [==============================] - 39s 784us/sample - loss: 1.5636 - accuracy: 0.1003 - val_loss: 7.0022 - val_accuracy: 0.1001

on_epoch_begin: 1609164953.547106s

Real time: 1609164953.5471158
Epoch 5/5

on_train_batch_begin: 1609164953.551697s

on_train_batch_end: 1609164954.315141s

 1024/50000 [..............................] - ETA: 36s - loss: 1.3523 - accuracy: 0.1004
on_train_batch_begin: 1609164954.315628s

1 step training time: 0.763931s

on_train_batch_end: 1609164955.085080s

 2048/50000 [>.............................] - ETA: 36s - loss: 1.3135 - accuracy: 0.1001
on_train_batch_begin: 1609164955.085578s

2 step training time: 0.769950s

on_train_batch_end: 1609164955.845791s

 3072/50000 [>.............................] - ETA: 35s - loss: 1.2741 - accuracy: 0.0999
on_train_batch_begin: 1609164955.846303s

3 step training time: 0.760725s

on_train_batch_end: 1609164956.619925s

 4096/50000 [=>............................] - ETA: 34s - loss: 1.2718 - accuracy: 0.1000
on_train_batch_begin: 1609164956.620424s

4 step training time: 0.774122s

on_train_batch_end: 1609164957.381648s

 5120/50000 [==>...........................] - ETA: 33s - loss: 1.2412 - accuracy: 0.1001
on_train_batch_begin: 1609164957.382153s

5 step training time: 0.761729s

on_train_batch_end: 1609164958.154562s

 6144/50000 [==>...........................] - ETA: 32s - loss: 1.2398 - accuracy: 0.1001
on_train_batch_begin: 1609164958.155106s

6 step training time: 0.772953s

on_train_batch_end: 1609164958.923812s

 7168/50000 [===>..........................] - ETA: 32s - loss: 1.2215 - accuracy: 0.1001
on_train_batch_begin: 1609164958.924294s

7 step training time: 0.769189s

on_train_batch_end: 1609164959.695922s

 8192/50000 [===>..........................] - ETA: 31s - loss: 1.2227 - accuracy: 0.1001
on_train_batch_begin: 1609164959.696458s

8 step training time: 0.772164s

on_train_batch_end: 1609164960.459383s

 9216/50000 [====>.........................] - ETA: 30s - loss: 1.2107 - accuracy: 0.1001
on_train_batch_begin: 1609164960.459869s

9 step training time: 0.763411s

on_train_batch_end: 1609164961.231103s

10240/50000 [=====>........................] - ETA: 29s - loss: 1.2105 - accuracy: 0.1002
on_train_batch_begin: 1609164961.231590s

10 step training time: 0.771721s

on_train_batch_end: 1609164961.993750s

11264/50000 [=====>........................] - ETA: 29s - loss: 1.2089 - accuracy: 0.1002
on_train_batch_begin: 1609164961.994492s

11 step training time: 0.762902s

on_train_batch_end: 1609164962.767729s

12288/50000 [======>.......................] - ETA: 28s - loss: 1.2018 - accuracy: 0.1002
on_train_batch_begin: 1609164962.768217s

12 step training time: 0.773726s

on_train_batch_end: 1609164963.531064s

13312/50000 [======>.......................] - ETA: 27s - loss: 1.1910 - accuracy: 0.1002
on_train_batch_begin: 1609164963.531580s

13 step training time: 0.763362s

on_train_batch_end: 1609164964.304286s

14336/50000 [=======>......................] - ETA: 26s - loss: 1.1821 - accuracy: 0.1002
on_train_batch_begin: 1609164964.304775s

14 step training time: 0.773196s

on_train_batch_end: 1609164965.067543s

15360/50000 [========>.....................] - ETA: 25s - loss: 1.1794 - accuracy: 0.1002
on_train_batch_begin: 1609164965.068031s

15 step training time: 0.763256s

on_train_batch_end: 1609164965.838734s

16384/50000 [========>.....................] - ETA: 25s - loss: 1.1752 - accuracy: 0.1002
on_train_batch_begin: 1609164965.839220s

16 step training time: 0.771189s

on_train_batch_end: 1609164966.594750s

17408/50000 [=========>....................] - ETA: 24s - loss: 1.1661 - accuracy: 0.1002
on_train_batch_begin: 1609164966.595235s

17 step training time: 0.756015s

on_train_batch_end: 1609164967.370169s

18432/50000 [==========>...................] - ETA: 23s - loss: 1.1649 - accuracy: 0.1002
on_train_batch_begin: 1609164967.370719s

18 step training time: 0.775484s

on_train_batch_end: 1609164968.134311s

19456/50000 [==========>...................] - ETA: 22s - loss: 1.1592 - accuracy: 0.1002
on_train_batch_begin: 1609164968.134841s

19 step training time: 0.764122s

on_train_batch_end: 1609164968.898134s

20480/50000 [===========>..................] - ETA: 22s - loss: 1.1577 - accuracy: 0.1002
on_train_batch_begin: 1609164968.898619s

20 step training time: 0.763777s

on_train_batch_end: 1609164969.663153s

21504/50000 [===========>..................] - ETA: 21s - loss: 1.1553 - accuracy: 0.1002
on_train_batch_begin: 1609164969.663677s

21 step training time: 0.765058s

on_train_batch_end: 1609164970.438810s

22528/50000 [============>.................] - ETA: 20s - loss: 1.1486 - accuracy: 0.1002
on_train_batch_begin: 1609164970.439311s

22 step training time: 0.775634s

on_train_batch_end: 1609164971.207153s

23552/50000 [=============>................] - ETA: 19s - loss: 1.1450 - accuracy: 0.1002
on_train_batch_begin: 1609164971.207645s

23 step training time: 0.768334s

on_train_batch_end: 1609164971.977869s

24576/50000 [=============>................] - ETA: 19s - loss: 1.1390 - accuracy: 0.1002
on_train_batch_begin: 1609164971.978354s

24 step training time: 0.770709s

on_train_batch_end: 1609164972.746650s

25600/50000 [==============>...............] - ETA: 18s - loss: 1.1346 - accuracy: 0.1002
on_train_batch_begin: 1609164972.747181s

25 step training time: 0.768827s

on_train_batch_end: 1609164973.514702s

26624/50000 [==============>...............] - ETA: 17s - loss: 1.1328 - accuracy: 0.1002
on_train_batch_begin: 1609164973.515196s

26 step training time: 0.768015s

on_train_batch_end: 1609164974.275072s

27648/50000 [===============>..............] - ETA: 16s - loss: 1.1319 - accuracy: 0.1002
on_train_batch_begin: 1609164974.275563s

27 step training time: 0.760367s

on_train_batch_end: 1609164975.047382s

28672/50000 [================>.............] - ETA: 15s - loss: 1.1248 - accuracy: 0.1002
on_train_batch_begin: 1609164975.047870s

28 step training time: 0.772307s

on_train_batch_end: 1609164975.814365s

29696/50000 [================>.............] - ETA: 15s - loss: 1.1210 - accuracy: 0.1003
on_train_batch_begin: 1609164975.814912s

29 step training time: 0.767042s

on_train_batch_end: 1609164976.590291s

30720/50000 [=================>............] - ETA: 14s - loss: 1.1194 - accuracy: 0.1003
on_train_batch_begin: 1609164976.590826s

30 step training time: 0.775914s

on_train_batch_end: 1609164977.352998s

31744/50000 [==================>...........] - ETA: 13s - loss: 1.1177 - accuracy: 0.1002
on_train_batch_begin: 1609164977.353491s

31 step training time: 0.762665s

on_train_batch_end: 1609164978.126321s

32768/50000 [==================>...........] - ETA: 12s - loss: 1.1152 - accuracy: 0.1002
on_train_batch_begin: 1609164978.126852s

32 step training time: 0.773362s

on_train_batch_end: 1609164978.889733s

33792/50000 [===================>..........] - ETA: 12s - loss: 1.1140 - accuracy: 0.1002
on_train_batch_begin: 1609164978.890220s

33 step training time: 0.763368s

on_train_batch_end: 1609164979.657867s

34816/50000 [===================>..........] - ETA: 11s - loss: 1.1131 - accuracy: 0.1002
on_train_batch_begin: 1609164979.658355s

34 step training time: 0.768134s

on_train_batch_end: 1609164980.419670s

35840/50000 [====================>.........] - ETA: 10s - loss: 1.1101 - accuracy: 0.1003
on_train_batch_begin: 1609164980.420154s

35 step training time: 0.761799s

on_train_batch_end: 1609164981.200251s

36864/50000 [=====================>........] - ETA: 9s - loss: 1.1102 - accuracy: 0.1003 
on_train_batch_begin: 1609164981.200737s

36 step training time: 0.780583s

on_train_batch_end: 1609164981.963432s

37888/50000 [=====================>........] - ETA: 9s - loss: 1.1054 - accuracy: 0.1003
on_train_batch_begin: 1609164981.963919s

37 step training time: 0.763182s

on_train_batch_end: 1609164982.733540s

38912/50000 [======================>.......] - ETA: 8s - loss: 1.1043 - accuracy: 0.1003
on_train_batch_begin: 1609164982.734025s

38 step training time: 0.770106s

on_train_batch_end: 1609164983.499716s

39936/50000 [======================>.......] - ETA: 7s - loss: 1.0993 - accuracy: 0.1003
on_train_batch_begin: 1609164983.500216s

39 step training time: 0.766191s

on_train_batch_end: 1609164984.273774s

40960/50000 [=======================>......] - ETA: 6s - loss: 1.0988 - accuracy: 0.1003
on_train_batch_begin: 1609164984.274258s

40 step training time: 0.774042s

on_train_batch_end: 1609164985.044958s

41984/50000 [========================>.....] - ETA: 6s - loss: 1.0975 - accuracy: 0.1003
on_train_batch_begin: 1609164985.045445s

41 step training time: 0.771187s

on_train_batch_end: 1609164985.818196s

43008/50000 [========================>.....] - ETA: 5s - loss: 1.0938 - accuracy: 0.1003
on_train_batch_begin: 1609164985.818717s

42 step training time: 0.773272s

on_train_batch_end: 1609164986.581992s

44032/50000 [=========================>....] - ETA: 4s - loss: 1.0951 - accuracy: 0.1003
on_train_batch_begin: 1609164986.582492s

43 step training time: 0.763775s

on_train_batch_end: 1609164987.355664s

45056/50000 [==========================>...] - ETA: 3s - loss: 1.0913 - accuracy: 0.1003
on_train_batch_begin: 1609164987.356153s

44 step training time: 0.773661s

on_train_batch_end: 1609164988.121588s

46080/50000 [==========================>...] - ETA: 2s - loss: 1.0878 - accuracy: 0.1003
on_train_batch_begin: 1609164988.122078s

45 step training time: 0.765924s

on_train_batch_end: 1609164988.894816s

47104/50000 [===========================>..] - ETA: 2s - loss: 1.0864 - accuracy: 0.1003
on_train_batch_begin: 1609164988.895300s

46 step training time: 0.773222s

on_train_batch_end: 1609164989.656361s

48128/50000 [===========================>..] - ETA: 1s - loss: 1.0866 - accuracy: 0.1003
on_train_batch_begin: 1609164989.656857s

47 step training time: 0.761557s

on_train_batch_end: 1609164990.429409s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0836 - accuracy: 0.1003
on_train_batch_begin: 1609164990.429906s

48 step training time: 0.773049s

on_train_batch_end: 1609164991.083370s

on_test_batch_begin: 1609164991.096546s

49 step training time: 0.666640s

on_epoch_end: 1609164993.096361s

Validation time: 1.999797s

Real time: 1609164993.096361s

Epoch time: 39.549275636672974s

50000/50000 [==============================] - 40s 791us/sample - loss: 1.0850 - accuracy: 0.1003 - val_loss: 7.0172 - val_accuracy: 0.0999
Tempo do fit: 235.1540584564209