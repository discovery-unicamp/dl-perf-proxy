wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 8:00
   204800/170498071 [..............................] - ETA: 1:18
  1032192/170498071 [..............................] - ETA: 23s 
  3702784/170498071 [..............................] - ETA: 8s 
  6938624/170498071 [>.............................] - ETA: 5s
 10174464/170498071 [>.............................] - ETA: 4s
 13377536/170498071 [=>............................] - ETA: 4s
 16474112/170498071 [=>............................] - ETA: 3s
 19718144/170498071 [==>...........................] - ETA: 3s
 22847488/170498071 [===>..........................] - ETA: 3s
 26099712/170498071 [===>..........................] - ETA: 3s
 29204480/170498071 [====>.........................] - ETA: 2s
 32423936/170498071 [====>.........................] - ETA: 2s
 35627008/170498071 [=====>........................] - ETA: 2s
 38707200/170498071 [=====>........................] - ETA: 2s
 41934848/170498071 [======>.......................] - ETA: 2s
 45031424/170498071 [======>.......................] - ETA: 2s
 48283648/170498071 [=======>......................] - ETA: 2s
 51421184/170498071 [========>.....................] - ETA: 2s
 54681600/170498071 [========>.....................] - ETA: 2s
 57868288/170498071 [=========>....................] - ETA: 2s
 60989440/170498071 [=========>....................] - ETA: 1s
 64167936/170498071 [==========>...................] - ETA: 1s
 67321856/170498071 [==========>...................] - ETA: 1s
 70492160/170498071 [===========>..................] - ETA: 1s
 73629696/170498071 [===========>..................] - ETA: 1s
 76537856/170498071 [============>.................] - ETA: 1s
 79405056/170498071 [============>.................] - ETA: 1s
 82321408/170498071 [=============>................] - ETA: 1s
 85352448/170498071 [==============>...............] - ETA: 1s
 88317952/170498071 [==============>...............] - ETA: 1s
 91365376/170498071 [===============>..............] - ETA: 1s
 94330880/170498071 [===============>..............] - ETA: 1s
 97370112/170498071 [================>.............] - ETA: 1s
100294656/170498071 [================>.............] - ETA: 1s
103260160/170498071 [=================>............] - ETA: 1s
106258432/170498071 [=================>............] - ETA: 1s
109142016/170498071 [==================>...........] - ETA: 1s
112254976/170498071 [==================>...........] - ETA: 1s
115253248/170498071 [===================>..........] - ETA: 0s
118054912/170498071 [===================>..........] - ETA: 0s
121118720/170498071 [====================>.........] - ETA: 0s
124084224/170498071 [====================>.........] - ETA: 0s
126910464/170498071 [=====================>........] - ETA: 0s
129835008/170498071 [=====================>........] - ETA: 0s
132816896/170498071 [======================>.......] - ETA: 0s
135815168/170498071 [======================>.......] - ETA: 0s
138813440/170498071 [=======================>......] - ETA: 0s
141737984/170498071 [=======================>......] - ETA: 0s
144728064/170498071 [========================>.....] - ETA: 0s
147693568/170498071 [========================>.....] - ETA: 0s
150724608/170498071 [=========================>....] - ETA: 0s
153722880/170498071 [==========================>...] - ETA: 0s
156688384/170498071 [==========================>...] - ETA: 0s
159703040/170498071 [===========================>..] - ETA: 0s
162701312/170498071 [===========================>..] - ETA: 0s
165486592/170498071 [============================>.] - ETA: 0s
168599552/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 11s
 3252224/94765736 [>.............................] - ETA: 1s 
 7200768/94765736 [=>............................] - ETA: 1s
10567680/94765736 [==>...........................] - ETA: 1s
15294464/94765736 [===>..........................] - ETA: 1s
18841600/94765736 [====>.........................] - ETA: 1s
22388736/94765736 [======>.......................] - ETA: 1s
24748032/94765736 [======>.......................] - ETA: 1s
27115520/94765736 [=======>......................] - ETA: 1s
29409280/94765736 [========>.....................] - ETA: 1s
30670848/94765736 [========>.....................] - ETA: 1s
32956416/94765736 [=========>....................] - ETA: 1s
34127872/94765736 [=========>....................] - ETA: 1s
36503552/94765736 [==========>...................] - ETA: 1s
38862848/94765736 [===========>..................] - ETA: 1s
43597824/94765736 [============>.................] - ETA: 1s
47136768/94765736 [=============>................] - ETA: 1s
49504256/94765736 [==============>...............] - ETA: 1s
50683904/94765736 [===============>..............] - ETA: 1s
55410688/94765736 [================>.............] - ETA: 0s
57712640/94765736 [=================>............] - ETA: 0s
59269120/94765736 [=================>............] - ETA: 0s
60071936/94765736 [==================>...........] - ETA: 0s
65986560/94765736 [===================>..........] - ETA: 0s
69533696/94765736 [=====================>........] - ETA: 0s
73859072/94765736 [======================>.......] - ETA: 0s
75440128/94765736 [======================>.......] - ETA: 0s
77471744/94765736 [=======================>......] - ETA: 0s
78987264/94765736 [========================>.....] - ETA: 0s
83058688/94765736 [=========================>....] - ETA: 0s
84893696/94765736 [=========================>....] - ETA: 0s
87195648/94765736 [==========================>...] - ETA: 0s
90144768/94765736 [===========================>..] - ETA: 0s
94773248/94765736 [==============================] - 2s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 29.001668691635132
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1609169860.352872s

Real time: 1609169860.3528965
Epoch 1/5

on_train_batch_begin: 1609169861.411619s

on_train_batch_end: 1609169992.354997s

  512/50000 [..............................] - ETA: 3:32:38 - loss: 16.4583 - accuracy: 0.0000e+00
on_train_batch_begin: 1609169992.355758s

1 step training time: 130.944139s

on_train_batch_end: 1609169992.527535s

 1024/50000 [..............................] - ETA: 1:45:21 - loss: 15.1637 - accuracy: 3.0518e-04
on_train_batch_begin: 1609169992.527949s

2 step training time: 0.172191s

on_train_batch_end: 1609169992.694925s

 1536/50000 [..............................] - ETA: 1:09:35 - loss: 13.9736 - accuracy: 4.2725e-04
on_train_batch_begin: 1609169992.695329s

3 step training time: 0.167380s

on_train_batch_end: 1609169992.862768s

 2048/50000 [>.............................] - ETA: 51:42 - loss: 12.7231 - accuracy: 8.8501e-04  
on_train_batch_begin: 1609169992.863186s

4 step training time: 0.167857s

on_train_batch_end: 1609169993.029649s

 2560/50000 [>.............................] - ETA: 40:58 - loss: 11.8382 - accuracy: 0.0014    
on_train_batch_begin: 1609169993.030056s

5 step training time: 0.166870s

on_train_batch_end: 1609169993.196581s

 3072/50000 [>.............................] - ETA: 33:49 - loss: 11.1764 - accuracy: 0.0024
on_train_batch_begin: 1609169993.196984s

6 step training time: 0.166928s

on_train_batch_end: 1609169993.363839s

 3584/50000 [=>............................] - ETA: 28:42 - loss: 10.6934 - accuracy: 0.0033
on_train_batch_begin: 1609169993.364237s

7 step training time: 0.167253s

on_train_batch_end: 1609169993.530556s

 4096/50000 [=>............................] - ETA: 24:52 - loss: 10.2888 - accuracy: 0.0048
on_train_batch_begin: 1609169993.530943s

8 step training time: 0.166706s

on_train_batch_end: 1609169993.697187s

 4608/50000 [=>............................] - ETA: 21:53 - loss: 9.9495 - accuracy: 0.0070 
on_train_batch_begin: 1609169993.697600s

9 step training time: 0.166658s

on_train_batch_end: 1609169993.864240s

 5120/50000 [==>...........................] - ETA: 19:30 - loss: 9.6656 - accuracy: 0.0091
on_train_batch_begin: 1609169993.864619s

10 step training time: 0.167018s

on_train_batch_end: 1609169994.031512s

 5632/50000 [==>...........................] - ETA: 17:33 - loss: 9.4154 - accuracy: 0.0115
on_train_batch_begin: 1609169994.031898s

11 step training time: 0.167279s

on_train_batch_end: 1609169994.198956s

 6144/50000 [==>...........................] - ETA: 15:55 - loss: 9.2009 - accuracy: 0.0141
on_train_batch_begin: 1609169994.199342s

12 step training time: 0.167444s

on_train_batch_end: 1609169994.365576s

 6656/50000 [==>...........................] - ETA: 14:32 - loss: 9.0005 - accuracy: 0.0168
on_train_batch_begin: 1609169994.365957s

13 step training time: 0.166614s

on_train_batch_end: 1609169994.537544s

 7168/50000 [===>..........................] - ETA: 13:21 - loss: 8.8370 - accuracy: 0.0187
on_train_batch_begin: 1609169994.537930s

14 step training time: 0.171973s

on_train_batch_end: 1609169994.703544s

 7680/50000 [===>..........................] - ETA: 12:20 - loss: 8.6797 - accuracy: 0.0209
on_train_batch_begin: 1609169994.703929s

15 step training time: 0.165999s

on_train_batch_end: 1609169994.869865s

 8192/50000 [===>..........................] - ETA: 11:26 - loss: 8.5498 - accuracy: 0.0224
on_train_batch_begin: 1609169994.870247s

16 step training time: 0.166318s

on_train_batch_end: 1609169995.035582s

 8704/50000 [====>.........................] - ETA: 10:39 - loss: 8.4309 - accuracy: 0.0239
on_train_batch_begin: 1609169995.035970s

17 step training time: 0.165723s

on_train_batch_end: 1609169995.203157s

 9216/50000 [====>.........................] - ETA: 9:56 - loss: 8.3153 - accuracy: 0.0253 
on_train_batch_begin: 1609169995.203536s

18 step training time: 0.167567s

on_train_batch_end: 1609169995.369824s

 9728/50000 [====>.........................] - ETA: 9:18 - loss: 8.2070 - accuracy: 0.0268
on_train_batch_begin: 1609169995.370206s

19 step training time: 0.166670s

on_train_batch_end: 1609169995.537577s

10240/50000 [=====>........................] - ETA: 8:44 - loss: 8.1075 - accuracy: 0.0282
on_train_batch_begin: 1609169995.537961s

20 step training time: 0.167754s

on_train_batch_end: 1609169995.704986s

10752/50000 [=====>........................] - ETA: 8:14 - loss: 8.0070 - accuracy: 0.0295
on_train_batch_begin: 1609169995.705408s

21 step training time: 0.167448s

on_train_batch_end: 1609169995.872486s

11264/50000 [=====>........................] - ETA: 7:46 - loss: 7.9166 - accuracy: 0.0307
on_train_batch_begin: 1609169995.872874s

22 step training time: 0.167466s

on_train_batch_end: 1609169996.039453s

11776/50000 [======>.......................] - ETA: 7:20 - loss: 7.8278 - accuracy: 0.0318
on_train_batch_begin: 1609169996.039830s

23 step training time: 0.166956s

on_train_batch_end: 1609169996.207830s

12288/50000 [======>.......................] - ETA: 6:56 - loss: 7.7349 - accuracy: 0.0330
on_train_batch_begin: 1609169996.208219s

24 step training time: 0.168390s

on_train_batch_end: 1609169996.374599s

12800/50000 [======>.......................] - ETA: 6:35 - loss: 7.6379 - accuracy: 0.0341
on_train_batch_begin: 1609169996.374988s

25 step training time: 0.166769s

on_train_batch_end: 1609169996.542946s

13312/50000 [======>.......................] - ETA: 6:15 - loss: 7.5510 - accuracy: 0.0350
on_train_batch_begin: 1609169996.543331s

26 step training time: 0.168343s

on_train_batch_end: 1609169996.710714s

13824/50000 [=======>......................] - ETA: 5:56 - loss: 7.4644 - accuracy: 0.0360
on_train_batch_begin: 1609169996.711106s

27 step training time: 0.167774s

on_train_batch_end: 1609169996.879498s

14336/50000 [=======>......................] - ETA: 5:39 - loss: 7.3844 - accuracy: 0.0368
on_train_batch_begin: 1609169996.879879s

28 step training time: 0.168774s

on_train_batch_end: 1609169997.047185s

14848/50000 [=======>......................] - ETA: 5:23 - loss: 7.3063 - accuracy: 0.0380
on_train_batch_begin: 1609169997.047571s

29 step training time: 0.167691s

on_train_batch_end: 1609169997.213414s

15360/50000 [========>.....................] - ETA: 5:08 - loss: 7.2255 - accuracy: 0.0390
on_train_batch_begin: 1609169997.213799s

30 step training time: 0.166229s

on_train_batch_end: 1609169997.379880s

15872/50000 [========>.....................] - ETA: 4:54 - loss: 7.1424 - accuracy: 0.0402
on_train_batch_begin: 1609169997.380259s

31 step training time: 0.166459s

on_train_batch_end: 1609169997.546750s

16384/50000 [========>.....................] - ETA: 4:41 - loss: 7.0579 - accuracy: 0.0413
on_train_batch_begin: 1609169997.547137s

32 step training time: 0.166878s

on_train_batch_end: 1609169997.713856s

16896/50000 [=========>....................] - ETA: 4:29 - loss: 6.9814 - accuracy: 0.0427
on_train_batch_begin: 1609169997.714235s

33 step training time: 0.167098s

on_train_batch_end: 1609169997.880325s

17408/50000 [=========>....................] - ETA: 4:17 - loss: 6.9015 - accuracy: 0.0440
on_train_batch_begin: 1609169997.880712s

34 step training time: 0.166476s

on_train_batch_end: 1609169998.047108s

17920/50000 [=========>....................] - ETA: 4:06 - loss: 6.8298 - accuracy: 0.0451
on_train_batch_begin: 1609169998.047487s

35 step training time: 0.166775s

on_train_batch_end: 1609169998.214613s

18432/50000 [==========>...................] - ETA: 3:56 - loss: 6.7584 - accuracy: 0.0463
on_train_batch_begin: 1609169998.214992s

36 step training time: 0.167506s

on_train_batch_end: 1609169998.381546s

18944/50000 [==========>...................] - ETA: 3:46 - loss: 6.6812 - accuracy: 0.0474
on_train_batch_begin: 1609169998.381937s

37 step training time: 0.166945s

on_train_batch_end: 1609169998.548299s

19456/50000 [==========>...................] - ETA: 3:36 - loss: 6.6115 - accuracy: 0.0485
on_train_batch_begin: 1609169998.548679s

38 step training time: 0.166742s

on_train_batch_end: 1609169998.714720s

19968/50000 [==========>...................] - ETA: 3:28 - loss: 6.5306 - accuracy: 0.0497
on_train_batch_begin: 1609169998.715102s

39 step training time: 0.166423s

on_train_batch_end: 1609169998.883064s

20480/50000 [===========>..................] - ETA: 3:19 - loss: 6.4606 - accuracy: 0.0508
on_train_batch_begin: 1609169998.883441s

40 step training time: 0.168338s

on_train_batch_end: 1609169999.049583s

20992/50000 [===========>..................] - ETA: 3:11 - loss: 6.3981 - accuracy: 0.0518
on_train_batch_begin: 1609169999.049963s

41 step training time: 0.166522s

on_train_batch_end: 1609169999.217309s

21504/50000 [===========>..................] - ETA: 3:04 - loss: 6.3399 - accuracy: 0.0528
on_train_batch_begin: 1609169999.217699s

42 step training time: 0.167736s

on_train_batch_end: 1609169999.383029s

22016/50000 [============>.................] - ETA: 2:56 - loss: 6.2760 - accuracy: 0.0539
on_train_batch_begin: 1609169999.383411s

43 step training time: 0.165712s

on_train_batch_end: 1609169999.550465s

22528/50000 [============>.................] - ETA: 2:49 - loss: 6.2094 - accuracy: 0.0548
on_train_batch_begin: 1609169999.550852s

44 step training time: 0.167442s

on_train_batch_end: 1609169999.716508s

23040/50000 [============>.................] - ETA: 2:43 - loss: 6.1460 - accuracy: 0.0559
on_train_batch_begin: 1609169999.716893s

45 step training time: 0.166041s

on_train_batch_end: 1609169999.883027s

23552/50000 [=============>................] - ETA: 2:36 - loss: 6.0883 - accuracy: 0.0568
on_train_batch_begin: 1609169999.883403s

46 step training time: 0.166510s

on_train_batch_end: 1609170000.050420s

24064/50000 [=============>................] - ETA: 2:30 - loss: 6.0253 - accuracy: 0.0577
on_train_batch_begin: 1609170000.050809s

47 step training time: 0.167407s

on_train_batch_end: 1609170000.217953s

24576/50000 [=============>................] - ETA: 2:24 - loss: 5.9690 - accuracy: 0.0585
on_train_batch_begin: 1609170000.218340s

48 step training time: 0.167531s

on_train_batch_end: 1609170000.384834s

25088/50000 [==============>...............] - ETA: 2:19 - loss: 5.9095 - accuracy: 0.0594
on_train_batch_begin: 1609170000.385223s

49 step training time: 0.166883s

on_train_batch_end: 1609170000.551700s

25600/50000 [==============>...............] - ETA: 2:13 - loss: 5.8536 - accuracy: 0.0602
on_train_batch_begin: 1609170000.552085s

50 step training time: 0.166862s

on_train_batch_end: 1609170000.721071s

26112/50000 [==============>...............] - ETA: 2:08 - loss: 5.7984 - accuracy: 0.0610
on_train_batch_begin: 1609170000.721485s

51 step training time: 0.169400s

on_train_batch_end: 1609170000.887285s

26624/50000 [==============>...............] - ETA: 2:03 - loss: 5.7470 - accuracy: 0.0618
on_train_batch_begin: 1609170000.887673s

52 step training time: 0.166188s

on_train_batch_end: 1609170001.053792s

27136/50000 [===============>..............] - ETA: 1:58 - loss: 5.6902 - accuracy: 0.0625
on_train_batch_begin: 1609170001.054175s

53 step training time: 0.166502s

on_train_batch_end: 1609170001.221690s

27648/50000 [===============>..............] - ETA: 1:53 - loss: 5.6363 - accuracy: 0.0632
on_train_batch_begin: 1609170001.222073s

54 step training time: 0.167897s

on_train_batch_end: 1609170001.388039s

28160/50000 [===============>..............] - ETA: 1:49 - loss: 5.5928 - accuracy: 0.0639
on_train_batch_begin: 1609170001.388423s

55 step training time: 0.166350s

on_train_batch_end: 1609170001.556105s

28672/50000 [================>.............] - ETA: 1:45 - loss: 5.5504 - accuracy: 0.0646
on_train_batch_begin: 1609170001.556488s

56 step training time: 0.168065s

on_train_batch_end: 1609170001.724027s

29184/50000 [================>.............] - ETA: 1:40 - loss: 5.5017 - accuracy: 0.0652
on_train_batch_begin: 1609170001.724408s

57 step training time: 0.167920s

on_train_batch_end: 1609170001.891098s

29696/50000 [================>.............] - ETA: 1:36 - loss: 5.4578 - accuracy: 0.0659
on_train_batch_begin: 1609170001.891487s

58 step training time: 0.167079s

on_train_batch_end: 1609170002.059638s

30208/50000 [=================>............] - ETA: 1:32 - loss: 5.4132 - accuracy: 0.0664
on_train_batch_begin: 1609170002.060025s

59 step training time: 0.168538s

on_train_batch_end: 1609170002.228460s

30720/50000 [=================>............] - ETA: 1:29 - loss: 5.3752 - accuracy: 0.0670
on_train_batch_begin: 1609170002.228857s

60 step training time: 0.168832s

on_train_batch_end: 1609170002.396380s

31232/50000 [=================>............] - ETA: 1:25 - loss: 5.3335 - accuracy: 0.0676
on_train_batch_begin: 1609170002.396767s

61 step training time: 0.167910s

on_train_batch_end: 1609170002.563367s

31744/50000 [==================>...........] - ETA: 1:21 - loss: 5.2923 - accuracy: 0.0681
on_train_batch_begin: 1609170002.563751s

62 step training time: 0.166985s

on_train_batch_end: 1609170002.731172s

32256/50000 [==================>...........] - ETA: 1:18 - loss: 5.2562 - accuracy: 0.0687
on_train_batch_begin: 1609170002.731554s

63 step training time: 0.167802s

on_train_batch_end: 1609170002.898418s

32768/50000 [==================>...........] - ETA: 1:14 - loss: 5.2192 - accuracy: 0.0692
on_train_batch_begin: 1609170002.898800s

64 step training time: 0.167246s

on_train_batch_end: 1609170003.065567s

33280/50000 [==================>...........] - ETA: 1:11 - loss: 5.1807 - accuracy: 0.0697
on_train_batch_begin: 1609170003.065956s

65 step training time: 0.167156s

on_train_batch_end: 1609170003.232612s

33792/50000 [===================>..........] - ETA: 1:08 - loss: 5.1421 - accuracy: 0.0702
on_train_batch_begin: 1609170003.233002s

66 step training time: 0.167046s

on_train_batch_end: 1609170003.400270s

34304/50000 [===================>..........] - ETA: 1:05 - loss: 5.1127 - accuracy: 0.0706
on_train_batch_begin: 1609170003.400657s

67 step training time: 0.167655s

on_train_batch_end: 1609170003.566729s

34816/50000 [===================>..........] - ETA: 1:02 - loss: 5.0812 - accuracy: 0.0711
on_train_batch_begin: 1609170003.567106s

68 step training time: 0.166449s

on_train_batch_end: 1609170003.733732s

35328/50000 [====================>.........] - ETA: 59s - loss: 5.0468 - accuracy: 0.0715 
on_train_batch_begin: 1609170003.734103s

69 step training time: 0.166998s

on_train_batch_end: 1609170003.899637s

35840/50000 [====================>.........] - ETA: 56s - loss: 5.0136 - accuracy: 0.0720
on_train_batch_begin: 1609170003.900021s

70 step training time: 0.165917s

on_train_batch_end: 1609170004.066650s

36352/50000 [====================>.........] - ETA: 53s - loss: 4.9789 - accuracy: 0.0724
on_train_batch_begin: 1609170004.067036s

71 step training time: 0.167015s

on_train_batch_end: 1609170004.233923s

36864/50000 [=====================>........] - ETA: 51s - loss: 4.9504 - accuracy: 0.0728
on_train_batch_begin: 1609170004.234302s

72 step training time: 0.167266s

on_train_batch_end: 1609170004.400510s

37376/50000 [=====================>........] - ETA: 48s - loss: 4.9223 - accuracy: 0.0732
on_train_batch_begin: 1609170004.400887s

73 step training time: 0.166585s

on_train_batch_end: 1609170004.567471s

37888/50000 [=====================>........] - ETA: 46s - loss: 4.8962 - accuracy: 0.0736
on_train_batch_begin: 1609170004.567853s

74 step training time: 0.166965s

on_train_batch_end: 1609170004.733872s

38400/50000 [======================>.......] - ETA: 43s - loss: 4.8676 - accuracy: 0.0739
on_train_batch_begin: 1609170004.734242s

75 step training time: 0.166389s

on_train_batch_end: 1609170004.900766s

38912/50000 [======================>.......] - ETA: 41s - loss: 4.8385 - accuracy: 0.0743
on_train_batch_begin: 1609170004.901140s

76 step training time: 0.166898s

on_train_batch_end: 1609170005.068439s

39424/50000 [======================>.......] - ETA: 38s - loss: 4.8126 - accuracy: 0.0747
on_train_batch_begin: 1609170005.068831s

77 step training time: 0.167691s

on_train_batch_end: 1609170005.235563s

39936/50000 [======================>.......] - ETA: 36s - loss: 4.7887 - accuracy: 0.0750
on_train_batch_begin: 1609170005.235941s

78 step training time: 0.167109s

on_train_batch_end: 1609170005.402268s

40448/50000 [=======================>......] - ETA: 34s - loss: 4.7639 - accuracy: 0.0753
on_train_batch_begin: 1609170005.402648s

79 step training time: 0.166707s

on_train_batch_end: 1609170005.569643s

40960/50000 [=======================>......] - ETA: 32s - loss: 4.7372 - accuracy: 0.0757
on_train_batch_begin: 1609170005.570026s

80 step training time: 0.167379s

on_train_batch_end: 1609170005.736781s

41472/50000 [=======================>......] - ETA: 29s - loss: 4.7142 - accuracy: 0.0760
on_train_batch_begin: 1609170005.737154s

81 step training time: 0.167127s

on_train_batch_end: 1609170005.904272s

41984/50000 [========================>.....] - ETA: 27s - loss: 4.6910 - accuracy: 0.0763
on_train_batch_begin: 1609170005.904648s

82 step training time: 0.167494s

on_train_batch_end: 1609170006.070982s

42496/50000 [========================>.....] - ETA: 25s - loss: 4.6661 - accuracy: 0.0766
on_train_batch_begin: 1609170006.071363s

83 step training time: 0.166715s

on_train_batch_end: 1609170006.238819s

43008/50000 [========================>.....] - ETA: 23s - loss: 4.6419 - accuracy: 0.0769
on_train_batch_begin: 1609170006.239198s

84 step training time: 0.167835s

on_train_batch_end: 1609170006.405413s

43520/50000 [=========================>....] - ETA: 21s - loss: 4.6160 - accuracy: 0.0772
on_train_batch_begin: 1609170006.405797s

85 step training time: 0.166599s

on_train_batch_end: 1609170006.573448s

44032/50000 [=========================>....] - ETA: 19s - loss: 4.5909 - accuracy: 0.0775
on_train_batch_begin: 1609170006.573835s

86 step training time: 0.168038s

on_train_batch_end: 1609170006.741208s

44544/50000 [=========================>....] - ETA: 17s - loss: 4.5686 - accuracy: 0.0778
on_train_batch_begin: 1609170006.741619s

87 step training time: 0.167784s

on_train_batch_end: 1609170006.908461s

45056/50000 [==========================>...] - ETA: 16s - loss: 4.5459 - accuracy: 0.0781
on_train_batch_begin: 1609170006.908851s

88 step training time: 0.167233s

on_train_batch_end: 1609170007.074424s

45568/50000 [==========================>...] - ETA: 14s - loss: 4.5251 - accuracy: 0.0784
on_train_batch_begin: 1609170007.074796s

89 step training time: 0.165945s

on_train_batch_end: 1609170007.241091s

46080/50000 [==========================>...] - ETA: 12s - loss: 4.5045 - accuracy: 0.0787
on_train_batch_begin: 1609170007.241501s

90 step training time: 0.166705s

on_train_batch_end: 1609170007.407989s

46592/50000 [==========================>...] - ETA: 10s - loss: 4.4883 - accuracy: 0.0789
on_train_batch_begin: 1609170007.408361s

91 step training time: 0.166860s

on_train_batch_end: 1609170007.575069s

47104/50000 [===========================>..] - ETA: 9s - loss: 4.4686 - accuracy: 0.0792 
on_train_batch_begin: 1609170007.575447s

92 step training time: 0.167086s

on_train_batch_end: 1609170007.742077s

47616/50000 [===========================>..] - ETA: 7s - loss: 4.4465 - accuracy: 0.0794
on_train_batch_begin: 1609170007.742461s

93 step training time: 0.167014s

on_train_batch_end: 1609170007.910613s

48128/50000 [===========================>..] - ETA: 5s - loss: 4.4247 - accuracy: 0.0797
on_train_batch_begin: 1609170007.911010s

94 step training time: 0.168548s

on_train_batch_end: 1609170008.078101s

48640/50000 [============================>.] - ETA: 4s - loss: 4.4010 - accuracy: 0.0799
on_train_batch_begin: 1609170008.078498s

95 step training time: 0.167489s

on_train_batch_end: 1609170008.245184s

49152/50000 [============================>.] - ETA: 2s - loss: 4.3801 - accuracy: 0.0802
on_train_batch_begin: 1609170008.245608s

96 step training time: 0.167110s

on_train_batch_end: 1609170008.411493s

49664/50000 [============================>.] - ETA: 1s - loss: 4.3616 - accuracy: 0.0804
on_train_batch_begin: 1609170008.411880s

97 step training time: 0.166272s

on_train_batch_end: 1609170013.101601s

on_test_batch_begin: 1609170013.489034s

98 step training time: 5.077154s

on_epoch_end: 1609170027.820608s

Validation time: 14.331553s

Real time: 1609170027.820608s

Epoch time: 167.46773743629456s

50000/50000 [==============================] - 167s 3ms/sample - loss: 4.3501 - accuracy: 0.0805 - val_loss: 7.7187 - val_accuracy: 0.0000e+00

on_epoch_begin: 1609170027.820876s

Real time: 1609170027.8208854
Epoch 2/5

on_train_batch_begin: 1609170027.828632s

on_train_batch_end: 1609170027.996431s

  512/50000 [..............................] - ETA: 16s - loss: 2.5150 - accuracy: 0.1027
on_train_batch_begin: 1609170027.996819s

1 step training time: 0.168187s

on_train_batch_end: 1609170028.163065s

 1024/50000 [..............................] - ETA: 16s - loss: 2.6441 - accuracy: 0.1022
on_train_batch_begin: 1609170028.163446s

2 step training time: 0.166627s

on_train_batch_end: 1609170028.329434s

 1536/50000 [..............................] - ETA: 16s - loss: 2.6128 - accuracy: 0.1022
on_train_batch_begin: 1609170028.329816s

3 step training time: 0.166370s

on_train_batch_end: 1609170028.496504s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.5960 - accuracy: 0.1021
on_train_batch_begin: 1609170028.496896s

4 step training time: 0.167080s

on_train_batch_end: 1609170028.664073s

 2560/50000 [>.............................] - ETA: 15s - loss: 2.6357 - accuracy: 0.1019
on_train_batch_begin: 1609170028.664448s

5 step training time: 0.167552s

on_train_batch_end: 1609170028.830079s

 3072/50000 [>.............................] - ETA: 15s - loss: 2.5883 - accuracy: 0.1021
on_train_batch_begin: 1609170028.830452s

6 step training time: 0.166004s

on_train_batch_end: 1609170028.995800s

 3584/50000 [=>............................] - ETA: 15s - loss: 2.5581 - accuracy: 0.1019
on_train_batch_begin: 1609170028.996168s

7 step training time: 0.165716s

on_train_batch_end: 1609170029.162610s

 4096/50000 [=>............................] - ETA: 15s - loss: 2.5337 - accuracy: 0.1019
on_train_batch_begin: 1609170029.162989s

8 step training time: 0.166821s

on_train_batch_end: 1609170029.328831s

 4608/50000 [=>............................] - ETA: 14s - loss: 2.5370 - accuracy: 0.1020
on_train_batch_begin: 1609170029.329220s

9 step training time: 0.166231s

on_train_batch_end: 1609170029.495590s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.5067 - accuracy: 0.1021
on_train_batch_begin: 1609170029.495968s

10 step training time: 0.166749s

on_train_batch_end: 1609170029.661719s

 5632/50000 [==>...........................] - ETA: 14s - loss: 2.5039 - accuracy: 0.1020
on_train_batch_begin: 1609170029.662097s

11 step training time: 0.166129s

on_train_batch_end: 1609170029.828668s

 6144/50000 [==>...........................] - ETA: 14s - loss: 2.5229 - accuracy: 0.1020
on_train_batch_begin: 1609170029.829085s

12 step training time: 0.166988s

on_train_batch_end: 1609170029.996383s

 6656/50000 [==>...........................] - ETA: 14s - loss: 2.5268 - accuracy: 0.1021
on_train_batch_begin: 1609170029.996760s

13 step training time: 0.167675s

on_train_batch_end: 1609170030.163301s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.5128 - accuracy: 0.1021
on_train_batch_begin: 1609170030.163680s

14 step training time: 0.166920s

on_train_batch_end: 1609170030.329517s

 7680/50000 [===>..........................] - ETA: 13s - loss: 2.5173 - accuracy: 0.1020
on_train_batch_begin: 1609170030.329904s

15 step training time: 0.166223s

on_train_batch_end: 1609170030.495874s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.5016 - accuracy: 0.1020
on_train_batch_begin: 1609170030.496254s

16 step training time: 0.166350s

on_train_batch_end: 1609170030.663179s

 8704/50000 [====>.........................] - ETA: 13s - loss: 2.5079 - accuracy: 0.1020
on_train_batch_begin: 1609170030.663561s

17 step training time: 0.167307s

on_train_batch_end: 1609170030.830819s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.5180 - accuracy: 0.1020
on_train_batch_begin: 1609170030.831205s

18 step training time: 0.167645s

on_train_batch_end: 1609170030.998376s

 9728/50000 [====>.........................] - ETA: 13s - loss: 2.5285 - accuracy: 0.1021
on_train_batch_begin: 1609170030.998763s

19 step training time: 0.167558s

on_train_batch_end: 1609170031.165761s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.5384 - accuracy: 0.1021
on_train_batch_begin: 1609170031.166146s

20 step training time: 0.167383s

on_train_batch_end: 1609170031.333180s

10752/50000 [=====>........................] - ETA: 12s - loss: 2.5381 - accuracy: 0.1022
on_train_batch_begin: 1609170031.333598s

21 step training time: 0.167452s

on_train_batch_end: 1609170031.500461s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.5480 - accuracy: 0.1022
on_train_batch_begin: 1609170031.500847s

22 step training time: 0.167249s

on_train_batch_end: 1609170031.667985s

11776/50000 [======>.......................] - ETA: 12s - loss: 2.5340 - accuracy: 0.1023
on_train_batch_begin: 1609170031.668369s

23 step training time: 0.167522s

on_train_batch_end: 1609170031.834541s

12288/50000 [======>.......................] - ETA: 12s - loss: 2.5283 - accuracy: 0.1023
on_train_batch_begin: 1609170031.834925s

24 step training time: 0.166556s

on_train_batch_end: 1609170032.002557s

12800/50000 [======>.......................] - ETA: 12s - loss: 2.5246 - accuracy: 0.1024
on_train_batch_begin: 1609170032.002941s

25 step training time: 0.168015s

on_train_batch_end: 1609170032.169139s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.5119 - accuracy: 0.1025
on_train_batch_begin: 1609170032.169553s

26 step training time: 0.166612s

on_train_batch_end: 1609170032.336540s

13824/50000 [=======>......................] - ETA: 11s - loss: 2.5127 - accuracy: 0.1024
on_train_batch_begin: 1609170032.336916s

27 step training time: 0.167363s

on_train_batch_end: 1609170032.504114s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.5071 - accuracy: 0.1024
on_train_batch_begin: 1609170032.504492s

28 step training time: 0.167577s

on_train_batch_end: 1609170032.670858s

14848/50000 [=======>......................] - ETA: 11s - loss: 2.5156 - accuracy: 0.1024
on_train_batch_begin: 1609170032.671239s

29 step training time: 0.166747s

on_train_batch_end: 1609170032.838360s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.5102 - accuracy: 0.1025
on_train_batch_begin: 1609170032.838749s

30 step training time: 0.167510s

on_train_batch_end: 1609170033.005680s

15872/50000 [========>.....................] - ETA: 11s - loss: 2.5109 - accuracy: 0.1025
on_train_batch_begin: 1609170033.006059s

31 step training time: 0.167310s

on_train_batch_end: 1609170033.173855s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.5130 - accuracy: 0.1025
on_train_batch_begin: 1609170033.174264s

32 step training time: 0.168205s

on_train_batch_end: 1609170033.340835s

16896/50000 [=========>....................] - ETA: 10s - loss: 2.5053 - accuracy: 0.1026
on_train_batch_begin: 1609170033.341237s

33 step training time: 0.166973s

on_train_batch_end: 1609170033.508021s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.4986 - accuracy: 0.1026
on_train_batch_begin: 1609170033.508419s

34 step training time: 0.167182s

on_train_batch_end: 1609170033.675770s

17920/50000 [=========>....................] - ETA: 10s - loss: 2.4898 - accuracy: 0.1026
on_train_batch_begin: 1609170033.676175s

35 step training time: 0.167756s

on_train_batch_end: 1609170033.841949s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.4807 - accuracy: 0.1026
on_train_batch_begin: 1609170033.842343s

36 step training time: 0.166168s

on_train_batch_end: 1609170034.010206s

18944/50000 [==========>...................] - ETA: 10s - loss: 2.4744 - accuracy: 0.1025
on_train_batch_begin: 1609170034.010601s

37 step training time: 0.168258s

on_train_batch_end: 1609170034.177533s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.4697 - accuracy: 0.1026 
on_train_batch_begin: 1609170034.177940s

38 step training time: 0.167339s

on_train_batch_end: 1609170034.345094s

19968/50000 [==========>...................] - ETA: 9s - loss: 2.4686 - accuracy: 0.1026
on_train_batch_begin: 1609170034.345526s

39 step training time: 0.167586s

on_train_batch_end: 1609170034.511919s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.4617 - accuracy: 0.1026
on_train_batch_begin: 1609170034.512310s

40 step training time: 0.166784s

on_train_batch_end: 1609170034.679350s

20992/50000 [===========>..................] - ETA: 9s - loss: 2.4549 - accuracy: 0.1026
on_train_batch_begin: 1609170034.679777s

41 step training time: 0.167467s

on_train_batch_end: 1609170034.846670s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.4507 - accuracy: 0.1026
on_train_batch_begin: 1609170034.847063s

42 step training time: 0.167286s

on_train_batch_end: 1609170035.014071s

22016/50000 [============>.................] - ETA: 9s - loss: 2.4461 - accuracy: 0.1026
on_train_batch_begin: 1609170035.014464s

43 step training time: 0.167401s

on_train_batch_end: 1609170035.180453s

22528/50000 [============>.................] - ETA: 8s - loss: 2.4372 - accuracy: 0.1026
on_train_batch_begin: 1609170035.180846s

44 step training time: 0.166382s

on_train_batch_end: 1609170035.348393s

23040/50000 [============>.................] - ETA: 8s - loss: 2.4251 - accuracy: 0.1027
on_train_batch_begin: 1609170035.348788s

45 step training time: 0.167942s

on_train_batch_end: 1609170035.514609s

23552/50000 [=============>................] - ETA: 8s - loss: 2.4205 - accuracy: 0.1027
on_train_batch_begin: 1609170035.514997s

46 step training time: 0.166209s

on_train_batch_end: 1609170035.680790s

24064/50000 [=============>................] - ETA: 8s - loss: 2.4102 - accuracy: 0.1027
on_train_batch_begin: 1609170035.681192s

47 step training time: 0.166195s

on_train_batch_end: 1609170035.848148s

24576/50000 [=============>................] - ETA: 8s - loss: 2.4051 - accuracy: 0.1027
on_train_batch_begin: 1609170035.848540s

48 step training time: 0.167348s

on_train_batch_end: 1609170036.014997s

25088/50000 [==============>...............] - ETA: 8s - loss: 2.3949 - accuracy: 0.1027
on_train_batch_begin: 1609170036.015398s

49 step training time: 0.166858s

on_train_batch_end: 1609170036.182844s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.3897 - accuracy: 0.1026
on_train_batch_begin: 1609170036.183240s

50 step training time: 0.167842s

on_train_batch_end: 1609170036.349972s

26112/50000 [==============>...............] - ETA: 7s - loss: 2.3819 - accuracy: 0.1027
on_train_batch_begin: 1609170036.350368s

51 step training time: 0.167128s

on_train_batch_end: 1609170036.518172s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.3781 - accuracy: 0.1027
on_train_batch_begin: 1609170036.518580s

52 step training time: 0.168212s

on_train_batch_end: 1609170036.685770s

27136/50000 [===============>..............] - ETA: 7s - loss: 2.3741 - accuracy: 0.1027
on_train_batch_begin: 1609170036.686167s

53 step training time: 0.167587s

on_train_batch_end: 1609170036.853914s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.3703 - accuracy: 0.1027
on_train_batch_begin: 1609170036.854316s

54 step training time: 0.168148s

on_train_batch_end: 1609170037.020721s

28160/50000 [===============>..............] - ETA: 7s - loss: 2.3664 - accuracy: 0.1027
on_train_batch_begin: 1609170037.021103s

55 step training time: 0.166788s

on_train_batch_end: 1609170037.187768s

28672/50000 [================>.............] - ETA: 6s - loss: 2.3688 - accuracy: 0.1028
on_train_batch_begin: 1609170037.188151s

56 step training time: 0.167048s

on_train_batch_end: 1609170037.355672s

29184/50000 [================>.............] - ETA: 6s - loss: 2.3599 - accuracy: 0.1028
on_train_batch_begin: 1609170037.356053s

57 step training time: 0.167902s

on_train_batch_end: 1609170037.521462s

29696/50000 [================>.............] - ETA: 6s - loss: 2.3549 - accuracy: 0.1028
on_train_batch_begin: 1609170037.521847s

58 step training time: 0.165794s

on_train_batch_end: 1609170037.687735s

30208/50000 [=================>............] - ETA: 6s - loss: 2.3536 - accuracy: 0.1028
on_train_batch_begin: 1609170037.688122s

59 step training time: 0.166275s

on_train_batch_end: 1609170037.854172s

30720/50000 [=================>............] - ETA: 6s - loss: 2.3459 - accuracy: 0.1028
on_train_batch_begin: 1609170037.854582s

60 step training time: 0.166460s

on_train_batch_end: 1609170038.021187s

31232/50000 [=================>............] - ETA: 6s - loss: 2.3387 - accuracy: 0.1029
on_train_batch_begin: 1609170038.021600s

61 step training time: 0.167018s

on_train_batch_end: 1609170038.187976s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.3345 - accuracy: 0.1029
on_train_batch_begin: 1609170038.188356s

62 step training time: 0.166756s

on_train_batch_end: 1609170038.354851s

32256/50000 [==================>...........] - ETA: 5s - loss: 2.3319 - accuracy: 0.1029
on_train_batch_begin: 1609170038.355234s

63 step training time: 0.166878s

on_train_batch_end: 1609170038.521087s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.3275 - accuracy: 0.1029
on_train_batch_begin: 1609170038.521511s

64 step training time: 0.166276s

on_train_batch_end: 1609170038.688934s

33280/50000 [==================>...........] - ETA: 5s - loss: 2.3246 - accuracy: 0.1029
on_train_batch_begin: 1609170038.689336s

65 step training time: 0.167826s

on_train_batch_end: 1609170038.855417s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.3160 - accuracy: 0.1029
on_train_batch_begin: 1609170038.855819s

66 step training time: 0.166483s

on_train_batch_end: 1609170039.022072s

34304/50000 [===================>..........] - ETA: 5s - loss: 2.3139 - accuracy: 0.1030
on_train_batch_begin: 1609170039.022471s

67 step training time: 0.166652s

on_train_batch_end: 1609170039.188994s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.3100 - accuracy: 0.1030
on_train_batch_begin: 1609170039.189420s

68 step training time: 0.166949s

on_train_batch_end: 1609170039.355838s

35328/50000 [====================>.........] - ETA: 4s - loss: 2.3084 - accuracy: 0.1030
on_train_batch_begin: 1609170039.356241s

69 step training time: 0.166821s

on_train_batch_end: 1609170039.523147s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.3057 - accuracy: 0.1030
on_train_batch_begin: 1609170039.523578s

70 step training time: 0.167337s

on_train_batch_end: 1609170039.690349s

36352/50000 [====================>.........] - ETA: 4s - loss: 2.3022 - accuracy: 0.1030
on_train_batch_begin: 1609170039.690751s

71 step training time: 0.167173s

on_train_batch_end: 1609170039.857433s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.2966 - accuracy: 0.1030
on_train_batch_begin: 1609170039.857834s

72 step training time: 0.167083s

on_train_batch_end: 1609170040.023315s

37376/50000 [=====================>........] - ETA: 4s - loss: 2.2937 - accuracy: 0.1030
on_train_batch_begin: 1609170040.023711s

73 step training time: 0.165877s

on_train_batch_end: 1609170040.190965s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.2903 - accuracy: 0.1030
on_train_batch_begin: 1609170040.191361s

74 step training time: 0.167650s

on_train_batch_end: 1609170040.357349s

38400/50000 [======================>.......] - ETA: 3s - loss: 2.2878 - accuracy: 0.1030
on_train_batch_begin: 1609170040.357743s

75 step training time: 0.166382s

on_train_batch_end: 1609170040.524846s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.2850 - accuracy: 0.1031
on_train_batch_begin: 1609170040.525252s

76 step training time: 0.167509s

on_train_batch_end: 1609170040.692914s

39424/50000 [======================>.......] - ETA: 3s - loss: 2.2802 - accuracy: 0.1031
on_train_batch_begin: 1609170040.693341s

77 step training time: 0.168089s

on_train_batch_end: 1609170040.861224s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.2750 - accuracy: 0.1031
on_train_batch_begin: 1609170040.861640s

78 step training time: 0.168299s

on_train_batch_end: 1609170041.030110s

40448/50000 [=======================>......] - ETA: 3s - loss: 2.2694 - accuracy: 0.1031
on_train_batch_begin: 1609170041.030508s

79 step training time: 0.168868s

on_train_batch_end: 1609170041.198762s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.2624 - accuracy: 0.1032
on_train_batch_begin: 1609170041.199164s

80 step training time: 0.168655s

on_train_batch_end: 1609170041.366727s

41472/50000 [=======================>......] - ETA: 2s - loss: 2.2566 - accuracy: 0.1032
on_train_batch_begin: 1609170041.367125s

81 step training time: 0.167961s

on_train_batch_end: 1609170041.534883s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.2523 - accuracy: 0.1032
on_train_batch_begin: 1609170041.535352s

82 step training time: 0.168227s

on_train_batch_end: 1609170041.704685s

42496/50000 [========================>.....] - ETA: 2s - loss: 2.2501 - accuracy: 0.1032
on_train_batch_begin: 1609170041.705078s

83 step training time: 0.169727s

on_train_batch_end: 1609170041.873885s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.2483 - accuracy: 0.1032
on_train_batch_begin: 1609170041.874281s

84 step training time: 0.169202s

on_train_batch_end: 1609170042.042066s

43520/50000 [=========================>....] - ETA: 2s - loss: 2.2441 - accuracy: 0.1032
on_train_batch_begin: 1609170042.042466s

85 step training time: 0.168186s

on_train_batch_end: 1609170042.209950s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.2393 - accuracy: 0.1032
on_train_batch_begin: 1609170042.210350s

86 step training time: 0.167883s

on_train_batch_end: 1609170042.379196s

44544/50000 [=========================>....] - ETA: 1s - loss: 2.2336 - accuracy: 0.1032
on_train_batch_begin: 1609170042.379591s

87 step training time: 0.169241s

on_train_batch_end: 1609170042.548197s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.2318 - accuracy: 0.1032
on_train_batch_begin: 1609170042.548616s

88 step training time: 0.169025s

on_train_batch_end: 1609170042.716316s

45568/50000 [==========================>...] - ETA: 1s - loss: 2.2290 - accuracy: 0.1032
on_train_batch_begin: 1609170042.716719s

89 step training time: 0.168103s

on_train_batch_end: 1609170042.883118s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.2235 - accuracy: 0.1032
on_train_batch_begin: 1609170042.883516s

90 step training time: 0.166798s

on_train_batch_end: 1609170043.051190s

46592/50000 [==========================>...] - ETA: 1s - loss: 2.2181 - accuracy: 0.1032
on_train_batch_begin: 1609170043.051588s

91 step training time: 0.168072s

on_train_batch_end: 1609170043.220452s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.2107 - accuracy: 0.1032
on_train_batch_begin: 1609170043.220850s

92 step training time: 0.169262s

on_train_batch_end: 1609170043.389301s

47616/50000 [===========================>..] - ETA: 0s - loss: 2.2055 - accuracy: 0.1032
on_train_batch_begin: 1609170043.389702s

93 step training time: 0.168852s

on_train_batch_end: 1609170043.556805s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.2012 - accuracy: 0.1032
on_train_batch_begin: 1609170043.557201s

94 step training time: 0.167499s

on_train_batch_end: 1609170043.724399s

48640/50000 [============================>.] - ETA: 0s - loss: 2.1964 - accuracy: 0.1032
on_train_batch_begin: 1609170043.724794s

95 step training time: 0.167593s

on_train_batch_end: 1609170043.891071s

49152/50000 [============================>.] - ETA: 0s - loss: 2.1924 - accuracy: 0.1032
on_train_batch_begin: 1609170043.891469s

96 step training time: 0.166675s

on_train_batch_end: 1609170044.057940s

49664/50000 [============================>.] - ETA: 0s - loss: 2.1887 - accuracy: 0.1032
on_train_batch_begin: 1609170044.058332s

97 step training time: 0.166862s

on_train_batch_end: 1609170044.212641s

on_test_batch_begin: 1609170044.248169s

98 step training time: 0.189837s

on_epoch_end: 1609170044.983408s

Validation time: 0.735224s

Real time: 1609170044.983408s

Epoch time: 17.162543535232544s

50000/50000 [==============================] - 17s 343us/sample - loss: 2.1870 - accuracy: 0.1032 - val_loss: 6.7253 - val_accuracy: 0.0997

on_epoch_begin: 1609170044.983666s

Real time: 1609170044.9836757
Epoch 3/5

on_train_batch_begin: 1609170044.991685s

on_train_batch_end: 1609170045.160325s

  512/50000 [..............................] - ETA: 17s - loss: 1.7548 - accuracy: 0.1051
on_train_batch_begin: 1609170045.160726s

1 step training time: 0.169041s

on_train_batch_end: 1609170045.326829s

 1024/50000 [..............................] - ETA: 16s - loss: 1.6652 - accuracy: 0.1052
on_train_batch_begin: 1609170045.327218s

2 step training time: 0.166492s

on_train_batch_end: 1609170045.494246s

 1536/50000 [..............................] - ETA: 16s - loss: 1.6683 - accuracy: 0.1046
on_train_batch_begin: 1609170045.494640s

3 step training time: 0.167422s

on_train_batch_end: 1609170045.661115s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.6748 - accuracy: 0.1047
on_train_batch_begin: 1609170045.661536s

4 step training time: 0.166897s

on_train_batch_end: 1609170045.829230s

 2560/50000 [>.............................] - ETA: 15s - loss: 1.6743 - accuracy: 0.1046
on_train_batch_begin: 1609170045.829654s

5 step training time: 0.168118s

on_train_batch_end: 1609170045.996378s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.6824 - accuracy: 0.1044
on_train_batch_begin: 1609170045.996772s

6 step training time: 0.167118s

on_train_batch_end: 1609170046.163801s

 3584/50000 [=>............................] - ETA: 15s - loss: 1.6722 - accuracy: 0.1042
on_train_batch_begin: 1609170046.164193s

7 step training time: 0.167422s

on_train_batch_end: 1609170046.331156s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.6718 - accuracy: 0.1042
on_train_batch_begin: 1609170046.331555s

8 step training time: 0.167361s

on_train_batch_end: 1609170046.498991s

 4608/50000 [=>............................] - ETA: 14s - loss: 1.6676 - accuracy: 0.1039
on_train_batch_begin: 1609170046.499386s

9 step training time: 0.167831s

on_train_batch_end: 1609170046.667155s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.6617 - accuracy: 0.1043
on_train_batch_begin: 1609170046.667535s

10 step training time: 0.168149s

on_train_batch_end: 1609170046.833021s

 5632/50000 [==>...........................] - ETA: 14s - loss: 1.6506 - accuracy: 0.1041
on_train_batch_begin: 1609170046.833429s

11 step training time: 0.165895s

on_train_batch_end: 1609170047.000770s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.6594 - accuracy: 0.1040
on_train_batch_begin: 1609170047.001157s

12 step training time: 0.167728s

on_train_batch_end: 1609170047.167721s

 6656/50000 [==>...........................] - ETA: 14s - loss: 1.6615 - accuracy: 0.1041
on_train_batch_begin: 1609170047.168112s

13 step training time: 0.166955s

on_train_batch_end: 1609170047.335174s

 7168/50000 [===>..........................] - ETA: 14s - loss: 1.6501 - accuracy: 0.1040
on_train_batch_begin: 1609170047.335550s

14 step training time: 0.167438s

on_train_batch_end: 1609170047.502381s

 7680/50000 [===>..........................] - ETA: 13s - loss: 1.6344 - accuracy: 0.1040
on_train_batch_begin: 1609170047.502763s

15 step training time: 0.167212s

on_train_batch_end: 1609170047.669225s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.6337 - accuracy: 0.1040
on_train_batch_begin: 1609170047.669635s

16 step training time: 0.166872s

on_train_batch_end: 1609170047.835125s

 8704/50000 [====>.........................] - ETA: 13s - loss: 1.6330 - accuracy: 0.1040
on_train_batch_begin: 1609170047.835506s

17 step training time: 0.165871s

on_train_batch_end: 1609170048.002165s

 9216/50000 [====>.........................] - ETA: 13s - loss: 1.6360 - accuracy: 0.1041
on_train_batch_begin: 1609170048.002548s

18 step training time: 0.167042s

on_train_batch_end: 1609170048.168802s

 9728/50000 [====>.........................] - ETA: 13s - loss: 1.6359 - accuracy: 0.1042
on_train_batch_begin: 1609170048.169183s

19 step training time: 0.166636s

on_train_batch_end: 1609170048.335105s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.6336 - accuracy: 0.1042
on_train_batch_begin: 1609170048.335486s

20 step training time: 0.166302s

on_train_batch_end: 1609170048.501831s

10752/50000 [=====>........................] - ETA: 12s - loss: 1.6277 - accuracy: 0.1042
on_train_batch_begin: 1609170048.502208s

21 step training time: 0.166722s

on_train_batch_end: 1609170048.667749s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.6190 - accuracy: 0.1042
on_train_batch_begin: 1609170048.668159s

22 step training time: 0.165951s

on_train_batch_end: 1609170048.834398s

11776/50000 [======>.......................] - ETA: 12s - loss: 1.6036 - accuracy: 0.1043
on_train_batch_begin: 1609170048.834770s

23 step training time: 0.166611s

on_train_batch_end: 1609170049.001194s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.5974 - accuracy: 0.1043
on_train_batch_begin: 1609170049.001598s

24 step training time: 0.166828s

on_train_batch_end: 1609170049.167247s

12800/50000 [======>.......................] - ETA: 12s - loss: 1.5876 - accuracy: 0.1043
on_train_batch_begin: 1609170049.167628s

25 step training time: 0.166030s

on_train_batch_end: 1609170049.335046s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.5746 - accuracy: 0.1044
on_train_batch_begin: 1609170049.335455s

26 step training time: 0.167827s

on_train_batch_end: 1609170049.501518s

13824/50000 [=======>......................] - ETA: 11s - loss: 1.5702 - accuracy: 0.1044
on_train_batch_begin: 1609170049.501888s

27 step training time: 0.166433s

on_train_batch_end: 1609170049.668147s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.5597 - accuracy: 0.1044
on_train_batch_begin: 1609170049.668523s

28 step training time: 0.166635s

on_train_batch_end: 1609170049.834558s

14848/50000 [=======>......................] - ETA: 11s - loss: 1.5588 - accuracy: 0.1044
on_train_batch_begin: 1609170049.834938s

29 step training time: 0.166415s

on_train_batch_end: 1609170050.001312s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.5541 - accuracy: 0.1043
on_train_batch_begin: 1609170050.001709s

30 step training time: 0.166771s

on_train_batch_end: 1609170050.168658s

15872/50000 [========>.....................] - ETA: 11s - loss: 1.5493 - accuracy: 0.1043
on_train_batch_begin: 1609170050.169054s

31 step training time: 0.167346s

on_train_batch_end: 1609170050.335865s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.5468 - accuracy: 0.1043
on_train_batch_begin: 1609170050.336252s

32 step training time: 0.167198s

on_train_batch_end: 1609170050.503268s

16896/50000 [=========>....................] - ETA: 10s - loss: 1.5436 - accuracy: 0.1043
on_train_batch_begin: 1609170050.503653s

33 step training time: 0.167401s

on_train_batch_end: 1609170050.669192s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.5339 - accuracy: 0.1043
on_train_batch_begin: 1609170050.669609s

34 step training time: 0.165956s

on_train_batch_end: 1609170050.835210s

17920/50000 [=========>....................] - ETA: 10s - loss: 1.5295 - accuracy: 0.1042
on_train_batch_begin: 1609170050.835588s

35 step training time: 0.165979s

on_train_batch_end: 1609170051.000704s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.5219 - accuracy: 0.1042
on_train_batch_begin: 1609170051.001101s

36 step training time: 0.165513s

on_train_batch_end: 1609170051.166772s

18944/50000 [==========>...................] - ETA: 10s - loss: 1.5196 - accuracy: 0.1043
on_train_batch_begin: 1609170051.167152s

37 step training time: 0.166051s

on_train_batch_end: 1609170051.334905s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.5157 - accuracy: 0.1043 
on_train_batch_begin: 1609170051.335310s

38 step training time: 0.168158s

on_train_batch_end: 1609170051.501074s

19968/50000 [==========>...................] - ETA: 9s - loss: 1.5235 - accuracy: 0.1043
on_train_batch_begin: 1609170051.501505s

39 step training time: 0.166194s

on_train_batch_end: 1609170051.669048s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.5210 - accuracy: 0.1043
on_train_batch_begin: 1609170051.669486s

40 step training time: 0.167982s

on_train_batch_end: 1609170051.835804s

20992/50000 [===========>..................] - ETA: 9s - loss: 1.5198 - accuracy: 0.1043
on_train_batch_begin: 1609170051.836201s

41 step training time: 0.166714s

on_train_batch_end: 1609170052.002737s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.5175 - accuracy: 0.1043
on_train_batch_begin: 1609170052.003131s

42 step training time: 0.166931s

on_train_batch_end: 1609170052.171125s

22016/50000 [============>.................] - ETA: 9s - loss: 1.5187 - accuracy: 0.1043
on_train_batch_begin: 1609170052.171516s

43 step training time: 0.168385s

on_train_batch_end: 1609170052.339092s

22528/50000 [============>.................] - ETA: 8s - loss: 1.5168 - accuracy: 0.1042
on_train_batch_begin: 1609170052.339480s

44 step training time: 0.167964s

on_train_batch_end: 1609170052.504817s

23040/50000 [============>.................] - ETA: 8s - loss: 1.5127 - accuracy: 0.1042
on_train_batch_begin: 1609170052.505215s

45 step training time: 0.165735s

on_train_batch_end: 1609170052.671660s

23552/50000 [=============>................] - ETA: 8s - loss: 1.5095 - accuracy: 0.1042
on_train_batch_begin: 1609170052.672036s

46 step training time: 0.166821s

on_train_batch_end: 1609170052.838608s

24064/50000 [=============>................] - ETA: 8s - loss: 1.5073 - accuracy: 0.1042
on_train_batch_begin: 1609170052.838997s

47 step training time: 0.166960s

on_train_batch_end: 1609170053.006232s

24576/50000 [=============>................] - ETA: 8s - loss: 1.5055 - accuracy: 0.1043
on_train_batch_begin: 1609170053.006607s

48 step training time: 0.167610s

on_train_batch_end: 1609170053.172252s

25088/50000 [==============>...............] - ETA: 8s - loss: 1.5055 - accuracy: 0.1042
on_train_batch_begin: 1609170053.172645s

49 step training time: 0.166038s

on_train_batch_end: 1609170053.338960s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.5030 - accuracy: 0.1042
on_train_batch_begin: 1609170053.339341s

50 step training time: 0.166697s

on_train_batch_end: 1609170053.507166s

26112/50000 [==============>...............] - ETA: 7s - loss: 1.5038 - accuracy: 0.1042
on_train_batch_begin: 1609170053.507543s

51 step training time: 0.168201s

on_train_batch_end: 1609170053.674482s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.5044 - accuracy: 0.1042
on_train_batch_begin: 1609170053.674866s

52 step training time: 0.167323s

on_train_batch_end: 1609170053.841804s

27136/50000 [===============>..............] - ETA: 7s - loss: 1.5053 - accuracy: 0.1042
on_train_batch_begin: 1609170053.842184s

53 step training time: 0.167318s

on_train_batch_end: 1609170054.009251s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.5036 - accuracy: 0.1042
on_train_batch_begin: 1609170054.009653s

54 step training time: 0.167470s

on_train_batch_end: 1609170054.176454s

28160/50000 [===============>..............] - ETA: 7s - loss: 1.5054 - accuracy: 0.1042
on_train_batch_begin: 1609170054.176831s

55 step training time: 0.167178s

on_train_batch_end: 1609170054.343374s

28672/50000 [================>.............] - ETA: 6s - loss: 1.5045 - accuracy: 0.1042
on_train_batch_begin: 1609170054.343748s

56 step training time: 0.166917s

on_train_batch_end: 1609170054.509781s

29184/50000 [================>.............] - ETA: 6s - loss: 1.5052 - accuracy: 0.1042
on_train_batch_begin: 1609170054.510162s

57 step training time: 0.166414s

on_train_batch_end: 1609170054.677258s

29696/50000 [================>.............] - ETA: 6s - loss: 1.5066 - accuracy: 0.1042
on_train_batch_begin: 1609170054.677666s

58 step training time: 0.167504s

on_train_batch_end: 1609170054.843247s

30208/50000 [=================>............] - ETA: 6s - loss: 1.5031 - accuracy: 0.1042
on_train_batch_begin: 1609170054.843633s

59 step training time: 0.165967s

on_train_batch_end: 1609170055.010240s

30720/50000 [=================>............] - ETA: 6s - loss: 1.5055 - accuracy: 0.1042
on_train_batch_begin: 1609170055.010613s

60 step training time: 0.166981s

on_train_batch_end: 1609170055.176893s

31232/50000 [=================>............] - ETA: 6s - loss: 1.5057 - accuracy: 0.1042
on_train_batch_begin: 1609170055.177289s

61 step training time: 0.166676s

on_train_batch_end: 1609170055.343509s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.5053 - accuracy: 0.1042
on_train_batch_begin: 1609170055.343891s

62 step training time: 0.166602s

on_train_batch_end: 1609170055.510848s

32256/50000 [==================>...........] - ETA: 5s - loss: 1.5009 - accuracy: 0.1042
on_train_batch_begin: 1609170055.511231s

63 step training time: 0.167340s

on_train_batch_end: 1609170055.676963s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.5005 - accuracy: 0.1042
on_train_batch_begin: 1609170055.677421s

64 step training time: 0.166189s

on_train_batch_end: 1609170055.844322s

33280/50000 [==================>...........] - ETA: 5s - loss: 1.4991 - accuracy: 0.1042
on_train_batch_begin: 1609170055.844708s

65 step training time: 0.167288s

on_train_batch_end: 1609170056.011144s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.4999 - accuracy: 0.1042
on_train_batch_begin: 1609170056.011519s

66 step training time: 0.166811s

on_train_batch_end: 1609170056.178757s

34304/50000 [===================>..........] - ETA: 5s - loss: 1.5004 - accuracy: 0.1042
on_train_batch_begin: 1609170056.179133s

67 step training time: 0.167614s

on_train_batch_end: 1609170056.345247s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.4988 - accuracy: 0.1042
on_train_batch_begin: 1609170056.345661s

68 step training time: 0.166528s

on_train_batch_end: 1609170056.511753s

35328/50000 [====================>.........] - ETA: 4s - loss: 1.4974 - accuracy: 0.1042
on_train_batch_begin: 1609170056.512139s

69 step training time: 0.166478s

on_train_batch_end: 1609170056.678027s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.4980 - accuracy: 0.1042
on_train_batch_begin: 1609170056.678397s

70 step training time: 0.166258s

on_train_batch_end: 1609170056.844259s

36352/50000 [====================>.........] - ETA: 4s - loss: 1.4948 - accuracy: 0.1042
on_train_batch_begin: 1609170056.844646s

71 step training time: 0.166250s

on_train_batch_end: 1609170057.012190s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.4940 - accuracy: 0.1042
on_train_batch_begin: 1609170057.012573s

72 step training time: 0.167927s

on_train_batch_end: 1609170057.180106s

37376/50000 [=====================>........] - ETA: 4s - loss: 1.4926 - accuracy: 0.1042
on_train_batch_begin: 1609170057.180492s

73 step training time: 0.167919s

on_train_batch_end: 1609170057.349046s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.4904 - accuracy: 0.1042
on_train_batch_begin: 1609170057.349456s

74 step training time: 0.168964s

on_train_batch_end: 1609170057.515497s

38400/50000 [======================>.......] - ETA: 3s - loss: 1.4921 - accuracy: 0.1042
on_train_batch_begin: 1609170057.515886s

75 step training time: 0.166429s

on_train_batch_end: 1609170057.683230s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.4882 - accuracy: 0.1043
on_train_batch_begin: 1609170057.683614s

76 step training time: 0.167728s

on_train_batch_end: 1609170057.849569s

39424/50000 [======================>.......] - ETA: 3s - loss: 1.4872 - accuracy: 0.1043
on_train_batch_begin: 1609170057.849955s

77 step training time: 0.166341s

on_train_batch_end: 1609170058.016645s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.4861 - accuracy: 0.1043
on_train_batch_begin: 1609170058.017036s

78 step training time: 0.167081s

on_train_batch_end: 1609170058.184120s

40448/50000 [=======================>......] - ETA: 3s - loss: 1.4850 - accuracy: 0.1043
on_train_batch_begin: 1609170058.184495s

79 step training time: 0.167459s

on_train_batch_end: 1609170058.351288s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.4821 - accuracy: 0.1043
on_train_batch_begin: 1609170058.351667s

80 step training time: 0.167171s

on_train_batch_end: 1609170058.517958s

41472/50000 [=======================>......] - ETA: 2s - loss: 1.4803 - accuracy: 0.1043
on_train_batch_begin: 1609170058.518343s

81 step training time: 0.166676s

on_train_batch_end: 1609170058.685723s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.4786 - accuracy: 0.1043
on_train_batch_begin: 1609170058.686100s

82 step training time: 0.167758s

on_train_batch_end: 1609170058.852170s

42496/50000 [========================>.....] - ETA: 2s - loss: 1.4793 - accuracy: 0.1043
on_train_batch_begin: 1609170058.852552s

83 step training time: 0.166452s

on_train_batch_end: 1609170059.022361s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.4773 - accuracy: 0.1043
on_train_batch_begin: 1609170059.022739s

84 step training time: 0.170187s

on_train_batch_end: 1609170059.187857s

43520/50000 [=========================>....] - ETA: 2s - loss: 1.4753 - accuracy: 0.1043
on_train_batch_begin: 1609170059.188245s

85 step training time: 0.165506s

on_train_batch_end: 1609170059.355295s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.4729 - accuracy: 0.1043
on_train_batch_begin: 1609170059.355675s

86 step training time: 0.167430s

on_train_batch_end: 1609170059.522854s

44544/50000 [=========================>....] - ETA: 1s - loss: 1.4697 - accuracy: 0.1043
on_train_batch_begin: 1609170059.523241s

87 step training time: 0.167566s

on_train_batch_end: 1609170059.688707s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.4696 - accuracy: 0.1043
on_train_batch_begin: 1609170059.689085s

88 step training time: 0.165844s

on_train_batch_end: 1609170059.855669s

45568/50000 [==========================>...] - ETA: 1s - loss: 1.4690 - accuracy: 0.1043
on_train_batch_begin: 1609170059.856056s

89 step training time: 0.166971s

on_train_batch_end: 1609170060.023196s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.4697 - accuracy: 0.1042
on_train_batch_begin: 1609170060.023583s

90 step training time: 0.167527s

on_train_batch_end: 1609170060.191057s

46592/50000 [==========================>...] - ETA: 1s - loss: 1.4647 - accuracy: 0.1042
on_train_batch_begin: 1609170060.191452s

91 step training time: 0.167868s

on_train_batch_end: 1609170060.358049s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.4621 - accuracy: 0.1042
on_train_batch_begin: 1609170060.358440s

92 step training time: 0.166988s

on_train_batch_end: 1609170060.524975s

47616/50000 [===========================>..] - ETA: 0s - loss: 1.4592 - accuracy: 0.1043
on_train_batch_begin: 1609170060.525389s

93 step training time: 0.166949s

on_train_batch_end: 1609170060.694305s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.4584 - accuracy: 0.1042
on_train_batch_begin: 1609170060.694695s

94 step training time: 0.169306s

on_train_batch_end: 1609170060.860241s

48640/50000 [============================>.] - ETA: 0s - loss: 1.4566 - accuracy: 0.1043
on_train_batch_begin: 1609170060.860617s

95 step training time: 0.165922s

on_train_batch_end: 1609170061.027580s

49152/50000 [============================>.] - ETA: 0s - loss: 1.4576 - accuracy: 0.1042
on_train_batch_begin: 1609170061.027993s

96 step training time: 0.167376s

on_train_batch_end: 1609170061.194454s

49664/50000 [============================>.] - ETA: 0s - loss: 1.4576 - accuracy: 0.1042
on_train_batch_begin: 1609170061.194844s

97 step training time: 0.166851s

on_train_batch_end: 1609170061.347363s

on_test_batch_begin: 1609170061.378716s

98 step training time: 0.183872s

on_epoch_end: 1609170062.115377s

Validation time: 0.736647s

Real time: 1609170062.115377s

Epoch time: 17.131722927093506s

50000/50000 [==============================] - 17s 343us/sample - loss: 1.4577 - accuracy: 0.1043 - val_loss: 7.2969 - val_accuracy: 0.0999

on_epoch_begin: 1609170062.115627s

Real time: 1609170062.115637
Epoch 4/5

on_train_batch_begin: 1609170062.123601s

on_train_batch_end: 1609170062.292984s

  512/50000 [..............................] - ETA: 17s - loss: 1.0390 - accuracy: 0.1056
on_train_batch_begin: 1609170062.293402s

1 step training time: 0.169801s

on_train_batch_end: 1609170062.460578s

 1024/50000 [..............................] - ETA: 16s - loss: 1.1220 - accuracy: 0.1044
on_train_batch_begin: 1609170062.460953s

2 step training time: 0.167551s

on_train_batch_end: 1609170062.627614s

 1536/50000 [..............................] - ETA: 16s - loss: 1.1953 - accuracy: 0.1048
on_train_batch_begin: 1609170062.627999s

3 step training time: 0.167046s

on_train_batch_end: 1609170062.796142s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.2064 - accuracy: 0.1047
on_train_batch_begin: 1609170062.796707s

4 step training time: 0.168708s

on_train_batch_end: 1609170062.964794s

 2560/50000 [>.............................] - ETA: 15s - loss: 1.1990 - accuracy: 0.1047
on_train_batch_begin: 1609170062.965178s

5 step training time: 0.168470s

on_train_batch_end: 1609170063.131095s

 3072/50000 [>.............................] - ETA: 15s - loss: 1.1691 - accuracy: 0.1045
on_train_batch_begin: 1609170063.131481s

6 step training time: 0.166304s

on_train_batch_end: 1609170063.299152s

 3584/50000 [=>............................] - ETA: 15s - loss: 1.1606 - accuracy: 0.1048
on_train_batch_begin: 1609170063.299542s

7 step training time: 0.168061s

on_train_batch_end: 1609170063.465754s

 4096/50000 [=>............................] - ETA: 15s - loss: 1.1602 - accuracy: 0.1047
on_train_batch_begin: 1609170063.466137s

8 step training time: 0.166595s

on_train_batch_end: 1609170063.632948s

 4608/50000 [=>............................] - ETA: 14s - loss: 1.1684 - accuracy: 0.1046
on_train_batch_begin: 1609170063.633359s

9 step training time: 0.167222s

on_train_batch_end: 1609170063.800326s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.1755 - accuracy: 0.1049
on_train_batch_begin: 1609170063.800702s

10 step training time: 0.167343s

on_train_batch_end: 1609170063.967291s

 5632/50000 [==>...........................] - ETA: 14s - loss: 1.1485 - accuracy: 0.1051
on_train_batch_begin: 1609170063.967666s

11 step training time: 0.166964s

on_train_batch_end: 1609170064.134488s

 6144/50000 [==>...........................] - ETA: 14s - loss: 1.1579 - accuracy: 0.1051
on_train_batch_begin: 1609170064.134875s

12 step training time: 0.167208s

on_train_batch_end: 1609170064.301101s

 6656/50000 [==>...........................] - ETA: 14s - loss: 1.1541 - accuracy: 0.1049
on_train_batch_begin: 1609170064.301514s

13 step training time: 0.166640s

on_train_batch_end: 1609170064.467558s

 7168/50000 [===>..........................] - ETA: 14s - loss: 1.1656 - accuracy: 0.1049
on_train_batch_begin: 1609170064.467947s

14 step training time: 0.166433s

on_train_batch_end: 1609170064.634616s

 7680/50000 [===>..........................] - ETA: 13s - loss: 1.1636 - accuracy: 0.1050
on_train_batch_begin: 1609170064.635009s

15 step training time: 0.167062s

on_train_batch_end: 1609170064.802573s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.1646 - accuracy: 0.1049
on_train_batch_begin: 1609170064.802955s

16 step training time: 0.167946s

on_train_batch_end: 1609170064.968937s

 8704/50000 [====>.........................] - ETA: 13s - loss: 1.1652 - accuracy: 0.1049
on_train_batch_begin: 1609170064.969340s

17 step training time: 0.166385s

on_train_batch_end: 1609170065.136604s

 9216/50000 [====>.........................] - ETA: 13s - loss: 1.1602 - accuracy: 0.1050
on_train_batch_begin: 1609170065.136988s

18 step training time: 0.167648s

on_train_batch_end: 1609170065.303170s

 9728/50000 [====>.........................] - ETA: 13s - loss: 1.1650 - accuracy: 0.1050
on_train_batch_begin: 1609170065.303547s

19 step training time: 0.166559s

on_train_batch_end: 1609170065.469413s

10240/50000 [=====>........................] - ETA: 13s - loss: 1.1608 - accuracy: 0.1051
on_train_batch_begin: 1609170065.469798s

20 step training time: 0.166251s

on_train_batch_end: 1609170065.636832s

10752/50000 [=====>........................] - ETA: 12s - loss: 1.1618 - accuracy: 0.1051
on_train_batch_begin: 1609170065.637234s

21 step training time: 0.167436s

on_train_batch_end: 1609170065.804218s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.1737 - accuracy: 0.1050
on_train_batch_begin: 1609170065.804612s

22 step training time: 0.167378s

on_train_batch_end: 1609170065.970982s

11776/50000 [======>.......................] - ETA: 12s - loss: 1.1738 - accuracy: 0.1051
on_train_batch_begin: 1609170065.971373s

23 step training time: 0.166760s

on_train_batch_end: 1609170066.137661s

12288/50000 [======>.......................] - ETA: 12s - loss: 1.1736 - accuracy: 0.1050
on_train_batch_begin: 1609170066.138056s

24 step training time: 0.166683s

on_train_batch_end: 1609170066.304319s

12800/50000 [======>.......................] - ETA: 12s - loss: 1.1746 - accuracy: 0.1049
on_train_batch_begin: 1609170066.304702s

25 step training time: 0.166646s

on_train_batch_end: 1609170066.471153s

13312/50000 [======>.......................] - ETA: 12s - loss: 1.1803 - accuracy: 0.1049
on_train_batch_begin: 1609170066.471524s

26 step training time: 0.166822s

on_train_batch_end: 1609170066.639067s

13824/50000 [=======>......................] - ETA: 11s - loss: 1.1814 - accuracy: 0.1049
on_train_batch_begin: 1609170066.639461s

27 step training time: 0.167936s

on_train_batch_end: 1609170066.806405s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.1798 - accuracy: 0.1049
on_train_batch_begin: 1609170066.806784s

28 step training time: 0.167323s

on_train_batch_end: 1609170066.973526s

14848/50000 [=======>......................] - ETA: 11s - loss: 1.1795 - accuracy: 0.1049
on_train_batch_begin: 1609170066.973912s

29 step training time: 0.167128s

on_train_batch_end: 1609170067.141046s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.1834 - accuracy: 0.1050
on_train_batch_begin: 1609170067.141455s

30 step training time: 0.167543s

on_train_batch_end: 1609170067.307276s

15872/50000 [========>.....................] - ETA: 11s - loss: 1.1840 - accuracy: 0.1050
on_train_batch_begin: 1609170067.307660s

31 step training time: 0.166205s

on_train_batch_end: 1609170067.474882s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.1853 - accuracy: 0.1050
on_train_batch_begin: 1609170067.475256s

32 step training time: 0.167596s

on_train_batch_end: 1609170067.640692s

16896/50000 [=========>....................] - ETA: 10s - loss: 1.1855 - accuracy: 0.1050
on_train_batch_begin: 1609170067.641087s

33 step training time: 0.165831s

on_train_batch_end: 1609170067.807917s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.1803 - accuracy: 0.1051
on_train_batch_begin: 1609170067.808299s

34 step training time: 0.167212s

on_train_batch_end: 1609170067.976087s

17920/50000 [=========>....................] - ETA: 10s - loss: 1.1832 - accuracy: 0.1051
on_train_batch_begin: 1609170067.976463s

35 step training time: 0.168164s

on_train_batch_end: 1609170068.142441s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.1798 - accuracy: 0.1051
on_train_batch_begin: 1609170068.142814s

36 step training time: 0.166351s

on_train_batch_end: 1609170068.309246s

18944/50000 [==========>...................] - ETA: 10s - loss: 1.1813 - accuracy: 0.1051
on_train_batch_begin: 1609170068.309648s

37 step training time: 0.166834s

on_train_batch_end: 1609170068.475276s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.1821 - accuracy: 0.1051 
on_train_batch_begin: 1609170068.475660s

38 step training time: 0.166012s

on_train_batch_end: 1609170068.641075s

19968/50000 [==========>...................] - ETA: 9s - loss: 1.1835 - accuracy: 0.1051
on_train_batch_begin: 1609170068.641481s

39 step training time: 0.165822s

on_train_batch_end: 1609170068.806493s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.1845 - accuracy: 0.1050
on_train_batch_begin: 1609170068.806866s

40 step training time: 0.165385s

on_train_batch_end: 1609170068.973353s

20992/50000 [===========>..................] - ETA: 9s - loss: 1.1828 - accuracy: 0.1050
on_train_batch_begin: 1609170068.973724s

41 step training time: 0.166858s

on_train_batch_end: 1609170069.139877s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.1825 - accuracy: 0.1050
on_train_batch_begin: 1609170069.140254s

42 step training time: 0.166530s

on_train_batch_end: 1609170069.305877s

22016/50000 [============>.................] - ETA: 9s - loss: 1.1806 - accuracy: 0.1049
on_train_batch_begin: 1609170069.306251s

43 step training time: 0.165998s

on_train_batch_end: 1609170069.473077s

22528/50000 [============>.................] - ETA: 8s - loss: 1.1807 - accuracy: 0.1049
on_train_batch_begin: 1609170069.473483s

44 step training time: 0.167232s

on_train_batch_end: 1609170069.640021s

23040/50000 [============>.................] - ETA: 8s - loss: 1.1788 - accuracy: 0.1050
on_train_batch_begin: 1609170069.640414s

45 step training time: 0.166930s

on_train_batch_end: 1609170069.807379s

23552/50000 [=============>................] - ETA: 8s - loss: 1.1759 - accuracy: 0.1050
on_train_batch_begin: 1609170069.807762s

46 step training time: 0.167348s

on_train_batch_end: 1609170069.974465s

24064/50000 [=============>................] - ETA: 8s - loss: 1.1746 - accuracy: 0.1049
on_train_batch_begin: 1609170069.974858s

47 step training time: 0.167096s

on_train_batch_end: 1609170070.142205s

24576/50000 [=============>................] - ETA: 8s - loss: 1.1723 - accuracy: 0.1050
on_train_batch_begin: 1609170070.142597s

48 step training time: 0.167739s

on_train_batch_end: 1609170070.309856s

25088/50000 [==============>...............] - ETA: 8s - loss: 1.1708 - accuracy: 0.1050
on_train_batch_begin: 1609170070.310252s

49 step training time: 0.167655s

on_train_batch_end: 1609170070.476908s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.1682 - accuracy: 0.1050
on_train_batch_begin: 1609170070.477325s

50 step training time: 0.167073s

on_train_batch_end: 1609170070.643923s

26112/50000 [==============>...............] - ETA: 7s - loss: 1.1684 - accuracy: 0.1049
on_train_batch_begin: 1609170070.644314s

51 step training time: 0.166989s

on_train_batch_end: 1609170070.811462s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.1679 - accuracy: 0.1049
on_train_batch_begin: 1609170070.811861s

52 step training time: 0.167547s

on_train_batch_end: 1609170070.978367s

27136/50000 [===============>..............] - ETA: 7s - loss: 1.1695 - accuracy: 0.1049
on_train_batch_begin: 1609170070.978757s

53 step training time: 0.166896s

on_train_batch_end: 1609170071.146677s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.1684 - accuracy: 0.1050
on_train_batch_begin: 1609170071.147066s

54 step training time: 0.168309s

on_train_batch_end: 1609170071.313775s

28160/50000 [===============>..............] - ETA: 7s - loss: 1.1651 - accuracy: 0.1050
on_train_batch_begin: 1609170071.314165s

55 step training time: 0.167099s

on_train_batch_end: 1609170071.480929s

28672/50000 [================>.............] - ETA: 6s - loss: 1.1635 - accuracy: 0.1050
on_train_batch_begin: 1609170071.481339s

56 step training time: 0.167174s

on_train_batch_end: 1609170071.649255s

29184/50000 [================>.............] - ETA: 6s - loss: 1.1595 - accuracy: 0.1050
on_train_batch_begin: 1609170071.649670s

57 step training time: 0.168331s

on_train_batch_end: 1609170071.816024s

29696/50000 [================>.............] - ETA: 6s - loss: 1.1575 - accuracy: 0.1050
on_train_batch_begin: 1609170071.816410s

58 step training time: 0.166740s

on_train_batch_end: 1609170071.983139s

30208/50000 [=================>............] - ETA: 6s - loss: 1.1569 - accuracy: 0.1050
on_train_batch_begin: 1609170071.983531s

59 step training time: 0.167121s

on_train_batch_end: 1609170072.150377s

30720/50000 [=================>............] - ETA: 6s - loss: 1.1558 - accuracy: 0.1050
on_train_batch_begin: 1609170072.150770s

60 step training time: 0.167238s

on_train_batch_end: 1609170072.317719s

31232/50000 [=================>............] - ETA: 6s - loss: 1.1552 - accuracy: 0.1050
on_train_batch_begin: 1609170072.318166s

61 step training time: 0.167397s

on_train_batch_end: 1609170072.485474s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.1554 - accuracy: 0.1050
on_train_batch_begin: 1609170072.485863s

62 step training time: 0.167697s

on_train_batch_end: 1609170072.652740s

32256/50000 [==================>...........] - ETA: 5s - loss: 1.1525 - accuracy: 0.1051
on_train_batch_begin: 1609170072.653115s

63 step training time: 0.167251s

on_train_batch_end: 1609170072.820049s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.1505 - accuracy: 0.1051
on_train_batch_begin: 1609170072.820438s

64 step training time: 0.167323s

on_train_batch_end: 1609170072.987488s

33280/50000 [==================>...........] - ETA: 5s - loss: 1.1490 - accuracy: 0.1051
on_train_batch_begin: 1609170072.987870s

65 step training time: 0.167432s

on_train_batch_end: 1609170073.154171s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.1479 - accuracy: 0.1051
on_train_batch_begin: 1609170073.154556s

66 step training time: 0.166686s

on_train_batch_end: 1609170073.320999s

34304/50000 [===================>..........] - ETA: 5s - loss: 1.1439 - accuracy: 0.1052
on_train_batch_begin: 1609170073.321409s

67 step training time: 0.166854s

on_train_batch_end: 1609170073.488194s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.1428 - accuracy: 0.1052
on_train_batch_begin: 1609170073.488581s

68 step training time: 0.167172s

on_train_batch_end: 1609170073.655644s

35328/50000 [====================>.........] - ETA: 4s - loss: 1.1389 - accuracy: 0.1051
on_train_batch_begin: 1609170073.656020s

69 step training time: 0.167439s

on_train_batch_end: 1609170073.823702s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.1371 - accuracy: 0.1051
on_train_batch_begin: 1609170073.824076s

70 step training time: 0.168056s

on_train_batch_end: 1609170073.989880s

36352/50000 [====================>.........] - ETA: 4s - loss: 1.1357 - accuracy: 0.1052
on_train_batch_begin: 1609170073.990258s

71 step training time: 0.166183s

on_train_batch_end: 1609170074.157204s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.1355 - accuracy: 0.1052
on_train_batch_begin: 1609170074.157612s

72 step training time: 0.167353s

on_train_batch_end: 1609170074.324703s

37376/50000 [=====================>........] - ETA: 4s - loss: 1.1337 - accuracy: 0.1052
on_train_batch_begin: 1609170074.325089s

73 step training time: 0.167477s

on_train_batch_end: 1609170074.491949s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.1309 - accuracy: 0.1052
on_train_batch_begin: 1609170074.492332s

74 step training time: 0.167243s

on_train_batch_end: 1609170074.658764s

38400/50000 [======================>.......] - ETA: 3s - loss: 1.1322 - accuracy: 0.1052
on_train_batch_begin: 1609170074.659145s

75 step training time: 0.166813s

on_train_batch_end: 1609170074.826001s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.1324 - accuracy: 0.1052
on_train_batch_begin: 1609170074.826376s

76 step training time: 0.167231s

on_train_batch_end: 1609170074.993328s

39424/50000 [======================>.......] - ETA: 3s - loss: 1.1315 - accuracy: 0.1052
on_train_batch_begin: 1609170074.993709s

77 step training time: 0.167333s

on_train_batch_end: 1609170075.160679s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.1301 - accuracy: 0.1052
on_train_batch_begin: 1609170075.161059s

78 step training time: 0.167350s

on_train_batch_end: 1609170075.326707s

40448/50000 [=======================>......] - ETA: 3s - loss: 1.1321 - accuracy: 0.1052
on_train_batch_begin: 1609170075.327094s

79 step training time: 0.166035s

on_train_batch_end: 1609170075.493255s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.1302 - accuracy: 0.1052
on_train_batch_begin: 1609170075.493665s

80 step training time: 0.166571s

on_train_batch_end: 1609170075.662374s

41472/50000 [=======================>......] - ETA: 2s - loss: 1.1293 - accuracy: 0.1052
on_train_batch_begin: 1609170075.662750s

81 step training time: 0.169086s

on_train_batch_end: 1609170075.828443s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.1289 - accuracy: 0.1052
on_train_batch_begin: 1609170075.828823s

82 step training time: 0.166073s

on_train_batch_end: 1609170075.994766s

42496/50000 [========================>.....] - ETA: 2s - loss: 1.1264 - accuracy: 0.1052
on_train_batch_begin: 1609170075.995154s

83 step training time: 0.166332s

on_train_batch_end: 1609170076.161116s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.1257 - accuracy: 0.1052
on_train_batch_begin: 1609170076.161535s

84 step training time: 0.166381s

on_train_batch_end: 1609170076.328160s

43520/50000 [=========================>....] - ETA: 2s - loss: 1.1235 - accuracy: 0.1052
on_train_batch_begin: 1609170076.328535s

85 step training time: 0.167000s

on_train_batch_end: 1609170076.495549s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.1256 - accuracy: 0.1052
on_train_batch_begin: 1609170076.495930s

86 step training time: 0.167395s

on_train_batch_end: 1609170076.663410s

44544/50000 [=========================>....] - ETA: 1s - loss: 1.1227 - accuracy: 0.1052
on_train_batch_begin: 1609170076.663787s

87 step training time: 0.167856s

on_train_batch_end: 1609170076.829629s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.1217 - accuracy: 0.1052
on_train_batch_begin: 1609170076.830012s

88 step training time: 0.166225s

on_train_batch_end: 1609170076.996479s

45568/50000 [==========================>...] - ETA: 1s - loss: 1.1197 - accuracy: 0.1052
on_train_batch_begin: 1609170076.996883s

89 step training time: 0.166872s

on_train_batch_end: 1609170077.163329s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.1193 - accuracy: 0.1052
on_train_batch_begin: 1609170077.163706s

90 step training time: 0.166822s

on_train_batch_end: 1609170077.330606s

46592/50000 [==========================>...] - ETA: 1s - loss: 1.1179 - accuracy: 0.1052
on_train_batch_begin: 1609170077.330988s

91 step training time: 0.167282s

on_train_batch_end: 1609170077.499022s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.1165 - accuracy: 0.1052
on_train_batch_begin: 1609170077.499402s

92 step training time: 0.168414s

on_train_batch_end: 1609170077.665740s

47616/50000 [===========================>..] - ETA: 0s - loss: 1.1146 - accuracy: 0.1052
on_train_batch_begin: 1609170077.666122s

93 step training time: 0.166720s

on_train_batch_end: 1609170077.832514s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.1118 - accuracy: 0.1053
on_train_batch_begin: 1609170077.832892s

94 step training time: 0.166771s

on_train_batch_end: 1609170078.000645s

48640/50000 [============================>.] - ETA: 0s - loss: 1.1108 - accuracy: 0.1053
on_train_batch_begin: 1609170078.001023s

95 step training time: 0.168131s

on_train_batch_end: 1609170078.167880s

49152/50000 [============================>.] - ETA: 0s - loss: 1.1095 - accuracy: 0.1053
on_train_batch_begin: 1609170078.168254s

96 step training time: 0.167231s

on_train_batch_end: 1609170078.335298s

49664/50000 [============================>.] - ETA: 0s - loss: 1.1081 - accuracy: 0.1053
on_train_batch_begin: 1609170078.335697s

97 step training time: 0.167443s

on_train_batch_end: 1609170078.489062s

on_test_batch_begin: 1609170078.523586s

98 step training time: 0.187889s

on_epoch_end: 1609170079.252944s

Validation time: 0.729343s

Real time: 1609170079.252944s

Epoch time: 17.137327909469604s

50000/50000 [==============================] - 17s 343us/sample - loss: 1.1085 - accuracy: 0.1053 - val_loss: 6.8932 - val_accuracy: 0.1001

on_epoch_begin: 1609170079.253193s

Real time: 1609170079.2532024
Epoch 5/5

on_train_batch_begin: 1609170079.260871s

on_train_batch_end: 1609170079.428734s

  512/50000 [..............................] - ETA: 16s - loss: 0.9023 - accuracy: 0.1035
on_train_batch_begin: 1609170079.429119s

1 step training time: 0.168248s

on_train_batch_end: 1609170079.595997s

 1024/50000 [..............................] - ETA: 16s - loss: 0.9304 - accuracy: 0.1042
on_train_batch_begin: 1609170079.596371s

2 step training time: 0.167252s

on_train_batch_end: 1609170079.762520s

 1536/50000 [..............................] - ETA: 16s - loss: 0.9088 - accuracy: 0.1047
on_train_batch_begin: 1609170079.762908s

3 step training time: 0.166537s

on_train_batch_end: 1609170079.929131s

 2048/50000 [>.............................] - ETA: 15s - loss: 0.9066 - accuracy: 0.1052
on_train_batch_begin: 1609170079.929547s

4 step training time: 0.166640s

on_train_batch_end: 1609170080.096453s

 2560/50000 [>.............................] - ETA: 15s - loss: 0.8847 - accuracy: 0.1058
on_train_batch_begin: 1609170080.096841s

5 step training time: 0.167294s

on_train_batch_end: 1609170080.262708s

 3072/50000 [>.............................] - ETA: 15s - loss: 0.8693 - accuracy: 0.1055
on_train_batch_begin: 1609170080.263087s

6 step training time: 0.166246s

on_train_batch_end: 1609170080.429624s

 3584/50000 [=>............................] - ETA: 15s - loss: 0.8835 - accuracy: 0.1058
on_train_batch_begin: 1609170080.429996s

7 step training time: 0.166909s

on_train_batch_end: 1609170080.596454s

 4096/50000 [=>............................] - ETA: 15s - loss: 0.8926 - accuracy: 0.1058
on_train_batch_begin: 1609170080.596837s

8 step training time: 0.166841s

on_train_batch_end: 1609170080.763744s

 4608/50000 [=>............................] - ETA: 14s - loss: 0.8864 - accuracy: 0.1058
on_train_batch_begin: 1609170080.764114s

9 step training time: 0.167277s

on_train_batch_end: 1609170080.930860s

 5120/50000 [==>...........................] - ETA: 14s - loss: 0.8860 - accuracy: 0.1060
on_train_batch_begin: 1609170080.931247s

10 step training time: 0.167134s

on_train_batch_end: 1609170081.099686s

 5632/50000 [==>...........................] - ETA: 14s - loss: 0.8967 - accuracy: 0.1059
on_train_batch_begin: 1609170081.100067s

11 step training time: 0.168820s

on_train_batch_end: 1609170081.267116s

 6144/50000 [==>...........................] - ETA: 14s - loss: 0.8838 - accuracy: 0.1061
on_train_batch_begin: 1609170081.267498s

12 step training time: 0.167431s

on_train_batch_end: 1609170081.433741s

 6656/50000 [==>...........................] - ETA: 14s - loss: 0.8897 - accuracy: 0.1061
on_train_batch_begin: 1609170081.434125s

13 step training time: 0.166627s

on_train_batch_end: 1609170081.599893s

 7168/50000 [===>..........................] - ETA: 14s - loss: 0.8856 - accuracy: 0.1064
on_train_batch_begin: 1609170081.600277s

14 step training time: 0.166152s

on_train_batch_end: 1609170081.766352s

 7680/50000 [===>..........................] - ETA: 13s - loss: 0.8816 - accuracy: 0.1063
on_train_batch_begin: 1609170081.766731s

15 step training time: 0.166454s

on_train_batch_end: 1609170081.933755s

 8192/50000 [===>..........................] - ETA: 13s - loss: 0.8639 - accuracy: 0.1063
on_train_batch_begin: 1609170081.934128s

16 step training time: 0.167397s

on_train_batch_end: 1609170082.100195s

 8704/50000 [====>.........................] - ETA: 13s - loss: 0.8601 - accuracy: 0.1062
on_train_batch_begin: 1609170082.100570s

17 step training time: 0.166443s

on_train_batch_end: 1609170082.267849s

 9216/50000 [====>.........................] - ETA: 13s - loss: 0.8609 - accuracy: 0.1062
on_train_batch_begin: 1609170082.268225s

18 step training time: 0.167655s

on_train_batch_end: 1609170082.435823s

 9728/50000 [====>.........................] - ETA: 13s - loss: 0.8625 - accuracy: 0.1061
on_train_batch_begin: 1609170082.436200s

19 step training time: 0.167975s

on_train_batch_end: 1609170082.602514s

10240/50000 [=====>........................] - ETA: 13s - loss: 0.8523 - accuracy: 0.1061
on_train_batch_begin: 1609170082.602893s

20 step training time: 0.166693s

on_train_batch_end: 1609170082.769616s

10752/50000 [=====>........................] - ETA: 12s - loss: 0.8597 - accuracy: 0.1061
on_train_batch_begin: 1609170082.769988s

21 step training time: 0.167095s

on_train_batch_end: 1609170082.937131s

11264/50000 [=====>........................] - ETA: 12s - loss: 0.8615 - accuracy: 0.1062
on_train_batch_begin: 1609170082.937533s

22 step training time: 0.167545s

on_train_batch_end: 1609170083.104344s

11776/50000 [======>.......................] - ETA: 12s - loss: 0.8592 - accuracy: 0.1062
on_train_batch_begin: 1609170083.104731s

23 step training time: 0.167199s

on_train_batch_end: 1609170083.272002s

12288/50000 [======>.......................] - ETA: 12s - loss: 0.8659 - accuracy: 0.1062
on_train_batch_begin: 1609170083.272387s

24 step training time: 0.167656s

on_train_batch_end: 1609170083.438417s

12800/50000 [======>.......................] - ETA: 12s - loss: 0.8628 - accuracy: 0.1061
on_train_batch_begin: 1609170083.438804s

25 step training time: 0.166417s

on_train_batch_end: 1609170083.604960s

13312/50000 [======>.......................] - ETA: 11s - loss: 0.8577 - accuracy: 0.1062
on_train_batch_begin: 1609170083.605373s

26 step training time: 0.166568s

on_train_batch_end: 1609170083.772811s

13824/50000 [=======>......................] - ETA: 11s - loss: 0.8548 - accuracy: 0.1062
on_train_batch_begin: 1609170083.773186s

27 step training time: 0.167814s

on_train_batch_end: 1609170083.939835s

14336/50000 [=======>......................] - ETA: 11s - loss: 0.8511 - accuracy: 0.1063
on_train_batch_begin: 1609170083.940215s

28 step training time: 0.167028s

on_train_batch_end: 1609170084.107581s

14848/50000 [=======>......................] - ETA: 11s - loss: 0.8485 - accuracy: 0.1063
on_train_batch_begin: 1609170084.107964s

29 step training time: 0.167749s

on_train_batch_end: 1609170084.275569s

15360/50000 [========>.....................] - ETA: 11s - loss: 0.8494 - accuracy: 0.1063
on_train_batch_begin: 1609170084.275956s

30 step training time: 0.167993s

on_train_batch_end: 1609170084.442676s

15872/50000 [========>.....................] - ETA: 11s - loss: 0.8530 - accuracy: 0.1063
on_train_batch_begin: 1609170084.443058s

31 step training time: 0.167102s

on_train_batch_end: 1609170084.610241s

16384/50000 [========>.....................] - ETA: 10s - loss: 0.8498 - accuracy: 0.1063
on_train_batch_begin: 1609170084.610622s

32 step training time: 0.167564s

on_train_batch_end: 1609170084.777640s

16896/50000 [=========>....................] - ETA: 10s - loss: 0.8462 - accuracy: 0.1064
on_train_batch_begin: 1609170084.778014s

33 step training time: 0.167391s

on_train_batch_end: 1609170084.945016s

17408/50000 [=========>....................] - ETA: 10s - loss: 0.8465 - accuracy: 0.1064
on_train_batch_begin: 1609170084.945423s

34 step training time: 0.167410s

on_train_batch_end: 1609170085.111162s

17920/50000 [=========>....................] - ETA: 10s - loss: 0.8422 - accuracy: 0.1064
on_train_batch_begin: 1609170085.111537s

35 step training time: 0.166113s

on_train_batch_end: 1609170085.277394s

18432/50000 [==========>...................] - ETA: 10s - loss: 0.8372 - accuracy: 0.1064
on_train_batch_begin: 1609170085.277784s

36 step training time: 0.166247s

on_train_batch_end: 1609170085.445994s

18944/50000 [==========>...................] - ETA: 10s - loss: 0.8380 - accuracy: 0.1064
on_train_batch_begin: 1609170085.446375s

37 step training time: 0.168591s

on_train_batch_end: 1609170085.613416s

19456/50000 [==========>...................] - ETA: 9s - loss: 0.8402 - accuracy: 0.1064 
on_train_batch_begin: 1609170085.613787s

38 step training time: 0.167413s

on_train_batch_end: 1609170085.785028s

19968/50000 [==========>...................] - ETA: 9s - loss: 0.8395 - accuracy: 0.1064
on_train_batch_begin: 1609170085.785439s

39 step training time: 0.171652s

on_train_batch_end: 1609170085.951044s

20480/50000 [===========>..................] - ETA: 9s - loss: 0.8369 - accuracy: 0.1064
on_train_batch_begin: 1609170085.951425s

40 step training time: 0.165986s

on_train_batch_end: 1609170086.117102s

20992/50000 [===========>..................] - ETA: 9s - loss: 0.8381 - accuracy: 0.1065
on_train_batch_begin: 1609170086.117508s

41 step training time: 0.166084s

on_train_batch_end: 1609170086.283664s

21504/50000 [===========>..................] - ETA: 9s - loss: 0.8380 - accuracy: 0.1065
on_train_batch_begin: 1609170086.284044s

42 step training time: 0.166536s

on_train_batch_end: 1609170086.450586s

22016/50000 [============>.................] - ETA: 9s - loss: 0.8359 - accuracy: 0.1065
on_train_batch_begin: 1609170086.450965s

43 step training time: 0.166921s

on_train_batch_end: 1609170086.617247s

22528/50000 [============>.................] - ETA: 8s - loss: 0.8316 - accuracy: 0.1065
on_train_batch_begin: 1609170086.617652s

44 step training time: 0.166687s

on_train_batch_end: 1609170086.783424s

23040/50000 [============>.................] - ETA: 8s - loss: 0.8329 - accuracy: 0.1065
on_train_batch_begin: 1609170086.783799s

45 step training time: 0.166147s

on_train_batch_end: 1609170086.950516s

23552/50000 [=============>................] - ETA: 8s - loss: 0.8324 - accuracy: 0.1065
on_train_batch_begin: 1609170086.950894s

46 step training time: 0.167095s

on_train_batch_end: 1609170087.117868s

24064/50000 [=============>................] - ETA: 8s - loss: 0.8331 - accuracy: 0.1064
on_train_batch_begin: 1609170087.118245s

47 step training time: 0.167351s

on_train_batch_end: 1609170087.284593s

24576/50000 [=============>................] - ETA: 8s - loss: 0.8304 - accuracy: 0.1065
on_train_batch_begin: 1609170087.284988s

48 step training time: 0.166743s

on_train_batch_end: 1609170087.452603s

25088/50000 [==============>...............] - ETA: 8s - loss: 0.8317 - accuracy: 0.1065
on_train_batch_begin: 1609170087.452993s

49 step training time: 0.168005s

on_train_batch_end: 1609170087.619747s

25600/50000 [==============>...............] - ETA: 7s - loss: 0.8323 - accuracy: 0.1065
on_train_batch_begin: 1609170087.620142s

50 step training time: 0.167148s

on_train_batch_end: 1609170087.785878s

26112/50000 [==============>...............] - ETA: 7s - loss: 0.8297 - accuracy: 0.1065
on_train_batch_begin: 1609170087.786276s

51 step training time: 0.166135s

on_train_batch_end: 1609170087.952950s

26624/50000 [==============>...............] - ETA: 7s - loss: 0.8283 - accuracy: 0.1065
on_train_batch_begin: 1609170087.953370s

52 step training time: 0.167094s

on_train_batch_end: 1609170088.119981s

27136/50000 [===============>..............] - ETA: 7s - loss: 0.8257 - accuracy: 0.1065
on_train_batch_begin: 1609170088.120388s

53 step training time: 0.167018s

on_train_batch_end: 1609170088.288424s

27648/50000 [===============>..............] - ETA: 7s - loss: 0.8259 - accuracy: 0.1065
on_train_batch_begin: 1609170088.288822s

54 step training time: 0.168434s

on_train_batch_end: 1609170088.456259s

28160/50000 [===============>..............] - ETA: 7s - loss: 0.8256 - accuracy: 0.1065
on_train_batch_begin: 1609170088.456651s

55 step training time: 0.167830s

on_train_batch_end: 1609170088.622761s

28672/50000 [================>.............] - ETA: 6s - loss: 0.8274 - accuracy: 0.1065
on_train_batch_begin: 1609170088.623153s

56 step training time: 0.166502s

on_train_batch_end: 1609170088.791015s

29184/50000 [================>.............] - ETA: 6s - loss: 0.8263 - accuracy: 0.1065
on_train_batch_begin: 1609170088.791408s

57 step training time: 0.168254s

on_train_batch_end: 1609170088.959272s

29696/50000 [================>.............] - ETA: 6s - loss: 0.8247 - accuracy: 0.1065
on_train_batch_begin: 1609170088.959673s

58 step training time: 0.168265s

on_train_batch_end: 1609170089.126865s

30208/50000 [=================>............] - ETA: 6s - loss: 0.8266 - accuracy: 0.1065
on_train_batch_begin: 1609170089.127407s

59 step training time: 0.167734s

on_train_batch_end: 1609170089.295656s

30720/50000 [=================>............] - ETA: 6s - loss: 0.8277 - accuracy: 0.1065
on_train_batch_begin: 1609170089.296060s

60 step training time: 0.168653s

on_train_batch_end: 1609170089.462607s

31232/50000 [=================>............] - ETA: 6s - loss: 0.8261 - accuracy: 0.1066
on_train_batch_begin: 1609170089.463001s

61 step training time: 0.166940s

on_train_batch_end: 1609170089.628592s

31744/50000 [==================>...........] - ETA: 5s - loss: 0.8256 - accuracy: 0.1065
on_train_batch_begin: 1609170089.628982s

62 step training time: 0.165981s

on_train_batch_end: 1609170089.795789s

32256/50000 [==================>...........] - ETA: 5s - loss: 0.8264 - accuracy: 0.1065
on_train_batch_begin: 1609170089.796183s

63 step training time: 0.167202s

on_train_batch_end: 1609170089.963386s

32768/50000 [==================>...........] - ETA: 5s - loss: 0.8273 - accuracy: 0.1065
on_train_batch_begin: 1609170089.963785s

64 step training time: 0.167601s

on_train_batch_end: 1609170090.130030s

33280/50000 [==================>...........] - ETA: 5s - loss: 0.8271 - accuracy: 0.1065
on_train_batch_begin: 1609170090.130424s

65 step training time: 0.166640s

on_train_batch_end: 1609170090.311094s

33792/50000 [===================>..........] - ETA: 5s - loss: 0.8275 - accuracy: 0.1065
on_train_batch_begin: 1609170090.311488s

66 step training time: 0.181063s

on_train_batch_end: 1609170090.478939s

34304/50000 [===================>..........] - ETA: 5s - loss: 0.8275 - accuracy: 0.1065
on_train_batch_begin: 1609170090.479338s

67 step training time: 0.167850s

on_train_batch_end: 1609170090.644984s

34816/50000 [===================>..........] - ETA: 4s - loss: 0.8254 - accuracy: 0.1065
on_train_batch_begin: 1609170090.645421s

68 step training time: 0.166083s

on_train_batch_end: 1609170090.812473s

35328/50000 [====================>.........] - ETA: 4s - loss: 0.8276 - accuracy: 0.1065
on_train_batch_begin: 1609170090.812868s

69 step training time: 0.167446s

on_train_batch_end: 1609170090.978732s

35840/50000 [====================>.........] - ETA: 4s - loss: 0.8269 - accuracy: 0.1065
on_train_batch_begin: 1609170090.979123s

70 step training time: 0.166255s

on_train_batch_end: 1609170091.145333s

36352/50000 [====================>.........] - ETA: 4s - loss: 0.8265 - accuracy: 0.1065
on_train_batch_begin: 1609170091.145710s

71 step training time: 0.166586s

on_train_batch_end: 1609170091.312232s

36864/50000 [=====================>........] - ETA: 4s - loss: 0.8249 - accuracy: 0.1065
on_train_batch_begin: 1609170091.312619s

72 step training time: 0.166909s

on_train_batch_end: 1609170091.478715s

37376/50000 [=====================>........] - ETA: 4s - loss: 0.8228 - accuracy: 0.1065
on_train_batch_begin: 1609170091.479094s

73 step training time: 0.166475s

on_train_batch_end: 1609170091.645563s

37888/50000 [=====================>........] - ETA: 3s - loss: 0.8209 - accuracy: 0.1065
on_train_batch_begin: 1609170091.645945s

74 step training time: 0.166851s

on_train_batch_end: 1609170091.813044s

38400/50000 [======================>.......] - ETA: 3s - loss: 0.8198 - accuracy: 0.1065
on_train_batch_begin: 1609170091.813452s

75 step training time: 0.167507s

on_train_batch_end: 1609170091.978727s

38912/50000 [======================>.......] - ETA: 3s - loss: 0.8191 - accuracy: 0.1065
on_train_batch_begin: 1609170091.979104s

76 step training time: 0.165653s

on_train_batch_end: 1609170092.145442s

39424/50000 [======================>.......] - ETA: 3s - loss: 0.8192 - accuracy: 0.1065
on_train_batch_begin: 1609170092.145817s

77 step training time: 0.166713s

on_train_batch_end: 1609170092.312921s

39936/50000 [======================>.......] - ETA: 3s - loss: 0.8199 - accuracy: 0.1065
on_train_batch_begin: 1609170092.313321s

78 step training time: 0.167503s

on_train_batch_end: 1609170092.479107s

40448/50000 [=======================>......] - ETA: 3s - loss: 0.8183 - accuracy: 0.1066
on_train_batch_begin: 1609170092.479485s

79 step training time: 0.166164s

on_train_batch_end: 1609170092.645758s

40960/50000 [=======================>......] - ETA: 2s - loss: 0.8182 - accuracy: 0.1066
on_train_batch_begin: 1609170092.646142s

80 step training time: 0.166657s

on_train_batch_end: 1609170092.814045s

41472/50000 [=======================>......] - ETA: 2s - loss: 0.8176 - accuracy: 0.1066
on_train_batch_begin: 1609170092.814423s

81 step training time: 0.168281s

on_train_batch_end: 1609170092.979892s

41984/50000 [========================>.....] - ETA: 2s - loss: 0.8169 - accuracy: 0.1066
on_train_batch_begin: 1609170092.980271s

82 step training time: 0.165848s

on_train_batch_end: 1609170093.147263s

42496/50000 [========================>.....] - ETA: 2s - loss: 0.8157 - accuracy: 0.1066
on_train_batch_begin: 1609170093.147653s

83 step training time: 0.167382s

on_train_batch_end: 1609170093.314764s

43008/50000 [========================>.....] - ETA: 2s - loss: 0.8156 - accuracy: 0.1066
on_train_batch_begin: 1609170093.315148s

84 step training time: 0.167495s

on_train_batch_end: 1609170093.484423s

43520/50000 [=========================>....] - ETA: 2s - loss: 0.8163 - accuracy: 0.1066
on_train_batch_begin: 1609170093.484799s

85 step training time: 0.169651s

on_train_batch_end: 1609170093.651061s

44032/50000 [=========================>....] - ETA: 1s - loss: 0.8150 - accuracy: 0.1066
on_train_batch_begin: 1609170093.651439s

86 step training time: 0.166640s

on_train_batch_end: 1609170093.817376s

44544/50000 [=========================>....] - ETA: 1s - loss: 0.8155 - accuracy: 0.1066
on_train_batch_begin: 1609170093.817767s

87 step training time: 0.166328s

on_train_batch_end: 1609170093.984958s

45056/50000 [==========================>...] - ETA: 1s - loss: 0.8151 - accuracy: 0.1066
on_train_batch_begin: 1609170093.985384s

88 step training time: 0.167617s

on_train_batch_end: 1609170094.151335s

45568/50000 [==========================>...] - ETA: 1s - loss: 0.8140 - accuracy: 0.1066
on_train_batch_begin: 1609170094.151712s

89 step training time: 0.166327s

on_train_batch_end: 1609170094.319272s

46080/50000 [==========================>...] - ETA: 1s - loss: 0.8135 - accuracy: 0.1066
on_train_batch_begin: 1609170094.319649s

90 step training time: 0.167937s

on_train_batch_end: 1609170094.486027s

46592/50000 [==========================>...] - ETA: 1s - loss: 0.8129 - accuracy: 0.1066
on_train_batch_begin: 1609170094.486402s

91 step training time: 0.166753s

on_train_batch_end: 1609170094.652199s

47104/50000 [===========================>..] - ETA: 0s - loss: 0.8122 - accuracy: 0.1066
on_train_batch_begin: 1609170094.652578s

92 step training time: 0.166176s

on_train_batch_end: 1609170094.818454s

47616/50000 [===========================>..] - ETA: 0s - loss: 0.8119 - accuracy: 0.1066
on_train_batch_begin: 1609170094.818830s

93 step training time: 0.166252s

on_train_batch_end: 1609170094.985204s

48128/50000 [===========================>..] - ETA: 0s - loss: 0.8121 - accuracy: 0.1066
on_train_batch_begin: 1609170094.985617s

94 step training time: 0.166787s

on_train_batch_end: 1609170095.151438s

48640/50000 [============================>.] - ETA: 0s - loss: 0.8119 - accuracy: 0.1066
on_train_batch_begin: 1609170095.151810s

95 step training time: 0.166193s

on_train_batch_end: 1609170095.318797s

49152/50000 [============================>.] - ETA: 0s - loss: 0.8122 - accuracy: 0.1066
on_train_batch_begin: 1609170095.319180s

96 step training time: 0.167371s

on_train_batch_end: 1609170095.485990s

49664/50000 [============================>.] - ETA: 0s - loss: 0.8126 - accuracy: 0.1066
on_train_batch_begin: 1609170095.486371s

97 step training time: 0.167191s

on_train_batch_end: 1609170095.639137s

on_test_batch_begin: 1609170095.672370s

98 step training time: 0.185999s

on_epoch_end: 1609170096.399334s

Validation time: 0.726950s

Real time: 1609170096.399334s

Epoch time: 17.146153450012207s

50000/50000 [==============================] - 17s 343us/sample - loss: 0.8133 - accuracy: 0.1066 - val_loss: 6.1103 - val_accuracy: 0.1000
Tempo do fit: 240.00549840927124