wnloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 7:46
   212992/170498071 [..............................] - ETA: 57s 
   827392/170498071 [..............................] - ETA: 28s
  3268608/170498071 [..............................] - ETA: 9s 
  6430720/170498071 [>.............................] - ETA: 6s
  9314304/170498071 [>.............................] - ETA: 5s
 12574720/170498071 [=>............................] - ETA: 4s
 15720448/170498071 [=>............................] - ETA: 3s
 18866176/170498071 [==>...........................] - ETA: 3s
 22102016/170498071 [==>...........................] - ETA: 3s
 25141248/170498071 [===>..........................] - ETA: 3s
 28385280/170498071 [===>..........................] - ETA: 2s
 31580160/170498071 [====>.........................] - ETA: 2s
 34660352/170498071 [=====>........................] - ETA: 2s
 37953536/170498071 [=====>........................] - ETA: 2s
 40951808/170498071 [======>.......................] - ETA: 2s
 43098112/170498071 [======>.......................] - ETA: 2s
 47325184/170498071 [=======>......................] - ETA: 2s
 50601984/170498071 [=======>......................] - ETA: 2s
 53829632/170498071 [========>.....................] - ETA: 2s
 56827904/170498071 [========>.....................] - ETA: 2s
 60071936/170498071 [=========>....................] - ETA: 2s
 63135744/170498071 [==========>...................] - ETA: 1s
 66412544/170498071 [==========>...................] - ETA: 1s
 69640192/170498071 [===========>..................] - ETA: 1s
 72638464/170498071 [===========>..................] - ETA: 1s
 75948032/170498071 [============>.................] - ETA: 1s
 78897152/170498071 [============>.................] - ETA: 1s
 82157568/170498071 [=============>................] - ETA: 1s
 85450752/170498071 [==============>...............] - ETA: 1s
 88383488/170498071 [==============>...............] - ETA: 1s
 91693056/170498071 [===============>..............] - ETA: 1s
 94584832/170498071 [===============>..............] - ETA: 1s
 97878016/170498071 [================>.............] - ETA: 1s
101081088/170498071 [================>.............] - ETA: 1s
104128512/170498071 [=================>............] - ETA: 1s
107405312/170498071 [=================>............] - ETA: 1s
110387200/170498071 [==================>...........] - ETA: 1s
113647616/170498071 [==================>...........] - ETA: 0s
116776960/170498071 [===================>..........] - ETA: 0s
119873536/170498071 [====================>.........] - ETA: 0s
123133952/170498071 [====================>.........] - ETA: 0s
126132224/170498071 [=====================>........] - ETA: 0s
129441792/170498071 [=====================>........] - ETA: 0s
132571136/170498071 [======================>.......] - ETA: 0s
135634944/170498071 [======================>.......] - ETA: 0s
138944512/170498071 [=======================>......] - ETA: 0s
141975552/170498071 [=======================>......] - ETA: 0s
145235968/170498071 [========================>.....] - ETA: 0s
148381696/170498071 [=========================>....] - ETA: 0s
151576576/170498071 [=========================>....] - ETA: 0s
154869760/170498071 [==========================>...] - ETA: 0s
157884416/170498071 [==========================>...] - ETA: 0s
161193984/170498071 [===========================>..] - ETA: 0s
164241408/170498071 [===========================>..] - ETA: 0s
167452672/170498071 [============================>.] - ETA: 0s
170500096/170498071 [==============================] - 3s 0us/step
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

    8192/94765736 [..............................] - ETA: 0s
 8372224/94765736 [=>............................] - ETA: 0s
12664832/94765736 [===>..........................] - ETA: 0s
18841600/94765736 [====>.........................] - ETA: 0s
28286976/94765736 [=======>......................] - ETA: 0s
35012608/94765736 [==========>...................] - ETA: 0s
41639936/94765736 [============>.................] - ETA: 0s
47112192/94765736 [=============>................] - ETA: 0s
47546368/94765736 [==============>...............] - ETA: 0s
56598528/94765736 [================>.............] - ETA: 0s
58892288/94765736 [=================>............] - ETA: 0s
59875328/94765736 [=================>............] - ETA: 0s
65822720/94765736 [===================>..........] - ETA: 0s
66510848/94765736 [====================>.........] - ETA: 0s
75161600/94765736 [======================>.......] - ETA: 0s
79855616/94765736 [========================>.....] - ETA: 0s
89800704/94765736 [===========================>..] - ETA: 0s
94281728/94765736 [============================>.] - ETA: 0s
94773248/94765736 [==============================] - 1s 0us/step
Model: "resnet50"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
Tempo de Inicializacao: 12.53443431854248
Train on 50000 samples, validate on 10000 samples

on_epoch_begin: 1615678998.389756s

Real time: 1615678998.38978
Epoch 1/5

on_train_batch_begin: 1615678999.139907s

on_train_batch_end: 1615679015.676293s

 1024/50000 [..............................] - ETA: 13:46 - loss: 17.7586 - accuracy: 4.0913e-04
on_train_batch_begin: 1615679015.676893s

1 step training time: 16.536986s

on_train_batch_end: 1615679015.995333s

 2048/50000 [>.............................] - ETA: 6:52 - loss: 15.7741 - accuracy: 2.8944e-04 
on_train_batch_begin: 1615679015.995637s

2 step training time: 0.318744s

on_train_batch_end: 1615679016.317568s

 3072/50000 [>.............................] - ETA: 4:33 - loss: 13.7554 - accuracy: 4.6412e-04
on_train_batch_begin: 1615679016.317872s

3 step training time: 0.322235s

on_train_batch_end: 1615679016.640222s

 4096/50000 [=>............................] - ETA: 3:24 - loss: 12.4645 - accuracy: 8.5425e-04
on_train_batch_begin: 1615679016.640522s

4 step training time: 0.322650s

on_train_batch_end: 1615679016.964655s

 5120/50000 [==>...........................] - ETA: 2:42 - loss: 11.6301 - accuracy: 0.0022    
on_train_batch_begin: 1615679016.964954s

5 step training time: 0.324433s

on_train_batch_end: 1615679017.287789s

 6144/50000 [==>...........................] - ETA: 2:14 - loss: 11.0296 - accuracy: 0.0049
on_train_batch_begin: 1615679017.288141s

6 step training time: 0.323187s

on_train_batch_end: 1615679017.608533s

 7168/50000 [===>..........................] - ETA: 1:54 - loss: 10.5609 - accuracy: 0.0084
on_train_batch_begin: 1615679017.608845s

7 step training time: 0.320704s

on_train_batch_end: 1615679017.929172s

 8192/50000 [===>..........................] - ETA: 1:39 - loss: 10.2028 - accuracy: 0.0129
on_train_batch_begin: 1615679017.929447s

8 step training time: 0.320602s

on_train_batch_end: 1615679018.246035s

 9216/50000 [====>.........................] - ETA: 1:27 - loss: 9.9025 - accuracy: 0.0165 
on_train_batch_begin: 1615679018.246328s

9 step training time: 0.316881s

on_train_batch_end: 1615679018.567003s

10240/50000 [=====>........................] - ETA: 1:18 - loss: 9.6573 - accuracy: 0.0206
on_train_batch_begin: 1615679018.567287s

10 step training time: 0.320959s

on_train_batch_end: 1615679018.888034s

11264/50000 [=====>........................] - ETA: 1:10 - loss: 9.4490 - accuracy: 0.0238
on_train_batch_begin: 1615679018.888328s

11 step training time: 0.321041s

on_train_batch_end: 1615679019.205627s

12288/50000 [======>.......................] - ETA: 1:03 - loss: 9.2639 - accuracy: 0.0274
on_train_batch_begin: 1615679019.205893s

12 step training time: 0.317565s

on_train_batch_end: 1615679019.523220s

13312/50000 [======>.......................] - ETA: 58s - loss: 9.1051 - accuracy: 0.0302 
on_train_batch_begin: 1615679019.523498s

13 step training time: 0.317604s

on_train_batch_end: 1615679019.846148s

14336/50000 [=======>......................] - ETA: 53s - loss: 8.9691 - accuracy: 0.0331
on_train_batch_begin: 1615679019.846435s

14 step training time: 0.322937s

on_train_batch_end: 1615679020.165461s

15360/50000 [========>.....................] - ETA: 49s - loss: 8.8458 - accuracy: 0.0348
on_train_batch_begin: 1615679020.165744s

15 step training time: 0.319309s

on_train_batch_end: 1615679020.488168s

16384/50000 [========>.....................] - ETA: 45s - loss: 8.7438 - accuracy: 0.0367
on_train_batch_begin: 1615679020.488447s

16 step training time: 0.322703s

on_train_batch_end: 1615679020.807959s

17408/50000 [=========>....................] - ETA: 41s - loss: 8.6417 - accuracy: 0.0386
on_train_batch_begin: 1615679020.808247s

17 step training time: 0.319800s

on_train_batch_end: 1615679021.126121s

18432/50000 [==========>...................] - ETA: 38s - loss: 8.5440 - accuracy: 0.0401
on_train_batch_begin: 1615679021.126363s

18 step training time: 0.318116s

on_train_batch_end: 1615679021.447177s

19456/50000 [==========>...................] - ETA: 36s - loss: 8.4676 - accuracy: 0.0416
on_train_batch_begin: 1615679021.447428s

19 step training time: 0.321065s

on_train_batch_end: 1615679021.768504s

20480/50000 [===========>..................] - ETA: 33s - loss: 8.3846 - accuracy: 0.0429
on_train_batch_begin: 1615679021.768771s

20 step training time: 0.321343s

on_train_batch_end: 1615679022.067528s

21504/50000 [===========>..................] - ETA: 31s - loss: 8.3117 - accuracy: 0.0441
on_train_batch_begin: 1615679022.067818s

21 step training time: 0.299047s

on_train_batch_end: 1615679022.388047s

22528/50000 [============>.................] - ETA: 29s - loss: 8.2359 - accuracy: 0.0449
on_train_batch_begin: 1615679022.388370s

22 step training time: 0.320552s

on_train_batch_end: 1615679022.711019s

23552/50000 [=============>................] - ETA: 27s - loss: 8.1771 - accuracy: 0.0456
on_train_batch_begin: 1615679022.711297s

23 step training time: 0.322927s

on_train_batch_end: 1615679023.033979s

24576/50000 [=============>................] - ETA: 25s - loss: 8.1063 - accuracy: 0.0466
on_train_batch_begin: 1615679023.034255s

24 step training time: 0.322958s

on_train_batch_end: 1615679023.355455s

25600/50000 [==============>...............] - ETA: 23s - loss: 8.0415 - accuracy: 0.0471
on_train_batch_begin: 1615679023.355731s

25 step training time: 0.321476s

on_train_batch_end: 1615679023.679328s

26624/50000 [==============>...............] - ETA: 22s - loss: 7.9781 - accuracy: 0.0480
on_train_batch_begin: 1615679023.679610s

26 step training time: 0.323879s

on_train_batch_end: 1615679024.001179s

27648/50000 [===============>..............] - ETA: 20s - loss: 7.9205 - accuracy: 0.0490
on_train_batch_begin: 1615679024.001446s

27 step training time: 0.321836s

on_train_batch_end: 1615679024.304425s

28672/50000 [================>.............] - ETA: 19s - loss: 7.8686 - accuracy: 0.0501
on_train_batch_begin: 1615679024.304709s

28 step training time: 0.303262s

on_train_batch_end: 1615679024.620709s

29696/50000 [================>.............] - ETA: 17s - loss: 7.8095 - accuracy: 0.0508
on_train_batch_begin: 1615679024.620994s

29 step training time: 0.316285s

on_train_batch_end: 1615679024.942153s

30720/50000 [=================>............] - ETA: 16s - loss: 7.7558 - accuracy: 0.0515
on_train_batch_begin: 1615679024.942423s

30 step training time: 0.321429s

on_train_batch_end: 1615679025.261311s

31744/50000 [==================>...........] - ETA: 15s - loss: 7.7060 - accuracy: 0.0525
on_train_batch_begin: 1615679025.261562s

31 step training time: 0.319139s

on_train_batch_end: 1615679025.577631s

32768/50000 [==================>...........] - ETA: 14s - loss: 7.6562 - accuracy: 0.0534
on_train_batch_begin: 1615679025.577904s

32 step training time: 0.316341s

on_train_batch_end: 1615679025.896000s

33792/50000 [===================>..........] - ETA: 13s - loss: 7.6131 - accuracy: 0.0538
on_train_batch_begin: 1615679025.896297s

33 step training time: 0.318393s

on_train_batch_end: 1615679026.218061s

34816/50000 [===================>..........] - ETA: 12s - loss: 7.5725 - accuracy: 0.0541
on_train_batch_begin: 1615679026.218324s

34 step training time: 0.322027s

on_train_batch_end: 1615679026.540263s

35840/50000 [====================>.........] - ETA: 11s - loss: 7.5373 - accuracy: 0.0547
on_train_batch_begin: 1615679026.540550s

35 step training time: 0.322226s

on_train_batch_end: 1615679026.860585s

36864/50000 [=====================>........] - ETA: 10s - loss: 7.4966 - accuracy: 0.0555
on_train_batch_begin: 1615679026.860860s

36 step training time: 0.320310s

on_train_batch_end: 1615679027.178763s

37888/50000 [=====================>........] - ETA: 9s - loss: 7.4547 - accuracy: 0.0566 
on_train_batch_begin: 1615679027.179055s

37 step training time: 0.318195s

on_train_batch_end: 1615679027.498899s

38912/50000 [======================>.......] - ETA: 8s - loss: 7.4166 - accuracy: 0.0573
on_train_batch_begin: 1615679027.499186s

38 step training time: 0.320131s

on_train_batch_end: 1615679027.818639s

39936/50000 [======================>.......] - ETA: 7s - loss: 7.3806 - accuracy: 0.0583
on_train_batch_begin: 1615679027.818905s

39 step training time: 0.319719s

on_train_batch_end: 1615679028.141253s

40960/50000 [=======================>......] - ETA: 6s - loss: 7.3405 - accuracy: 0.0591
on_train_batch_begin: 1615679028.141513s

40 step training time: 0.322608s

on_train_batch_end: 1615679028.457693s

41984/50000 [========================>.....] - ETA: 5s - loss: 7.3038 - accuracy: 0.0598
on_train_batch_begin: 1615679028.457979s

41 step training time: 0.316466s

on_train_batch_end: 1615679028.776751s

43008/50000 [========================>.....] - ETA: 4s - loss: 7.2662 - accuracy: 0.0607
on_train_batch_begin: 1615679028.777035s

42 step training time: 0.319056s

on_train_batch_end: 1615679029.098332s

44032/50000 [=========================>....] - ETA: 4s - loss: 7.2313 - accuracy: 0.0615
on_train_batch_begin: 1615679029.098631s

43 step training time: 0.321596s

on_train_batch_end: 1615679029.420264s

45056/50000 [==========================>...] - ETA: 3s - loss: 7.1970 - accuracy: 0.0622
on_train_batch_begin: 1615679029.420534s

44 step training time: 0.321903s

on_train_batch_end: 1615679029.742924s

46080/50000 [==========================>...] - ETA: 2s - loss: 7.1640 - accuracy: 0.0630
on_train_batch_begin: 1615679029.743195s

45 step training time: 0.322661s

on_train_batch_end: 1615679030.061652s

47104/50000 [===========================>..] - ETA: 1s - loss: 7.1283 - accuracy: 0.0636
on_train_batch_begin: 1615679030.061912s

46 step training time: 0.318717s

on_train_batch_end: 1615679030.377960s

48128/50000 [===========================>..] - ETA: 1s - loss: 7.0973 - accuracy: 0.0640
on_train_batch_begin: 1615679030.378247s

47 step training time: 0.316335s

on_train_batch_end: 1615679030.698635s

49152/50000 [============================>.] - ETA: 0s - loss: 7.0648 - accuracy: 0.0646
on_train_batch_begin: 1615679030.698918s

48 step training time: 0.320671s

on_train_batch_end: 1615679036.349808s

on_test_batch_begin: 1615679036.537428s

49 step training time: 5.838509s

on_epoch_end: 1615679041.072342s

Validation time: 4.534900s

Real time: 1615679041.072342s

Epoch time: 42.682576417922974s

50000/50000 [==============================] - 43s 854us/sample - loss: 7.0408 - accuracy: 0.0649 - val_loss: 24521.3565 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615679041.072541s

Real time: 1615679041.0725489
Epoch 2/5

on_train_batch_begin: 1615679041.075937s

on_train_batch_end: 1615679041.396584s

 1024/50000 [..............................] - ETA: 15s - loss: 5.5949 - accuracy: 0.0804
on_train_batch_begin: 1615679041.396832s

1 step training time: 0.320894s

on_train_batch_end: 1615679041.717752s

 2048/50000 [>.............................] - ETA: 15s - loss: 5.5673 - accuracy: 0.0815
on_train_batch_begin: 1615679041.718062s

2 step training time: 0.321230s

on_train_batch_end: 1615679042.040973s

 3072/50000 [>.............................] - ETA: 14s - loss: 5.6035 - accuracy: 0.0837
on_train_batch_begin: 1615679042.041257s

3 step training time: 0.323195s

on_train_batch_end: 1615679042.357213s

 4096/50000 [=>............................] - ETA: 14s - loss: 5.6063 - accuracy: 0.0831
on_train_batch_begin: 1615679042.357508s

4 step training time: 0.316251s

on_train_batch_end: 1615679042.675395s

 5120/50000 [==>...........................] - ETA: 14s - loss: 5.5811 - accuracy: 0.0831
on_train_batch_begin: 1615679042.675692s

5 step training time: 0.318184s

on_train_batch_end: 1615679042.997377s

 6144/50000 [==>...........................] - ETA: 13s - loss: 5.5666 - accuracy: 0.0833
on_train_batch_begin: 1615679042.997674s

6 step training time: 0.321982s

on_train_batch_end: 1615679043.317899s

 7168/50000 [===>..........................] - ETA: 13s - loss: 5.5475 - accuracy: 0.0831
on_train_batch_begin: 1615679043.318173s

7 step training time: 0.320499s

on_train_batch_end: 1615679043.642021s

 8192/50000 [===>..........................] - ETA: 13s - loss: 5.5346 - accuracy: 0.0824
on_train_batch_begin: 1615679043.642413s

8 step training time: 0.324240s

on_train_batch_end: 1615679043.962161s

 9216/50000 [====>.........................] - ETA: 12s - loss: 5.5251 - accuracy: 0.0804
on_train_batch_begin: 1615679043.962463s

9 step training time: 0.320050s

on_train_batch_end: 1615679044.281718s

10240/50000 [=====>........................] - ETA: 12s - loss: 5.5020 - accuracy: 0.0793
on_train_batch_begin: 1615679044.282010s

10 step training time: 0.319546s

on_train_batch_end: 1615679044.601640s

11264/50000 [=====>........................] - ETA: 12s - loss: 5.4758 - accuracy: 0.0786
on_train_batch_begin: 1615679044.601935s

11 step training time: 0.319926s

on_train_batch_end: 1615679044.924932s

12288/50000 [======>.......................] - ETA: 11s - loss: 5.4700 - accuracy: 0.0781
on_train_batch_begin: 1615679044.925225s

12 step training time: 0.323290s

on_train_batch_end: 1615679045.247350s

13312/50000 [======>.......................] - ETA: 11s - loss: 5.4505 - accuracy: 0.0772
on_train_batch_begin: 1615679045.247612s

13 step training time: 0.322388s

on_train_batch_end: 1615679045.570726s

14336/50000 [=======>......................] - ETA: 11s - loss: 5.4331 - accuracy: 0.0771
on_train_batch_begin: 1615679045.570969s

14 step training time: 0.323356s

on_train_batch_end: 1615679045.889358s

15360/50000 [========>.....................] - ETA: 10s - loss: 5.4192 - accuracy: 0.0771
on_train_batch_begin: 1615679045.889633s

15 step training time: 0.318665s

on_train_batch_end: 1615679046.205865s

16384/50000 [========>.....................] - ETA: 10s - loss: 5.4111 - accuracy: 0.0775
on_train_batch_begin: 1615679046.206119s

16 step training time: 0.316485s

on_train_batch_end: 1615679046.527074s

17408/50000 [=========>....................] - ETA: 10s - loss: 5.3942 - accuracy: 0.0775
on_train_batch_begin: 1615679046.527324s

17 step training time: 0.321205s

on_train_batch_end: 1615679046.848943s

18432/50000 [==========>...................] - ETA: 9s - loss: 5.3758 - accuracy: 0.0778 
on_train_batch_begin: 1615679046.849254s

18 step training time: 0.321930s

on_train_batch_end: 1615679047.167426s

19456/50000 [==========>...................] - ETA: 9s - loss: 5.3616 - accuracy: 0.0777
on_train_batch_begin: 1615679047.167703s

19 step training time: 0.318449s

on_train_batch_end: 1615679047.486781s

20480/50000 [===========>..................] - ETA: 9s - loss: 5.3467 - accuracy: 0.0777
on_train_batch_begin: 1615679047.487078s

20 step training time: 0.319375s

on_train_batch_end: 1615679047.809046s

21504/50000 [===========>..................] - ETA: 8s - loss: 5.3278 - accuracy: 0.0776
on_train_batch_begin: 1615679047.809344s

21 step training time: 0.322266s

on_train_batch_end: 1615679048.130404s

22528/50000 [============>.................] - ETA: 8s - loss: 5.3172 - accuracy: 0.0771
on_train_batch_begin: 1615679048.130670s

22 step training time: 0.321326s

on_train_batch_end: 1615679048.451077s

23552/50000 [=============>................] - ETA: 8s - loss: 5.2990 - accuracy: 0.0766
on_train_batch_begin: 1615679048.451328s

23 step training time: 0.320658s

on_train_batch_end: 1615679048.768551s

24576/50000 [=============>................] - ETA: 7s - loss: 5.2824 - accuracy: 0.0764
on_train_batch_begin: 1615679048.768797s

24 step training time: 0.317469s

on_train_batch_end: 1615679049.089549s

25600/50000 [==============>...............] - ETA: 7s - loss: 5.2695 - accuracy: 0.0762
on_train_batch_begin: 1615679049.089852s

25 step training time: 0.321055s

on_train_batch_end: 1615679049.412440s

26624/50000 [==============>...............] - ETA: 7s - loss: 5.2549 - accuracy: 0.0758
on_train_batch_begin: 1615679049.412724s

26 step training time: 0.322872s

on_train_batch_end: 1615679049.734508s

27648/50000 [===============>..............] - ETA: 7s - loss: 5.2354 - accuracy: 0.0757
on_train_batch_begin: 1615679049.734781s

27 step training time: 0.322057s

on_train_batch_end: 1615679050.051264s

28672/50000 [================>.............] - ETA: 6s - loss: 5.2139 - accuracy: 0.0755
on_train_batch_begin: 1615679050.051553s

28 step training time: 0.316772s

on_train_batch_end: 1615679050.370067s

29696/50000 [================>.............] - ETA: 6s - loss: 5.1975 - accuracy: 0.0753
on_train_batch_begin: 1615679050.370323s

29 step training time: 0.318770s

on_train_batch_end: 1615679050.692504s

30720/50000 [=================>............] - ETA: 6s - loss: 5.1834 - accuracy: 0.0752
on_train_batch_begin: 1615679050.692772s

30 step training time: 0.322448s

on_train_batch_end: 1615679051.015799s

31744/50000 [==================>...........] - ETA: 5s - loss: 5.1606 - accuracy: 0.0752
on_train_batch_begin: 1615679051.016116s

31 step training time: 0.323345s

on_train_batch_end: 1615679051.338527s

32768/50000 [==================>...........] - ETA: 5s - loss: 5.1432 - accuracy: 0.0750
on_train_batch_begin: 1615679051.338794s

32 step training time: 0.322677s

on_train_batch_end: 1615679051.655300s

33792/50000 [===================>..........] - ETA: 5s - loss: 5.1266 - accuracy: 0.0750
on_train_batch_begin: 1615679051.655566s

33 step training time: 0.316772s

on_train_batch_end: 1615679051.976287s

34816/50000 [===================>..........] - ETA: 4s - loss: 5.1013 - accuracy: 0.0751
on_train_batch_begin: 1615679051.976550s

34 step training time: 0.320984s

on_train_batch_end: 1615679052.297052s

35840/50000 [====================>.........] - ETA: 4s - loss: 5.0838 - accuracy: 0.0752
on_train_batch_begin: 1615679052.297328s

35 step training time: 0.320777s

on_train_batch_end: 1615679052.621175s

36864/50000 [=====================>........] - ETA: 4s - loss: 5.0638 - accuracy: 0.0753
on_train_batch_begin: 1615679052.621467s

36 step training time: 0.324140s

on_train_batch_end: 1615679052.939984s

37888/50000 [=====================>........] - ETA: 3s - loss: 5.0456 - accuracy: 0.0752
on_train_batch_begin: 1615679052.940295s

37 step training time: 0.318828s

on_train_batch_end: 1615679053.258955s

38912/50000 [======================>.......] - ETA: 3s - loss: 5.0276 - accuracy: 0.0753
on_train_batch_begin: 1615679053.259247s

38 step training time: 0.318952s

on_train_batch_end: 1615679053.581382s

39936/50000 [======================>.......] - ETA: 3s - loss: 5.0097 - accuracy: 0.0754
on_train_batch_begin: 1615679053.581652s

39 step training time: 0.322405s

on_train_batch_end: 1615679053.903114s

40960/50000 [=======================>......] - ETA: 2s - loss: 4.9917 - accuracy: 0.0755
on_train_batch_begin: 1615679053.903400s

40 step training time: 0.321748s

on_train_batch_end: 1615679054.225257s

41984/50000 [========================>.....] - ETA: 2s - loss: 4.9733 - accuracy: 0.0756
on_train_batch_begin: 1615679054.225505s

41 step training time: 0.322105s

on_train_batch_end: 1615679054.541904s

43008/50000 [========================>.....] - ETA: 2s - loss: 4.9550 - accuracy: 0.0758
on_train_batch_begin: 1615679054.542153s

42 step training time: 0.316648s

on_train_batch_end: 1615679054.862157s

44032/50000 [=========================>....] - ETA: 1s - loss: 4.9390 - accuracy: 0.0758
on_train_batch_begin: 1615679054.862425s

43 step training time: 0.320272s

on_train_batch_end: 1615679055.184561s

45056/50000 [==========================>...] - ETA: 1s - loss: 4.9185 - accuracy: 0.0758
on_train_batch_begin: 1615679055.184846s

44 step training time: 0.322422s

on_train_batch_end: 1615679055.506193s

46080/50000 [==========================>...] - ETA: 1s - loss: 4.8984 - accuracy: 0.0758
on_train_batch_begin: 1615679055.506483s

45 step training time: 0.321637s

on_train_batch_end: 1615679055.825880s

47104/50000 [===========================>..] - ETA: 0s - loss: 4.8786 - accuracy: 0.0759
on_train_batch_begin: 1615679055.826153s

46 step training time: 0.319670s

on_train_batch_end: 1615679056.144599s

48128/50000 [===========================>..] - ETA: 0s - loss: 4.8632 - accuracy: 0.0761
on_train_batch_begin: 1615679056.144877s

47 step training time: 0.318724s

on_train_batch_end: 1615679056.465021s

49152/50000 [============================>.] - ETA: 0s - loss: 4.8451 - accuracy: 0.0764
on_train_batch_begin: 1615679056.465284s

48 step training time: 0.320407s

on_train_batch_end: 1615679056.733651s

on_test_batch_begin: 1615679056.745756s

49 step training time: 0.280472s

on_epoch_end: 1615679057.525772s

Validation time: 0.780006s

Real time: 1615679057.525772s

Epoch time: 16.453238487243652s

50000/50000 [==============================] - 16s 329us/sample - loss: 4.8290 - accuracy: 0.0765 - val_loss: 10.5686 - val_accuracy: 0.0000e+00

on_epoch_begin: 1615679057.525965s

Real time: 1615679057.5259717
Epoch 3/5

on_train_batch_begin: 1615679057.529380s

on_train_batch_end: 1615679057.848493s

 1024/50000 [..............................] - ETA: 15s - loss: 4.0195 - accuracy: 0.0885
on_train_batch_begin: 1615679057.848764s

1 step training time: 0.319384s

on_train_batch_end: 1615679058.171380s

 2048/50000 [>.............................] - ETA: 15s - loss: 3.9734 - accuracy: 0.0900
on_train_batch_begin: 1615679058.171618s

2 step training time: 0.322854s

on_train_batch_end: 1615679058.492314s

 3072/50000 [>.............................] - ETA: 14s - loss: 3.9134 - accuracy: 0.0900
on_train_batch_begin: 1615679058.492540s

3 step training time: 0.320922s

on_train_batch_end: 1615679058.808307s

 4096/50000 [=>............................] - ETA: 14s - loss: 3.8834 - accuracy: 0.0899
on_train_batch_begin: 1615679058.808592s

4 step training time: 0.316053s

on_train_batch_end: 1615679059.130060s

 5120/50000 [==>...........................] - ETA: 14s - loss: 3.8469 - accuracy: 0.0895
on_train_batch_begin: 1615679059.130361s

5 step training time: 0.321769s

on_train_batch_end: 1615679059.453579s

 6144/50000 [==>...........................] - ETA: 13s - loss: 3.8194 - accuracy: 0.0896
on_train_batch_begin: 1615679059.453855s

6 step training time: 0.323494s

on_train_batch_end: 1615679059.776925s

 7168/50000 [===>..........................] - ETA: 13s - loss: 3.7992 - accuracy: 0.0894
on_train_batch_begin: 1615679059.777175s

7 step training time: 0.323320s

on_train_batch_end: 1615679060.101852s

 8192/50000 [===>..........................] - ETA: 13s - loss: 3.7576 - accuracy: 0.0895
on_train_batch_begin: 1615679060.102106s

8 step training time: 0.324931s

on_train_batch_end: 1615679060.425399s

 9216/50000 [====>.........................] - ETA: 12s - loss: 3.7338 - accuracy: 0.0893
on_train_batch_begin: 1615679060.425630s

9 step training time: 0.323524s

on_train_batch_end: 1615679060.753064s

10240/50000 [=====>........................] - ETA: 12s - loss: 3.7252 - accuracy: 0.0889
on_train_batch_begin: 1615679060.753309s

10 step training time: 0.327679s

on_train_batch_end: 1615679061.077812s

11264/50000 [=====>........................] - ETA: 12s - loss: 3.6764 - accuracy: 0.0893
on_train_batch_begin: 1615679061.078076s

11 step training time: 0.324768s

on_train_batch_end: 1615679061.402418s

12288/50000 [======>.......................] - ETA: 11s - loss: 3.6649 - accuracy: 0.0895
on_train_batch_begin: 1615679061.402703s

12 step training time: 0.324627s

on_train_batch_end: 1615679061.720826s

13312/50000 [======>.......................] - ETA: 11s - loss: 3.6389 - accuracy: 0.0899
on_train_batch_begin: 1615679061.721103s

13 step training time: 0.318400s

on_train_batch_end: 1615679062.039329s

14336/50000 [=======>......................] - ETA: 11s - loss: 3.6181 - accuracy: 0.0901
on_train_batch_begin: 1615679062.039600s

14 step training time: 0.318496s

on_train_batch_end: 1615679062.360828s

15360/50000 [========>.....................] - ETA: 10s - loss: 3.5969 - accuracy: 0.0906
on_train_batch_begin: 1615679062.361089s

15 step training time: 0.321489s

on_train_batch_end: 1615679062.684459s

16384/50000 [========>.....................] - ETA: 10s - loss: 3.5905 - accuracy: 0.0908
on_train_batch_begin: 1615679062.684742s

16 step training time: 0.323653s

on_train_batch_end: 1615679063.008237s

17408/50000 [=========>....................] - ETA: 10s - loss: 3.5804 - accuracy: 0.0908
on_train_batch_begin: 1615679063.008543s

17 step training time: 0.323801s

on_train_batch_end: 1615679063.332207s

18432/50000 [==========>...................] - ETA: 9s - loss: 3.5678 - accuracy: 0.0909 
on_train_batch_begin: 1615679063.332493s

18 step training time: 0.323950s

on_train_batch_end: 1615679063.656878s

19456/50000 [==========>...................] - ETA: 9s - loss: 3.5495 - accuracy: 0.0911
on_train_batch_begin: 1615679063.657148s

19 step training time: 0.324655s

on_train_batch_end: 1615679063.976787s

20480/50000 [===========>..................] - ETA: 9s - loss: 3.5343 - accuracy: 0.0914
on_train_batch_begin: 1615679063.977045s

20 step training time: 0.319897s

on_train_batch_end: 1615679064.293753s

21504/50000 [===========>..................] - ETA: 8s - loss: 3.5171 - accuracy: 0.0914
on_train_batch_begin: 1615679064.293987s

21 step training time: 0.316942s

on_train_batch_end: 1615679064.615558s

22528/50000 [============>.................] - ETA: 8s - loss: 3.4940 - accuracy: 0.0918
on_train_batch_begin: 1615679064.615816s

22 step training time: 0.321829s

on_train_batch_end: 1615679064.938092s

23552/50000 [=============>................] - ETA: 8s - loss: 3.4824 - accuracy: 0.0919
on_train_batch_begin: 1615679064.938349s

23 step training time: 0.322534s

on_train_batch_end: 1615679065.262015s

24576/50000 [=============>................] - ETA: 8s - loss: 3.4689 - accuracy: 0.0921
on_train_batch_begin: 1615679065.262312s

24 step training time: 0.323963s

on_train_batch_end: 1615679065.587676s

25600/50000 [==============>...............] - ETA: 7s - loss: 3.4593 - accuracy: 0.0921
on_train_batch_begin: 1615679065.587936s

25 step training time: 0.325624s

on_train_batch_end: 1615679065.912193s

26624/50000 [==============>...............] - ETA: 7s - loss: 3.4435 - accuracy: 0.0921
on_train_batch_begin: 1615679065.912466s

26 step training time: 0.324530s

on_train_batch_end: 1615679066.233562s

27648/50000 [===============>..............] - ETA: 7s - loss: 3.4335 - accuracy: 0.0922
on_train_batch_begin: 1615679066.233820s

27 step training time: 0.321353s

on_train_batch_end: 1615679066.559388s

28672/50000 [================>.............] - ETA: 6s - loss: 3.4144 - accuracy: 0.0922
on_train_batch_begin: 1615679066.559628s

28 step training time: 0.325808s

on_train_batch_end: 1615679066.884267s

29696/50000 [================>.............] - ETA: 6s - loss: 3.4046 - accuracy: 0.0922
on_train_batch_begin: 1615679066.884527s

29 step training time: 0.324899s

on_train_batch_end: 1615679067.206820s

30720/50000 [=================>............] - ETA: 6s - loss: 3.3967 - accuracy: 0.0922
on_train_batch_begin: 1615679067.207084s

30 step training time: 0.322556s

on_train_batch_end: 1615679067.526541s

31744/50000 [==================>...........] - ETA: 5s - loss: 3.3860 - accuracy: 0.0923
on_train_batch_begin: 1615679067.526835s

31 step training time: 0.319751s

on_train_batch_end: 1615679067.846985s

32768/50000 [==================>...........] - ETA: 5s - loss: 3.3718 - accuracy: 0.0925
on_train_batch_begin: 1615679067.847285s

32 step training time: 0.320451s

on_train_batch_end: 1615679068.169597s

33792/50000 [===================>..........] - ETA: 5s - loss: 3.3645 - accuracy: 0.0925
on_train_batch_begin: 1615679068.169903s

33 step training time: 0.322617s

on_train_batch_end: 1615679068.491239s

34816/50000 [===================>..........] - ETA: 4s - loss: 3.3623 - accuracy: 0.0925
on_train_batch_begin: 1615679068.491492s

34 step training time: 0.321589s

on_train_batch_end: 1615679068.814124s

35840/50000 [====================>.........] - ETA: 4s - loss: 3.3558 - accuracy: 0.0925
on_train_batch_begin: 1615679068.814371s

35 step training time: 0.322879s

on_train_batch_end: 1615679069.137874s

36864/50000 [=====================>........] - ETA: 4s - loss: 3.3488 - accuracy: 0.0926
on_train_batch_begin: 1615679069.138128s

36 step training time: 0.323756s

on_train_batch_end: 1615679069.460510s

37888/50000 [=====================>........] - ETA: 3s - loss: 3.3386 - accuracy: 0.0927
on_train_batch_begin: 1615679069.460805s

37 step training time: 0.322678s

on_train_batch_end: 1615679069.786609s

38912/50000 [======================>.......] - ETA: 3s - loss: 3.3247 - accuracy: 0.0929
on_train_batch_begin: 1615679069.786897s

38 step training time: 0.326092s

on_train_batch_end: 1615679070.109859s

39936/50000 [======================>.......] - ETA: 3s - loss: 3.3229 - accuracy: 0.0929
on_train_batch_begin: 1615679070.110148s

39 step training time: 0.323251s

on_train_batch_end: 1615679070.435334s

40960/50000 [=======================>......] - ETA: 2s - loss: 3.3122 - accuracy: 0.0931
on_train_batch_begin: 1615679070.435601s

40 step training time: 0.325453s

on_train_batch_end: 1615679070.759631s

41984/50000 [========================>.....] - ETA: 2s - loss: 3.3062 - accuracy: 0.0931
on_train_batch_begin: 1615679070.759893s

41 step training time: 0.324292s

on_train_batch_end: 1615679071.081314s

43008/50000 [========================>.....] - ETA: 2s - loss: 3.2961 - accuracy: 0.0932
on_train_batch_begin: 1615679071.081591s

42 step training time: 0.321698s

on_train_batch_end: 1615679071.402799s

44032/50000 [=========================>....] - ETA: 1s - loss: 3.2847 - accuracy: 0.0933
on_train_batch_begin: 1615679071.403089s

43 step training time: 0.321498s

on_train_batch_end: 1615679071.723724s

45056/50000 [==========================>...] - ETA: 1s - loss: 3.2782 - accuracy: 0.0933
on_train_batch_begin: 1615679071.723986s

44 step training time: 0.320898s

on_train_batch_end: 1615679072.043683s

46080/50000 [==========================>...] - ETA: 1s - loss: 3.2678 - accuracy: 0.0933
on_train_batch_begin: 1615679072.043947s

45 step training time: 0.319961s

on_train_batch_end: 1615679072.366425s

47104/50000 [===========================>..] - ETA: 0s - loss: 3.2642 - accuracy: 0.0933
on_train_batch_begin: 1615679072.366670s

46 step training time: 0.322722s

on_train_batch_end: 1615679072.688411s

48128/50000 [===========================>..] - ETA: 0s - loss: 3.2538 - accuracy: 0.0933
on_train_batch_begin: 1615679072.688731s

47 step training time: 0.322061s

on_train_batch_end: 1615679073.011862s

49152/50000 [============================>.] - ETA: 0s - loss: 3.2476 - accuracy: 0.0933
on_train_batch_begin: 1615679073.012166s

48 step training time: 0.323435s

on_train_batch_end: 1615679073.282099s

on_test_batch_begin: 1615679073.298124s

49 step training time: 0.285959s

on_epoch_end: 1615679074.081781s

Validation time: 0.783645s

Real time: 1615679074.081781s

Epoch time: 16.555825233459473s

50000/50000 [==============================] - 17s 331us/sample - loss: 3.2390 - accuracy: 0.0934 - val_loss: 7.2497 - val_accuracy: 0.0999

on_epoch_begin: 1615679074.081958s

Real time: 1615679074.0819635
Epoch 4/5

on_train_batch_begin: 1615679074.085235s

on_train_batch_end: 1615679074.409855s

 1024/50000 [..............................] - ETA: 15s - loss: 2.7732 - accuracy: 0.0971
on_train_batch_begin: 1615679074.410098s

1 step training time: 0.324864s

on_train_batch_end: 1615679074.734313s

 2048/50000 [>.............................] - ETA: 15s - loss: 2.7002 - accuracy: 0.0964
on_train_batch_begin: 1615679074.734549s

2 step training time: 0.324451s

on_train_batch_end: 1615679075.060916s

 3072/50000 [>.............................] - ETA: 14s - loss: 2.7191 - accuracy: 0.0959
on_train_batch_begin: 1615679075.061176s

3 step training time: 0.326627s

on_train_batch_end: 1615679075.384588s

 4096/50000 [=>............................] - ETA: 14s - loss: 2.7240 - accuracy: 0.0955
on_train_batch_begin: 1615679075.384838s

4 step training time: 0.323661s

on_train_batch_end: 1615679075.709605s

 5120/50000 [==>...........................] - ETA: 14s - loss: 2.7175 - accuracy: 0.0958
on_train_batch_begin: 1615679075.709912s

5 step training time: 0.325074s

on_train_batch_end: 1615679076.034515s

 6144/50000 [==>...........................] - ETA: 13s - loss: 2.6879 - accuracy: 0.0962
on_train_batch_begin: 1615679076.034798s

6 step training time: 0.324886s

on_train_batch_end: 1615679076.359275s

 7168/50000 [===>..........................] - ETA: 13s - loss: 2.6928 - accuracy: 0.0964
on_train_batch_begin: 1615679076.359529s

7 step training time: 0.324731s

on_train_batch_end: 1615679076.681295s

 8192/50000 [===>..........................] - ETA: 13s - loss: 2.6539 - accuracy: 0.0967
on_train_batch_begin: 1615679076.681543s

8 step training time: 0.322014s

on_train_batch_end: 1615679077.024925s

 9216/50000 [====>.........................] - ETA: 13s - loss: 2.6241 - accuracy: 0.0968
on_train_batch_begin: 1615679077.025199s

9 step training time: 0.343656s

on_train_batch_end: 1615679077.347451s

10240/50000 [=====>........................] - ETA: 12s - loss: 2.6216 - accuracy: 0.0967
on_train_batch_begin: 1615679077.347723s

10 step training time: 0.322524s

on_train_batch_end: 1615679077.669322s

11264/50000 [=====>........................] - ETA: 12s - loss: 2.6192 - accuracy: 0.0967
on_train_batch_begin: 1615679077.669611s

11 step training time: 0.321887s

on_train_batch_end: 1615679077.990988s

12288/50000 [======>.......................] - ETA: 11s - loss: 2.6126 - accuracy: 0.0964
on_train_batch_begin: 1615679077.991283s

12 step training time: 0.321672s

on_train_batch_end: 1615679078.313342s

13312/50000 [======>.......................] - ETA: 11s - loss: 2.5996 - accuracy: 0.0963
on_train_batch_begin: 1615679078.313632s

13 step training time: 0.322350s

on_train_batch_end: 1615679078.637644s

14336/50000 [=======>......................] - ETA: 11s - loss: 2.5847 - accuracy: 0.0962
on_train_batch_begin: 1615679078.637923s

14 step training time: 0.324291s

on_train_batch_end: 1615679078.961683s

15360/50000 [========>.....................] - ETA: 11s - loss: 2.5604 - accuracy: 0.0963
on_train_batch_begin: 1615679078.961969s

15 step training time: 0.324045s

on_train_batch_end: 1615679079.285223s

16384/50000 [========>.....................] - ETA: 10s - loss: 2.5445 - accuracy: 0.0963
on_train_batch_begin: 1615679079.285489s

16 step training time: 0.323520s

on_train_batch_end: 1615679079.609214s

17408/50000 [=========>....................] - ETA: 10s - loss: 2.5255 - accuracy: 0.0964
on_train_batch_begin: 1615679079.609500s

17 step training time: 0.324011s

on_train_batch_end: 1615679079.933108s

18432/50000 [==========>...................] - ETA: 10s - loss: 2.5072 - accuracy: 0.0965
on_train_batch_begin: 1615679079.933381s

18 step training time: 0.323881s

on_train_batch_end: 1615679080.256906s

19456/50000 [==========>...................] - ETA: 9s - loss: 2.4788 - accuracy: 0.0966 
on_train_batch_begin: 1615679080.257176s

19 step training time: 0.323795s

on_train_batch_end: 1615679080.582294s

20480/50000 [===========>..................] - ETA: 9s - loss: 2.4540 - accuracy: 0.0968
on_train_batch_begin: 1615679080.582561s

20 step training time: 0.325385s

on_train_batch_end: 1615679080.905778s

21504/50000 [===========>..................] - ETA: 9s - loss: 2.4285 - accuracy: 0.0969
on_train_batch_begin: 1615679080.906046s

21 step training time: 0.323485s

on_train_batch_end: 1615679081.230580s

22528/50000 [============>.................] - ETA: 8s - loss: 2.4144 - accuracy: 0.0971
on_train_batch_begin: 1615679081.230850s

22 step training time: 0.324804s

on_train_batch_end: 1615679081.554469s

23552/50000 [=============>................] - ETA: 8s - loss: 2.3907 - accuracy: 0.0972
on_train_batch_begin: 1615679081.554744s

23 step training time: 0.323895s

on_train_batch_end: 1615679081.878665s

24576/50000 [=============>................] - ETA: 8s - loss: 2.3692 - accuracy: 0.0973
on_train_batch_begin: 1615679081.878957s

24 step training time: 0.324212s

on_train_batch_end: 1615679082.202864s

25600/50000 [==============>...............] - ETA: 7s - loss: 2.3519 - accuracy: 0.0975
on_train_batch_begin: 1615679082.203153s

25 step training time: 0.324196s

on_train_batch_end: 1615679082.529269s

26624/50000 [==============>...............] - ETA: 7s - loss: 2.3273 - accuracy: 0.0976
on_train_batch_begin: 1615679082.529542s

26 step training time: 0.326389s

on_train_batch_end: 1615679082.856521s

27648/50000 [===============>..............] - ETA: 7s - loss: 2.3012 - accuracy: 0.0977
on_train_batch_begin: 1615679082.856856s

27 step training time: 0.327314s

on_train_batch_end: 1615679083.182865s

28672/50000 [================>.............] - ETA: 6s - loss: 2.2776 - accuracy: 0.0978
on_train_batch_begin: 1615679083.183152s

28 step training time: 0.326296s

on_train_batch_end: 1615679083.505023s

29696/50000 [================>.............] - ETA: 6s - loss: 2.2643 - accuracy: 0.0978
on_train_batch_begin: 1615679083.505286s

29 step training time: 0.322134s

on_train_batch_end: 1615679083.828708s

30720/50000 [=================>............] - ETA: 6s - loss: 2.2488 - accuracy: 0.0979
on_train_batch_begin: 1615679083.828998s

30 step training time: 0.323712s

on_train_batch_end: 1615679084.152872s

31744/50000 [==================>...........] - ETA: 5s - loss: 2.2306 - accuracy: 0.0980
on_train_batch_begin: 1615679084.153149s

31 step training time: 0.324151s

on_train_batch_end: 1615679084.475676s

32768/50000 [==================>...........] - ETA: 5s - loss: 2.2149 - accuracy: 0.0981
on_train_batch_begin: 1615679084.475947s

32 step training time: 0.322799s

on_train_batch_end: 1615679084.799500s

33792/50000 [===================>..........] - ETA: 5s - loss: 2.1978 - accuracy: 0.0981
on_train_batch_begin: 1615679084.799785s

33 step training time: 0.323838s

on_train_batch_end: 1615679085.124097s

34816/50000 [===================>..........] - ETA: 4s - loss: 2.1843 - accuracy: 0.0982
on_train_batch_begin: 1615679085.124366s

34 step training time: 0.324581s

on_train_batch_end: 1615679085.448209s

35840/50000 [====================>.........] - ETA: 4s - loss: 2.1718 - accuracy: 0.0982
on_train_batch_begin: 1615679085.448500s

35 step training time: 0.324134s

on_train_batch_end: 1615679085.772855s

36864/50000 [=====================>........] - ETA: 4s - loss: 2.1573 - accuracy: 0.0983
on_train_batch_begin: 1615679085.773153s

36 step training time: 0.324653s

on_train_batch_end: 1615679086.096936s

37888/50000 [=====================>........] - ETA: 3s - loss: 2.1426 - accuracy: 0.0983
on_train_batch_begin: 1615679086.097223s

37 step training time: 0.324070s

on_train_batch_end: 1615679086.420800s

38912/50000 [======================>.......] - ETA: 3s - loss: 2.1291 - accuracy: 0.0983
on_train_batch_begin: 1615679086.421075s

38 step training time: 0.323852s

on_train_batch_end: 1615679086.744701s

39936/50000 [======================>.......] - ETA: 3s - loss: 2.1090 - accuracy: 0.0984
on_train_batch_begin: 1615679086.744962s

39 step training time: 0.323887s

on_train_batch_end: 1615679087.069418s

40960/50000 [=======================>......] - ETA: 2s - loss: 2.0954 - accuracy: 0.0984
on_train_batch_begin: 1615679087.069682s

40 step training time: 0.324720s

on_train_batch_end: 1615679087.394241s

41984/50000 [========================>.....] - ETA: 2s - loss: 2.0837 - accuracy: 0.0985
on_train_batch_begin: 1615679087.394510s

41 step training time: 0.324828s

on_train_batch_end: 1615679087.717934s

43008/50000 [========================>.....] - ETA: 2s - loss: 2.0694 - accuracy: 0.0985
on_train_batch_begin: 1615679087.718187s

42 step training time: 0.323677s

on_train_batch_end: 1615679088.041848s

44032/50000 [=========================>....] - ETA: 1s - loss: 2.0566 - accuracy: 0.0986
on_train_batch_begin: 1615679088.042138s

43 step training time: 0.323951s

on_train_batch_end: 1615679088.366013s

45056/50000 [==========================>...] - ETA: 1s - loss: 2.0435 - accuracy: 0.0986
on_train_batch_begin: 1615679088.366297s

44 step training time: 0.324159s

on_train_batch_end: 1615679088.690520s

46080/50000 [==========================>...] - ETA: 1s - loss: 2.0303 - accuracy: 0.0987
on_train_batch_begin: 1615679088.690773s

45 step training time: 0.324476s

on_train_batch_end: 1615679089.014974s

47104/50000 [===========================>..] - ETA: 0s - loss: 2.0179 - accuracy: 0.0987
on_train_batch_begin: 1615679089.015247s

46 step training time: 0.324474s

on_train_batch_end: 1615679089.339741s

48128/50000 [===========================>..] - ETA: 0s - loss: 2.0062 - accuracy: 0.0987
on_train_batch_begin: 1615679089.340010s

47 step training time: 0.324764s

on_train_batch_end: 1615679089.662703s

49152/50000 [============================>.] - ETA: 0s - loss: 1.9959 - accuracy: 0.0988
on_train_batch_begin: 1615679089.662951s

48 step training time: 0.322940s

on_train_batch_end: 1615679089.936517s

on_test_batch_begin: 1615679089.950587s

49 step training time: 0.287636s

on_epoch_end: 1615679090.732367s

Validation time: 0.781769s

Real time: 1615679090.732367s

Epoch time: 16.65041756629944s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.9844 - accuracy: 0.0988 - val_loss: 6.9605 - val_accuracy: 0.1000

on_epoch_begin: 1615679090.732547s

Real time: 1615679090.7325513
Epoch 5/5

on_train_batch_begin: 1615679090.735754s

on_train_batch_end: 1615679091.062092s

 1024/50000 [..............................] - ETA: 15s - loss: 1.1437 - accuracy: 0.1015
on_train_batch_begin: 1615679091.062338s

1 step training time: 0.326583s

on_train_batch_end: 1615679091.388301s

 2048/50000 [>.............................] - ETA: 15s - loss: 1.2416 - accuracy: 0.1009
on_train_batch_begin: 1615679091.388580s

2 step training time: 0.326242s

on_train_batch_end: 1615679091.713744s

 3072/50000 [>.............................] - ETA: 14s - loss: 1.1723 - accuracy: 0.1009
on_train_batch_begin: 1615679091.713988s

3 step training time: 0.325408s

on_train_batch_end: 1615679092.038706s

 4096/50000 [=>............................] - ETA: 14s - loss: 1.1820 - accuracy: 0.1008
on_train_batch_begin: 1615679092.039024s

4 step training time: 0.325036s

on_train_batch_end: 1615679092.364097s

 5120/50000 [==>...........................] - ETA: 14s - loss: 1.1817 - accuracy: 0.1008
on_train_batch_begin: 1615679092.364374s

5 step training time: 0.325350s

on_train_batch_end: 1615679092.689589s

 6144/50000 [==>...........................] - ETA: 13s - loss: 1.1589 - accuracy: 0.1007
on_train_batch_begin: 1615679092.689842s

6 step training time: 0.325468s

on_train_batch_end: 1615679093.016276s

 7168/50000 [===>..........................] - ETA: 13s - loss: 1.1640 - accuracy: 0.1007
on_train_batch_begin: 1615679093.016659s

7 step training time: 0.326818s

on_train_batch_end: 1615679093.341051s

 8192/50000 [===>..........................] - ETA: 13s - loss: 1.1656 - accuracy: 0.1006
on_train_batch_begin: 1615679093.341311s

8 step training time: 0.324652s

on_train_batch_end: 1615679093.663371s

 9216/50000 [====>.........................] - ETA: 12s - loss: 1.1623 - accuracy: 0.1005
on_train_batch_begin: 1615679093.663628s

9 step training time: 0.322317s

on_train_batch_end: 1615679093.988590s

10240/50000 [=====>........................] - ETA: 12s - loss: 1.1612 - accuracy: 0.1005
on_train_batch_begin: 1615679093.988877s

10 step training time: 0.325249s

on_train_batch_end: 1615679094.313612s

11264/50000 [=====>........................] - ETA: 12s - loss: 1.1645 - accuracy: 0.1005
on_train_batch_begin: 1615679094.313896s

11 step training time: 0.325019s

on_train_batch_end: 1615679094.636704s

12288/50000 [======>.......................] - ETA: 11s - loss: 1.1644 - accuracy: 0.1005
on_train_batch_begin: 1615679094.636958s

12 step training time: 0.323062s

on_train_batch_end: 1615679094.961014s

13312/50000 [======>.......................] - ETA: 11s - loss: 1.1543 - accuracy: 0.1005
on_train_batch_begin: 1615679094.961281s

13 step training time: 0.324323s

on_train_batch_end: 1615679095.285455s

14336/50000 [=======>......................] - ETA: 11s - loss: 1.1407 - accuracy: 0.1005
on_train_batch_begin: 1615679095.285737s

14 step training time: 0.324456s

on_train_batch_end: 1615679095.610173s

15360/50000 [========>.....................] - ETA: 11s - loss: 1.1418 - accuracy: 0.1004
on_train_batch_begin: 1615679095.610448s

15 step training time: 0.324710s

on_train_batch_end: 1615679095.934956s

16384/50000 [========>.....................] - ETA: 10s - loss: 1.1487 - accuracy: 0.1004
on_train_batch_begin: 1615679095.935215s

16 step training time: 0.324767s

on_train_batch_end: 1615679096.260611s

17408/50000 [=========>....................] - ETA: 10s - loss: 1.1451 - accuracy: 0.1004
on_train_batch_begin: 1615679096.260901s

17 step training time: 0.325687s

on_train_batch_end: 1615679096.584235s

18432/50000 [==========>...................] - ETA: 10s - loss: 1.1490 - accuracy: 0.1004
on_train_batch_begin: 1615679096.584491s

18 step training time: 0.323590s

on_train_batch_end: 1615679096.908829s

19456/50000 [==========>...................] - ETA: 9s - loss: 1.1448 - accuracy: 0.1004 
on_train_batch_begin: 1615679096.909095s

19 step training time: 0.324604s

on_train_batch_end: 1615679097.233881s

20480/50000 [===========>..................] - ETA: 9s - loss: 1.1405 - accuracy: 0.1004
on_train_batch_begin: 1615679097.234138s

20 step training time: 0.325042s

on_train_batch_end: 1615679097.557758s

21504/50000 [===========>..................] - ETA: 9s - loss: 1.1372 - accuracy: 0.1004
on_train_batch_begin: 1615679097.558008s

21 step training time: 0.323870s

on_train_batch_end: 1615679097.881942s

22528/50000 [============>.................] - ETA: 8s - loss: 1.1348 - accuracy: 0.1004
on_train_batch_begin: 1615679097.882203s

22 step training time: 0.324196s

on_train_batch_end: 1615679098.206698s

23552/50000 [=============>................] - ETA: 8s - loss: 1.1392 - accuracy: 0.1004
on_train_batch_begin: 1615679098.206991s

23 step training time: 0.324788s

on_train_batch_end: 1615679098.531981s

24576/50000 [=============>................] - ETA: 8s - loss: 1.1331 - accuracy: 0.1004
on_train_batch_begin: 1615679098.532278s

24 step training time: 0.325286s

on_train_batch_end: 1615679098.856607s

25600/50000 [==============>...............] - ETA: 7s - loss: 1.1301 - accuracy: 0.1004
on_train_batch_begin: 1615679098.856850s

25 step training time: 0.324573s

on_train_batch_end: 1615679099.182059s

26624/50000 [==============>...............] - ETA: 7s - loss: 1.1350 - accuracy: 0.1004
on_train_batch_begin: 1615679099.182306s

26 step training time: 0.325455s

on_train_batch_end: 1615679099.507704s

27648/50000 [===============>..............] - ETA: 7s - loss: 1.1334 - accuracy: 0.1004
on_train_batch_begin: 1615679099.507977s

27 step training time: 0.325671s

on_train_batch_end: 1615679099.832298s

28672/50000 [================>.............] - ETA: 6s - loss: 1.1284 - accuracy: 0.1004
on_train_batch_begin: 1615679099.832584s

28 step training time: 0.324607s

on_train_batch_end: 1615679100.156564s

29696/50000 [================>.............] - ETA: 6s - loss: 1.1277 - accuracy: 0.1004
on_train_batch_begin: 1615679100.156857s

29 step training time: 0.324273s

on_train_batch_end: 1615679100.481631s

30720/50000 [=================>............] - ETA: 6s - loss: 1.1231 - accuracy: 0.1004
on_train_batch_begin: 1615679100.481912s

30 step training time: 0.325056s

on_train_batch_end: 1615679100.806268s

31744/50000 [==================>...........] - ETA: 5s - loss: 1.1217 - accuracy: 0.1004
on_train_batch_begin: 1615679100.806549s

31 step training time: 0.324637s

on_train_batch_end: 1615679101.129627s

32768/50000 [==================>...........] - ETA: 5s - loss: 1.1180 - accuracy: 0.1004
on_train_batch_begin: 1615679101.129916s

32 step training time: 0.323367s

on_train_batch_end: 1615679101.454178s

33792/50000 [===================>..........] - ETA: 5s - loss: 1.1161 - accuracy: 0.1004
on_train_batch_begin: 1615679101.454454s

33 step training time: 0.324538s

on_train_batch_end: 1615679101.779592s

34816/50000 [===================>..........] - ETA: 4s - loss: 1.1124 - accuracy: 0.1004
on_train_batch_begin: 1615679101.779909s

34 step training time: 0.325456s

on_train_batch_end: 1615679102.103780s

35840/50000 [====================>.........] - ETA: 4s - loss: 1.1066 - accuracy: 0.1004
on_train_batch_begin: 1615679102.104071s

35 step training time: 0.324162s

on_train_batch_end: 1615679102.429180s

36864/50000 [=====================>........] - ETA: 4s - loss: 1.1034 - accuracy: 0.1004
on_train_batch_begin: 1615679102.429485s

36 step training time: 0.325414s

on_train_batch_end: 1615679102.754236s

37888/50000 [=====================>........] - ETA: 3s - loss: 1.1042 - accuracy: 0.1004
on_train_batch_begin: 1615679102.754529s

37 step training time: 0.325044s

on_train_batch_end: 1615679103.079025s

38912/50000 [======================>.......] - ETA: 3s - loss: 1.1002 - accuracy: 0.1004
on_train_batch_begin: 1615679103.079313s

38 step training time: 0.324783s

on_train_batch_end: 1615679103.403505s

39936/50000 [======================>.......] - ETA: 3s - loss: 1.0979 - accuracy: 0.1004
on_train_batch_begin: 1615679103.403802s

39 step training time: 0.324489s

on_train_batch_end: 1615679103.727217s

40960/50000 [=======================>......] - ETA: 2s - loss: 1.0940 - accuracy: 0.1004
on_train_batch_begin: 1615679103.727557s

40 step training time: 0.323755s

on_train_batch_end: 1615679104.053000s

41984/50000 [========================>.....] - ETA: 2s - loss: 1.0925 - accuracy: 0.1004
on_train_batch_begin: 1615679104.053316s

41 step training time: 0.325758s

on_train_batch_end: 1615679104.379645s

43008/50000 [========================>.....] - ETA: 2s - loss: 1.0904 - accuracy: 0.1004
on_train_batch_begin: 1615679104.380032s

42 step training time: 0.326716s

on_train_batch_end: 1615679104.703615s

44032/50000 [=========================>....] - ETA: 1s - loss: 1.0877 - accuracy: 0.1004
on_train_batch_begin: 1615679104.703903s

43 step training time: 0.323871s

on_train_batch_end: 1615679105.027325s

45056/50000 [==========================>...] - ETA: 1s - loss: 1.0882 - accuracy: 0.1004
on_train_batch_begin: 1615679105.027606s

44 step training time: 0.323703s

on_train_batch_end: 1615679105.351533s

46080/50000 [==========================>...] - ETA: 1s - loss: 1.0856 - accuracy: 0.1004
on_train_batch_begin: 1615679105.351809s

45 step training time: 0.324203s

on_train_batch_end: 1615679105.675386s

47104/50000 [===========================>..] - ETA: 0s - loss: 1.0828 - accuracy: 0.1004
on_train_batch_begin: 1615679105.675647s

46 step training time: 0.323838s

on_train_batch_end: 1615679105.999625s

48128/50000 [===========================>..] - ETA: 0s - loss: 1.0805 - accuracy: 0.1004
on_train_batch_begin: 1615679105.999881s

47 step training time: 0.324234s

on_train_batch_end: 1615679106.323503s

49152/50000 [============================>.] - ETA: 0s - loss: 1.0785 - accuracy: 0.1004
on_train_batch_begin: 1615679106.323793s

48 step training time: 0.323912s

on_train_batch_end: 1615679106.595443s

on_test_batch_begin: 1615679106.607531s

49 step training time: 0.283739s

on_epoch_end: 1615679107.381947s

Validation time: 0.774405s

Real time: 1615679107.381947s

Epoch time: 16.64941167831421s

50000/50000 [==============================] - 17s 333us/sample - loss: 1.0776 - accuracy: 0.1004 - val_loss: 7.3013 - val_accuracy: 0.0999
Tempo do fit: 112.37581086158752