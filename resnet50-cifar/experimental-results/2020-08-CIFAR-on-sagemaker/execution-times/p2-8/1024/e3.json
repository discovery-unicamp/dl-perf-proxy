{
    "init": -1.0,
    "total_training": 224.21572184562683,
    "largest_real_time_delta": 220.2147536277771,
    "fit_time": 224.21572184562683,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 136.951482,
                "2": 0.251719,
                "3": 0.230592,
                "4": 0.206896,
                "5": 0.207749,
                "6": 0.248662,
                "7": 0.24827,
                "8": 0.243948,
                "9": 0.204633,
                "10": 0.20637,
                "11": 0.206588,
                "12": 0.242541,
                "13": 0.235117,
                "14": 0.246607,
                "15": 0.229792,
                "16": 0.207201,
                "17": 0.246841,
                "18": 0.229364,
                "19": 0.204908,
                "20": 0.205812,
                "21": 0.207105,
                "22": 0.204905,
                "23": 0.246113,
                "24": 0.246062,
                "25": 0.205288,
                "26": 0.205862,
                "27": 0.20406,
                "28": 0.205967,
                "29": 0.205604,
                "30": 0.206477,
                "31": 0.20723,
                "32": 0.207366,
                "33": 0.246153,
                "34": 0.231584,
                "35": 0.206688,
                "36": 0.207766,
                "37": 0.208537,
                "38": 0.20531,
                "39": 0.251389,
                "40": 0.266001,
                "41": 0.237642,
                "42": 0.207972,
                "43": 0.204877,
                "44": 0.206194,
                "45": 0.206529,
                "46": 0.206119,
                "47": 0.204455,
                "48": 0.24753,
                "49": 7.970658
            },
            "validation_time": 16.338434,
            "epoch_time": 172.73899102210999,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.207658,
                "2": 0.204649,
                "3": 0.207223,
                "4": 0.207027,
                "5": 0.205806,
                "6": 0.205782,
                "7": 0.242971,
                "8": 0.245403,
                "9": 0.206906,
                "10": 0.205571,
                "11": 0.207641,
                "12": 0.207934,
                "13": 0.207836,
                "14": 0.244474,
                "15": 0.232155,
                "16": 0.20576,
                "17": 0.250507,
                "18": 0.229053,
                "19": 0.206764,
                "20": 0.205759,
                "21": 0.248141,
                "22": 0.229358,
                "23": 0.246073,
                "24": 0.24415,
                "25": 0.206697,
                "26": 0.24938,
                "27": 0.230519,
                "28": 0.205266,
                "29": 0.246496,
                "30": 0.231896,
                "31": 0.20522,
                "32": 0.248068,
                "33": 0.238122,
                "34": 0.206266,
                "35": 0.247259,
                "36": 0.244233,
                "37": 0.205466,
                "38": 0.246474,
                "39": 0.254926,
                "40": 0.244671,
                "41": 0.243376,
                "42": 0.232029,
                "43": 0.244851,
                "44": 0.243661,
                "45": 0.205981,
                "46": 0.205245,
                "47": 0.245023,
                "48": 0.241942,
                "49": 0.235672
            },
            "validation_time": 0.507117,
            "epoch_time": 11.629103183746338,
            "validation_accuracy": 0.0
        },
        "3": {
            "steps": {
                "1": 0.246493,
                "2": 0.232468,
                "3": 0.205702,
                "4": 0.207019,
                "5": 0.205978,
                "6": 0.24278,
                "7": 0.238425,
                "8": 0.205734,
                "9": 0.208562,
                "10": 0.208135,
                "11": 0.24569,
                "12": 0.235396,
                "13": 0.206412,
                "14": 0.246125,
                "15": 0.236507,
                "16": 0.206027,
                "17": 0.206948,
                "18": 0.205949,
                "19": 0.205272,
                "20": 0.246687,
                "21": 0.230065,
                "22": 0.205558,
                "23": 0.247385,
                "24": 0.232474,
                "25": 0.205343,
                "26": 0.246028,
                "27": 0.254139,
                "28": 0.258036,
                "29": 0.232025,
                "30": 0.206918,
                "31": 0.205137,
                "32": 0.204477,
                "33": 0.247669,
                "34": 0.231774,
                "35": 0.207042,
                "36": 0.249336,
                "37": 0.231484,
                "38": 0.208267,
                "39": 0.244797,
                "40": 0.232979,
                "41": 0.243658,
                "42": 0.234755,
                "43": 0.205325,
                "44": 0.244466,
                "45": 0.230803,
                "46": 0.245332,
                "47": 0.239481,
                "48": 0.244786,
                "49": 0.259466
            },
            "validation_time": 0.509015,
            "epoch_time": 11.688607454299927,
            "validation_accuracy": 0.0
        },
        "4": {
            "steps": {
                "1": 0.249141,
                "2": 0.22939,
                "3": 0.205816,
                "4": 0.207945,
                "5": 0.246135,
                "6": 0.252862,
                "7": 0.235338,
                "8": 0.20591,
                "9": 0.207289,
                "10": 0.206576,
                "11": 0.206361,
                "12": 0.206474,
                "13": 0.20707,
                "14": 0.207526,
                "15": 0.2482,
                "16": 0.236901,
                "17": 0.20429,
                "18": 0.248503,
                "19": 0.233993,
                "20": 0.247324,
                "21": 0.233187,
                "22": 0.205858,
                "23": 0.248731,
                "24": 0.233162,
                "25": 0.208017,
                "26": 0.204847,
                "27": 0.207365,
                "28": 0.246212,
                "29": 0.232396,
                "30": 0.246917,
                "31": 0.236145,
                "32": 0.246223,
                "33": 0.23372,
                "34": 0.244543,
                "35": 0.234651,
                "36": 0.249596,
                "37": 0.232749,
                "38": 0.245034,
                "39": 0.234892,
                "40": 0.248031,
                "41": 0.232757,
                "42": 0.205403,
                "43": 0.250698,
                "44": 0.231725,
                "45": 0.245761,
                "46": 0.252211,
                "47": 0.235232,
                "48": 0.246629,
                "49": 0.27529
            },
            "validation_time": 0.512676,
            "epoch_time": 11.862341165542603,
            "validation_accuracy": 0.0999
        },
        "5": {
            "steps": {
                "1": 0.249991,
                "2": 0.252145,
                "3": 0.237426,
                "4": 0.205396,
                "5": 0.248379,
                "6": 0.233139,
                "7": 0.248363,
                "8": 0.234558,
                "9": 0.2074,
                "10": 0.247839,
                "11": 0.238918,
                "12": 0.249298,
                "13": 0.25193,
                "14": 0.255901,
                "15": 0.255543,
                "16": 0.232426,
                "17": 0.206842,
                "18": 0.248838,
                "19": 0.253784,
                "20": 0.232661,
                "21": 0.245634,
                "22": 0.233003,
                "23": 0.208361,
                "24": 0.248644,
                "25": 0.231796,
                "26": 0.206679,
                "27": 0.248763,
                "28": 0.232311,
                "29": 0.249486,
                "30": 0.25411,
                "31": 0.234987,
                "32": 0.246949,
                "33": 0.234334,
                "34": 0.248645,
                "35": 0.236308,
                "36": 0.246607,
                "37": 0.255066,
                "38": 0.254999,
                "39": 0.254869,
                "40": 0.253218,
                "41": 0.230258,
                "42": 0.207048,
                "43": 0.248694,
                "44": 0.25451,
                "45": 0.23284,
                "46": 0.249308,
                "47": 0.232287,
                "48": 0.247235,
                "49": 0.257576
            },
            "validation_time": 0.510823,
            "epoch_time": 12.294596672058105,
            "validation_accuracy": 0.0999
        }
    },
    "computing_system": "p2-8",
    "batch_size": "1024"
}
