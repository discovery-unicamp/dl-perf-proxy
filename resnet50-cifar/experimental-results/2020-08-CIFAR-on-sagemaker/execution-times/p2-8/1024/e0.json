{
    "init": -1.0,
    "total_training": 219.98134803771973,
    "largest_real_time_delta": 216.16466903686523,
    "fit_time": 219.98134803771973,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 130.421261,
                "2": 0.250871,
                "3": 0.228566,
                "4": 0.246137,
                "5": 0.229483,
                "6": 0.204362,
                "7": 0.248038,
                "8": 0.234648,
                "9": 0.247274,
                "10": 0.227379,
                "11": 0.24613,
                "12": 0.228814,
                "13": 0.24601,
                "14": 0.248346,
                "15": 0.247733,
                "16": 0.254082,
                "17": 0.250379,
                "18": 0.248031,
                "19": 0.249506,
                "20": 0.254102,
                "21": 0.2507,
                "22": 0.248235,
                "23": 0.24882,
                "24": 0.237497,
                "25": 0.245726,
                "26": 0.230511,
                "27": 0.245712,
                "28": 0.254997,
                "29": 0.251141,
                "30": 0.247256,
                "31": 0.246507,
                "32": 0.235104,
                "33": 0.249633,
                "34": 0.227114,
                "35": 0.246979,
                "36": 0.22966,
                "37": 0.246678,
                "38": 0.24724,
                "39": 0.249264,
                "40": 0.254383,
                "41": 0.25099,
                "42": 0.24677,
                "43": 0.250006,
                "44": 0.253758,
                "45": 0.251276,
                "46": 0.247066,
                "47": 0.249131,
                "48": 0.254743,
                "49": 7.62359
            },
            "validation_time": 14.771088,
            "epoch_time": 165.35210347175598
        },
        "2": {
            "steps": {
                "1": 0.248901,
                "2": 0.230017,
                "3": 0.248561,
                "4": 0.22872,
                "5": 0.246985,
                "6": 0.229654,
                "7": 0.248775,
                "8": 0.228884,
                "9": 0.248235,
                "10": 0.251109,
                "11": 0.248464,
                "12": 0.248799,
                "13": 0.251158,
                "14": 0.248968,
                "15": 0.248007,
                "16": 0.248703,
                "17": 0.251341,
                "18": 0.247941,
                "19": 0.250082,
                "20": 0.247705,
                "21": 0.250202,
                "22": 0.25144,
                "23": 0.248257,
                "24": 0.247613,
                "25": 0.250377,
                "26": 0.251363,
                "27": 0.250412,
                "28": 0.248729,
                "29": 0.25242,
                "30": 0.250378,
                "31": 0.250154,
                "32": 0.248625,
                "33": 0.251491,
                "34": 0.250179,
                "35": 0.248868,
                "36": 0.250143,
                "37": 0.250124,
                "38": 0.25078,
                "39": 0.250248,
                "40": 0.248915,
                "41": 0.251962,
                "42": 0.250263,
                "43": 0.247098,
                "44": 0.248243,
                "45": 0.2519,
                "46": 0.249637,
                "47": 0.24831,
                "48": 0.249514,
                "49": 0.275094
            },
            "validation_time": 0.499022,
            "epoch_time": 12.680621147155762
        },
        "3": {
            "steps": {
                "1": 0.251254,
                "2": 0.228348,
                "3": 0.248329,
                "4": 0.229581,
                "5": 0.248186,
                "6": 0.255231,
                "7": 0.250787,
                "8": 0.246603,
                "9": 0.249637,
                "10": 0.252396,
                "11": 0.250578,
                "12": 0.24719,
                "13": 0.250792,
                "14": 0.251535,
                "15": 0.250879,
                "16": 0.247804,
                "17": 0.250129,
                "18": 0.252131,
                "19": 0.250274,
                "20": 0.248545,
                "21": 0.25148,
                "22": 0.250337,
                "23": 0.250903,
                "24": 0.247537,
                "25": 0.250105,
                "26": 0.250429,
                "27": 0.249437,
                "28": 0.249908,
                "29": 0.250399,
                "30": 0.250836,
                "31": 0.250402,
                "32": 0.247718,
                "33": 0.249904,
                "34": 0.252573,
                "35": 0.251065,
                "36": 0.249568,
                "37": 0.25042,
                "38": 0.252004,
                "39": 0.25033,
                "40": 0.247981,
                "41": 0.248622,
                "42": 0.249771,
                "43": 0.249818,
                "44": 0.249419,
                "45": 0.251057,
                "46": 0.249952,
                "47": 0.249942,
                "48": 0.226357,
                "49": 0.268946
            },
            "validation_time": 0.500757,
            "epoch_time": 12.716126918792725
        },
        "4": {
            "steps": {
                "1": 0.249715,
                "2": 0.229424,
                "3": 0.249466,
                "4": 0.24752,
                "5": 0.250619,
                "6": 0.226892,
                "7": 0.249044,
                "8": 0.226599,
                "9": 0.247512,
                "10": 0.231068,
                "11": 0.247985,
                "12": 0.227268,
                "13": 0.247529,
                "14": 0.252699,
                "15": 0.249743,
                "16": 0.249721,
                "17": 0.251576,
                "18": 0.250137,
                "19": 0.249029,
                "20": 0.249206,
                "21": 0.251759,
                "22": 0.251703,
                "23": 0.249916,
                "24": 0.248644,
                "25": 0.252929,
                "26": 0.248453,
                "27": 0.250761,
                "28": 0.247449,
                "29": 0.252151,
                "30": 0.249597,
                "31": 0.249869,
                "32": 0.250258,
                "33": 0.250928,
                "34": 0.24851,
                "35": 0.249796,
                "36": 0.248555,
                "37": 0.251822,
                "38": 0.247353,
                "39": 0.250347,
                "40": 0.249604,
                "41": 0.252455,
                "42": 0.247565,
                "43": 0.250736,
                "44": 0.248662,
                "45": 0.250429,
                "46": 0.248992,
                "47": 0.24927,
                "48": 0.249789,
                "49": 0.269906
            },
            "validation_time": 0.500362,
            "epoch_time": 12.65923547744751
        },
        "5": {
            "steps": {
                "1": 0.251058,
                "2": 0.226885,
                "3": 0.249778,
                "4": 0.229415,
                "5": 0.250433,
                "6": 0.250784,
                "7": 0.251561,
                "8": 0.248207,
                "9": 0.250643,
                "10": 0.250308,
                "11": 0.251131,
                "12": 0.248737,
                "13": 0.25043,
                "14": 0.248217,
                "15": 0.250339,
                "16": 0.245546,
                "17": 0.250703,
                "18": 0.249424,
                "19": 0.251479,
                "20": 0.244742,
                "21": 0.250752,
                "22": 0.250019,
                "23": 0.251753,
                "24": 0.251092,
                "25": 0.250025,
                "26": 0.249624,
                "27": 0.250447,
                "28": 0.249645,
                "29": 0.249017,
                "30": 0.252915,
                "31": 0.25182,
                "32": 0.249016,
                "33": 0.251913,
                "34": 0.252618,
                "35": 0.25258,
                "36": 0.249176,
                "37": 0.250449,
                "38": 0.251707,
                "39": 0.251668,
                "40": 0.250188,
                "41": 0.250483,
                "42": 0.251698,
                "43": 0.250876,
                "44": 0.248916,
                "45": 0.251039,
                "46": 0.251304,
                "47": 0.250162,
                "48": 0.249363,
                "49": 0.276318
            },
            "validation_time": 0.501177,
            "epoch_time": 12.755589962005615
        }
    },
    "computing_system": "p2-8",
    "batch_size": "1024"
}
