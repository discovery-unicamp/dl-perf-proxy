{
    "init": -1.0,
    "total_training": 223.32858324050903,
    "largest_real_time_delta": 219.4284152984619,
    "fit_time": 223.32858324050903,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 133.821961,
                "2": 0.209509,
                "3": 0.248265,
                "4": 0.236766,
                "5": 0.246916,
                "6": 0.232217,
                "7": 0.206273,
                "8": 0.206991,
                "9": 0.250354,
                "10": 0.229987,
                "11": 0.206741,
                "12": 0.248855,
                "13": 0.230742,
                "14": 0.20577,
                "15": 0.24935,
                "16": 0.234518,
                "17": 0.206609,
                "18": 0.249032,
                "19": 0.230225,
                "20": 0.249929,
                "21": 0.228695,
                "22": 0.24913,
                "23": 0.23006,
                "24": 0.250649,
                "25": 0.229428,
                "26": 0.206621,
                "27": 0.250919,
                "28": 0.236639,
                "29": 0.20664,
                "30": 0.248998,
                "31": 0.232002,
                "32": 0.250872,
                "33": 0.229464,
                "34": 0.249537,
                "35": 0.229334,
                "36": 0.250409,
                "37": 0.229828,
                "38": 0.248706,
                "39": 0.232035,
                "40": 0.207457,
                "41": 0.249796,
                "42": 0.229949,
                "43": 0.252273,
                "44": 0.23639,
                "45": 0.247416,
                "46": 0.23146,
                "47": 0.251475,
                "48": 0.237019,
                "49": 7.528654
            },
            "validation_time": 16.187427,
            "epoch_time": 169.85489964485168,
            "validation_accuracy": 0.0999
        },
        "2": {
            "steps": {
                "1": 0.206992,
                "2": 0.205671,
                "3": 0.206235,
                "4": 0.249264,
                "5": 0.230431,
                "6": 0.252292,
                "7": 0.229245,
                "8": 0.250255,
                "9": 0.247724,
                "10": 0.254493,
                "11": 0.227532,
                "12": 0.208254,
                "13": 0.249968,
                "14": 0.231323,
                "15": 0.249826,
                "16": 0.232021,
                "17": 0.246514,
                "18": 0.231976,
                "19": 0.247357,
                "20": 0.231337,
                "21": 0.250138,
                "22": 0.250775,
                "23": 0.252645,
                "24": 0.228737,
                "25": 0.249607,
                "26": 0.231484,
                "27": 0.248538,
                "28": 0.231978,
                "29": 0.251598,
                "30": 0.230798,
                "31": 0.249666,
                "32": 0.230378,
                "33": 0.250502,
                "34": 0.232298,
                "35": 0.250913,
                "36": 0.231858,
                "37": 0.251446,
                "38": 0.250042,
                "39": 0.254431,
                "40": 0.230875,
                "41": 0.249296,
                "42": 0.233288,
                "43": 0.253205,
                "44": 0.229003,
                "45": 0.253608,
                "46": 0.231158,
                "47": 0.208262,
                "48": 0.250489,
                "49": 0.261044
            },
            "validation_time": 0.505607,
            "epoch_time": 12.230037689208984,
            "validation_accuracy": 0.0999
        },
        "3": {
            "steps": {
                "1": 0.25227,
                "2": 0.232284,
                "3": 0.249024,
                "4": 0.230306,
                "5": 0.207047,
                "6": 0.250664,
                "7": 0.227936,
                "8": 0.247971,
                "9": 0.234768,
                "10": 0.254047,
                "11": 0.228513,
                "12": 0.251405,
                "13": 0.229087,
                "14": 0.24998,
                "15": 0.228094,
                "16": 0.245533,
                "17": 0.254438,
                "18": 0.236842,
                "19": 0.24774,
                "20": 0.247353,
                "21": 0.253157,
                "22": 0.236552,
                "23": 0.249112,
                "24": 0.229197,
                "25": 0.249443,
                "26": 0.235554,
                "27": 0.251862,
                "28": 0.227436,
                "29": 0.250327,
                "30": 0.238174,
                "31": 0.252124,
                "32": 0.229303,
                "33": 0.20556,
                "34": 0.251169,
                "35": 0.227577,
                "36": 0.246826,
                "37": 0.233824,
                "38": 0.253206,
                "39": 0.227965,
                "40": 0.252223,
                "41": 0.250715,
                "42": 0.253874,
                "43": 0.248773,
                "44": 0.257113,
                "45": 0.228472,
                "46": 0.249307,
                "47": 0.231722,
                "48": 0.251175,
                "49": 0.258703
            },
            "validation_time": 0.502005,
            "epoch_time": 12.345690965652466,
            "validation_accuracy": 0.0999
        },
        "4": {
            "steps": {
                "1": 0.247572,
                "2": 0.250926,
                "3": 0.250674,
                "4": 0.230252,
                "5": 0.246606,
                "6": 0.234741,
                "7": 0.250287,
                "8": 0.228832,
                "9": 0.249624,
                "10": 0.230426,
                "11": 0.251113,
                "12": 0.236131,
                "13": 0.251026,
                "14": 0.251857,
                "15": 0.253373,
                "16": 0.22745,
                "17": 0.253013,
                "18": 0.2363,
                "19": 0.251161,
                "20": 0.232851,
                "21": 0.248701,
                "22": 0.234405,
                "23": 0.253232,
                "24": 0.24889,
                "25": 0.254669,
                "26": 0.234001,
                "27": 0.252093,
                "28": 0.249281,
                "29": 0.254128,
                "30": 0.2355,
                "31": 0.252144,
                "32": 0.234212,
                "33": 0.251748,
                "34": 0.230692,
                "35": 0.250821,
                "36": 0.229724,
                "37": 0.252539,
                "38": 0.233477,
                "39": 0.253964,
                "40": 0.22874,
                "41": 0.248885,
                "42": 0.233714,
                "43": 0.248448,
                "44": 0.230732,
                "45": 0.252245,
                "46": 0.233494,
                "47": 0.250199,
                "48": 0.230671,
                "49": 0.277906
            },
            "validation_time": 0.50742,
            "epoch_time": 12.46836805343628,
            "validation_accuracy": 0.0999
        },
        "5": {
            "steps": {
                "1": 0.251361,
                "2": 0.231448,
                "3": 0.251549,
                "4": 0.235844,
                "5": 0.250406,
                "6": 0.230164,
                "7": 0.25461,
                "8": 0.2287,
                "9": 0.250701,
                "10": 0.230908,
                "11": 0.252818,
                "12": 0.227464,
                "13": 0.25183,
                "14": 0.229504,
                "15": 0.248595,
                "16": 0.23493,
                "17": 0.252717,
                "18": 0.250357,
                "19": 0.254262,
                "20": 0.251115,
                "21": 0.256624,
                "22": 0.251994,
                "23": 0.253646,
                "24": 0.249517,
                "25": 0.255558,
                "26": 0.252091,
                "27": 0.253811,
                "28": 0.252125,
                "29": 0.254392,
                "30": 0.25306,
                "31": 0.255146,
                "32": 0.227073,
                "33": 0.251518,
                "34": 0.228375,
                "35": 0.250949,
                "36": 0.234627,
                "37": 0.252316,
                "38": 0.233169,
                "39": 0.252533,
                "40": 0.228961,
                "41": 0.250065,
                "42": 0.227435,
                "43": 0.251491,
                "44": 0.230129,
                "45": 0.250714,
                "46": 0.233319,
                "47": 0.252365,
                "48": 0.229666,
                "49": 0.269994
            },
            "validation_time": 0.508853,
            "epoch_time": 12.528462886810303,
            "validation_accuracy": 0.0999
        }
    },
    "computing_system": "p2-8",
    "batch_size": "1024"
}
