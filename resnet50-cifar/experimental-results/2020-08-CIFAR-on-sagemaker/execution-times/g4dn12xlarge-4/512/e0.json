{
    "init": -1.0,
    "total_training": 106.51476716995239,
    "largest_real_time_delta": 103.2202799320221,
    "fit_time": 106.51476716995239,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 45.673799,
                "2": 0.102445,
                "3": 0.100179,
                "4": 0.102538,
                "5": 0.100193,
                "6": 0.100182,
                "7": 0.100485,
                "8": 0.1008,
                "9": 0.101432,
                "10": 0.100696,
                "11": 0.099947,
                "12": 0.100549,
                "13": 0.102308,
                "14": 0.100683,
                "15": 0.10055,
                "16": 0.101591,
                "17": 0.099604,
                "18": 0.100203,
                "19": 0.099974,
                "20": 0.099225,
                "21": 0.099051,
                "22": 0.098941,
                "23": 0.09919,
                "24": 0.101601,
                "25": 0.101208,
                "26": 0.101246,
                "27": 0.10081,
                "28": 0.099685,
                "29": 0.099664,
                "30": 0.099356,
                "31": 0.099456,
                "32": 0.099372,
                "33": 0.099973,
                "34": 0.09956,
                "35": 0.098612,
                "36": 0.099299,
                "37": 0.099992,
                "38": 0.099014,
                "39": 0.101787,
                "40": 0.099467,
                "41": 0.099696,
                "42": 0.100063,
                "43": 0.09935,
                "44": 0.099496,
                "45": 0.100003,
                "46": 0.100806,
                "47": 0.100435,
                "48": 0.100161,
                "49": 0.099772,
                "50": 0.099906,
                "51": 0.102393,
                "52": 0.099709,
                "53": 0.101594,
                "54": 0.099899,
                "55": 0.102264,
                "56": 0.100137,
                "57": 0.100075,
                "58": 0.099828,
                "59": 0.100175,
                "60": 0.100427,
                "61": 0.101009,
                "62": 0.099352,
                "63": 0.099885,
                "64": 0.099412,
                "65": 0.09949,
                "66": 0.100838,
                "67": 0.101471,
                "68": 0.100023,
                "69": 0.100695,
                "70": 0.101134,
                "71": 0.100997,
                "72": 0.100181,
                "73": 0.099574,
                "74": 0.098978,
                "75": 0.099724,
                "76": 0.100129,
                "77": 0.100358,
                "78": 0.101196,
                "79": 0.098992,
                "80": 0.10043,
                "81": 0.100494,
                "82": 0.099805,
                "83": 0.100158,
                "84": 0.100123,
                "85": 0.100918,
                "86": 0.100625,
                "87": 0.100214,
                "88": 0.100376,
                "89": 0.100618,
                "90": 0.1,
                "91": 0.100202,
                "92": 0.100143,
                "93": 0.101104,
                "94": 0.099751,
                "95": 0.099202,
                "96": 0.099843,
                "97": 0.10011,
                "98": 1.552117
            },
            "validation_time": 4.501379,
            "epoch_time": 62.12814021110535,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.105602,
                "2": 0.099908,
                "3": 0.100263,
                "4": 0.099866,
                "5": 0.09944,
                "6": 0.101649,
                "7": 0.101757,
                "8": 0.100435,
                "9": 0.100689,
                "10": 0.099213,
                "11": 0.098943,
                "12": 0.100003,
                "13": 0.101225,
                "14": 0.098653,
                "15": 0.100136,
                "16": 0.102012,
                "17": 0.101014,
                "18": 0.100863,
                "19": 0.101176,
                "20": 0.10036,
                "21": 0.100742,
                "22": 0.101894,
                "23": 0.100315,
                "24": 0.100359,
                "25": 0.100211,
                "26": 0.102574,
                "27": 0.101228,
                "28": 0.101561,
                "29": 0.101229,
                "30": 0.101036,
                "31": 0.101081,
                "32": 0.101712,
                "33": 0.101521,
                "34": 0.10051,
                "35": 0.099809,
                "36": 0.102201,
                "37": 0.100537,
                "38": 0.099912,
                "39": 0.099983,
                "40": 0.099182,
                "41": 0.101024,
                "42": 0.105913,
                "43": 0.099773,
                "44": 0.101037,
                "45": 0.101176,
                "46": 0.102295,
                "47": 0.099715,
                "48": 0.099904,
                "49": 0.099179,
                "50": 0.100178,
                "51": 0.100742,
                "52": 0.100146,
                "53": 0.100378,
                "54": 0.100725,
                "55": 0.100366,
                "56": 0.10144,
                "57": 0.101603,
                "58": 0.101853,
                "59": 0.100603,
                "60": 0.101603,
                "61": 0.100289,
                "62": 0.100543,
                "63": 0.101088,
                "64": 0.099347,
                "65": 0.099749,
                "66": 0.100334,
                "67": 0.098964,
                "68": 0.099708,
                "69": 0.099596,
                "70": 0.099536,
                "71": 0.101485,
                "72": 0.101655,
                "73": 0.099676,
                "74": 0.10044,
                "75": 0.100694,
                "76": 0.100491,
                "77": 0.100457,
                "78": 0.100824,
                "79": 0.100194,
                "80": 0.101547,
                "81": 0.100496,
                "82": 0.099225,
                "83": 0.100044,
                "84": 0.100161,
                "85": 0.102685,
                "86": 0.099021,
                "87": 0.102177,
                "88": 0.101161,
                "89": 0.099727,
                "90": 0.099906,
                "91": 0.100977,
                "92": 0.100137,
                "93": 0.101422,
                "94": 0.101386,
                "95": 0.103086,
                "96": 0.100885,
                "97": 0.099322,
                "98": 0.107789
            },
            "validation_time": 0.372997,
            "epoch_time": 10.254091262817383,
            "validation_accuracy": 0.0997
        },
        "3": {
            "steps": {
                "1": 0.100611,
                "2": 0.099664,
                "3": 0.100603,
                "4": 0.099518,
                "5": 0.100229,
                "6": 0.099986,
                "7": 0.100588,
                "8": 0.101168,
                "9": 0.100437,
                "10": 0.100689,
                "11": 0.100384,
                "12": 0.10007,
                "13": 0.100938,
                "14": 0.100471,
                "15": 0.101909,
                "16": 0.10033,
                "17": 0.100329,
                "18": 0.101356,
                "19": 0.100781,
                "20": 0.100827,
                "21": 0.099806,
                "22": 0.100932,
                "23": 0.099534,
                "24": 0.098985,
                "25": 0.100466,
                "26": 0.099919,
                "27": 0.099983,
                "28": 0.099667,
                "29": 0.101547,
                "30": 0.099901,
                "31": 0.102026,
                "32": 0.103659,
                "33": 0.100378,
                "34": 0.101891,
                "35": 0.100317,
                "36": 0.101155,
                "37": 0.10018,
                "38": 0.100664,
                "39": 0.099892,
                "40": 0.100796,
                "41": 0.101041,
                "42": 0.099809,
                "43": 0.100221,
                "44": 0.100761,
                "45": 0.102336,
                "46": 0.10006,
                "47": 0.100315,
                "48": 0.099567,
                "49": 0.099939,
                "50": 0.099947,
                "51": 0.102357,
                "52": 0.099336,
                "53": 0.100281,
                "54": 0.100401,
                "55": 0.10168,
                "56": 0.101156,
                "57": 0.099746,
                "58": 0.099262,
                "59": 0.0999,
                "60": 0.101103,
                "61": 0.09924,
                "62": 0.099202,
                "63": 0.100961,
                "64": 0.100161,
                "65": 0.101852,
                "66": 0.100571,
                "67": 0.100402,
                "68": 0.100778,
                "69": 0.101522,
                "70": 0.102337,
                "71": 0.10169,
                "72": 0.101889,
                "73": 0.100833,
                "74": 0.100826,
                "75": 0.100556,
                "76": 0.10124,
                "77": 0.101222,
                "78": 0.09963,
                "79": 0.099971,
                "80": 0.099922,
                "81": 0.100523,
                "82": 0.099639,
                "83": 0.099288,
                "84": 0.100123,
                "85": 0.101468,
                "86": 0.100338,
                "87": 0.10007,
                "88": 0.100841,
                "89": 0.099962,
                "90": 0.100955,
                "91": 0.100135,
                "92": 0.099597,
                "93": 0.099849,
                "94": 0.101114,
                "95": 0.09961,
                "96": 0.102178,
                "97": 0.101295,
                "98": 0.109849
            },
            "validation_time": 0.371645,
            "epoch_time": 10.23938274383545,
            "validation_accuracy": 0.1
        },
        "4": {
            "steps": {
                "1": 0.103196,
                "2": 0.099273,
                "3": 0.101742,
                "4": 0.100931,
                "5": 0.101009,
                "6": 0.100094,
                "7": 0.101941,
                "8": 0.100399,
                "9": 0.100036,
                "10": 0.101455,
                "11": 0.104135,
                "12": 0.101268,
                "13": 0.100968,
                "14": 0.101072,
                "15": 0.10113,
                "16": 0.102407,
                "17": 0.100362,
                "18": 0.10121,
                "19": 0.10131,
                "20": 0.100794,
                "21": 0.099791,
                "22": 0.099661,
                "23": 0.10009,
                "24": 0.102279,
                "25": 0.099651,
                "26": 0.099142,
                "27": 0.099964,
                "28": 0.100847,
                "29": 0.102252,
                "30": 0.099848,
                "31": 0.100052,
                "32": 0.099988,
                "33": 0.101286,
                "34": 0.100515,
                "35": 0.100709,
                "36": 0.099766,
                "37": 0.098802,
                "38": 0.100926,
                "39": 0.100805,
                "40": 0.099862,
                "41": 0.099581,
                "42": 0.101849,
                "43": 0.100217,
                "44": 0.102895,
                "45": 0.100518,
                "46": 0.102278,
                "47": 0.100559,
                "48": 0.100618,
                "49": 0.100602,
                "50": 0.103208,
                "51": 0.10121,
                "52": 0.100234,
                "53": 0.100658,
                "54": 0.101997,
                "55": 0.102464,
                "56": 0.10083,
                "57": 0.100109,
                "58": 0.102379,
                "59": 0.100467,
                "60": 0.099893,
                "61": 0.099503,
                "62": 0.099921,
                "63": 0.100473,
                "64": 0.099714,
                "65": 0.100249,
                "66": 0.101793,
                "67": 0.100004,
                "68": 0.102465,
                "69": 0.099803,
                "70": 0.10216,
                "71": 0.100614,
                "72": 0.100072,
                "73": 0.10022,
                "74": 0.101112,
                "75": 0.100821,
                "76": 0.100306,
                "77": 0.10049,
                "78": 0.101101,
                "79": 0.100843,
                "80": 0.100771,
                "81": 0.102391,
                "82": 0.099834,
                "83": 0.09981,
                "84": 0.100026,
                "85": 0.099154,
                "86": 0.100027,
                "87": 0.100969,
                "88": 0.099784,
                "89": 0.101439,
                "90": 0.100001,
                "91": 0.1014,
                "92": 0.100559,
                "93": 0.101164,
                "94": 0.101073,
                "95": 0.107616,
                "96": 0.10066,
                "97": 0.099741,
                "98": 0.109314
            },
            "validation_time": 0.375177,
            "epoch_time": 10.270227432250977,
            "validation_accuracy": 0.1
        },
        "5": {
            "steps": {
                "1": 0.103193,
                "2": 0.100216,
                "3": 0.100191,
                "4": 0.101911,
                "5": 0.101063,
                "6": 0.102154,
                "7": 0.100454,
                "8": 0.101569,
                "9": 0.102625,
                "10": 0.101048,
                "11": 0.103202,
                "12": 0.102505,
                "13": 0.101437,
                "14": 0.101949,
                "15": 0.101844,
                "16": 0.100909,
                "17": 0.100912,
                "18": 0.102366,
                "19": 0.10222,
                "20": 0.101556,
                "21": 0.102989,
                "22": 0.102949,
                "23": 0.100981,
                "24": 0.101938,
                "25": 0.101725,
                "26": 0.099987,
                "27": 0.102458,
                "28": 0.101007,
                "29": 0.101032,
                "30": 0.1019,
                "31": 0.10127,
                "32": 0.100262,
                "33": 0.100779,
                "34": 0.101449,
                "35": 0.102453,
                "36": 0.100889,
                "37": 0.102753,
                "38": 0.101324,
                "39": 0.100273,
                "40": 0.100839,
                "41": 0.10264,
                "42": 0.101225,
                "43": 0.100979,
                "44": 0.101381,
                "45": 0.100832,
                "46": 0.100243,
                "47": 0.100197,
                "48": 0.10021,
                "49": 0.100285,
                "50": 0.100882,
                "51": 0.100473,
                "52": 0.101453,
                "53": 0.100017,
                "54": 0.101948,
                "55": 0.100542,
                "56": 0.102056,
                "57": 0.099794,
                "58": 0.10023,
                "59": 0.100642,
                "60": 0.101999,
                "61": 0.10162,
                "62": 0.101779,
                "63": 0.101758,
                "64": 0.102227,
                "65": 0.101359,
                "66": 0.102205,
                "67": 0.101552,
                "68": 0.100845,
                "69": 0.100939,
                "70": 0.102692,
                "71": 0.100718,
                "72": 0.100332,
                "73": 0.100612,
                "74": 0.10065,
                "75": 0.102013,
                "76": 0.101749,
                "77": 0.100653,
                "78": 0.101107,
                "79": 0.10251,
                "80": 0.101047,
                "81": 0.103239,
                "82": 0.102487,
                "83": 0.101359,
                "84": 0.100296,
                "85": 0.101741,
                "86": 0.100884,
                "87": 0.102938,
                "88": 0.100617,
                "89": 0.102735,
                "90": 0.100159,
                "91": 0.102811,
                "92": 0.100224,
                "93": 0.100268,
                "94": 0.101572,
                "95": 0.102915,
                "96": 0.09968,
                "97": 0.102366,
                "98": 0.109084
            },
            "validation_time": 0.377669,
            "epoch_time": 10.327703475952148,
            "validation_accuracy": 0.1001
        }
    },
    "computing_system": "g4dn12xlarge-4",
    "batch_size": "512"
}
