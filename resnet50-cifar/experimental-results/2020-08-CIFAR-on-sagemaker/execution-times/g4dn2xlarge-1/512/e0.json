{
    "init": -1.0,
    "total_training": 114.64009380340576,
    "largest_real_time_delta": 111.31376624107361,
    "fit_time": 114.64009380340576,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 15.420754,
                "2": 0.169105,
                "3": 0.167058,
                "4": 0.169503,
                "5": 0.168511,
                "6": 0.167434,
                "7": 0.170718,
                "8": 0.168116,
                "9": 0.16708,
                "10": 0.167261,
                "11": 0.170151,
                "12": 0.168731,
                "13": 0.16776,
                "14": 0.168041,
                "15": 0.169835,
                "16": 0.169354,
                "17": 0.161134,
                "18": 0.169114,
                "19": 0.168522,
                "20": 0.169197,
                "21": 0.169214,
                "22": 0.169452,
                "23": 0.168101,
                "24": 0.168839,
                "25": 0.167895,
                "26": 0.169827,
                "27": 0.168055,
                "28": 0.163529,
                "29": 0.168666,
                "30": 0.168808,
                "31": 0.168681,
                "32": 0.168698,
                "33": 0.167822,
                "34": 0.169573,
                "35": 0.168275,
                "36": 0.166483,
                "37": 0.168679,
                "38": 0.169991,
                "39": 0.169503,
                "40": 0.167719,
                "41": 0.169699,
                "42": 0.16763,
                "43": 0.167318,
                "44": 0.168242,
                "45": 0.169261,
                "46": 0.168495,
                "47": 0.169755,
                "48": 0.16943,
                "49": 0.169306,
                "50": 0.167375,
                "51": 0.1684,
                "52": 0.169589,
                "53": 0.168317,
                "54": 0.167724,
                "55": 0.17018,
                "56": 0.168348,
                "57": 0.168797,
                "58": 0.170339,
                "59": 0.168754,
                "60": 0.167628,
                "61": 0.169795,
                "62": 0.169127,
                "63": 0.169597,
                "64": 0.170208,
                "65": 0.169135,
                "66": 0.167887,
                "67": 0.169458,
                "68": 0.168669,
                "69": 0.167967,
                "70": 0.169108,
                "71": 0.171206,
                "72": 0.169276,
                "73": 0.169212,
                "74": 0.172086,
                "75": 0.169735,
                "76": 0.170968,
                "77": 0.169724,
                "78": 0.168335,
                "79": 0.171236,
                "80": 0.169075,
                "81": 0.167877,
                "82": 0.171397,
                "83": 0.171661,
                "84": 0.168708,
                "85": 0.170835,
                "86": 0.169883,
                "87": 0.170204,
                "88": 0.16998,
                "89": 0.169527,
                "90": 0.170369,
                "91": 0.1703,
                "92": 0.169575,
                "93": 0.171184,
                "94": 0.168184,
                "95": 0.169447,
                "96": 0.1713,
                "97": 0.169747,
                "98": 3.956822
            },
            "validation_time": 3.987821,
            "epoch_time": 40.32477426528931,
            "validation_accuracy": 0.0933
        },
        "2": {
            "steps": {
                "1": 0.168969,
                "2": 0.170885,
                "3": 0.170374,
                "4": 0.158422,
                "5": 0.170876,
                "6": 0.177653,
                "7": 0.170361,
                "8": 0.172089,
                "9": 0.169488,
                "10": 0.17144,
                "11": 0.1617,
                "12": 0.173254,
                "13": 0.170678,
                "14": 0.172169,
                "15": 0.170663,
                "16": 0.172666,
                "17": 0.169792,
                "18": 0.168417,
                "19": 0.170287,
                "20": 0.169277,
                "21": 0.171693,
                "22": 0.169758,
                "23": 0.168923,
                "24": 0.172016,
                "25": 0.169414,
                "26": 0.169011,
                "27": 0.170914,
                "28": 0.17132,
                "29": 0.172191,
                "30": 0.169517,
                "31": 0.170163,
                "32": 0.171016,
                "33": 0.169592,
                "34": 0.172755,
                "35": 0.17073,
                "36": 0.168961,
                "37": 0.170922,
                "38": 0.171323,
                "39": 0.17204,
                "40": 0.170755,
                "41": 0.171906,
                "42": 0.170903,
                "43": 0.169863,
                "44": 0.171245,
                "45": 0.1702,
                "46": 0.170354,
                "47": 0.17096,
                "48": 0.171252,
                "49": 0.171512,
                "50": 0.171105,
                "51": 0.171458,
                "52": 0.171189,
                "53": 0.17038,
                "54": 0.171571,
                "55": 0.170358,
                "56": 0.171225,
                "57": 0.172085,
                "58": 0.171028,
                "59": 0.169044,
                "60": 0.169827,
                "61": 0.1713,
                "62": 0.17031,
                "63": 0.173419,
                "64": 0.17176,
                "65": 0.172086,
                "66": 0.170498,
                "67": 0.169483,
                "68": 0.171326,
                "69": 0.16865,
                "70": 0.1727,
                "71": 0.171623,
                "72": 0.173005,
                "73": 0.170236,
                "74": 0.171246,
                "75": 0.172282,
                "76": 0.170941,
                "77": 0.171221,
                "78": 0.171352,
                "79": 0.171498,
                "80": 0.171575,
                "81": 0.172574,
                "82": 0.170894,
                "83": 0.173202,
                "84": 0.171908,
                "85": 0.170881,
                "86": 0.172058,
                "87": 0.169891,
                "88": 0.172663,
                "89": 0.170982,
                "90": 0.172094,
                "91": 0.17157,
                "92": 0.17146,
                "93": 0.170941,
                "94": 0.169629,
                "95": 0.171884,
                "96": 0.169294,
                "97": 0.174212,
                "98": 0.130209
            },
            "validation_time": 0.838061,
            "epoch_time": 17.544174909591675,
            "validation_accuracy": 0.0997
        },
        "3": {
            "steps": {
                "1": 0.169985,
                "2": 0.173558,
                "3": 0.170485,
                "4": 0.170826,
                "5": 0.171417,
                "6": 0.171337,
                "7": 0.171979,
                "8": 0.172976,
                "9": 0.172207,
                "10": 0.170681,
                "11": 0.172837,
                "12": 0.171651,
                "13": 0.172231,
                "14": 0.172566,
                "15": 0.171563,
                "16": 0.171948,
                "17": 0.172023,
                "18": 0.171401,
                "19": 0.171671,
                "20": 0.171875,
                "21": 0.170304,
                "22": 0.173149,
                "23": 0.169954,
                "24": 0.171711,
                "25": 0.170887,
                "26": 0.174433,
                "27": 0.17115,
                "28": 0.173417,
                "29": 0.171975,
                "30": 0.171962,
                "31": 0.172415,
                "32": 0.172187,
                "33": 0.171923,
                "34": 0.173206,
                "35": 0.171012,
                "36": 0.172767,
                "37": 0.172796,
                "38": 0.173753,
                "39": 0.172223,
                "40": 0.173032,
                "41": 0.171896,
                "42": 0.170669,
                "43": 0.172063,
                "44": 0.170449,
                "45": 0.173134,
                "46": 0.171116,
                "47": 0.17249,
                "48": 0.170886,
                "49": 0.173169,
                "50": 0.171787,
                "51": 0.171965,
                "52": 0.172373,
                "53": 0.166284,
                "54": 0.173744,
                "55": 0.172328,
                "56": 0.172962,
                "57": 0.172184,
                "58": 0.172887,
                "59": 0.172225,
                "60": 0.172031,
                "61": 0.171802,
                "62": 0.174409,
                "63": 0.171888,
                "64": 0.172962,
                "65": 0.171721,
                "66": 0.172452,
                "67": 0.170895,
                "68": 0.172243,
                "69": 0.173425,
                "70": 0.172992,
                "71": 0.171484,
                "72": 0.17292,
                "73": 0.171455,
                "74": 0.173389,
                "75": 0.172098,
                "76": 0.172383,
                "77": 0.172472,
                "78": 0.172177,
                "79": 0.172101,
                "80": 0.173581,
                "81": 0.172757,
                "82": 0.17205,
                "83": 0.172649,
                "84": 0.17299,
                "85": 0.172065,
                "86": 0.173018,
                "87": 0.172505,
                "88": 0.174091,
                "89": 0.171906,
                "90": 0.172518,
                "91": 0.172081,
                "92": 0.174696,
                "93": 0.173186,
                "94": 0.173203,
                "95": 0.172481,
                "96": 0.172449,
                "97": 0.170579,
                "98": 0.135057
            },
            "validation_time": 0.849217,
            "epoch_time": 17.687894344329834,
            "validation_accuracy": 0.0997
        },
        "4": {
            "steps": {
                "1": 0.172314,
                "2": 0.172559,
                "3": 0.172,
                "4": 0.173525,
                "5": 0.172938,
                "6": 0.17325,
                "7": 0.172106,
                "8": 0.173076,
                "9": 0.171361,
                "10": 0.172456,
                "11": 0.171046,
                "12": 0.174745,
                "13": 0.171352,
                "14": 0.174646,
                "15": 0.173522,
                "16": 0.173515,
                "17": 0.171972,
                "18": 0.172717,
                "19": 0.172132,
                "20": 0.17371,
                "21": 0.173593,
                "22": 0.174069,
                "23": 0.173518,
                "24": 0.17438,
                "25": 0.173074,
                "26": 0.173743,
                "27": 0.173685,
                "28": 0.173108,
                "29": 0.174148,
                "30": 0.173577,
                "31": 0.173773,
                "32": 0.17451,
                "33": 0.173647,
                "34": 0.174573,
                "35": 0.173305,
                "36": 0.174018,
                "37": 0.173933,
                "38": 0.173696,
                "39": 0.171595,
                "40": 0.173563,
                "41": 0.171181,
                "42": 0.173224,
                "43": 0.173729,
                "44": 0.173574,
                "45": 0.174403,
                "46": 0.173215,
                "47": 0.174517,
                "48": 0.173885,
                "49": 0.174877,
                "50": 0.173678,
                "51": 0.174292,
                "52": 0.173772,
                "53": 0.173908,
                "54": 0.173857,
                "55": 0.173532,
                "56": 0.17263,
                "57": 0.171801,
                "58": 0.174134,
                "59": 0.173169,
                "60": 0.174495,
                "61": 0.175167,
                "62": 0.173846,
                "63": 0.173925,
                "64": 0.174318,
                "65": 0.174385,
                "66": 0.17312,
                "67": 0.173835,
                "68": 0.174079,
                "69": 0.174547,
                "70": 0.174153,
                "71": 0.17468,
                "72": 0.17571,
                "73": 0.174573,
                "74": 0.173053,
                "75": 0.175946,
                "76": 0.173852,
                "77": 0.174334,
                "78": 0.174443,
                "79": 0.173054,
                "80": 0.173994,
                "81": 0.174297,
                "82": 0.173611,
                "83": 0.173481,
                "84": 0.174354,
                "85": 0.172536,
                "86": 0.174303,
                "87": 0.172854,
                "88": 0.174283,
                "89": 0.174552,
                "90": 0.174289,
                "91": 0.175236,
                "92": 0.1751,
                "93": 0.173685,
                "94": 0.172647,
                "95": 0.174437,
                "96": 0.174595,
                "97": 0.173483,
                "98": 0.133345
            },
            "validation_time": 0.851791,
            "epoch_time": 17.83153223991394,
            "validation_accuracy": 0.0997
        },
        "5": {
            "steps": {
                "1": 0.172657,
                "2": 0.174094,
                "3": 0.173305,
                "4": 0.17596,
                "5": 0.174741,
                "6": 0.17408,
                "7": 0.1731,
                "8": 0.175208,
                "9": 0.176039,
                "10": 0.174675,
                "11": 0.174425,
                "12": 0.173589,
                "13": 0.173692,
                "14": 0.17434,
                "15": 0.174669,
                "16": 0.174963,
                "17": 0.173589,
                "18": 0.174972,
                "19": 0.172633,
                "20": 0.17364,
                "21": 0.173403,
                "22": 0.173902,
                "23": 0.175806,
                "24": 0.174465,
                "25": 0.173748,
                "26": 0.174566,
                "27": 0.173952,
                "28": 0.173782,
                "29": 0.175202,
                "30": 0.174066,
                "31": 0.175348,
                "32": 0.175879,
                "33": 0.175321,
                "34": 0.175498,
                "35": 0.174383,
                "36": 0.173764,
                "37": 0.17474,
                "38": 0.174069,
                "39": 0.174301,
                "40": 0.176528,
                "41": 0.175213,
                "42": 0.173665,
                "43": 0.174245,
                "44": 0.174486,
                "45": 0.175272,
                "46": 0.174968,
                "47": 0.173817,
                "48": 0.174866,
                "49": 0.174562,
                "50": 0.174752,
                "51": 0.174227,
                "52": 0.174031,
                "53": 0.173259,
                "54": 0.173727,
                "55": 0.174821,
                "56": 0.173315,
                "57": 0.174887,
                "58": 0.174151,
                "59": 0.175011,
                "60": 0.174956,
                "61": 0.174149,
                "62": 0.175411,
                "63": 0.175667,
                "64": 0.175643,
                "65": 0.174449,
                "66": 0.174211,
                "67": 0.174413,
                "68": 0.173302,
                "69": 0.173851,
                "70": 0.173939,
                "71": 0.174733,
                "72": 0.175398,
                "73": 0.17365,
                "74": 0.173591,
                "75": 0.174219,
                "76": 0.175759,
                "77": 0.176502,
                "78": 0.175349,
                "79": 0.175215,
                "80": 0.173577,
                "81": 0.17437,
                "82": 0.174599,
                "83": 0.174028,
                "84": 0.175262,
                "85": 0.175599,
                "86": 0.174018,
                "87": 0.175368,
                "88": 0.174577,
                "89": 0.174791,
                "90": 0.174481,
                "91": 0.175017,
                "92": 0.175487,
                "93": 0.167706,
                "94": 0.176261,
                "95": 0.175411,
                "96": 0.175399,
                "97": 0.176694,
                "98": 0.132982
            },
            "validation_time": 0.860953,
            "epoch_time": 17.924701929092407,
            "validation_accuracy": 0.0997
        }
    },
    "computing_system": "g4dn2xlarge-1",
    "batch_size": "512"
}
