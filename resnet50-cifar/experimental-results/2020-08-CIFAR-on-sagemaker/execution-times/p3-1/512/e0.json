{
    "init": -1.0,
    "total_training": 61.7929105758667,
    "largest_real_time_delta": 57.55568242073059,
    "fit_time": 61.7929105758667,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 15.63278,
                "2": 0.073575,
                "3": 0.069664,
                "4": 0.069997,
                "5": 0.070244,
                "6": 0.071688,
                "7": 0.069829,
                "8": 0.070592,
                "9": 0.069832,
                "10": 0.069968,
                "11": 0.070947,
                "12": 0.069464,
                "13": 0.071692,
                "14": 0.071514,
                "15": 0.070691,
                "16": 0.070397,
                "17": 0.070707,
                "18": 0.07093,
                "19": 0.071521,
                "20": 0.071027,
                "21": 0.070329,
                "22": 0.070208,
                "23": 0.070231,
                "24": 0.070389,
                "25": 0.070385,
                "26": 0.070058,
                "27": 0.069638,
                "28": 0.070123,
                "29": 0.069841,
                "30": 0.069107,
                "31": 0.071897,
                "32": 0.071067,
                "33": 0.070122,
                "34": 0.069494,
                "35": 0.071742,
                "36": 0.071636,
                "37": 0.070082,
                "38": 0.069693,
                "39": 0.069773,
                "40": 0.071081,
                "41": 0.071203,
                "42": 0.071221,
                "43": 0.071661,
                "44": 0.071613,
                "45": 0.071549,
                "46": 0.069973,
                "47": 0.070668,
                "48": 0.06992,
                "49": 0.070205,
                "50": 0.069898,
                "51": 0.070572,
                "52": 0.072198,
                "53": 0.070019,
                "54": 0.070065,
                "55": 0.070616,
                "56": 0.070197,
                "57": 0.069805,
                "58": 0.069997,
                "59": 0.070247,
                "60": 0.071077,
                "61": 0.069678,
                "62": 0.070113,
                "63": 0.070371,
                "64": 0.070345,
                "65": 0.070946,
                "66": 0.069598,
                "67": 0.070104,
                "68": 0.070525,
                "69": 0.069884,
                "70": 0.069904,
                "71": 0.068897,
                "72": 0.069717,
                "73": 0.069965,
                "74": 0.069755,
                "75": 0.069479,
                "76": 0.072197,
                "77": 0.069552,
                "78": 0.070148,
                "79": 0.070086,
                "80": 0.070187,
                "81": 0.070185,
                "82": 0.070198,
                "83": 0.070495,
                "84": 0.070223,
                "85": 0.070362,
                "86": 0.069702,
                "87": 0.069461,
                "88": 0.069119,
                "89": 0.069413,
                "90": 0.069415,
                "91": 0.069688,
                "92": 0.069836,
                "93": 0.071786,
                "94": 0.071781,
                "95": 0.069501,
                "96": 0.069589,
                "97": 0.0709,
                "98": 1.423471
            },
            "validation_time": 3.242908,
            "epoch_time": 27.998271465301514
        },
        "2": {
            "steps": {
                "1": 0.070574,
                "2": 0.069922,
                "3": 0.070298,
                "4": 0.069896,
                "5": 0.070644,
                "6": 0.06956,
                "7": 0.069597,
                "8": 0.069223,
                "9": 0.070008,
                "10": 0.06968,
                "11": 0.07033,
                "12": 0.070024,
                "13": 0.070141,
                "14": 0.069716,
                "15": 0.069368,
                "16": 0.069718,
                "17": 0.069912,
                "18": 0.072176,
                "19": 0.069766,
                "20": 0.070448,
                "21": 0.069667,
                "22": 0.071091,
                "23": 0.07101,
                "24": 0.069646,
                "25": 0.07004,
                "26": 0.070122,
                "27": 0.069666,
                "28": 0.070024,
                "29": 0.06984,
                "30": 0.070287,
                "31": 0.070474,
                "32": 0.069811,
                "33": 0.069581,
                "34": 0.070827,
                "35": 0.069518,
                "36": 0.069523,
                "37": 0.071788,
                "38": 0.069232,
                "39": 0.069886,
                "40": 0.069596,
                "41": 0.069486,
                "42": 0.069566,
                "43": 0.069316,
                "44": 0.069759,
                "45": 0.070224,
                "46": 0.069875,
                "47": 0.070143,
                "48": 0.070061,
                "49": 0.069656,
                "50": 0.069907,
                "51": 0.069867,
                "52": 0.069279,
                "53": 0.069593,
                "54": 0.069474,
                "55": 0.069133,
                "56": 0.069959,
                "57": 0.071315,
                "58": 0.069917,
                "59": 0.070222,
                "60": 0.070632,
                "61": 0.070349,
                "62": 0.07013,
                "63": 0.069574,
                "64": 0.070023,
                "65": 0.070046,
                "66": 0.070369,
                "67": 0.069773,
                "68": 0.07035,
                "69": 0.069714,
                "70": 0.06989,
                "71": 0.069325,
                "72": 0.073087,
                "73": 0.069741,
                "74": 0.070229,
                "75": 0.069605,
                "76": 0.070873,
                "77": 0.069449,
                "78": 0.069516,
                "79": 0.07118,
                "80": 0.071277,
                "81": 0.069515,
                "82": 0.070125,
                "83": 0.069431,
                "84": 0.071966,
                "85": 0.069928,
                "86": 0.070615,
                "87": 0.070911,
                "88": 0.069831,
                "89": 0.069809,
                "90": 0.071052,
                "91": 0.069639,
                "92": 0.069925,
                "93": 0.070752,
                "94": 0.069643,
                "95": 0.069896,
                "96": 0.069661,
                "97": 0.07129,
                "98": 0.071996
            },
            "validation_time": 0.496632,
            "epoch_time": 7.3714587688446045
        },
        "3": {
            "steps": {
                "1": 0.070203,
                "2": 0.069386,
                "3": 0.073837,
                "4": 0.069899,
                "5": 0.069268,
                "6": 0.069813,
                "7": 0.069268,
                "8": 0.069384,
                "9": 0.069713,
                "10": 0.07107,
                "11": 0.071358,
                "12": 0.069629,
                "13": 0.069546,
                "14": 0.069566,
                "15": 0.069482,
                "16": 0.071111,
                "17": 0.069486,
                "18": 0.069411,
                "19": 0.069512,
                "20": 0.069383,
                "21": 0.069998,
                "22": 0.070264,
                "23": 0.070218,
                "24": 0.071323,
                "25": 0.069463,
                "26": 0.070301,
                "27": 0.06969,
                "28": 0.069502,
                "29": 0.070524,
                "30": 0.069605,
                "31": 0.071082,
                "32": 0.06984,
                "33": 0.069396,
                "34": 0.06961,
                "35": 0.070073,
                "36": 0.074248,
                "37": 0.069787,
                "38": 0.069203,
                "39": 0.069669,
                "40": 0.069902,
                "41": 0.069912,
                "42": 0.069814,
                "43": 0.069759,
                "44": 0.069796,
                "45": 0.069427,
                "46": 0.070017,
                "47": 0.069842,
                "48": 0.069076,
                "49": 0.069739,
                "50": 0.069726,
                "51": 0.075885,
                "52": 0.069918,
                "53": 0.069946,
                "54": 0.069706,
                "55": 0.070236,
                "56": 0.070063,
                "57": 0.070001,
                "58": 0.070974,
                "59": 0.069702,
                "60": 0.069255,
                "61": 0.069583,
                "62": 0.069287,
                "63": 0.071233,
                "64": 0.069939,
                "65": 0.069612,
                "66": 0.068703,
                "67": 0.073536,
                "68": 0.069613,
                "69": 0.070066,
                "70": 0.070083,
                "71": 0.071146,
                "72": 0.069569,
                "73": 0.071316,
                "74": 0.070072,
                "75": 0.069965,
                "76": 0.070185,
                "77": 0.069697,
                "78": 0.069542,
                "79": 0.069636,
                "80": 0.069851,
                "81": 0.071378,
                "82": 0.069878,
                "83": 0.069902,
                "84": 0.071013,
                "85": 0.069768,
                "86": 0.069573,
                "87": 0.06967,
                "88": 0.069109,
                "89": 0.069936,
                "90": 0.069865,
                "91": 0.069908,
                "92": 0.069569,
                "93": 0.069897,
                "94": 0.069944,
                "95": 0.070324,
                "96": 0.070523,
                "97": 0.073962,
                "98": 0.073547
            },
            "validation_time": 0.507959,
            "epoch_time": 7.389488697052002
        },
        "4": {
            "steps": {
                "1": 0.07037,
                "2": 0.074195,
                "3": 0.069669,
                "4": 0.069668,
                "5": 0.069953,
                "6": 0.069839,
                "7": 0.071117,
                "8": 0.069728,
                "9": 0.069889,
                "10": 0.07185,
                "11": 0.070072,
                "12": 0.070163,
                "13": 0.07057,
                "14": 0.071059,
                "15": 0.070444,
                "16": 0.070183,
                "17": 0.069998,
                "18": 0.06991,
                "19": 0.074282,
                "20": 0.069851,
                "21": 0.07042,
                "22": 0.069549,
                "23": 0.069668,
                "24": 0.070696,
                "25": 0.06992,
                "26": 0.070518,
                "27": 0.069824,
                "28": 0.070378,
                "29": 0.069833,
                "30": 0.070246,
                "31": 0.070273,
                "32": 0.06948,
                "33": 0.069959,
                "34": 0.069883,
                "35": 0.070261,
                "36": 0.069656,
                "37": 0.070012,
                "38": 0.06973,
                "39": 0.069468,
                "40": 0.069636,
                "41": 0.069703,
                "42": 0.069463,
                "43": 0.069441,
                "44": 0.069399,
                "45": 0.070999,
                "46": 0.070323,
                "47": 0.070032,
                "48": 0.069583,
                "49": 0.069398,
                "50": 0.071678,
                "51": 0.070601,
                "52": 0.069847,
                "53": 0.069314,
                "54": 0.069997,
                "55": 0.069682,
                "56": 0.070329,
                "57": 0.069919,
                "58": 0.072569,
                "59": 0.070147,
                "60": 0.07025,
                "61": 0.070002,
                "62": 0.070276,
                "63": 0.069865,
                "64": 0.071153,
                "65": 0.073317,
                "66": 0.06977,
                "67": 0.070054,
                "68": 0.069767,
                "69": 0.071135,
                "70": 0.069685,
                "71": 0.069591,
                "72": 0.070168,
                "73": 0.069988,
                "74": 0.069611,
                "75": 0.069876,
                "76": 0.069909,
                "77": 0.070784,
                "78": 0.070827,
                "79": 0.070194,
                "80": 0.069821,
                "81": 0.072176,
                "82": 0.069601,
                "83": 0.069594,
                "84": 0.069633,
                "85": 0.069225,
                "86": 0.071292,
                "87": 0.070026,
                "88": 0.069566,
                "89": 0.071116,
                "90": 0.070029,
                "91": 0.070735,
                "92": 0.069928,
                "93": 0.070214,
                "94": 0.071813,
                "95": 0.06981,
                "96": 0.071811,
                "97": 0.069397,
                "98": 0.078302
            },
            "validation_time": 0.501237,
            "epoch_time": 7.400481700897217
        },
        "5": {
            "steps": {
                "1": 0.071126,
                "2": 0.070188,
                "3": 0.070212,
                "4": 0.072157,
                "5": 0.0704,
                "6": 0.069864,
                "7": 0.070011,
                "8": 0.070036,
                "9": 0.070896,
                "10": 0.070005,
                "11": 0.071666,
                "12": 0.071328,
                "13": 0.069879,
                "14": 0.070845,
                "15": 0.071007,
                "16": 0.069822,
                "17": 0.070124,
                "18": 0.070194,
                "19": 0.070139,
                "20": 0.072063,
                "21": 0.070195,
                "22": 0.070996,
                "23": 0.07098,
                "24": 0.069893,
                "25": 0.069482,
                "26": 0.070107,
                "27": 0.07028,
                "28": 0.07039,
                "29": 0.07075,
                "30": 0.070574,
                "31": 0.07022,
                "32": 0.069916,
                "33": 0.07116,
                "34": 0.069564,
                "35": 0.069439,
                "36": 0.070038,
                "37": 0.069472,
                "38": 0.069469,
                "39": 0.069734,
                "40": 0.071438,
                "41": 0.071331,
                "42": 0.069596,
                "43": 0.069581,
                "44": 0.069669,
                "45": 0.069969,
                "46": 0.070469,
                "47": 0.070547,
                "48": 0.069962,
                "49": 0.069504,
                "50": 0.069811,
                "51": 0.069805,
                "52": 0.069666,
                "53": 0.069849,
                "54": 0.069986,
                "55": 0.069925,
                "56": 0.071156,
                "57": 0.070556,
                "58": 0.069881,
                "59": 0.069973,
                "60": 0.069584,
                "61": 0.06949,
                "62": 0.069663,
                "63": 0.070306,
                "64": 0.07004,
                "65": 0.070312,
                "66": 0.070812,
                "67": 0.069678,
                "68": 0.071038,
                "69": 0.070222,
                "70": 0.070023,
                "71": 0.075163,
                "72": 0.070187,
                "73": 0.069837,
                "74": 0.071054,
                "75": 0.069948,
                "76": 0.070376,
                "77": 0.070871,
                "78": 0.069716,
                "79": 0.069544,
                "80": 0.069488,
                "81": 0.069723,
                "82": 0.069527,
                "83": 0.069567,
                "84": 0.070512,
                "85": 0.069744,
                "86": 0.07225,
                "87": 0.070346,
                "88": 0.069788,
                "89": 0.072756,
                "90": 0.069848,
                "91": 0.0694,
                "92": 0.069669,
                "93": 0.070463,
                "94": 0.070029,
                "95": 0.070728,
                "96": 0.070658,
                "97": 0.069346,
                "98": 0.072114
            },
            "validation_time": 0.499506,
            "epoch_time": 7.394991636276245
        }
    },
    "computing_system": "p3-1",
    "batch_size": "512"
}
