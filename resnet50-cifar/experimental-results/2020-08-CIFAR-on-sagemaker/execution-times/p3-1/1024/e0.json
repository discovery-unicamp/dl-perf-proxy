{
    "init": -1.0,
    "total_training": 54.49269509315491,
    "largest_real_time_delta": 50.82900357246399,
    "fit_time": 54.49269509315491,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 15.01235,
                "2": 0.11631,
                "3": 0.115529,
                "4": 0.115222,
                "5": 0.117271,
                "6": 0.115118,
                "7": 0.115811,
                "8": 0.115053,
                "9": 0.115651,
                "10": 0.115403,
                "11": 0.114856,
                "12": 0.115231,
                "13": 0.115083,
                "14": 0.115137,
                "15": 0.115115,
                "16": 0.114866,
                "17": 0.114871,
                "18": 0.115098,
                "19": 0.115256,
                "20": 0.114959,
                "21": 0.11581,
                "22": 0.115753,
                "23": 0.114724,
                "24": 0.115262,
                "25": 0.114752,
                "26": 0.115171,
                "27": 0.115334,
                "28": 0.115869,
                "29": 0.117777,
                "30": 0.116669,
                "31": 0.115024,
                "32": 0.115846,
                "33": 0.115067,
                "34": 0.115468,
                "35": 0.116155,
                "36": 0.116521,
                "37": 0.115468,
                "38": 0.114919,
                "39": 0.114976,
                "40": 0.115066,
                "41": 0.114571,
                "42": 0.115169,
                "43": 0.115153,
                "44": 0.11508,
                "45": 0.115151,
                "46": 0.115289,
                "47": 0.115812,
                "48": 0.114141,
                "49": 2.056528
            },
            "validation_time": 3.298013,
            "epoch_time": 26.610013246536255
        },
        "2": {
            "steps": {
                "1": 0.115111,
                "2": 0.115898,
                "3": 0.114775,
                "4": 0.115196,
                "5": 0.114327,
                "6": 0.115549,
                "7": 0.115105,
                "8": 0.115263,
                "9": 0.114974,
                "10": 0.115748,
                "11": 0.115237,
                "12": 0.115167,
                "13": 0.114643,
                "14": 0.115155,
                "15": 0.115258,
                "16": 0.114818,
                "17": 0.114831,
                "18": 0.114346,
                "19": 0.116438,
                "20": 0.114725,
                "21": 0.114953,
                "22": 0.115478,
                "23": 0.115579,
                "24": 0.114859,
                "25": 0.116729,
                "26": 0.115719,
                "27": 0.115296,
                "28": 0.115701,
                "29": 0.114629,
                "30": 0.113857,
                "31": 0.114808,
                "32": 0.114264,
                "33": 0.115014,
                "34": 0.115267,
                "35": 0.115665,
                "36": 0.114783,
                "37": 0.115413,
                "38": 0.115096,
                "39": 0.114725,
                "40": 0.114789,
                "41": 0.114993,
                "42": 0.115097,
                "43": 0.115581,
                "44": 0.116183,
                "45": 0.114641,
                "46": 0.115195,
                "47": 0.114368,
                "48": 0.11449,
                "49": 0.112605
            },
            "validation_time": 0.399584,
            "epoch_time": 6.042177200317383
        },
        "3": {
            "steps": {
                "1": 0.114821,
                "2": 0.114554,
                "3": 0.115447,
                "4": 0.115256,
                "5": 0.115638,
                "6": 0.115354,
                "7": 0.115535,
                "8": 0.115311,
                "9": 0.115229,
                "10": 0.114469,
                "11": 0.114871,
                "12": 0.115846,
                "13": 0.11555,
                "14": 0.11498,
                "15": 0.114341,
                "16": 0.114992,
                "17": 0.115125,
                "18": 0.114913,
                "19": 0.114831,
                "20": 0.114909,
                "21": 0.115391,
                "22": 0.115215,
                "23": 0.115221,
                "24": 0.114804,
                "25": 0.114449,
                "26": 0.114974,
                "27": 0.116885,
                "28": 0.114825,
                "29": 0.113865,
                "30": 0.115604,
                "31": 0.114177,
                "32": 0.115298,
                "33": 0.114877,
                "34": 0.115063,
                "35": 0.118564,
                "36": 0.115498,
                "37": 0.114634,
                "38": 0.114845,
                "39": 0.114929,
                "40": 0.115396,
                "41": 0.114319,
                "42": 0.11458,
                "43": 0.115233,
                "44": 0.114567,
                "45": 0.115293,
                "46": 0.11553,
                "47": 0.11508,
                "48": 0.116801,
                "49": 0.115844
            },
            "validation_time": 0.405133,
            "epoch_time": 6.053072929382324
        },
        "4": {
            "steps": {
                "1": 0.114821,
                "2": 0.115127,
                "3": 0.114984,
                "4": 0.114829,
                "5": 0.1146,
                "6": 0.114951,
                "7": 0.11529,
                "8": 0.115304,
                "9": 0.115352,
                "10": 0.11563,
                "11": 0.114922,
                "12": 0.114748,
                "13": 0.115124,
                "14": 0.115418,
                "15": 0.115289,
                "16": 0.11481,
                "17": 0.115086,
                "18": 0.114755,
                "19": 0.115135,
                "20": 0.114587,
                "21": 0.115707,
                "22": 0.115335,
                "23": 0.114657,
                "24": 0.114491,
                "25": 0.115659,
                "26": 0.115662,
                "27": 0.114978,
                "28": 0.114548,
                "29": 0.114763,
                "30": 0.114946,
                "31": 0.115591,
                "32": 0.114801,
                "33": 0.114868,
                "34": 0.115172,
                "35": 0.114693,
                "36": 0.114743,
                "37": 0.115545,
                "38": 0.11564,
                "39": 0.114721,
                "40": 0.11508,
                "41": 0.115592,
                "42": 0.114716,
                "43": 0.115043,
                "44": 0.115052,
                "45": 0.115583,
                "46": 0.114712,
                "47": 0.114188,
                "48": 0.114368,
                "49": 0.116921
            },
            "validation_time": 0.404784,
            "epoch_time": 6.047520637512207
        },
        "5": {
            "steps": {
                "1": 0.115919,
                "2": 0.116473,
                "3": 0.114221,
                "4": 0.115268,
                "5": 0.115049,
                "6": 0.115264,
                "7": 0.114993,
                "8": 0.115036,
                "9": 0.115068,
                "10": 0.115388,
                "11": 0.114788,
                "12": 0.115736,
                "13": 0.115251,
                "14": 0.115484,
                "15": 0.11458,
                "16": 0.115415,
                "17": 0.117639,
                "18": 0.115162,
                "19": 0.117312,
                "20": 0.115539,
                "21": 0.115059,
                "22": 0.11526,
                "23": 0.115223,
                "24": 0.114377,
                "25": 0.115353,
                "26": 0.115153,
                "27": 0.1141,
                "28": 0.114956,
                "29": 0.115644,
                "30": 0.114563,
                "31": 0.114744,
                "32": 0.115348,
                "33": 0.117798,
                "34": 0.115439,
                "35": 0.11551,
                "36": 0.116525,
                "37": 0.115455,
                "38": 0.115704,
                "39": 0.115405,
                "40": 0.11546,
                "41": 0.115982,
                "42": 0.11582,
                "43": 0.115394,
                "44": 0.114705,
                "45": 0.115946,
                "46": 0.116363,
                "47": 0.115598,
                "48": 0.116543,
                "49": 0.114615
            },
            "validation_time": 0.413503,
            "epoch_time": 6.075284242630005
        }
    },
    "computing_system": "p3-1",
    "batch_size": "1024"
}
