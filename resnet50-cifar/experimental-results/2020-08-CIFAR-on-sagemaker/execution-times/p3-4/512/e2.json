{
    "init": -1.0,
    "total_training": 98.36227059364319,
    "largest_real_time_delta": 94.4856390953064,
    "fit_time": 98.36227059364319,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 58.962539,
                "2": 0.056867,
                "3": 0.054316,
                "4": 0.053614,
                "5": 0.053311,
                "6": 0.055945,
                "7": 0.052502,
                "8": 0.054231,
                "9": 0.055372,
                "10": 0.05338,
                "11": 0.056074,
                "12": 0.054483,
                "13": 0.053907,
                "14": 0.053975,
                "15": 0.051589,
                "16": 0.052468,
                "17": 0.05778,
                "18": 0.05329,
                "19": 0.054943,
                "20": 0.056537,
                "21": 0.053702,
                "22": 0.051588,
                "23": 0.053983,
                "24": 0.053662,
                "25": 0.053228,
                "26": 0.05365,
                "27": 0.053252,
                "28": 0.053681,
                "29": 0.050578,
                "30": 0.0563,
                "31": 0.057238,
                "32": 0.054852,
                "33": 0.056345,
                "34": 0.053368,
                "35": 0.052869,
                "36": 0.054146,
                "37": 0.054437,
                "38": 0.052903,
                "39": 0.053063,
                "40": 0.054828,
                "41": 0.053937,
                "42": 0.057298,
                "43": 0.054811,
                "44": 0.053209,
                "45": 0.054934,
                "46": 0.053596,
                "47": 0.056022,
                "48": 0.054471,
                "49": 0.053552,
                "50": 0.055405,
                "51": 0.05349,
                "52": 0.052566,
                "53": 0.055159,
                "54": 0.053687,
                "55": 0.05474,
                "56": 0.051839,
                "57": 0.053344,
                "58": 0.053157,
                "59": 0.051915,
                "60": 0.052633,
                "61": 0.052692,
                "62": 0.058175,
                "63": 0.053373,
                "64": 0.051616,
                "65": 0.053204,
                "66": 0.055187,
                "67": 0.05398,
                "68": 0.055086,
                "69": 0.054809,
                "70": 0.054202,
                "71": 0.052437,
                "72": 0.053687,
                "73": 0.053461,
                "74": 0.052916,
                "75": 0.0539,
                "76": 0.054051,
                "77": 0.052776,
                "78": 0.053607,
                "79": 0.051052,
                "80": 0.055128,
                "81": 0.053394,
                "82": 0.058129,
                "83": 0.054491,
                "84": 0.052829,
                "85": 0.057836,
                "86": 0.053426,
                "87": 0.054377,
                "88": 0.053445,
                "89": 0.053795,
                "90": 0.052825,
                "91": 0.053269,
                "92": 0.059927,
                "93": 0.054373,
                "94": 0.053291,
                "95": 0.054072,
                "96": 0.054215,
                "97": 0.053098,
                "98": 0.949679
            },
            "validation_time": 5.690596,
            "epoch_time": 71.73057794570923,
            "validation_accuracy": 0.0997
        },
        "2": {
            "steps": {
                "1": 0.057862,
                "2": 0.056067,
                "3": 0.059036,
                "4": 0.053432,
                "5": 0.052095,
                "6": 0.053104,
                "7": 0.053793,
                "8": 0.053057,
                "9": 0.054498,
                "10": 0.054382,
                "11": 0.054364,
                "12": 0.053882,
                "13": 0.057038,
                "14": 0.055934,
                "15": 0.053063,
                "16": 0.052501,
                "17": 0.052588,
                "18": 0.053434,
                "19": 0.052544,
                "20": 0.055489,
                "21": 0.054058,
                "22": 0.051077,
                "23": 0.051682,
                "24": 0.052304,
                "25": 0.053615,
                "26": 0.052842,
                "27": 0.053153,
                "28": 0.052065,
                "29": 0.054312,
                "30": 0.054366,
                "31": 0.056354,
                "32": 0.053554,
                "33": 0.059777,
                "34": 0.0561,
                "35": 0.053175,
                "36": 0.051968,
                "37": 0.054671,
                "38": 0.057382,
                "39": 0.054466,
                "40": 0.05994,
                "41": 0.055428,
                "42": 0.053502,
                "43": 0.052907,
                "44": 0.051459,
                "45": 0.051945,
                "46": 0.051598,
                "47": 0.053633,
                "48": 0.053913,
                "49": 0.057292,
                "50": 0.056166,
                "51": 0.057723,
                "52": 0.054673,
                "53": 0.054511,
                "54": 0.054106,
                "55": 0.053268,
                "56": 0.054211,
                "57": 0.053346,
                "58": 0.054591,
                "59": 0.056369,
                "60": 0.052849,
                "61": 0.055592,
                "62": 0.05559,
                "63": 0.055312,
                "64": 0.053371,
                "65": 0.057302,
                "66": 0.053766,
                "67": 0.053407,
                "68": 0.054627,
                "69": 0.055709,
                "70": 0.054031,
                "71": 0.054109,
                "72": 0.053457,
                "73": 0.053634,
                "74": 0.058898,
                "75": 0.053658,
                "76": 0.051922,
                "77": 0.052958,
                "78": 0.056756,
                "79": 0.053147,
                "80": 0.053364,
                "81": 0.052258,
                "82": 0.053661,
                "83": 0.05367,
                "84": 0.053738,
                "85": 0.054597,
                "86": 0.054827,
                "87": 0.055021,
                "88": 0.053736,
                "89": 0.053404,
                "90": 0.055164,
                "91": 0.053449,
                "92": 0.05268,
                "93": 0.053315,
                "94": 0.05324,
                "95": 0.052999,
                "96": 0.052566,
                "97": 0.056156,
                "98": 0.079928
            },
            "validation_time": 0.330662,
            "epoch_time": 5.680049896240234,
            "validation_accuracy": 0.0999
        },
        "3": {
            "steps": {
                "1": 0.054475,
                "2": 0.053099,
                "3": 0.054574,
                "4": 0.053753,
                "5": 0.053758,
                "6": 0.05371,
                "7": 0.054001,
                "8": 0.05455,
                "9": 0.053984,
                "10": 0.055729,
                "11": 0.054981,
                "12": 0.053722,
                "13": 0.053792,
                "14": 0.053257,
                "15": 0.052853,
                "16": 0.054811,
                "17": 0.053371,
                "18": 0.053609,
                "19": 0.05391,
                "20": 0.054519,
                "21": 0.053324,
                "22": 0.052541,
                "23": 0.053276,
                "24": 0.05332,
                "25": 0.057596,
                "26": 0.054362,
                "27": 0.057295,
                "28": 0.053402,
                "29": 0.054358,
                "30": 0.054886,
                "31": 0.051746,
                "32": 0.055455,
                "33": 0.053992,
                "34": 0.052845,
                "35": 0.056301,
                "36": 0.058007,
                "37": 0.053682,
                "38": 0.05632,
                "39": 0.056158,
                "40": 0.055762,
                "41": 0.054404,
                "42": 0.053022,
                "43": 0.052091,
                "44": 0.052856,
                "45": 0.053916,
                "46": 0.055208,
                "47": 0.05369,
                "48": 0.054282,
                "49": 0.054198,
                "50": 0.056664,
                "51": 0.054458,
                "52": 0.057067,
                "53": 0.054248,
                "54": 0.051817,
                "55": 0.053392,
                "56": 0.054515,
                "57": 0.05429,
                "58": 0.055293,
                "59": 0.051655,
                "60": 0.053919,
                "61": 0.054398,
                "62": 0.053632,
                "63": 0.055536,
                "64": 0.058575,
                "65": 0.053296,
                "66": 0.057535,
                "67": 0.054547,
                "68": 0.054225,
                "69": 0.051924,
                "70": 0.054107,
                "71": 0.05408,
                "72": 0.060029,
                "73": 0.054894,
                "74": 0.053763,
                "75": 0.054522,
                "76": 0.054992,
                "77": 0.054703,
                "78": 0.051692,
                "79": 0.053159,
                "80": 0.058304,
                "81": 0.058324,
                "82": 0.054434,
                "83": 0.053921,
                "84": 0.054314,
                "85": 0.053431,
                "86": 0.055116,
                "87": 0.053666,
                "88": 0.053653,
                "89": 0.053917,
                "90": 0.057395,
                "91": 0.055452,
                "92": 0.056739,
                "93": 0.054646,
                "94": 0.054553,
                "95": 0.053543,
                "96": 0.050546,
                "97": 0.053708,
                "98": 0.074136
            },
            "validation_time": 0.326032,
            "epoch_time": 5.687463998794556,
            "validation_accuracy": 0.1001
        },
        "4": {
            "steps": {
                "1": 0.054117,
                "2": 0.052706,
                "3": 0.054157,
                "4": 0.053952,
                "5": 0.053402,
                "6": 0.057856,
                "7": 0.053658,
                "8": 0.055017,
                "9": 0.055834,
                "10": 0.053416,
                "11": 0.054167,
                "12": 0.053026,
                "13": 0.054142,
                "14": 0.053751,
                "15": 0.052822,
                "16": 0.056334,
                "17": 0.054387,
                "18": 0.05413,
                "19": 0.054181,
                "20": 0.05361,
                "21": 0.055886,
                "22": 0.053573,
                "23": 0.053766,
                "24": 0.059224,
                "25": 0.056673,
                "26": 0.052906,
                "27": 0.055016,
                "28": 0.05779,
                "29": 0.054122,
                "30": 0.053309,
                "31": 0.05365,
                "32": 0.05405,
                "33": 0.054029,
                "34": 0.055693,
                "35": 0.053807,
                "36": 0.054186,
                "37": 0.051785,
                "38": 0.053417,
                "39": 0.053612,
                "40": 0.054232,
                "41": 0.053448,
                "42": 0.059061,
                "43": 0.054552,
                "44": 0.05666,
                "45": 0.054087,
                "46": 0.056742,
                "47": 0.053711,
                "48": 0.053848,
                "49": 0.053956,
                "50": 0.0527,
                "51": 0.055686,
                "52": 0.053199,
                "53": 0.056777,
                "54": 0.054186,
                "55": 0.055111,
                "56": 0.053411,
                "57": 0.05195,
                "58": 0.054996,
                "59": 0.056128,
                "60": 0.054438,
                "61": 0.057803,
                "62": 0.051761,
                "63": 0.053748,
                "64": 0.052066,
                "65": 0.053968,
                "66": 0.054145,
                "67": 0.054127,
                "68": 0.054054,
                "69": 0.053186,
                "70": 0.05336,
                "71": 0.054378,
                "72": 0.054128,
                "73": 0.054797,
                "74": 0.054465,
                "75": 0.051354,
                "76": 0.056005,
                "77": 0.053724,
                "78": 0.05438,
                "79": 0.053542,
                "80": 0.05364,
                "81": 0.053748,
                "82": 0.053538,
                "83": 0.054039,
                "84": 0.054187,
                "85": 0.054536,
                "86": 0.055128,
                "87": 0.05447,
                "88": 0.054016,
                "89": 0.053192,
                "90": 0.052777,
                "91": 0.053676,
                "92": 0.053663,
                "93": 0.054944,
                "94": 0.056116,
                "95": 0.053114,
                "96": 0.053579,
                "97": 0.053649,
                "98": 0.074522
            },
            "validation_time": 0.329618,
            "epoch_time": 5.676909685134888,
            "validation_accuracy": 0.0999
        },
        "5": {
            "steps": {
                "1": 0.054577,
                "2": 0.054173,
                "3": 0.054647,
                "4": 0.05767,
                "5": 0.055008,
                "6": 0.059151,
                "7": 0.051306,
                "8": 0.053149,
                "9": 0.055432,
                "10": 0.054558,
                "11": 0.054895,
                "12": 0.050801,
                "13": 0.053575,
                "14": 0.053205,
                "15": 0.053401,
                "16": 0.055866,
                "17": 0.052055,
                "18": 0.055976,
                "19": 0.054023,
                "20": 0.053753,
                "21": 0.054806,
                "22": 0.056107,
                "23": 0.058834,
                "24": 0.054076,
                "25": 0.057432,
                "26": 0.055413,
                "27": 0.054581,
                "28": 0.053537,
                "29": 0.05405,
                "30": 0.052568,
                "31": 0.054047,
                "32": 0.054469,
                "33": 0.054567,
                "34": 0.052521,
                "35": 0.053097,
                "36": 0.056594,
                "37": 0.051831,
                "38": 0.053333,
                "39": 0.053188,
                "40": 0.054227,
                "41": 0.054019,
                "42": 0.053355,
                "43": 0.054301,
                "44": 0.055729,
                "45": 0.055113,
                "46": 0.055578,
                "47": 0.057892,
                "48": 0.052212,
                "49": 0.054816,
                "50": 0.053743,
                "51": 0.052715,
                "52": 0.054827,
                "53": 0.054921,
                "54": 0.053546,
                "55": 0.056214,
                "56": 0.05353,
                "57": 0.056748,
                "58": 0.055668,
                "59": 0.055453,
                "60": 0.052158,
                "61": 0.057569,
                "62": 0.060586,
                "63": 0.054381,
                "64": 0.051343,
                "65": 0.053588,
                "66": 0.056408,
                "67": 0.054681,
                "68": 0.051824,
                "69": 0.054229,
                "70": 0.054304,
                "71": 0.054758,
                "72": 0.054564,
                "73": 0.051234,
                "74": 0.061546,
                "75": 0.052605,
                "76": 0.051219,
                "77": 0.053709,
                "78": 0.05363,
                "79": 0.053866,
                "80": 0.054765,
                "81": 0.055611,
                "82": 0.059253,
                "83": 0.054746,
                "84": 0.054102,
                "85": 0.051705,
                "86": 0.053413,
                "87": 0.054725,
                "88": 0.057874,
                "89": 0.054181,
                "90": 0.057974,
                "91": 0.055755,
                "92": 0.055937,
                "93": 0.05394,
                "94": 0.053416,
                "95": 0.055187,
                "96": 0.05856,
                "97": 0.053047,
                "98": 0.071535
            },
            "validation_time": 0.333091,
            "epoch_time": 5.709704637527466,
            "validation_accuracy": 0.1001
        }
    },
    "computing_system": "p3-4",
    "batch_size": "512"
}
