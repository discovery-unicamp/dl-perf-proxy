{
    "init": -1.0,
    "total_training": 96.98366665840149,
    "largest_real_time_delta": 93.26001691818237,
    "fit_time": 96.98366665840149,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 57.613316,
                "2": 0.05528,
                "3": 0.052496,
                "4": 0.057268,
                "5": 0.052574,
                "6": 0.055988,
                "7": 0.057274,
                "8": 0.052966,
                "9": 0.051369,
                "10": 0.050256,
                "11": 0.052043,
                "12": 0.056278,
                "13": 0.051127,
                "14": 0.056647,
                "15": 0.054726,
                "16": 0.05523,
                "17": 0.052385,
                "18": 0.053827,
                "19": 0.053873,
                "20": 0.052738,
                "21": 0.052911,
                "22": 0.053146,
                "23": 0.052074,
                "24": 0.053476,
                "25": 0.056782,
                "26": 0.052613,
                "27": 0.051969,
                "28": 0.052741,
                "29": 0.053049,
                "30": 0.052784,
                "31": 0.051786,
                "32": 0.053405,
                "33": 0.050333,
                "34": 0.052079,
                "35": 0.05261,
                "36": 0.052772,
                "37": 0.051426,
                "38": 0.052391,
                "39": 0.052615,
                "40": 0.052033,
                "41": 0.053182,
                "42": 0.052829,
                "43": 0.057539,
                "44": 0.054734,
                "45": 0.051554,
                "46": 0.052045,
                "47": 0.051894,
                "48": 0.054138,
                "49": 0.053582,
                "50": 0.052755,
                "51": 0.053157,
                "52": 0.055672,
                "53": 0.055118,
                "54": 0.052392,
                "55": 0.052116,
                "56": 0.055752,
                "57": 0.051555,
                "58": 0.054001,
                "59": 0.051711,
                "60": 0.051658,
                "61": 0.052159,
                "62": 0.052714,
                "63": 0.056149,
                "64": 0.05444,
                "65": 0.051965,
                "66": 0.051628,
                "67": 0.056608,
                "68": 0.049632,
                "69": 0.053619,
                "70": 0.054096,
                "71": 0.054115,
                "72": 0.052258,
                "73": 0.057408,
                "74": 0.051614,
                "75": 0.05137,
                "76": 0.056641,
                "77": 0.052791,
                "78": 0.053867,
                "79": 0.05233,
                "80": 0.056006,
                "81": 0.051286,
                "82": 0.052484,
                "83": 0.052345,
                "84": 0.054926,
                "85": 0.051475,
                "86": 0.053783,
                "87": 0.052695,
                "88": 0.053071,
                "89": 0.051704,
                "90": 0.054099,
                "91": 0.052199,
                "92": 0.050124,
                "93": 0.054122,
                "94": 0.055104,
                "95": 0.052116,
                "96": 0.05525,
                "97": 0.052314,
                "98": 0.938678
            },
            "validation_time": 6.534487,
            "epoch_time": 71.10250759124756,
            "validation_accuracy": 0.0997
        },
        "2": {
            "steps": {
                "1": 0.055927,
                "2": 0.057681,
                "3": 0.052649,
                "4": 0.055587,
                "5": 0.054753,
                "6": 0.052933,
                "7": 0.053917,
                "8": 0.05337,
                "9": 0.051046,
                "10": 0.051817,
                "11": 0.052355,
                "12": 0.05387,
                "13": 0.052722,
                "14": 0.051937,
                "15": 0.056219,
                "16": 0.053234,
                "17": 0.052345,
                "18": 0.053763,
                "19": 0.052739,
                "20": 0.053348,
                "21": 0.049588,
                "22": 0.053402,
                "23": 0.052395,
                "24": 0.05266,
                "25": 0.051564,
                "26": 0.054281,
                "27": 0.054827,
                "28": 0.053614,
                "29": 0.057104,
                "30": 0.052892,
                "31": 0.052405,
                "32": 0.052639,
                "33": 0.052704,
                "34": 0.051963,
                "35": 0.051541,
                "36": 0.057798,
                "37": 0.050935,
                "38": 0.05463,
                "39": 0.053139,
                "40": 0.052936,
                "41": 0.051948,
                "42": 0.052529,
                "43": 0.053819,
                "44": 0.051487,
                "45": 0.051514,
                "46": 0.05189,
                "47": 0.052536,
                "48": 0.05043,
                "49": 0.051601,
                "50": 0.05354,
                "51": 0.052857,
                "52": 0.055379,
                "53": 0.051106,
                "54": 0.051765,
                "55": 0.05309,
                "56": 0.050863,
                "57": 0.057299,
                "58": 0.052044,
                "59": 0.052284,
                "60": 0.051659,
                "61": 0.054745,
                "62": 0.053848,
                "63": 0.05233,
                "64": 0.051782,
                "65": 0.050844,
                "66": 0.052321,
                "67": 0.05103,
                "68": 0.057242,
                "69": 0.052607,
                "70": 0.052304,
                "71": 0.051469,
                "72": 0.052449,
                "73": 0.050646,
                "74": 0.052954,
                "75": 0.052891,
                "76": 0.052527,
                "77": 0.051136,
                "78": 0.05204,
                "79": 0.053401,
                "80": 0.05249,
                "81": 0.051749,
                "82": 0.054841,
                "83": 0.052944,
                "84": 0.052552,
                "85": 0.054218,
                "86": 0.053001,
                "87": 0.051542,
                "88": 0.05145,
                "89": 0.051904,
                "90": 0.051525,
                "91": 0.05182,
                "92": 0.051186,
                "93": 0.052737,
                "94": 0.051494,
                "95": 0.051183,
                "96": 0.053123,
                "97": 0.05336,
                "98": 0.075169
            },
            "validation_time": 0.322153,
            "epoch_time": 5.529595613479614,
            "validation_accuracy": 0.0997
        },
        "3": {
            "steps": {
                "1": 0.052401,
                "2": 0.052176,
                "3": 0.053313,
                "4": 0.051685,
                "5": 0.05183,
                "6": 0.052461,
                "7": 0.053029,
                "8": 0.053542,
                "9": 0.052651,
                "10": 0.052119,
                "11": 0.051275,
                "12": 0.057778,
                "13": 0.05137,
                "14": 0.055656,
                "15": 0.054966,
                "16": 0.054262,
                "17": 0.052635,
                "18": 0.052251,
                "19": 0.056534,
                "20": 0.052805,
                "21": 0.055955,
                "22": 0.050803,
                "23": 0.052472,
                "24": 0.052589,
                "25": 0.052728,
                "26": 0.055342,
                "27": 0.052577,
                "28": 0.052457,
                "29": 0.055624,
                "30": 0.052415,
                "31": 0.053685,
                "32": 0.050676,
                "33": 0.05313,
                "34": 0.051781,
                "35": 0.052676,
                "36": 0.054415,
                "37": 0.053921,
                "38": 0.050632,
                "39": 0.050159,
                "40": 0.051966,
                "41": 0.051916,
                "42": 0.053053,
                "43": 0.055089,
                "44": 0.052978,
                "45": 0.049876,
                "46": 0.052034,
                "47": 0.052969,
                "48": 0.052935,
                "49": 0.053581,
                "50": 0.052262,
                "51": 0.051562,
                "52": 0.052741,
                "53": 0.051642,
                "54": 0.054482,
                "55": 0.052511,
                "56": 0.0561,
                "57": 0.054236,
                "58": 0.052867,
                "59": 0.052073,
                "60": 0.053817,
                "61": 0.055861,
                "62": 0.05331,
                "63": 0.054546,
                "64": 0.053561,
                "65": 0.053003,
                "66": 0.053431,
                "67": 0.053977,
                "68": 0.053009,
                "69": 0.052418,
                "70": 0.053974,
                "71": 0.05272,
                "72": 0.052157,
                "73": 0.053889,
                "74": 0.053775,
                "75": 0.051056,
                "76": 0.055178,
                "77": 0.052256,
                "78": 0.051804,
                "79": 0.052837,
                "80": 0.056426,
                "81": 0.052468,
                "82": 0.050551,
                "83": 0.056061,
                "84": 0.056605,
                "85": 0.050335,
                "86": 0.053698,
                "87": 0.056213,
                "88": 0.052959,
                "89": 0.054254,
                "90": 0.053018,
                "91": 0.052433,
                "92": 0.052678,
                "93": 0.058287,
                "94": 0.0534,
                "95": 0.05495,
                "96": 0.053756,
                "97": 0.051728,
                "98": 0.069823
            },
            "validation_time": 0.315613,
            "epoch_time": 5.553202390670776,
            "validation_accuracy": 0.0997
        },
        "4": {
            "steps": {
                "1": 0.052864,
                "2": 0.054396,
                "3": 0.057557,
                "4": 0.053861,
                "5": 0.051098,
                "6": 0.053013,
                "7": 0.051574,
                "8": 0.053881,
                "9": 0.0518,
                "10": 0.051637,
                "11": 0.05154,
                "12": 0.050334,
                "13": 0.056381,
                "14": 0.052742,
                "15": 0.052817,
                "16": 0.054569,
                "17": 0.052898,
                "18": 0.052118,
                "19": 0.052551,
                "20": 0.054842,
                "21": 0.052222,
                "22": 0.056838,
                "23": 0.051847,
                "24": 0.054,
                "25": 0.058041,
                "26": 0.05067,
                "27": 0.051514,
                "28": 0.052274,
                "29": 0.053804,
                "30": 0.053211,
                "31": 0.05142,
                "32": 0.052062,
                "33": 0.054249,
                "34": 0.050965,
                "35": 0.054766,
                "36": 0.052849,
                "37": 0.051272,
                "38": 0.053279,
                "39": 0.052813,
                "40": 0.051715,
                "41": 0.051466,
                "42": 0.052805,
                "43": 0.052835,
                "44": 0.052298,
                "45": 0.051207,
                "46": 0.051887,
                "47": 0.052575,
                "48": 0.053717,
                "49": 0.055303,
                "50": 0.052568,
                "51": 0.053135,
                "52": 0.052769,
                "53": 0.05134,
                "54": 0.049573,
                "55": 0.050876,
                "56": 0.051371,
                "57": 0.051212,
                "58": 0.052405,
                "59": 0.052712,
                "60": 0.052345,
                "61": 0.052064,
                "62": 0.054705,
                "63": 0.052167,
                "64": 0.051735,
                "65": 0.050787,
                "66": 0.052395,
                "67": 0.053926,
                "68": 0.055608,
                "69": 0.055576,
                "70": 0.05221,
                "71": 0.052216,
                "72": 0.05176,
                "73": 0.054032,
                "74": 0.051764,
                "75": 0.055712,
                "76": 0.052275,
                "77": 0.051739,
                "78": 0.054363,
                "79": 0.05119,
                "80": 0.052958,
                "81": 0.053296,
                "82": 0.051852,
                "83": 0.05199,
                "84": 0.050935,
                "85": 0.05164,
                "86": 0.054851,
                "87": 0.052851,
                "88": 0.055787,
                "89": 0.051597,
                "90": 0.053103,
                "91": 0.051898,
                "92": 0.051541,
                "93": 0.051451,
                "94": 0.05207,
                "95": 0.052393,
                "96": 0.052212,
                "97": 0.055211,
                "98": 0.070724
            },
            "validation_time": 0.326083,
            "epoch_time": 5.523027181625366,
            "validation_accuracy": 0.0997
        },
        "5": {
            "steps": {
                "1": 0.052777,
                "2": 0.055868,
                "3": 0.051633,
                "4": 0.052141,
                "5": 0.051713,
                "6": 0.055197,
                "7": 0.054315,
                "8": 0.052625,
                "9": 0.05359,
                "10": 0.053001,
                "11": 0.051224,
                "12": 0.051606,
                "13": 0.051615,
                "14": 0.052636,
                "15": 0.052578,
                "16": 0.058127,
                "17": 0.052688,
                "18": 0.057512,
                "19": 0.052854,
                "20": 0.051179,
                "21": 0.051813,
                "22": 0.05331,
                "23": 0.050751,
                "24": 0.054758,
                "25": 0.054738,
                "26": 0.058202,
                "27": 0.052923,
                "28": 0.055519,
                "29": 0.052008,
                "30": 0.054713,
                "31": 0.052692,
                "32": 0.05186,
                "33": 0.054405,
                "34": 0.05604,
                "35": 0.052138,
                "36": 0.056253,
                "37": 0.050817,
                "38": 0.053162,
                "39": 0.055582,
                "40": 0.052175,
                "41": 0.051933,
                "42": 0.052712,
                "43": 0.051309,
                "44": 0.054369,
                "45": 0.052165,
                "46": 0.052309,
                "47": 0.053115,
                "48": 0.051652,
                "49": 0.052413,
                "50": 0.053769,
                "51": 0.05199,
                "52": 0.057181,
                "53": 0.052344,
                "54": 0.0524,
                "55": 0.054772,
                "56": 0.050881,
                "57": 0.055943,
                "58": 0.054169,
                "59": 0.051938,
                "60": 0.052655,
                "61": 0.051548,
                "62": 0.053892,
                "63": 0.056065,
                "64": 0.052292,
                "65": 0.050674,
                "66": 0.050062,
                "67": 0.053656,
                "68": 0.051557,
                "69": 0.053706,
                "70": 0.053999,
                "71": 0.052922,
                "72": 0.050351,
                "73": 0.057415,
                "74": 0.053797,
                "75": 0.052094,
                "76": 0.053435,
                "77": 0.055424,
                "78": 0.052087,
                "79": 0.051814,
                "80": 0.052064,
                "81": 0.052432,
                "82": 0.049626,
                "83": 0.052167,
                "84": 0.050903,
                "85": 0.054188,
                "86": 0.056237,
                "87": 0.051993,
                "88": 0.052099,
                "89": 0.053542,
                "90": 0.05204,
                "91": 0.052857,
                "92": 0.051919,
                "93": 0.052435,
                "94": 0.054051,
                "95": 0.051818,
                "96": 0.051667,
                "97": 0.051158,
                "98": 0.073885
            },
            "validation_time": 0.322497,
            "epoch_time": 5.550745010375977,
            "validation_accuracy": 0.1001
        }
    },
    "computing_system": "p3-4",
    "batch_size": "512"
}
