{
    "init": -1.0,
    "total_training": 98.93248748779297,
    "largest_real_time_delta": 95.07451677322388,
    "fit_time": 98.93248748779297,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 58.511996,
                "2": 0.055544,
                "3": 0.05531,
                "4": 0.059438,
                "5": 0.053098,
                "6": 0.052889,
                "7": 0.053342,
                "8": 0.053212,
                "9": 0.05637,
                "10": 0.054305,
                "11": 0.052528,
                "12": 0.05687,
                "13": 0.054128,
                "14": 0.053295,
                "15": 0.053039,
                "16": 0.053029,
                "17": 0.052078,
                "18": 0.054007,
                "19": 0.057689,
                "20": 0.053132,
                "21": 0.054332,
                "22": 0.051158,
                "23": 0.056412,
                "24": 0.053249,
                "25": 0.053426,
                "26": 0.052491,
                "27": 0.052332,
                "28": 0.051291,
                "29": 0.054086,
                "30": 0.052502,
                "31": 0.053542,
                "32": 0.050548,
                "33": 0.053466,
                "34": 0.056827,
                "35": 0.053221,
                "36": 0.057646,
                "37": 0.058392,
                "38": 0.05484,
                "39": 0.054381,
                "40": 0.054644,
                "41": 0.050956,
                "42": 0.052888,
                "43": 0.052513,
                "44": 0.053481,
                "45": 0.05197,
                "46": 0.053497,
                "47": 0.056682,
                "48": 0.054626,
                "49": 0.056034,
                "50": 0.05815,
                "51": 0.052454,
                "52": 0.053067,
                "53": 0.053234,
                "54": 0.056507,
                "55": 0.052658,
                "56": 0.056074,
                "57": 0.058883,
                "58": 0.056827,
                "59": 0.054961,
                "60": 0.053196,
                "61": 0.054288,
                "62": 0.054267,
                "63": 0.053274,
                "64": 0.053308,
                "65": 0.0548,
                "66": 0.053091,
                "67": 0.052869,
                "68": 0.053938,
                "69": 0.056092,
                "70": 0.059707,
                "71": 0.052343,
                "72": 0.055705,
                "73": 0.053904,
                "74": 0.052983,
                "75": 0.058282,
                "76": 0.053371,
                "77": 0.054429,
                "78": 0.054459,
                "79": 0.058174,
                "80": 0.057834,
                "81": 0.053092,
                "82": 0.050351,
                "83": 0.053334,
                "84": 0.052225,
                "85": 0.053013,
                "86": 0.0536,
                "87": 0.057582,
                "88": 0.053246,
                "89": 0.053023,
                "90": 0.055145,
                "91": 0.053734,
                "92": 0.0544,
                "93": 0.056193,
                "94": 0.054102,
                "95": 0.055718,
                "96": 0.053725,
                "97": 0.053081,
                "98": 0.94848
            },
            "validation_time": 6.717344,
            "epoch_time": 72.32793736457825,
            "validation_accuracy": 0.0984
        },
        "2": {
            "steps": {
                "1": 0.053922,
                "2": 0.054806,
                "3": 0.052877,
                "4": 0.052889,
                "5": 0.053973,
                "6": 0.054969,
                "7": 0.055474,
                "8": 0.054035,
                "9": 0.053324,
                "10": 0.058947,
                "11": 0.053109,
                "12": 0.057782,
                "13": 0.055353,
                "14": 0.056185,
                "15": 0.05157,
                "16": 0.051088,
                "17": 0.054989,
                "18": 0.05236,
                "19": 0.053211,
                "20": 0.057948,
                "21": 0.054093,
                "22": 0.057812,
                "23": 0.052846,
                "24": 0.055173,
                "25": 0.053778,
                "26": 0.053364,
                "27": 0.053366,
                "28": 0.054348,
                "29": 0.053852,
                "30": 0.054139,
                "31": 0.056581,
                "32": 0.050902,
                "33": 0.053852,
                "34": 0.05393,
                "35": 0.053781,
                "36": 0.056607,
                "37": 0.053957,
                "38": 0.058403,
                "39": 0.059337,
                "40": 0.054916,
                "41": 0.055582,
                "42": 0.053505,
                "43": 0.053766,
                "44": 0.055247,
                "45": 0.054059,
                "46": 0.053819,
                "47": 0.055867,
                "48": 0.057004,
                "49": 0.053826,
                "50": 0.051608,
                "51": 0.059768,
                "52": 0.0527,
                "53": 0.053096,
                "54": 0.058389,
                "55": 0.054294,
                "56": 0.055036,
                "57": 0.050787,
                "58": 0.058882,
                "59": 0.058944,
                "60": 0.052961,
                "61": 0.055852,
                "62": 0.057016,
                "63": 0.05121,
                "64": 0.053972,
                "65": 0.058805,
                "66": 0.055678,
                "67": 0.053077,
                "68": 0.053939,
                "69": 0.057463,
                "70": 0.054968,
                "71": 0.053946,
                "72": 0.05301,
                "73": 0.055058,
                "74": 0.052467,
                "75": 0.05324,
                "76": 0.052696,
                "77": 0.050982,
                "78": 0.050863,
                "79": 0.052164,
                "80": 0.055714,
                "81": 0.051725,
                "82": 0.057166,
                "83": 0.054481,
                "84": 0.053791,
                "85": 0.051184,
                "86": 0.052813,
                "87": 0.05319,
                "88": 0.052508,
                "89": 0.052864,
                "90": 0.053088,
                "91": 0.05343,
                "92": 0.053164,
                "93": 0.053385,
                "94": 0.052184,
                "95": 0.053906,
                "96": 0.053359,
                "97": 0.052306,
                "98": 0.076135
            },
            "validation_time": 0.324965,
            "epoch_time": 5.676438331604004,
            "validation_accuracy": 0.0998
        },
        "3": {
            "steps": {
                "1": 0.053659,
                "2": 0.052687,
                "3": 0.053748,
                "4": 0.054466,
                "5": 0.053849,
                "6": 0.053624,
                "7": 0.053986,
                "8": 0.05622,
                "9": 0.052998,
                "10": 0.052575,
                "11": 0.052732,
                "12": 0.054043,
                "13": 0.053908,
                "14": 0.05445,
                "15": 0.053465,
                "16": 0.053402,
                "17": 0.052402,
                "18": 0.053692,
                "19": 0.053043,
                "20": 0.053078,
                "21": 0.053881,
                "22": 0.053132,
                "23": 0.057271,
                "24": 0.057812,
                "25": 0.053693,
                "26": 0.053285,
                "27": 0.055082,
                "28": 0.052571,
                "29": 0.053907,
                "30": 0.052811,
                "31": 0.053283,
                "32": 0.054984,
                "33": 0.055078,
                "34": 0.05272,
                "35": 0.053474,
                "36": 0.054837,
                "37": 0.053055,
                "38": 0.05449,
                "39": 0.056498,
                "40": 0.054445,
                "41": 0.052907,
                "42": 0.052766,
                "43": 0.054596,
                "44": 0.054904,
                "45": 0.057155,
                "46": 0.05567,
                "47": 0.053009,
                "48": 0.05215,
                "49": 0.053797,
                "50": 0.05127,
                "51": 0.054157,
                "52": 0.054372,
                "53": 0.056841,
                "54": 0.059515,
                "55": 0.052395,
                "56": 0.053341,
                "57": 0.053036,
                "58": 0.052636,
                "59": 0.056819,
                "60": 0.055556,
                "61": 0.05325,
                "62": 0.052281,
                "63": 0.056244,
                "64": 0.056234,
                "65": 0.05162,
                "66": 0.055712,
                "67": 0.054546,
                "68": 0.057346,
                "69": 0.055379,
                "70": 0.058282,
                "71": 0.053133,
                "72": 0.053818,
                "73": 0.054295,
                "74": 0.055586,
                "75": 0.052958,
                "76": 0.053904,
                "77": 0.056173,
                "78": 0.054786,
                "79": 0.053921,
                "80": 0.053458,
                "81": 0.05365,
                "82": 0.053725,
                "83": 0.053312,
                "84": 0.05624,
                "85": 0.05845,
                "86": 0.058911,
                "87": 0.054553,
                "88": 0.053176,
                "89": 0.053661,
                "90": 0.056096,
                "91": 0.058533,
                "92": 0.054273,
                "93": 0.053459,
                "94": 0.05323,
                "95": 0.053173,
                "96": 0.054366,
                "97": 0.056812,
                "98": 0.072855
            },
            "validation_time": 0.320357,
            "epoch_time": 5.67262077331543,
            "validation_accuracy": 0.1
        },
        "4": {
            "steps": {
                "1": 0.052687,
                "2": 0.054632,
                "3": 0.055653,
                "4": 0.055845,
                "5": 0.053402,
                "6": 0.050952,
                "7": 0.054238,
                "8": 0.056988,
                "9": 0.051833,
                "10": 0.053763,
                "11": 0.054725,
                "12": 0.055688,
                "13": 0.052789,
                "14": 0.055505,
                "15": 0.052599,
                "16": 0.050461,
                "17": 0.054414,
                "18": 0.053066,
                "19": 0.052942,
                "20": 0.058802,
                "21": 0.055782,
                "22": 0.053783,
                "23": 0.05254,
                "24": 0.053775,
                "25": 0.054053,
                "26": 0.053098,
                "27": 0.055208,
                "28": 0.052613,
                "29": 0.053858,
                "30": 0.054155,
                "31": 0.058227,
                "32": 0.054673,
                "33": 0.052848,
                "34": 0.052742,
                "35": 0.052713,
                "36": 0.053419,
                "37": 0.053921,
                "38": 0.052456,
                "39": 0.053738,
                "40": 0.058872,
                "41": 0.054523,
                "42": 0.053219,
                "43": 0.052269,
                "44": 0.053421,
                "45": 0.052801,
                "46": 0.057678,
                "47": 0.05273,
                "48": 0.05395,
                "49": 0.05554,
                "50": 0.051069,
                "51": 0.056497,
                "52": 0.053451,
                "53": 0.05361,
                "54": 0.054068,
                "55": 0.054132,
                "56": 0.053557,
                "57": 0.053389,
                "58": 0.057802,
                "59": 0.052165,
                "60": 0.052888,
                "61": 0.055647,
                "62": 0.058035,
                "63": 0.058408,
                "64": 0.059122,
                "65": 0.055745,
                "66": 0.053229,
                "67": 0.056972,
                "68": 0.058261,
                "69": 0.052703,
                "70": 0.054442,
                "71": 0.053884,
                "72": 0.052925,
                "73": 0.057541,
                "74": 0.054093,
                "75": 0.053539,
                "76": 0.053951,
                "77": 0.054036,
                "78": 0.053267,
                "79": 0.053994,
                "80": 0.057364,
                "81": 0.054131,
                "82": 0.053252,
                "83": 0.057836,
                "84": 0.054723,
                "85": 0.054892,
                "86": 0.053468,
                "87": 0.052689,
                "88": 0.05303,
                "89": 0.054293,
                "90": 0.053883,
                "91": 0.05402,
                "92": 0.053272,
                "93": 0.054876,
                "94": 0.053721,
                "95": 0.05386,
                "96": 0.053607,
                "97": 0.052232,
                "98": 0.073108
            },
            "validation_time": 0.325816,
            "epoch_time": 5.671735048294067,
            "validation_accuracy": 0.0996
        },
        "5": {
            "steps": {
                "1": 0.061926,
                "2": 0.051131,
                "3": 0.055808,
                "4": 0.054711,
                "5": 0.056765,
                "6": 0.058663,
                "7": 0.054297,
                "8": 0.058573,
                "9": 0.05508,
                "10": 0.054173,
                "11": 0.058327,
                "12": 0.056019,
                "13": 0.053441,
                "14": 0.054538,
                "15": 0.055492,
                "16": 0.05315,
                "17": 0.054275,
                "18": 0.056074,
                "19": 0.057849,
                "20": 0.054352,
                "21": 0.054616,
                "22": 0.053466,
                "23": 0.054198,
                "24": 0.054848,
                "25": 0.054521,
                "26": 0.052565,
                "27": 0.052901,
                "28": 0.054122,
                "29": 0.054119,
                "30": 0.054223,
                "31": 0.057119,
                "32": 0.052302,
                "33": 0.054847,
                "34": 0.052206,
                "35": 0.054641,
                "36": 0.053996,
                "37": 0.053661,
                "38": 0.053746,
                "39": 0.054094,
                "40": 0.05781,
                "41": 0.054071,
                "42": 0.050799,
                "43": 0.053292,
                "44": 0.053653,
                "45": 0.054166,
                "46": 0.05297,
                "47": 0.057998,
                "48": 0.058777,
                "49": 0.05192,
                "50": 0.05661,
                "51": 0.058543,
                "52": 0.059307,
                "53": 0.054918,
                "54": 0.055602,
                "55": 0.053098,
                "56": 0.055438,
                "57": 0.055783,
                "58": 0.054646,
                "59": 0.053938,
                "60": 0.052722,
                "61": 0.057627,
                "62": 0.052098,
                "63": 0.053232,
                "64": 0.053753,
                "65": 0.053578,
                "66": 0.058962,
                "67": 0.053416,
                "68": 0.053547,
                "69": 0.05383,
                "70": 0.053004,
                "71": 0.055546,
                "72": 0.053627,
                "73": 0.05619,
                "74": 0.0539,
                "75": 0.052578,
                "76": 0.053034,
                "77": 0.054954,
                "78": 0.055645,
                "79": 0.05306,
                "80": 0.052197,
                "81": 0.056403,
                "82": 0.057709,
                "83": 0.057452,
                "84": 0.053702,
                "85": 0.054689,
                "86": 0.053877,
                "87": 0.053466,
                "88": 0.053228,
                "89": 0.053268,
                "90": 0.053227,
                "91": 0.054915,
                "92": 0.058121,
                "93": 0.05353,
                "94": 0.052818,
                "95": 0.056334,
                "96": 0.052544,
                "97": 0.055604,
                "98": 0.074858
            },
            "validation_time": 0.332696,
            "epoch_time": 5.7248241901397705,
            "validation_accuracy": 0.1002
        }
    },
    "computing_system": "p3-4",
    "batch_size": "512"
}
