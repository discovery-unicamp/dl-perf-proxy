{
    "init": -1.0,
    "total_training": 89.41702342033386,
    "largest_real_time_delta": 85.5128219127655,
    "fit_time": 89.41702342033386,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 59.538585,
                "2": 0.07021,
                "3": 0.064824,
                "4": 0.065243,
                "5": 0.065753,
                "6": 0.066621,
                "7": 0.065295,
                "8": 0.069016,
                "9": 0.066388,
                "10": 0.064868,
                "11": 0.069412,
                "12": 0.065216,
                "13": 0.07,
                "14": 0.068818,
                "15": 0.067993,
                "16": 0.066824,
                "17": 0.068882,
                "18": 0.066038,
                "19": 0.067616,
                "20": 0.065875,
                "21": 0.065599,
                "22": 0.066101,
                "23": 0.064896,
                "24": 0.063877,
                "25": 0.067969,
                "26": 0.070155,
                "27": 0.070191,
                "28": 0.068642,
                "29": 0.069318,
                "30": 0.065689,
                "31": 0.064802,
                "32": 0.065553,
                "33": 0.063566,
                "34": 0.064252,
                "35": 0.065777,
                "36": 0.065801,
                "37": 0.0653,
                "38": 0.068266,
                "39": 0.065117,
                "40": 0.063842,
                "41": 0.070025,
                "42": 0.06565,
                "43": 0.063835,
                "44": 0.065062,
                "45": 0.065805,
                "46": 0.064909,
                "47": 0.064603,
                "48": 0.065358,
                "49": 1.270885
            },
            "validation_time": 6.571346,
            "epoch_time": 71.44820046424866,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.069604,
                "2": 0.065882,
                "3": 0.063514,
                "4": 0.06519,
                "5": 0.063337,
                "6": 0.065853,
                "7": 0.065317,
                "8": 0.066997,
                "9": 0.067685,
                "10": 0.066028,
                "11": 0.065903,
                "12": 0.064502,
                "13": 0.068506,
                "14": 0.065232,
                "15": 0.065233,
                "16": 0.062468,
                "17": 0.06885,
                "18": 0.064814,
                "19": 0.068336,
                "20": 0.06478,
                "21": 0.066375,
                "22": 0.064545,
                "23": 0.064322,
                "24": 0.064351,
                "25": 0.069064,
                "26": 0.064013,
                "27": 0.063845,
                "28": 0.064488,
                "29": 0.061786,
                "30": 0.062548,
                "31": 0.066267,
                "32": 0.066073,
                "33": 0.068697,
                "34": 0.067098,
                "35": 0.064031,
                "36": 0.065787,
                "37": 0.065694,
                "38": 0.064542,
                "39": 0.065932,
                "40": 0.065041,
                "41": 0.065589,
                "42": 0.066097,
                "43": 0.066358,
                "44": 0.06518,
                "45": 0.068761,
                "46": 0.065011,
                "47": 0.068276,
                "48": 0.064726,
                "49": 0.088246
            },
            "validation_time": 0.240227,
            "epoch_time": 3.486759662628174,
            "validation_accuracy": 0.1001
        },
        "3": {
            "steps": {
                "1": 0.066607,
                "2": 0.06877,
                "3": 0.06395,
                "4": 0.065442,
                "5": 0.063672,
                "6": 0.066509,
                "7": 0.065278,
                "8": 0.064128,
                "9": 0.06482,
                "10": 0.070565,
                "11": 0.066071,
                "12": 0.065381,
                "13": 0.064575,
                "14": 0.064555,
                "15": 0.064464,
                "16": 0.064523,
                "17": 0.064748,
                "18": 0.071607,
                "19": 0.065363,
                "20": 0.064451,
                "21": 0.065105,
                "22": 0.0645,
                "23": 0.069248,
                "24": 0.064543,
                "25": 0.064515,
                "26": 0.068197,
                "27": 0.066111,
                "28": 0.068913,
                "29": 0.064033,
                "30": 0.066574,
                "31": 0.065202,
                "32": 0.063277,
                "33": 0.068019,
                "34": 0.066064,
                "35": 0.068315,
                "36": 0.065617,
                "37": 0.066805,
                "38": 0.068399,
                "39": 0.065223,
                "40": 0.066331,
                "41": 0.06651,
                "42": 0.064123,
                "43": 0.066266,
                "44": 0.067404,
                "45": 0.063946,
                "46": 0.068382,
                "47": 0.067815,
                "48": 0.063684,
                "49": 0.086326
            },
            "validation_time": 0.24535,
            "epoch_time": 3.5060746669769287,
            "validation_accuracy": 0.0999
        },
        "4": {
            "steps": {
                "1": 0.067055,
                "2": 0.068072,
                "3": 0.064719,
                "4": 0.070889,
                "5": 0.06933,
                "6": 0.0704,
                "7": 0.065845,
                "8": 0.068573,
                "9": 0.068129,
                "10": 0.064251,
                "11": 0.068232,
                "12": 0.065007,
                "13": 0.067861,
                "14": 0.070781,
                "15": 0.065815,
                "16": 0.06497,
                "17": 0.068568,
                "18": 0.066178,
                "19": 0.065261,
                "20": 0.06349,
                "21": 0.066141,
                "22": 0.06531,
                "23": 0.066615,
                "24": 0.068573,
                "25": 0.067296,
                "26": 0.067056,
                "27": 0.06575,
                "28": 0.064231,
                "29": 0.065314,
                "30": 0.066584,
                "31": 0.070683,
                "32": 0.06809,
                "33": 0.064697,
                "34": 0.065607,
                "35": 0.067717,
                "36": 0.069566,
                "37": 0.068672,
                "38": 0.071778,
                "39": 0.064888,
                "40": 0.064064,
                "41": 0.06563,
                "42": 0.06942,
                "43": 0.065948,
                "44": 0.06535,
                "45": 0.065026,
                "46": 0.069013,
                "47": 0.064452,
                "48": 0.064599,
                "49": 0.085741
            },
            "validation_time": 0.246355,
            "epoch_time": 3.54925537109375,
            "validation_accuracy": 0.0998
        },
        "5": {
            "steps": {
                "1": 0.0659,
                "2": 0.068755,
                "3": 0.065536,
                "4": 0.064825,
                "5": 0.064792,
                "6": 0.06493,
                "7": 0.071876,
                "8": 0.06676,
                "9": 0.064951,
                "10": 0.06535,
                "11": 0.065135,
                "12": 0.064191,
                "13": 0.065566,
                "14": 0.065546,
                "15": 0.066548,
                "16": 0.068323,
                "17": 0.064896,
                "18": 0.066548,
                "19": 0.063871,
                "20": 0.069607,
                "21": 0.06743,
                "22": 0.069614,
                "23": 0.0668,
                "24": 0.065546,
                "25": 0.065126,
                "26": 0.068866,
                "27": 0.06619,
                "28": 0.065721,
                "29": 0.065512,
                "30": 0.065658,
                "31": 0.069557,
                "32": 0.070086,
                "33": 0.069701,
                "34": 0.064843,
                "35": 0.065309,
                "36": 0.065884,
                "37": 0.06547,
                "38": 0.065682,
                "39": 0.067071,
                "40": 0.063678,
                "41": 0.065134,
                "42": 0.065158,
                "43": 0.064644,
                "44": 0.064941,
                "45": 0.068338,
                "46": 0.064938,
                "47": 0.066365,
                "48": 0.065081,
                "49": 0.084959
            },
            "validation_time": 0.24852,
            "epoch_time": 3.521587371826172,
            "validation_accuracy": 0.0999
        }
    },
    "computing_system": "p3-4",
    "batch_size": "1024"
}
