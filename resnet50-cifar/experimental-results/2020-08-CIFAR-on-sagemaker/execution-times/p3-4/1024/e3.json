{
    "init": -1.0,
    "total_training": 90.43958640098572,
    "largest_real_time_delta": 85.44181108474731,
    "fit_time": 90.43958640098572,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 59.41988,
                "2": 0.068123,
                "3": 0.065446,
                "4": 0.064369,
                "5": 0.064729,
                "6": 0.064011,
                "7": 0.063679,
                "8": 0.06885,
                "9": 0.066021,
                "10": 0.063068,
                "11": 0.063133,
                "12": 0.063576,
                "13": 0.064718,
                "14": 0.06544,
                "15": 0.064039,
                "16": 0.063157,
                "17": 0.066212,
                "18": 0.064469,
                "19": 0.068672,
                "20": 0.063732,
                "21": 0.068613,
                "22": 0.065372,
                "23": 0.06465,
                "24": 0.063208,
                "25": 0.064878,
                "26": 0.068256,
                "27": 0.06308,
                "28": 0.066677,
                "29": 0.063205,
                "30": 0.067387,
                "31": 0.068767,
                "32": 0.067373,
                "33": 0.063302,
                "34": 0.066765,
                "35": 0.063296,
                "36": 0.063435,
                "37": 0.062625,
                "38": 0.064305,
                "39": 0.063685,
                "40": 0.065218,
                "41": 0.063767,
                "42": 0.062142,
                "43": 0.067869,
                "44": 0.068884,
                "45": 0.064747,
                "46": 0.070838,
                "47": 0.065558,
                "48": 0.063861,
                "49": 1.285831
            },
            "validation_time": 6.740548,
            "epoch_time": 71.49444007873535,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.064522,
                "2": 0.06462,
                "3": 0.065339,
                "4": 0.066677,
                "5": 0.065361,
                "6": 0.065886,
                "7": 0.063235,
                "8": 0.066781,
                "9": 0.068085,
                "10": 0.068217,
                "11": 0.067791,
                "12": 0.063559,
                "13": 0.063362,
                "14": 0.065365,
                "15": 0.065575,
                "16": 0.065672,
                "17": 0.066631,
                "18": 0.06416,
                "19": 0.067285,
                "20": 0.066814,
                "21": 0.064421,
                "22": 0.067413,
                "23": 0.068774,
                "24": 0.065472,
                "25": 0.066498,
                "26": 0.06407,
                "27": 0.06485,
                "28": 0.065685,
                "29": 0.063961,
                "30": 0.064511,
                "31": 0.062775,
                "32": 0.069971,
                "33": 0.062955,
                "34": 0.065017,
                "35": 0.063542,
                "36": 0.062403,
                "37": 0.068704,
                "38": 0.062561,
                "39": 0.068321,
                "40": 0.065674,
                "41": 0.06465,
                "42": 0.066811,
                "43": 0.065906,
                "44": 0.063194,
                "45": 0.064787,
                "46": 0.064368,
                "47": 0.063856,
                "48": 0.065854,
                "49": 0.088502
            },
            "validation_time": 0.246296,
            "epoch_time": 3.482548475265503,
            "validation_accuracy": 0.0
        },
        "3": {
            "steps": {
                "1": 0.065542,
                "2": 0.063776,
                "3": 0.06565,
                "4": 0.069533,
                "5": 0.062681,
                "6": 0.067712,
                "7": 0.064728,
                "8": 0.067075,
                "9": 0.06923,
                "10": 0.068284,
                "11": 0.06411,
                "12": 0.065328,
                "13": 0.067827,
                "14": 0.067345,
                "15": 0.06343,
                "16": 0.064246,
                "17": 0.063921,
                "18": 0.063414,
                "19": 0.065595,
                "20": 0.064799,
                "21": 0.064569,
                "22": 0.068437,
                "23": 0.069763,
                "24": 0.064923,
                "25": 0.06404,
                "26": 0.068201,
                "27": 0.064989,
                "28": 0.068571,
                "29": 0.067967,
                "30": 0.070109,
                "31": 0.065384,
                "32": 0.06392,
                "33": 0.06447,
                "34": 0.066917,
                "35": 0.063421,
                "36": 0.068152,
                "37": 0.067247,
                "38": 0.065296,
                "39": 0.063356,
                "40": 0.063096,
                "41": 0.066916,
                "42": 0.063539,
                "43": 0.065773,
                "44": 0.063988,
                "45": 0.06996,
                "46": 0.066525,
                "47": 0.062861,
                "48": 0.066231,
                "49": 0.083611
            },
            "validation_time": 0.247047,
            "epoch_time": 3.499436140060425,
            "validation_accuracy": 0.0
        },
        "4": {
            "steps": {
                "1": 0.069576,
                "2": 0.063159,
                "3": 0.065479,
                "4": 0.065266,
                "5": 0.068362,
                "6": 0.06475,
                "7": 0.067541,
                "8": 0.067582,
                "9": 0.06802,
                "10": 0.064236,
                "11": 0.066862,
                "12": 0.06275,
                "13": 0.063369,
                "14": 0.063069,
                "15": 0.06443,
                "16": 0.070764,
                "17": 0.062567,
                "18": 0.063528,
                "19": 0.065275,
                "20": 0.064766,
                "21": 0.064678,
                "22": 0.069716,
                "23": 0.068028,
                "24": 0.063937,
                "25": 0.064237,
                "26": 0.062768,
                "27": 0.065876,
                "28": 0.064139,
                "29": 0.063458,
                "30": 0.06362,
                "31": 0.063829,
                "32": 0.064367,
                "33": 0.068182,
                "34": 0.064302,
                "35": 0.062962,
                "36": 0.064179,
                "37": 0.064561,
                "38": 0.067411,
                "39": 0.068924,
                "40": 0.064338,
                "41": 0.067878,
                "42": 0.064993,
                "43": 0.064869,
                "44": 0.063378,
                "45": 0.063637,
                "46": 0.064817,
                "47": 0.067332,
                "48": 0.063419,
                "49": 0.084806
            },
            "validation_time": 0.254361,
            "epoch_time": 3.4799747467041016,
            "validation_accuracy": 0.0999
        },
        "5": {
            "steps": {
                "1": 0.065693,
                "2": 0.066877,
                "3": 0.063623,
                "4": 0.065138,
                "5": 0.065288,
                "6": 0.064304,
                "7": 0.068158,
                "8": 0.06339,
                "9": 0.069655,
                "10": 0.068136,
                "11": 0.063625,
                "12": 0.064481,
                "13": 0.063042,
                "14": 0.066393,
                "15": 0.064842,
                "16": 0.065455,
                "17": 0.063754,
                "18": 0.065504,
                "19": 0.066782,
                "20": 0.064193,
                "21": 0.064809,
                "22": 0.064295,
                "23": 0.069231,
                "24": 0.064074,
                "25": 0.06834,
                "26": 0.06442,
                "27": 0.06387,
                "28": 0.064586,
                "29": 0.062542,
                "30": 0.068565,
                "31": 0.064555,
                "32": 0.064081,
                "33": 0.065191,
                "34": 0.067664,
                "35": 0.064168,
                "36": 0.064166,
                "37": 0.063931,
                "38": 0.068025,
                "39": 0.06753,
                "40": 0.065159,
                "41": 0.064952,
                "42": 0.065246,
                "43": 0.06355,
                "44": 0.064493,
                "45": 0.064626,
                "46": 0.064929,
                "47": 0.069523,
                "48": 0.064498,
                "49": 0.090065
            },
            "validation_time": 0.249274,
            "epoch_time": 3.484395742416382,
            "validation_accuracy": 0.0999
        }
    },
    "computing_system": "p3-4",
    "batch_size": "1024"
}
