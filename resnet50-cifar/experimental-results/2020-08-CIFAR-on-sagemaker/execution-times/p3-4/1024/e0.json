{
    "init": -1.0,
    "total_training": 88.11411142349243,
    "largest_real_time_delta": 84.29477262496948,
    "fit_time": 88.11411142349243,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 58.749143,
                "2": 0.068397,
                "3": 0.066527,
                "4": 0.065253,
                "5": 0.068069,
                "6": 0.064251,
                "7": 0.06803,
                "8": 0.069249,
                "9": 0.06351,
                "10": 0.063989,
                "11": 0.064108,
                "12": 0.06172,
                "13": 0.063401,
                "14": 0.06491,
                "15": 0.064548,
                "16": 0.063387,
                "17": 0.063016,
                "18": 0.069844,
                "19": 0.065029,
                "20": 0.062587,
                "21": 0.06495,
                "22": 0.062576,
                "23": 0.063325,
                "24": 0.063515,
                "25": 0.065505,
                "26": 0.061696,
                "27": 0.065584,
                "28": 0.063961,
                "29": 0.062273,
                "30": 0.064573,
                "31": 0.06347,
                "32": 0.066142,
                "33": 0.061752,
                "34": 0.068944,
                "35": 0.064101,
                "36": 0.063893,
                "37": 0.066732,
                "38": 0.067697,
                "39": 0.064741,
                "40": 0.065087,
                "41": 0.065504,
                "42": 0.064157,
                "43": 0.064229,
                "44": 0.064332,
                "45": 0.065239,
                "46": 0.068553,
                "47": 0.067387,
                "48": 0.068635,
                "49": 1.30279
            },
            "validation_time": 6.506488,
            "epoch_time": 70.54315638542175,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.069377,
                "2": 0.06466,
                "3": 0.064943,
                "4": 0.066541,
                "5": 0.06831,
                "6": 0.066188,
                "7": 0.063081,
                "8": 0.06847,
                "9": 0.063183,
                "10": 0.063016,
                "11": 0.063663,
                "12": 0.066329,
                "13": 0.062581,
                "14": 0.063951,
                "15": 0.064391,
                "16": 0.063297,
                "17": 0.064488,
                "18": 0.063874,
                "19": 0.066478,
                "20": 0.062856,
                "21": 0.064829,
                "22": 0.062595,
                "23": 0.065468,
                "24": 0.065645,
                "25": 0.062828,
                "26": 0.063242,
                "27": 0.062639,
                "28": 0.064213,
                "29": 0.061669,
                "30": 0.062578,
                "31": 0.063413,
                "32": 0.060563,
                "33": 0.062662,
                "34": 0.0645,
                "35": 0.063837,
                "36": 0.06458,
                "37": 0.066632,
                "38": 0.062301,
                "39": 0.063393,
                "40": 0.065012,
                "41": 0.063718,
                "42": 0.063767,
                "43": 0.064478,
                "44": 0.0661,
                "45": 0.064987,
                "46": 0.063898,
                "47": 0.065655,
                "48": 0.063388,
                "49": 0.083532
            },
            "validation_time": 0.245403,
            "epoch_time": 3.4230971336364746,
            "validation_accuracy": 8.4363e-05
        },
        "3": {
            "steps": {
                "1": 0.068117,
                "2": 0.063534,
                "3": 0.063042,
                "4": 0.062656,
                "5": 0.063841,
                "6": 0.066121,
                "7": 0.063326,
                "8": 0.066504,
                "9": 0.064341,
                "10": 0.062994,
                "11": 0.064659,
                "12": 0.067562,
                "13": 0.065988,
                "14": 0.066458,
                "15": 0.061367,
                "16": 0.066994,
                "17": 0.063822,
                "18": 0.062324,
                "19": 0.063514,
                "20": 0.062799,
                "21": 0.063823,
                "22": 0.062367,
                "23": 0.063247,
                "24": 0.063116,
                "25": 0.067131,
                "26": 0.063707,
                "27": 0.06231,
                "28": 0.063573,
                "29": 0.064021,
                "30": 0.066497,
                "31": 0.064455,
                "32": 0.062493,
                "33": 0.065708,
                "34": 0.063546,
                "35": 0.064882,
                "36": 0.065892,
                "37": 0.068188,
                "38": 0.063311,
                "39": 0.06289,
                "40": 0.064594,
                "41": 0.067663,
                "42": 0.063198,
                "43": 0.064349,
                "44": 0.062218,
                "45": 0.063047,
                "46": 0.064517,
                "47": 0.067721,
                "48": 0.066922,
                "49": 0.086974
            },
            "validation_time": 0.245777,
            "epoch_time": 3.4337642192840576,
            "validation_accuracy": 0.0999
        },
        "4": {
            "steps": {
                "1": 0.064921,
                "2": 0.06388,
                "3": 0.063819,
                "4": 0.063781,
                "5": 0.069046,
                "6": 0.06423,
                "7": 0.065256,
                "8": 0.062505,
                "9": 0.064599,
                "10": 0.066665,
                "11": 0.064856,
                "12": 0.067553,
                "13": 0.06639,
                "14": 0.066985,
                "15": 0.069969,
                "16": 0.064835,
                "17": 0.064202,
                "18": 0.068709,
                "19": 0.065356,
                "20": 0.063955,
                "21": 0.064153,
                "22": 0.068163,
                "23": 0.068978,
                "24": 0.064845,
                "25": 0.064409,
                "26": 0.062284,
                "27": 0.065027,
                "28": 0.067537,
                "29": 0.06671,
                "30": 0.0671,
                "31": 0.067781,
                "32": 0.069751,
                "33": 0.067115,
                "34": 0.067339,
                "35": 0.06984,
                "36": 0.063685,
                "37": 0.063037,
                "38": 0.064996,
                "39": 0.064481,
                "40": 0.062817,
                "41": 0.068161,
                "42": 0.063264,
                "43": 0.064299,
                "44": 0.065225,
                "45": 0.063287,
                "46": 0.06251,
                "47": 0.064383,
                "48": 0.061415,
                "49": 0.080286
            },
            "validation_time": 0.241452,
            "epoch_time": 3.4714956283569336,
            "validation_accuracy": 0.0999
        },
        "5": {
            "steps": {
                "1": 0.064575,
                "2": 0.067288,
                "3": 0.065111,
                "4": 0.063068,
                "5": 0.066911,
                "6": 0.067599,
                "7": 0.063634,
                "8": 0.06375,
                "9": 0.068348,
                "10": 0.063403,
                "11": 0.06338,
                "12": 0.064082,
                "13": 0.062948,
                "14": 0.063528,
                "15": 0.063493,
                "16": 0.064242,
                "17": 0.064519,
                "18": 0.06357,
                "19": 0.06393,
                "20": 0.064155,
                "21": 0.067188,
                "22": 0.063397,
                "23": 0.066205,
                "24": 0.065647,
                "25": 0.063098,
                "26": 0.064077,
                "27": 0.067248,
                "28": 0.064132,
                "29": 0.064991,
                "30": 0.064811,
                "31": 0.065529,
                "32": 0.061557,
                "33": 0.06274,
                "34": 0.064285,
                "35": 0.063749,
                "36": 0.063824,
                "37": 0.066509,
                "38": 0.066058,
                "39": 0.06319,
                "40": 0.063866,
                "41": 0.063321,
                "42": 0.063794,
                "43": 0.063872,
                "44": 0.06473,
                "45": 0.06366,
                "46": 0.06339,
                "47": 0.064521,
                "48": 0.062496,
                "49": 0.082626
            },
            "validation_time": 0.240556,
            "epoch_time": 3.4223122596740723,
            "validation_accuracy": 0.1016
        }
    },
    "computing_system": "p3-4",
    "batch_size": "1024"
}
