{
    "init": -1.0,
    "total_training": 120.55296063423157,
    "largest_real_time_delta": 117.22739362716675,
    "fit_time": 120.55296063423157,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 18.606376,
                "2": 0.333061,
                "3": 0.333377,
                "4": 0.33008,
                "5": 0.329283,
                "6": 0.334545,
                "7": 0.330865,
                "8": 0.328196,
                "9": 0.327379,
                "10": 0.335638,
                "11": 0.331228,
                "12": 0.328034,
                "13": 0.331477,
                "14": 0.335207,
                "15": 0.33179,
                "16": 0.314035,
                "17": 0.338245,
                "18": 0.335375,
                "19": 0.332628,
                "20": 0.329129,
                "21": 0.329953,
                "22": 0.335145,
                "23": 0.331939,
                "24": 0.331388,
                "25": 0.335236,
                "26": 0.331605,
                "27": 0.333673,
                "28": 0.330846,
                "29": 0.329786,
                "30": 0.335693,
                "31": 0.330854,
                "32": 0.330431,
                "33": 0.334986,
                "34": 0.331756,
                "35": 0.328089,
                "36": 0.336494,
                "37": 0.331831,
                "38": 0.33563,
                "39": 0.333618,
                "40": 0.336055,
                "41": 0.332674,
                "42": 0.335726,
                "43": 0.3344,
                "44": 0.33428,
                "45": 0.333465,
                "46": 0.33475,
                "47": 0.334939,
                "48": 0.33378,
                "49": 6.204619
            },
            "validation_time": 4.690674,
            "epoch_time": 45.862685680389404,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.342016,
                "2": 0.336506,
                "3": 0.338018,
                "4": 0.340946,
                "5": 0.336551,
                "6": 0.337505,
                "7": 0.339349,
                "8": 0.336826,
                "9": 0.339241,
                "10": 0.340611,
                "11": 0.336731,
                "12": 0.339196,
                "13": 0.343132,
                "14": 0.34024,
                "15": 0.338293,
                "16": 0.340453,
                "17": 0.343563,
                "18": 0.341686,
                "19": 0.339425,
                "20": 0.339087,
                "21": 0.340261,
                "22": 0.34539,
                "23": 0.343031,
                "24": 0.341449,
                "25": 0.342431,
                "26": 0.339287,
                "27": 0.339647,
                "28": 0.343492,
                "29": 0.342938,
                "30": 0.343235,
                "31": 0.345026,
                "32": 0.342955,
                "33": 0.341879,
                "34": 0.338798,
                "35": 0.343899,
                "36": 0.342748,
                "37": 0.342679,
                "38": 0.344422,
                "39": 0.343885,
                "40": 0.343863,
                "41": 0.341717,
                "42": 0.342398,
                "43": 0.340767,
                "44": 0.340771,
                "45": 0.342936,
                "46": 0.344521,
                "47": 0.344188,
                "48": 0.343882,
                "49": 0.300086
            },
            "validation_time": 0.830827,
            "epoch_time": 17.51613736152649,
            "validation_accuracy": 0.1
        },
        "3": {
            "steps": {
                "1": 0.343127,
                "2": 0.339027,
                "3": 0.344307,
                "4": 0.343867,
                "5": 0.342117,
                "6": 0.343461,
                "7": 0.347019,
                "8": 0.344478,
                "9": 0.344065,
                "10": 0.346459,
                "11": 0.346163,
                "12": 0.34385,
                "13": 0.346777,
                "14": 0.346148,
                "15": 0.343695,
                "16": 0.345476,
                "17": 0.34381,
                "18": 0.344915,
                "19": 0.345345,
                "20": 0.34254,
                "21": 0.345089,
                "22": 0.345909,
                "23": 0.345891,
                "24": 0.345598,
                "25": 0.34469,
                "26": 0.345514,
                "27": 0.345952,
                "28": 0.346703,
                "29": 0.345125,
                "30": 0.347284,
                "31": 0.348226,
                "32": 0.348817,
                "33": 0.345202,
                "34": 0.347014,
                "35": 0.346284,
                "36": 0.346639,
                "37": 0.347224,
                "38": 0.346194,
                "39": 0.347282,
                "40": 0.346332,
                "41": 0.346055,
                "42": 0.344383,
                "43": 0.346863,
                "44": 0.344433,
                "45": 0.345084,
                "46": 0.344159,
                "47": 0.344473,
                "48": 0.346916,
                "49": 0.297956
            },
            "validation_time": 0.823226,
            "epoch_time": 17.70045757293701,
            "validation_accuracy": 0.0999
        },
        "4": {
            "steps": {
                "1": 0.346692,
                "2": 0.346703,
                "3": 0.349278,
                "4": 0.350348,
                "5": 0.347487,
                "6": 0.34734,
                "7": 0.348607,
                "8": 0.349208,
                "9": 0.35059,
                "10": 0.349565,
                "11": 0.347509,
                "12": 0.350308,
                "13": 0.348547,
                "14": 0.34714,
                "15": 0.346604,
                "16": 0.346527,
                "17": 0.335179,
                "18": 0.352562,
                "19": 0.352677,
                "20": 0.351349,
                "21": 0.349775,
                "22": 0.351428,
                "23": 0.349691,
                "24": 0.334446,
                "25": 0.35401,
                "26": 0.352288,
                "27": 0.349254,
                "28": 0.351427,
                "29": 0.35228,
                "30": 0.351027,
                "31": 0.350921,
                "32": 0.352893,
                "33": 0.353159,
                "34": 0.3513,
                "35": 0.350916,
                "36": 0.350541,
                "37": 0.355766,
                "38": 0.351445,
                "39": 0.350943,
                "40": 0.35038,
                "41": 0.352552,
                "42": 0.352636,
                "43": 0.354146,
                "44": 0.352665,
                "45": 0.354601,
                "46": 0.352082,
                "47": 0.354072,
                "48": 0.353626,
                "49": 0.309227
            },
            "validation_time": 0.838461,
            "epoch_time": 17.955487489700317,
            "validation_accuracy": 0.0999
        },
        "5": {
            "steps": {
                "1": 0.350705,
                "2": 0.351082,
                "3": 0.356957,
                "4": 0.353357,
                "5": 0.350625,
                "6": 0.35714,
                "7": 0.353717,
                "8": 0.355437,
                "9": 0.353464,
                "10": 0.354551,
                "11": 0.354207,
                "12": 0.35522,
                "13": 0.353786,
                "14": 0.355796,
                "15": 0.354629,
                "16": 0.352021,
                "17": 0.35493,
                "18": 0.354805,
                "19": 0.353456,
                "20": 0.35286,
                "21": 0.354661,
                "22": 0.3568,
                "23": 0.355792,
                "24": 0.353782,
                "25": 0.353408,
                "26": 0.355784,
                "27": 0.356755,
                "28": 0.356224,
                "29": 0.354913,
                "30": 0.353833,
                "31": 0.358565,
                "32": 0.353301,
                "33": 0.357388,
                "34": 0.35446,
                "35": 0.354284,
                "36": 0.356636,
                "37": 0.354983,
                "38": 0.360556,
                "39": 0.356183,
                "40": 0.357699,
                "41": 0.355076,
                "42": 0.3581,
                "43": 0.354754,
                "44": 0.358685,
                "45": 0.356547,
                "46": 0.355726,
                "47": 0.35669,
                "48": 0.353394,
                "49": 0.311167
            },
            "validation_time": 0.833869,
            "epoch_time": 18.191962718963623,
            "validation_accuracy": 0.1001
        }
    },
    "computing_system": "g4dn8xlarge-1",
    "batch_size": "1024"
}
