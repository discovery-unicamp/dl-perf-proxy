{
    "init": -1.0,
    "total_training": 118.84576559066772,
    "largest_real_time_delta": 115.48534512519836,
    "fit_time": 118.84576559066772,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 15.612493,
                "2": 0.172444,
                "3": 0.171309,
                "4": 0.171654,
                "5": 0.170502,
                "6": 0.172441,
                "7": 0.170297,
                "8": 0.169709,
                "9": 0.171905,
                "10": 0.170117,
                "11": 0.173404,
                "12": 0.171209,
                "13": 0.173279,
                "14": 0.169617,
                "15": 0.1706,
                "16": 0.170492,
                "17": 0.168937,
                "18": 0.174033,
                "19": 0.170513,
                "20": 0.169855,
                "21": 0.17212,
                "22": 0.170162,
                "23": 0.172671,
                "24": 0.169379,
                "25": 0.173253,
                "26": 0.17081,
                "27": 0.171034,
                "28": 0.172739,
                "29": 0.171055,
                "30": 0.172876,
                "31": 0.170869,
                "32": 0.172963,
                "33": 0.169955,
                "34": 0.171496,
                "35": 0.170655,
                "36": 0.172023,
                "37": 0.171938,
                "38": 0.17123,
                "39": 0.174239,
                "40": 0.170215,
                "41": 0.173919,
                "42": 0.17099,
                "43": 0.172498,
                "44": 0.171833,
                "45": 0.172026,
                "46": 0.172617,
                "47": 0.170732,
                "48": 0.173476,
                "49": 0.173533,
                "50": 0.172476,
                "51": 0.171263,
                "52": 0.174046,
                "53": 0.173686,
                "54": 0.173405,
                "55": 0.171551,
                "56": 0.173538,
                "57": 0.17218,
                "58": 0.17376,
                "59": 0.172442,
                "60": 0.173414,
                "61": 0.172606,
                "62": 0.173107,
                "63": 0.171114,
                "64": 0.17438,
                "65": 0.172142,
                "66": 0.173671,
                "67": 0.172369,
                "68": 0.173143,
                "69": 0.173432,
                "70": 0.173918,
                "71": 0.172484,
                "72": 0.173239,
                "73": 0.171139,
                "74": 0.17433,
                "75": 0.173959,
                "76": 0.173133,
                "77": 0.173716,
                "78": 0.173633,
                "79": 0.175608,
                "80": 0.173742,
                "81": 0.174596,
                "82": 0.174331,
                "83": 0.175288,
                "84": 0.174328,
                "85": 0.171377,
                "86": 0.174945,
                "87": 0.173311,
                "88": 0.173234,
                "89": 0.173586,
                "90": 0.176128,
                "91": 0.174532,
                "92": 0.172953,
                "93": 0.175781,
                "94": 0.173689,
                "95": 0.175386,
                "96": 0.174335,
                "97": 0.174025,
                "98": 4.103869
            },
            "validation_time": 4.0582,
            "epoch_time": 41.08540177345276,
            "validation_accuracy": 0.062
        },
        "2": {
            "steps": {
                "1": 0.174234,
                "2": 0.174797,
                "3": 0.1745,
                "4": 0.17497,
                "5": 0.174317,
                "6": 0.174492,
                "7": 0.173747,
                "8": 0.174903,
                "9": 0.176535,
                "10": 0.175005,
                "11": 0.1738,
                "12": 0.174201,
                "13": 0.175267,
                "14": 0.175889,
                "15": 0.175241,
                "16": 0.175488,
                "17": 0.177043,
                "18": 0.176893,
                "19": 0.176204,
                "20": 0.169689,
                "21": 0.179179,
                "22": 0.177799,
                "23": 0.179068,
                "24": 0.175505,
                "25": 0.174984,
                "26": 0.178078,
                "27": 0.169041,
                "28": 0.177309,
                "29": 0.180129,
                "30": 0.175433,
                "31": 0.175563,
                "32": 0.176277,
                "33": 0.175597,
                "34": 0.17598,
                "35": 0.177003,
                "36": 0.175531,
                "37": 0.176181,
                "38": 0.176763,
                "39": 0.175544,
                "40": 0.175744,
                "41": 0.177649,
                "42": 0.176714,
                "43": 0.175676,
                "44": 0.178309,
                "45": 0.176168,
                "46": 0.176244,
                "47": 0.17703,
                "48": 0.177445,
                "49": 0.177308,
                "50": 0.176509,
                "51": 0.178274,
                "52": 0.177712,
                "53": 0.176182,
                "54": 0.176327,
                "55": 0.176255,
                "56": 0.177477,
                "57": 0.176785,
                "58": 0.17826,
                "59": 0.176651,
                "60": 0.176281,
                "61": 0.17847,
                "62": 0.176223,
                "63": 0.175887,
                "64": 0.177089,
                "65": 0.177403,
                "66": 0.175827,
                "67": 0.176626,
                "68": 0.178944,
                "69": 0.178197,
                "70": 0.17645,
                "71": 0.176523,
                "72": 0.178549,
                "73": 0.17825,
                "74": 0.176973,
                "75": 0.177061,
                "76": 0.178361,
                "77": 0.17761,
                "78": 0.177831,
                "79": 0.177411,
                "80": 0.179532,
                "81": 0.179999,
                "82": 0.176701,
                "83": 0.176607,
                "84": 0.17822,
                "85": 0.176946,
                "86": 0.17736,
                "87": 0.17669,
                "88": 0.178621,
                "89": 0.177676,
                "90": 0.177205,
                "91": 0.176758,
                "92": 0.179602,
                "93": 0.17852,
                "94": 0.17752,
                "95": 0.177384,
                "96": 0.178853,
                "97": 0.177751,
                "98": 0.13714
            },
            "validation_time": 0.867471,
            "epoch_time": 18.142696142196655,
            "validation_accuracy": 0.0999
        },
        "3": {
            "steps": {
                "1": 0.176662,
                "2": 0.179465,
                "3": 0.178627,
                "4": 0.178998,
                "5": 0.178539,
                "6": 0.177402,
                "7": 0.179272,
                "8": 0.179347,
                "9": 0.178642,
                "10": 0.177269,
                "11": 0.178146,
                "12": 0.180103,
                "13": 0.17958,
                "14": 0.177394,
                "15": 0.178146,
                "16": 0.177035,
                "17": 0.180057,
                "18": 0.179989,
                "19": 0.179372,
                "20": 0.178872,
                "21": 0.177729,
                "22": 0.179272,
                "23": 0.180645,
                "24": 0.179099,
                "25": 0.177377,
                "26": 0.178065,
                "27": 0.179649,
                "28": 0.180227,
                "29": 0.181615,
                "30": 0.179174,
                "31": 0.177636,
                "32": 0.177841,
                "33": 0.179099,
                "34": 0.180388,
                "35": 0.181368,
                "36": 0.182906,
                "37": 0.179991,
                "38": 0.177238,
                "39": 0.179047,
                "40": 0.179291,
                "41": 0.180054,
                "42": 0.181241,
                "43": 0.180285,
                "44": 0.177611,
                "45": 0.178153,
                "46": 0.179776,
                "47": 0.181357,
                "48": 0.181376,
                "49": 0.181319,
                "50": 0.178764,
                "51": 0.175182,
                "52": 0.179169,
                "53": 0.180212,
                "54": 0.179842,
                "55": 0.179908,
                "56": 0.178032,
                "57": 0.179717,
                "58": 0.17928,
                "59": 0.182016,
                "60": 0.181029,
                "61": 0.182447,
                "62": 0.180463,
                "63": 0.179219,
                "64": 0.178908,
                "65": 0.180015,
                "66": 0.178738,
                "67": 0.180911,
                "68": 0.181355,
                "69": 0.181801,
                "70": 0.18206,
                "71": 0.181053,
                "72": 0.178854,
                "73": 0.179761,
                "74": 0.179885,
                "75": 0.178699,
                "76": 0.181331,
                "77": 0.180891,
                "78": 0.182555,
                "79": 0.182359,
                "80": 0.181979,
                "81": 0.181512,
                "82": 0.181056,
                "83": 0.182485,
                "84": 0.18095,
                "85": 0.179637,
                "86": 0.180311,
                "87": 0.180888,
                "88": 0.181185,
                "89": 0.180697,
                "90": 0.180818,
                "91": 0.181919,
                "92": 0.182241,
                "93": 0.182591,
                "94": 0.181908,
                "95": 0.181355,
                "96": 0.182132,
                "97": 0.180768,
                "98": 0.137258
            },
            "validation_time": 0.872682,
            "epoch_time": 18.4639413356781,
            "validation_accuracy": 0.0999
        },
        "4": {
            "steps": {
                "1": 0.182917,
                "2": 0.180958,
                "3": 0.179484,
                "4": 0.182617,
                "5": 0.179646,
                "6": 0.180687,
                "7": 0.180913,
                "8": 0.183016,
                "9": 0.181938,
                "10": 0.183783,
                "11": 0.182677,
                "12": 0.183551,
                "13": 0.182962,
                "14": 0.182694,
                "15": 0.182292,
                "16": 0.181862,
                "17": 0.183072,
                "18": 0.182441,
                "19": 0.182583,
                "20": 0.182692,
                "21": 0.183734,
                "22": 0.182707,
                "23": 0.183022,
                "24": 0.182548,
                "25": 0.183169,
                "26": 0.183322,
                "27": 0.182385,
                "28": 0.182689,
                "29": 0.182739,
                "30": 0.182401,
                "31": 0.182757,
                "32": 0.183517,
                "33": 0.183498,
                "34": 0.18128,
                "35": 0.183788,
                "36": 0.183891,
                "37": 0.181996,
                "38": 0.183256,
                "39": 0.181767,
                "40": 0.184155,
                "41": 0.18389,
                "42": 0.182976,
                "43": 0.182239,
                "44": 0.18305,
                "45": 0.183728,
                "46": 0.183397,
                "47": 0.183118,
                "48": 0.183265,
                "49": 0.182478,
                "50": 0.183179,
                "51": 0.182773,
                "52": 0.184145,
                "53": 0.184265,
                "54": 0.181864,
                "55": 0.184083,
                "56": 0.183256,
                "57": 0.182467,
                "58": 0.184019,
                "59": 0.181951,
                "60": 0.184353,
                "61": 0.183658,
                "62": 0.182941,
                "63": 0.183526,
                "64": 0.183087,
                "65": 0.183579,
                "66": 0.182275,
                "67": 0.182904,
                "68": 0.18386,
                "69": 0.182674,
                "70": 0.184358,
                "71": 0.181756,
                "72": 0.18395,
                "73": 0.183904,
                "74": 0.181927,
                "75": 0.184915,
                "76": 0.183061,
                "77": 0.184022,
                "78": 0.183426,
                "79": 0.182104,
                "80": 0.183771,
                "81": 0.182635,
                "82": 0.184288,
                "83": 0.18398,
                "84": 0.181619,
                "85": 0.184544,
                "86": 0.183364,
                "87": 0.182952,
                "88": 0.183705,
                "89": 0.182608,
                "90": 0.183616,
                "91": 0.18273,
                "92": 0.184153,
                "93": 0.183364,
                "94": 0.182895,
                "95": 0.183682,
                "96": 0.180858,
                "97": 0.184452,
                "98": 0.141147
            },
            "validation_time": 0.883612,
            "epoch_time": 18.775037050247192,
            "validation_accuracy": 0.1001
        },
        "5": {
            "steps": {
                "1": 0.188342,
                "2": 0.184689,
                "3": 0.182456,
                "4": 0.184229,
                "5": 0.173644,
                "6": 0.185507,
                "7": 0.189415,
                "8": 0.18446,
                "9": 0.182811,
                "10": 0.184646,
                "11": 0.183776,
                "12": 0.183234,
                "13": 0.183012,
                "14": 0.182959,
                "15": 0.183818,
                "16": 0.183403,
                "17": 0.183258,
                "18": 0.182449,
                "19": 0.184817,
                "20": 0.18479,
                "21": 0.184958,
                "22": 0.185425,
                "23": 0.184007,
                "24": 0.185371,
                "25": 0.187925,
                "26": 0.18644,
                "27": 0.18384,
                "28": 0.184074,
                "29": 0.182243,
                "30": 0.184797,
                "31": 0.184089,
                "32": 0.184656,
                "33": 0.183942,
                "34": 0.184891,
                "35": 0.184449,
                "36": 0.185214,
                "37": 0.186649,
                "38": 0.188298,
                "39": 0.183804,
                "40": 0.184437,
                "41": 0.183096,
                "42": 0.184734,
                "43": 0.186012,
                "44": 0.185082,
                "45": 0.187282,
                "46": 0.187766,
                "47": 0.183961,
                "48": 0.18365,
                "49": 0.182948,
                "50": 0.184844,
                "51": 0.186995,
                "52": 0.184457,
                "53": 0.187759,
                "54": 0.18775,
                "55": 0.184082,
                "56": 0.184817,
                "57": 0.184836,
                "58": 0.185233,
                "59": 0.186818,
                "60": 0.189699,
                "61": 0.183755,
                "62": 0.183312,
                "63": 0.184078,
                "64": 0.185158,
                "65": 0.187239,
                "66": 0.188558,
                "67": 0.187792,
                "68": 0.184139,
                "69": 0.184124,
                "70": 0.185778,
                "71": 0.186315,
                "72": 0.188515,
                "73": 0.189303,
                "74": 0.184827,
                "75": 0.183238,
                "76": 0.185448,
                "77": 0.185934,
                "78": 0.189735,
                "79": 0.186827,
                "80": 0.183587,
                "81": 0.184177,
                "82": 0.18496,
                "83": 0.187083,
                "84": 0.19271,
                "85": 0.185064,
                "86": 0.184405,
                "87": 0.183406,
                "88": 0.184865,
                "89": 0.188922,
                "90": 0.19073,
                "91": 0.185011,
                "92": 0.18378,
                "93": 0.185018,
                "94": 0.186157,
                "95": 0.189526,
                "96": 0.189504,
                "97": 0.183814,
                "98": 0.142015
            },
            "validation_time": 0.898438,
            "epoch_time": 19.017595052719116,
            "validation_accuracy": 0.1001
        }
    },
    "computing_system": "g4dn8xlarge-1",
    "batch_size": "512"
}
