{
    "init": -1.0,
    "total_training": 118.6634750366211,
    "largest_real_time_delta": 115.28808546066284,
    "fit_time": 118.6634750366211,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 16.019589,
                "2": 0.177913,
                "3": 0.171737,
                "4": 0.172313,
                "5": 0.171554,
                "6": 0.171827,
                "7": 0.173366,
                "8": 0.173262,
                "9": 0.172282,
                "10": 0.172615,
                "11": 0.172482,
                "12": 0.17239,
                "13": 0.171257,
                "14": 0.165641,
                "15": 0.174683,
                "16": 0.172884,
                "17": 0.173887,
                "18": 0.172286,
                "19": 0.171842,
                "20": 0.171754,
                "21": 0.173028,
                "22": 0.172503,
                "23": 0.172399,
                "24": 0.173242,
                "25": 0.171857,
                "26": 0.172347,
                "27": 0.172574,
                "28": 0.174241,
                "29": 0.17338,
                "30": 0.174007,
                "31": 0.172091,
                "32": 0.172511,
                "33": 0.172786,
                "34": 0.171734,
                "35": 0.17313,
                "36": 0.172542,
                "37": 0.172383,
                "38": 0.173265,
                "39": 0.171827,
                "40": 0.17149,
                "41": 0.172519,
                "42": 0.1721,
                "43": 0.172127,
                "44": 0.171345,
                "45": 0.173511,
                "46": 0.172699,
                "47": 0.172498,
                "48": 0.173369,
                "49": 0.17297,
                "50": 0.172895,
                "51": 0.172889,
                "52": 0.172128,
                "53": 0.174175,
                "54": 0.172746,
                "55": 0.173067,
                "56": 0.172072,
                "57": 0.172848,
                "58": 0.173506,
                "59": 0.173634,
                "60": 0.174092,
                "61": 0.173727,
                "62": 0.174293,
                "63": 0.173887,
                "64": 0.17088,
                "65": 0.173044,
                "66": 0.174406,
                "67": 0.173569,
                "68": 0.174426,
                "69": 0.174283,
                "70": 0.173717,
                "71": 0.173446,
                "72": 0.173473,
                "73": 0.174486,
                "74": 0.172891,
                "75": 0.172141,
                "76": 0.173516,
                "77": 0.171916,
                "78": 0.174255,
                "79": 0.172631,
                "80": 0.17346,
                "81": 0.171236,
                "82": 0.17568,
                "83": 0.17207,
                "84": 0.174409,
                "85": 0.175366,
                "86": 0.175459,
                "87": 0.174192,
                "88": 0.173626,
                "89": 0.173547,
                "90": 0.17276,
                "91": 0.173059,
                "92": 0.173383,
                "93": 0.173398,
                "94": 0.173596,
                "95": 0.173805,
                "96": 0.174345,
                "97": 0.171394,
                "98": 4.025746
            },
            "validation_time": 4.156878,
            "epoch_time": 41.55565929412842,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.175506,
                "2": 0.175751,
                "3": 0.175259,
                "4": 0.176373,
                "5": 0.174498,
                "6": 0.175096,
                "7": 0.175965,
                "8": 0.175066,
                "9": 0.175644,
                "10": 0.176336,
                "11": 0.1752,
                "12": 0.175474,
                "13": 0.175161,
                "14": 0.176967,
                "15": 0.175304,
                "16": 0.175764,
                "17": 0.175833,
                "18": 0.176046,
                "19": 0.177519,
                "20": 0.176986,
                "21": 0.17596,
                "22": 0.176487,
                "23": 0.175086,
                "24": 0.17499,
                "25": 0.17552,
                "26": 0.177864,
                "27": 0.177168,
                "28": 0.175569,
                "29": 0.175499,
                "30": 0.17483,
                "31": 0.175524,
                "32": 0.177051,
                "33": 0.175946,
                "34": 0.176901,
                "35": 0.176443,
                "36": 0.177458,
                "37": 0.177086,
                "38": 0.178784,
                "39": 0.176614,
                "40": 0.177369,
                "41": 0.176692,
                "42": 0.176885,
                "43": 0.176864,
                "44": 0.17761,
                "45": 0.177218,
                "46": 0.177906,
                "47": 0.176865,
                "48": 0.176816,
                "49": 0.177022,
                "50": 0.176246,
                "51": 0.176382,
                "52": 0.177599,
                "53": 0.177835,
                "54": 0.175682,
                "55": 0.176474,
                "56": 0.175467,
                "57": 0.177675,
                "58": 0.176007,
                "59": 0.177583,
                "60": 0.176146,
                "61": 0.177686,
                "62": 0.177935,
                "63": 0.168889,
                "64": 0.178661,
                "65": 0.177113,
                "66": 0.177016,
                "67": 0.175942,
                "68": 0.17785,
                "69": 0.178304,
                "70": 0.177338,
                "71": 0.177743,
                "72": 0.176827,
                "73": 0.178738,
                "74": 0.177268,
                "75": 0.176444,
                "76": 0.177166,
                "77": 0.177145,
                "78": 0.177275,
                "79": 0.182036,
                "80": 0.177675,
                "81": 0.17732,
                "82": 0.177188,
                "83": 0.176562,
                "84": 0.177592,
                "85": 0.176421,
                "86": 0.177217,
                "87": 0.178369,
                "88": 0.177085,
                "89": 0.176329,
                "90": 0.177335,
                "91": 0.177888,
                "92": 0.1787,
                "93": 0.177241,
                "94": 0.177536,
                "95": 0.177664,
                "96": 0.178265,
                "97": 0.176116,
                "98": 0.141644
            },
            "validation_time": 0.873423,
            "epoch_time": 18.15915322303772,
            "validation_accuracy": 0.0997
        },
        "3": {
            "steps": {
                "1": 0.177388,
                "2": 0.178422,
                "3": 0.178548,
                "4": 0.175968,
                "5": 0.177792,
                "6": 0.177851,
                "7": 0.178787,
                "8": 0.177577,
                "9": 0.176812,
                "10": 0.176956,
                "11": 0.17832,
                "12": 0.17808,
                "13": 0.177697,
                "14": 0.177236,
                "15": 0.178366,
                "16": 0.177209,
                "17": 0.178425,
                "18": 0.177256,
                "19": 0.177783,
                "20": 0.177623,
                "21": 0.177137,
                "22": 0.178647,
                "23": 0.177671,
                "24": 0.176624,
                "25": 0.177423,
                "26": 0.179783,
                "27": 0.178245,
                "28": 0.177463,
                "29": 0.177078,
                "30": 0.17862,
                "31": 0.177449,
                "32": 0.177333,
                "33": 0.177551,
                "34": 0.178562,
                "35": 0.177012,
                "36": 0.177679,
                "37": 0.177618,
                "38": 0.177955,
                "39": 0.178109,
                "40": 0.179885,
                "41": 0.17736,
                "42": 0.177474,
                "43": 0.178704,
                "44": 0.178413,
                "45": 0.177615,
                "46": 0.178805,
                "47": 0.178421,
                "48": 0.176809,
                "49": 0.177114,
                "50": 0.178244,
                "51": 0.177919,
                "52": 0.178001,
                "53": 0.177966,
                "54": 0.177785,
                "55": 0.178158,
                "56": 0.178706,
                "57": 0.179675,
                "58": 0.178526,
                "59": 0.177958,
                "60": 0.177879,
                "61": 0.179745,
                "62": 0.179211,
                "63": 0.176786,
                "64": 0.178444,
                "65": 0.179319,
                "66": 0.179633,
                "67": 0.179734,
                "68": 0.177586,
                "69": 0.178173,
                "70": 0.179241,
                "71": 0.178524,
                "72": 0.179836,
                "73": 0.178606,
                "74": 0.177802,
                "75": 0.17918,
                "76": 0.179421,
                "77": 0.179993,
                "78": 0.17958,
                "79": 0.178002,
                "80": 0.17889,
                "81": 0.179049,
                "82": 0.180862,
                "83": 0.179542,
                "84": 0.179168,
                "85": 0.178307,
                "86": 0.178178,
                "87": 0.180036,
                "88": 0.179043,
                "89": 0.177699,
                "90": 0.178501,
                "91": 0.179186,
                "92": 0.180724,
                "93": 0.181543,
                "94": 0.178061,
                "95": 0.180111,
                "96": 0.178672,
                "97": 0.178266,
                "98": 0.135008
            },
            "validation_time": 0.873793,
            "epoch_time": 18.310199737548828,
            "validation_accuracy": 0.0997
        },
        "4": {
            "steps": {
                "1": 0.179562,
                "2": 0.180082,
                "3": 0.179079,
                "4": 0.178778,
                "5": 0.179188,
                "6": 0.180682,
                "7": 0.179857,
                "8": 0.182272,
                "9": 0.18187,
                "10": 0.180399,
                "11": 0.17866,
                "12": 0.178878,
                "13": 0.179559,
                "14": 0.179963,
                "15": 0.180191,
                "16": 0.173937,
                "17": 0.180044,
                "18": 0.17953,
                "19": 0.180428,
                "20": 0.179945,
                "21": 0.179127,
                "22": 0.179632,
                "23": 0.179685,
                "24": 0.179525,
                "25": 0.180933,
                "26": 0.181654,
                "27": 0.180591,
                "28": 0.180067,
                "29": 0.179338,
                "30": 0.179307,
                "31": 0.17936,
                "32": 0.180718,
                "33": 0.181427,
                "34": 0.181364,
                "35": 0.180314,
                "36": 0.179257,
                "37": 0.180009,
                "38": 0.17926,
                "39": 0.179796,
                "40": 0.180317,
                "41": 0.180482,
                "42": 0.182731,
                "43": 0.181248,
                "44": 0.179622,
                "45": 0.181472,
                "46": 0.180877,
                "47": 0.179549,
                "48": 0.179444,
                "49": 0.180103,
                "50": 0.181487,
                "51": 0.180342,
                "52": 0.18016,
                "53": 0.180009,
                "54": 0.180256,
                "55": 0.179594,
                "56": 0.180413,
                "57": 0.180594,
                "58": 0.181539,
                "59": 0.182577,
                "60": 0.181696,
                "61": 0.181657,
                "62": 0.180141,
                "63": 0.180274,
                "64": 0.180178,
                "65": 0.179872,
                "66": 0.179996,
                "67": 0.180979,
                "68": 0.180506,
                "69": 0.182451,
                "70": 0.181093,
                "71": 0.181384,
                "72": 0.179027,
                "73": 0.18038,
                "74": 0.180545,
                "75": 0.180456,
                "76": 0.180969,
                "77": 0.181093,
                "78": 0.181753,
                "79": 0.17955,
                "80": 0.181065,
                "81": 0.181058,
                "82": 0.179856,
                "83": 0.180258,
                "84": 0.182152,
                "85": 0.181158,
                "86": 0.181521,
                "87": 0.18124,
                "88": 0.180168,
                "89": 0.180935,
                "90": 0.180203,
                "91": 0.18027,
                "92": 0.181448,
                "93": 0.182062,
                "94": 0.182099,
                "95": 0.181751,
                "96": 0.182857,
                "97": 0.181013,
                "98": 0.137452
            },
            "validation_time": 0.882165,
            "epoch_time": 18.525103092193604,
            "validation_accuracy": 0.0998
        },
        "5": {
            "steps": {
                "1": 0.184357,
                "2": 0.18399,
                "3": 0.180455,
                "4": 0.181462,
                "5": 0.182512,
                "6": 0.182334,
                "7": 0.181682,
                "8": 0.179998,
                "9": 0.180702,
                "10": 0.179577,
                "11": 0.181171,
                "12": 0.180995,
                "13": 0.183069,
                "14": 0.182444,
                "15": 0.183197,
                "16": 0.183657,
                "17": 0.182303,
                "18": 0.182014,
                "19": 0.181331,
                "20": 0.18211,
                "21": 0.18366,
                "22": 0.183488,
                "23": 0.183306,
                "24": 0.183315,
                "25": 0.183248,
                "26": 0.183399,
                "27": 0.183031,
                "28": 0.182848,
                "29": 0.180741,
                "30": 0.182973,
                "31": 0.180453,
                "32": 0.182678,
                "33": 0.181649,
                "34": 0.181893,
                "35": 0.180706,
                "36": 0.18115,
                "37": 0.182205,
                "38": 0.182385,
                "39": 0.183628,
                "40": 0.182841,
                "41": 0.182025,
                "42": 0.183069,
                "43": 0.183292,
                "44": 0.184697,
                "45": 0.18127,
                "46": 0.182775,
                "47": 0.187449,
                "48": 0.180398,
                "49": 0.183771,
                "50": 0.183465,
                "51": 0.18235,
                "52": 0.182418,
                "53": 0.18361,
                "54": 0.183956,
                "55": 0.184204,
                "56": 0.18216,
                "57": 0.182655,
                "58": 0.183668,
                "59": 0.183289,
                "60": 0.183981,
                "61": 0.183708,
                "62": 0.181479,
                "63": 0.183479,
                "64": 0.183816,
                "65": 0.182612,
                "66": 0.182923,
                "67": 0.182773,
                "68": 0.172051,
                "69": 0.181507,
                "70": 0.182582,
                "71": 0.183283,
                "72": 0.183288,
                "73": 0.18502,
                "74": 0.18344,
                "75": 0.183513,
                "76": 0.181761,
                "77": 0.182421,
                "78": 0.183511,
                "79": 0.182073,
                "80": 0.182518,
                "81": 0.181997,
                "82": 0.18245,
                "83": 0.182251,
                "84": 0.18414,
                "85": 0.182951,
                "86": 0.181667,
                "87": 0.182113,
                "88": 0.18194,
                "89": 0.18308,
                "90": 0.18325,
                "91": 0.183015,
                "92": 0.182871,
                "93": 0.182038,
                "94": 0.182007,
                "95": 0.181735,
                "96": 0.18248,
                "97": 0.18109,
                "98": 0.140621
            },
            "validation_time": 0.891183,
            "epoch_time": 18.73725724220276,
            "validation_accuracy": 0.0998
        }
    },
    "computing_system": "g4dn16xlarge-1",
    "batch_size": "512"
}
