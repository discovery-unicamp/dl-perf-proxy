{
    "init": -1.0,
    "total_training": 121.65925812721252,
    "largest_real_time_delta": 118.25761699676514,
    "fit_time": 121.65925812721252,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 16.904148,
                "2": 0.335982,
                "3": 0.334088,
                "4": 0.332888,
                "5": 0.33539,
                "6": 0.332872,
                "7": 0.335846,
                "8": 0.338556,
                "9": 0.333516,
                "10": 0.334114,
                "11": 0.357873,
                "12": 0.330788,
                "13": 0.327138,
                "14": 0.340184,
                "15": 0.333997,
                "16": 0.335375,
                "17": 0.336926,
                "18": 0.335284,
                "19": 0.332686,
                "20": 0.336478,
                "21": 0.337661,
                "22": 0.335541,
                "23": 0.336505,
                "24": 0.339348,
                "25": 0.338116,
                "26": 0.33444,
                "27": 0.340237,
                "28": 0.336413,
                "29": 0.337689,
                "30": 0.337616,
                "31": 0.337806,
                "32": 0.339698,
                "33": 0.337251,
                "34": 0.337611,
                "35": 0.342336,
                "36": 0.340349,
                "37": 0.336771,
                "38": 0.338105,
                "39": 0.338977,
                "40": 0.337948,
                "41": 0.341784,
                "42": 0.337225,
                "43": 0.339038,
                "44": 0.340765,
                "45": 0.341539,
                "46": 0.33789,
                "47": 0.342324,
                "48": 0.341534,
                "49": 6.404522
            },
            "validation_time": 4.755105,
            "epoch_time": 44.67435050010681
        },
        "2": {
            "steps": {
                "1": 0.349832,
                "2": 0.342757,
                "3": 0.344799,
                "4": 0.351859,
                "5": 0.345815,
                "6": 0.344623,
                "7": 0.34772,
                "8": 0.344087,
                "9": 0.343063,
                "10": 0.346898,
                "11": 0.345258,
                "12": 0.349455,
                "13": 0.343637,
                "14": 0.345087,
                "15": 0.345835,
                "16": 0.344778,
                "17": 0.345285,
                "18": 0.348215,
                "19": 0.349776,
                "20": 0.348167,
                "21": 0.35152,
                "22": 0.345979,
                "23": 0.34618,
                "24": 0.346894,
                "25": 0.351127,
                "26": 0.349957,
                "27": 0.35084,
                "28": 0.349524,
                "29": 0.349902,
                "30": 0.351356,
                "31": 0.350025,
                "32": 0.347036,
                "33": 0.349128,
                "34": 0.351691,
                "35": 0.353125,
                "36": 0.351499,
                "37": 0.329824,
                "38": 0.353962,
                "39": 0.350295,
                "40": 0.348112,
                "41": 0.35132,
                "42": 0.35238,
                "43": 0.34953,
                "44": 0.352269,
                "45": 0.354473,
                "46": 0.354368,
                "47": 0.351769,
                "48": 0.354975,
                "49": 0.309969
            },
            "validation_time": 0.816031,
            "epoch_time": 17.855546712875366
        },
        "3": {
            "steps": {
                "1": 0.351795,
                "2": 0.350049,
                "3": 0.353039,
                "4": 0.355124,
                "5": 0.351678,
                "6": 0.356508,
                "7": 0.355287,
                "8": 0.351306,
                "9": 0.354524,
                "10": 0.35365,
                "11": 0.3565,
                "12": 0.354387,
                "13": 0.355998,
                "14": 0.356727,
                "15": 0.357544,
                "16": 0.358002,
                "17": 0.355002,
                "18": 0.357388,
                "19": 0.353987,
                "20": 0.3569,
                "21": 0.355448,
                "22": 0.357617,
                "23": 0.355905,
                "24": 0.357144,
                "25": 0.35622,
                "26": 0.356722,
                "27": 0.359166,
                "28": 0.354626,
                "29": 0.357757,
                "30": 0.357922,
                "31": 0.355108,
                "32": 0.358723,
                "33": 0.356353,
                "34": 0.35882,
                "35": 0.35858,
                "36": 0.360588,
                "37": 0.35976,
                "38": 0.358583,
                "39": 0.357792,
                "40": 0.36005,
                "41": 0.359857,
                "42": 0.357765,
                "43": 0.359726,
                "44": 0.359865,
                "45": 0.358984,
                "46": 0.3569,
                "47": 0.362503,
                "48": 0.358413,
                "49": 0.304822
            },
            "validation_time": 0.823482,
            "epoch_time": 18.253902912139893
        },
        "4": {
            "steps": {
                "1": 0.357413,
                "2": 0.357216,
                "3": 0.365593,
                "4": 0.360338,
                "5": 0.358814,
                "6": 0.361351,
                "7": 0.339311,
                "8": 0.372792,
                "9": 0.36837,
                "10": 0.355158,
                "11": 0.359424,
                "12": 0.363466,
                "13": 0.358227,
                "14": 0.36352,
                "15": 0.362653,
                "16": 0.358754,
                "17": 0.360711,
                "18": 0.364115,
                "19": 0.363522,
                "20": 0.361682,
                "21": 0.362317,
                "22": 0.360223,
                "23": 0.363712,
                "24": 0.363726,
                "25": 0.362756,
                "26": 0.3647,
                "27": 0.364519,
                "28": 0.362461,
                "29": 0.362648,
                "30": 0.362154,
                "31": 0.366509,
                "32": 0.365127,
                "33": 0.365999,
                "34": 0.363913,
                "35": 0.363472,
                "36": 0.362088,
                "37": 0.364704,
                "38": 0.362412,
                "39": 0.36389,
                "40": 0.36473,
                "41": 0.362162,
                "42": 0.366688,
                "43": 0.367645,
                "44": 0.366109,
                "45": 0.363399,
                "46": 0.36771,
                "47": 0.367399,
                "48": 0.361943,
                "49": 0.313077
            },
            "validation_time": 0.837713,
            "epoch_time": 18.561694383621216
        },
        "5": {
            "steps": {
                "1": 0.361857,
                "2": 0.362089,
                "3": 0.372168,
                "4": 0.363219,
                "5": 0.367238,
                "6": 0.369946,
                "7": 0.367125,
                "8": 0.36734,
                "9": 0.365047,
                "10": 0.36675,
                "11": 0.368314,
                "12": 0.36527,
                "13": 0.364666,
                "14": 0.369445,
                "15": 0.369357,
                "16": 0.370687,
                "17": 0.368447,
                "18": 0.366227,
                "19": 0.369083,
                "20": 0.36776,
                "21": 0.372058,
                "22": 0.367367,
                "23": 0.3687,
                "24": 0.369958,
                "25": 0.367702,
                "26": 0.368543,
                "27": 0.37339,
                "28": 0.369941,
                "29": 0.369403,
                "30": 0.374784,
                "31": 0.367657,
                "32": 0.367799,
                "33": 0.372341,
                "34": 0.370553,
                "35": 0.366891,
                "36": 0.37109,
                "37": 0.371339,
                "38": 0.370671,
                "39": 0.372776,
                "40": 0.371125,
                "41": 0.370352,
                "42": 0.371737,
                "43": 0.371638,
                "44": 0.386751,
                "45": 0.370039,
                "46": 0.375632,
                "47": 0.370402,
                "48": 0.369201,
                "49": 0.320964
            },
            "validation_time": 0.855223,
            "epoch_time": 18.911393880844116
        }
    },
    "computing_system": "g4dn4xlarge-1",
    "batch_size": "1024"
}
