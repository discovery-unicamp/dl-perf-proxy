{
    "init": -1.0,
    "total_training": 119.27186489105225,
    "largest_real_time_delta": 115.8438184261322,
    "fit_time": 119.27186489105225,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 16.453095,
                "2": 0.172585,
                "3": 0.171399,
                "4": 0.172626,
                "5": 0.172439,
                "6": 0.172867,
                "7": 0.173066,
                "8": 0.173157,
                "9": 0.173668,
                "10": 0.172785,
                "11": 0.173309,
                "12": 0.17276,
                "13": 0.170895,
                "14": 0.172203,
                "15": 0.173102,
                "16": 0.173047,
                "17": 0.171836,
                "18": 0.173521,
                "19": 0.171264,
                "20": 0.173479,
                "21": 0.173282,
                "22": 0.172742,
                "23": 0.171707,
                "24": 0.173323,
                "25": 0.172163,
                "26": 0.173211,
                "27": 0.172215,
                "28": 0.174071,
                "29": 0.172936,
                "30": 0.174136,
                "31": 0.174983,
                "32": 0.17382,
                "33": 0.164698,
                "34": 0.171409,
                "35": 0.174318,
                "36": 0.172224,
                "37": 0.174166,
                "38": 0.173252,
                "39": 0.172963,
                "40": 0.173253,
                "41": 0.172165,
                "42": 0.173154,
                "43": 0.173978,
                "44": 0.174386,
                "45": 0.167818,
                "46": 0.174234,
                "47": 0.173287,
                "48": 0.173098,
                "49": 0.173459,
                "50": 0.173891,
                "51": 0.172897,
                "52": 0.173531,
                "53": 0.173441,
                "54": 0.17382,
                "55": 0.172767,
                "56": 0.176598,
                "57": 0.17394,
                "58": 0.173862,
                "59": 0.174409,
                "60": 0.174745,
                "61": 0.174008,
                "62": 0.173185,
                "63": 0.175366,
                "64": 0.172818,
                "65": 0.173674,
                "66": 0.173962,
                "67": 0.17411,
                "68": 0.173631,
                "69": 0.172178,
                "70": 0.173384,
                "71": 0.173929,
                "72": 0.175188,
                "73": 0.173955,
                "74": 0.175862,
                "75": 0.173628,
                "76": 0.174336,
                "77": 0.173564,
                "78": 0.173698,
                "79": 0.173867,
                "80": 0.174665,
                "81": 0.174998,
                "82": 0.17302,
                "83": 0.174266,
                "84": 0.174899,
                "85": 0.17497,
                "86": 0.173561,
                "87": 0.174852,
                "88": 0.176615,
                "89": 0.174792,
                "90": 0.173478,
                "91": 0.173743,
                "92": 0.173901,
                "93": 0.174248,
                "94": 0.174734,
                "95": 0.174951,
                "96": 0.175775,
                "97": 0.173382,
                "98": 4.055862
            },
            "validation_time": 4.164696,
            "epoch_time": 42.08714318275452
        },
        "2": {
            "steps": {
                "1": 0.174821,
                "2": 0.166852,
                "3": 0.176007,
                "4": 0.174726,
                "5": 0.173887,
                "6": 0.174435,
                "7": 0.174703,
                "8": 0.175161,
                "9": 0.175649,
                "10": 0.174168,
                "11": 0.175099,
                "12": 0.17532,
                "13": 0.178581,
                "14": 0.174807,
                "15": 0.175999,
                "16": 0.175509,
                "17": 0.175986,
                "18": 0.174724,
                "19": 0.175898,
                "20": 0.176393,
                "21": 0.175556,
                "22": 0.175929,
                "23": 0.175357,
                "24": 0.175557,
                "25": 0.176846,
                "26": 0.175249,
                "27": 0.175987,
                "28": 0.176047,
                "29": 0.175344,
                "30": 0.175189,
                "31": 0.174709,
                "32": 0.174611,
                "33": 0.175592,
                "34": 0.174396,
                "35": 0.175186,
                "36": 0.17797,
                "37": 0.173906,
                "38": 0.174733,
                "39": 0.173815,
                "40": 0.175644,
                "41": 0.175211,
                "42": 0.176281,
                "43": 0.174433,
                "44": 0.176363,
                "45": 0.175804,
                "46": 0.175885,
                "47": 0.177058,
                "48": 0.175552,
                "49": 0.175244,
                "50": 0.176874,
                "51": 0.176215,
                "52": 0.175358,
                "53": 0.176689,
                "54": 0.177192,
                "55": 0.175277,
                "56": 0.176324,
                "57": 0.175699,
                "58": 0.176868,
                "59": 0.176171,
                "60": 0.17582,
                "61": 0.177083,
                "62": 0.17702,
                "63": 0.175758,
                "64": 0.17624,
                "65": 0.176063,
                "66": 0.174733,
                "67": 0.177164,
                "68": 0.175463,
                "69": 0.177727,
                "70": 0.176472,
                "71": 0.176002,
                "72": 0.176343,
                "73": 0.178047,
                "74": 0.176938,
                "75": 0.17623,
                "76": 0.176622,
                "77": 0.177303,
                "78": 0.17568,
                "79": 0.176058,
                "80": 0.176925,
                "81": 0.17696,
                "82": 0.176979,
                "83": 0.177554,
                "84": 0.175313,
                "85": 0.17715,
                "86": 0.177431,
                "87": 0.177033,
                "88": 0.175982,
                "89": 0.177599,
                "90": 0.177449,
                "91": 0.17789,
                "92": 0.177516,
                "93": 0.177666,
                "94": 0.177763,
                "95": 0.175556,
                "96": 0.177911,
                "97": 0.176309,
                "98": 0.136787
            },
            "validation_time": 0.876722,
            "epoch_time": 18.083751916885376
        },
        "3": {
            "steps": {
                "1": 0.175438,
                "2": 0.17634,
                "3": 0.176496,
                "4": 0.176522,
                "5": 0.176532,
                "6": 0.178948,
                "7": 0.17649,
                "8": 0.178199,
                "9": 0.176343,
                "10": 0.176862,
                "11": 0.171623,
                "12": 0.180236,
                "13": 0.178524,
                "14": 0.178475,
                "15": 0.175586,
                "16": 0.177263,
                "17": 0.177111,
                "18": 0.176809,
                "19": 0.177941,
                "20": 0.177526,
                "21": 0.178314,
                "22": 0.177965,
                "23": 0.17795,
                "24": 0.17812,
                "25": 0.178665,
                "26": 0.177971,
                "27": 0.17808,
                "28": 0.178972,
                "29": 0.179474,
                "30": 0.178653,
                "31": 0.178153,
                "32": 0.177018,
                "33": 0.171977,
                "34": 0.178086,
                "35": 0.17648,
                "36": 0.179417,
                "37": 0.177706,
                "38": 0.178719,
                "39": 0.178503,
                "40": 0.179272,
                "41": 0.181104,
                "42": 0.1788,
                "43": 0.179569,
                "44": 0.178998,
                "45": 0.17873,
                "46": 0.180084,
                "47": 0.180653,
                "48": 0.18076,
                "49": 0.179585,
                "50": 0.178109,
                "51": 0.177758,
                "52": 0.179571,
                "53": 0.180767,
                "54": 0.179975,
                "55": 0.179659,
                "56": 0.177736,
                "57": 0.17882,
                "58": 0.179931,
                "59": 0.179034,
                "60": 0.178018,
                "61": 0.177681,
                "62": 0.178042,
                "63": 0.179852,
                "64": 0.178196,
                "65": 0.179354,
                "66": 0.178435,
                "67": 0.177812,
                "68": 0.17895,
                "69": 0.178513,
                "70": 0.180044,
                "71": 0.178492,
                "72": 0.178426,
                "73": 0.179744,
                "74": 0.177445,
                "75": 0.180277,
                "76": 0.178612,
                "77": 0.179356,
                "78": 0.178965,
                "79": 0.179779,
                "80": 0.179843,
                "81": 0.179325,
                "82": 0.179169,
                "83": 0.1792,
                "84": 0.17911,
                "85": 0.179971,
                "86": 0.181037,
                "87": 0.178133,
                "88": 0.178467,
                "89": 0.179239,
                "90": 0.178542,
                "91": 0.178771,
                "92": 0.181504,
                "93": 0.179804,
                "94": 0.1797,
                "95": 0.179188,
                "96": 0.178982,
                "97": 0.179197,
                "98": 0.136868
            },
            "validation_time": 0.882732,
            "epoch_time": 18.336857080459595
        },
        "4": {
            "steps": {
                "1": 0.177373,
                "2": 0.179171,
                "3": 0.180995,
                "4": 0.180686,
                "5": 0.179916,
                "6": 0.179518,
                "7": 0.179122,
                "8": 0.178789,
                "9": 0.178241,
                "10": 0.18043,
                "11": 0.179241,
                "12": 0.178919,
                "13": 0.179689,
                "14": 0.17873,
                "15": 0.179568,
                "16": 0.181196,
                "17": 0.180071,
                "18": 0.180912,
                "19": 0.180302,
                "20": 0.179944,
                "21": 0.179271,
                "22": 0.179631,
                "23": 0.182083,
                "24": 0.180433,
                "25": 0.179151,
                "26": 0.180712,
                "27": 0.179734,
                "28": 0.180892,
                "29": 0.179796,
                "30": 0.180063,
                "31": 0.181199,
                "32": 0.182549,
                "33": 0.182005,
                "34": 0.18239,
                "35": 0.179775,
                "36": 0.180423,
                "37": 0.180876,
                "38": 0.179403,
                "39": 0.1802,
                "40": 0.179674,
                "41": 0.182474,
                "42": 0.181377,
                "43": 0.181267,
                "44": 0.181607,
                "45": 0.181024,
                "46": 0.179417,
                "47": 0.181256,
                "48": 0.179226,
                "49": 0.179887,
                "50": 0.181568,
                "51": 0.179973,
                "52": 0.181159,
                "53": 0.180683,
                "54": 0.180333,
                "55": 0.180195,
                "56": 0.180619,
                "57": 0.179965,
                "58": 0.181069,
                "59": 0.182064,
                "60": 0.18176,
                "61": 0.181221,
                "62": 0.181934,
                "63": 0.179603,
                "64": 0.179893,
                "65": 0.180273,
                "66": 0.180914,
                "67": 0.180723,
                "68": 0.181937,
                "69": 0.173535,
                "70": 0.180274,
                "71": 0.180577,
                "72": 0.182021,
                "73": 0.180336,
                "74": 0.18136,
                "75": 0.180794,
                "76": 0.180696,
                "77": 0.179358,
                "78": 0.18207,
                "79": 0.181366,
                "80": 0.179925,
                "81": 0.1833,
                "82": 0.180881,
                "83": 0.182984,
                "84": 0.181341,
                "85": 0.18235,
                "86": 0.182745,
                "87": 0.17575,
                "88": 0.180883,
                "89": 0.181145,
                "90": 0.182561,
                "91": 0.182993,
                "92": 0.181921,
                "93": 0.184016,
                "94": 0.183207,
                "95": 0.183649,
                "96": 0.18274,
                "97": 0.182887,
                "98": 0.138781
            },
            "validation_time": 0.890756,
            "epoch_time": 18.557148933410645
        },
        "5": {
            "steps": {
                "1": 0.180027,
                "2": 0.18018,
                "3": 0.181184,
                "4": 0.181928,
                "5": 0.181401,
                "6": 0.182146,
                "7": 0.180783,
                "8": 0.182253,
                "9": 0.183186,
                "10": 0.183558,
                "11": 0.182753,
                "12": 0.182581,
                "13": 0.183987,
                "14": 0.183777,
                "15": 0.18301,
                "16": 0.183355,
                "17": 0.182653,
                "18": 0.182818,
                "19": 0.18368,
                "20": 0.182968,
                "21": 0.1833,
                "22": 0.182009,
                "23": 0.182175,
                "24": 0.182655,
                "25": 0.183047,
                "26": 0.182761,
                "27": 0.183832,
                "28": 0.183454,
                "29": 0.182687,
                "30": 0.183427,
                "31": 0.184979,
                "32": 0.183869,
                "33": 0.183309,
                "34": 0.181736,
                "35": 0.184081,
                "36": 0.184801,
                "37": 0.181177,
                "38": 0.183964,
                "39": 0.18397,
                "40": 0.1834,
                "41": 0.183176,
                "42": 0.18244,
                "43": 0.182895,
                "44": 0.183034,
                "45": 0.182007,
                "46": 0.182678,
                "47": 0.182267,
                "48": 0.182583,
                "49": 0.183235,
                "50": 0.183312,
                "51": 0.182701,
                "52": 0.183022,
                "53": 0.182818,
                "54": 0.182349,
                "55": 0.183233,
                "56": 0.182299,
                "57": 0.182975,
                "58": 0.182016,
                "59": 0.182888,
                "60": 0.183626,
                "61": 0.182714,
                "62": 0.183712,
                "63": 0.182458,
                "64": 0.183135,
                "65": 0.183551,
                "66": 0.182556,
                "67": 0.182349,
                "68": 0.183322,
                "69": 0.182607,
                "70": 0.18342,
                "71": 0.182643,
                "72": 0.182831,
                "73": 0.183223,
                "74": 0.183003,
                "75": 0.182929,
                "76": 0.182871,
                "77": 0.182542,
                "78": 0.183019,
                "79": 0.18322,
                "80": 0.182606,
                "81": 0.183253,
                "82": 0.182525,
                "83": 0.18321,
                "84": 0.183224,
                "85": 0.18344,
                "86": 0.182506,
                "87": 0.183272,
                "88": 0.183399,
                "89": 0.182236,
                "90": 0.182678,
                "91": 0.182956,
                "92": 0.183054,
                "93": 0.18323,
                "94": 0.182554,
                "95": 0.182112,
                "96": 0.181645,
                "97": 0.18215,
                "98": 0.142592
            },
            "validation_time": 0.897481,
            "epoch_time": 18.778178691864014
        }
    },
    "computing_system": "g4dn4xlarge-1",
    "batch_size": "512"
}
