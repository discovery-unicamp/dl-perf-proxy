{
    "init": -1.0,
    "total_training": 163.1542887687683,
    "largest_real_time_delta": 159.19357657432556,
    "fit_time": 163.1542887687683,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 128.190251,
                "2": 0.065256,
                "3": 0.062721,
                "4": 0.062232,
                "5": 0.062763,
                "6": 0.06467,
                "7": 0.062722,
                "8": 0.061597,
                "9": 0.063138,
                "10": 0.060728,
                "11": 0.060256,
                "12": 0.061381,
                "13": 0.06044,
                "14": 0.061735,
                "15": 0.063109,
                "16": 0.065559,
                "17": 0.064394,
                "18": 0.064374,
                "19": 0.063204,
                "20": 0.059497,
                "21": 0.062369,
                "22": 0.060951,
                "23": 0.061901,
                "24": 0.06388,
                "25": 0.064342,
                "26": 0.064425,
                "27": 0.064605,
                "28": 0.064514,
                "29": 0.064453,
                "30": 0.063806,
                "31": 0.060113,
                "32": 0.062409,
                "33": 0.061019,
                "34": 0.0651,
                "35": 0.064337,
                "36": 0.061677,
                "37": 0.062641,
                "38": 0.064651,
                "39": 0.059855,
                "40": 0.065461,
                "41": 0.060953,
                "42": 0.060445,
                "43": 0.065868,
                "44": 0.062205,
                "45": 0.062484,
                "46": 0.065783,
                "47": 0.064375,
                "48": 0.059286,
                "49": 1.350378
            },
            "validation_time": 11.938302,
            "epoch_time": 145.46049737930298,
            "validation_accuracy": 0.0
        },
        "2": {
            "steps": {
                "1": 0.065771,
                "2": 0.066078,
                "3": 0.066089,
                "4": 0.060299,
                "5": 0.06447,
                "6": 0.059062,
                "7": 0.062734,
                "8": 0.065895,
                "9": 0.065543,
                "10": 0.063738,
                "11": 0.061049,
                "12": 0.066101,
                "13": 0.066074,
                "14": 0.063138,
                "15": 0.064972,
                "16": 0.062022,
                "17": 0.062408,
                "18": 0.065682,
                "19": 0.06552,
                "20": 0.064382,
                "21": 0.064212,
                "22": 0.061189,
                "23": 0.060961,
                "24": 0.064122,
                "25": 0.063427,
                "26": 0.059865,
                "27": 0.060962,
                "28": 0.065209,
                "29": 0.063162,
                "30": 0.065201,
                "31": 0.062049,
                "32": 0.060986,
                "33": 0.060023,
                "34": 0.065386,
                "35": 0.06481,
                "36": 0.063809,
                "37": 0.063606,
                "38": 0.062318,
                "39": 0.06312,
                "40": 0.063132,
                "41": 0.061913,
                "42": 0.067837,
                "43": 0.063541,
                "44": 0.066452,
                "45": 0.064455,
                "46": 0.063204,
                "47": 0.063494,
                "48": 0.064596,
                "49": 0.100928
            },
            "validation_time": 0.272376,
            "epoch_time": 3.4355320930480957,
            "validation_accuracy": 0.0999
        },
        "3": {
            "steps": {
                "1": 0.068252,
                "2": 0.067316,
                "3": 0.066316,
                "4": 0.065293,
                "5": 0.063105,
                "6": 0.061493,
                "7": 0.06375,
                "8": 0.065643,
                "9": 0.061822,
                "10": 0.065373,
                "11": 0.063101,
                "12": 0.06719,
                "13": 0.062082,
                "14": 0.062212,
                "15": 0.064016,
                "16": 0.064814,
                "17": 0.067253,
                "18": 0.062818,
                "19": 0.063944,
                "20": 0.064072,
                "21": 0.063915,
                "22": 0.066658,
                "23": 0.065955,
                "24": 0.066684,
                "25": 0.067188,
                "26": 0.062896,
                "27": 0.062798,
                "28": 0.062508,
                "29": 0.063503,
                "30": 0.063568,
                "31": 0.06339,
                "32": 0.066618,
                "33": 0.06628,
                "34": 0.06354,
                "35": 0.064802,
                "36": 0.0643,
                "37": 0.063821,
                "38": 0.065587,
                "39": 0.064826,
                "40": 0.065921,
                "41": 0.063462,
                "42": 0.067031,
                "43": 0.061515,
                "44": 0.064026,
                "45": 0.06424,
                "46": 0.066435,
                "47": 0.063564,
                "48": 0.062522,
                "49": 0.106208
            },
            "validation_time": 0.24701,
            "epoch_time": 3.4587604999542236,
            "validation_accuracy": 0.0999
        },
        "4": {
            "steps": {
                "1": 0.063504,
                "2": 0.06469,
                "3": 0.064813,
                "4": 0.061889,
                "5": 0.064965,
                "6": 0.064363,
                "7": 0.061064,
                "8": 0.066011,
                "9": 0.063239,
                "10": 0.060452,
                "11": 0.063764,
                "12": 0.063532,
                "13": 0.06213,
                "14": 0.063101,
                "15": 0.063496,
                "16": 0.065673,
                "17": 0.063467,
                "18": 0.066759,
                "19": 0.065032,
                "20": 0.063677,
                "21": 0.063428,
                "22": 0.068158,
                "23": 0.064456,
                "24": 0.066451,
                "25": 0.063538,
                "26": 0.064461,
                "27": 0.063617,
                "28": 0.068262,
                "29": 0.063349,
                "30": 0.065452,
                "31": 0.062362,
                "32": 0.062838,
                "33": 0.064285,
                "34": 0.065573,
                "35": 0.06437,
                "36": 0.066489,
                "37": 0.061418,
                "38": 0.062931,
                "39": 0.061032,
                "40": 0.064287,
                "41": 0.063206,
                "42": 0.067969,
                "43": 0.061386,
                "44": 0.064625,
                "45": 0.060519,
                "46": 0.061104,
                "47": 0.063822,
                "48": 0.061211,
                "49": 0.107015
            },
            "validation_time": 0.254324,
            "epoch_time": 3.4359323978424072,
            "validation_accuracy": 0.0999
        },
        "5": {
            "steps": {
                "1": 0.06373,
                "2": 0.063638,
                "3": 0.061452,
                "4": 0.06322,
                "5": 0.059962,
                "6": 0.060339,
                "7": 0.060633,
                "8": 0.060423,
                "9": 0.063666,
                "10": 0.061098,
                "11": 0.062418,
                "12": 0.065148,
                "13": 0.060815,
                "14": 0.067257,
                "15": 0.059906,
                "16": 0.060821,
                "17": 0.062586,
                "18": 0.063552,
                "19": 0.06127,
                "20": 0.061145,
                "21": 0.063236,
                "22": 0.061826,
                "23": 0.061995,
                "24": 0.062911,
                "25": 0.061894,
                "26": 0.063805,
                "27": 0.064078,
                "28": 0.065714,
                "29": 0.062546,
                "30": 0.065816,
                "31": 0.064476,
                "32": 0.063159,
                "33": 0.062386,
                "34": 0.064922,
                "35": 0.06366,
                "36": 0.063661,
                "37": 0.065384,
                "38": 0.064715,
                "39": 0.06422,
                "40": 0.061142,
                "41": 0.063181,
                "42": 0.061688,
                "43": 0.062537,
                "44": 0.061738,
                "45": 0.063148,
                "46": 0.061745,
                "47": 0.062462,
                "48": 0.068357,
                "49": 0.100113
            },
            "validation_time": 0.274263,
            "epoch_time": 3.4018709659576416,
            "validation_accuracy": 0.0999
        }
    },
    "computing_system": "p3-8",
    "batch_size": "1024"
}
