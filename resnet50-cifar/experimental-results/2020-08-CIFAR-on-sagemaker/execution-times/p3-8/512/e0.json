{
    "init": -1.0,
    "total_training": 173.5634651184082,
    "largest_real_time_delta": 169.71295499801636,
    "fit_time": 173.5634651184082,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 127.169606,
                "2": 0.062835,
                "3": 0.05203,
                "4": 0.053236,
                "5": 0.054328,
                "6": 0.0531,
                "7": 0.052388,
                "8": 0.055992,
                "9": 0.052563,
                "10": 0.05435,
                "11": 0.052621,
                "12": 0.05533,
                "13": 0.055918,
                "14": 0.052548,
                "15": 0.052055,
                "16": 0.058964,
                "17": 0.05162,
                "18": 0.052562,
                "19": 0.053332,
                "20": 0.053831,
                "21": 0.052525,
                "22": 0.052416,
                "23": 0.052744,
                "24": 0.054582,
                "25": 0.053876,
                "26": 0.055892,
                "27": 0.052369,
                "28": 0.056393,
                "29": 0.053988,
                "30": 0.055484,
                "31": 0.053496,
                "32": 0.054471,
                "33": 0.052422,
                "34": 0.053927,
                "35": 0.052746,
                "36": 0.054049,
                "37": 0.054259,
                "38": 0.052062,
                "39": 0.056209,
                "40": 0.054422,
                "41": 0.051936,
                "42": 0.056976,
                "43": 0.055978,
                "44": 0.053083,
                "45": 0.054402,
                "46": 0.053247,
                "47": 0.054671,
                "48": 0.055027,
                "49": 0.052501,
                "50": 0.053637,
                "51": 0.05224,
                "52": 0.051372,
                "53": 0.05394,
                "54": 0.052505,
                "55": 0.055308,
                "56": 0.055695,
                "57": 0.051135,
                "58": 0.056053,
                "59": 0.056079,
                "60": 0.057898,
                "61": 0.052438,
                "62": 0.052581,
                "63": 0.05213,
                "64": 0.052306,
                "65": 0.051737,
                "66": 0.056916,
                "67": 0.052376,
                "68": 0.053071,
                "69": 0.053396,
                "70": 0.056619,
                "71": 0.057938,
                "72": 0.053828,
                "73": 0.05314,
                "74": 0.053406,
                "75": 0.054006,
                "76": 0.056821,
                "77": 0.05379,
                "78": 0.055639,
                "79": 0.055547,
                "80": 0.05662,
                "81": 0.058152,
                "82": 0.056085,
                "83": 0.053109,
                "84": 0.053831,
                "85": 0.05886,
                "86": 0.055324,
                "87": 0.055037,
                "88": 0.053761,
                "89": 0.054463,
                "90": 0.052917,
                "91": 0.052952,
                "92": 0.051751,
                "93": 0.054286,
                "94": 0.052319,
                "95": 0.053572,
                "96": 0.059108,
                "97": 0.05737,
                "98": 1.224739
            },
            "validation_time": 11.702772,
            "epoch_time": 146.3369927406311,
            "validation_accuracy": 0.0069
        },
        "2": {
            "steps": {
                "1": 0.058534,
                "2": 0.062391,
                "3": 0.05607,
                "4": 0.055449,
                "5": 0.059079,
                "6": 0.056589,
                "7": 0.057569,
                "8": 0.054957,
                "9": 0.056701,
                "10": 0.055467,
                "11": 0.055665,
                "12": 0.056831,
                "13": 0.057579,
                "14": 0.058605,
                "15": 0.057714,
                "16": 0.053523,
                "17": 0.057304,
                "18": 0.053415,
                "19": 0.05396,
                "20": 0.058512,
                "21": 0.054328,
                "22": 0.058125,
                "23": 0.054872,
                "24": 0.054342,
                "25": 0.061093,
                "26": 0.060756,
                "27": 0.054416,
                "28": 0.054225,
                "29": 0.057625,
                "30": 0.061235,
                "31": 0.059407,
                "32": 0.058408,
                "33": 0.054488,
                "34": 0.05888,
                "35": 0.059124,
                "36": 0.056098,
                "37": 0.056946,
                "38": 0.058061,
                "39": 0.053299,
                "40": 0.054165,
                "41": 0.058015,
                "42": 0.054924,
                "43": 0.053487,
                "44": 0.056298,
                "45": 0.057061,
                "46": 0.056417,
                "47": 0.057,
                "48": 0.054076,
                "49": 0.057079,
                "50": 0.055047,
                "51": 0.054339,
                "52": 0.056493,
                "53": 0.056595,
                "54": 0.057401,
                "55": 0.058356,
                "56": 0.056602,
                "57": 0.05571,
                "58": 0.056873,
                "59": 0.056954,
                "60": 0.05934,
                "61": 0.055363,
                "62": 0.055142,
                "63": 0.054131,
                "64": 0.055066,
                "65": 0.054355,
                "66": 0.054573,
                "67": 0.053566,
                "68": 0.055166,
                "69": 0.055968,
                "70": 0.054271,
                "71": 0.057817,
                "72": 0.053028,
                "73": 0.053716,
                "74": 0.05877,
                "75": 0.056271,
                "76": 0.056648,
                "77": 0.054628,
                "78": 0.056657,
                "79": 0.054485,
                "80": 0.058137,
                "81": 0.055741,
                "82": 0.052947,
                "83": 0.054857,
                "84": 0.05277,
                "85": 0.057696,
                "86": 0.054491,
                "87": 0.055943,
                "88": 0.05724,
                "89": 0.058479,
                "90": 0.053845,
                "91": 0.055012,
                "92": 0.056176,
                "93": 0.054995,
                "94": 0.054993,
                "95": 0.053251,
                "96": 0.054154,
                "97": 0.0539,
                "98": 0.093829
            },
            "validation_time": 0.366095,
            "epoch_time": 5.916107177734375,
            "validation_accuracy": 0.0997
        },
        "3": {
            "steps": {
                "1": 0.059509,
                "2": 0.056623,
                "3": 0.057608,
                "4": 0.055494,
                "5": 0.054725,
                "6": 0.055993,
                "7": 0.054273,
                "8": 0.058137,
                "9": 0.054668,
                "10": 0.056247,
                "11": 0.057712,
                "12": 0.052698,
                "13": 0.053818,
                "14": 0.056461,
                "15": 0.055226,
                "16": 0.052958,
                "17": 0.057401,
                "18": 0.057357,
                "19": 0.053706,
                "20": 0.058034,
                "21": 0.055587,
                "22": 0.057152,
                "23": 0.054342,
                "24": 0.054503,
                "25": 0.053124,
                "26": 0.054292,
                "27": 0.05417,
                "28": 0.051937,
                "29": 0.053228,
                "30": 0.055748,
                "31": 0.058241,
                "32": 0.060036,
                "33": 0.058962,
                "34": 0.053903,
                "35": 0.054667,
                "36": 0.054372,
                "37": 0.057546,
                "38": 0.057261,
                "39": 0.052618,
                "40": 0.052878,
                "41": 0.052883,
                "42": 0.052037,
                "43": 0.053704,
                "44": 0.055458,
                "45": 0.053581,
                "46": 0.055496,
                "47": 0.053777,
                "48": 0.0547,
                "49": 0.055997,
                "50": 0.052566,
                "51": 0.056431,
                "52": 0.057046,
                "53": 0.052542,
                "54": 0.056277,
                "55": 0.053786,
                "56": 0.056401,
                "57": 0.053401,
                "58": 0.053455,
                "59": 0.054795,
                "60": 0.053505,
                "61": 0.055337,
                "62": 0.05663,
                "63": 0.055832,
                "64": 0.054596,
                "65": 0.057983,
                "66": 0.054718,
                "67": 0.053005,
                "68": 0.053864,
                "69": 0.057909,
                "70": 0.053721,
                "71": 0.05538,
                "72": 0.055149,
                "73": 0.052764,
                "74": 0.056176,
                "75": 0.055751,
                "76": 0.059961,
                "77": 0.059119,
                "78": 0.058154,
                "79": 0.054779,
                "80": 0.059285,
                "81": 0.056801,
                "82": 0.054466,
                "83": 0.056029,
                "84": 0.057903,
                "85": 0.055204,
                "86": 0.055681,
                "87": 0.055143,
                "88": 0.057648,
                "89": 0.053901,
                "90": 0.053708,
                "91": 0.053518,
                "92": 0.0537,
                "93": 0.052197,
                "94": 0.052548,
                "95": 0.051797,
                "96": 0.052073,
                "97": 0.052037,
                "98": 0.092705
            },
            "validation_time": 0.358383,
            "epoch_time": 5.8147666454315186,
            "validation_accuracy": 0.0998
        },
        "4": {
            "steps": {
                "1": 0.06081,
                "2": 0.054879,
                "3": 0.057755,
                "4": 0.053326,
                "5": 0.054745,
                "6": 0.053699,
                "7": 0.054248,
                "8": 0.054172,
                "9": 0.056469,
                "10": 0.05447,
                "11": 0.05837,
                "12": 0.058193,
                "13": 0.055323,
                "14": 0.057061,
                "15": 0.056991,
                "16": 0.057195,
                "17": 0.054203,
                "18": 0.060257,
                "19": 0.056081,
                "20": 0.054445,
                "21": 0.052893,
                "22": 0.057434,
                "23": 0.055002,
                "24": 0.054543,
                "25": 0.055331,
                "26": 0.057184,
                "27": 0.057592,
                "28": 0.0535,
                "29": 0.053558,
                "30": 0.056639,
                "31": 0.056118,
                "32": 0.05628,
                "33": 0.057148,
                "34": 0.055585,
                "35": 0.054683,
                "36": 0.054497,
                "37": 0.056821,
                "38": 0.055929,
                "39": 0.058729,
                "40": 0.053251,
                "41": 0.054525,
                "42": 0.053167,
                "43": 0.056394,
                "44": 0.054098,
                "45": 0.052179,
                "46": 0.055877,
                "47": 0.056784,
                "48": 0.055532,
                "49": 0.053417,
                "50": 0.057008,
                "51": 0.055136,
                "52": 0.054546,
                "53": 0.054968,
                "54": 0.054316,
                "55": 0.056059,
                "56": 0.057704,
                "57": 0.053684,
                "58": 0.055854,
                "59": 0.055365,
                "60": 0.053954,
                "61": 0.054693,
                "62": 0.058237,
                "63": 0.05531,
                "64": 0.05675,
                "65": 0.053608,
                "66": 0.055738,
                "67": 0.053499,
                "68": 0.057343,
                "69": 0.054171,
                "70": 0.058966,
                "71": 0.054602,
                "72": 0.058719,
                "73": 0.057193,
                "74": 0.05509,
                "75": 0.058016,
                "76": 0.059418,
                "77": 0.054593,
                "78": 0.0578,
                "79": 0.054075,
                "80": 0.05684,
                "81": 0.057714,
                "82": 0.05445,
                "83": 0.053053,
                "84": 0.058979,
                "85": 0.058333,
                "86": 0.057021,
                "87": 0.057366,
                "88": 0.055094,
                "89": 0.054876,
                "90": 0.053935,
                "91": 0.058358,
                "92": 0.054945,
                "93": 0.055129,
                "94": 0.058128,
                "95": 0.054524,
                "96": 0.056326,
                "97": 0.057555,
                "98": 0.088873
            },
            "validation_time": 0.349668,
            "epoch_time": 5.863105297088623,
            "validation_accuracy": 0.1002
        },
        "5": {
            "steps": {
                "1": 0.055039,
                "2": 0.054295,
                "3": 0.054516,
                "4": 0.057242,
                "5": 0.056725,
                "6": 0.056191,
                "7": 0.053769,
                "8": 0.056936,
                "9": 0.051944,
                "10": 0.052597,
                "11": 0.053814,
                "12": 0.053695,
                "13": 0.051926,
                "14": 0.05424,
                "15": 0.054334,
                "16": 0.053878,
                "17": 0.055321,
                "18": 0.055096,
                "19": 0.055039,
                "20": 0.053718,
                "21": 0.05308,
                "22": 0.058055,
                "23": 0.056241,
                "24": 0.054568,
                "25": 0.057518,
                "26": 0.053281,
                "27": 0.054829,
                "28": 0.05283,
                "29": 0.057305,
                "30": 0.057981,
                "31": 0.05524,
                "32": 0.057649,
                "33": 0.054975,
                "34": 0.055965,
                "35": 0.05622,
                "36": 0.052138,
                "37": 0.054091,
                "38": 0.054849,
                "39": 0.054827,
                "40": 0.052978,
                "41": 0.052613,
                "42": 0.054466,
                "43": 0.054436,
                "44": 0.053658,
                "45": 0.052095,
                "46": 0.060001,
                "47": 0.056442,
                "48": 0.053794,
                "49": 0.053746,
                "50": 0.053089,
                "51": 0.054461,
                "52": 0.052885,
                "53": 0.054071,
                "54": 0.054449,
                "55": 0.053858,
                "56": 0.056263,
                "57": 0.054061,
                "58": 0.052968,
                "59": 0.056473,
                "60": 0.05288,
                "61": 0.057756,
                "62": 0.053792,
                "63": 0.052442,
                "64": 0.053019,
                "65": 0.05842,
                "66": 0.053671,
                "67": 0.056144,
                "68": 0.0571,
                "69": 0.056531,
                "70": 0.056773,
                "71": 0.053436,
                "72": 0.053738,
                "73": 0.056878,
                "74": 0.055082,
                "75": 0.054629,
                "76": 0.054177,
                "77": 0.056873,
                "78": 0.055871,
                "79": 0.053191,
                "80": 0.053293,
                "81": 0.055993,
                "82": 0.055754,
                "83": 0.05367,
                "84": 0.055905,
                "85": 0.05441,
                "86": 0.054719,
                "87": 0.056604,
                "88": 0.055737,
                "89": 0.057045,
                "90": 0.057492,
                "91": 0.052855,
                "92": 0.056092,
                "93": 0.052822,
                "94": 0.054603,
                "95": 0.055394,
                "96": 0.058973,
                "97": 0.054547,
                "98": 0.085893
            },
            "validation_time": 0.360066,
            "epoch_time": 5.781015634536743,
            "validation_accuracy": 0.1005
        }
    },
    "computing_system": "p3-8",
    "batch_size": "512"
}
