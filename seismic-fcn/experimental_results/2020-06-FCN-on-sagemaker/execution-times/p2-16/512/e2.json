{
    "init": 7.830712080001831,
    "total_training": 71.1815838814,
    "largest_real_time_delta": 60.549999952316284,
    "fit_time": 63.0229611397,
    "write_model_time": 0.327875852585,
    "epochs": {
        "1": {
            "steps": {
                "1": 21.4785339832,
                "2": 0.0966610908508,
                "3": 0.100130081177,
                "4": 0.0952100753784,
                "5": 0.0931510925293,
                "6": 0.0937330722809,
                "7": 0.0973999500275,
                "8": 0.0955729484558,
                "9": 0.0948610305786,
                "10": 0.0939271450043,
                "11": 0.100980043411,
                "12": 0.0943880081177,
                "13": 0.0949881076813,
                "14": 0.0934319496155,
                "15": 0.101504802704,
                "16": 0.096440076828,
                "17": 0.0947139263153,
                "18": 0.0939559936523,
                "19": 0.100760936737,
                "20": 0.0944418907166,
                "21": 0.0959510803223,
                "22": 0.0935478210449,
                "23": 0.0990209579468,
                "24": 0.0959510803223,
                "25": 0.0955190658569,
                "26": 0.0930230617523,
                "27": 0.101019859314,
                "28": 0.0939269065857,
                "29": 0.0945520401001,
                "30": 0.0935909748077,
                "31": 0.101696014404,
                "32": 0.0945110321045,
                "33": 0.0938467979431,
                "34": 0.0925500392914,
                "35": 0.0989098548889,
                "36": 0.0941870212555,
                "37": 0.0950989723206,
                "38": 0.0923159122467,
                "39": 0.100785017014,
                "40": 0.0938980579376,
                "41": 0.0948600769043,
                "42": 0.0937759876251,
                "43": 0.101427078247,
                "44": 0.0935969352722,
                "45": 0.095743894577,
                "46": 0.0941030979156,
                "47": 0.101386070251,
                "48": 0.094447851181,
                "49": 0.0950748920441,
                "50": 0.0942821502686,
                "51": 0.101411104202,
                "52": 0.0933330059052,
                "53": 0.0948600769043,
                "54": 0.093672990799,
                "55": 0.099681854248,
                "56": 0.0930891036987,
                "57": 0.0951671600342,
                "58": 0.0929291248322,
                "59": 0.0996079444885,
                "60": 0.0936589241028,
                "61": 0.0944249629974,
                "62": 0.0933570861816,
                "63": 0.099898815155,
                "64": 0.0956571102142,
                "65": 0.0948321819305,
                "66": 0.0937390327454,
                "67": 0.0989410877228,
                "68": 0.0942339897156,
                "69": 0.0953090190887,
                "70": 0.0939469337463,
                "71": 0.101542949677,
                "72": 0.094388961792,
                "73": 0.0956828594208,
                "74": 0.0956370830536,
                "75": 0.0999839305878,
                "76": 0.0942161083221,
                "77": 0.0949921607971,
                "78": 0.0943779945374,
                "79": 0.0973031520844,
                "80": 0.117841959
            },
            "validation_accuracy": 0.9151,
            "validation_time": 0.518826007843,
            "epoch_time": 29.6033859253
        },
        "2": {
            "steps": {
                "1": 0.0956358909607,
                "2": 0.0951421260834,
                "3": 0.0950601100922,
                "4": 0.10010099411,
                "5": 0.0953748226166,
                "6": 0.0956511497498,
                "7": 0.0960438251495,
                "8": 0.102864027023,
                "9": 0.0962870121002,
                "10": 0.0958490371704,
                "11": 0.0962121486664,
                "12": 0.100182056427,
                "13": 0.0956749916077,
                "14": 0.0947890281677,
                "15": 0.0968289375305,
                "16": 0.0997550487518,
                "17": 0.0950729846954,
                "18": 0.0964331626892,
                "19": 0.0962619781494,
                "20": 0.100682020187,
                "21": 0.0947089195251,
                "22": 0.0942151546478,
                "23": 0.0956490039825,
                "24": 0.0996840000153,
                "25": 0.0961267948151,
                "26": 0.0950210094452,
                "27": 0.0956449508667,
                "28": 0.0987069606781,
                "29": 0.0950961112976,
                "30": 0.0946781635284,
                "31": 0.0946161746979,
                "32": 0.10133600235,
                "33": 0.0945959091187,
                "34": 0.0953481197357,
                "35": 0.0940001010895,
                "36": 0.0988929271698,
                "37": 0.0939199924469,
                "38": 0.0958018302917,
                "39": 0.0947871208191,
                "40": 0.0990331172943,
                "41": 0.0965139865875,
                "42": 0.096039056778,
                "43": 0.0943810939789,
                "44": 0.0969841480255,
                "45": 0.0955038070679,
                "46": 0.0941140651703,
                "47": 0.0953269004822,
                "48": 0.0989720821381,
                "49": 0.0939989089966,
                "50": 0.0935890674591,
                "51": 0.0962100028992,
                "52": 0.0972850322723,
                "53": 0.0960080623627,
                "54": 0.0937161445618,
                "55": 0.094743013382,
                "56": 0.100122928619,
                "57": 0.0946600437164,
                "58": 0.0936000347137,
                "59": 0.0959119796753,
                "60": 0.0984370708466,
                "61": 0.0953860282898,
                "62": 0.0945639610291,
                "63": 0.0942599773407,
                "64": 0.100719928741,
                "65": 0.09334897995,
                "66": 0.0947749614716,
                "67": 0.0950009822845,
                "68": 0.0985748767853,
                "69": 0.094761133194,
                "70": 0.0958437919617,
                "71": 0.0957281589508,
                "72": 0.0987739562988,
                "73": 0.0973889827728,
                "74": 0.095675945282,
                "75": 0.0956718921661,
                "76": 0.0998041629791,
                "77": 0.0971591472626,
                "78": 0.094621181488,
                "79": 0.0913090705872,
                "80": 0.0730609893799
            },
            "validation_accuracy": 0.9528,
            "validation_time": 0.0413010120392,
            "epoch_time": 7.72156906128
        },
        "3": {
            "steps": {
                "1": 0.100689888,
                "2": 0.0994489192963,
                "3": 0.097158908844,
                "4": 0.0957541465759,
                "5": 0.0951759815216,
                "6": 0.0967271327972,
                "7": 0.0969378948212,
                "8": 0.0968599319458,
                "9": 0.0955810546875,
                "10": 0.097118139267,
                "11": 0.098023891449,
                "12": 0.0972838401794,
                "13": 0.0941240787506,
                "14": 0.095801115036,
                "15": 0.0976929664612,
                "16": 0.0963761806488,
                "17": 0.0958690643311,
                "18": 0.0954320430756,
                "19": 0.097503900528,
                "20": 0.0962281227112,
                "21": 0.0960309505463,
                "22": 0.0962159633636,
                "23": 0.0973191261292,
                "24": 0.0962381362915,
                "25": 0.0963439941406,
                "26": 0.0957701206207,
                "27": 0.0969769954681,
                "28": 0.0961229801178,
                "29": 0.0953361988068,
                "30": 0.0955591201782,
                "31": 0.0976750850677,
                "32": 0.0965790748596,
                "33": 0.0960102081299,
                "34": 0.0994300842285,
                "35": 0.098051071167,
                "36": 0.0969758033752,
                "37": 0.0976569652557,
                "38": 0.100941181183,
                "39": 0.102061033249,
                "40": 0.0981440544128,
                "41": 0.0957679748535,
                "42": 0.0969347953796,
                "43": 0.0972309112549,
                "44": 0.095782995224,
                "45": 0.0952410697937,
                "46": 0.0967769622803,
                "47": 0.0971109867096,
                "48": 0.0958578586578,
                "49": 0.0955541133881,
                "50": 0.0959401130676,
                "51": 0.0972249507904,
                "52": 0.0962669849396,
                "53": 0.0953481197357,
                "54": 0.0967330932617,
                "55": 0.0972108840942,
                "56": 0.0972640514374,
                "57": 0.0951850414276,
                "58": 0.0960838794708,
                "59": 0.0976719856262,
                "60": 0.0963170528412,
                "61": 0.095587015152,
                "62": 0.0953960418701,
                "63": 0.0979919433594,
                "64": 0.0980489253998,
                "65": 0.0955338478088,
                "66": 0.0963730812073,
                "67": 0.0987000465393,
                "68": 0.09707903862,
                "69": 0.0963399410248,
                "70": 0.0972139835358,
                "71": 0.0979042053223,
                "72": 0.0973510742188,
                "73": 0.0956020355225,
                "74": 0.0967950820923,
                "75": 0.0978589057922,
                "76": 0.099622964859,
                "77": 0.0966989994049,
                "78": 0.0969541072845,
                "79": 0.0951068401337,
                "80": 0.0746331214905
            },
            "validation_accuracy": 0.967,
            "validation_time": 0.0401859283447,
            "epoch_time": 7.77469491959
        },
        "4": {
            "steps": {
                "1": 0.101099014282,
                "2": 0.100816011429,
                "3": 0.0969820022583,
                "4": 0.0973560810089,
                "5": 0.0965180397034,
                "6": 0.100047826767,
                "7": 0.0949029922485,
                "8": 0.0967361927032,
                "9": 0.0954048633575,
                "10": 0.0978209972382,
                "11": 0.0948519706726,
                "12": 0.095794916153,
                "13": 0.0970408916473,
                "14": 0.0973010063171,
                "15": 0.0945558547974,
                "16": 0.0951290130615,
                "17": 0.0968279838562,
                "18": 0.0965230464935,
                "19": 0.0938959121704,
                "20": 0.0947618484497,
                "21": 0.0940539836884,
                "22": 0.0963299274445,
                "23": 0.0948209762573,
                "24": 0.0954208374023,
                "25": 0.0954411029816,
                "26": 0.0979819297791,
                "27": 0.0947678089142,
                "28": 0.0960807800293,
                "29": 0.0957598686218,
                "30": 0.0974600315094,
                "31": 0.094908952713,
                "32": 0.0962429046631,
                "33": 0.0945200920105,
                "34": 0.09801197052,
                "35": 0.095951795578,
                "36": 0.0950419902802,
                "37": 0.0953099727631,
                "38": 0.0968980789185,
                "39": 0.0947852134705,
                "40": 0.0954911708832,
                "41": 0.095251083374,
                "42": 0.0969660282135,
                "43": 0.094230890274,
                "44": 0.0953741073608,
                "45": 0.0949552059174,
                "46": 0.0976579189301,
                "47": 0.0946719646454,
                "48": 0.0973269939423,
                "49": 0.0949258804321,
                "50": 0.0970618724823,
                "51": 0.0953850746155,
                "52": 0.0955619812012,
                "53": 0.094575881958,
                "54": 0.0960819721222,
                "55": 0.0940079689026,
                "56": 0.0937519073486,
                "57": 0.0957450866699,
                "58": 0.0955929756165,
                "59": 0.0935781002045,
                "60": 0.0947868824005,
                "61": 0.0949740409851,
                "62": 0.0957159996033,
                "63": 0.0942101478577,
                "64": 0.0950720310211,
                "65": 0.0945448875427,
                "66": 0.0970480442047,
                "67": 0.0966489315033,
                "68": 0.095232963562,
                "69": 0.0952501296997,
                "70": 0.0980629920959,
                "71": 0.0946900844574,
                "72": 0.0959830284119,
                "73": 0.0938489437103,
                "74": 0.0975949764252,
                "75": 0.0949759483337,
                "76": 0.0949831008911,
                "77": 0.094801902771,
                "78": 0.0968809127808,
                "79": 0.0920131206512,
                "80": 0.0734279155731
            },
            "validation_accuracy": 0.9764,
            "validation_time": 0.0414788722992,
            "epoch_time": 7.69336414337
        },
        "5": {
            "steps": {
                "1": 0.105040073395,
                "2": 0.0983898639679,
                "3": 0.0955801010132,
                "4": 0.0977449417114,
                "5": 0.0976309776306,
                "6": 0.0960819721222,
                "7": 0.0966830253601,
                "8": 0.0971310138702,
                "9": 0.0984358787537,
                "10": 0.0960800647736,
                "11": 0.0967519283295,
                "12": 0.0994040966034,
                "13": 0.0964889526367,
                "14": 0.0966308116913,
                "15": 0.0954501628876,
                "16": 0.0955951213837,
                "17": 0.0983738899231,
                "18": 0.0950970649719,
                "19": 0.0959048271179,
                "20": 0.0974299907684,
                "21": 0.0967838764191,
                "22": 0.095743894577,
                "23": 0.0947029590607,
                "24": 0.0958299636841,
                "25": 0.0988838672638,
                "26": 0.0966610908508,
                "27": 0.0958449840546,
                "28": 0.0964741706848,
                "29": 0.100440979004,
                "30": 0.0962600708008,
                "31": 0.0960669517517,
                "32": 0.0959129333496,
                "33": 0.0997288227081,
                "34": 0.0963380336761,
                "35": 0.0951738357544,
                "36": 0.0965700149536,
                "37": 0.0971479415894,
                "38": 0.0964329242706,
                "39": 0.0953850746155,
                "40": 0.0958178043365,
                "41": 0.0969200134277,
                "42": 0.0954539775848,
                "43": 0.094575881958,
                "44": 0.0952110290527,
                "45": 0.0974318981171,
                "46": 0.0944628715515,
                "47": 0.094172000885,
                "48": 0.0961940288544,
                "49": 0.0984961986542,
                "50": 0.0948460102081,
                "51": 0.0950438976288,
                "52": 0.0963230133057,
                "53": 0.0976948738098,
                "54": 0.0951919555664,
                "55": 0.0944299697876,
                "56": 0.0960869789124,
                "57": 0.098886013031,
                "58": 0.095320224762,
                "59": 0.0952351093292,
                "60": 0.096727848053,
                "61": 0.0961811542511,
                "62": 0.0952899456024,
                "63": 0.095321893692,
                "64": 0.0972290039062,
                "65": 0.0972859859467,
                "66": 0.0954370498657,
                "67": 0.0970778465271,
                "68": 0.0958268642426,
                "69": 0.0973510742188,
                "70": 0.0974111557007,
                "71": 0.0957889556885,
                "72": 0.0970370769501,
                "73": 0.0976531505585,
                "74": 0.0985338687897,
                "75": 0.0967018604279,
                "76": 0.0960631370544,
                "77": 0.0965559482574,
                "78": 0.0954070091248,
                "79": 0.0903000831604,
                "80": 0.0734169483185
            },
            "validation_accuracy": 0.9717,
            "validation_time": 0.0412330627441,
            "epoch_time": 7.74825191498
        }
    },
    "computing_system": "p2-16",
    "batch_size": "512"
}
