{
    "init": 7.620447874069214,
    "total_training": 57.4597928524,
    "largest_real_time_delta": 47.0699999332428,
    "fit_time": 49.5164480209,
    "write_model_time": 0.322860002518,
    "epochs": {
        "1": {
            "steps": {
                "1": 21.6352458,
                "2": 0.123465061188,
                "3": 0.125156879425,
                "4": 0.124856948853,
                "5": 0.119292020798,
                "6": 0.123641014099,
                "7": 0.119354009628,
                "8": 0.119719982147,
                "9": 0.125026941299,
                "10": 0.123145103455,
                "11": 0.119529008865,
                "12": 0.118928909302,
                "13": 0.119470119476,
                "14": 0.122498989105,
                "15": 0.120050191879,
                "16": 0.124711990356,
                "17": 0.120603084564,
                "18": 0.123790979385,
                "19": 0.12645983696,
                "20": 0.120990991592,
                "21": 0.125172138214,
                "22": 0.123046875,
                "23": 0.125839948654,
                "24": 0.126097202301,
                "25": 0.124248981476,
                "26": 0.123712062836,
                "27": 0.119611978531,
                "28": 0.124960899353,
                "29": 0.124846935272,
                "30": 0.123256921768,
                "31": 0.124830007553,
                "32": 0.126390218735,
                "33": 0.125,
                "34": 0.123296976089,
                "35": 0.125124931335,
                "36": 0.125823020935,
                "37": 0.123996019363,
                "38": 0.12403011322,
                "39": 0.119823932648,
                "40": 0.265519142151
            },
            "validation_accuracy": 0.8443,
            "validation_time": 0.522078990936,
            "epoch_time": 27.1177458763
        },
        "2": {
            "steps": {
                "1": 0.127806901932,
                "2": 0.120548963547,
                "3": 0.123748064041,
                "4": 0.12575507164,
                "5": 0.119832038879,
                "6": 0.1248691082,
                "7": 0.122206926346,
                "8": 0.124320030212,
                "9": 0.125571012497,
                "10": 0.124222993851,
                "11": 0.123918056488,
                "12": 0.123986959457,
                "13": 0.124408960342,
                "14": 0.124689102173,
                "15": 0.123252153397,
                "16": 0.124058961868,
                "17": 0.123961925507,
                "18": 0.12521982193,
                "19": 0.123065948486,
                "20": 0.12445807457,
                "21": 0.124587059021,
                "22": 0.124574899673,
                "23": 0.122741937637,
                "24": 0.125746965408,
                "25": 0.124406099319,
                "26": 0.124994039536,
                "27": 0.123121023178,
                "28": 0.123428821564,
                "29": 0.124087095261,
                "30": 0.123959064484,
                "31": 0.123183965683,
                "32": 0.124135017395,
                "33": 0.124821901321,
                "34": 0.124974012375,
                "35": 0.123337030411,
                "36": 0.124934911728,
                "37": 0.12508392334,
                "38": 0.125293970108,
                "39": 0.115391016006,
                "40": 0.104830026627
            },
            "validation_accuracy": 0.9292,
            "validation_time": 0.0405049324036,
            "epoch_time": 4.99387288094
        },
        "3": {
            "steps": {
                "1": 0.12562417984,
                "2": 0.122764825821,
                "3": 0.118851900101,
                "4": 0.122584104538,
                "5": 0.122990131378,
                "6": 0.123253107071,
                "7": 0.123364925385,
                "8": 0.123537063599,
                "9": 0.124163866043,
                "10": 0.12375497818,
                "11": 0.125779151917,
                "12": 0.123621940613,
                "13": 0.123678207397,
                "14": 0.122630119324,
                "15": 0.124269008636,
                "16": 0.122813940048,
                "17": 0.122900009155,
                "18": 0.124023914337,
                "19": 0.126335859299,
                "20": 0.122528076172,
                "21": 0.123110055923,
                "22": 0.1237180233,
                "23": 0.125023841858,
                "24": 0.124144077301,
                "25": 0.123262882233,
                "26": 0.122642040253,
                "27": 0.12629199028,
                "28": 0.123309850693,
                "29": 0.123706102371,
                "30": 0.123699188232,
                "31": 0.125239133835,
                "32": 0.122474908829,
                "33": 0.123240947723,
                "34": 0.124456882477,
                "35": 0.125072956085,
                "36": 0.124455928802,
                "37": 0.123292922974,
                "38": 0.123524904251,
                "39": 0.113321065903,
                "40": 0.103300094604
            },
            "validation_accuracy": 0.9528,
            "validation_time": 0.037024974823,
            "epoch_time": 4.96885704994
        },
        "4": {
            "steps": {
                "1": 0.129497051239,
                "2": 0.124387025833,
                "3": 0.125816106796,
                "4": 0.124899864197,
                "5": 0.126979112625,
                "6": 0.119714975357,
                "7": 0.125972986221,
                "8": 0.125767946243,
                "9": 0.125945091248,
                "10": 0.124547958374,
                "11": 0.125251054764,
                "12": 0.124579191208,
                "13": 0.126842021942,
                "14": 0.126498937607,
                "15": 0.120605945587,
                "16": 0.125216007233,
                "17": 0.127868175507,
                "18": 0.11939406395,
                "19": 0.126159906387,
                "20": 0.125850915909,
                "21": 0.127414941788,
                "22": 0.124448060989,
                "23": 0.124907970428,
                "24": 0.123393058777,
                "25": 0.126723051071,
                "26": 0.119471073151,
                "27": 0.125931978226,
                "28": 0.124320983887,
                "29": 0.126290082932,
                "30": 0.12330698967,
                "31": 0.125168085098,
                "32": 0.124513864517,
                "33": 0.125914096832,
                "34": 0.124997138977,
                "35": 0.126913070679,
                "36": 0.123847961426,
                "37": 0.126307010651,
                "38": 0.123512983322,
                "39": 0.118937969208,
                "40": 0.100322961807
            },
            "validation_accuracy": 0.9623,
            "validation_time": 0.0374178886414,
            "epoch_time": 5.02145409584
        },
        "5": {
            "steps": {
                "1": 0.125339984894,
                "2": 0.122720003128,
                "3": 0.123942136765,
                "4": 0.123256921768,
                "5": 0.122911930084,
                "6": 0.123903989792,
                "7": 0.124764204025,
                "8": 0.122726202011,
                "9": 0.12336397171,
                "10": 0.123729944229,
                "11": 0.124967098236,
                "12": 0.124159097672,
                "13": 0.122709989548,
                "14": 0.123003005981,
                "15": 0.124153852463,
                "16": 0.117916107178,
                "17": 0.122032880783,
                "18": 0.122883081436,
                "19": 0.123940944672,
                "20": 0.123028039932,
                "21": 0.123727083206,
                "22": 0.122606039047,
                "23": 0.124943971634,
                "24": 0.124055862427,
                "25": 0.122727870941,
                "26": 0.123552083969,
                "27": 0.11900806427,
                "28": 0.123893022537,
                "29": 0.123046875,
                "30": 0.123091936111,
                "31": 0.124102115631,
                "32": 0.122717142105,
                "33": 0.123215913773,
                "34": 0.123157024384,
                "35": 0.125645160675,
                "36": 0.123631954193,
                "37": 0.12242603302,
                "38": 0.122502088547,
                "39": 0.120642900467,
                "40": 0.103586912155
            },
            "validation_accuracy": 0.967,
            "validation_time": 0.04039311409,
            "epoch_time": 4.96320796013
        }
    },
    "computing_system": "p2-16",
    "batch_size": "1024"
}
