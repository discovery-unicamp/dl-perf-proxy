{
    "init": 0.17886805534362793,
    "total_training": 18.3767490387,
    "largest_real_time_delta": 15.079999923706055,
    "fit_time": -1.0,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 3.57150816917,
                "2": 0.0551960468292,
                "3": 0.0554389953613,
                "4": 0.0557589530945,
                "5": 0.0554368495941,
                "6": 0.055242061615,
                "7": 0.0552580356598,
                "8": 0.0547890663147,
                "9": 0.0548479557037,
                "10": 0.0545470714569,
                "11": 0.05490899086,
                "12": 0.0547170639038,
                "13": 0.0549499988556,
                "14": 0.0547139644623,
                "15": 0.0547659397125,
                "16": 0.0550739765167,
                "17": 0.0545258522034,
                "18": 0.0547189712524,
                "19": 0.054615020752,
                "20": 0.0547161102295,
                "21": 0.0547029972076,
                "22": 0.0550019741058,
                "23": 0.0551600456238,
                "24": 0.0561249256134,
                "25": 0.0548279285431,
                "26": 0.0548250675201,
                "27": 0.0548989772797,
                "28": 0.0550539493561,
                "29": 0.0547831058502,
                "30": 0.0549960136414,
                "31": 0.0553059577942,
                "32": 0.0551908016205,
                "33": 0.055065870285,
                "34": 0.0549468994141,
                "35": 0.0546989440918,
                "36": 0.0547621250153,
                "37": 0.0554549694061,
                "38": 0.0552129745483,
                "39": 0.0502769947052,
                "40": 0.57692694664
            },
            "validation_accuracy": 0.8491,
            "validation_time": 0.0917859077454,
            "epoch_time": 6.33991718292
        },
        "2": {
            "steps": {
                "1": 0.0550229549408,
                "2": 0.0547099113464,
                "3": 0.0549468994141,
                "4": 0.0547652244568,
                "5": 0.054692029953,
                "6": 0.0546641349792,
                "7": 0.0544850826263,
                "8": 0.0549478530884,
                "9": 0.0558331012726,
                "10": 0.0548760890961,
                "11": 0.0548350811005,
                "12": 0.0549120903015,
                "13": 0.0550639629364,
                "14": 0.0551469326019,
                "15": 0.0552020072937,
                "16": 0.0554850101471,
                "17": 0.055449962616,
                "18": 0.0550119876862,
                "19": 0.0547800064087,
                "20": 0.0547239780426,
                "21": 0.0546758174896,
                "22": 0.0548660755157,
                "23": 0.0546460151672,
                "24": 0.0547821521759,
                "25": 0.0551550388336,
                "26": 0.0551390647888,
                "27": 0.0551471710205,
                "28": 0.055878162384,
                "29": 0.0552961826324,
                "30": 0.0545430183411,
                "31": 0.0549869537354,
                "32": 0.0547759532928,
                "33": 0.0546579360962,
                "34": 0.0548131465912,
                "35": 0.0550529956818,
                "36": 0.0547800064087,
                "37": 0.0550088882446,
                "38": 0.0547230243683,
                "39": 0.0471210479736,
                "40": 0.027153968811
            },
            "validation_accuracy": 0.934,
            "validation_time": 0.00517201423645,
            "epoch_time": 2.18173789978
        },
        "3": {
            "steps": {
                "1": 0.0551481246948,
                "2": 0.0553441047668,
                "3": 0.0548748970032,
                "4": 0.0548980236053,
                "5": 0.0549771785736,
                "6": 0.0549499988556,
                "7": 0.05490899086,
                "8": 0.0548410415649,
                "9": 0.0548059940338,
                "10": 0.0551588535309,
                "11": 0.0551760196686,
                "12": 0.0558469295502,
                "13": 0.0556788444519,
                "14": 0.0556790828705,
                "15": 0.0552320480347,
                "16": 0.0547208786011,
                "17": 0.054811000824,
                "18": 0.0548739433289,
                "19": 0.054899930954,
                "20": 0.0548489093781,
                "21": 0.0547959804535,
                "22": 0.0547859668732,
                "23": 0.0547378063202,
                "24": 0.0548260211945,
                "25": 0.0548810958862,
                "26": 0.0545349121094,
                "27": 0.0553078651428,
                "28": 0.0553920269012,
                "29": 0.05539894104,
                "30": 0.0551018714905,
                "31": 0.0552759170532,
                "32": 0.0549890995026,
                "33": 0.0548629760742,
                "34": 0.0544230937958,
                "35": 0.0548260211945,
                "36": 0.0547571182251,
                "37": 0.0547871589661,
                "38": 0.0547251701355,
                "39": 0.046993970871,
                "40": 0.0270221233368
            },
            "validation_accuracy": 0.9387,
            "validation_time": 0.00470900535583,
            "epoch_time": 2.18250107765
        },
        "4": {
            "steps": {
                "1": 0.0546939373016,
                "2": 0.0548629760742,
                "3": 0.0557589530945,
                "4": 0.0547420978546,
                "5": 0.0548148155212,
                "6": 0.0547618865967,
                "7": 0.0548808574677,
                "8": 0.0547978878021,
                "9": 0.0555260181427,
                "10": 0.055037021637,
                "11": 0.0550899505615,
                "12": 0.054741859436,
                "13": 0.0550520420074,
                "14": 0.0553500652313,
                "15": 0.0552990436554,
                "16": 0.0551221370697,
                "17": 0.0553021430969,
                "18": 0.0552840232849,
                "19": 0.0551750659943,
                "20": 0.0553848743439,
                "21": 0.0552141666412,
                "22": 0.0552201271057,
                "23": 0.0555610656738,
                "24": 0.0547070503235,
                "25": 0.0550940036774,
                "26": 0.0547811985016,
                "27": 0.0549011230469,
                "28": 0.0549161434174,
                "29": 0.0549399852753,
                "30": 0.0550529956818,
                "31": 0.0549809932709,
                "32": 0.0550510883331,
                "33": 0.0548191070557,
                "34": 0.0551931858063,
                "35": 0.0548961162567,
                "36": 0.0552108287811,
                "37": 0.0552051067352,
                "38": 0.055438041687,
                "39": 0.0472919940948,
                "40": 0.0272300243378
            },
            "validation_accuracy": 0.9528,
            "validation_time": 0.00504302978516,
            "epoch_time": 2.18614196777
        },
        "5": {
            "steps": {
                "1": 0.0552039146423,
                "2": 0.0551769733429,
                "3": 0.0553159713745,
                "4": 0.0553390979767,
                "5": 0.0551221370697,
                "6": 0.0553770065308,
                "7": 0.0550229549408,
                "8": 0.0556101799011,
                "9": 0.0553209781647,
                "10": 0.0550000667572,
                "11": 0.0550808906555,
                "12": 0.0547578334808,
                "13": 0.0548758506775,
                "14": 0.0546379089355,
                "15": 0.0549800395966,
                "16": 0.0561089515686,
                "17": 0.0552940368652,
                "18": 0.0555551052094,
                "19": 0.0546929836273,
                "20": 0.0548250675201,
                "21": 0.0550320148468,
                "22": 0.0546321868896,
                "23": 0.0546379089355,
                "24": 0.0547640323639,
                "25": 0.0546979904175,
                "26": 0.0550770759583,
                "27": 0.0548639297485,
                "28": 0.0550270080566,
                "29": 0.0548710823059,
                "30": 0.0547139644623,
                "31": 0.054692029953,
                "32": 0.0547940731049,
                "33": 0.0549621582031,
                "34": 0.0548160076141,
                "35": 0.0549139976501,
                "36": 0.0549149513245,
                "37": 0.0549399852753,
                "38": 0.0548977851868,
                "39": 0.0472440719604,
                "40": 0.0273339748383
            },
            "validation_accuracy": 0.9575,
            "validation_time": 0.00485181808472,
            "epoch_time": 2.18418192863
        }
    },
    "computing_system": "p3-1",
    "batch_size": "1024"
}
