{
    "init": 4.503906011581421,
    "total_training": 36.4977118969,
    "largest_real_time_delta": 30.490000009536743,
    "fit_time": 31.8468060493,
    "write_model_time": 0.146962881088,
    "epochs": {
        "1": {
            "steps": {
                "1": 11.2109639645,
                "2": 0.0979869365692,
                "3": 0.095470905304,
                "4": 0.0950839519501,
                "5": 0.0910639762878,
                "6": 0.0942101478577,
                "7": 0.0918538570404,
                "8": 0.0903759002686,
                "9": 0.0926492214203,
                "10": 0.0962941646576,
                "11": 0.09534907341,
                "12": 0.0943810939789,
                "13": 0.095860004425,
                "14": 0.0944390296936,
                "15": 0.0946409702301,
                "16": 0.094386100769,
                "17": 0.0958151817322,
                "18": 0.0921740531921,
                "19": 0.0949130058289,
                "20": 0.0954020023346,
                "21": 0.0960919857025,
                "22": 0.096184015274,
                "23": 0.0960280895233,
                "24": 0.0949728488922,
                "25": 0.0911378860474,
                "26": 0.0966410636902,
                "27": 0.0965738296509,
                "28": 0.096174955368,
                "29": 0.0965099334717,
                "30": 0.0908579826355,
                "31": 0.0951409339905,
                "32": 0.0909390449524,
                "33": 0.0927491188049,
                "34": 0.0966310501099,
                "35": 0.0955760478973,
                "36": 0.0892839431763,
                "37": 0.09685587883,
                "38": 0.0939209461212,
                "39": 0.0909059047699,
                "40": 0.390352010727
            },
            "validation_accuracy": 0.8255,
            "validation_time": 0.286216020584,
            "epoch_time": 15.4875531197
        },
        "2": {
            "steps": {
                "1": 0.100406885147,
                "2": 0.0964260101318,
                "3": 0.0941200256348,
                "4": 0.0890519618988,
                "5": 0.098039150238,
                "6": 0.096186876297,
                "7": 0.0909099578857,
                "8": 0.0950889587402,
                "9": 0.092386007309,
                "10": 0.0948920249939,
                "11": 0.0950949192047,
                "12": 0.0904259681702,
                "13": 0.0939462184906,
                "14": 0.0908279418945,
                "15": 0.0948169231415,
                "16": 0.0943551063538,
                "17": 0.0958349704742,
                "18": 0.0946428775787,
                "19": 0.0947599411011,
                "20": 0.0952570438385,
                "21": 0.0912051200867,
                "22": 0.0910999774933,
                "23": 0.0952620506287,
                "24": 0.0885319709778,
                "25": 0.0962610244751,
                "26": 0.0956628322601,
                "27": 0.0945720672607,
                "28": 0.0881311893463,
                "29": 0.0964150428772,
                "30": 0.091010093689,
                "31": 0.0945680141449,
                "32": 0.0931289196014,
                "33": 0.0924079418182,
                "34": 0.090096950531,
                "35": 0.0947210788727,
                "36": 0.0909869670868,
                "37": 0.0955009460449,
                "38": 0.089907169342,
                "39": 0.0892870426178,
                "40": 0.0661780834198
            },
            "validation_accuracy": 0.9245,
            "validation_time": 0.0260050296783,
            "epoch_time": 3.75324392319
        },
        "3": {
            "steps": {
                "1": 0.0907979011536,
                "2": 0.0946779251099,
                "3": 0.0955140590668,
                "4": 0.0943939685822,
                "5": 0.0899410247803,
                "6": 0.0949580669403,
                "7": 0.0965850353241,
                "8": 0.0956070423126,
                "9": 0.0962271690369,
                "10": 0.0883049964905,
                "11": 0.0929460525513,
                "12": 0.0950179100037,
                "13": 0.0930209159851,
                "14": 0.0891759395599,
                "15": 0.097225189209,
                "16": 0.0906240940094,
                "17": 0.0952320098877,
                "18": 0.0947642326355,
                "19": 0.0968101024628,
                "20": 0.0903780460358,
                "21": 0.097934961319,
                "22": 0.0932259559631,
                "23": 0.0952131748199,
                "24": 0.094279050827,
                "25": 0.0961818695068,
                "26": 0.0921869277954,
                "27": 0.0958971977234,
                "28": 0.0895400047302,
                "29": 0.0974609851837,
                "30": 0.0944979190826,
                "31": 0.0971150398254,
                "32": 0.0931270122528,
                "33": 0.0969150066376,
                "34": 0.0952010154724,
                "35": 0.0962920188904,
                "36": 0.0911908149719,
                "37": 0.0917870998383,
                "38": 0.0947530269623,
                "39": 0.0869309902191,
                "40": 0.0624749660492
            },
            "validation_accuracy": 0.934,
            "validation_time": 0.0242660045624,
            "epoch_time": 3.76342201233
        },
        "4": {
            "steps": {
                "1": 0.0958271026611,
                "2": 0.0927090644836,
                "3": 0.0908799171448,
                "4": 0.0932078361511,
                "5": 0.0966670513153,
                "6": 0.0938060283661,
                "7": 0.0906209945679,
                "8": 0.0941359996796,
                "9": 0.0963740348816,
                "10": 0.0941879749298,
                "11": 0.0918869972229,
                "12": 0.0958099365234,
                "13": 0.092139005661,
                "14": 0.0925631523132,
                "15": 0.0946311950684,
                "16": 0.0900220870972,
                "17": 0.0962879657745,
                "18": 0.0945100784302,
                "19": 0.0937731266022,
                "20": 0.0924010276794,
                "21": 0.0959029197693,
                "22": 0.0938320159912,
                "23": 0.0896990299225,
                "24": 0.0950109958649,
                "25": 0.0921721458435,
                "26": 0.0894441604614,
                "27": 0.0950179100037,
                "28": 0.0960700511932,
                "29": 0.0960490703583,
                "30": 0.0941019058228,
                "31": 0.095223903656,
                "32": 0.095202922821,
                "33": 0.0965390205383,
                "34": 0.0895841121674,
                "35": 0.0951690673828,
                "36": 0.0960829257965,
                "37": 0.0940999984741,
                "38": 0.0917429924011,
                "39": 0.0830299854279,
                "40": 0.0624120235443
            },
            "validation_accuracy": 0.9575,
            "validation_time": 0.0245718955994,
            "epoch_time": 3.7472910881
        },
        "5": {
            "steps": {
                "1": 0.0970728397369,
                "2": 0.0940198898315,
                "3": 0.095174074173,
                "4": 0.0946199893951,
                "5": 0.0968520641327,
                "6": 0.0942449569702,
                "7": 0.09055519104,
                "8": 0.0914781093597,
                "9": 0.0954689979553,
                "10": 0.0913660526276,
                "11": 0.0948231220245,
                "12": 0.0881600379944,
                "13": 0.0927112102509,
                "14": 0.0950119495392,
                "15": 0.0905749797821,
                "16": 0.0936999320984,
                "17": 0.0956718921661,
                "18": 0.0900859832764,
                "19": 0.0950708389282,
                "20": 0.0933220386505,
                "21": 0.0969390869141,
                "22": 0.0941820144653,
                "23": 0.093211889267,
                "24": 0.0945928096771,
                "25": 0.0924599170685,
                "26": 0.0942068099976,
                "27": 0.0947978496552,
                "28": 0.0906519889832,
                "29": 0.0949552059174,
                "30": 0.0892400741577,
                "31": 0.0933921337128,
                "32": 0.0936369895935,
                "33": 0.0972859859467,
                "34": 0.0951890945435,
                "35": 0.0882639884949,
                "36": 0.0889451503754,
                "37": 0.0958211421967,
                "38": 0.0928859710693,
                "39": 0.0820121765137,
                "40": 0.0673248767853
            },
            "validation_accuracy": 0.967,
            "validation_time": 0.0239889621735,
            "epoch_time": 3.73782992363
        }
    },
    "computing_system": "p2-8",
    "batch_size": "1024"
}
