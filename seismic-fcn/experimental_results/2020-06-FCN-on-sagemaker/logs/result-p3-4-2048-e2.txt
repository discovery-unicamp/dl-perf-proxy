/usr/bin/python 03_FCN_trainer_sm.py --batch-size 2048 --epochs 5 --file-output out.txt --num-gpus 4
Dados carregados de /opt/ml/input/data/train/train/train_SolimoesTacutu_64x64.pickle
 - train_labels
 - train_dataset
Conjunto de treinamento: (40512, 64, 64)

Dados carregados de /opt/ml/input/data/train/validation/valid_SolimoesTacutu_64x64.pickle
 - valid_labels
 - valid_dataset
Conjunto de validacao: (212, 64, 64)
Nenhuma borda adicionada
Novo formato do dado: (40512, 64, 64, 1)
Nenhuma borda adicionada
Novo formato do dado: (212, 64, 64, 1)
Informacoes gerais:
 - modelo: /opt/ml/model/FCN_9_SolimoesTacutu_64x64.ckpt
 - Conjunto de treinamento:
    - Total: 40512
 - Conjunto de validacao:
 - Tamanho do batch: 2048
 - Numero de epocas: 5
 - Taxa de aprendizagem inicial: 0.1
 - Taxa de decaimento: 0.01
 - GPUs solicitadas: 4
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 64, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 60, 60, 20)        520       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 30, 30, 20)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 26, 26, 50)        25050     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 13, 13, 50)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1, 1, 500)         4225500   
_________________________________________________________________
dropout_1 (Dropout)          (None, 1, 1, 500)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1, 1, 2)           1002      
=================================================================
Total params: 4,252,072
Trainable params: 4,252,072
Non-trainable params: 0
_________________________________________________________________
Training ...
('Tempo de inicializacao: ', 3.6783740520477295)
Train on 40512 samples, validate on 212 samples
Epoch 1/5

Real time: 1592977372.18

 2048/40512 [>.............................] - ETA: 2:39 - loss: 0.7563 - accuracy: 0.5146
1 step training time: 8.46984195709s

 4096/40512 [==>...........................] - ETA: 1:15 - loss: 0.7323 - accuracy: 0.6382
2 step training time: 0.0677309036255s

 6144/40512 [===>..........................] - ETA: 48s - loss: 0.7348 - accuracy: 0.6777 
3 step training time: 0.0677409172058s

 8192/40512 [=====>........................] - ETA: 34s - loss: 0.7096 - accuracy: 0.6953
4 step training time: 0.0672099590302s

10240/40512 [======>.......................] - ETA: 25s - loss: 0.6943 - accuracy: 0.7038
5 step training time: 0.0672369003296s

12288/40512 [========>.....................] - ETA: 20s - loss: 0.6836 - accuracy: 0.7109
6 step training time: 0.0667939186096s

14336/40512 [=========>....................] - ETA: 16s - loss: 0.6728 - accuracy: 0.7165
7 step training time: 0.0668768882751s

16384/40512 [===========>..................] - ETA: 13s - loss: 0.6627 - accuracy: 0.7217
8 step training time: 0.0671679973602s

18432/40512 [============>.................] - ETA: 10s - loss: 0.6544 - accuracy: 0.7269
9 step training time: 0.0674738883972s

20480/40512 [==============>...............] - ETA: 8s - loss: 0.6499 - accuracy: 0.7301 
10 step training time: 0.0676047801971s

22528/40512 [===============>..............] - ETA: 7s - loss: 0.6461 - accuracy: 0.7317
11 step training time: 0.0678479671478s

24576/40512 [=================>............] - ETA: 5s - loss: 0.6418 - accuracy: 0.7338
12 step training time: 0.0677280426025s

26624/40512 [==================>...........] - ETA: 4s - loss: 0.6381 - accuracy: 0.7355
13 step training time: 0.0674800872803s

28672/40512 [====================>.........] - ETA: 3s - loss: 0.6340 - accuracy: 0.7375
14 step training time: 0.0674619674683s

30720/40512 [=====================>........] - ETA: 3s - loss: 0.6302 - accuracy: 0.7392
15 step training time: 0.0667808055878s

32768/40512 [=======================>......] - ETA: 2s - loss: 0.6265 - accuracy: 0.7403
16 step training time: 0.0671350955963s

34816/40512 [========================>.....] - ETA: 1s - loss: 0.6226 - accuracy: 0.7417
17 step training time: 0.0670459270477s

36864/40512 [==========================>...] - ETA: 0s - loss: 0.6191 - accuracy: 0.7431
18 step training time: 0.0675511360168s

38912/40512 [===========================>..] - ETA: 0s - loss: 0.6152 - accuracy: 0.7448
19 step training time: 0.0645241737366s

20 step training time: 0.425705909729s

40512/40512 [==============================] - 10s 254us/step - loss: 0.6130 - accuracy: 0.7453 - val_loss: 0.5523 - val_accuracy: 0.7500
Validation time: 0.155415058136s

Real time: 1592977382.46s

Epoch time: 10.2859320641s
Epoch 2/5

Real time: 1592977382.46

 2048/40512 [>.............................] - ETA: 1s - loss: 0.5249 - accuracy: 0.7783
1 step training time: 0.0686159133911s

 4096/40512 [==>...........................] - ETA: 1s - loss: 0.5320 - accuracy: 0.7698
2 step training time: 0.0683550834656s

 6144/40512 [===>..........................] - ETA: 1s - loss: 0.5431 - accuracy: 0.7646
3 step training time: 0.0683760643005s

 8192/40512 [=====>........................] - ETA: 1s - loss: 0.5407 - accuracy: 0.7643
4 step training time: 0.0680780410767s

10240/40512 [======>.......................] - ETA: 1s - loss: 0.5388 - accuracy: 0.7689
5 step training time: 0.0679280757904s

12288/40512 [========>.....................] - ETA: 0s - loss: 0.5365 - accuracy: 0.7714
6 step training time: 0.0680139064789s

14336/40512 [=========>....................] - ETA: 0s - loss: 0.5353 - accuracy: 0.7700
7 step training time: 0.0673580169678s

16384/40512 [===========>..................] - ETA: 0s - loss: 0.5323 - accuracy: 0.7719
8 step training time: 0.0684721469879s

18432/40512 [============>.................] - ETA: 0s - loss: 0.5303 - accuracy: 0.7741
9 step training time: 0.0682699680328s

20480/40512 [==============>...............] - ETA: 0s - loss: 0.5266 - accuracy: 0.7767
10 step training time: 0.0669491291046s

22528/40512 [===============>..............] - ETA: 0s - loss: 0.5237 - accuracy: 0.7772
11 step training time: 0.0670120716095s

24576/40512 [=================>............] - ETA: 0s - loss: 0.5204 - accuracy: 0.7794
12 step training time: 0.0671389102936s

26624/40512 [==================>...........] - ETA: 0s - loss: 0.5185 - accuracy: 0.7791
13 step training time: 0.0672829151154s

28672/40512 [====================>.........] - ETA: 0s - loss: 0.5170 - accuracy: 0.7800
14 step training time: 0.0674240589142s

30720/40512 [=====================>........] - ETA: 0s - loss: 0.5143 - accuracy: 0.7816
15 step training time: 0.0672099590302s

32768/40512 [=======================>......] - ETA: 0s - loss: 0.5111 - accuracy: 0.7831
16 step training time: 0.0672271251678s

34816/40512 [========================>.....] - ETA: 0s - loss: 0.5079 - accuracy: 0.7846
17 step training time: 0.0671920776367s

36864/40512 [==========================>...] - ETA: 0s - loss: 0.5049 - accuracy: 0.7861
18 step training time: 0.0672879219055s

38912/40512 [===========================>..] - ETA: 0s - loss: 0.5023 - accuracy: 0.7884
19 step training time: 0.0593318939209s

20 step training time: 0.0375189781189s

40512/40512 [==============================] - 1s 33us/step - loss: 0.5010 - accuracy: 0.7892 - val_loss: 0.4059 - val_accuracy: 0.8491
Validation time: 0.00633811950684s

Real time: 1592977383.81s

Epoch time: 1.34862995148s
Epoch 3/5

Real time: 1592977383.81

 2048/40512 [>.............................] - ETA: 1s - loss: 0.4493 - accuracy: 0.8184
1 step training time: 0.0881209373474s

 4096/40512 [==>...........................] - ETA: 1s - loss: 0.4486 - accuracy: 0.8198
2 step training time: 0.087819814682s

 6144/40512 [===>..........................] - ETA: 1s - loss: 0.4403 - accuracy: 0.8255
3 step training time: 0.0868229866028s

 8192/40512 [=====>........................] - ETA: 1s - loss: 0.4385 - accuracy: 0.8290
4 step training time: 0.0671510696411s

10240/40512 [======>.......................] - ETA: 1s - loss: 0.4342 - accuracy: 0.8312
5 step training time: 0.0643661022186s

12288/40512 [========>.....................] - ETA: 1s - loss: 0.4299 - accuracy: 0.8324
6 step training time: 0.0674681663513s

14336/40512 [=========>....................] - ETA: 0s - loss: 0.4278 - accuracy: 0.8334
7 step training time: 0.0673389434814s

16384/40512 [===========>..................] - ETA: 0s - loss: 0.4238 - accuracy: 0.8362
8 step training time: 0.0670800209045s

18432/40512 [============>.................] - ETA: 0s - loss: 0.4228 - accuracy: 0.8377
9 step training time: 0.0671741962433s

20480/40512 [==============>...............] - ETA: 0s - loss: 0.4211 - accuracy: 0.8385
10 step training time: 0.0670390129089s

22528/40512 [===============>..............] - ETA: 0s - loss: 0.4207 - accuracy: 0.8374
11 step training time: 0.0670928955078s

24576/40512 [=================>............] - ETA: 0s - loss: 0.4197 - accuracy: 0.8387
12 step training time: 0.0672850608826s

26624/40512 [==================>...........] - ETA: 0s - loss: 0.4188 - accuracy: 0.8397
13 step training time: 0.0670330524445s

28672/40512 [====================>.........] - ETA: 0s - loss: 0.4168 - accuracy: 0.8410
14 step training time: 0.0675101280212s

30720/40512 [=====================>........] - ETA: 0s - loss: 0.4156 - accuracy: 0.8411
15 step training time: 0.06769490242s

32768/40512 [=======================>......] - ETA: 0s - loss: 0.4123 - accuracy: 0.8429
16 step training time: 0.067312002182s

34816/40512 [========================>.....] - ETA: 0s - loss: 0.4123 - accuracy: 0.8426
17 step training time: 0.0675740242004s

36864/40512 [==========================>...] - ETA: 0s - loss: 0.4105 - accuracy: 0.8434
18 step training time: 0.0682649612427s

38912/40512 [===========================>..] - ETA: 0s - loss: 0.4092 - accuracy: 0.8438
19 step training time: 0.0630061626434s

20 step training time: 0.0374581813812s

40512/40512 [==============================] - 1s 35us/step - loss: 0.4070 - accuracy: 0.8452 - val_loss: 0.3225 - val_accuracy: 0.9104
Validation time: 0.00640106201172s

Real time: 1592977385.22s

Epoch time: 1.40331983566s
Epoch 4/5

Real time: 1592977385.22

 2048/40512 [>.............................] - ETA: 1s - loss: 0.3896 - accuracy: 0.8638
1 step training time: 0.0669889450073s

 4096/40512 [==>...........................] - ETA: 1s - loss: 0.3744 - accuracy: 0.8660
2 step training time: 0.0672988891602s

 6144/40512 [===>..........................] - ETA: 1s - loss: 0.3690 - accuracy: 0.8669
3 step training time: 0.0670020580292s

 8192/40512 [=====>........................] - ETA: 1s - loss: 0.3694 - accuracy: 0.8657
4 step training time: 0.0669779777527s

10240/40512 [======>.......................] - ETA: 0s - loss: 0.3669 - accuracy: 0.8671
5 step training time: 0.0670940876007s

12288/40512 [========>.....................] - ETA: 0s - loss: 0.3685 - accuracy: 0.8652
6 step training time: 0.067088842392s

14336/40512 [=========>....................] - ETA: 0s - loss: 0.3651 - accuracy: 0.8682
7 step training time: 0.0674839019775s

16384/40512 [===========>..................] - ETA: 0s - loss: 0.3636 - accuracy: 0.8697
8 step training time: 0.0669538974762s

18432/40512 [============>.................] - ETA: 0s - loss: 0.3634 - accuracy: 0.8685
9 step training time: 0.0673899650574s

20480/40512 [==============>...............] - ETA: 0s - loss: 0.3603 - accuracy: 0.8694
10 step training time: 0.0675940513611s

22528/40512 [===============>..............] - ETA: 0s - loss: 0.3602 - accuracy: 0.8698
11 step training time: 0.0670838356018s

24576/40512 [=================>............] - ETA: 0s - loss: 0.3590 - accuracy: 0.8702
12 step training time: 0.0670919418335s

26624/40512 [==================>...........] - ETA: 0s - loss: 0.3578 - accuracy: 0.8710
13 step training time: 0.0670619010925s

28672/40512 [====================>.........] - ETA: 0s - loss: 0.3578 - accuracy: 0.8709
14 step training time: 0.0671689510345s

30720/40512 [=====================>........] - ETA: 0s - loss: 0.3573 - accuracy: 0.8710
15 step training time: 0.0675311088562s

32768/40512 [=======================>......] - ETA: 0s - loss: 0.3550 - accuracy: 0.8727
16 step training time: 0.0672240257263s

34816/40512 [========================>.....] - ETA: 0s - loss: 0.3538 - accuracy: 0.8733
17 step training time: 0.0674459934235s

36864/40512 [==========================>...] - ETA: 0s - loss: 0.3526 - accuracy: 0.8736
18 step training time: 0.0674629211426s

38912/40512 [===========================>..] - ETA: 0s - loss: 0.3521 - accuracy: 0.8736
19 step training time: 0.0624449253082s

20 step training time: 0.0369999408722s

40512/40512 [==============================] - 1s 33us/step - loss: 0.3510 - accuracy: 0.8745 - val_loss: 0.2815 - val_accuracy: 0.9340
Validation time: 0.00637698173523s

Real time: 1592977386.56s

Epoch time: 1.34165978432s
Epoch 5/5

Real time: 1592977386.56

 2048/40512 [>.............................] - ETA: 1s - loss: 0.3196 - accuracy: 0.8867
1 step training time: 0.0671310424805s

 4096/40512 [==>...........................] - ETA: 1s - loss: 0.3251 - accuracy: 0.8887
2 step training time: 0.066684961319s

 6144/40512 [===>..........................] - ETA: 1s - loss: 0.3254 - accuracy: 0.8892
3 step training time: 0.0670928955078s

 8192/40512 [=====>........................] - ETA: 1s - loss: 0.3332 - accuracy: 0.8853
4 step training time: 0.0683269500732s

10240/40512 [======>.......................] - ETA: 0s - loss: 0.3330 - accuracy: 0.8852
5 step training time: 0.0695009231567s

12288/40512 [========>.....................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8872
6 step training time: 0.0693490505219s

14336/40512 [=========>....................] - ETA: 0s - loss: 0.3322 - accuracy: 0.8882
7 step training time: 0.0697300434113s

16384/40512 [===========>..................] - ETA: 0s - loss: 0.3288 - accuracy: 0.8892
8 step training time: 0.0687849521637s

18432/40512 [============>.................] - ETA: 0s - loss: 0.3259 - accuracy: 0.8908
9 step training time: 0.0679049491882s

20480/40512 [==============>...............] - ETA: 0s - loss: 0.3247 - accuracy: 0.8908
10 step training time: 0.067323923111s

22528/40512 [===============>..............] - ETA: 0s - loss: 0.3252 - accuracy: 0.8906
11 step training time: 0.0683958530426s

24576/40512 [=================>............] - ETA: 0s - loss: 0.3246 - accuracy: 0.8903
12 step training time: 0.0680420398712s

26624/40512 [==================>...........] - ETA: 0s - loss: 0.3245 - accuracy: 0.8904
13 step training time: 0.0678269863129s

28672/40512 [====================>.........] - ETA: 0s - loss: 0.3230 - accuracy: 0.8916
14 step training time: 0.0681729316711s

30720/40512 [=====================>........] - ETA: 0s - loss: 0.3217 - accuracy: 0.8926
15 step training time: 0.0680320262909s

32768/40512 [=======================>......] - ETA: 0s - loss: 0.3216 - accuracy: 0.8913
16 step training time: 0.0692019462585s

34816/40512 [========================>.....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8928
17 step training time: 0.0680460929871s

36864/40512 [==========================>...] - ETA: 0s - loss: 0.3176 - accuracy: 0.8934
18 step training time: 0.0681447982788s

38912/40512 [===========================>..] - ETA: 0s - loss: 0.3163 - accuracy: 0.8944
19 step training time: 0.06334400177s

20 step training time: 0.037575006485s

40512/40512 [==============================] - 1s 34us/step - loss: 0.3163 - accuracy: 0.8946 - val_loss: 0.2382 - val_accuracy: 0.9481
Validation time: 0.00656414031982s

Real time: 1592977387.92s

Epoch time: 1.36122202873s
Tempo do fit: 16.5957899094
Modelo salvo:/opt/ml/model/FCN_9_SolimoesTacutu_64x64.ckpt
Tempo levado para o modelo ser salvo: 0.0890309810638
Duracao do treinamento:  20.3632321358

Training complete.
