{
    "init": -1.0,
    "total_training": 18.856621265411377,
    "largest_real_time_delta": 15.81155800819397,
    "fit_time": -1.0,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 2.765331,
                "2": 0.021724,
                "3": 0.020674,
                "4": 0.020646,
                "5": 0.020277,
                "6": 0.020644,
                "7": 0.020416,
                "8": 0.020392,
                "9": 0.020151,
                "10": 0.020533,
                "11": 0.020399,
                "12": 0.020513,
                "13": 0.020528,
                "14": 0.020517,
                "15": 0.020355,
                "16": 0.020622,
                "17": 0.020257,
                "18": 0.020771,
                "19": 0.020471,
                "20": 0.020624,
                "21": 0.020464,
                "22": 0.020697,
                "23": 0.02054,
                "24": 0.020723,
                "25": 0.020639,
                "26": 0.020719,
                "27": 0.020761,
                "28": 0.020843,
                "29": 0.020376,
                "30": 0.020423,
                "31": 0.020421,
                "32": 0.020523,
                "33": 0.020983,
                "34": 0.022432,
                "35": 0.021982,
                "36": 0.02182,
                "37": 0.021345,
                "38": 0.021555,
                "39": 0.021112,
                "40": 0.021054,
                "41": 0.02036,
                "42": 0.021104,
                "43": 0.02029,
                "44": 0.020952,
                "45": 0.020699,
                "46": 0.020792,
                "47": 0.020514,
                "48": 0.021008,
                "49": 0.020494,
                "50": 0.020513,
                "51": 0.020571,
                "52": 0.021265,
                "53": 0.020642,
                "54": 0.020846,
                "55": 0.021036,
                "56": 0.021465,
                "57": 0.0208,
                "58": 0.021214,
                "59": 0.020259,
                "60": 0.02036,
                "61": 0.020253,
                "62": 0.020724,
                "63": 0.020305,
                "64": 0.02051,
                "65": 0.020182,
                "66": 0.020741,
                "67": 0.020637,
                "68": 0.020648,
                "69": 0.020551,
                "70": 0.021671,
                "71": 0.021031,
                "72": 0.021224,
                "73": 0.021037,
                "74": 0.021048,
                "75": 0.020728,
                "76": 0.021279,
                "77": 0.020474,
                "78": 0.020906,
                "79": 0.020395,
                "80": 0.020529,
                "81": 0.020319,
                "82": 0.020782,
                "83": 0.020945,
                "84": 0.021155,
                "85": 0.020807,
                "86": 0.020845,
                "87": 0.020644,
                "88": 0.020744,
                "89": 0.020584,
                "90": 0.021368,
                "91": 0.021007,
                "92": 0.021618,
                "93": 0.021174,
                "94": 0.020995,
                "95": 0.020555,
                "96": 0.021238,
                "97": 0.020475,
                "98": 0.020793,
                "99": 0.020387,
                "100": 0.02285,
                "101": 0.020801,
                "102": 0.02165,
                "103": 0.02181,
                "104": 0.021687,
                "105": 0.02122,
                "106": 0.021155,
                "107": 0.02088,
                "108": 0.020415,
                "109": 0.020283,
                "110": 0.020961,
                "111": 0.020227,
                "112": 0.021047,
                "113": 0.02068,
                "114": 0.020517,
                "115": 0.020581,
                "116": 0.020903,
                "117": 0.020377,
                "118": 0.044557
            },
            "validation_accuracy": 0.9577,
            "validation_time": 0.201993,
            "epoch_time": 5.428355693817139
        },
        "2": {
            "steps": {
                "1": 0.021693,
                "2": 0.021087,
                "3": 0.021135,
                "4": 0.021436,
                "5": 0.021299,
                "6": 0.02168,
                "7": 0.021344,
                "8": 0.02113,
                "9": 0.020697,
                "10": 0.020699,
                "11": 0.020607,
                "12": 0.020656,
                "13": 0.020563,
                "14": 0.020589,
                "15": 0.020577,
                "16": 0.02053,
                "17": 0.020512,
                "18": 0.020309,
                "19": 0.020479,
                "20": 0.020406,
                "21": 0.021033,
                "22": 0.020981,
                "23": 0.020971,
                "24": 0.020744,
                "25": 0.020756,
                "26": 0.020524,
                "27": 0.020311,
                "28": 0.020522,
                "29": 0.020554,
                "30": 0.020322,
                "31": 0.020542,
                "32": 0.020552,
                "33": 0.020418,
                "34": 0.021167,
                "35": 0.021757,
                "36": 0.022149,
                "37": 0.021843,
                "38": 0.02141,
                "39": 0.021055,
                "40": 0.020975,
                "41": 0.021448,
                "42": 0.021337,
                "43": 0.021496,
                "44": 0.021228,
                "45": 0.020879,
                "46": 0.02099,
                "47": 0.020655,
                "48": 0.020392,
                "49": 0.020659,
                "50": 0.020319,
                "51": 0.020509,
                "52": 0.020309,
                "53": 0.020406,
                "54": 0.020392,
                "55": 0.020509,
                "56": 0.020411,
                "57": 0.020502,
                "58": 0.020464,
                "59": 0.020713,
                "60": 0.020408,
                "61": 0.020622,
                "62": 0.020577,
                "63": 0.020342,
                "64": 0.020569,
                "65": 0.020409,
                "66": 0.020512,
                "67": 0.020446,
                "68": 0.02062,
                "69": 0.02046,
                "70": 0.021141,
                "71": 0.020485,
                "72": 0.021139,
                "73": 0.020645,
                "74": 0.021319,
                "75": 0.020787,
                "76": 0.020847,
                "77": 0.020529,
                "78": 0.020966,
                "79": 0.020483,
                "80": 0.020595,
                "81": 0.020558,
                "82": 0.020979,
                "83": 0.020663,
                "84": 0.021753,
                "85": 0.021868,
                "86": 0.021366,
                "87": 0.02151,
                "88": 0.021225,
                "89": 0.020956,
                "90": 0.020744,
                "91": 0.020683,
                "92": 0.020446,
                "93": 0.02042,
                "94": 0.020512,
                "95": 0.020401,
                "96": 0.02049,
                "97": 0.020646,
                "98": 0.020958,
                "99": 0.020973,
                "100": 0.020405,
                "101": 0.020371,
                "102": 0.020354,
                "103": 0.020581,
                "104": 0.021221,
                "105": 0.020458,
                "106": 0.020697,
                "107": 0.020572,
                "108": 0.020816,
                "109": 0.020747,
                "110": 0.021283,
                "111": 0.020916,
                "112": 0.020868,
                "113": 0.020436,
                "114": 0.02052,
                "115": 0.020517,
                "116": 0.020326,
                "117": 0.020105,
                "118": 0.007606
            },
            "validation_accuracy": 0.976,
            "validation_time": 0.12961,
            "epoch_time": 2.5709152221679688
        },
        "3": {
            "steps": {
                "1": 0.020167,
                "2": 0.020407,
                "3": 0.020673,
                "4": 0.021322,
                "5": 0.021049,
                "6": 0.021011,
                "7": 0.020651,
                "8": 0.020683,
                "9": 0.020532,
                "10": 0.020761,
                "11": 0.020838,
                "12": 0.021457,
                "13": 0.021644,
                "14": 0.021965,
                "15": 0.021259,
                "16": 0.021516,
                "17": 0.021159,
                "18": 0.021074,
                "19": 0.020549,
                "20": 0.020576,
                "21": 0.020323,
                "22": 0.020695,
                "23": 0.020347,
                "24": 0.020732,
                "25": 0.02045,
                "26": 0.020838,
                "27": 0.020538,
                "28": 0.021081,
                "29": 0.02038,
                "30": 0.02111,
                "31": 0.020963,
                "32": 0.020636,
                "33": 0.021061,
                "34": 0.020773,
                "35": 0.020889,
                "36": 0.021266,
                "37": 0.020804,
                "38": 0.02074,
                "39": 0.020468,
                "40": 0.020617,
                "41": 0.021034,
                "42": 0.02095,
                "43": 0.021374,
                "44": 0.02138,
                "45": 0.021797,
                "46": 0.02126,
                "47": 0.02152,
                "48": 0.020871,
                "49": 0.021208,
                "50": 0.020314,
                "51": 0.020689,
                "52": 0.0205,
                "53": 0.020893,
                "54": 0.020364,
                "55": 0.020958,
                "56": 0.020777,
                "57": 0.02055,
                "58": 0.021057,
                "59": 0.021133,
                "60": 0.020846,
                "61": 0.021676,
                "62": 0.021255,
                "63": 0.021343,
                "64": 0.021062,
                "65": 0.021062,
                "66": 0.021062,
                "67": 0.020801,
                "68": 0.021311,
                "69": 0.021184,
                "70": 0.021366,
                "71": 0.021253,
                "72": 0.021826,
                "73": 0.021171,
                "74": 0.021271,
                "75": 0.020636,
                "76": 0.021066,
                "77": 0.020225,
                "78": 0.020696,
                "79": 0.02028,
                "80": 0.020825,
                "81": 0.02044,
                "82": 0.020439,
                "83": 0.020467,
                "84": 0.020408,
                "85": 0.020518,
                "86": 0.020661,
                "87": 0.02108,
                "88": 0.020851,
                "89": 0.021252,
                "90": 0.020696,
                "91": 0.021028,
                "92": 0.020918,
                "93": 0.021089,
                "94": 0.021473,
                "95": 0.02086,
                "96": 0.021198,
                "97": 0.02066,
                "98": 0.021084,
                "99": 0.020629,
                "100": 0.021756,
                "101": 0.021585,
                "102": 0.021814,
                "103": 0.021197,
                "104": 0.02155,
                "105": 0.020847,
                "106": 0.021355,
                "107": 0.020456,
                "108": 0.020947,
                "109": 0.021059,
                "110": 0.0207,
                "111": 0.020959,
                "112": 0.020585,
                "113": 0.021022,
                "114": 0.020816,
                "115": 0.02153,
                "116": 0.021383,
                "117": 0.020914,
                "118": 0.007881
            },
            "validation_accuracy": 0.98,
            "validation_time": 0.134013,
            "epoch_time": 2.5947721004486084
        },
        "4": {
            "steps": {
                "1": 0.020149,
                "2": 0.019809,
                "3": 0.020595,
                "4": 0.020269,
                "5": 0.020906,
                "6": 0.020706,
                "7": 0.020866,
                "8": 0.020661,
                "9": 0.021168,
                "10": 0.021133,
                "11": 0.021856,
                "12": 0.021241,
                "13": 0.021718,
                "14": 0.021092,
                "15": 0.021466,
                "16": 0.020844,
                "17": 0.020994,
                "18": 0.020476,
                "19": 0.021061,
                "20": 0.020396,
                "21": 0.020779,
                "22": 0.020659,
                "23": 0.020312,
                "24": 0.020791,
                "25": 0.021007,
                "26": 0.020746,
                "27": 0.02159,
                "28": 0.021242,
                "29": 0.021369,
                "30": 0.02083,
                "31": 0.021225,
                "32": 0.020629,
                "33": 0.020823,
                "34": 0.020527,
                "35": 0.021094,
                "36": 0.021459,
                "37": 0.021885,
                "38": 0.022309,
                "39": 0.021743,
                "40": 0.022126,
                "41": 0.021712,
                "42": 0.021152,
                "43": 0.021164,
                "44": 0.020774,
                "45": 0.021055,
                "46": 0.020681,
                "47": 0.021182,
                "48": 0.020516,
                "49": 0.021201,
                "50": 0.020681,
                "51": 0.021162,
                "52": 0.020583,
                "53": 0.020999,
                "54": 0.020545,
                "55": 0.020966,
                "56": 0.020505,
                "57": 0.021236,
                "58": 0.021081,
                "59": 0.021664,
                "60": 0.021385,
                "61": 0.021621,
                "62": 0.021589,
                "63": 0.020869,
                "64": 0.020874,
                "65": 0.020361,
                "66": 0.020763,
                "67": 0.020892,
                "68": 0.020392,
                "69": 0.020697,
                "70": 0.020377,
                "71": 0.020869,
                "72": 0.020568,
                "73": 0.02117,
                "74": 0.020611,
                "75": 0.021151,
                "76": 0.021074,
                "77": 0.020556,
                "78": 0.020779,
                "79": 0.021067,
                "80": 0.020495,
                "81": 0.020974,
                "82": 0.020823,
                "83": 0.02123,
                "84": 0.021542,
                "85": 0.022191,
                "86": 0.021785,
                "87": 0.022264,
                "88": 0.021538,
                "89": 0.021453,
                "90": 0.020839,
                "91": 0.021236,
                "92": 0.02057,
                "93": 0.021042,
                "94": 0.020788,
                "95": 0.021239,
                "96": 0.020608,
                "97": 0.02133,
                "98": 0.020818,
                "99": 0.021155,
                "100": 0.020662,
                "101": 0.020972,
                "102": 0.020337,
                "103": 0.020921,
                "104": 0.020316,
                "105": 0.02081,
                "106": 0.020481,
                "107": 0.02096,
                "108": 0.020992,
                "109": 0.021853,
                "110": 0.021473,
                "111": 0.021953,
                "112": 0.021407,
                "113": 0.021548,
                "114": 0.020817,
                "115": 0.020982,
                "116": 0.020494,
                "117": 0.020553,
                "118": 0.007567
            },
            "validation_accuracy": 0.9842,
            "validation_time": 0.134354,
            "epoch_time": 2.6021783351898193
        },
        "5": {
            "steps": {
                "1": 0.02041,
                "2": 0.020072,
                "3": 0.020791,
                "4": 0.020882,
                "5": 0.020515,
                "6": 0.021055,
                "7": 0.020682,
                "8": 0.021561,
                "9": 0.021118,
                "10": 0.021585,
                "11": 0.02079,
                "12": 0.021107,
                "13": 0.020581,
                "14": 0.020951,
                "15": 0.020459,
                "16": 0.021354,
                "17": 0.021307,
                "18": 0.021944,
                "19": 0.022013,
                "20": 0.021294,
                "21": 0.021624,
                "22": 0.021007,
                "23": 0.021072,
                "24": 0.020552,
                "25": 0.021076,
                "26": 0.020522,
                "27": 0.020943,
                "28": 0.02063,
                "29": 0.020828,
                "30": 0.020434,
                "31": 0.021207,
                "32": 0.020703,
                "33": 0.021343,
                "34": 0.020986,
                "35": 0.021553,
                "36": 0.020986,
                "37": 0.021147,
                "38": 0.020631,
                "39": 0.020861,
                "40": 0.020619,
                "41": 0.021606,
                "42": 0.022221,
                "43": 0.021772,
                "44": 0.021896,
                "45": 0.021222,
                "46": 0.021501,
                "47": 0.020768,
                "48": 0.021161,
                "49": 0.020586,
                "50": 0.020928,
                "51": 0.020968,
                "52": 0.020578,
                "53": 0.020869,
                "54": 0.02105,
                "55": 0.020633,
                "56": 0.020944,
                "57": 0.020604,
                "58": 0.020954,
                "59": 0.020531,
                "60": 0.021002,
                "61": 0.020599,
                "62": 0.020867,
                "63": 0.020538,
                "64": 0.021222,
                "65": 0.021695,
                "66": 0.021658,
                "67": 0.022121,
                "68": 0.02161,
                "69": 0.021994,
                "70": 0.021032,
                "71": 0.021271,
                "72": 0.020513,
                "73": 0.021014,
                "74": 0.020525,
                "75": 0.020988,
                "76": 0.020487,
                "77": 0.020879,
                "78": 0.020884,
                "79": 0.020651,
                "80": 0.02118,
                "81": 0.020907,
                "82": 0.021394,
                "83": 0.021503,
                "84": 0.020885,
                "85": 0.020856,
                "86": 0.020372,
                "87": 0.020977,
                "88": 0.020622,
                "89": 0.021205,
                "90": 0.02098,
                "91": 0.022225,
                "92": 0.02176,
                "93": 0.022238,
                "94": 0.021631,
                "95": 0.021694,
                "96": 0.020698,
                "97": 0.021057,
                "98": 0.020449,
                "99": 0.02089,
                "100": 0.020479,
                "101": 0.021014,
                "102": 0.020593,
                "103": 0.020866,
                "104": 0.020765,
                "105": 0.021288,
                "106": 0.020904,
                "107": 0.021412,
                "108": 0.020931,
                "109": 0.021301,
                "110": 0.02079,
                "111": 0.021106,
                "112": 0.023111,
                "113": 0.021267,
                "114": 0.02115,
                "115": 0.022107,
                "116": 0.021572,
                "117": 0.021212,
                "118": 0.007905
            },
            "validation_accuracy": 0.9858,
            "validation_time": 0.136037,
            "epoch_time": 2.6125898361206055
        }
    },
    "computing_system": "g4dn16xlarge-1",
    "batch_size": "512"
}
