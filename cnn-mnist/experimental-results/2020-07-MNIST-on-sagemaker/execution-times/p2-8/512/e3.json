{
    "init": -1.0,
    "total_training": 28.03486943244934,
    "largest_real_time_delta": 22.41384983062744,
    "fit_time": -1.0,
    "write_model_time": -1.0,
    "epochs": {
        "1": {
            "steps": {
                "1": 10.884679,
                "2": 0.01809,
                "3": 0.016988,
                "4": 0.0177,
                "5": 0.01791,
                "6": 0.016685,
                "7": 0.017893,
                "8": 0.017576,
                "9": 0.017744,
                "10": 0.017984,
                "11": 0.017092,
                "12": 0.017754,
                "13": 0.018253,
                "14": 0.017701,
                "15": 0.01657,
                "16": 0.0177,
                "17": 0.016388,
                "18": 0.017028,
                "19": 0.017995,
                "20": 0.017712,
                "21": 0.017714,
                "22": 0.017899,
                "23": 0.018581,
                "24": 0.018161,
                "25": 0.018632,
                "26": 0.017051,
                "27": 0.018269,
                "28": 0.017551,
                "29": 0.017593,
                "30": 0.018235,
                "31": 0.018233,
                "32": 0.017941,
                "33": 0.017488,
                "34": 0.017253,
                "35": 0.018518,
                "36": 0.018048,
                "37": 0.017887,
                "38": 0.017571,
                "39": 0.017632,
                "40": 0.017001,
                "41": 0.018209,
                "42": 0.017302,
                "43": 0.018141,
                "44": 0.016862,
                "45": 0.016965,
                "46": 0.017835,
                "47": 0.017682,
                "48": 0.017834,
                "49": 0.017831,
                "50": 0.01681,
                "51": 0.018231,
                "52": 0.017912,
                "53": 0.018428,
                "54": 0.017117,
                "55": 0.016871,
                "56": 0.017735,
                "57": 0.017976,
                "58": 0.017489,
                "59": 0.017597,
                "60": 0.016846,
                "61": 0.018057,
                "62": 0.017014,
                "63": 0.017851,
                "64": 0.017559,
                "65": 0.018165,
                "66": 0.017241,
                "67": 0.01709,
                "68": 0.017026,
                "69": 0.016806,
                "70": 0.017721,
                "71": 0.018007,
                "72": 0.017922,
                "73": 0.018158,
                "74": 0.017518,
                "75": 0.017778,
                "76": 0.017604,
                "77": 0.018267,
                "78": 0.01724,
                "79": 0.017446,
                "80": 0.016801,
                "81": 0.018058,
                "82": 0.017194,
                "83": 0.017977,
                "84": 0.017713,
                "85": 0.018052,
                "86": 0.0178,
                "87": 0.018286,
                "88": 0.016878,
                "89": 0.018097,
                "90": 0.017289,
                "91": 0.01714,
                "92": 0.017124,
                "93": 0.016978,
                "94": 0.016659,
                "95": 0.017083,
                "96": 0.016996,
                "97": 0.017719,
                "98": 0.016965,
                "99": 0.018273,
                "100": 0.017488,
                "101": 0.017372,
                "102": 0.01718,
                "103": 0.017957,
                "104": 0.017445,
                "105": 0.017931,
                "106": 0.017869,
                "107": 0.018293,
                "108": 0.017424,
                "109": 0.01793,
                "110": 0.0167,
                "111": 0.016889,
                "112": 0.017051,
                "113": 0.0172,
                "114": 0.017408,
                "115": 0.018218,
                "116": 0.017651,
                "117": 0.016597,
                "118": 0.024283
            },
            "validation_accuracy": 0.9607,
            "validation_time": 0.457228,
            "epoch_time": 13.408204317092896
        },
        "2": {
            "steps": {
                "1": 0.018201,
                "2": 0.017433,
                "3": 0.017383,
                "4": 0.017857,
                "5": 0.017668,
                "6": 0.016977,
                "7": 0.017137,
                "8": 0.016961,
                "9": 0.017438,
                "10": 0.018165,
                "11": 0.017596,
                "12": 0.018051,
                "13": 0.017659,
                "14": 0.01693,
                "15": 0.016845,
                "16": 0.017627,
                "17": 0.017658,
                "18": 0.018203,
                "19": 0.017743,
                "20": 0.017137,
                "21": 0.01736,
                "22": 0.018215,
                "23": 0.017661,
                "24": 0.01828,
                "25": 0.017134,
                "26": 0.017673,
                "27": 0.017059,
                "28": 0.017678,
                "29": 0.017301,
                "30": 0.018295,
                "31": 0.016926,
                "32": 0.017726,
                "33": 0.018797,
                "34": 0.017917,
                "35": 0.017802,
                "36": 0.017614,
                "37": 0.016924,
                "38": 0.01737,
                "39": 0.017133,
                "40": 0.017005,
                "41": 0.017297,
                "42": 0.017858,
                "43": 0.018151,
                "44": 0.016924,
                "45": 0.017415,
                "46": 0.017832,
                "47": 0.017651,
                "48": 0.017495,
                "49": 0.016892,
                "50": 0.01737,
                "51": 0.01747,
                "52": 0.018083,
                "53": 0.017556,
                "54": 0.016391,
                "55": 0.01675,
                "56": 0.017441,
                "57": 0.016776,
                "58": 0.018086,
                "59": 0.018238,
                "60": 0.017541,
                "61": 0.01754,
                "62": 0.018025,
                "63": 0.017025,
                "64": 0.017966,
                "65": 0.01802,
                "66": 0.017725,
                "67": 0.016835,
                "68": 0.017681,
                "69": 0.016867,
                "70": 0.017091,
                "71": 0.017631,
                "72": 0.018399,
                "73": 0.017914,
                "74": 0.017355,
                "75": 0.016834,
                "76": 0.018146,
                "77": 0.016736,
                "78": 0.017812,
                "79": 0.017261,
                "80": 0.017443,
                "81": 0.017278,
                "82": 0.018224,
                "83": 0.01723,
                "84": 0.017664,
                "85": 0.018089,
                "86": 0.016934,
                "87": 0.016953,
                "88": 0.017076,
                "89": 0.017618,
                "90": 0.017015,
                "91": 0.017443,
                "92": 0.017596,
                "93": 0.017489,
                "94": 0.017646,
                "95": 0.017818,
                "96": 0.01749,
                "97": 0.017455,
                "98": 0.01802,
                "99": 0.017678,
                "100": 0.017305,
                "101": 0.016792,
                "102": 0.01753,
                "103": 0.017747,
                "104": 0.017436,
                "105": 0.017567,
                "106": 0.017553,
                "107": 0.016973,
                "108": 0.017959,
                "109": 0.017116,
                "110": 0.017793,
                "111": 0.017966,
                "112": 0.017812,
                "113": 0.017718,
                "114": 0.017178,
                "115": 0.016619,
                "116": 0.017829,
                "117": 0.017381,
                "118": 0.015723
            },
            "validation_accuracy": 0.9776,
            "validation_time": 0.18263,
            "epoch_time": 2.249706268310547
        },
        "3": {
            "steps": {
                "1": 0.017046,
                "2": 0.016915,
                "3": 0.017256,
                "4": 0.017431,
                "5": 0.017494,
                "6": 0.017327,
                "7": 0.017688,
                "8": 0.017541,
                "9": 0.01773,
                "10": 0.017404,
                "11": 0.017567,
                "12": 0.017521,
                "13": 0.017757,
                "14": 0.016722,
                "15": 0.018257,
                "16": 0.017561,
                "17": 0.017563,
                "18": 0.017668,
                "19": 0.017196,
                "20": 0.016247,
                "21": 0.017743,
                "22": 0.017358,
                "23": 0.017645,
                "24": 0.016909,
                "25": 0.01789,
                "26": 0.017881,
                "27": 0.018124,
                "28": 0.017967,
                "29": 0.017787,
                "30": 0.017393,
                "31": 0.017853,
                "32": 0.01754,
                "33": 0.017054,
                "34": 0.017487,
                "35": 0.017996,
                "36": 0.017209,
                "37": 0.018893,
                "38": 0.0176,
                "39": 0.018577,
                "40": 0.017749,
                "41": 0.017838,
                "42": 0.017133,
                "43": 0.01752,
                "44": 0.017865,
                "45": 0.017882,
                "46": 0.01766,
                "47": 0.017962,
                "48": 0.017465,
                "49": 0.017856,
                "50": 0.01792,
                "51": 0.017981,
                "52": 0.017159,
                "53": 0.018125,
                "54": 0.017329,
                "55": 0.017814,
                "56": 0.01764,
                "57": 0.017567,
                "58": 0.017594,
                "59": 0.017269,
                "60": 0.016412,
                "61": 0.017399,
                "62": 0.017251,
                "63": 0.017137,
                "64": 0.016834,
                "65": 0.018099,
                "66": 0.017341,
                "67": 0.017887,
                "68": 0.017477,
                "69": 0.017548,
                "70": 0.017231,
                "71": 0.018581,
                "72": 0.017557,
                "73": 0.01835,
                "74": 0.017767,
                "75": 0.017576,
                "76": 0.018077,
                "77": 0.017597,
                "78": 0.016675,
                "79": 0.017559,
                "80": 0.017413,
                "81": 0.01717,
                "82": 0.017388,
                "83": 0.016732,
                "84": 0.01774,
                "85": 0.017781,
                "86": 0.01682,
                "87": 0.017784,
                "88": 0.016615,
                "89": 0.017327,
                "90": 0.017738,
                "91": 0.017319,
                "92": 0.01735,
                "93": 0.017923,
                "94": 0.017091,
                "95": 0.01845,
                "96": 0.017921,
                "97": 0.017734,
                "98": 0.017454,
                "99": 0.017892,
                "100": 0.016895,
                "101": 0.01779,
                "102": 0.018242,
                "103": 0.017486,
                "104": 0.01784,
                "105": 0.018202,
                "106": 0.017664,
                "107": 0.017563,
                "108": 0.017113,
                "109": 0.017333,
                "110": 0.017403,
                "111": 0.0168,
                "112": 0.017766,
                "113": 0.017017,
                "114": 0.017413,
                "115": 0.017087,
                "116": 0.017225,
                "117": 0.017678,
                "118": 0.014867
            },
            "validation_accuracy": 0.9782,
            "validation_time": 0.18035,
            "epoch_time": 2.2501115798950195
        },
        "4": {
            "steps": {
                "1": 0.01822,
                "2": 0.017149,
                "3": 0.01782,
                "4": 0.017478,
                "5": 0.017681,
                "6": 0.01733,
                "7": 0.017747,
                "8": 0.017105,
                "9": 0.01744,
                "10": 0.017985,
                "11": 0.017373,
                "12": 0.017503,
                "13": 0.017899,
                "14": 0.017841,
                "15": 0.01776,
                "16": 0.017788,
                "17": 0.017131,
                "18": 0.017661,
                "19": 0.017807,
                "20": 0.017488,
                "21": 0.017886,
                "22": 0.017568,
                "23": 0.01732,
                "24": 0.018248,
                "25": 0.017923,
                "26": 0.017727,
                "27": 0.01733,
                "28": 0.017841,
                "29": 0.017302,
                "30": 0.018109,
                "31": 0.017461,
                "32": 0.017096,
                "33": 0.017443,
                "34": 0.017482,
                "35": 0.017745,
                "36": 0.017221,
                "37": 0.017696,
                "38": 0.017514,
                "39": 0.017272,
                "40": 0.01735,
                "41": 0.017359,
                "42": 0.018115,
                "43": 0.01807,
                "44": 0.017689,
                "45": 0.017609,
                "46": 0.0179,
                "47": 0.017081,
                "48": 0.01669,
                "49": 0.018219,
                "50": 0.017661,
                "51": 0.016517,
                "52": 0.017852,
                "53": 0.017103,
                "54": 0.017888,
                "55": 0.017606,
                "56": 0.017372,
                "57": 0.01655,
                "58": 0.017854,
                "59": 0.017195,
                "60": 0.017569,
                "61": 0.017143,
                "62": 0.017513,
                "63": 0.01804,
                "64": 0.017892,
                "65": 0.017469,
                "66": 0.017944,
                "67": 0.017602,
                "68": 0.01815,
                "69": 0.016565,
                "70": 0.017381,
                "71": 0.017449,
                "72": 0.017363,
                "73": 0.017478,
                "74": 0.018054,
                "75": 0.01747,
                "76": 0.017289,
                "77": 0.017789,
                "78": 0.01755,
                "79": 0.017306,
                "80": 0.018569,
                "81": 0.017629,
                "82": 0.017838,
                "83": 0.017313,
                "84": 0.018428,
                "85": 0.017307,
                "86": 0.017969,
                "87": 0.016535,
                "88": 0.018561,
                "89": 0.016635,
                "90": 0.017171,
                "91": 0.017057,
                "92": 0.017705,
                "93": 0.017703,
                "94": 0.017678,
                "95": 0.016744,
                "96": 0.017829,
                "97": 0.017092,
                "98": 0.018007,
                "99": 0.017852,
                "100": 0.018426,
                "101": 0.016854,
                "102": 0.018164,
                "103": 0.017975,
                "104": 0.017055,
                "105": 0.01746,
                "106": 0.017426,
                "107": 0.017837,
                "108": 0.017536,
                "109": 0.016926,
                "110": 0.01824,
                "111": 0.017332,
                "112": 0.017091,
                "113": 0.017992,
                "114": 0.017756,
                "115": 0.017532,
                "116": 0.018299,
                "117": 0.016825,
                "118": 0.015212
            },
            "validation_accuracy": 0.9863,
            "validation_time": 0.180682,
            "epoch_time": 2.253542184829712
        },
        "5": {
            "steps": {
                "1": 0.017017,
                "2": 0.017375,
                "3": 0.017433,
                "4": 0.017718,
                "5": 0.017502,
                "6": 0.017586,
                "7": 0.01783,
                "8": 0.016948,
                "9": 0.017611,
                "10": 0.018219,
                "11": 0.017507,
                "12": 0.018053,
                "13": 0.018224,
                "14": 0.016694,
                "15": 0.017553,
                "16": 0.018176,
                "17": 0.017686,
                "18": 0.017134,
                "19": 0.018316,
                "20": 0.01737,
                "21": 0.017336,
                "22": 0.018333,
                "23": 0.017972,
                "24": 0.017404,
                "25": 0.018137,
                "26": 0.016722,
                "27": 0.01738,
                "28": 0.017265,
                "29": 0.017253,
                "30": 0.017112,
                "31": 0.017433,
                "32": 0.016533,
                "33": 0.016574,
                "34": 0.018312,
                "35": 0.017775,
                "36": 0.017402,
                "37": 0.017404,
                "38": 0.017638,
                "39": 0.017271,
                "40": 0.017299,
                "41": 0.017651,
                "42": 0.017915,
                "43": 0.018294,
                "44": 0.017035,
                "45": 0.01726,
                "46": 0.017264,
                "47": 0.017348,
                "48": 0.017528,
                "49": 0.017864,
                "50": 0.017075,
                "51": 0.017055,
                "52": 0.017761,
                "53": 0.017288,
                "54": 0.017828,
                "55": 0.017246,
                "56": 0.01708,
                "57": 0.018022,
                "58": 0.016952,
                "59": 0.017871,
                "60": 0.017369,
                "61": 0.017516,
                "62": 0.017174,
                "63": 0.017813,
                "64": 0.017548,
                "65": 0.017753,
                "66": 0.017426,
                "67": 0.017885,
                "68": 0.017715,
                "69": 0.017757,
                "70": 0.017618,
                "71": 0.017526,
                "72": 0.017087,
                "73": 0.018494,
                "74": 0.016682,
                "75": 0.018171,
                "76": 0.018155,
                "77": 0.017667,
                "78": 0.017059,
                "79": 0.017313,
                "80": 0.017203,
                "81": 0.017118,
                "82": 0.017367,
                "83": 0.017053,
                "84": 0.016209,
                "85": 0.017778,
                "86": 0.017548,
                "87": 0.017507,
                "88": 0.017444,
                "89": 0.017705,
                "90": 0.018028,
                "91": 0.018563,
                "92": 0.016574,
                "93": 0.017691,
                "94": 0.017738,
                "95": 0.017377,
                "96": 0.017051,
                "97": 0.017381,
                "98": 0.01774,
                "99": 0.016736,
                "100": 0.017932,
                "101": 0.018085,
                "102": 0.017593,
                "103": 0.017027,
                "104": 0.017323,
                "105": 0.017971,
                "106": 0.017223,
                "107": 0.017879,
                "108": 0.017996,
                "109": 0.017925,
                "110": 0.017372,
                "111": 0.017642,
                "112": 0.017087,
                "113": 0.017527,
                "114": 0.01738,
                "115": 0.016832,
                "116": 0.017528,
                "117": 0.017306,
                "118": 0.016111
            },
            "validation_accuracy": 0.9869,
            "validation_time": 0.18131,
            "epoch_time": 2.24761700630188
        }
    },
    "computing_system": "p2-8",
    "batch_size": "512"
}
